(window.webpackJsonp=window.webpackJsonp||[]).push([[150],{462:function(s,t,a){"use strict";a.r(t);var n=a(7),r=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"_3-kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-kafka"}},[s._v("#")]),s._v(" 3.Kafka")]),s._v(" "),t("h4",{attrs:{id:"概述"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[s._v("#")]),s._v(" 概述")]),s._v(" "),t("p",[s._v("Kafka 是基于"),t("strong",[s._v("发布/订阅模型")]),s._v("的消息系统, 是一个"),t("strong",[s._v("基于 Zookeeper 协调的分布式消息系统")]),s._v(", 是一个分布式流式处理平台.")]),s._v(" "),t("blockquote",[t("p",[s._v("Kafka的特点")])]),s._v(" "),t("p",[s._v("Kafka 主要特点:")]),s._v(" "),t("ul",[t("li",[s._v("以时间复杂度为 O(1) 的方式提供"),t("strong",[s._v("消息持久化")]),s._v("能力, 即使对 TB 级以上数据也能保证"),t("strong",[s._v("常数时间复杂度的访问性能")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("高吞吐率")]),s._v(". 能做到单机支持"),t("strong",[s._v("每秒 100K 条以上")]),s._v("消息传输.")]),s._v(" "),t("li",[s._v("支持 Kafka Server 间的消息分区及分布式消费, 同时保证"),t("strong",[s._v("每个 Partition 内的消息顺序传输")]),s._v(".")]),s._v(" "),t("li",[s._v("同时支持离线数据处理和实时数据处理.")]),s._v(" "),t("li",[s._v("支持在线水平扩展.")])]),s._v(" "),t("blockquote",[t("p",[s._v("Kafka的应用场景")])]),s._v(" "),t("p",[s._v("Kafka 主要应用场景:")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("消息队列")]),s._v(": 建立实时流数据管道, 以可靠地在系统或应用程序之间获取数据.")]),s._v(" "),t("li",[t("strong",[s._v("数据处理:")]),s._v("  构建实时的流数据处理程序来转换或处理数据流.")]),s._v(" "),t("li",[t("strong",[s._v("日志收集")]),s._v(": 可以用 Kafka 收集各种服务的日志, 并以"),t("strong",[s._v("统一接口服务")]),s._v("的方式开放给各种消费者, 如 Hadoop, Hbase, Solr 等.")]),s._v(" "),t("li",[t("strong",[s._v("用户活动跟踪")]),s._v(": 可以用于记录用户的浏览网页, 搜索, 点击等活动, 这些信息被各个服务器发布到 Kafka, 消费者者通过订阅这些信息来做实时监控分析, 或者装载到 Hadoop, 数据仓库中做离线分析和挖掘.")]),s._v(" "),t("li",[t("strong",[s._v("运营指标")]),s._v(": 可以用来记录运营监控数据. 包括收集各种分布式应用数据, 生产各种操作的集中反馈, 比如报警和报告.")])]),s._v(" "),t("h4",{attrs:{id:"kafka架构模型🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka架构模型🌟"}},[s._v("#")]),s._v(" Kafka架构模型🌟")]),s._v(" "),t("p",[s._v("整体架构如下所示.")]),s._v(" "),t("p",[s._v("​"),t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703210722829.png",alt:""}}),s._v("​")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("Producer(生产者)")]),s._v(" : 消息生产者.")]),s._v(" "),t("li",[t("strong",[s._v("Consumer(消费者)")]),s._v(" : 消息消费者.")]),s._v(" "),t("li",[t("strong",[s._v("Consumer Group(消费者组)")]),s._v(" : 由多个 consumer 组成. 消费者组内每个消费者负责消费"),t("strong",[s._v("不同分区")]),s._v("的数据, "),t("strong",[s._v("一个分区只能由一个消费者消费, 消费者组之间互不影响")]),s._v(". 消费者组是逻辑上的一个订阅者. 如果只有一个消费组, 那么架构其实就是消息模型中的"),t("strong",[s._v("点对点模型")]),s._v("; 如果有多个消费组, 那就对应消息模型中的"),t("strong",[s._v("发布订阅模型")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("Broker")]),s._v(": 可以看作是一个独立的 Kafka "),t("strong",[s._v("服务器实例")]),s._v(". 多个 Broker 组成 Kafka Cluster.")]),s._v(" "),t("li",[t("strong",[s._v("Topic(主题)")]),s._v(" : 生产者将消息发送到特定的"),t("strong",[s._v("主题")]),s._v(", 消费者需订阅特定的主题来消费消息.")]),s._v(" "),t("li",[t("strong",[s._v("Partition(分区)")]),s._v(" : Partition 可以理解为"),t("strong",[s._v("消息队列中的队列")]),s._v(". 主要使用来实现负载均衡. Partition 属于 Topic 的一部分. 一个 "),t("strong",[s._v("Topic 可以有多个 Partition")]),s._v(", 同一 Topic 下的 Partition 可以"),t("strong",[s._v("分布在不同的 Broker 上")]),s._v(", 这表明一个 Topic 可以分布在多个 Broker.")]),s._v(" "),t("li",[t("strong",[s._v("Replica")]),s._v(": 为保证集群中的某个节点发生故障时, 该节点上的 Partition 数据不丢失, Kafka 提供了"),t("strong",[s._v("副本机制")]),s._v(", 一个 Topic 的每个分区都有若干个副本, 副本包含一个 "),t("strong",[s._v("leader")]),s._v(" 和若干个 "),t("strong",[s._v("follower")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("Leader")]),s._v(": 每个分区"),t("strong",[s._v('多个副本的 "主"')]),s._v(" , 生产者发送数据的对象, 以及消费者消费数据的对象都是 leader.")]),s._v(" "),t("li",[t("strong",[s._v("Follower")]),s._v(": 每个分区"),t("strong",[s._v('多个副本中的 "从"')]),s._v(" , 实时从 leader 中"),t("strong",[s._v("同步")]),s._v("数据, 保持和 leader 数据的一致. leader 发生故障时, 会选举一个 follower 会成为新的 leader.")])]),s._v(" "),t("p",[s._v("服务端(Brokers)和客户端(Producer, Consumer)之间通过 "),t("strong",[s._v("TCP 协议")]),s._v("完成通信.")]),s._v(" "),t("h4",{attrs:{id:"生产者🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#生产者🌟"}},[s._v("#")]),s._v(" 生产者🌟")]),s._v(" "),t("h5",{attrs:{id:"_1-发消息流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-发消息流程"}},[s._v("#")]),s._v(" 1.发消息流程")]),s._v(" "),t("p",[t("strong",[s._v("Kafka 每次发送数据都是向 Leader 分区发送数据, 并顺序写入到磁盘, 然后 Leader 分区会将数据同步到各个 Follower 分区")]),s._v(".")]),s._v(" "),t("p",[s._v("数据写入分区的原则: 1.数据在写入的时候可以指定需要写入的分区, 如果有则写入指定的分区; 2.如果没有指定分区, 但设置了数据 key, 则根据 key 值 hash 出一个分区; 3.如果既没指定分区也没有设置 key, 则轮询选出一个分区.")]),s._v(" "),t("p",[s._v("发现消息的整体流程如下:")]),s._v(" "),t("ol",[t("li",[s._v("首先创建一个 "),t("strong",[s._v("ProducerRecord")]),s._v(", 这个对象需要包含消息的"),t("strong",[s._v("主题(topic)和值(value)")]),s._v(" , 可以选择性"),t("strong",[s._v("指定一个键值(key)或分区(partition)")]),s._v(" .")]),s._v(" "),t("li",[s._v("发送消息时, 生产者会将键和值"),t("strong",[s._v("序列化为字节数组")]),s._v(", 然后发送到"),t("strong",[s._v("分配器(partitioner)")]),s._v(" .")]),s._v(" "),t("li",[s._v("如果指定了"),t("strong",[s._v("分区")]),s._v(", 那么分配器返回该分区即可; 否则分配器将会"),t("strong",[s._v("基于键值")]),s._v("来选择一个分区并返回.")]),s._v(" "),t("li",[s._v("选择完分区后, 生产者知道了消息所属的主题和分区, 它将这条记录添加到相同主题和分区的"),t("strong",[s._v("批量消息")]),s._v("中, 另一个线程负责发送这些批量消息到对应的 broker.")]),s._v(" "),t("li",[s._v("broker 接收到消息后, 如果成功写入则"),t("strong",[s._v("返回一个包含消息的主题, 分区及位移的 RecordMetadata 对象")]),s._v(", 否则返回异常.")]),s._v(" "),t("li",[s._v("生产者接收到结果后, 对于异常可能会进行重试.")])]),s._v(" "),t("h5",{attrs:{id:"_2-发消息模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-发消息模型"}},[s._v("#")]),s._v(" 2.发消息模型")]),s._v(" "),t("p",[s._v("Kafka 中 "),t("strong",[s._v("Partition(分区)是存储保存消息的地方")]),s._v(", 发送的消息都被放在分区里. 每次添加消息到 Partition 的时候都会采用"),t("strong",[s._v("尾加法")]),s._v(", 如图所示.")]),s._v(" "),t("p",[s._v("​"),t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703211238314.png",alt:""}}),s._v("​")]),s._v(" "),t("h4",{attrs:{id:"消费者🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费者🌟"}},[s._v("#")]),s._v(" 消费者🌟")]),s._v(" "),t("h5",{attrs:{id:"_1-消费者与消费组"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-消费者与消费组"}},[s._v("#")]),s._v(" 1.消费者与消费组")]),s._v(" "),t("p",[s._v("消费者需要主动从 Leader 分区拉取数据.")]),s._v(" "),t("p",[t("strong",[s._v("多个消费者可以组成一个消费组, 同一个消费组者的消费者可以消费同一个 topic 下不同分区的数据, 但一个分区的消息只会被一个消费组内的一个消费者消费, 防止出现重复消费的问题. 注意: 不同的消费者组, 依然可以消费同一个分区的数据")]),s._v(".")]),s._v(" "),t("p",[s._v("假设有一个 T1 主题, 该主题有 4 个分区. 同时有一个消费组 G1, 该消费组只有一个消费者 C1. 那么 C1 将会消费这 4 个分区的消息, 如下所示.")]),s._v(" "),t("p",[s._v("​"),t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212022186.png",alt:""}}),s._v("​")]),s._v(" "),t("p",[s._v("如果增加新的消费者 C2 到消费组 G1, 那么每个消费者将会分别消费"),t("strong",[s._v("两个分区")]),s._v("的消息, 如下所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212044971.png",alt:""}})]),s._v(" "),t("p",[s._v("如果增加到 4 个消费者, 那么每个消费者将会分别消费"),t("strong",[s._v("一个分区")]),s._v("的消息, 如下所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212107839.png",alt:""}})]),s._v(" "),t("p",[s._v("但如果继续增加消费者到这个消费组, "),t("strong",[s._v("剩余的消费者将会空闲")]),s._v(", 不会消费任何消息:")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212140432.png",alt:""}})]),s._v(" "),t("p",[s._v("总而言之, 当消费速度低于生产速度引起消息堆积时, 可以"),t("strong",[s._v("通过增加消费者数量来进行水平扩展提升消费能力")]),s._v(". 因此建议创建主题时选择使用适量的分区数, 这样可以在消费负载高的情况下增加消费者来提升性能. 注意: 消费者的数量"),t("strong",[s._v("不应该比分区数多")]),s._v(", 因为多出来的消费者是空闲的, 没有任何帮助.")]),s._v(" "),t("p",[t("strong",[s._v("Kafka 只需写入一次消息, 就能支持任意多的消费者组读取这个消息.")]),s._v(" "),t("strong",[t("strong",[s._v("换句话说,")])]),s._v("   ******每个**"),t("strong",[t("strong",[s._v("​")]),s._v("消费者组")]),s._v("​****"),t("strong",[s._v("都可以消费全量的消息"),t("strong",[t("strong",[t("strong",[s._v("​ "),t("strong",[t("strong",[s._v(". 为了使得每个应用都能读到全量消息, 应用需要有")])]),s._v("​")]),s._v("不同的消费组")]),s._v(". 假如新增了一个新的消费组 G2, 而这个消费组有")]),s._v("两个消费者")]),s._v(", 那么消费方式如下所示.")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212219650.png",alt:""}})]),s._v(" "),t("p",[s._v("这里消费组 G1 和 G2 都能收到 T1 主题的"),t("strong",[s._v("全量消息")]),s._v(", 在逻辑意义上来说它们"),t("strong",[s._v("属于不同的应用")]),s._v(".")]),s._v(" "),t("p",[s._v("如果应用需要读取全量消息, 那需要为该应用设置一个消费组; 如果该应用消费能力不足, 那么考虑在这个消费组里增加消费者. 实际的应用中, "),t("strong",[s._v("建议消费者组的消费者数量与分区数量保持一致")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_2-分区重平衡"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-分区重平衡"}},[s._v("#")]),s._v(" 2.分区重平衡")]),s._v(" "),t("p",[s._v("当"),t("strong",[s._v("新的消费者")]),s._v("加入"),t("strong",[s._v("消费组")]),s._v(", 它会消费一个或多个分区, 而这些分区之前是由其他消费者负责的; 或当有消费者离开消费组(如重启, 宕机等)时, 它所消费的分区会"),t("strong",[s._v("分配给其他分区")]),s._v(". 这种现象称为"),t("strong",[s._v("重平衡(rebalance)")]),s._v(" . 重平衡保证了高可用和水平扩展.")]),s._v(" "),t("p",[t("strong",[s._v("注意: 在重平衡期间, 所有消费者都不能消费消息, 因此这会造成整个消费组短暂的不可用")]),s._v(". 将分区进行重平衡也会导致原来的消费者状态过期, 导致消费者需要重新更新状态, 这段期间也会降低消费性能.")]),s._v(" "),t("p",[s._v("消费者通过"),t("strong",[s._v("定期发送心跳")]),s._v("(hearbeat)到一个作为组协调者(group coordinator)的 broker 来保持在消费组内存活. 这个 broker 不是固定的, 每个消费组都可能不同. 当消费者拉取消息或者提交时, 便会发送心跳. 如果消费者超过一定时间没有发送心跳, 那么它的"),t("strong",[s._v("会话(session)就会过期")]),s._v(", 组协调者会认为该消费者已经宕机, 然后触发重平衡. 从消费者宕机到会话过期是有一定时间的, 这段时间内该消费者的分区都不能进行消息消费. 可以进行"),t("strong",[s._v("优雅关闭")]),s._v(", 这样消费者会发送离开的消息给组协调者, 这样组协调者可以"),t("strong",[s._v("立即进行重平衡")]),s._v("而不需要等待会话过期.")]),s._v(" "),t("p",[t("strong",[s._v("Kafka 将发送心跳与拉取消息进行分离")]),s._v(", 这样发送心跳的频率不受拉取的频率影响. 高版本的 Kafka 支持配置一个消费者多长时间不拉取消息但仍然保持存活, 这个配置可以避免活锁(livelock). "),t("strong",[s._v("活锁")]),s._v("是指应用没有故障但是由于某些原因不能进一步消费.")]),s._v(" "),t("h5",{attrs:{id:"_3-kafka消费模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-kafka消费模式"}},[s._v("#")]),s._v(" 3.Kafka消费模式")]),s._v(" "),t("p",[s._v("消费者从 Broker 获取到数据有两种方式. 1."),t("strong",[s._v("push 模式")]),s._v(": Broker 向消费者"),t("strong",[s._v("推送数据")]),s._v("; 2."),t("strong",[s._v("pull 模式")]),s._v(": 消费者从 Broker "),t("strong",[s._v("拉取数据")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("push 模式")]),s._v("的目标是尽可能以最快速度传递消息, 但是这样很"),t("strong",[s._v("容易造成消费者来不及处理消息")]),s._v(", 典型的表现就是拒绝服务以及网络拥塞. push 模式很难适应消费速率不同的消费者, 因为这种模式下消息发送速率由 broker 决定. 而 "),t("strong",[s._v("pull 模式")]),s._v("则可以根据消费者的"),t("strong",[s._v("消费能力")]),s._v("以适当的速率消费消息.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("对 Kafka 而言, pull 模式更合适. 消费者可以自己控制消费消息的速率")])]),s._v(", 也可以自己控制消费方式: 即可批量消费也可逐条消费, 同时还能选择不同的提交方式从而实现不同的传输语义.")]),s._v(" "),t("h5",{attrs:{id:"_4-消费位置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-消费位置"}},[s._v("#")]),s._v(" 4.消费位置")]),s._v(" "),t("p",[s._v("分区中的"),t("strong",[s._v("消息可以被不同的消费组多次消费")]),s._v(", 那分区中被消费的消息是何时删除的? 分区又是如何知道一个消费组当前消费的位置呢?")]),s._v(" "),t("p",[s._v("Partition 会为"),t("strong",[s._v("每个消费组保存一个偏移量")]),s._v(", 记录"),t("strong",[s._v("消费组消费到的位置")]),s._v(". 如下图:")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703212811956.png",alt:""}})]),s._v(" "),t("p",[s._v("无论消息是否被消费, "),t("mark",[t("strong",[s._v("分区从不删除消息, 除非消息到期")])]),s._v(". 如设置保留时间为 2 天, 则消息发布 2 天内任何消费组都可以消费, 2 天后消息自动被删除.")]),s._v(" "),t("h5",{attrs:{id:"_5-消息消费顺序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-消息消费顺序"}},[s._v("#")]),s._v(" 5.消息消费顺序")]),s._v(" "),t("p",[s._v("在使用消息队列的过程中经常有业务场景需要"),t("strong",[s._v("严格保证")]),s._v("消息的消费顺序, 比如同时发了 2 个消息, 这 2 个消息对应的操作分别对应的数据库操作是: 更改用户会员等级, 根据会员等级计算订单价格. 假如这两条消息的消费顺序不一样造成的最终结果就会截然不同.")]),s._v(" "),t("p",[s._v("Kafka 中一个 topic 的消息是"),t("strong",[s._v("被打散分配到多个分区中存储的")]),s._v(", 消费组在消费时需要从不同分区获取消息, 那最终如何重建出 Topic 中消息的"),t("strong",[s._v("顺序")]),s._v("? 答案是: "),t("strong",[s._v("没有办法")]),s._v(". "),t("mark",[t("strong",[s._v("Kafka 只会保证在同一个分区内消息是有序的, 而不能保证 Topic(主题) 中所有 Partition(分区) 的全局有序性")])]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703211238314.png",alt:""}})]),s._v(" "),t("p",[s._v("消息在被追加到分区的时候都会"),t("strong",[s._v("分配一个特定的偏移量")]),s._v("(offset), 偏移量表示消费者当前消费到分区的所在位置. Kafka "),t("strong",[s._v("通过偏移量来保证消息在分区内的顺序性")]),s._v(".")]),s._v(" "),t("p",[s._v("Kafka 发送一条消息的时候, 可以指定 "),t("strong",[s._v("topic, partition, key, data")]),s._v(" 等参数. 如果发送消息时指定了 Partition 参数, 则所有消息都"),t("strong",[s._v("会被发送到指定的分区")]),s._v(". 并且同一个 key 的消息可以"),t("strong",[s._v("保证只发送到同一个分区")]),s._v(". 这里可以采用表/对象的 id 来作为 key.")]),s._v(" "),t("h5",{attrs:{id:"_6-offset的维护"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-offset的维护"}},[s._v("#")]),s._v(" 6.offset的维护")]),s._v(" "),t("p",[s._v("由于消费者在消费过程中可能会出现断电宕机等故障, 故障恢复后, 需要从故障前的位置继续消费, 所以消费者需要实时记录自己消费到了哪个 "),t("strong",[s._v("offset")]),s._v(", 以便故障恢复后继续消费.")]),s._v(" "),t("p",[t("strong",[s._v("group + topic + partition 才能确定一个 offset!")])]),s._v(" "),t("p",[s._v("消费者默认"),t("strong",[s._v("将 offset 保存在 Kafka 本地一个内置的 topic 中")]),s._v(", 该 topic 为  "),t("strong",[s._v("__consumer_offsets")]),s._v("(此时消费者对于 offset 相当于生产者).")]),s._v(" "),t("h4",{attrs:{id:"常见消费问题解决🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#常见消费问题解决🌟"}},[s._v("#")]),s._v(" 常见消费问题解决🌟")]),s._v(" "),t("p",[s._v("消息队列应该考虑的一些可能出现的消费问题有:")]),s._v(" "),t("ul",[t("li",[s._v("**如何保证消息不丢失? **")]),s._v(" "),t("li",[s._v("**如何保证消息不被重复消费? **")])]),s._v(" "),t("h5",{attrs:{id:"_1-保证消息不丢失-可靠性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-保证消息不丢失-可靠性"}},[s._v("#")]),s._v(" 1.保证消息不丢失/可靠性")]),s._v(" "),t("h6",{attrs:{id:"_1-生产者丢失消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-生产者丢失消息"}},[s._v("#")]),s._v(" (1)生产者丢失消息")]),s._v(" "),t("p",[s._v("生产者发送消息之后, 消息可能因为"),t("strong",[s._v("网络问题")]),s._v("并没有发送到消息队列, 所以不能认为发送消息就一定会成功. 为确定消息是否发送成功, "),t("strong",[s._v("需要判断消息发送的结果")]),s._v(". 可以"),t("strong",[s._v("添加回调函数, 如果消息发送失败, 检查失败原因后重新发送即可")]),s._v("!")]),s._v(" "),t("p",[s._v("推荐为生产者的 "),t("strong",[s._v("retries(重试次数)设置一个比较合理的值")]),s._v(", 一般是 "),t("strong",[s._v("3")]),s._v(", 为保证消息不丢失也可以设置比较大一点. 设置完成后, 当出现网络问题时能够"),t("strong",[s._v("自动重试消息发送")]),s._v(", 避免消息丢失.")]),s._v(" "),t("h6",{attrs:{id:"_2-消费者丢失消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-消费者丢失消息"}},[s._v("#")]),s._v(" (2)消费者丢失消息")]),s._v(" "),t("p",[s._v("当消费者"),t("strong",[s._v("拉取")]),s._v("到了分区的某个消息之后, "),t("strong",[s._v("消费者会自动提交 offset")]),s._v(". 自动提交可能存在问题, 即当消费者刚拿到这个消息准备进行真正消费的时候, 突然挂了, "),t("strong",[s._v("消息实际上并没有被消费, 但 offset 却被自动提交了")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("解决办法也比较粗暴, 关闭自动提交 offset, 每次在真正消费完消息之后再自己手动提交 offset.")]),s._v(" "),t("strong",[t("strong",[s._v("但这样会带来消息被")])]),s._v("​"),t("strong",[s._v("重复消费")]),s._v("的问题. 比如刚刚消费完消息后还没提交 offset, 结果消费者挂了, 消费者恢复后会再次拉取并消费前一次的消息, 造成重复消费.")]),s._v(" "),t("h6",{attrs:{id:"_3-kafka自身丢失消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-kafka自身丢失消息"}},[s._v("#")]),s._v(" (3)Kafka自身丢失消息")]),s._v(" "),t("p",[s._v("Kafka 为分区引入了多副本(Replica)机制. 如果 leader 副本所在的 broker 突然挂掉, 那就需要从 follower 副本重新选出一个 leader. "),t("strong",[s._v("如果挂掉的 leader 数据还有一些没有被 follower 副本的同步的话, 就会造成消息丢失")]),s._v(".")]),s._v(" "),t("p",[s._v("解决方法:")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("设置 acks = all")]),s._v(". acks 是为生产者配置的参数. acks 默认值为 1, 代表消息被 leader 接收之后就算发送成功. 配置 "),t("strong",[s._v("acks = all")]),s._v(" 代表则"),t("strong",[s._v("所有副本都要接收到该消息")]),s._v("之后该消息才算发送成功.")]),s._v(" "),t("li",[t("strong",[s._v("设置 replication.factor >= 3")]),s._v(". 可以保证每个分区至少有 3 个副本. 虽然造成了数据冗余, 但提高了数据安全性.")]),s._v(" "),t("li",[t("strong",[s._v("设置 min.insync.replicas > 1")]),s._v(". 这个配置代表消息至少要被写入到 "),t("strong",[s._v("2 个副本")]),s._v("才算是被成功发送. min.insync.replicas 默认值为 1, 生产环境中应尽量避免使用默认值. 但为了保证整个 Kafka 服务的高可用性, 需要确保 "),t("strong",[s._v("replication.factor > min.insync.replicas")]),s._v(". 为什么? 因为在两者相等的情况下, 只要有一个副本挂掉, 整个分区就无法正常工作了. 这明显违反高可用性! 一般推荐设置为 "),t("strong",[s._v("replication.factor = min.insync.replicas + 1")]),s._v(".")])]),s._v(" "),t("h5",{attrs:{id:"_2-保证消息不被重复消费"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-保证消息不被重复消费"}},[s._v("#")]),s._v(" 2.保证消息不被重复消费")]),s._v(" "),t("p",[s._v("如何保证消息"),t("strong",[s._v("不被重复消费")]),s._v(", 也就是保证消息消费的"),t("strong",[s._v("幂等性")]),s._v(".")]),s._v(" "),t("h6",{attrs:{id:"_1-重复消费问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-重复消费问题"}},[s._v("#")]),s._v(" (1)重复消费问题")]),s._v(" "),t("p",[t("strong",[s._v("每个消息")]),s._v("被写进去后都有一个 "),t("strong",[s._v("offset")]),s._v(", 代表消息顺序. 当消费者消费该数据之后, 会把"),t("strong",[s._v("自己消费过的消息的 offset 进行提交")]),s._v(", 代表已经消费过了. 下次要是重启, 就会继续从上次"),t("strong",[s._v("消费到的 offset")]),s._v(" 继续消费.")]),s._v(" "),t("p",[s._v("如果直接消费者突然挂到后再重启, 就可能导致消费者已经消费了消息, 但"),t("strong",[s._v("没来得及提交 offset")]),s._v(". 等重启之后, 少数消息就会"),t("strong",[s._v("再次消费一次")]),s._v(".")]),s._v(" "),t("p",[s._v("其他 MQ 也会有重复消费的问题, 需要针对实际场景来考虑如何"),t("strong",[s._v("保证重复消费的幂等性")]),s._v(".")]),s._v(" "),t("h6",{attrs:{id:"_2-保证幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-保证幂等性"}},[s._v("#")]),s._v(" (2)保证幂等性")]),s._v(" "),t("p",[t("strong",[s._v("怎么保证消息队列消费的幂等性?")]),s._v("  需要结合业务来思考.")]),s._v(" "),t("ul",[t("li",[s._v("通过 "),t("strong",[s._v("insertOrUpdate")]),s._v(" 的方式进行数据写库.")]),s._v(" "),t("li",[s._v("对于消息可以单独"),t("strong",[s._v("建表")]),s._v(", 用于存储消息消费记录. 生产者发送消息前"),t("strong",[s._v("判断库中是否有记录")]),s._v(", 没有记录则先入库, 状态为"),t("strong",[s._v("待消费")]),s._v(", 发送消息时把主键 id 带上. 消费者接收消息时通过主键 id 查询记录表, 判断消息状态是否已消费. 若没有消费, 则处理消息, 处理完后, 更新消息记录的状态为已消费.")])]),s._v(" "),t("h4",{attrs:{id:"可靠性🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可靠性🌟"}},[s._v("#")]),s._v(" 可靠性🌟")]),s._v(" "),t("h5",{attrs:{id:"_1-概述"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-概述"}},[s._v("#")]),s._v(" 1.概述")]),s._v(" "),t("p",[s._v("Kafka 中的可靠性保证有如下四点:")]),s._v(" "),t("ul",[t("li",[s._v("对于"),t("strong",[s._v("一个分区")]),s._v("来说, 它的"),t("strong",[s._v("消息是有序")]),s._v("的.")]),s._v(" "),t("li",[s._v("当消息写入所有 "),t("strong",[s._v("in-sync 状态的副本")]),s._v("后, 消息才会认为"),t("strong",[s._v("已提交(committed)")]),s._v(" . 这里的写入有可能只是写入到文件系统的"),t("strong",[s._v("缓存")]),s._v(", 不一定刷新到磁盘. 生产者可以等待不同时机的确认, 比如等待分区主副本"),t("strong",[s._v("写入即返回")]),s._v(", 或者等待所有 in-sync 状态副本写入才返回.")]),s._v(" "),t("li",[s._v("一旦消息已提交, 只要有一个副本存活, 数据就不会丢失.")]),s._v(" "),t("li",[s._v("消费者只能"),t("strong",[s._v("读取到已提交")]),s._v("的消息.")])]),s._v(" "),t("p",[s._v("可靠性不是无偿的, 它与系统可用性, 吞吐量, 延迟息息相关, 因此往往需要做权衡, 只追求可靠性并不实际.")]),s._v(" "),t("h5",{attrs:{id:"_2-多副本机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-多副本机制"}},[s._v("#")]),s._v(" 2.多副本机制")]),s._v(" "),t("p",[s._v("Kafka 为分区引入了"),t("strong",[s._v("多副本(Replica)机制")]),s._v(". 分区中的多个副本之间会有一个 leader 副本, 其他副本称为 "),t("strong",[s._v("follower")]),s._v(" 副本. 发送的消息会"),t("strong",[s._v("被发送到 leader 副本")]),s._v(", 然后 follower 副本才能从 leader 副本中"),t("strong",[s._v("拉取消息进行同步")]),s._v(".")]),s._v(" "),t("p",[s._v("生产者和消费者"),t("strong",[s._v("只与 leader 副本交互")]),s._v(". 其他副本只是 leader 副本的"),t("strong",[s._v("拷贝")]),s._v(", 它们的存在只是为了"),t("strong",[s._v("保证消息存储的安全性")]),s._v(". 当 leader 副本发生故障时会从 follower 中"),t("strong",[s._v("选举出一个 leader")]),s._v(". follower 副本如果与 leader 同步程度达不到要求则无法参与 leader 选举.")]),s._v(" "),t("p",[t("strong",[s._v("多副本机制的好处")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("通过给特定 Topic 指定多个分区, 而各个分区可以"),t("strong",[s._v("分布在不同的 Broker 上")]),s._v(", 这样能提供较好的并发能力("),t("strong",[s._v("负载均衡")]),s._v(").")]),s._v(" "),t("li",[s._v("分区可以指定对应的 Replica 数量, 这可以提高消息存储"),t("strong",[s._v("安全性")]),s._v(", 提高容灾能力, 不过也相应的增加了所需的存储空间.")])]),s._v(" "),t("h5",{attrs:{id:"_3-副本数据同步策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-副本数据同步策略"}},[s._v("#")]),s._v(" 3.副本数据同步策略")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",{staticStyle:{"text-align":"center"}},[t("strong",[s._v("方案")])]),s._v(" "),t("th",{staticStyle:{"text-align":"center"}},[t("strong",[s._v("优点")])]),s._v(" "),t("th",{staticStyle:{"text-align":"center"}},[t("strong",[s._v("缺点")])])])]),s._v(" "),t("tbody",[t("tr",[t("td",{staticStyle:{"text-align":"center"}},[t("strong",[s._v("半数以上完成同步, 就发送 ack")])]),s._v(" "),t("td",{staticStyle:{"text-align":"center"}},[s._v("延迟低")]),s._v(" "),t("td",{staticStyle:{"text-align":"center"}},[s._v("选举新的 leader 时, 容忍 n 台节点的故障, 需要 2n + 1 个副本")])]),s._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[t("strong",[s._v("全部完成同步, 才发送 ack")])]),s._v(" "),t("td",{staticStyle:{"text-align":"center"}},[s._v("选举新 leader 时, 容忍 n 台节点的故障, 需要 n + 1 个副本")]),s._v(" "),t("td",{staticStyle:{"text-align":"center"}},[s._v("延迟高")])])])]),s._v(" "),t("p",[s._v("Kafka 选择了"),t("strong",[s._v("第二种方案")]),s._v(", 原因如下:")]),s._v(" "),t("ul",[t("li",[s._v("同样为了容忍 n 台节点的故障, 第一种方案需要 2n + 1 个副本, 而第二种方案只需要 n + 1 个副本, Kafka 的每个分区都有大量数据, 第一种方案会造成大量数据冗余.")]),s._v(" "),t("li",[s._v("虽然第二种方案的网络延迟会比较高, 但网络延迟对 Kafka 的影响较小(一般在同一网络环境下传输).")])]),s._v(" "),t("h4",{attrs:{id:"kafka与zookeeper"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka与zookeeper"}},[s._v("#")]),s._v(" Kafka与Zookeeper")]),s._v(" "),t("p",[s._v("ZooKeeper 主要为 Kafka 提供"),t("strong",[s._v("元数据管理")]),s._v("的功能.")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("Broker 注册")]),s._v(": Zookeeper 上有一个专门"),t("strong",[s._v("用来进行 Broker 服务器列表记录")]),s._v("的节点. 每个 Broker 启动时, 都会到 Zookeeper 上进行"),t("strong",[s._v("注册")]),s._v(", 即到  "),t("strong",[s._v("/brokers/ids")]),s._v(" 下创建属于自己的节点. 每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中.")]),s._v(" "),t("li",[t("strong",[s._v("Topic 注册")]),s._v(": 在 Kafka 中, 同一个 Topic 的消息会被"),t("strong",[s._v("分成多个分区并将其分布在多个 Broker 上")]),s._v(", 这些分区信息及与 Broker 的"),t("strong",[s._v("对应关系也是由 Zookeeper 维护")]),s._v(". 比如创建了一个名字为 "),t("strong",[s._v("my-topic")]),s._v(" 的主题并且它有两个分区, 对应到 Zookeeper 中会创建下面的文件夹:  "),t("strong",[s._v("/brokers/topics/my-topic/Partitions/0, /brokers/topics/my-topic/Partitions/1")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("负载均衡")]),s._v(": 对于同一个 Topic 的不同分区, Kafka 会"),t("strong",[s._v("尽力将这些分区分布到不同的 Broker 服务器上")]),s._v(". 当生产者产生消息后也会尽量投递到不同 Broker 的分区里面. 当消费者进行消费时, Zookeeper 可以根据当前的分区数量以及消费者数量来实现"),t("strong",[s._v("动态负载均衡")]),s._v(".")])]),s._v(" "),t("h4",{attrs:{id:"kafka与存储实现🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka与存储实现🌟"}},[s._v("#")]),s._v(" Kafka与存储实现🌟")]),s._v(" "),t("h5",{attrs:{id:"_1-kafka消息存储方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-kafka消息存储方式"}},[s._v("#")]),s._v(" 1.Kafka消息存储方式")]),s._v(" "),t("p",[s._v("Kafka 的消息是"),t("strong",[s._v("存储在于文件系统")]),s._v("之上的. Kafka 高度依赖文件系统来"),t("strong",[s._v("存储和缓存")]),s._v('消息. 有的人认为 "磁盘是缓慢的", 所以对这样的设计持有怀疑态度. 实际上磁盘可以比预想的快很多或慢很多, 这取决于它们如何被使用; 一个好的磁盘结构设计可以使之与网络速度一样快.')]),s._v(" "),t("p",[s._v("现代的操作系统针对"),t("strong",[s._v("磁盘的读写")]),s._v('已经做了一些优化方案来加快磁盘的访问速度. 比如 "'),t("strong",[s._v("预读")]),s._v('" 会提前将一个比较大的磁盘数据块读入内存. "'),t("strong",[s._v("后写")]),s._v('" 会将很多小的逻辑写操作合并起来组合成一个大的物理写操作. 并且操作系统还会将主内存剩余的所有空闲内存空间都用作'),t("strong",[s._v("磁盘缓存")]),s._v(", 所有的磁盘读写操作都会经过统一的磁盘缓存(除了直接 I/O 会绕过磁盘缓存). 综合这几点优化特点, 如果是针对磁盘的"),t("mark",[t("strong",[s._v("顺序访问")])]),s._v("​, 某些情况下它可能比随机的内存访问都要快, 甚至可以和网络速度相差无几.")]),s._v(" "),t("p",[t("strong",[s._v("Topic 其实是逻辑上的概念, 面向消费者和生产者, 物理上存储的其实是 Partition")]),s._v(", 每一个 Partition 最终对应一个"),t("strong",[s._v("目录, 里面存储所有的消息和索引文件")]),s._v(". 默认情况下, 每个 Topic 在创建时如果不指定 Partition 数量时只会创建 1 个 Partition. 比如创建一个 Topic 名字为 test, 没有指定 Partition 的数量时会默认创建一个 "),t("strong",[s._v("test-0 的文件夹")]),s._v(", 这里的命名规则是: "),t("code",[s._v("<topic_name>-<partition_id>")]),s._v("​.")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703211238314.png",alt:""}})]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部, 这样的顺序写磁盘操作让 Kafka 的效率非常高")])]),s._v(". 经验证, "),t("strong",[s._v("顺序写磁盘")]),s._v("效率可能比随机写内存还要高, 这是 Kafka 高吞吐率的一个重要保证.")]),s._v(" "),t("p",[s._v("每一条消息被发送到 Broker 中, 会"),t("strong",[s._v("根据 Partition 规则")]),s._v("选择被存储到哪一个 Partition. 如果 Partition 规则设置的合理, 所有消息可以均匀分布到不同的 Partition 中.")]),s._v(" "),t("h5",{attrs:{id:"_2-底层存储细节"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-底层存储细节"}},[s._v("#")]),s._v(" 2.底层存储细节")]),s._v(" "),t("p",[s._v("假设 Kafka 集群"),t("strong",[s._v("只有一个 Broker")]),s._v(', 创建 2 个 Topic 名称分别为: "topic1" 和 "topic2", Partition 数量分别为 1, 2, 那么的'),t("strong",[s._v("根目录")]),s._v("下就会创建如下"),t("strong",[s._v("三个文件夹")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic1-0\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic2-0\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic2-1\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("在 Kafka 的"),t("strong",[s._v("文件存储")]),s._v("中, "),t("strong",[s._v("同一个 Topic 下有多个不同的 Partition")]),s._v(", 每个 Partition 都为一个"),t("strong",[s._v("目录")]),s._v(", 而每一个目录又被平均分配成多个大小相等的 "),t("strong",[s._v("Segment File")]),s._v(", Segment File 又由 "),t("strong",[s._v("index file 和 data file 组成")]),s._v(", 它们总是"),t("strong",[s._v("成对出现")]),s._v(', 后缀 ".index" 表示'),t("strong",[s._v("索引文件")]),s._v(', ".log" 表示'),t("strong",[s._v("数据文件")]),s._v(". "),t("strong",[s._v("索引文件中的元数据指向对应数据文件中")]),s._v(" message 的物理偏移地址.")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703213719650.png",alt:""}})]),s._v(" "),t("p",[s._v("假设设置每个 Segment 大小为 500 MB, 并启动生产者向 topic1 发送大量消息, topic1-0 文件夹中就会产生类似如下的一些文件:")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic1-0 \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000000000.index")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000000000.log")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000368769.index")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000368769.log")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000737337.index")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000000737337.log")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000001105814.index")]),s._v(" \n   "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--00000000000001105814.log")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic2-0 \n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" --topic2-1\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[t("strong",[s._v("Segment 是 Kafka 文件存储的最小单位. "),t("strong",[s._v("​"),t("strong",[t("strong",[s._v("Segment 文件命名规则: Partition 全局的第一个 Segment "),t("strong",[t("strong",[s._v("​")])])]),s._v("从 0")])])]),s._v("​ **** 开始, 后续每个 Segment 文件名为上一个 Segment 文件****​"),t("strong",[s._v("最后一条消息的 offset 值")]),s._v(". 数值最大为 64 位 long 大小, 19 位数字字符长度, 没有数字用 0 填充. 如 00000000000000368769.index 和 00000000000000368769.log.")]),s._v(" "),t("p",[s._v("以上面的一对 Segment File 为例, 说明一下"),t("strong",[s._v("索引文件和数据文件对应关系")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/image-20220703214601780.png",alt:""}})]),s._v(" "),t("p",[s._v("其中以索引文件中元数据 "),t("code",[s._v("<3, 497>")]),s._v("​ 为例, 在数据文件中表示第 3 个 message(在全局 Partition 表示第 368769 + 3 = 368772 个 message)以及该消息的物理偏移地址为 497.")]),s._v(" "),t("p",[s._v("注意该 index 文件并不是从 0 开始, 也不是每次递增 1 的, 这是因为 Kafka 采取"),t("strong",[s._v("稀疏索引存储")]),s._v("的方式, 每隔一定字节的数据建立一条索引, 它减少了索引文件大小, 使得能够把 index 映射到内存, 降低了查询时的磁盘 IO 开销, 同时也并没有给查询带来太多的时间消耗.")]),s._v(" "),t("p",[s._v("因为其文件名为上一个 Segment 最后一条消息的 offset, 所以当需要查找一个指定 offset 的消息时, 通过在所有 segment 的文件名中进行"),t("strong",[s._v("二分查找")]),s._v("就能找到它归属的 Segment 文件, 再在其 index 文件中找到其对应到文件上的物理位置, 就能获取该消息.")]),s._v(" "),t("p",[s._v("由于消息在 Partition 的 Segment 数据文件中是"),t("strong",[s._v("顺序读写")]),s._v("的, 且消息消费后不会删除(删除策略是针对过期的 Segment 文件), 这种顺序磁盘 IO 存储设计师 Kafka 高性能很重要的原因.")]),s._v(" "),t("blockquote",[t("p",[s._v("Kafka如何准确的知道message的偏移?")])]),s._v(" "),t("p",[s._v("在 Kafka 定义了标准的数据存储结构, 在 Partition 中的"),t("strong",[s._v("每一条 message 都包含了以下三个属性")]),s._v(":")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("offset")]),s._v(": 表示消息在当前 Partition 中的偏移量, 是一个逻辑值, 唯一确定了 Partition 中的一条 message, 可以简单认为是一个 id.")]),s._v(" "),t("li",[t("strong",[s._v("MessageSize")]),s._v(": 表示 message 内容 data 的大小.")]),s._v(" "),t("li",[t("strong",[s._v("data")]),s._v(": message 的具体内容.")])]),s._v(" "),t("h4",{attrs:{id:"kafka高效读写数据🌟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka高效读写数据🌟"}},[s._v("#")]),s._v(" Kafka高效读写数据🌟")]),s._v(" "),t("h5",{attrs:{id:"_1-顺序写磁盘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-顺序写磁盘"}},[s._v("#")]),s._v(" 1.顺序写磁盘")]),s._v(" "),t("p",[s._v("生产者的消息写入到 log 文件的过程是"),t("strong",[s._v("追加到文件末端的顺序写")]),s._v(". 同样的磁盘, 顺序写能到 "),t("strong",[s._v("600M/s")]),s._v(", 而随机写只有 "),t("strong",[s._v("100k/s")]),s._v(". 这与磁盘的机械机构有关, 顺序写之所以快, 是因为其省去了大量磁头寻址的时间.")]),s._v(" "),t("h5",{attrs:{id:"_2-零拷贝技术"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-零拷贝技术"}},[s._v("#")]),s._v(" 2.零拷贝技术")]),s._v(" "),t("p",[s._v("Kafka 的消息会有"),t("strong",[s._v("多个订阅者")]),s._v(', 生产者发布的消息会被不同的消费者多次消费, 为优化这个流程, Kafka 使用了 "'),t("strong",[s._v("零拷贝技术")]),s._v('".')]),s._v(" "),t("p",[s._v('"零拷贝技术" 只用将'),t("strong",[s._v("磁盘文件的数据复制到页面缓存中一次")]),s._v(", 然后将数据"),t("strong",[s._v("从页面缓存直接发送到网络中")]),s._v("(发送给不同的订阅者时, 都可以使用同一个页面缓存), 避免了重复复制操作.")]),s._v(" "),t("p",[t("strong",[s._v('如果有 10 个消费者, 传统方式下, 数据复制次数为 4 * 10 = 40 次, 而使用 "零拷贝" 只需要 1 + 10 = 11 次, 一次为从磁盘复制到页面缓存, 10 次即 10 个消费者各自读取一次页面缓存')]),s._v(".")]),s._v(" "),t("h4",{attrs:{id:"kafka事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka事务"}},[s._v("#")]),s._v(" Kafka事务")]),s._v(" "),t("p",[s._v("Kafka 从 0.11 版本开始引入了"),t("strong",[s._v("事务")]),s._v(". 事务可以保证 Kafka 在 "),t("strong",[s._v("Exactly Once 语义")]),s._v("的基础上, 生产和消费可以"),t("strong",[s._v("跨分区和会话, 要么全部成功, 要么全部失败")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-生产者事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-生产者事务"}},[s._v("#")]),s._v(" 1.生产者事务")]),s._v(" "),t("p",[s._v("为了实现跨分区跨会话的事务, 需要引入一个"),t("strong",[s._v("全局唯一的 Transaction ID(一定是客户端给的)")]),s._v(" , 并将生产者获得的 PID 和 Transaction ID 绑定. 这样当生产者重启后就可以通过正在进行的 Transaction ID 获得原来的 PID.")]),s._v(" "),t("p",[s._v("为管理 Transaction, Kafka 引入了一个新的组件 "),t("strong",[s._v("Transaction Coordinator")]),s._v(". 生产者就是通过与 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态. Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic, 这样即使整个服务重启, 由于事务状态得到保存, 进行中的事务状态可以得到恢复, 从而继续进行.")]),s._v(" "),t("h5",{attrs:{id:"_2-消费者事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-消费者事务"}},[s._v("#")]),s._v(" 2.消费者事务")]),s._v(" "),t("p",[s._v("对于消费者而言, 事务的保证就会相对较弱, 尤其是"),t("strong",[s._v("无法保证 Commit 的信息被精确消费")]),s._v(". 这是由于消费者可以通过 offset 访问任意信息, 而且不同的 Segment File 生命周期不同, 同一事务的消息可能会出现重启后被删除的情况.")]),s._v(" "),t("h3",{attrs:{id:"基本使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基本使用"}},[s._v("#")]),s._v(" 基本使用")]),s._v(" "),t("h4",{attrs:{id:"生产者api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#生产者api"}},[s._v("#")]),s._v(" 生产者API")]),s._v(" "),t("h5",{attrs:{id:"_1-消息发送流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-消息发送流程"}},[s._v("#")]),s._v(" 1.消息发送流程")]),s._v(" "),t("p",[s._v("Producer 发送消息采用的是"),t("strong",[s._v("异步发送")]),s._v("的方式. 消息发送的过程涉及两个线程: "),t("strong",[s._v("main 线程和 Sender 线程")]),s._v(", 以及一个线程共享变量: "),t("strong",[s._v("RecordAccumulator")]),s._v("(接收器).")]),s._v(" "),t("p",[t("strong",[s._v("main 线程将消息发送给 RecordAccumulator, Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker.")])]),s._v(" "),t("p",[s._v("相关参数:")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("batch.size")]),s._v(": 只有数据积累到 batch.size 之后, sender 才会发送数据.")]),s._v(" "),t("li",[t("strong",[s._v("linger.ms")]),s._v(": 如果数据迟迟未达到 batch.size, sender 等待 linger.time 之后也会发送数据.")])]),s._v(" "),t("h5",{attrs:{id:"_2-异步发送api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-异步发送api"}},[s._v("#")]),s._v(" 2.异步发送API")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("KafkaProducer")]),s._v(": 需要创建一个生产者对象, 用于发送数据.")]),s._v(" "),t("li",[t("strong",[s._v("ProducerConfig")]),s._v(": 获取所需的配置参数.")]),s._v(" "),t("li",[t("strong",[s._v("ProducerRecord")]),s._v(": 每条数据都要封装成一个 "),t("strong",[s._v("ProducerRecord")]),s._v(" 对象.")])]),s._v(" "),t("h6",{attrs:{id:"_1-不带回调函数的异步-asyncproducer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-不带回调函数的异步-asyncproducer"}},[s._v("#")]),s._v(" (1)不带回调函数的异步(AsyncProducer)")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 不带回调函数的异步Producer API */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AsyncProducer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop101:9092,hadoop102:9092,hadoop103:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ACKS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"all"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("RETRIES_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("LINGER_MS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 配置拦截器")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 通过配置创建KafkaProducer对象")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" producer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"message"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("send")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br")])]),t("h6",{attrs:{id:"_2-带回调函数的异步-callbackproducer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-带回调函数的异步-callbackproducer"}},[s._v("#")]),s._v(" (2)带回调函数的异步(CallbackProducer)")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 带回调函数的异步Producer API */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CallbackProducer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"192.168.72.133:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ACKS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"all"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("RETRIES_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" producer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"message"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("send")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Callback")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("onCompletion")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RecordMetadata")]),s._v(" recordMetadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Exception")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"success:"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" recordMetadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("topic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("\n                                           "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" recordMetadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("partition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("\n                                           "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" recordMetadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("printStackTrace")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br")])]),t("h5",{attrs:{id:"_3-同步发送api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-同步发送api"}},[s._v("#")]),s._v(" 3.同步发送API")]),s._v(" "),t("h6",{attrs:{id:"_1-同步发送-syncproducer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-同步发送-syncproducer"}},[s._v("#")]),s._v(" (1)同步发送(SyncProducer)")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 同步 Producer API */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SyncProducer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ExecutionException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InterruptedException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建properties对象用于存放配置")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 添加配置")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop101:9092,hadoop102:9092,hadoop103:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ACKS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"all"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("RETRIES_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 重试次数")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("LINGER_MS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 通过已有配置创建kafkaProducer对象")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" producer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaProducer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 循环调用 send 方法不断发送数据")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"message"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 通过get()方法实现同步效果")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RecordMetadata")]),s._v(" metadata "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("send")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("metadata "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"success:"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" metadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("topic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("\n                        metadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("partition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" metadata"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        producer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 关闭生产者对象")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br")])]),t("h4",{attrs:{id:"消费者api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费者api"}},[s._v("#")]),s._v(" 消费者API")]),s._v(" "),t("p",[s._v("消费者消费数据时的可靠性是比较容易保证的, 因为数据在 Kafka 中是"),t("strong",[s._v("持久化")]),s._v("的, 故一般不用担心数据丢失问题.")]),s._v(" "),t("p",[s._v("由于消费者在消费过程中可能会出现断电宕机等故障, 所以 "),t("strong",[s._v("offset 的维护是消费者消费数据时必须考虑的问题")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-自动提交offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-自动提交offset"}},[s._v("#")]),s._v(" 1.自动提交offset")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("KafkaConsumer")]),s._v(": 需要创建一个消费者对象, 用于消费数据.")]),s._v(" "),t("li",[t("strong",[s._v("ConsumerConfig")]),s._v(": 获取所需的配置参数.")]),s._v(" "),t("li",[t("strong",[s._v("ConsuemrRecord")]),s._v(": 每条数据都被封装成一个 ConsumerRecord 对象.")])]),s._v(" "),t("p",[s._v("为了能专注于业务逻辑, Kafka 提供了"),t("strong",[s._v("自动提交 offset")]),s._v(" 的功能. 自动提交 offset 的相关参数:")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("enable.auto.commit")]),s._v(": 是否开启自动提交 offset 功能.")]),s._v(" "),t("li",[t("strong",[s._v("auto.commit.interval.ms")]),s._v(": 自动提交 offset 的时间间隔.")])]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 自动提交 offset */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AutoCommitOffset")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop101:9092,hadoop102:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_DESERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringDeserializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_DESERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringDeserializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("GROUP_ID_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tian"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// groupid")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("AUTO_OFFSET_RESET_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"earliest"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 配置自动提交")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ENABLE_AUTO_COMMIT_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" consumer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("subscribe")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Arrays")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("asList")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 添加需要消费的 topic")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("finally")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 在死循环中无法调用 close 方法, 所以需要使用 finally")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("p",[s._v("但自动提交可能引起"),t("strong",[s._v("消息消费失败")]),s._v("的问题.")]),s._v(" "),t("h5",{attrs:{id:"_2-手动提交offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-手动提交offset"}},[s._v("#")]),s._v(" 2.手动提交offset")]),s._v(" "),t("p",[s._v("Kafka 还提供了手动提交 offset 的 API. 手动提交 offset 的方法有两种: 分别是 "),t("strong",[s._v("commitSync")]),s._v("("),t("strong",[s._v("同步提交")]),s._v(")和 "),t("strong",[s._v("commitAsync")]),s._v("("),t("strong",[s._v("异步提交")]),s._v("). 两者的相同点是, 都会将"),t("strong",[s._v("本次 poll 的一批数据最高的偏移量提交")]),s._v("; 不同点是, commitSync "),t("strong",[s._v("阻塞当前线程")]),s._v(", 一直到提交成功, 并且会自动失败充实(由不可控因素导致, 也会出现提交失败); 而 commitAsync 则没有失败重试机制, 故有可能提交失败.")]),s._v(" "),t("h6",{attrs:{id:"_1-同步提交commitsync-offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-同步提交commitsync-offset"}},[s._v("#")]),s._v(" (1)同步提交commitSync offset")]),s._v(" "),t("p",[s._v("由于同步提交 offset 有失败重试机制, "),t("strong",[s._v("故更加可靠")]),s._v(".")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 同步手动提交 offset */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CustomComsumer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"bootstrap.servers"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop102:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//Kafka 集群")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"group.id"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"test"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者组, 只要 group.id 相同, 就属于同一个消费者组")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 关闭自动提交 offset")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enable.auto.commit"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"false"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key.deserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.kafka.common.serialization.StringDeserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"value.deserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.kafka.common.serialization.StringDeserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" consumer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("subscribe")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Arrays")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("asList")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者订阅主题")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者拉取数据")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("printf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"offset = %d, key = %s, value = %s%n"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("key")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitSync")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 同步提交, 当前线程会阻塞直到offset提交成功")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("h6",{attrs:{id:"_2-异步提交commitasync-offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-异步提交commitasync-offset"}},[s._v("#")]),s._v(" (2)异步提交commitAsync offset")]),s._v(" "),t("p",[s._v("虽然同步提交 offset 更可靠一些, 但是由于其会"),t("strong",[s._v("阻塞当前线程")]),s._v("直到提交成功, 因此"),t("strong",[s._v("吞吐量会受到很大的影响")]),s._v(". 更多情况下, 会选用异步提交 offset 的方式.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 异步手动提交 offset */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AsyncManualCommitOffset")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop101:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("GROUP_ID_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tian"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("ENABLE_AUTO_COMMIT_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_DESERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringDeserializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_DESERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringDeserializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" consumer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("subscribe")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Arrays")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("asList")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"offset:"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("\n                        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key:"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("key")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"value"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitAsync")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OffsetCommitCallback")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("onComplete")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OffsetAndMetadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Exception")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"commit failed for "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 异步提交")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br")])]),t("h5",{attrs:{id:"_3-自定义存储offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-自定义存储offset"}},[s._v("#")]),s._v(" 3.自定义存储offset")]),s._v(" "),t("p",[s._v("offset 默认存储在 Kafka 的一个"),t("strong",[s._v("内置的 topic 中")]),s._v(". 除此之外, Kafka 还可以选择"),t("strong",[s._v("自定义存储 offset")]),s._v(".")]),s._v(" "),t("p",[s._v("offset 的维护是相当繁琐的, 因为需要考虑到消费者的 "),t("strong",[s._v("Rebalance")]),s._v(". 当有新的消费者加入消费者组, 已有的消费者推出消费者组或者所订阅的主题的分区发生变化, 就会"),t("strong",[s._v("触发到分区的重新分配, 重新分配的过程叫做 Rebalance.")])]),s._v(" "),t("p",[s._v("消费者发生 Rebalance 之后, 每个"),t("strong",[s._v("消费者消费的分区就会发生变化")]),s._v(". 因此消费者要首先获取到自己被重新分配到的分区, 并且定位到每个分区"),t("strong",[s._v("最近提交的 offset 位置")]),s._v("继续消费.")]),s._v(" "),t("p",[s._v("要实现自定义存储 offset, 需要借助 "),t("strong",[s._v("ConsumerRebalanceListener")]),s._v(". 示例代码如下, 其中提交和获取 offset 的方法, 需要根据所选的 offset 存储系统自行实现.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** 自定义存储offset */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CustomConsumer")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" currentOffset "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HashMap")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("main")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" args"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Properties")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"bootstrap.servers"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop102:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// Kafka集群")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"group.id"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"test"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者组, 只要group.id相同, 就属于同一个消费者组")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 关闭自动提交offset")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"enable.auto.commit"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"false"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key.deserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.kafka.common.serialization.StringDeserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"value.deserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.kafka.common.serialization.StringDeserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" consumer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaConsumer")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者订阅主题")]),s._v("\n        consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("subscribe")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Arrays")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("asList")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"first"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRebalanceListener")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            \n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 该方法会在Rebalance之前调用")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("onPartitionsRevoked")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Collection")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" partitions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("currentOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 该方法会在Rebalance之后调用")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("onPartitionsAssigned")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Collection")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" partitions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                currentOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("clear")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),s._v(" partition "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" partitions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 定位到最近提交的offset位置继续消费")]),s._v("\n                    consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("seek")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("partition"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("partition"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费者拉取数据")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("printf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"offset = %d, key = %s, value = %s%n"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("key")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                currentOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("topic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("partition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("currentOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 获取某分区的最新offset")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),s._v(" partition"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 提交该消费者所有分区的offset")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitOffset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" currentOffset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br")])]),t("p",[s._v("‍")]),s._v(" "),t("h4",{attrs:{id:"参考资料"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[s._v("#")]),s._v(" 参考资料")]),s._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://www.infoq.cn/article/kafka-analysis-part-1",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://www.infoq.cn/article/kafka-analysis-part-1"),t("OutboundLink")],1),s._v(" - Kafka 设计解析(一): Kafka 背景及架构介绍")]),s._v(" "),t("li",[t("a",{attrs:{href:"http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/06/kafka-Meet-Kafka.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/06/kafka-Meet-Kafka.html"),t("OutboundLink")],1),s._v(" - Kafka系列(一)初识Kafka")]),s._v(" "),t("li",[t("a",{attrs:{href:"https://lotabout.me/2018/kafka-introduction/",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://lotabout.me/2018/kafka-introduction/"),t("OutboundLink")],1),s._v(" - Kafka 入门介绍")]),s._v(" "),t("li",[t("a",{attrs:{href:"https://www.zhihu.com/question/28925721",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://www.zhihu.com/question/28925721"),t("OutboundLink")],1),s._v(" - Kafka 中的 Topic 为什么要进行分区? - 知乎")]),s._v(" "),t("li",[t("a",{attrs:{href:"https://blog.joway.io/posts/kafka-design-practice/",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://blog.joway.io/posts/kafka-design-practice/"),t("OutboundLink")],1),s._v(" - Kafka 的设计与实践思考")]),s._v(" "),t("li",[t("a",{attrs:{href:"http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/21/kafka-data-delivery.html"),t("OutboundLink")],1),s._v(" - Kafka系列(六)可靠的数据传输")]),s._v(" "),t("li",[t("a",{attrs:{href:"https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd",target:"_blank",rel:"noopener noreferrer"}},[s._v("Kafka系列第三篇!10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://segmentfault.com/a/1190000012990954",target:"_blank",rel:"noopener noreferrer"}},[s._v("CentOS7 下 Kafka 的安装介绍 - 个人文章 - SegmentFault 思否"),t("OutboundLink")],1)]),s._v(" "),t("li",[s._v("非常重要: "),t("a",{attrs:{href:"https://blog.csdn.net/qq_25868207/article/details/81516024",target:"_blank",rel:"noopener noreferrer"}},[s._v("kafka 踩坑之消费者收不到消息 - kris - CSDN 博客"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://blog.csdn.net/u010391342/article/details/81430402",target:"_blank",rel:"noopener noreferrer"}},[s._v("kafka 安装搭建(整合 springBoot 使用) - u010391342 的博客 - CSDN 博客"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://www.cnblogs.com/ALittleMoreLove/archive/2018/07/31/9396745.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("Zookeeper+Kafka 的单节点配置 - 紫轩弦月 - 博客园"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://blog.csdn.net/sweatOtt/article/details/86714272",target:"_blank",rel:"noopener noreferrer"}},[s._v("@KafkaListener 注解解密 - laomei - CSDN 博客"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://www.jianshu.com/p/ac03f126980e",target:"_blank",rel:"noopener noreferrer"}},[s._v("使用Docker快速搭建Kafka开发环境 - 简书"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://docs.spring.io/spring-kafka/reference/html",target:"_blank",rel:"noopener noreferrer"}},[s._v("Spring for Apache Kafka"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://docs.spring.io/spring-kafka/docs/2.2.8.RELEASE/api/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Overview (Spring Kafka 2.2.8.RELEASE API)"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://www.jianshu.com/p/7a284bf4efc9",target:"_blank",rel:"noopener noreferrer"}},[s._v("SpringBoot整合Kafka实现发布订阅 - 简书"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"http://www.mydlq.club/article/34/",target:"_blank",rel:"noopener noreferrer"}},[s._v("SpringBoot 集成 Spring For Kafka 操作 Kafka 详解 · 小豆丁个人博客"),t("OutboundLink")],1)]),s._v(" "),t("li",[t("a",{attrs:{href:"https://developer.aliyun.com/article/868759",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://developer.aliyun.com/article/868759"),t("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=r.exports}}]);