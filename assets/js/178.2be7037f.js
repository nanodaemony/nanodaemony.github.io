(window.webpackJsonp=window.webpackJsonp||[]).push([[178],{490:function(s,t,a){"use strict";a.r(t);var n=a(7),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"_100-系统性能调优必知必会-极客时间-🌸"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_100-系统性能调优必知必会-极客时间-🌸"}},[s._v("#")]),s._v(" 100.系统性能调优必知必会(极客时间)🌸")]),s._v(" "),t("h3",{attrs:{id:"开篇词"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#开篇词"}},[s._v("#")]),s._v(" 开篇词")]),s._v(" "),t("h4",{attrs:{id:"开篇词-万变不离其宗-性能优化也有章可循"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#开篇词-万变不离其宗-性能优化也有章可循"}},[s._v("#")]),s._v(" 开篇词-万变不离其宗,性能优化也有章可循")]),s._v(" "),t("p",[s._v('从 2004 年毕业到现在, 我的工作总是与"性能"相伴, 从底层, 应用层到前端, 我一直都很关心系统如何能够服务更多的用户, 提供更快的体验. 换句话说, '),t("strong",[s._v("性能优化最根本的目的, 还是要跟上业务的发展脚步.")])]),s._v(" "),t("p",[s._v("而从十几年的性能优化工作中我发现, 性能不只对产品的攻城掠地至关重要, 它也是程序员价值的重要体现, 特别是它在工作面试, 技术等级晋升上也扮演着核心角色.")]),s._v(" "),t("p",[s._v("比如, 在大多数拥有技术职级晋升体系的公司里, 为了保障公平性, 一般都是由跨部门的专家组成评委会的, 而**其他部门的高级专家在不熟悉候选人业务的情况下, 只能去考察底层的硬核知识, 而性能问题又是最有区分度的问题. **如果你始终埋头在业务中, 不关心更通用的性能优化方法论, 将在技术等级晋升上非常吃亏.")]),s._v(" "),t("p",[s._v('再比如, 在面试互联网大厂时, 面试官总会问许多超出工作范围的性能问题, 为什么会这样呢? 当然你可以感慨甚至抱怨, 这不就是"面试造火箭, 入职拧螺丝"嘛, 但你也可以从面试官的角度来看这个问题, 就会发现性能就是最好的面试题, 它从算法到架构, 既能考察候选人的潜力, 也能考察候选人的工程能力. 如果候选人具备系统的性能优化方法论, 那么无论在架构设计还是应用模块开发上, 他的代码可扩展性都会更好, 消耗的计算力, 带宽, 磁盘等 IT 资源也更少!')]),s._v(" "),t("p",[s._v("具体应该从哪里入手呢? 当然是看需求. 当下的后端几乎都是"),t("strong",[s._v("分布式系统")]),s._v(", 那么对应的, 大家面对的课题也就是"),t("mark",[t("strong",[s._v("如何全面提升复杂集群的性能")])]),s._v(". 然而, 如果你在 Google 上搜索如何优化分布式系统的性能, 就只能找到孤零零的几篇文章, 而谈到分布式系统的多数书籍也都在讨论容错, 事务, 流控等概念的实现, 很少有文章介绍如何优化整个系统的性能. 这恰恰就是这门课的初衷.")]),s._v(" "),t("p",[s._v("我希望把自己这些年来在分布式性能领域所遇到的问题和解决方案, 归纳总结, 抽离萃取, 梳理出一条"),t("strong",[s._v("系统化的性能学习路径")]),s._v("交付给你, 告诉你我眼中的性能问题本质是怎样的. 在我看来, "),t("mark",[t("strong",[s._v("性能优化的本质就是最大化整个系统的综合效率, 为了达到这个目标, 我们需要从空间, 时间维度上, 不断地优化基础资源间的协作方式")])]),s._v(".")]),s._v(" "),t("p",[s._v("下面总结了一份系统性能优化核心关注点的知识脑图:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0ce4a81c3f96f2aa7c026e2815df62bc-20230731165330-wvvscol.png",alt:""}})]),s._v(" "),t("p",[s._v("这里是从 4 个方面来梳理的, 这其实就是在提升一个新系统的性能时, 可以入手的 4 个层次.")]),s._v(" "),t("ul",[t("li",[s._v("首先, 可以从"),t("strong",[s._v("提升单机进程的性能")]),s._v("入手, 包括高效地使用主机的 CPU, 内存, 磁盘等硬件, 通过并发编程提升吞吐量, 根据业务特性选择合适的算法.")]),s._v(" "),t("li",[s._v("其次, 分布式系统是由各个组件通过网络连接在一起, 所以"),t("strong",[s._v("优化传输层网络可以让所有组件同时受益")]),s._v(". 具体优化时, 可以从降低请求的时延, 提升总体吞吐量两个方向入手.")]),s._v(" "),t("li",[s._v("再次, 要"),t("strong",[s._v("对业务消息采用更高效的编码方式")]),s._v(", 这既包括协议头, 包体的优化, 也包括 TLS 安全层的性能提升. 具体优化时, 既要深入静态编码, 也要从动态的增量编码上优化. 同时, 调整消息的交互方式也能提升性能.")]),s._v(" "),t("li",[s._v("最后, 再"),t("strong",[s._v("从集群整体上进行架构层面的优化")]),s._v(". 基于 ACP, AKF, NWR 等分布式理论, 优化方向仍然是降低时延和提升吞吐量, 但实现方式则要运用分而治之的思想, 调度集群中的所有结点协作配合, 完成性能优化目标.")])]),s._v(" "),t("p",[s._v("本门课的知识点并不是非常新的前沿知识, 而是大家经常面对的日常问题. 这里的关键是得"),t("strong",[s._v("系统地")]),s._v("掌握这些知识点, 在心中构建出性能优化树状知识图谱, 然后才能更有底气地优化整个系统的性能.")]),s._v(" "),t("p",[s._v("性能问题其实是计算机体系的底层问题, 它涉及到的知识面非常广, 这个课程不可能覆盖全部领域. 我最希望给到你的, "),t("strong",[s._v("是基于自己的经历和经验, 对知识做一次筛选和过滤, 把我已经构建起来的性能优化体系给到你")]),s._v(", 但同时, 我能保证我们在解决性能优化中一些典型问题的同时, 可以关联到绝大部分领域, 对于任何一个领域, 如果你需要进一步深入学习, 你也能够知道自己的目标和路径.")]),s._v(" "),t("h3",{attrs:{id:"基础设施优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基础设施优化"}},[s._v("#")]),s._v(" 基础设施优化")]),s._v(" "),t("h4",{attrs:{id:"_01-cpu缓存-怎样写代码能够让cpu执行得更快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_01-cpu缓存-怎样写代码能够让cpu执行得更快"}},[s._v("#")]),s._v(" 01-CPU缓存:怎样写代码能够让CPU执行得更快?")]),s._v(" "),t("p",[s._v("本节先从主机最重要的部件 CPU 开始, 聊聊"),t("mark",[t("strong",[s._v("如何通过提升 CPU 缓存的命中率来优化程序的性能")])]),s._v(".")]),s._v(" "),t("p",[s._v("任何代码的执行都依赖 CPU, 通常, 使用好 CPU 是操作系统内核的工作. 然而, 当编写计算密集型的程序时, CPU 的执行效率就开始变得至关重要. 由于 CPU 缓存由更快的 "),t("strong",[s._v("SRAM")]),s._v(" 构成(内存是由 DRAM 构成的), 而且"),t("strong",[s._v("离 CPU 核心更近, 如果运算时需要的输入数据是从 CPU 缓存, 而不是内存中读取时, 运算速度就会快很多")]),s._v(". 所以, 了解 CPU 缓存对性能的影响, 便能够更有效地编写代码, 优化程序性能.")]),s._v(" "),t("p",[s._v("然而, 很多同学并不清楚 CPU 缓存的运行规则, 不知道如何写代码才能够配合 CPU 缓存的工作方式, 这样, 便放弃了可以大幅提升核心计算代码执行速度的机会. 而且, 越是底层的优化, 适用范围越广, CPU 缓存便是如此, 它的运行规则对分布式集群里各种操作系统, 编程语言都有效. 所以, 一旦你能掌握它, 集群中巨大的主机数量便能够放大优化效果.")]),s._v(" "),t("p",[s._v("接下来就看看, CPU 缓存结构到底是什么样的, 又该如何优化它?")]),s._v(" "),t("h5",{attrs:{id:"_1-cpu的多级缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-cpu的多级缓存"}},[s._v("#")]),s._v(" 1.CPU的多级缓存")]),s._v(" "),t("p",[s._v("刚刚提到, "),t("strong",[s._v("CPU 缓存离 CPU 核心更近, 由于电子信号传输是需要时间的, 所以离 CPU 核心越近, 缓存的读写速度就越快. 但 CPU 的空间很狭小, 离 CPU 越近缓存大小受到的限制也越大. 所以, 综合硬件布局, 性能等因素, CPU 缓存通常分为大小不等的")]),s._v("​"),t("mark",[t("strong",[s._v("三级缓存")])]),s._v(".")]),s._v(" "),t("p",[s._v("CPU 缓存的材质 SRAM 比内存使用的 DRAM 贵许多, 所以不同于内存动辄以 GB 计算, 它的大小是以 MB 来计算的. 比如, 在我的 Linux 系统上, 离 CPU 最近的一级缓存是 32KB, 二级缓存是 256KB, 最大的三级缓存则是 20MB(Windows 系统查看缓存大小可以用 wmic cpu 指令, 或者用CPU-Z这个工具).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ffb1e679933934c68cf59a3b4f7096c3-20230731165330-kqblcnz.png",alt:""}})]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("三级缓存要比一, 二级缓存大许多倍, 这是因为当下的 CPU 都是多核心的, 每个核心都有自己的一, 二级缓存, 但三级缓存却是一颗 CPU 上所有核心共享的")])]),s._v(".")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("程序执行时, 会先将内存中的数据载入到共享的三级缓存中, 再进入每颗核心独有的二级缓存, 最后进入最快的一级缓存, 之后才会被 CPU 使用")])]),s._v(", 就像下面这张图.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/392f95155c9a1e65c99f737efb86102d-20230731165330-d4pdd9b.png",alt:""}})]),s._v(" "),t("p",[s._v("缓存要比内存快很多. CPU 访问一次内存通常需要 100 个时钟周期以上, 而访问一级缓存只需要 4~5 个时钟周期, 二级缓存大约 12 个时钟周期, 三级缓存大约 30 个时钟周期(对于 2GHZ 主频的 CPU 来说, 一个时钟周期是 0.5 纳秒. 你可以在 LZMA 的Benchmark中找到几种典型 CPU 缓存的访问速度).")]),s._v(" "),t("p",[s._v("如果 CPU 所要操作的数据在缓存中, 则直接读取, 这称为"),t("strong",[s._v("缓存命中")]),s._v(". 命中缓存会带来很大的性能提升, "),t("strong",[s._v("因此,")]),s._v(" "),t("mark",[t("strong",[s._v("代码优化目标是提升 CPU 缓存的命中率")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v('当然, 缓存命中率是很笼统的, 具体优化时还得一分为二. 比如, 在查看 CPU 缓存时会发现有 2 个一级缓存(比如 Linux 上就是上图中的 index0 和 index1), 这是因为, CPU 会区别对待指令与数据. 比如, "1+1=2" 这个运算, "+" 就是指令, 会放在一级指令缓存中, 而 "1" 这个输入数字, 则放在一级数据缓存中. 虽然在冯诺依曼计算机体系结构中, 代码指令与数据是放在一起的, 但执行时却是分开进入指令缓存与数据缓存的, 因此要分开来看二者的缓存命中率.')]),s._v(" "),t("h5",{attrs:{id:"_2-提升数据缓存的命中率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-提升数据缓存的命中率"}},[s._v("#")]),s._v(" 2.提升数据缓存的命中率")]),s._v(" "),t("p",[s._v("先来看"),t("strong",[s._v("数据的访问顺序")]),s._v("是如何影响缓存命中率的.")]),s._v(" "),t("p",[s._v("比如现在要遍历二维数组, 其定义如下:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("可以思考一下, 用 array[j][i] 和 array[i][j] 访问数组元素, 哪一种性能更快?")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("j "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" j "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" j"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n       array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("在测试下, 前者 array[j][i] 执行的时间是后者 array[i][j] 的 8 倍之多. 为什么会有这么大的差距呢? 这是因为二维数组 array 所占用的"),t("strong",[s._v("内存是连续")]),s._v("的, 比如若长度 N 的值为 2, 那么内存中从前至后各元素的顺序是:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("如果用 array[i][j] 访问数组元素, 则完全与上述"),t("strong",[s._v("内存中元素顺序一致")]),s._v(", 因此访问 array[0][0] 时, 缓存已经把紧随其后的 3 个元素也载入了, CPU 通过快速的缓存来读取后续 3 个元素就可以. 如果用 array[j][i] 来访问, 访问的顺序就是:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("此时内存是"),t("strong",[s._v("跳跃访问")]),s._v("的, 如果 N 的数值很大, 那么操作 array[j][i] 时, 是没有办法把 array[j+1][i] 也读入缓存的.")]),s._v(" "),t("p",[s._v("到这里还有 2 个问题没有搞明白: "),t("strong",[s._v("为什么两者的执行时间有约 7, 8 倍的差距呢? 载入 array[0][0]元素时, 缓存一次性会载入多少元素呢?")])]),s._v(" "),t("p",[s._v("其实这两个问题的答案都与 "),t("mark",[t("strong",[s._v("CPU Cache Line")])]),s._v(" 相关, 它定义了"),t("strong",[s._v("缓存一次载入数据的大小")]),s._v(", Linux 上可以通过 coherency_line_size 配置查看它, 通常是 64 字节.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/71283648ce440d0faedab54ce2292087-20230731165330-1ji4bu2.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, 测试的服务器一次会载入 64 字节至缓存中. 当载入 array[0][0] 时, 若它们占用的内存不足 64 字节, "),t("strong",[s._v("CPU 就会顺序地补足后续元素")]),s._v(". 顺序访问的 array[i][j] 因为利用了这一特点, 所以就会比 array[j][i] 要快. 也正因为这样, 当元素类型是 4 个字节的整数时, 性能就会比 8 个字节的高精度浮点数时速度更快, 因为缓存一次载入的元素会更多.")]),s._v(" "),t("p",[s._v("**因此, 遇到这种遍历访问数组的情况时, 按照内存布局顺序访问将会带来很大的性能提升. **")]),s._v(" "),t("p",[s._v("再来看为什么执行时间相差 8 倍. 在二维数组中, 其实第一维元素存放的是地址, 第二维存放的才是目标元素. 由于 64 位操作系统的地址占用 8 个字节(32 位操作系统是 4 个字节), 因此, "),t("strong",[s._v("每批 Cache Line 最多也就能载入不到 8 个二维数组元素")]),s._v(", 所以性能差距大约接近 8 倍.")]),s._v(" "),t("p",[s._v("关于 CPU Cache Line 的应用其实非常广泛, 如果你用过 Nginx, 会发现它是用哈希表来存放域名, HTTP 头部等数据的, 这样访问速度非常快, 而哈希表里桶的大小如 server_names_hash_bucket_size, 它默认就等于 CPU Cache Line 的值. 由于"),t("strong",[s._v("所存放的字符串长度不能大于桶的大小, 所以当需要存放更长的字符串时, 就需要修改桶大小, 但 Nginx 官网上明确建议它应该是 CPU Cache Line 的整数倍")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0af764a49af00ee1940f99c25729206b-20230731165330-od1hrvx.png",alt:""}})]),s._v(" "),t("p",[s._v("为什么要做这样的要求呢? 就是因为缓存是按照 64 字节的整数倍来访问内存的, 哈希表的桶按此大小排列布局, 就可以"),t("strong",[s._v("尽量减少访问内存的次数")]),s._v(". 比如, 若桶大小为 64 字节, 那么根据地址获取字符串时只需要访问一次内存, 而桶大小为 50 字节, 会导致最坏 2 次访问内存, 而 70 字节最坏会有 3 次访问内存.")]),s._v(" "),t("p",[s._v("如果你在用 Linux 操作系统, 可以通过一个名叫 Perf 的工具直观地验证"),t("strong",[s._v("缓存命中")]),s._v("的情况. 执行 "),t("strong",[s._v("perf stat")]),s._v(" 可以统计出进程运行时的系统信息(通过 -e 选项指定要统计的事件, 如果要查看三级缓存总的命中率, 可以指定缓存未命中 cache-misses 事件, 以及读取缓存次数 cache-references 事件, 两者相除就是缓存的未命中率, 用 1 相减就是命中率. 类似的, 通过 L1-dcache-load-misses 和 L1-dcache-loads 可以得到 L1 缓存的命中率), 此时你会发现 array[i][j]的缓存命中率远高于 array[j][i].")]),s._v(" "),t("p",[s._v("当然, perf stat 还可以通过指令执行速度反映出两种访问方式的优劣, 如下图所示(instructions 事件指明了进程执行的总指令数, 而 cycles 事件指明了运行的时钟周期, 二者相除就可以得到每时钟周期所执行的指令数, 缩写为 IPC. 如果缓存未命中, 则 CPU 要等待内存的慢速读取, 因此 IPC 就会很低. array[i][j]的 IPC 值也比 array[j][i]要高得多):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1475a82cb4e78ecaa41e453742b58e00-20230731165330-r6rgji0.png",alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/faf46565607e75a2673405fc8c8bfdf0-20230731165330-f0ltzdw.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_3-提升指令缓存的命中率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-提升指令缓存的命中率"}},[s._v("#")]),s._v(" 3.提升指令缓存的命中率")]),s._v(" "),t("p",[s._v("说完数据的缓存命中率, 再来看"),t("strong",[s._v("指令的缓存命中率该如何提升")]),s._v(".")]),s._v(" "),t("p",[s._v("还是用一个例子来看一下. 比如, 有一个元素为 0 到 255 之间随机数字组成的数组:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("TESTN")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("rand")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("256")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("接下来要对它做两个操作: 一是循环遍历数组, 判断每个数字是否小于 128, 如果小于则把元素的值置为 0; 二是将数组排序. 那么, 先排序再遍历速度快, 还是先遍历再排序速度快呢?")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("128")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sort")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" array "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("N")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("先给出答案: 先排序的遍历时间只有后排序的三分之一. 为什么会这样呢? 这是因为循环中有大量的 if 条件分支, 而 CPU "),t("strong",[s._v("含有分支预测器")]),s._v(".")]),s._v(" "),t("p",[s._v("当代码中出现 if, switch 等语句时, 意味着此时至少可以选择跳转到两段不同的指令去执行. "),t("strong",[s._v("如果分支预测器可以预测接下来要在哪段代码执行(比如 if 还是 else 中的指令), 就可以提前把这些指令放在缓存中, CPU 执行时就会很快. 当数组中的元素完全随机时, 分支预测器无法有效工作, 而当 array 数组有序时, 分支预测器会动态地根据历史命中数据对未来进行预测, 命中率就会非常高")]),s._v(".")]),s._v(" "),t("p",[s._v("究竟有多高呢? 还是用 Linux 上的 perf 来做个验证. 使用 -e 选项指明 branch-loads 事件和 branch-load-misses 事件, 它们分别表示分支预测的次数, 以及预测失败的次数. 通过 L1-icache-load-misses 也能查看到一级缓存中指令的未命中情况. 可以看到, 先排序的话分支预测的成功率非常高, 而且一级指令缓存的未命中率也有大幅下降.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ca9a00aea2e9ff88317fb0389a29367e-20230731165330-msuaz62.png",alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a2456836f53d256123cb9121375c253f-20230731165330-8bvo3m7.png",alt:""}})]),s._v(" "),t("p",[s._v('C/C++ 语言中编译器还给应用程序员提供了显式预测分支概率的工具, 如果 if 中的条件表达式判断为 "真" 的概率非常高, 可以用 likely 宏把它括在里面, 反之则可以用 unlikely 宏. 当然, CPU 自身的条件预测已经非常准了, 仅当我们确信 CPU 条件预测不会准, 且能够知晓实际概率时, 才需要加入这两个宏.')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("#define "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("likely")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__builtin_expect")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n#define "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("unlikely")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__builtin_expect")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("likely")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h5",{attrs:{id:"_4-提升多核cpu下的缓存命中率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-提升多核cpu下的缓存命中率"}},[s._v("#")]),s._v(" 4.提升多核CPU下的缓存命中率")]),s._v(" "),t("p",[s._v("前面都是面向一个 CPU 核心谈数据及指令缓存的, 然而现代 CPU 几乎都是多核的. 虽然三级缓存面向所有核心, 但一, 二级缓存是每颗核心独享的. 即使只有一个 CPU 核心, 现代分时操作系统都支持许多进程同时运行. 这是因为"),t("strong",[s._v("操作系统把时间切成了许多片, 微观上各进程按时间片交替地占用 CPU")]),s._v(", 这造成宏观上看起来各程序同时在执行.")]),s._v(" "),t("p",[s._v("因此, 若进程 A 在时间片 1 里使用 CPU 核心 1, 自然也填满了核心 1 的一, 二级缓存, 当时间片 1 结束后, 操作系统会让进程 A 让出 CPU, 基于效率并兼顾公平的策略重新调度 CPU 核心 1, 以防止某些进程饿死. 如果此时 CPU 核心 1 繁忙, 而 CPU 核心 2 空闲, 则进程 A 很可能会被调度到 CPU 核心 2 上运行, 这样, 即使对代码优化得再好, 也只能在一个时间片内高效地使用 CPU 一, 二级缓存了, 下一个时间片便面临着缓存效率的问题.")]),s._v(" "),t("p",[s._v("因此, "),t("mark",[t("strong",[s._v("操作系统提供了将进程或者线程绑定到某一颗 CPU 上运行的能力")])]),s._v(". 如 Linux 上提供了 sched_setaffinity 方法实现这一功能, 其他操作系统也有类似功能的 API 可用.")]),s._v(" "),t("h5",{attrs:{id:"_5-小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-小结"}},[s._v("#")]),s._v(" 5.小结")]),s._v(" "),t("p",[s._v("本节介绍了 CPU 缓存对程序性能的影响. 这是很底层的性能优化, "),t("strong",[s._v("它对各种编程语言做密集计算时都有效")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("CPU 缓存分为数据缓存与指令缓存, 对于数据缓存, 应在循环体中尽量操作同一块内存上的数据, 由于缓存是根据 CPU Cache Line 批量操作数据的, 所以顺序地操作连续内存数据时也有性能提升.")])]),s._v(" "),t("p",[t("strong",[s._v("对于指令缓存, 有规律的条件分支能够让 CPU 的分支预测发挥作用, 进一步提升执行效率. 对于多核系统, 如果进程的缓存命中率非常高, 则可以考虑绑定 CPU 来提升缓存命中率.")])]),s._v(" "),t("h4",{attrs:{id:"_02-内存池-如何提升内存分配的效率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_02-内存池-如何提升内存分配的效率"}},[s._v("#")]),s._v(" 02-内存池:如何提升内存分配的效率?")]),s._v(" "),t("p",[s._v("或许有同学会认为, 我又不写底层框架, 内存分配也依赖虚拟机, 并不需要应用开发者了解. 如果你也这么认为, 那不妨看看这个例子: 在 Linux 系统中, 用 Xmx 设置 JVM 的最大堆内存为 8GB, 但在近百个并发线程下, 观察到 Java 进程占用了 14GB 的内存. 为什么会这样呢?")]),s._v(" "),t("p",[s._v("这是因为, 绝大部分高级语言都是用 C 语言编写的, 包括 Java, 申请内存必须经过 C 库, 而 C 库通过预分配更大的空间作为内存池, 来加快后续申请内存的速度. 这样预分配的 6GB 的 C 库内存池就与 JVM 中预分配的 8G 内存池叠加在一起, 造成了 Java 进程的内存占用超出了预期.")]),s._v(" "),t("p",[s._v("掌握内存池的特性, 既可以避免写程序时内存占用过大, 导致服务器性能下降或者进程 OOM(Out Of Memory, 内存溢出)被系统杀死, 还可以加快内存分配的速度. 在系统空闲时申请内存花费不了多少时间, 但是对于分布式环境下繁忙的多线程服务, 获取内存的时间会上升几十倍.")]),s._v(" "),t("p",[s._v("另一方面, 内存池是非常底层的技术, 当理解它后, 可以更换适合应用场景的内存池. 在多种编程语言共存的分布式系统中, "),t("strong",[s._v("内存池有很广泛的应用, 优化内存池带来的任何微小的性能提升, 都将被分布式集群巨大的主机规模放大, 从而带来整体上非常可观的收益")]),s._v(".")]),s._v(" "),t("p",[s._v("接下来就通过对内存池的学习, 看看如何提升内存分配的效率.")]),s._v(" "),t("h5",{attrs:{id:"_1-隐藏的内存池"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-隐藏的内存池"}},[s._v("#")]),s._v(" 1.隐藏的内存池")]),s._v(" "),t("p",[s._v("实际上, 在你的业务代码与系统内核间, 往往有"),t("strong",[s._v("两层内存池")]),s._v("容易被忽略, 尤其是其中的 C 库内存池.")]),s._v(" "),t("p",[s._v("当代码申请内存时, 首先会到达"),t("strong",[s._v("应用层内存池")]),s._v(", 如果应用层内存池有足够的可用内存, 就会直接返回给业务代码, 否则, 它会"),t("strong",[s._v("向更底层的 C 库内存池申请内存")]),s._v(". 比如, 如果在 Apache, Nginx 等服务之上做模块开发, 这些服务中就有独立的内存池. 当然, Java 中也有内存池, 当通过启动参数 Xmx 指定 JVM 的堆内存为 8GB 时, 就设定了 JVM 堆内存池的大小.")]),s._v(" "),t("p",[s._v("你可能听说过 Google 的 TCMalloc 和 FaceBook 的 JEMalloc, 它们也是 C 库内存池. "),t("strong",[s._v("当 C 库内存池无法满足内存申请时, 才会向操作系统内核申请分配内存")]),s._v(". 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/702642632e13739c815ab822dae96876-20230731165330-14de7m8.png",alt:""}})]),s._v(" "),t("p",[s._v("回到开头的问题, Java 已经有了应用层内存池, 为什么还会受到 C 库内存池的影响呢? 这是因为, "),t("strong",[s._v("除了 JVM 负责管理的堆内存外, Java 还拥有一些堆外内存, 由于它不使用 JVM 的垃圾回收机制, 所以更稳定, 持久, 处理 IO 的速度也更快. 这些堆外内存就会由 C 库内存池负责分配, 这是 Java 受到 C 库内存池影响的原因")]),s._v(".")]),s._v(" "),t("p",[s._v("其实不只是 Java, "),t("strong",[s._v("几乎所有程序都在使用 C 库内存池分配出的内存. C 库内存池影响着系统下依赖它的所有进程")]),s._v(". 下面就以 Linux 系统的默认 C 库内存池 "),t("strong",[s._v("Ptmalloc2")]),s._v(" 来具体分析, 看看它到底对性能发挥着怎样的作用.")]),s._v(" "),t("p",[s._v("C 库内存池工作时, 会预分配比你申请的字节数更大的空间作为内存池. 比如说, 当主进程下申请 1 字节的内存时, Ptmalloc2 会预分配 132K 字节的内存(Ptmalloc2 中叫 Main Arena), 应用代码再申请内存时, 会从这已经申请到的 132KB 中继续分配.")]),s._v(" "),t("p",[s._v("当释放这 1 字节时, Ptmalloc2 也"),t("strong",[s._v("不会把内存归还给操作系统")]),s._v(". Ptmalloc2 认为, 与其把这 1 字节释放给操作系统, 不如先"),t("strong",[s._v("缓存着放进内存池里")]),s._v(", 仍然当作用户态内存留下来, 进程再次申请 1 字节的内存时就可以直接复用, 这样速度快了很多.")]),s._v(" "),t("p",[s._v("你可能会想, 132KB 不多呀? 为什么这一讲开头提到的 Java 进程, 会被分配了几个 GB 的内存池呢? 这是因为"),t("strong",[s._v("多线程与单线程的预分配策略并不相同")]),s._v(".")]),s._v(" "),t("p",[s._v("每个"),t("strong",[s._v("子线程预分配的内存是 64MB")]),s._v("(Ptmalloc2 中被称为 Thread Arena, 32 位系统下为 1MB, 64 位系统下为 64MB). 如果有 100 个线程, 就"),t("strong",[s._v("将有 6GB 的内存都会被内存池占用")]),s._v(". 当然, 并不是设置了 1000 个线程, 就会预分配 60GB 的内存, "),t("strong",[s._v("子线程内存池最多只能到 8 倍的 CPU 核数")]),s._v(", 比如在 32 核的服务器上, 最多只会有 256 个子线程内存池, 但这也非常夸张了, 16GB(64MB * 256 = 16GB)的内存将一直被 Ptmalloc2 占用.")]),s._v(" "),t("p",[s._v("回到开头的问题, Linux 下的 JVM 编译时默认使用了 Ptmalloc2 内存池, "),t("strong",[s._v("因此每个线程都预分配了 64MB 的内存, 这造成含有上百个 Java 线程的 JVM 多使用了 6GB 的内存. 在多数情况下, 这些预分配出来的内存池, 可以提升后续内存分配的性能")]),s._v(".")]),s._v(" "),t("p",[s._v("然而, Java 中的 JVM 内存池已经管理了绝大部分内存, 确实不能接受莫名多出来 6GB 的内存, 那该怎么办呢? 既然知道了 Ptmalloc2 内存池的存在, 就有两种解决办法.")]),s._v(" "),t("p",[s._v("首先可以调整 Ptmalloc2 的工作方式. "),t("mark",[t("strong",[s._v("通过设置 MALLOC_ARENA_MAX 环境变量, 可以限制线程内存池的最大数量")])]),s._v(", 当然线程内存池的数量减少后, 会影响 Ptmalloc2 分配内存的速度. 不过由于 Java 主要使用 JVM 内存池来管理对象, 这点影响并不重要.")]),s._v(" "),t("p",[s._v("其次可以更换掉 Ptmalloc2 内存池, 选择一个预分配内存更少的内存池, 比如 Google 的 TCMalloc. 这并不是说 Google 出品的 TCMalloc 性能更好, 而是在特定的场景中的选择不同. 而且盲目地选择 TCMalloc 很可能会降低性能, 否则 Linux 系统早把默认的内存池改为 TCMalloc 了.")]),s._v(" "),t("p",[t("strong",[s._v("TCMalloc 和 Ptmalloc2 是目前最主流的两个内存池")]),s._v(", 接下来通过对比 TCMalloc 与 Ptmalloc2 内存池, 看看到底该如何选择内存池.")]),s._v(" "),t("h5",{attrs:{id:"_2-选择ptmalloc2还是tcmalloc"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-选择ptmalloc2还是tcmalloc"}},[s._v("#")]),s._v(" 2.选择Ptmalloc2还是TCMalloc?")]),s._v(" "),t("p",[s._v("先来看 TCMalloc 适用的场景, **它对多线程下小内存的分配特别友好. **")]),s._v(" "),t("p",[s._v("比如, 在 2GHz 的 CPU 上分配, 释放 256K 字节的内存, Ptmalloc2 耗时 32 纳秒, 而 TCMalloc 仅耗时 10 纳秒(测试代码参见这里). 差距超过了 3 倍, 为什么呢?  ****  这是因为, Ptmalloc2 假定, 如果线程 A 申请并释放了的内存, 线程 B 可能也会申请类似的内存, 所以"),t("strong",[s._v("它允许内存池在线程间复用以提升性能")]),s._v(".")]),s._v(" "),t("p",[s._v("因此, "),t("strong",[s._v("每次分配内存, Ptmalloc2 一定要加锁, 才能解决共享资源的互斥问题")]),s._v(". 然而, 加锁的消耗并不小. 如果监控分配速度的话, 会发现单线程服务调整为 100 个线程, Ptmalloc2 申请内存的速度会变慢 10 倍. TCMalloc 针对小内存做了很多优化, 每个线程独立分配内存, 无须加锁, 所以速度更快!")]),s._v(" "),t("p",[s._v("而且, "),t("strong",[s._v("线程数越多, Ptmalloc2 出现锁竞争的概率就越高.")]),s._v("  比如用 40 个线程做同样的测试, TCMalloc 只是从 10 纳秒上升到 25 纳秒, 只增长了 1.5 倍, 而 Ptmalloc2 则从 32 纳秒上升到 137 纳秒, 增长了 3 倍以上.")]),s._v(" "),t("p",[s._v("下图是 TCMalloc 作者给出的性能测试数据, 可以看到线程数越多, 二者的速度差距越大. 所以, "),t("mark",[t("strong",[s._v("当应用场景涉及大量的并发线程时, 换成 TCMalloc 库也更有优势")])]),s._v("​ "),t("strong",[s._v("!")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7dd2b1742ae1e65e9470e6ad5b70442c-20230731165330-o7kts4a.png",alt:""}})]),s._v(" "),t("p",[s._v("那么, 为什么 GlibC 不把默认的 Ptmalloc2 内存池换成 TCMalloc 呢? "),t("mark",[t("strong",[s._v("因为 Ptmalloc2 更擅长大内存的分配")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("比如, 单线程下分配 257K 字节的内存, Ptmalloc2 的耗时不变仍然是 32 纳秒, 但 TCMalloc 就由 10 纳秒上升到 64 纳秒, 增长了 5 倍以上! 现在 TCMalloc 反过来比 Ptmalloc2 慢了 1 倍! 这是因为 TCMalloc 特意针对小内存做了优化.")]),s._v(" "),t("p",[s._v("多少字节叫小内存呢? "),t("strong",[s._v("TCMalloc 把内存分为 3 个档次, 小于等于 256KB 的称为小内存, 从 256KB 到 1M 称为中等内存, 大于 1MB 的叫做大内存")]),s._v(". TCMalloc 对中等内存, 大内存的分配速度很慢, 比如用单线程分配 2M 的内存, Ptmalloc2 耗时仍然稳定在 32 纳秒, 但 TCMalloc 已经上升到 86 纳秒, 增长了 7 倍以上.")]),s._v(" "),t("p",[s._v("所以, "),t("mark",[t("strong",[s._v("如果主要分配 256KB 以下的内存, 特别是在多线程环境下, 应当选择 TCMalloc; 否则应使用 Ptmalloc2, 它的通用性更好")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("h5",{attrs:{id:"_3-从堆还是栈上分配内存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-从堆还是栈上分配内存"}},[s._v("#")]),s._v(" 3.从堆还是栈上分配内存?")]),s._v(" "),t("p",[s._v("不知道你发现没有, 刚刚讨论的内存池中分配出的都是"),t("strong",[s._v("堆内存")]),s._v(", 如果把在堆中分配的对象改为在栈上分配, 速度还会再快上 1 倍! 为什么?")]),s._v(" "),t("p",[s._v("可能有同学还不清楚堆和栈内存是如何分配的, 先简单介绍一下.")]),s._v(" "),t("p",[s._v("如果使用的是静态类型语言, 那么不使用 new 关键字分配的对象大都是在栈中的. 比如:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Java")]),s._v("语言"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("否则, 通过 new 或者 malloc 关键字分配的对象则是在堆中的:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),s._v("语言"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("malloc")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sizeof")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("C")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),s._v("语言"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Java")]),s._v("语言"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("另外, 对于动态类型语言, 无论是否使用 new 关键字, 内存都是从堆中分配的.")]),s._v(" "),t("p",[s._v("了解了这一点之后, 再来看看, "),t("strong",[s._v("为什么从栈中分配内存会更快")]),s._v(".")]),s._v(" "),t("p",[s._v("这是因为, "),t("mark",[t("strong",[s._v("由于每个线程都有独立的栈, 所以分配内存时不需要加锁保护, 而且栈上对象的尺寸在编译阶段就已经写入可执行文件了, 执行效率更高")])]),s._v("! 性能至上的 Golang 语言就是按照这个逻辑设计的, 即使你用 new 关键字分配了堆内存, 但编译器如果认为在栈中分配不影响功能语义时, 会自动改为在栈中分配.")]),s._v(" "),t("p",[s._v("当然, 在栈中分配内存也有缺点, 它有功能上的限制. 一是, "),t("strong",[s._v("栈内存生命周期有限")]),s._v(", 它会随着函数调用结束后自动释放. 在堆中分配的内存, 并不随着分配时所在函数调用的结束而释放, 它的生命周期足够使用; 二是, "),t("strong",[s._v("栈的容量有限")]),s._v(", 如 CentOS 7 中是 8MB 字节, 如果申请的内存超过限制会造成栈溢出错误(比如, 递归函数调用很容易造成这种问题), 而堆则没有容量限制.")]),s._v(" "),t("p",[t("strong",[s._v("所以, 当分配内存时, 如果在满足功能的情况下, 可以在栈中分配的话, 就选择栈.")])]),s._v(" "),t("h5",{attrs:{id:"_4-小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("最后做个小结.")]),s._v(" "),t("p",[s._v("进程申请内存的速度, 以及总内存空间都受到内存池的影响. 知道这些隐藏内存池的存在, 是提升分配内存效率的前提.")]),s._v(" "),t("p",[s._v("隐藏着的 C 库内存池, 对进程的内存开销有很大的影响. 当进程的占用空间超出预期时, 需要清楚正在使用的是什么内存池, 它对每个线程预分配了多大的空间. 不同的 C 库内存池, 都有它们最适合的应用场景, 例如 TCMalloc 对多线程下的小内存分配特别友好, 而 Ptmalloc2 则对各类尺寸的内存申请都有稳定的表现, 更加通用.")]),s._v(" "),t("p",[s._v("内存池管理着堆内存, 它的分配速度比不上在栈中分配内存. 只是栈中分配的内存受到生命周期和容量大小的限制, 应用场景更为有限. 然而, 如果有可能的话, "),t("strong",[s._v("尽量在栈中分配内存, 它比内存池中的堆内存分配速度快很多")]),s._v("!")]),s._v(" "),t("h4",{attrs:{id:"_03-索引-如何用哈希表管理亿级对象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_03-索引-如何用哈希表管理亿级对象"}},[s._v("#")]),s._v(" 03-索引:如何用哈希表管理亿级对象?")]),s._v(" "),t("p",[s._v("上一讲谈到, Ptmalloc2 为子线程预分配了 64MB 内存池, 虽然增大了内存消耗, 但却加快了分配速度, 这就是"),t("strong",[s._v("以空间换时间")]),s._v("的思想.")]),s._v(" "),t("p",[s._v("在内存有限的单片机上运行嵌入式程序时, 会压缩数据的空间占用, "),t("strong",[s._v("以时间换空间")]),s._v("; 但在面向海量用户的分布式服务中, "),t("strong",[s._v("使用更多的空间建立索引, 换取更短的查询时间")]),s._v(", 则是管理大数据的常用手段.")]),s._v(" "),t("p",[s._v("比如现在需要管理数亿条数据, 每条数据上有许多状态, 有些请求在查询这些状态, 有些请求则会根据业务规则有条件地更新状态, 有些请求会新增数据, 每条数据几十到几百字节. 如果需要提供微秒级的访问速度, 该怎么实现? (注意, 以上非功能性约束并不苛刻, 对于低 ARPU, 即每用户平均收入低的应用, 使用更少的资源实现同等功能非常重要. )")]),s._v(" "),t("p",[s._v("这种情况你会面对大量数据, 显然, 遍历全部数据去匹配查询关键字, 会非常耗时. 如果"),t("strong",[s._v("使用额外的空间为这些数据创建索引, 就可以基于索引实现快速查找, 这是常用的解决方案")]),s._v(". 比如, 用标准库里提供的字典类容器存放对象, 就是在数据前增加了索引, 其"),t("mark",[t("strong",[s._v("本质就是以空间换时间")])]),s._v(".")]),s._v(" "),t("p",[s._v("当然, 索引有很多, 哈希表, 红黑树, B 树都可以在内存中使用, 如果需要数据规模上亿后还能提供微秒级的访问速度, "),t("strong",[s._v("那么作为最快的索引, 哈希表是第一选择.")])]),s._v(" "),t("h5",{attrs:{id:"_2-为什么选择哈希表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么选择哈希表"}},[s._v("#")]),s._v(" 2.为什么选择哈希表?")]),s._v(" "),t("p",[s._v("为什么说哈希表是最快的索引呢? 怎么定量评价索引快慢呢?")]),s._v(" "),t("p",[s._v('实地运行程序统计时间不是个好主意, 因为它不只受数据特性, 数据规模的影响, 而且难以跨环境比较. 巴菲特说过: "'),t("strong",[s._v("近似的正确好过精确的错误.")]),s._v(' " 用'),t("strong",[s._v("近似的时间复杂度")]),s._v("描述运行时间, 好过实地运行得出的精确时间.")]),s._v(" "),t("p",[s._v('"时间复杂度" 经过了详细的数学运算, 它的运算过程就不详细展开讲了. 时间复杂度可以很好地反映运行时间随数据规模的变化趋势, 就如下图中, 横轴是数据规模, 纵轴是运行时间, 随着数据规模的增长, 水平直线 1 不随之变化, 也就是说, 运行时间不变, 是最好的曲线. 用大 O 表示法描述时间复杂度, 哈希表就是常量级的 O(1), 数据规模增长不影响它的运行时间, 所以 Memcached, Redis 都在用哈希表管理数据.')]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/9608b96e44ef5d270d684d616bac7d0d-20230731165330-33xtlry.png",alt:""}})]),s._v(" "),t("p",[s._v("为什么哈希表能做到 O(1) 时间复杂度呢?")]),s._v(" "),t("p",[s._v("首先, 哈希表基于数组实现, 而数组可以根据下标随机访问任意元素. 数组之所以可以随机访问, 是因为它"),t("strong",[s._v("由连续内存承载")]),s._v(", 且"),t("strong",[s._v("每个数组元素的大小都相等")]),s._v(". 于是, 当知道下标后, 把下标乘以元素大小, 再加上数组的首地址, 就可以获得目标访问地址, 直接获取数据.")]),s._v(" "),t("p",[s._v("其次, 哈希函数直接把查询关键字转换为数组下标, 再通过数组的随机访问特性获取数据. 比如, 如果关键字是字符串, 使用 BKDR 哈希算法将其转换为自然数, 再以哈希数组大小为除数, 对它进行求余, 就得到了数组下标. 如下图所示, 字符串 abc 经过哈希函数的运算, 得到了下标 39, 于是数据就存放在数组的第 39 个元素上. (注意, 这是个"),t("strong",[s._v("很糟糕")]),s._v("的哈希函数, 它使用的基数是 256, 即 2 的 8 次方, 下文会解释它为什么糟糕. )")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e65665a5062d6ec448d51a88f941af83-20230731165330-c1wuno4.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, **哈希函数的执行时间是常量, 数组的随机访问也是常量, 时间复杂度就是 O(1). **")]),s._v(" "),t("p",[s._v('实际上并非只有哈希表的时间复杂度是 O(1), 另一种索引 "位图", 它的时间复杂度也是 O(1). 不过本质上, 它是哈希表的'),t("strong",[s._v("变种")]),s._v(", 限制每个哈希桶只有 1 个比特位, 所以, 虽然它消耗的空间更少, 但仅用于辅助数据的主索引, 快速判断对象是否存在. 位图常用于解决缓存穿透的问题, 也常用于查找数组中的可用对象, 比如下图中通过批量判断位图数组的比特位(对 CPU 缓存也很友好), 找到数据数组中的对应元素.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/dcc2a0f43ebd26ac91c6dd9654c86ce9-20230731165330-7a5myrw.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, logN 也是不错的曲线, 随着数据规模的增长, 运行时间的增长是急剧放缓的. 红黑树的时间复杂度就是 O(logN). 如果需求中需要做范围查询, 遍历, 由于哈希表没办法找到关键字相邻的下一个元素, 所以哈希表不支持这类操作, 可以选择红黑树作为索引. 采用二分法的红黑树, 检索 1 万条数据需要做 14 次运算, 1 亿条也只需要 27 次而已.")]),s._v(" "),t("p",[s._v("如果"),t("strong",[s._v("红黑树过大, 内存中放不下时, 可以改用 B 树, 将部分索引存放在磁盘上")]),s._v(". 磁盘访问速度要比内存慢很多, 但 B 树充分考虑了机械磁盘寻址慢, 顺序读写快的特点, 通过多分支降低了树高, 减少了磁盘读写次数.")]),s._v(" "),t("p",[s._v("综合来看, 不考虑范围查询与遍历操作, 在追求最快速度的条件下, 哈希表是最好的选择.")]),s._v(" "),t("p",[s._v("然而, 在生产环境用哈希表管理如此多的数据, 必然面临以下问题:")]),s._v(" "),t("ol",[t("li",[s._v("首先, 面对上亿条数据, 为了保证可靠性, 需要做灾备恢复, 可以结合快照 +oplog 方式恢复数据, 但内存中的哈希表"),t("strong",[s._v("如何快速地序列化为快照文件")]),s._v("?")]),s._v(" "),t("li",[s._v("其次, 简单的使用标准库提供的哈希表处理如此规模的数据, 会导致内存消耗过大, 因为每多使用一个 8 字节的指针(或者叫引用)都会被放大亿万倍, 此时该"),t("strong",[s._v("如何实现更节约内存的个性化哈希表")]),s._v("?")]),s._v(" "),t("li",[s._v("再次, 哈希表频繁发生冲突时, 速度会急剧降低, 该通过哪些手段"),t("strong",[s._v("减少冲突概率")]),s._v("?")])]),s._v(" "),t("p",[s._v("接下来就来看看, 如何解决以上问题, 用哈希表有效地管理亿级数据.")]),s._v(" "),t("h5",{attrs:{id:"_2-内存结构与序列化方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-内存结构与序列化方案"}},[s._v("#")]),s._v(" 2.内存结构与序列化方案")]),s._v(" "),t("p",[s._v("事实上"),t("strong",[s._v("对于动态(元素是变化的)哈希表, 我们无法避免哈希冲突.")]),s._v('  比如上例中, "abc" 与 "cba" 这两个字符串哈希后都会落到下标 39 中, 这就产生了冲突. 有两种方法解决哈希冲突:')]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("链接法")]),s._v(", 落到数组同一个位置中的多个数据, 通过链表串在一起. 使用哈希函数查找到这个位置后, 再使用链表遍历的方式查找数据. Java 标准库中的哈希表就使用链接法解决冲突.")]),s._v(" "),t("li",[t("strong",[s._v("开放寻址法")]),s._v(", 插入时若发现对应的位置已经占用, 或者查询时发现该位置上的数据与查询关键字不同, 开放寻址法会按既定规则变换哈希函数(例如哈希函数设为 H(key,i), 顺序地把参数 i 加 1), 计算出下一个数组下标, 继续在哈希表中探查正确的位置.")])]),s._v(" "),t("p",[s._v("该选择哪种方法呢?")]),s._v(" "),t("p",[s._v("由于生产级存放大量对象的哈希表是需要容灾的, 比如每隔一天把哈希表数据定期备份到另一台服务器上. 当服务器宕机而启动备用服务器时, 首先可以用备份数据把哈希表恢复到 1 天前的状态, 再通过操作日志 oplog 把 1 天内的数据载入哈希表, 这样就可以最快速的恢复哈希表. 所以为了能够传输, 首先必须"),t("strong",[s._v("把哈希表序列化")]),s._v(".")]),s._v(" "),t("p",[s._v("链接法虽然实现简单, 还允许"),t("strong",[s._v("存放元素个数大于数组的大小")]),s._v("(也叫装载因子大于 1), 但链接法序列化数据的代价很大, 因为使用了指针后, 内存是不连续的.")]),s._v(" "),t("p",[t("strong",[s._v("开放寻址法")]),s._v("确保所有对象都在数组里, 就可以把数组用到的这段连续内存原地映射到文件中(参考 Linux 中的 mmap, Java 等语言都有类似的封装), 再通过备份文件的方式备份哈希表. 虽然操作系统会自动同步内存中变更的数据至文件, 但备份前还是需要主动刷新内存(参考 Linux 中的 msync, 它可以按地址及长度来分段刷新, 以减少 msync 的耗时), 以确定备份数据的精确时间点. 而新的进程启动时, 可以通过映射磁盘中的文件到内存, 快速重建哈希表提供服务.")]),s._v(" "),t("p",[t("strong",[s._v("如果能将数据完整的放进数组, 那么开放寻址法已经解决了序列化问题, 所以应该选择开放寻址法")]),s._v(".")]),s._v(" "),t("p",[s._v("但是, 有两个因素使得我们必须把数据放在哈希桶之外:")]),s._v(" "),t("ul",[t("li",[s._v("每条数据有上百字节;")]),s._v(" "),t("li",[s._v("哈希表中一定会有很多空桶(没有存放数据). 空桶的比例越高(装载因子越小), 冲突概率也会越低, 但如果每个空桶都占用上百字节, 亿级规模会轻松把浪费的内存放大许多倍.")])]),s._v(" "),t("p",[t("strong",[s._v("所以, 要把数据从哈希表中分离出来, 提升哈希表的灵活性(灵活调整装载因子)")]),s._v(" . 此时, 该如何序列化哈希表以外的数据呢? 最快速的序列化方案, 还是像开放寻址法的散列表一样, 使用定长数组存放对象, 通过原地映射文件的方式序列化数据. 由于数据未必是定长的, 所以又分为两种情况.")]),s._v(" "),t("p",[s._v("**一, 数据的长度是固定的. **可以用另一个数组 D 存放数据, 其中 D 的大小是待存放元素的最大数量, 注意, D 可以远小于哈希数组的大小. 如果哈希表是动态的, 支持新建与删除元素操作, 还需要把数组 D 中空闲的位置构建一个单链表, 新建时从链表头取元素, 删除时将元素归还至链表头部.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/78e7a26ad66548f173e9ff611cde60bb-20230731165330-exfbyko.png",alt:""}})]),s._v(" "),t("p",[s._v("**二, 数据的长度并不固定. **此时, 可以采用有限个定长数组存放数据, 用以空间换时间的思想, 加快访问速度. 如下图中, D1 数组存放长度小于 L1 的数据, D2 数组存放长度在 L1 和 L2 之间的数据, 以此类推. 而哈希表数组 H 中, 每个桶用 i 位存放该数据在哪个数组中, 用 j 位存放数组下标. 查找数据时, 前 i 位寻找数组, 后 j 位作为数组下标直接访问数据.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1e7a891acecacf6ffc87ec12e789012c-20230731165330-nfsw2jq.png",alt:""}})]),s._v(" "),t("p",[s._v("在这两种情况里, 哈希桶不需要存放 8 字节 64 位的地址. 因为, 或许数组 D 的大小不到 1 亿, 也就是说, 你最多只需要寻址 1 亿条数据, 这样 30 位足够使用. 要知道, 减少哈希桶的尺寸, 就意味着同等内存下可以扩大哈希数组, 从而降低装载因子.")]),s._v(" "),t("h5",{attrs:{id:"_3-降低哈希表的冲突概率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-降低哈希表的冲突概率"}},[s._v("#")]),s._v(" 3.降低哈希表的冲突概率")]),s._v(" "),t("p",[s._v("虽然哈希冲突有解决方案, 但若是所有元素都发生了冲突, 哈希表的时间复杂度就退化成了 O(N), 即每查找一次都要遍历所有数据. 所以, 为了获得与数据规模无关的常量级时间, 必须减少冲突的概率, 而减少冲突概率有两个办法, "),t("mark",[t("strong",[s._v("第一个办法是调优哈希函数, 第二个办法就是扩容")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("先看调优哈希函数. 什么是好的哈希函数呢? 首先它的"),t("strong",[s._v("计算量不能大, 其次应尽量降低冲突概率")]),s._v(". 回到开头的那个哈希函数:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e65665a5062d6ec448d51a88f941af83-20230731165330-15d6r73.png",alt:""}})]),s._v(" "),t("p",[s._v('这个哈希函数使得 "abc" 和 "cba" 两个关键字都落在了下标 39 上, 造成了哈希冲突, 是因为它'),t("strong",[s._v("丢失了字母的位置信息")]),s._v(". BKDR 是优秀的哈希算法, 但它不能以 28 作为基数, 这会导致字符串分布不均匀. 事实上, 应当找一个合适的"),t("strong",[s._v("素数作为基数")]),s._v(", 比如 31, Java 标准库的 BKDR 哈希算法就以它为基数, 它的计算量也很小: "),t("code",[s._v("n*31")]),s._v("​ 可以通过先把 n 左移 5 位, 再减去 n 的方式替换 (n*31 == n << 5 - n).")]),s._v(" "),t("p",[s._v("一次位移加一次减法, 要比一次乘法快得多. 当然, 图中的哈希函数之所以会丢失位置信息, 是因为"),t("strong",[s._v("以 28 作为基数的同时, 又把 28 - 1 作为除数所致")]),s._v(", 数学较好的同学可以试着推导证明, 这里只需要记住, "),t("strong",[s._v("基数必须是素数")]),s._v("就可以了.")]),s._v(" "),t("p",[s._v("当哈希函数把高信息量的关键字压缩成更小的数组下标时, "),t("strong",[s._v("一定会丢失信息")]),s._v(". 我们希望只丢失一些无关紧要的信息, 尽量多地保留区分度高的信息. 这需要分析关键字的特点, 分布规律. 比如, 对于 11 位手机号, 前 3 位接入号区分度最差, 中间 4 位表示地域的数字信息量有所增强, 最后 4 位个人号信息量最高. 如果哈希桶只有 1 万个, 那么通过 phonenum % 10000, 最大化保留后 4 位信息就是个不错的选择.")]),s._v(" "),t("p",[s._v("再比如, QQ 号似乎不像手机号的数字分布那么有特点, 然而, 如果静态的统计存量 QQ 号, 就会发现最后 1 位为 0 的号码特别多(数字更讨人欢喜), 区分度很低. 这样, 哈希函数应当主动降低最后 1 位的信息量, 减少它对哈希表位置的影响. 比如, QQ 号 % 100 就放大了最后 1 位的信息, 增大了哈希冲突, 而用 QQ 号 % 101("),t("strong",[s._v("101 是素数, 效果更好)")]),s._v(" 作为哈希函数, 就降低了最后 1 位的影响.")]),s._v(" "),t("p",[t("strong",[s._v("接下来看看减少哈希冲突概率的第二个办法, 扩容.")]),s._v("  装载因子越接近于 1, 冲突概率就会越大. 如果不能改变元素的数量, 只能通过扩容提升哈希桶的数量, 减少冲突.")]),s._v(" "),t("p",[s._v("由于哈希函数必须确保计算出的下标落在数组范围中, 而扩容会增加数组的大小, 进而影响哈希函数, 因此, 扩容前存放在哈希表中的所有元素, 它们"),t("strong",[s._v("在扩容后的数组中位置都发生了变化")]),s._v(". 所以, 扩容需要新老哈希表同时存在, 通过遍历全部数据, 用新的哈希函数把关键字放到合适的新哈希桶中. 可见扩容是一个"),t("strong",[s._v("极其耗时的操作")]),s._v(", 尤其在元素以亿计的情况下.")]),s._v(" "),t("p",[s._v("那么, 在耗时以小时计的扩容过程中, 如何持续提供正常服务呢? 其实, 只要把一次性的迁移过程, 分为多次后台迁移, 且提供服务时能够根据迁移情况选择新老哈希表即可. 如果单机内存可以存放下新老两张哈希表, 那么动态扩容不需要跨主机. 反之, 扩容过程将涉及新老哈希表所在的两台服务器, 实现更为复杂, 但原理是相同的.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-2"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("今天介绍了如何用哈希表管理上亿条数据. 为什么选择哈希表? 因为哈希表的运行时间不随着业务规模增长而变化. 位图本质上是哈希表的变种, 不过它常用于配合主索引, 快速判断数据的状态. 因为哈希表本身没办法找到关键字相邻的下一个元素, 所以哈希表不支持范围查询与遍历. 如果业务需要支持范围查询时, 需要考虑红黑树, B 树等索引, 它们其实并不慢. 当索引太大, 必须将一部分从内存中移到硬盘时, B 树就是一个很好的选择.")]),s._v(" "),t("p",[s._v("使用哈希表, 要注意几个关键问题.")]),s._v(" "),t("ul",[t("li",[s._v("生产环境一定要考虑容灾, 而把哈希表原地序列化为文件是一个解决方案, 它能保证新进程快速恢复哈希表. 解决哈希冲突有链接法和开放寻址法, 而后者更擅长序列化数据, 因此成为我们的首选.")]),s._v(" "),t("li",[s._v("亿级数据下, 必须注重内存的节约使用. 数亿条数据会放大节约下的点滴内存, 再把它们用于提升哈希数组的大小, 就可以通过降低装载因子来减少哈希冲突, 提升速度.")]),s._v(" "),t("li",[s._v("优化哈希函数也是降低哈希冲突的重要手段, 需要研究关键字的特征与分布, 设计出快速, 使关键字均匀分布的哈希函数.")])]),s._v(" "),t("p",[s._v("再延伸说一点, 哈希表, 红黑树等这些索引都使用了"),t("strong",[s._v("以空间换时间")]),s._v("的思想. 判断它们的时间消耗, 都需要依赖时间复杂度这个工具. 当然, 索引在某些场景下也会降低性能. 例如添加, 删除元素时, 更新索引消耗的时间就是新增的. 但相对于整体的收益, 这些消耗是微不足道的.")]),s._v(" "),t("h4",{attrs:{id:"_04-零拷贝-如何高效地传输文件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_04-零拷贝-如何高效地传输文件"}},[s._v("#")]),s._v(" 04-零拷贝:如何高效地传输文件?")]),s._v(" "),t("p",[s._v("上一讲谈到, 当索引的大小超过内存时, 就会用磁盘存放索引. 磁盘的读写速度远慢于内存, 所以才针对磁盘设计了减少读写次数的 B 树索引.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("磁盘是主机中最慢的硬件之一, 常常是性能瓶颈, 所以优化它能获得立竿见影的效果.")])])]),s._v(" "),t("p",[s._v("因此, 针对磁盘的优化技术层出不穷, 比如"),t("strong",[s._v("零拷贝, 直接 IO, 异步 IO")]),s._v(" 等等. 这些优化技术为了降低操作时延, 提升系统的吞吐量, 围绕着内核中的"),t("strong",[s._v("磁盘高速缓存(也叫 PageCache), 去减少 CPU 和磁盘设备的工作量")]),s._v(".")]),s._v(" "),t("p",[s._v("这些磁盘优化技术和策略虽然很有效, 但是理解它们并不容易. 只有搞懂内核操作磁盘的流程, 灵活正确地使用, 才能有效地优化磁盘性能.")]),s._v(" "),t("p",[s._v('本节就通过解决 "'),t("strong",[s._v("如何高效地传输文件")]),s._v('" 这个问题, 来分析下磁盘是如何工作的, 并且通过优化传输文件的性能, 来学习现在热门的'),t("strong",[s._v("零拷贝, 异步 IO 与直接 IO 这些磁盘优化技术")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-你会如何实现文件传输"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-你会如何实现文件传输"}},[s._v("#")]),s._v(" 1.你会如何实现文件传输?")]),s._v(" "),t("p",[s._v("服务器提供文件传输功能, 需要将磁盘上的文件读取出来, 通过网络协议发送到客户端. 如果需要你自己编码实现这个文件传输功能, 你会怎么实现呢?")]),s._v(" "),t("p",[s._v("通常, 你会选择最直接的方法: 从网络请求中找出文件在磁盘中的路径后, 如果这个文件比较大, 假设有 320MB, 可以在内存中分配 32KB 的缓冲区, 再把文件分成一万份, 每份只有 32KB, "),t("strong",[s._v("这样从文件的起始位置读入 32KB 到缓冲区, 再通过网络 API 把这 32KB 发送到客户端")]),s._v(". 接着重复一万次, 直到把完整的文件都发送完毕. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/578037aca9aa0605d44d4b97a3b89e92-20230731165330-w75vlp7.png",alt:""}})]),s._v(" "),t("p",[s._v("不过这个方案性能并不好, 主要有两个原因.")]),s._v(" "),t("p",[s._v("首先, 它至少"),t("strong",[s._v("经历了 4 万次用户态与内核态的上下文切换.")]),s._v("  因为每处理 32KB 的消息, 就需要一次 read 调用和一次 write 调用, "),t("strong",[s._v("每次系统调用都得先从用户态切换到内核态, 等内核完成任务后, 再从内核态切换回用户态")]),s._v(". 可见, 每处理 32KB, 就有 4 次上下文切换, 重复 1 万次后就有 4 万次切换.")]),s._v(" "),t("p",[s._v("上下文切换的成本并不小, 虽然一次切换仅消耗几十纳秒到几微秒, 但高并发服务会放大这类时间的消耗.")]),s._v(" "),t("p",[s._v("其次, 这个方案做了 **4 万次内存拷贝, 对 320MB 文件拷贝的字节数也翻了 4 倍, 到了 1280MB. **很显然, 过多的内存拷贝无谓地消耗了 CPU 资源, 降低了系统的并发处理能力.")]),s._v(" "),t("p",[s._v("所以要想提升传输文件的性能, 需要从"),t("mark",[t("strong",[s._v("降低上下文切换的频率和内存拷贝次数")])]),s._v("两个方向入手.")]),s._v(" "),t("h5",{attrs:{id:"_2-零拷贝如何提升文件传输性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-零拷贝如何提升文件传输性能"}},[s._v("#")]),s._v(" 2.零拷贝如何提升文件传输性能?")]),s._v(" "),t("p",[s._v("首先来看如何"),t("strong",[s._v("降低上下文切换的频率")]),s._v(".")]),s._v(" "),t("p",[s._v("为什么读取磁盘文件时, 一定要做上下文切换呢? 这是因为, "),t("strong",[s._v("读取磁盘或者操作网卡都由操作系统内核完成. 内核负责管理系统上的所有进程, 它的权限最高, 工作环境与用户进程完全不同")]),s._v(". 只要代码执行 read 或者 write 这样的系统调用, 一定会发生 2 次上下文切换: "),t("mark",[t("strong",[s._v("首先从用户态切换到内核态, 当内核执行完任务后, 再切换回用户态交由进程代码执行")])]),s._v(".")]),s._v(" "),t("p",[s._v("因此, 如果想减少上下文切换次数, 就一定要"),t("strong",[s._v("减少系统调用的次数")]),s._v(". 解决方案就是"),t("strong",[s._v("把 read, write 两次系统调用合并成一次, 在内核中完成磁盘与网卡的数据交换")]),s._v(".")]),s._v(" "),t("p",[s._v("其次, 应该考虑如何减少内存拷贝次数.")]),s._v(" "),t("p",[s._v("每周期中的 4 次内存拷贝, 其中与物理设备相关的 2 次拷贝是必不可少的, 包括: "),t("strong",[s._v("把磁盘内容拷贝到内存, 以及把内存拷贝到网卡")]),s._v(". 但另外 2 次与用户缓冲区相关的拷贝动作都不是必需的, 因为在把磁盘文件发到网络的场景中, "),t("strong",[s._v("用户缓冲区没有必须存在的理由")]),s._v(".")]),s._v(" "),t("p",[s._v("如果"),t("mark",[t("strong",[s._v("内核在读取文件后, 直接把 PageCache 中的内容拷贝到 Socket 缓冲区, 待到网卡发送完毕后, 再通知进程, 这样就只有 2 次上下文切换, 和 3 次内存拷贝")])]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e9548c592a6955f98dbe147d7e522483-20230731165330-tc5cvzm.png",alt:""}})]),s._v(" "),t("p",[s._v("如果网卡支持 "),t("strong",[s._v("SG-DMA")]),s._v("(The Scatter-Gather Direct Memory Access)技术, 还可以再去除 Socket 缓冲区的拷贝, 这样一共只有 2 次内存拷贝.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8b8b7cb787d251ce009721b583ba579b-20230731165330-dvdba8g.png",alt:""}})]),s._v(" "),t("p",[s._v("**实际上, 这就是零拷贝技术. **")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("它是操作系统提供的新函数, 同时接收文件描述符和 TCP socket 作为输入参数, 这样执行时就可以完全在内核态完成内存拷贝, 既减少了内存拷贝次数, 也降低了上下文切换次数.")])])]),s._v(" "),t("p",[s._v("而且, 零拷贝取消了用户缓冲区后, 不只降低了用户内存的消耗, 还通过最大化利用 socket 缓冲区中的内存, 间接地再一次减少了系统调用的次数, 从而带来了大幅减少上下文切换次数的机会!")]),s._v(" "),t("p",[s._v("没用零拷贝时, 为了传输 320MB 的文件, 在用户缓冲区分配了 32KB 的内存, 把文件分成 1 万份传送, 然而, "),t("strong",[s._v("这 32KB 是怎么来的?")]),s._v("  为什么不是 32MB 或者 32 字节呢? 这是因为, 在没有零拷贝的情况下, 我们希望内存的利用率最高. 如果用户缓冲区过大, 它就无法一次性把消息全拷贝给 socket 缓冲区; 如果用户缓冲区过小, 则会导致过多的 read/write 系统调用.")]),s._v(" "),t("p",[s._v("那用户缓冲区为什么不与 socket 缓冲区大小一致呢? 这是因为, "),t("strong",[s._v("socket 缓冲区的可用空间是动态变化的")]),s._v(", 它既用于 TCP 滑动窗口, 也用于应用缓冲区, 还受到整个系统内存的影响. 尤其在长肥网络中, 它的变化范围特别大.")]),s._v(" "),t("p",[t("strong",[s._v("零拷贝使我们不必关心 socket 缓冲区的大小.")]),s._v("  比如, 调用零拷贝发送方法时, 可以把发送字节数设为文件的所有未发送字节数, 例如 320MB, 也许此时 socket 缓冲区大小为 1.4MB, 那么一次性就会发送 1.4MB 到客户端, 而不是只有 32KB. 这意味着"),t("strong",[s._v("对于 1.4MB 的 1 次零拷贝")]),s._v(", 仅带来 2 次上下文切换, 而不使用零拷贝且用户缓冲区为 32KB 时, 经历了 176 次(4 * 1.4MB/32KB) 上下文切换.")]),s._v(" "),t("p",[s._v("综合上述各种优点, "),t("strong",[s._v("零拷贝可以把性能提升至少一倍以上!")]),s._v("  对开头提到的 320MB 文件的传输, 当 socket 缓冲区在 1.4MB 左右时, 只需要 4 百多次上下文切换, 以及 4 百多次内存拷贝, 拷贝的数据量也仅有 640MB, 这样不只请求时延会降低, 处理每个请求消耗的 CPU 资源也会更少, 从而支持更多的并发请求.")]),s._v(" "),t("p",[s._v("此外, "),t("strong",[s._v("零拷贝还使用了 PageCache 技术, 通过它, 零拷贝可以进一步提升性能")]),s._v(", 接下来看看 PageCache 是如何做到这一点的.")]),s._v(" "),t("h5",{attrs:{id:"_3-pagecache-磁盘高速缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-pagecache-磁盘高速缓存"}},[s._v("#")]),s._v(" 3.PageCache,磁盘高速缓存")]),s._v(" "),t("p",[s._v("回顾上文中的几张图可以发现, "),t("mark",[t("strong",[s._v("读取文件时, 是先把磁盘文件拷贝到 PageCache 上, 再拷贝到进程中")])]),s._v(". 为什么这样做呢? 有两个原因所致.")]),s._v(" "),t("p",[s._v("第一, 由于磁盘比内存的速度慢许多, 所以应该想办法"),t("strong",[s._v("把读写磁盘替换成读写内存")]),s._v(", 比如把磁盘中的数据复制到内存中, 就可以用读内存替换读磁盘. 但是, 内存空间远比磁盘要小, 内存中注定只能复制一小部分磁盘中的数据.")]),s._v(" "),t("p",[s._v("选择哪些数据复制到内存呢? 通常, "),t("strong",[s._v('刚被访问的数据在短时间内再次被访问的概率很高(这也叫"时间局部性"原理), 用 PageCache 缓存最近访问的数据, 当空间不足时淘汰最久未被访问的缓存(即 LRU 算法). 读磁盘时优先到 PageCache 中找一找, 如果数据存在便直接返回, 这便大大提升了读磁盘的性能')]),s._v(".")]),s._v(" "),t("p",[s._v("第二, 读取磁盘数据时, 需要先找到数据所在的位置, 对于机械磁盘来说, 就是旋转磁头到数据所在的扇区, 再开始顺序读取数据. 其中, 旋转磁头耗时很长, 为了降低它的影响, PageCache 使用了"),t("strong",[s._v("预读功能")]),s._v(".")]),s._v(" "),t("p",[s._v("也就是说, 虽然 read 方法只读取了 0-32KB 的字节, 但内核会把其后的 32-64KB 也读取到 PageCache, 这后 32KB 读取的成本很低. 如果在 32-64KB 淘汰出 PageCache 前, 进程读取到它了, 收益就非常大. 这一讲的传输文件场景中这是必然发生的.")]),s._v(" "),t("p",[s._v("从这两点可以看到 PageCache 的优点, 它在 90% 以上场景下都会提升磁盘性能, **但在某些情况下, PageCache 会不起作用, 甚至由于多做了一次内存拷贝, 造成性能的降低. **在这些场景中, 使用了 PageCache 的零拷贝也会损失性能.")]),s._v(" "),t("p",[s._v("具体是什么场景呢? 就是在"),t("strong",[s._v("传输大文件")]),s._v("的时候. 比如有很多 GB 级的文件需要传输, 每当用户访问这些大文件时, 内核就会把它们载入到 PageCache 中, 这些"),t("strong",[s._v("大文件很快会把有限的 PageCache 占满")]),s._v(". 由于文件太大, 文件中某一部分内容被再次访问到的概率其实非常低. 这带来了 2 个问题: 首先, 由于 PageCache 长期被大文件占据, 热点小文件就无法充分使用 PageCache, 它们读起来变慢了; 其次, PageCache 中的大文件没有享受到缓存的好处, 但却耗费 CPU 多拷贝到 PageCache 一次.")]),s._v(" "),t("p",[s._v("所以, "),t("mark",[t("strong",[s._v("高并发场景下, 为了防止 PageCache 被大文件占满后不再对小文件产生作用, 大文件不应使用 PageCache, 进而也不应使用零拷贝技术处理")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("h5",{attrs:{id:"_4-异步io-直接io"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-异步io-直接io"}},[s._v("#")]),s._v(" 4.异步IO+直接IO")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("高并发场景处理大文件时, 应当使用异步 IO 和直接 IO 来替换零拷贝技术")])]),s._v(".")]),s._v(" "),t("p",[s._v("仍然回到开头的例子, 当调用 read 方法读取文件时, 实际上 read 方法会在磁盘寻址过程中阻塞等待, 导致进程无法并发地处理其他任务, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/9a3db9fb3e129bb5a4bc8c912c312283-20230731165330-kv5pfaa.png",alt:""}})]),s._v(" "),t("p",[s._v("异步 IO(异步 IO 既可以处理网络 IO, 也可以处理磁盘 IO, 这里只关注磁盘 IO)可以解决阻塞问题. 它把读操作分为两部分, 前半部分向内核发起读请求, 但"),t("strong",[s._v("不等待数据就位就立刻返回")]),s._v(", 此时进程可以并发地处理其他任务. 当内核将磁盘中的数据拷贝到进程缓冲区后, 进程将接收到内核的通知, 再去处理数据, 这是"),t("strong",[s._v("异步 IO 的后半部分")]),s._v(". 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/146cc0b1906a3578681db99e028874e5-20230731165330-wm21zsg.png",alt:""}})]),s._v(" "),t("p",[s._v("从图中可以看到, 异步 IO 并没有拷贝到 PageCache 中, 这其实是异步 IO 实现上的缺陷. 经过 PageCache 的 IO 可以称为缓存 IO, 它与虚拟内存系统耦合太紧, 导致异步 IO 从诞生起到现在都不支持缓存 IO.")]),s._v(" "),t("p",[s._v("绕过 PageCache 的 IO 是个新物种, 可以退把它称为"),t("strong",[s._v("直接 IO")]),s._v(". 对于磁盘, 异步 IO 只支持直接 IO.")]),s._v(" "),t("p",[s._v("直接 IO 的应用场景并不多, 主要有两种: 第一, 应用程序已经实现了磁盘文件的缓存, 不需要 PageCache 再次缓存, 引发额外的性能消耗. 比如 MySQL 等数据库就使用直接 IO; 第二, 高并发下传输大文件, 前面提到过, 大文件难以命中 PageCache 缓存, 又带来额外的内存拷贝, 同时还挤占了小文件使用 PageCache 时需要的内存, 因此这时应该使用直接 IO.")]),s._v(" "),t("p",[s._v("当然, 直接 IO 也有一定的缺点. 除了缓存外, 内核(IO 调度算法)会试图缓存尽量多的连续 IO 在 PageCache 中, 最后"),t("strong",[s._v("合并")]),s._v("成一个更大的 IO 再发给磁盘, 这样可以减少磁盘的寻址操作; 另外, 内核也会"),t("strong",[s._v("预读")]),s._v("后续的 IO 放在 PageCache 中, 减少磁盘操作. 直接 IO 绕过了 PageCache, 所以无法享受这些性能提升.")]),s._v(" "),t("p",[s._v("有了直接 IO 后, 异步 IO 就可以无阻塞地读取文件了. 现在, 大文件由异步 IO 和直接 IO 处理, 小文件则交由零拷贝处理, 至于判断文件大小的阈值可以灵活配置(参见 Nginx 的 directio 指令).")]),s._v(" "),t("h5",{attrs:{id:"_5-小结-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-小结-2"}},[s._v("#")]),s._v(" 5.小结")]),s._v(" "),t("p",[t("strong",[s._v("基于用户缓冲区传输文件时, 过多的内存拷贝与上下文切换次数会降低性能. 零拷贝技术在内核中完成内存拷贝, 天然降低了内存拷贝次数. 它通过一次系统调用合并了磁盘读取与网络发送两个操作, 降低了上下文切换次数. 尤其是, 由于拷贝在内核中完成, 它可以最大化使用 socket 缓冲区的可用空间, 从而提高了一次系统调用中处理的数据量, 进一步降低了上下文切换次数.")])]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("零拷贝技术基于 PageCache, 而 PageCache 缓存了最近访问过的数据, 提升了访问缓存数据的性能, 同时, 为了解决机械磁盘寻址慢的问题, 它还协助 IO 调度算法实现了 IO 合并与预读(这也是顺序读比随机读性能好的原因), 这进一步提升了零拷贝的性能")])]),s._v(". 几乎所有操作系统都支持零拷贝, 如果应用场景就是把文件发送到网络中, 那么应当选择使用了零拷贝的解决方案.")]),s._v(" "),t("p",[s._v("不过, 零拷贝有一个缺点, 就是"),t("strong",[s._v("不允许进程对文件内容作一些加工再发送, 比如数据压缩后再发送")]),s._v(". 另外, 当 PageCache 引发负作用时, 也不能使用零拷贝, 此时可以用异步 IO + 直接 IO 替换. 通常会设定一个文件大小阈值, "),t("strong",[s._v("针对大文件使用异步 IO 和直接 IO, 而对小文件使用零拷贝")]),s._v(".")]),s._v(" "),t("p",[s._v("事实上 PageCache 对写操作也有很大的性能提升, 因为 write 方法在写入内存中的 PageCache 后就会返回, 速度非常快, 由内核负责异步地把 PageCache 刷新到磁盘中, 这里不再展开.")]),s._v(" "),t("p",[s._v("本节从零拷贝出发, 看到了文件传输场景中内核在幕后所做的工作. 这里面的性能优化技术, 要么"),t("strong",[s._v("减少了磁盘的工作量(比如 PageCache 缓存), 要么减少了 CPU 的工作量")]),s._v("(比如直接 IO), 要么提高了内存的利用率(比如零拷贝). 在学习其他磁盘 IO 优化技术时, 可以延着这三个优化方向前进, 看看究竟如何降低时延, 提高并发能力.")]),s._v(" "),t("h4",{attrs:{id:"_05-协程-如何快速地实现高并发服务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_05-协程-如何快速地实现高并发服务"}},[s._v("#")]),s._v(" 05-协程:如何快速地实现高并发服务?")]),s._v(" "),t("p",[s._v("上一讲谈到, 零拷贝通过减少上下文切换次数, 提升了文件传输的性能. 事实上"),t("strong",[s._v("高并发服务也是通过降低切换成本实现的")]),s._v(", 这一讲来看看它是如何做到的.")]),s._v(" "),t("p",[s._v("如果你需要访问多个服务来完成一个请求的处理, 比如实现文件上传功能时, 首先访问 Redis 缓存, 验证用户是否登陆, 再接收 HTTP 消息中的 body 并保存在磁盘上, 最后把文件路径等信息写入 MySQL 数据库中, 你会怎么做?")]),s._v(" "),t("p",[s._v("用阻塞 API 写同步代码最简单, 但一个线程同一时间只能处理一个请求, 有限的线程数导致无法实现万级别的并发连接, 过多的线程切换也抢走了 CPU 的时间, 从而降低了每秒能够处理的请求数量.")]),s._v(" "),t("p",[s._v("为了达到高并发, 你可能会选择一个异步框架, 用非阻塞 API 把业务逻辑打乱到多个回调函数, 通过多路复用实现高并发, 然而, 由于业务代码过度关注并发细节, 需要维护很多中间状态, 不但 Bug 率会很高, 项目的开发速度也上不去, 产品及时上线存在风险.")]),s._v(" "),t("p",[t("strong",[s._v("如果想兼顾开发效率, 又能保证高并发, 协程就是最好的选择. 它可以在保持异步化运行机制的同时, 用同步方式写代码, 这在实现高并发的同时, 缩短了开发周期, 是高性能服务未来的发展方向.")])]),s._v(" "),t("p",[s._v("你会发现, 解决高并发问题的技术一直在变化, 从"),t("strong",[s._v("多进程, 多线程, 到异步化, 协程")]),s._v(", 面对不同的场景, 它们都在用各自不同的方式解决问题. 下面就来看看, "),t("strong",[s._v("高并发的解决方案是怎么演进的, 协程到底解决了什么问题")]),s._v(", 它又该如何应用.")]),s._v(" "),t("h5",{attrs:{id:"_1-如何通过切换请求实现高并发"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何通过切换请求实现高并发"}},[s._v("#")]),s._v(" 1.如何通过切换请求实现高并发?")]),s._v(" "),t("p",[s._v("主机上资源有限, 一颗 CPU, 一块磁盘, 一张网卡, 如何同时服务上百个请求呢? "),t("strong",[s._v("多进程模式是最初的解决方案")]),s._v(". 内核把 CPU 的执行时间切分成许多时间片(timeslice), 比如 1 秒钟可以切分为 100 个 10 毫秒的时间片, 每个时间片再分发给不同的进程, 通常, 每个进程需要多个时间片才能完成一个请求.")]),s._v(" "),t("p",[s._v("这样, 虽然微观上, 比如说就这 10 毫秒时间 CPU 只能执行一个进程, 但宏观上 1 秒钟执行了 100 个时间片, 于是每个时间片所属进程中的请求也得到了执行, **这就实现了请求的并发执行. **")]),s._v(" "),t("p",[s._v("不过, "),t("strong",[s._v("每个进程的内存空间都是独立的")]),s._v(", 这样用多进程实现并发就有两个缺点: 一是内核的管理成本高, 二是无法简单地通过内存同步数据, 很不方便. 于是, 多线程模式就出现了, "),t("strong",[s._v("多线程模式通过共享内存地址空间")]),s._v(", 解决了这两个问题.")]),s._v(" "),t("p",[s._v("然而, 共享地址空间虽然可以方便地共享对象, 但这也导致一个问题, 那就是"),t("strong",[s._v("任何一个线程出错时, 进程中的所有线程会跟着一起崩溃")]),s._v(". 这也是如 Nginx 等强调稳定性的服务坚持使用多进程模式的原因.")]),s._v(" "),t("p",[s._v("事实上, 无论基于多进程还是多线程, 都难以实现高并发, 这由两个原因所致.")]),s._v(" "),t("p",[s._v("首先, 单个线程消耗的内存过多, 比如, 64 位的 Linux 为"),t("strong",[s._v("每个线程的栈分配了 8MB 的内存, 还预分配了 64MB 的内存作为堆内存池")]),s._v(". 所以, 很难有足够的内存去开启几万个线程实现并发.")]),s._v(" "),t("p",[s._v("其次, 切换请求是"),t("strong",[s._v("内核通过切换线程")]),s._v("实现的, 什么时候会切换线程呢? 不只时间片用尽, "),t("strong",[s._v("当调用阻塞方法时, 内核为了让 CPU 充分工作, 也会切换到其他线程执行.")]),s._v("  一次上下文切换的成本在几十纳秒到几微秒间, 当线程繁忙且数量众多时, 这些切换会消耗绝大部分的 CPU 运算能力.")]),s._v(" "),t("p",[s._v("下图以上一讲介绍过的磁盘 IO 为例, 描述了多线程中使用阻塞方法读磁盘, 2 个线程间的切换方式.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/726ba7e2fa6b1851c95925f1ee715141-20230731165330-qi8egy3.png",alt:""}})]),s._v(" "),t("p",[s._v("那么, 怎么才能实现高并发呢? "),t("strong",[s._v("把上图中本来由内核实现的请求切换工作, 交由用户态的代码来完成就可以了, 异步化编程通过应用层代码实现了请求切换, 降低了切换成本和内存占用空间")]),s._v(". 异步化依赖于 IO 多路复用机制, 比如 Linux 的 epoll 或者 Windows 上的 iocp, 同时, 必须"),t("strong",[s._v("把阻塞方法更改为非阻塞方法")]),s._v(", 才能避免内核切换带来的巨大消耗. Nginx, Redis 等高性能服务都依赖异步化实现了百万量级的并发.")]),s._v(" "),t("p",[s._v("下图描述了异步 IO 的非阻塞读和异步框架结合后, 是如何切换请求的.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2c444e2b51943a87160e699beb8af8b7-20230731165330-ucb9rn9.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("然而, 写异步化代码很容易出错.")]),s._v("  因为"),t("strong",[s._v("所有阻塞函数, 都需要通过非阻塞的系统调用拆分成两个函数")]),s._v(". 虽然这两个函数共同完成一个功能, 但调用方式却不同. "),t("strong",[s._v("第一个函数由你显式调用, 第二个函数则由多路复用机制调用")]),s._v(". 这种方式违反了软件工程的内聚性原则, 函数间同步数据也更复杂. 特别是条件分支众多, 涉及大量系统调用时, 异步化的改造工作会非常困难.")]),s._v(" "),t("p",[s._v("有没有办法既享受到异步化带来的高并发, 又可以使用阻塞函数写同步化代码呢?")]),s._v(" "),t("p",[s._v("协程可以做到, **它在异步化之上包了一层外衣, 兼顾了开发效率与运行效率. **")]),s._v(" "),t("h5",{attrs:{id:"_2-协程是如何实现高并发的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-协程是如何实现高并发的"}},[s._v("#")]),s._v(" 2.协程是如何实现高并发的?")]),s._v(" "),t("p",[s._v("协程与异步编程相似的地方在于, 它们"),t("mark",[t("strong",[s._v("必须使用非阻塞的系统调用与内核交互, 把切换请求的权力牢牢掌握在用户态的代码中")])]),s._v(". 但不同的地方在于, "),t("mark",[t("strong",[s._v("协程把异步化中的两段函数, 封装为一个阻塞的协程函数. 这个函数执行时, 会使调用它的协程无感知地放弃执行权, 由协程框架切换到其他就绪的协程继续执行. 当这个函数的结果满足后, 协程框架再选择合适的时机, 切换回它所在的协程继续执行")])]),s._v(". 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/35dcf3f9b6c17bd1243c3dc40f4e8f6a-20230731165330-cbrv47o.png",alt:""}})]),s._v(" "),t("p",[s._v("看起来非常棒, 然而, 异步化是通过回调函数来完成请求切换的, 业务逻辑与并发实现关联在一起, 很容易出错. "),t("strong",[s._v('协程不需要什么 "回调函数", 它允许用户调用 "阻塞的" 协程方法, 用同步编程方式写业务逻辑')]),s._v(".")]),s._v(" "),t("p",[s._v("那协程的切换是如何完成的呢?")]),s._v(" "),t("p",[s._v("实际上, "),t("mark",[t("strong",[s._v("用户态的代码切换协程, 与内核切换线程的原理是一样的")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  内核通过管理 CPU 的寄存器来切换线程, 下面以最重要的"),t("strong",[s._v("栈寄存器和指令寄存器为例, 看看协程切换时如何切换程序指令与内存")]),s._v(".")]),s._v(" "),t("p",[s._v("每个线程有"),t("strong",[s._v("独立的栈")]),s._v(", 而栈既保留了变量的值, 也保留了函数的调用关系, 参数和返回值, CPU 中的栈寄存器 SP 指向了当前线程的栈, 而指令寄存器 IP 保存着下一条要执行的指令地址. 因此, 从线程 1 切换到线程 2 时, 首先要把 SP, IP 寄存器的值为线程 1 保存下来, 再从内存中找出线程 2 上一次切换前保存好的寄存器值, 写入 CPU 的寄存器, 这样就完成了线程切换. (其他寄存器也需要管理, 替换, 原理与此相同, 不再赘述.)")]),s._v(" "),t("p",[s._v("协程的切换与此相同, 只是把内核的工作转移到协程框架实现而已, 下图是协程切换前的状态:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2833f8c7b8dc34727107ed7921e7b233-20230731165330-jgq4x8g.png",alt:""}})]),s._v(" "),t("p",[s._v("从协程 1 切换到协程 2 后的状态如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e14b44a0fd928ade54a6cdc1fa446ba8-20230731165330-dq01eqg.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("创建协程时, 会从进程的堆中分配一段内存作为协程的栈")]),s._v(". 线程的栈有 8MB, 而"),t("strong",[s._v("协程栈的大小通常只有几十 KB")]),s._v(". 而且, C 库内存池也不会为协程预分配内存, "),t("strong",[s._v("它感知不到协程的存在")]),s._v(". 这样, 更低的内存占用空间为高并发提供了保证, 毕竟十万并发请求, 就意味着 10 万个协程. 当然, "),t("mark",[t("strong",[s._v("栈缩小后, 就尽量不要使用递归函数, 也不能在栈中申请过多的内存, 这是实现高并发必须付出的代价")])]),s._v(".")]),s._v(" "),t("p",[s._v("由此可见, "),t("mark",[t("strong",[s._v("协程就是用户态的线程")])]),s._v(". 然而, "),t("mark",[t("strong",[s._v("为了保证所有切换都在用户态进行, 协程必须重新封装所有的阻塞系统调用, 否则, 一旦协程触发了线程切换, 会导致这个线程进入休眠状态, 进而其上的所有协程都得不到执行")])]),s._v(". 比如, 普通的 sleep 函数会让当前线程休眠, 由内核来唤醒线程, 而协程化改造后, sleep 只会让当前协程休眠, 由协程框架在指定时间后唤醒协程. 再比如, 线程间的互斥锁是使用信号量实现的, 而信号量也会导致线程休眠, 协程化改造互斥锁后, 同样由框架来协调, 同步各协程的执行.")]),s._v(" "),t("p",[t("strong",[s._v("所以,")]),s._v(" "),t("mark",[t("strong",[s._v("协程的高性能, 建立在切换必须由用户态代码完成之上, 这要求协程生态是完整的, 要尽量覆盖常见的组件")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  比如 MySQL 官方提供的客户端 SDK, 它使用了阻塞 socket 做网络访问, 会导致线程休眠, 必须用非阻塞 socket 把 SDK 改造为协程函数后, 才能在协程中使用.")]),s._v(" "),t("p",[s._v("当然, 并不是所有的函数都能用协程改造. 比如异步 IO, 它虽然是非阻塞的, 但无法使用 PageCache, 降低了系统吞吐量. 如果使用缓存 IO 读文件, 在没有命中 PageCache 时是可能发生阻塞的. 这种时候, "),t("strong",[s._v("如果对性能有更高的要求, 就需要把线程与协程结合起来用, 把可能阻塞的操作放在线程中执行, 通过生产者/消费者模型与协程配合工作")]),s._v(".")]),s._v(" "),t("p",[s._v("实际上, 面对多核系统, 也需要协程与线程配合工作. "),t("strong",[s._v("因为协程的载体是线程, 而一个线程同一时间只能使用一颗 CPU, 所以通过开启更多的线程, 将所有协程分布在这些线程中, 就能充分使用 CPU 资源")]),s._v(".")]),s._v(" "),t("p",[s._v("除此之外, 为了让协程获得更多的 CPU 时间, 还可以设置所在线程的优先级, 比如 Linux 下把线程的优先级设置到 -20, 就可以每次获得更长的时间片. 另外, 前面曾谈到 CPU 缓存对程序性能的影响, 为了减少 CPU 缓存失效的比例, 还可以把线程绑定到某个 CPU 上, 增加协程执行时命中 CPU 缓存的机率.")]),s._v(" "),t("p",[s._v("虽然这一讲中谈到协程框架在调度协程, 然而, 可以发现, "),t("strong",[s._v("很多协程库只提供了创建, 挂起, 恢复执行等基本方法, 并没有协程框架的存在, 需要业务代码自行调度协程")]),s._v(". 这是因为, 这些通用的协程库并不是专为服务器设计的. 服务器中可以由客户端网络连接的建立, 驱动着创建出协程, 同时伴随着请求的结束而终止. 在协程的运行条件不满足时, 多路复用框架会将它挂起, 并根据优先级策略选择另一个协程执行.")]),s._v(" "),t("p",[s._v("因此, 使用协程实现服务器端的高并发服务时, 并不只是选择协程库, 还要从其生态中找到结合 IO 多路复用的协程框架, 这样可以加快开发速度.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节从高并发的应用场景入手, 分析了协程出现的背景和实现原理, 以及它的应用范围. "),t("strong",[s._v("协程融合了多线程与异步化编程的优点, 既保证了开发效率, 也提升了运行效率")]),s._v(".")]),s._v(" "),t("p",[s._v("有限的硬件资源下, "),t("strong",[s._v("多线程")]),s._v("通过微观上时间片的切换, 实现了同时服务上百个用户的能力. 多线程的开发成本虽然低, 但内存消耗大, 切换次数过多, 无法实现高并发.")]),s._v(" "),t("p",[t("strong",[s._v("异步编程方式")]),s._v("通过非阻塞系统调用和多路复用, 把原本属于内核的请求切换能力, 放在用户态的代码中执行. 这样, 不仅减少了每个请求的内存消耗, 也降低了切换请求的成本, 最终实现了高并发. 然而, 异步编程违反了代码的内聚性, 还需要业务代码关注并发细节, 开发成本很高.")]),s._v(" "),t("p",[t("strong",[s._v("协程参考内核通过 CPU 寄存器切换线程的方法, 在用户态代码中实现了协程的切换, 既降低了切换请求的成本, 也使得协程中的业务代码不用关注自己何时被挂起, 何时被执行. 相比异步编程中要维护一堆数据结构表示中间状态, 协程直接用代码表示状态, 大大提升了开发效率")]),s._v(".")]),s._v(" "),t("p",[s._v("在协程中调用的所有 API, 都需要做非阻塞的协程化改造. 优秀的协程生态下, 常用服务都有对应的协程 SDK, 方便业务代码使用. 开发高并发服务时, 与 IO 多路复用结合的协程框架可以与这些 SDK 配合, 自动挂起, 切换协程, 进一步提升开发效率.")]),s._v(" "),t("p",[t("strong",[s._v("协程并不是完全与线程无关, 首先线程可以帮助协程充分使用多核 CPU 的计算力, 其次, 遇到无法协程化, 会导致内核切换的阻塞函数, 或者计算太密集从而长时间占用 CPU 的任务, 还是要放在独立的线程中执行, 以防止它影响所有协程的执行")]),s._v(".")]),s._v(" "),t("h4",{attrs:{id:"_06-锁-如何根据业务场景选择合适的锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_06-锁-如何根据业务场景选择合适的锁"}},[s._v("#")]),s._v(" 06-锁:如何根据业务场景选择合适的锁?")]),s._v(" "),t("p",[s._v("本节来谈谈如何根据业务场景选择合适的锁.")]),s._v(" "),t("p",[t("strong",[s._v("多线程下为了确保数据不会出错, 必须加锁后才能访问共享资源")]),s._v(". 一般最常用的是互斥锁, 然而, 还有很多种不同的锁, 比如自旋锁, 读写锁等等, 它们分别适用于不同的场景.")]),s._v(" "),t("p",[s._v('比如高并发场景下, 要求每个函数的执行时间必须都足够得短, 这样所有请求才能及时得到响应, 如果选择了错误的锁, 数万请求同时争抢下, 很容易导致大量请求长期取不到锁而处理超时, 系统吞吐量始终维持在很低的水平, 用户体验非常差, 最终"高并发"成了一句空谈.')]),s._v(" "),t("p",[s._v("怎样选择最合适的锁呢? 首先必须清楚"),t("strong",[s._v("加锁的成本究竟有多大")]),s._v(", 其次要"),t("strong",[s._v("分析业务场景中访问共享资源的方式")]),s._v(", 最后则要"),t("strong",[s._v("预估并发访问时发生锁冲突的概率")]),s._v(". 这样才能选对锁, 同时实现高并发和高吞吐量这两个目标.")]),s._v(" "),t("p",[s._v("本节就针对不同的应用场景, 了解下锁的选择和使用, 从而减少锁对高并发性能的影响.")]),s._v(" "),t("h5",{attrs:{id:"_1-互斥锁与自旋锁-休眠还是-忙等待"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-互斥锁与自旋锁-休眠还是-忙等待"}},[s._v("#")]),s._v(' 1.互斥锁与自旋锁:休眠还是"忙等待"?')]),s._v(" "),t("p",[t("strong",[s._v("常见的各种锁是有层级的, 最底层的两种锁就是")]),s._v("​"),t("mark",[t("strong",[s._v("互斥锁和自旋锁")])]),s._v("​ "),t("strong",[s._v(", 其他锁都是基于它们实现的")]),s._v(". 互斥锁的加锁成本更高, 但它在加锁失败时会释放 CPU 给其他线程; 自旋锁则刚好相反.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("当无法判断锁住的代码会执行多久时, 应该首选互斥锁, 互斥锁是一种独占锁")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  什么意思呢? 当 A 线程取到锁后, 互斥锁将被 A 线程独自占有, 当 A 没有释放这把锁时, 其他线程的取锁代码都会被阻塞.")]),s._v(" "),t("p",[s._v("阻塞是怎样进行的呢? "),t("strong",[s._v("对于 99% 的线程级互斥锁而言, 阻塞都是由操作系统内核实现的")]),s._v("(比如 Linux 下它通常由内核提供的信号量实现). 当获取锁失败时, 内核会将线程置为"),t("strong",[s._v("休眠状态")]),s._v(", 等到锁被释放后, 内核会在合适的时机唤醒线程, 而这个线程成功拿到锁后才能继续执行. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2618e5b9abdd0d68559143fd449e4d76-20230731165330-32a56ff.png",alt:""}})]),s._v(" "),t("p",[s._v("互斥锁通过内核帮忙切换线程, 简化了业务代码使用锁的难度.")]),s._v(" "),t("p",[s._v("但是, "),t("strong",[s._v("线程获取锁失败时, 增加了两次上下文切换的成本: 从运行中切换为休眠, 以及锁释放时从休眠状态切换为运行中. 上下文切换耗时在几十纳秒到几微秒之间, 或许这段时间比锁住的代码段执行时间还长. 而且, 线程主动进入休眠是高并发服务无法容忍的行为, 这让其他异步请求都无法执行")]),s._v(".")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("如果能确定被锁住的代码执行时间很短, 就应该用自旋锁取代互斥锁")])]),s._v(". 自旋锁比互斥锁快得多, 因为它通过 CPU 提供的 "),t("strong",[s._v("CAS")]),s._v(" 函数(全称 Compare And Swap), 在用户态代码中完成加锁与解锁操作.")]),s._v(" "),t("p",[s._v("加锁流程包括 2 个步骤: "),t("strong",[s._v("第 1 步查看锁的状态, 如果锁是空闲的, 第 2 步将锁设置为当前线程持有")]),s._v(".")]),s._v(" "),t("p",[s._v("在没有 CAS 操作前, 多个线程同时执行这 2 个步骤是会出错的. 比如线程 A 执行第 1 步发现锁是空闲的, 但它在执行第 2 步前, 线程 B 也执行了第 1 步, B 也发现锁是空闲的, 于是线程 A, B 会同时认为它们获得了锁.")]),s._v(" "),t("p",[s._v("CAS 函数把这 2 个步骤"),t("strong",[s._v("合并为一条硬件级指令")]),s._v(". 这样, 第 1 步比较锁状态和第 2 步锁变量赋值, 将变为不可分割的原子指令. 于是, 设锁为变量 lock, 整数 0 表示锁是空闲状态, 整数 pid 表示线程 ID, 那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作, CAS(lock, pid, 0) 则表示解锁操作.")]),s._v(" "),t("p",[s._v('多线程竞争锁的时候, 加锁失败的线程会 "忙等待", 直到它拿到锁. 什么叫 "忙等待" 呢? 它并不意味着一直执行 CAS 函数, 生产级的自旋锁在 "忙等待" 时, 会与 CPU 紧密配合 , 它通过 CPU 提供的 PAUSE 指令, 减少循环等待时的耗电量; 对于单核 CPU, 忙等待并没有意义, 此时它会主动把线程休眠.')]),s._v(" "),t("p",[s._v('如果你对此感兴趣, 可以阅读下面这段生产级的自旋锁, 看看它是怎么执行"忙等待"的:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 因为判断lock变量的值比CAS操作更快, 所以先判断lock再调用CAS效率更高")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lock "),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),s._v("mark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("CAS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("mark"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CPU_count")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果是多核CPU, “忙等待”才有意义")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2048")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// pause的时间, 应当越来越长")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("pause")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// CPU专为自旋锁设计了pause指令")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lock "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("CAS")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// pause后再尝试获取锁")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sched_yield")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 单核CPU, 或者长时间不能获取到锁, 应主动休眠, 让出CPU")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("在使用层面上, 自旋锁与互斥锁很相似, 实现层面上它们又完全不同. "),t("strong",[s._v("自旋锁开销少, 在多核系统下一般不会主动产生线程切换, 很适合异步, 协程等在用户态切换请求的编程方式, 有助于高并发服务充分利用多颗 CPU")]),s._v('. 但如果被锁住的代码执行时间过长, CPU 资源将被其他线程在 "忙等待" 中长时间占用.')]),s._v(" "),t("p",[t("mark",[t("strong",[s._v('当取不到锁时, 互斥锁用 "线程切换 "来面对, 自旋锁则用 "忙等待" 来面对. 这是两种最基本的处理方式, 更高级别的锁都会选择其中一种来实现, 比如读写锁就既可以基于互斥锁实现, 也可以基于自旋锁实现.')])])]),s._v(" "),t("p",[s._v("下面来看一看读写锁能带来怎样的性能提升.")]),s._v(" "),t("h5",{attrs:{id:"_2-允许并发持有的读写锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-允许并发持有的读写锁"}},[s._v("#")]),s._v(" 2.允许并发持有的读写锁")]),s._v(" "),t("p",[t("strong",[s._v("如果能够明确区分出读和写两种场景, 可以选择读写锁.")])]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("读写锁由读锁和写锁两部分构成, 仅读取共享资源的代码段用读锁来加锁, 会修改资源的代码段则用写锁来加锁")])]),s._v(".")]),s._v(" "),t("p",[s._v("读写锁的优势在于, "),t("strong",[s._v("当写锁未被持有时, 多个线程能够并发地持有读锁, 这提高了共享资源的使用率. 多个读锁被同时持有时, 读线程并不会修改共享资源, 所以它们的并发执行不会产生数据错误")]),s._v(".")]),s._v(" "),t("p",[s._v("而一旦写锁被持有后, 不只读线程必须阻塞在获取读锁的环节, 其他获取写锁的写线程也要被阻塞. 写锁就像互斥锁和自旋锁一样, 是一种独占锁; 而读锁允许并发持有, 则是一种共享锁.")]),s._v(" "),t("p",[t("strong",[s._v("因此, 读写锁真正发挥优势的场景,")]),s._v(" "),t("mark",[t("strong",[s._v("必然是读多写少的场景")])]),s._v("​ "),t("strong",[s._v(", 否则读锁将很难并发持有.")])]),s._v(" "),t("p",[s._v("实际上, 读写锁既可以倾向于读线程, 又可以倾向于写线程. 前者称为读优先锁, 后者称为写优先锁.")]),s._v(" "),t("p",[s._v("读优先锁更强调效率, 它期待锁能被更多的线程持有. 简单看下它的工作特点: 当线程 A 先持有读锁后, 即使线程 B 在等待写锁, 后续前来获取读锁的线程 C 仍然可以立刻加锁成功, 因为这样就有 A, C 这 2 个读线程在并发持有锁, 效率更高.")]),s._v(" "),t("p",[s._v("再来看写优先的读写锁. 同样的情况下, 线程 C 获取读锁会失败, 它将被阻塞在获取锁的代码中, 这样只要线程 A 释放读锁后, 线程 B 马上就可以获取到写锁. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/baa736ecca9b9f568928d1a1f8a9cec6-20230731165330-ivxt1d5.png",alt:""}})]),s._v(" "),t("p",[s._v("读优先锁并发性更好, 但问题也很明显. 如果读线程源源不断地获取读锁, 写线程将永远获取不到写锁. 写优先锁可以保证写线程不会饿死, 但如果新的写线程源源不断地到来, 读线程也可能被饿死.")]),s._v(" "),t("p",[s._v("那么, 能否兼顾二者, 避免读, 写线程饿死呢?")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("用队列把请求锁的线程排队, 按照先来后到的顺序加锁即可, 当然读线程仍然可以并发, 只不过不能插队到写线程之前")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  Java 中的 ReentrantReadWriteLock 读写锁, 就支持这种排队的公平读写锁.")]),s._v(" "),t("p",[s._v('如果不希望取锁时线程主动休眠, 还可以用自旋锁实现读写锁. 到底应该选择 "线程切换" 还是 "忙等待" 方式实现读写锁呢? 除去读写场景外, 这与选择互斥锁和自旋锁的方法相同, 就是根据加锁代码执行时间的长短来选择, 这里就不再赘述了.')]),s._v(" "),t("h5",{attrs:{id:"_3-乐观锁-不使用锁也能同步"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-乐观锁-不使用锁也能同步"}},[s._v("#")]),s._v(" 3.乐观锁:不使用锁也能同步")]),s._v(" "),t("p",[s._v("事实上, "),t("strong",[s._v("无论互斥锁, 自旋锁还是读写锁, 都属于悲观锁")]),s._v(".")]),s._v(" "),t("p",[s._v("什么叫悲观锁呢? 它"),t("strong",[s._v("认为同时修改资源的概率很高, 很容易出现冲突, 所以访问共享资源前, 先加上锁, 总体效率会更优")]),s._v(". 然而, "),t("strong",[s._v("如果并发产生冲突的概率很低, 就不必使用悲观锁, 而是使用乐观锁")]),s._v(".")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v('所谓 "乐观", 就是假定冲突的概率很低, 所以它采用的"加锁"方式是, 先修改完共享资源, 再验证这段时间内有没有发生冲突. 如果没有其他线程在修改资源, 那么操作完成. 如果发现其他线程已经修改了这个资源, 就放弃本次操作.')])])]),s._v(" "),t("p",[s._v("至于放弃后如何重试, 则与业务场景相关, 虽然重试的成本很高, 但出现冲突的概率足够低的话, 还是可以接受的. 可见, "),t("mark",[t("strong",[s._v("乐观锁全程并没有加锁, 所以它也叫无锁编程")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("无锁编程中, 验证是否发生了冲突是关键. 该怎么验证呢? 这与具体的场景有关.")]),s._v(" "),t("p",[s._v("比如说在线文档. Web 中的在线文档是怎么实现多人编辑的? 用户 A 先在浏览器中编辑某个文档, 之后用户 B 也打开了相同的页面开始编辑, 可是用户 B 最先编辑完成提交, 这一过程用户 A 却不知道. 当 A 提交他改完的内容时, A, B 之间的并行修改引发了冲突.")]),s._v(" "),t("p",[s._v("Web 服务是怎么解决这种冲突的呢? 它并没有限制用户先拿到锁后才能编辑文档, 这既因为冲突的概率非常低, 也因为加解锁的代价很高. Web 中的方案是这样的: "),t("strong",[s._v("让用户先改着, 但需要浏览器记录下修改前的文档版本号, 这通过下载文档时, 返回的 HTTP ETag 头部实现")]),s._v(".")]),s._v(" "),t("p",[s._v("当用户提交修改时, 浏览器在请求中通过 HTTP If-Match 头部携带原版本号, 服务器将它与文档的当前版本号比较, "),t("strong",[s._v("一致后新的修改才能生效, 否则提交失败")]),s._v(". 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/14d180ca51b96d9e0966a6983b671610-20230731165330-psym8da.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("乐观锁除了应用在 Web 分布式场景, 在数据库等单机上也有广泛的应用")]),s._v(". 只是面向多线程时, 最后的验证步骤是通过 CPU 提供的 CAS 操作完成的.")]),s._v(" "),t("p",[s._v("乐观锁虽然去除了锁操作, 但是一旦发生冲突, 重试的成本非常高. 所以, "),t("mark",[t("strong",[s._v("只有在冲突概率非常低, 且加锁成本较高时, 才考虑使用乐观锁")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("h5",{attrs:{id:"_4-小结-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-3"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节介绍了高并发下同步资源时, 如何根据应用场景选择合适的锁, 来优化服务的性能.")]),s._v(" "),t("p",[s._v("互斥锁能够满足各类功能性要求, 特别是被锁住的代码执行时间不可控时, 它通过内核执行线程切换及时释放了资源, 但它的性能消耗最大. 需要注意的是, 协程的互斥锁实现原理完全不同, 它并不与内核打交道, 虽然不能跨线程工作, 但效率很高.")]),s._v(" "),t("p",[t("strong",[s._v("如果能够确定被锁住的代码取到锁后很快就能释放, 应该使用更高效的自旋锁, 它特别适合基于异步编程实现的高并发服务.")])]),s._v(" "),t("p",[s._v("如果能区分出读写操作, 读写锁就是第一选择, 它允许多个读线程同时持有读锁, 提高了并发性. 读写锁是有倾向性的, 读优先锁很高效, 但容易让写线程饿死, 而写优先锁会优先服务写线程, 但对读线程亲和性差一些. 还有一种公平读写锁, 它通过把等待锁的线程排队, 以略微牺牲性能的方式, 保证了某种线程不会饿死, 通用性更佳.")]),s._v(" "),t("p",[s._v("另外, 读写锁既可以使用互斥锁实现, 也可以使用自旋锁实现, 应根据场景来选择合适的实现.")]),s._v(" "),t("p",[s._v("当并发访问共享资源, "),t("strong",[s._v("冲突概率非常低的时候, 可以选择无锁编程")]),s._v(". 它在 Web 和数据库中有广泛的应用. 然而, 一旦冲突概率上升, 就不适合使用它, 因为它解决冲突的重试成本非常高.")]),s._v(" "),t("p",[s._v("总之, 不管使用哪种锁, "),t("strong",[s._v("锁范围内的代码都应尽量的少, 执行速度要快")]),s._v(". 在此之上, 选择更合适的锁能够大幅提升高并发服务的性能!")]),s._v(" "),t("h3",{attrs:{id:"系统层网络优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#系统层网络优化"}},[s._v("#")]),s._v(" 系统层网络优化")]),s._v(" "),t("h4",{attrs:{id:"_07-性能好-效率高的一对多通讯该如何实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_07-性能好-效率高的一对多通讯该如何实现"}},[s._v("#")]),s._v(" 07-性能好,效率高的一对多通讯该如何实现?")]),s._v(" "),t("p",[s._v("从这一讲开始, 将从单机进入网络层面的性能优化.")]),s._v(" "),t("p",[s._v("我们接触过的绝大多数通讯方式, 无论是面向连接的 HTTP 协议, 还是无连接的 DNS 协议, 都是一对一收发消息的. 其实, 除了一对一, 还有"),t("strong",[s._v("一对多的通讯方式")]),s._v(", 它在网络资源的利用上效率要比一对一高得多. 这种一对多的通讯方式, 在局域网中有很广泛的应用, 常见的 ARP 欺骗, 泛洪攻击等, 都是通过一对多通讯进行的.")]),s._v(" "),t("p",[s._v("当应用场景中用一对多代替一对一通讯时, 发送方性能会获得很大的提升, 整个局域网的效率也会提高. 比如, 源主机的带宽只有 1Gbps, 如果采用一对一的方式向 100 个客户端发送流媒体, 这 100 台主机的带宽之和不会超过 1Gbps. 但采用一对多传输时, 总带宽就可以达到 100Gbps.")]),s._v(" "),t("p",[s._v("除了能提升性能以外, 由于一对多通讯可同时向所有主机发送消息, 这就在功能层面上可以替换许多人工操作. 比如分布式系统的服务发现, 使用人工配置既容易出错, 速度也慢, 而用广播就可以轻松实现自动化服务发现.")]),s._v(" "),t("p",[s._v("一对多通讯协议一直在发展, 在运营商的 IPTV 网络的视频直播中, 它就得到了广泛的应用. 即使你暂时不会用到一对多这种方式, 也应当了解下它是怎么工作的, 熟悉它的工作原理后, 还能更深入地理解一对一通讯协议.")]),s._v(" "),t("p",[s._v("本节就来学习"),t("strong",[s._v("如何实现一对多通讯")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-广播是怎么实现的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-广播是怎么实现的"}},[s._v("#")]),s._v(" 1.广播是怎么实现的?")]),s._v(" "),t("p",[s._v("一对多通讯分为两种: 对局域网内"),t("strong",[s._v("所有主机")]),s._v("发送消息的叫做"),t("strong",[s._v("广播")]),s._v(", 而对"),t("strong",[s._v("部分主机")]),s._v("发送消息的, 则叫做"),t("strong",[s._v("组播")]),s._v(". 先来看一下广播是怎么实现的.")]),s._v(" "),t("p",[t("strong",[s._v("使用广播要改用 UDP 协议")]),s._v(". 可能你会问, 为什么不能使用最熟悉的 TCP 协议呢? 这要从 TCP 协议的分层说起.")]),s._v(" "),t("p",[s._v("1978 年在 TCP 协议迭代了 3 个版本后, 才被 Jon Postel(IANA 创始人)提出违反了网络分层原则, 网络层和传输层耦合在一起很难扩展. 于是在 TCP 的第 4 个迭代版本中把协议一分为二, 包括网络层 IP 协议和传输层 TCP 协议(这也是今天的 IP 协议被称为 IPv4 的原因).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8d4368aaa36f8c821973fa7975a2e51a-20230731165330-3cdue97.png",alt:""}})]),s._v(" "),t("p",[s._v("当访问 Internet 站点时, IP 协议会将数据通过网络设备穿越多个卫星, 光纤等网络, 才能送到服务器. 而网络设备天然就拥有广播能力, 当它在一个网络端口上收到主机发来的报文时, 可以向其他端口上的所有主机重发一遍, 这就是广播, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a994c5552b8f5d4b0bd2cbb2a06b094b-20230731165330-4o8h0dz.png",alt:""}})]),s._v(" "),t("p",[s._v("**虽然 IP 协议已经具有广播功能, 但实际编程中并不会直接使用 IP 协议发送广播, 因为它很难与进程关联起来. **")]),s._v(" "),t("p",[s._v("根据网络分层模型, 上层协议可以使用下层协议的功能, 所以传输层协议拥有 IP 协议的广播能力. 同时, 传输层通过端口号把网络报文和进程关联在了一起, 就像 TCP 的 80 端口, 把 HTTP 消息与 Nginx 等 Web Server 关联在一起.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/77b4fdc642207fb69f196bcb4b18b20a-20230731165330-i4xvfa3.png",alt:""}})]),s._v(" "),t("p",[s._v("然而, "),t("strong",[s._v("传输层的 TCP 协议为了保证可靠性, 建立了逻辑上的连接概念, 由于一个连接上只能有两方, 所以 TCP 无法进行一对多通讯. 而传输层的 UDP 协议无需建立连接, 所以常用 UDP 协议发送广播")]),s._v(".")]),s._v(" "),t("p",[s._v("广播的性能高有两个原因: 首先, 交换机直接转发给接收方, 要比从发送方到接收方的传输路径更短. 其次, 原本需要发送方"),t("strong",[s._v("复制多份报文")]),s._v("再逐一发送至各个接受者的工作, "),t("strong",[s._v("被交换机完成了")]),s._v(", 这既分担了发送方的负载, 也充分使用了整个网络的带宽.")]),s._v(" "),t("p",[s._v("那么, 交换机收到消息后, "),t("strong",[s._v("怎么知道这是广播报文并转发给整个网络")]),s._v("呢? 我们知道, 以太网中的数据链路层, 通过硬件的 MAC 地址来传播消息, 交换机就通过报文的 MAC 地址来确定是否需要广播. "),t("mark",[t("strong",[s._v("当交换机收到目标 MAC 地址是 ff:ff:ff:ff:ff:ff 的报文时, 便知道这是一个广播报文")])]),s._v("​ "),t("strong",[s._v(",")]),s._v("  才会将它转发给局域网中的"),t("strong",[s._v("所有主机")]),s._v(", 否则只会转发给 MAC 地址对应端口上的主机.")]),s._v(" "),t("p",[s._v("不过, 日常写代码时无法控制底层的 MAC 地址, 只能填写目标 IP 地址. 什么样的目标 IP 地址, 会生成广播 MAC 地址呢? "),t("strong",[s._v("如果只是对所在子网进行广播, 那么使用受限广播地址")]),s._v(" "),t("mark",[t("strong",[s._v("255.255.255.255")])]),s._v(" "),t("strong",[s._v("就可以了; 如果局域网划分了多个子网, 主机需要向其他子网广播, 则需要正确地设置直接广播地址(路由器需要打开直接广播功能).")])]),s._v(" "),t("h5",{attrs:{id:"_2-如何正确地设置直接广播ip地址"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何正确地设置直接广播ip地址"}},[s._v("#")]),s._v(" 2.如何正确地设置直接广播IP地址?")]),s._v(" "),t("p",[s._v("怎么设置直接广播的 IP 地址呢? 首先得了解 IP 地址的构成.")]),s._v(" "),t("p",[s._v("由于 IP 协议需要跨越多个网络工作, 所以 IP 地址被一分为二, 包括前边的网络 ID 和后边的主机 ID, 其中, **网络 ID 用于不同网络间的寻址, 而主机 ID 则用于在本地局域网内通讯. **")]),s._v(" "),t("p",[s._v("举个例子, 如果局域网 IP 地址是 192.168.0.101, 那么网络 ID 就是 192.168.0, 而主机 ID 则是 101(这里假定网络管理员没有继续划分 C 类子网).")]),s._v(" "),t("p",[s._v("这是因为, 以 192.168 打头的 IP 地址, 被称为 C 类地址, 而 C 类地址中, 最后 1 个十进制数字代表主机 ID. 如果 IP 地址是 172.16.20.227, 这就是 B 类地址, 此时 172.16 是网络 ID, 而 20.227 才是主机 ID.")]),s._v(" "),t("p",[s._v("所以, "),t("strong",[s._v("IP 地址的前缀数字不同, 主机 ID 的划分位置也不同")]),s._v(". 事实上, IP 地址一共被划分为 A, B, C, D, E, 5 个类别, 它的划分依据正是 IP 地址转换为二进制后, 用前 4 个比特位作为依据的. 如果第 1 个比特位为 0, 这就是 A 类地址, 它的网络 ID 是 IP 地址的第 1 到第 8 比特位, 而主机 ID 则是随后的 24 个比特位. 如果局域网 IP 地址第 1 个数字是 10, 这就是 A 类私有地址(局域网中的地址不能在公网中使用, 统称为私有地址或者内网地址).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f03cd911a1979d231c586270515a4e05-20230731165330-3r333mm.png",alt:""}})]),s._v(" "),t("p",[s._v("类似的, 若前 2 个比特位是 10, 则是 B 类地址, 它的主机 ID 是后 16 位; 如果前 3 个比特位为 110, 这就是 C 类地址, 它的主机 ID 是后 8 位. 显然, 以 192 打头的地址, 前 3 位正是 110, 所以这是 C 类地址.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c8db7e8bcc5e023c15235aad81e78b78-20230731165330-ocr7tr8.png",alt:""}})]),s._v(" "),t("p",[s._v("此外还有 D 类组播地址和 E 类预留实验地址.")]),s._v(" "),t("p",[s._v("清楚了划分方法后, 再来看"),t("strong",[s._v("如何通过修改主机 ID 将 IP 地址改为直接广播地址")]),s._v(". 如果观察 IP 地址, 会发现主机 ID 不会出现全 0 和全 1 这两种情况, 这是因为全 0 和全 1 有特殊用途, 其中全 0 特指它自己(所以 0.0.0.0 可以指代本机 IP), 而全 1 表示全部主机.")]),s._v(" "),t("p",[t("strong",[s._v("所以,")]),s._v(" "),t("mark",[t("strong",[s._v("主机 ID 的比特位全部设为 1 后就是广播地址")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  比如, 192.168.0.101 是 C 类地址, 把主机 ID 从 101 改为 255 后, 就可以用 192.168.0.255 发送广播了.")]),s._v(" "),t("p",[s._v("然而, 事情到这并没有完. 一个 A 类网络可以容纳千万台主机, B 类网络则只能容纳 6 万多台主机, C 类网络则最多容纳 254 台主机. 仅有的三类网络中主机数量差距太大, 而世界上存在各种规模的企业, 它们所需网络中的主机规模千差万别, 上述划分方式太过单一, 无法满足各类企业的需求, **于是诞生了 CIDR 这种新的划分方式, 它通过子网掩码(或者叫 Netmask), 可以在任意的位置将 IP 地址拆分为网络 ID 和主机 ID, 扩展了 A, B, C 三类网络的用法. **")]),s._v(" "),t("p",[s._v("当查看主机的 IP 地址时, 就会看到其后跟着一个"),t("strong",[s._v("类似 IP 地址的子网掩码")]),s._v(". 子网掩码必须把它展开成二进制才能使用, 这样掩码前 N 位为 1 时, 就表示 IP 地址的前 N 位是网络 ID, 而掩码后面剩余的位全是 0, 表示 IP 地址对应的位是主机 ID.")]),s._v(" "),t("p",[s._v("比如, 若 192.168.0.101 的子网掩码是 255.255.255.192, 就表示 IP 地址的前 26 位是网络 ID, 后 6 位是主机 ID, 将主机 ID 置为全 1 后, 就得到了它的广播地址 192.168.0.127, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/cff908a329012f9f8fa6511bae6148db-20230731165330-5umnnsb.png",alt:""}})]),s._v(" "),t("p",[s._v("到这里, 设置好 IP 地址后, 再把 socket 句柄设置 SO_BROADCAST 属性, 就可以发送广播了. 广播虽然有很多优点, 可是一旦被滥用, 很容易产生网络风暴, 所以"),t("strong",[s._v("路由器默认是不转发广播报文")]),s._v("的.")]),s._v(" "),t("h5",{attrs:{id:"_3-用更精准的组播来做服务发现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-用更精准的组播来做服务发现"}},[s._v("#")]),s._v(" 3.用更精准的组播来做服务发现")]),s._v(" "),t("p",[s._v("当用 UDP 广播来做分布式系统的服务发现, 会遇到这样一个问题: 若并非网络内的所有主机都属于分布式系统, 那么, 当指定了端口的 UDP 广播报文到达其他主机时, 会怎么样呢? 这些广播报文在这 3 个步骤后会被丢弃:")]),s._v(" "),t("ol",[t("li",[s._v("第 1 步, 网卡设备收到报文后, 查看报文中的目标 MAC 地址是否与本机的 MAC 地址匹配, 如果不匹配就会丢弃. 广播 MAC 地址默认匹配, 继续交由上层的 IP 协议栈处理;")]),s._v(" "),t("li",[s._v("第 2 步, IP 协议栈查看目标 IP 地址是否为本机 IP 地址, 不匹配也会丢弃报文. 上文介绍过的广播 IP 地址同样默认匹配, 交由传输层协议继续处理.")]),s._v(" "),t("li",[s._v("第 3 步, 传输层检查目标端口是否有进程在监听, 如果没有则丢弃报文, 反之则交付给进程处理. 不属于集群的主机自然不会启动服务监听端口, 在这一步才会丢弃广播报文.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ab46f68e3f720ce9677c49e10b859e1d-20230731165330-ixvg7zi.png",alt:""}})]),s._v(" "),t("p",[s._v("可见, 对于不属于分布式集群的主机而言, 广播报文既占用了它们的带宽, 这 3 步协议栈的操作也消耗了 CPU 的计算力. 有什么办法能缩小广播的范围, 消除它加在无关主机上的负载呢?")]),s._v(" "),t("p",[s._v('组播可以做到. 组播是一种 "'),t("strong",[s._v("定向广播")]),s._v('", 它设定了一个虚拟组, 用组播 IP 来标识. 这个虚拟组中可以包含多个主机的 IP, 当向对应的组播 IP 发送消息时, '),t("strong",[s._v("仅在这个组内的主机才能收到消息")]),s._v(".")]),s._v(" "),t("p",[s._v("组播 IP 与常见的单播 IP 不同, 它是前文介绍过 5 类 IP 地址中的 "),t("strong",[s._v("D 类地址")]),s._v(", 32 位 IP 地址的前 4 位必须是 1110, 因此"),t("strong",[s._v("组播 IP 地址的范围是从 224.0.0.0 到 239.255.255.255")]),s._v(".")]),s._v(" "),t("p",[s._v("当设置好组播 IP 地址后, 还要通过管理组播地址的 IGMP 协议(Internet Group Management Protocol), 将主机 IP 地址添加进虚拟组中. 编程语言提供的 setsockopt 函数, 就可以操作 IGMP 协议管理组播地址. 比如, 使用参数 IP_ADD_MEMBERSHIP 就能够向虚拟组中增加 IP, 而 IP_DROP_MEMBERSHIP 则可以从组中去除某个主机的 IP.")]),s._v(" "),t("p",[s._v("组播相对于广播而言 , 除了能够更精准的管理组播范围, 还能够跨越多个网络工作. 当然, 如果将多个网络中的 IP 加入同一虚拟组时, 需要涉及到的路由器都可以正确地处理这些 IP 地址, 且都能支持 IGMP 协议.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-4"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-4"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("由于一对多通讯能够充分利用整体网络的性能, 而且通过交换机能够同时向许多主机发送消息, 所以在局域网内有广泛的应用. 在 TCP 协议分层后, IP 协议天然就支持一对多通讯方式. TCP 协议面向连接的特性使它放弃了一对多的通讯方式, 而 UDP 协议则继承了 IP 协议的这一功能. 所以, "),t("strong",[s._v("在一对多通讯场景中, 一般会选择 UDP 协议")]),s._v(".")]),s._v(" "),t("p",[s._v("正确输入广播地址的前提, 是理解 IP 地址如何划分为网络 ID 和主机 ID. 当主机 ID 所有的比特位改为全 1 时, IP 地址就表示该网络下的所有主机, 这就是广播地址. 当向广播地址发送 UDP 消息时, 网络中的所有主机都会收到. 广播在局域网中有广泛的应用, 转换 IP 地址与 MAC 地址的 ARP 协议就是用广播实现的.")]),s._v(" "),t("p",[t("strong",[s._v('广播对无关的主机增加了不必要的负担, 而组播可以更精准地 "定向" 广播. 组播地址也被称为 D 类地址, 它描述的虚拟组要通过 IGMP 协议管理')]),s._v(". 网络 API 中的 setsockopt 函数可以通过 IGMP 协议, 向虚拟组中添加或者删除 IP 地址. 当路由器支持 IGMP 协议时, 组播就可以跨越多个网络实现更广泛的一对多通讯.")]),s._v(" "),t("p",[s._v("广播和组播能够充分地使用全网带宽, 也通过交换机等网络设备分散了发送主机的负载. 但它很难对每台接收主机提供定制化服务, 这样可靠传输就很难实现. 这使得它们在更关注及时性, 对丢包不敏感的流媒体直播中更有应用前景.")]),s._v(" "),t("h4",{attrs:{id:"_08-事件驱动-c10m是如何实现的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_08-事件驱动-c10m是如何实现的"}},[s._v("#")]),s._v(" 08-事件驱动:C10M是如何实现的?")]),s._v(" "),t("p",[s._v("上一讲介绍了"),t("strong",[s._v("广播与组播这种一对多通讯方式")]),s._v(", 从这一讲开始, 回到主流的"),t("strong",[s._v("一对一通讯")]),s._v("方式.")]),s._v(" "),t("p",[s._v("早些年谈到高并发, 总是会提到 C10K, 这是指服务器同时处理 1 万个 TCP 连接. 随着服务器性能的提升, 近来我们更希望单台服务器的并发能力可以达到 C10M, 也就是同时可以处理 1 千万个 TCP 连接. 从 C10K 到 C10M, 实现技术并没有本质变化, 都是用事件驱动和异步开发实现的. 前面介绍过的协程, 也是依赖这二者实现高并发的.")]),s._v(" "),t("p",[s._v("做过异步开发的同学都知道, 处理基于 TCP 的应用层协议时, "),t("strong",[s._v("一个请求的处理代码必须被拆分到多个回调函数中, 由异步框架在相应的事件生成时调用它们. 这就是事件驱动方式, 它通过减少上下文切换次数")]),s._v(", 实现了 C10M 级别的高并发.")]),s._v(" "),t("p",[s._v('不过, 做应用开发的同学往往不清楚什么叫做 "事件", 不了解处理 HTTP 请求的回调函数与事件间的关系. 这样, 在高并发下, 当多个 HTTP 请求争抢执行时, 涉及资源分配, 释放等重要工作的回调函数, 就可能在错误的时间被调用, 进而引发一系列问题. 比如, 不同的回调函数对应不同的事件, 如果某个函数执行时间过长, 就会影响其他请求, 可能导致大量请求出现超时而处理失败.')]),s._v(" "),t("p",[s._v("这一讲就来介绍一下, "),t("strong",[s._v("事件是怎样产生的? 它是如何驱动请求执行的? 多路复用技术是怎样协助实现异步开发的? 理解了这些, 也就明白了这种事件驱动的解决方案, 知道了怎么样实现 C10M")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-事件是怎么产生的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-事件是怎么产生的"}},[s._v("#")]),s._v(" 1.事件是怎么产生的?")]),s._v(" "),t("p",[s._v('要了解"事件驱动"的运作机制, 首先就要搞清楚到底'),t("strong",[s._v("什么是事件")]),s._v(". 这就需要对网络原理有深入的理解了.")]),s._v(" "),t("p",[s._v("简单来说, "),t("strong",[s._v("从网络中接收到一个报文, 就可能产生一个事件")]),s._v(". 如上一讲介绍过的 UDP 请求就是最简单的例子, 一个 UDP 请求通常仅由一个网络报文组成, 所以"),t("strong",[s._v("当收到一个 UDP 报文, 就意味着收到一个请求, 它会生成一个事件, 进而触发回调函数执行")]),s._v(".")]),s._v(" "),t("p",[s._v("不过, 常见的 HTTP 等协议都是基于 TCP 实现的. 由于 TCP 是一种面向字节流的协议, HTTP 请求的大小并不受限制, 当一个 HTTP 请求的大小超过 TCP 报文的最大长度时, 请求会被拆分到多个报文中运输, 在接收端的缓冲区中重组, 排序. 因此, 并不是每个到达的 TCP 报文都能生成事件的.")]),s._v(" "),t("p",[s._v("如果不理解事件和 TCP 报文的关系, 就没法准确地掌握处理 HTTP 请求的函数何时被调用. 当然, 作为应用开发工程师, 无须在意实现细节, 只要"),t("strong",[s._v("了解 TCP 连接建立, 关闭, 以及消息的发送和接收")]),s._v("这四个场景中, 报文与事件间的关系就可以了.")]),s._v(" "),t("p",[s._v("事件并没有想象中那么复杂, 它只有两种类型: "),t("strong",[s._v("读事件与写事件")]),s._v(", 其中, 读事件表示有到达的消息需要处理, 而写事件表示可以发送消息(TCP 连接的写缓冲区中有可用空间). 先从"),t("strong",[s._v("三次握手建立连接")]),s._v("说起, 这一过程会产生"),t("strong",[s._v("一读, 一写")]),s._v("两个事件.")]),s._v(" "),t("p",[s._v("由于 TCP 允许双向传输, 所以**建立连接时, 会依次在连接的两个方向上建立通道. **主动发起连接的一方叫做客户端, 被动监听端口等待连接的一方叫做服务器.")]),s._v(" "),t("p",[s._v("客户端首先发送 SYN 报文给服务器, 而服务器收到后回复 ACK 和 SYN(这里只需要知道产生事件的过程即可, 下一讲会详细介绍这两个报文的含义), "),t("strong",[s._v("当它们到达客户端时, 双向连接中由客户端到服务器的通道就建立好了, 此时客户端就已经可以发送请求了, 因此客户端会产生写事件.")]),s._v("  接着, "),t("strong",[s._v("客户端发送 ACK 报文, 到达服务器后, 服务器上会产生读事件")]),s._v(", 因为进程原本在监听 80 等端口, 此时有新连接建立成功, 应当调用 accept 函数读取这个连接, 所以这是一个读事件.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/31563582042ef6491f9e7f08605630e8-20230731165330-gj2i7xt.png",alt:""}})]),s._v(" "),t("p",[s._v("在建立好的 TCP 连接上收发消息时, 读事件对应着接收到对方的消息, 这很好理解. 写事件则稍微复杂些, 举个例子加以说明. 假设要发送一个 2MB 的请求, "),t("strong",[s._v("当调用 write 函数发送时, 会先把内存中的数据拷贝到写缓冲区中后, 再发送到网卡上.")])]),s._v(" "),t("p",[s._v("为何要多此一举呢? 这是"),t("strong",[s._v("因为在对方没有明确表示收到前, TCP 会通过定时器重发写缓冲区中的数据, 保证消息能够到达对方")]),s._v(". 写缓冲区是有大小限制的, 后面会详细介绍. 这里假设写缓冲区只有 1MB, 所以调用 write 发送 2MB 数据时, write 函数的返回值只有 1MB, 表示写缓冲区已用尽. 当收到对方发来的 ACK 报文后, 缓冲区中的数据才能释放, 就会产生写事件通知进程发送剩余的那 1MB 数据.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/40347c487fdd17886ae7af442b5e2c3a-20230731165330-ited2y9.png",alt:""}})]),s._v(" "),t("p",[s._v("如同建立连接需要双向建立一样, "),t("strong",[s._v("关闭连接也需要双方各自关闭每个方向的通道")]),s._v(". 主动关闭的一方发送 FIN 报文, 到达被动方后, 内核自动回复 ACK 报文, 这表示从主动方到被动方的通道已经关闭. "),t("strong",[s._v("但被动方到主动方的通道也需要关闭, 所以此时被动方会产生读事件, 提醒被动方调用 close 函数关闭连接.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3267a32616de507da3843edc3f46406a-20230731165330-sa8fjm8.png",alt:""}})]),s._v(" "),t("p",[s._v("这样就清楚了 TCP 报文如何产生事件, 也明白回调函数何时执行了. 然而, 同步代码拆分成多个异步函数成本并不低, 咱们手里拿着事件驱动这个锤子, 可不能看到什么都像是钉子.")]),s._v(" "),t("p",[s._v("什么样的代码值得基于事件来做拆分呢? 还得回到"),t("strong",[s._v("高性能")]),s._v("这个最终目标上来. "),t("strong",[s._v("做性能优化一定要找出性能瓶颈, 针对瓶颈做优化性价比才最高")]),s._v(". 对于服务器来说, "),t("strong",[s._v("对最慢的操作做异步化改造, 才能值回开发效率的损失. 而服务里对资源的操作速度由快到慢, 依次是 CPU, 内存, 磁盘和网络")]),s._v(". CPU 和内存的执行速度都是纳秒级的, 无须考虑事件驱动, 而磁盘和网络都可以采用事件驱动的异步方式处理.")]),s._v(" "),t("p",[s._v("相对而言, 网络不只速度慢, 而且波动很大, 既受制于连接对端的性能, 也受制于网络传输路径. 把"),t("strong",[s._v("操作网络的同步 API 改为事件驱动的异步 API 收益最大")]),s._v(". 而磁盘(特别是机械硬盘)访问速度虽然不快, 但它最慢时也不过几十毫秒, 是可控的. 而且目前磁盘异步 IO 技术还不成熟, 它绕过了 PageCache 性能损失很大. 所以当下的事件驱动, 主要就是指网络事件.")]),s._v(" "),t("h5",{attrs:{id:"_2-该怎样处理网络事件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-该怎样处理网络事件"}},[s._v("#")]),s._v(" 2.该怎样处理网络事件?")]),s._v(" "),t("p",[s._v("有了网络事件的概念后, 再来看"),t("strong",[s._v("用户态代码如何处理事件")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("网络事件是由内核产生的, 进程该怎样获取到它们呢")]),s._v("? 如 epoll 这样的多路复用技术可以帮我们做到. 多路复用是通讯领域的词汇, 有些抽象但原理确很简单.")]),s._v(" "),t("p",[s._v("比如, 一条高速的光纤上, 允许多个用户用较低的网速同时通讯, 这就是多路复用. 同样道理, 一个进程虽然任一时刻只能处理一个请求, 但处理每个请求产生的事件时, 若耗时控制在 1 毫秒以内, 这样 1 秒钟就可以处理数千个请求, 从更长的时间维度上看, "),t("strong",[s._v("多个请求复用了一个进程, 也叫做多路复用(或者叫做")]),s._v("​"),t("mark",[t("strong",[s._v("时分多路复用")])]),s._v("​ "),t("strong",[s._v(")")]),s._v(" . 大家熟知的 epoll, 就是内核提供给用户态的多路复用接口, 进程可以通过它从内核中获取事件.")]),s._v(" "),t("p",[s._v("epoll 是如何获取网络事件的呢? 最简单的方法, "),t("strong",[s._v("就是在获取事件时, 把所有并发连接传给内核, 再由内核返回产生了事件的连接, 再处理这些连接对应的请求即可. epoll 前的 select 等多路复用函数就是这么干的")]),s._v(".")]),s._v(" "),t("p",[s._v("然而, C10M 意味着有一千万个连接, 若每个 socket 是 4 字节, 那么 1 千万连接就是 40M 字节. 这样, 每收集一次事件, 就需要从用户态复制 40M 字节到内核态. 而且高性能 Server 必须及时地处理网络事件, 所以每隔几十毫秒就要收集一次事件, 性能消耗巨大.")]),s._v(" "),t("p",[t("strong",[s._v("epoll 为了降低性能消耗, 把获取事件拆分成两步")]),s._v(".")]),s._v(" "),t("ol",[t("li",[s._v("第一步把"),t("strong",[s._v("需要监控的 socket 传给内核(epoll_ctl 函数)")]),s._v(" , 它仅在连接建立等有限的时机调用;")]),s._v(" "),t("li",[s._v("第二步"),t("strong",[s._v("收集事件(epoll_wait 函数)便不用传递 socket 了, 这样就把 socket 的重复传递改为了一次传递, 降低了性能损耗")]),s._v(".")])]),s._v(" "),t("p",[s._v("由于网卡的处理能力有限, 千兆网卡下, 每秒只能接收 100MB 左右的数据, 如果每个请求约 10KB, 那么每秒大概有 1 万个请求到达, 10 万个事件需要处理. 这样即使每隔 100 毫秒收集一次事件(调用 epoll_wait), 每次也不过只有 1 万个事件(100000 Event/s * 0.1s = 10000 Event/s)需要处理, 只要保证处理一个事件的平均时间小于 10 微秒(多核处理器可以做到), 100 毫秒内就可以处理完这些事件(100ms = 10us * 10000).  因此, 哪怕有 1 千万并发连接, 也能保证 1 万 RPS 的处理能力, 这就是 epoll 能在 C10M 下实现高吞吐量的原因.")]),s._v(" "),t("p",[t("strong",[s._v("进程获取到产生事件的 socket 后, 又该如何处理它呢? 这里的核心约束是, 处理任何一个事件的耗时都应该是微秒级或者毫秒级, 否则就会延误其他事件的处理, 不只降低了用户的体验, 而且会形成恶性循环")]),s._v(".")]),s._v(" "),t("p",[s._v("为了应对网络的不确定性, 每个参与网络通讯的进程都会为请求设置超时时间. 一旦某个 socket 上的事件迟迟不被处理, 当客户端的超时定时器触发时, 客户端往往会关闭连接并重发请求, 这会让服务器雪上加霜.")]),s._v(" "),t("p",[s._v("怎样保证处理一个事件的时间不会太长呢? 可以把"),t("strong",[s._v("处理事件的代码分为三类")]),s._v("来看.")]),s._v(" "),t("p",[s._v("第一类是"),t("strong",[s._v("计算任务")]),s._v(", 虽然内存, CPU 的速度很快, 然而循环执行也可能耗时达到秒级. 所以, 如果一定要引入需要密集计算才能完成的请求, 为了不阻碍其他事件的处理, 要么把这样的请求放在"),t("strong",[s._v("独立的线程中")]),s._v("完成, 要么把请求的处理过程拆分成多段, 确保每段能够快速执行完, 同时每段执行完都要均等地处理其他事件, 这样通过放慢该请求的处理时间, 就保障了其他请求的及时处理.")]),s._v(" "),t("p",[s._v("第二类会"),t("strong",[s._v("读写磁盘")]),s._v(", 由于磁盘的写入操作使用了 PageCache 的延迟写特性, 当 write 函数返回时只是复制到了内存中, 所以写入操作很快. 磁盘的读取操作就比较慢了, 这时通常要把大文件的读取, 拆分成许多份, 每份仅有几十 KB, 降低单次操作的耗时.")]),s._v(" "),t("p",[s._v("第三类是"),t("strong",[s._v("通过网络访问上游服务")]),s._v(". 与处理客户端请求相似, 必须使用非阻塞 socket, 用事件驱动方式处理请求. 需要注意的是, 许多网络服务提供的 SDK, 都是基于阻塞 socket 实现的, 使用前必须先做完非阻塞改造. 比如 Memcached 的官方 SDK 是用阻塞 socket 实现的, Nginx 如果直接使用该 SDK 访问它, 性能就会一落千丈. 正确的访问方式, 是使用第三方提供的 ngx_http_memcached_module 模块, 它用非阻塞 socket 重新封装了 SDK.")]),s._v(" "),t("p",[s._v("总之, "),t("strong",[s._v("网络报文到达后, 内核就产生了读, 写事件, 而 epoll 函数使得进程可以高效地收集到这些事件")]),s._v(". 接下来, 要确保在进程中处理每个事件的时间足够短, 才能及时地处理所有请求, 这个过程中既要"),t("strong",[s._v("避免阻塞 socket 的使用")]),s._v(", 也要把耗时过长的操作拆成多份执行. 最终, 通过快速, 及时, 均等地执行所有事件, 异步 Server 实现了高并发.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-2"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("最后对这一讲做个小结. 异步服务改为从事件层面处理请求, 在 epoll 这样的多路复用机制协助下, 最终实现了 C10M 级别的高并发服务.")]),s._v(" "),t("p",[s._v("事件有很多种, 网络消息的传输既慢又不可控, 所以用网络事件驱动请求的性价比最高. 这样就需要了解 TCP 报文是如何产生事件的.")]),s._v(" "),t("p",[s._v("TCP 连接建立时, 会在客户端产生写事件, 在服务器端产生读事件. 连接关闭时, 则会在被动关闭端产生读事件. 在连接上收发消息时, 也会产生事件, 其中发送消息前的写事件与内核分配的缓冲区有关.")]),s._v(" "),t("p",[s._v("清楚了事件与 TCP 报文的关系后, 可以"),t("strong",[s._v("用多路复用技术获取事件")]),s._v(", 其中 epoll 是佼佼者, 它取消了收集事件时重复传递的大量 socket 参数, 给 C10M 的实现提供了基础.")]),s._v(" "),t("p",[s._v("需要注意的是, "),t("strong",[s._v("处理 epoll 收集到的事件时, 必须保证处理一个事件的平均时间在毫秒级以内")]),s._v(". 传统的阻塞 socket 是做不到的, 所以必须用非阻塞 socket 替换阻塞 socket. 如果事件的回调函数耗时过长, 也得拆分为多个耗时短的函数, 用多次事件(比如定时器事件)的触发来替代.")]),s._v(" "),t("p",[s._v("虽然有了上述的事件驱动方案, 但实现 C10M 还需要更谨慎地使用不过数百 GB 的服务器内存. 关于"),t("strong",[s._v("如何降低内存的消耗")]),s._v(", 可以关注前面提到的内存池, 后面还会介绍如何减少连接缓冲区的空间占用.")]),s._v(" "),t("p",[s._v("这一讲介绍了事件驱动的总体方案, 但 C10M 需要高效的用心几乎所有服务器资源, 所以还得通过 Linux 更精细地"),t("strong",[s._v("控制 TCP 的行为")]),s._v(", 接下来的 3 讲将"),t("strong",[s._v("深入 Linux, 讨论如何优化 TCP 的性能")]),s._v(".")]),s._v(" "),t("h4",{attrs:{id:"_09-如何提升tcp三次握手的性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_09-如何提升tcp三次握手的性能"}},[s._v("#")]),s._v(" 09-如何提升TCP三次握手的性能?")]),s._v(" "),t("p",[s._v("上一讲提到 TCP 在三次握手建立连接, 四次握手关闭连接时是怎样产生事件的, 这两个过程中 TCP 连接经历了复杂的状态变化, 既容易导致编程出错, 也有很大的优化空间. 这一讲来看看"),t("strong",[s._v("在 Linux 操作系统下, 如何优化 TCP 的三次握手流程, 提升握手速度")]),s._v(".")]),s._v(" "),t("p",[s._v("TCP 是一个可以双向传输的全双工协议, 所以需要经过三次握手才能建立连接. "),t("strong",[s._v("三次握手在一个 HTTP 请求中的平均时间占比在 10% 以上, 在网络状况不佳, 高并发或者遭遇 SYN 泛洪攻击等场景中, 如果不能正确地调整三次握手中的参数, 就会对性能有很大的影响")]),s._v(".")]),s._v(" "),t("p",[s._v("TCP 协议是由操作系统实现的, 调整 TCP 必须通过操作系统提供的接口和工具, 这就需要理解 Linux 是怎样把三次握手中的状态暴露给我们, 以及通过哪些工具可以找到优化依据, 并通过哪些接口修改参数.")]),s._v(" "),t("p",[s._v("因此, 这一讲将"),t("strong",[s._v("介绍 TCP 握手过程中各状态的意义, 并以状态变化作为主线, 看看如何调整 Linux 参数才能提升握手的性能")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-客户端的优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-客户端的优化"}},[s._v("#")]),s._v(" 1.客户端的优化")]),s._v(" "),t("p",[t("strong",[s._v("客户端和服务器都可以针对三次握手优化性能")]),s._v(". 相对而言, 主动发起连接的客户端优化相对简单一些, 而服务器需要在监听端口上被动等待连接, 并保存许多握手的中间状态, 优化方法更为复杂一些. 首先来看如何优化客户端.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("三次握手建立连接的首要目的是同步序列号")])]),s._v(". 只有同步了序列号才有可靠的传输, TCP 协议的许多特性都是依赖序列号实现的, 比如流量控制, 消息丢失后的重发等等, 这也是三次握手中的报文被称为 SYN 的原因, 因为 SYN 的全称就叫做 Synchronize Sequence Numbers.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/38d384cd16c696832988c34dc5715991-20230731165330-epccr7e.png",alt:""}})]),s._v(" "),t("p",[s._v("三次握手虽然由操作系统实现, 但它通过"),t("strong",[s._v("连接状态")]),s._v("把这一过程暴露给了我们, 来细看下过程中出现的 3 种状态的意义. 客户端发送 SYN 开启了三次握手, 此时在客户端上"),t("strong",[s._v("用 netstat 命令")]),s._v("(后续查看连接状态都使用该命令)可以看到"),t("strong",[s._v("连接的状态是 SYN_SENT")]),s._v("(顾名思义, 就是把刚 SYN 发送出去).")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("tcp    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("172.16")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".20")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".227")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("39198")]),s._v("     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("129.28")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".56")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".36")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("81")]),s._v("         "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("SYN_SENT")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("客户端在等待服务器回复的 ACK 报文. 正常情况下, 服务器会在几毫秒内返回 ACK, 但如果客户端迟迟没有收到 ACK 会怎么样呢? 客户端会重发 SYN, "),t("strong",[s._v("重试的次数由 tcp_syn_retries 参数控制")]),s._v(", 默认是 6 次:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_syn_retries "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("第 1 次重试发生在 1 秒钟后, 接着会以翻倍的方式在第 2, 4, 8, 16, 32 秒共做 6 次重试, 最后一次重试会等待 64 秒, 如果仍然没有返回 ACK, 才会终止三次握手. 所以, 总耗时是 1+2+4+8+16+32+64=127 秒, 超过 2 分钟.")]),s._v(" "),t("p",[s._v("如果这是一台有明确任务的服务器, 就可以根据网络的稳定性和目标服务器的繁忙程度修改重试次数, 调整客户端的三次握手时间上限. 比如内网中通讯时, 就可以适当调低重试次数, 尽快把错误暴露给应用程序.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/97baa16246ca3c860af3e3a2b53aae6c-20230731165330-hrxu70c.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_2-服务器端的优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-服务器端的优化"}},[s._v("#")]),s._v(" 2.服务器端的优化")]),s._v(" "),t("p",[s._v("当服务器收到 SYN 报文后, 服务器会立刻回复 "),t("code",[s._v("SYN+ACK")]),s._v("​ 报文, 既确认了客户端的序列号, 也把自己的序列号发给了对方. 此时, 服务器端出现了新连接, 状态是 SYN_RCV(RCV 是 received 的缩写). 这个状态下, 服务器必须建立一个 SYN 半连接队列来维护未完成的握手信息, 当这个队列溢出后, 服务器将无法再建立新连接.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b4a9a50f349614dbf2762ec63a9e026d-20230731165330-jk6zdsn.png",alt:""}})]),s._v(" "),t("p",[s._v("新连接建立失败的原因有很多, 怎样获得由于队列已满而引发的失败次数呢? "),t("code",[s._v("netstat -s")]),s._v("​ 命令给出的统计结果中可以得到.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("# netstat "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("s "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" grep "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SYNs to LISTEN"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1192450")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SYNs")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("LISTEN")]),s._v(" sockets dropped\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("这里给出的是队列溢出导致 SYN 被丢弃的个数. 注意这是一个累计值, 如果数值在持续增加, 则应该调大 SYN 半连接队列. **修改队列大小的方法, 是设置 Linux 的 tcp_max_syn_backlog 参数: **")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_max_syn_backlog "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1024")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("如果 SYN 半连接队列已满, 只能丢弃连接吗? 并不是这样, **开启 syncookies 功能就可以在不使用 SYN 队列的情况下成功建立连接. **syncookies 是这么做的: 服务器根据当前状态计算出一个值, 放在己方发出的 SYN+ACK 报文中发出, 当客户端返回 ACK 报文时, 取出该值验证, 如果合法, 就认为连接建立成功, 如下图所示.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/42f853faf175c6fcb599a72b85cd27f2-20230731165330-mg7qph6.png",alt:""}})]),s._v(" "),t("p",[s._v("Linux 下怎样开启 syncookies 功能呢? 修改 tcp_syncookies 参数即可, 其中值为 0 时表示关闭该功能, 2 表示无条件开启功能, 而 1 则表示仅当 SYN 半连接队列放不下时, 再启用它. 由于 syncookie 仅用于应对 SYN 泛洪攻击(攻击者恶意构造大量的 SYN 报文发送给服务器, 造成 SYN 半连接队列溢出, 导致正常客户端的连接无法建立), 这种方式建立的连接, 许多 TCP 特性都无法使用. 所以, "),t("strong",[s._v("应当把 tcp_syncookies 设置为 1, 仅在队列满时再启用")]),s._v(".")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_syncookies "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("当客户端接收到服务器发来的 SYN+ACK 报文后, 就会回复 ACK 去通知服务器, 同时己方连接状态从 SYN_SENT 转换为 ESTABLISHED, 表示连接建立成功. 服务器端连接成功建立的时间还要再往后, 到它收到 ACK 后状态才变为 ESTABLISHED.")]),s._v(" "),t("p",[s._v("如果服务器没有收到 ACK, 就会一直重发 SYN+ACK 报文. 当网络繁忙, 不稳定时, 报文丢失就会变严重, 此时应该调大重发次数. 反之则可以调小重发次数. **修改重发次数的方法是, 调整 tcp_synack_retries 参数: **")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_synack_retries "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("tcp_synack_retries 的默认重试次数是 5 次, 与客户端重发 SYN 类似, 它的重试会经历 1, 2, 4, 8, 16 秒, 最后一次重试后等待 32 秒, 若仍然没有收到 ACK, 才会关闭连接, 故共需要等待 63 秒.")]),s._v(" "),t("p",[s._v("服务器收到 ACK 后连接建立成功, 此时内核会把连接从 SYN 半连接队列中移出, 再移入 accept 队列, 等待进程调用 accept 函数时把连接取出来. 如果进程不能及时地调用 accept 函数, 就会造成 accept 队列溢出, 最终导致建立好的 TCP 连接被丢弃.")]),s._v(" "),t("p",[s._v("实际上, 丢弃连接只是 Linux 的默认行为, 还可以选择向客户端发送 RST 复位报文, 告诉客户端连接已经建立失败. 打开这一功能需要将 tcp_abort_on_overflow 参数设置为 1.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_abort_on_overflow "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("通常情况下, 应当把 tcp_abort_on_overflow 设置为 0, 因为这样更有利于应对突发流量.")]),s._v("  举个例子, 当 accept 队列满导致服务器丢掉了 ACK, 与此同时, 客户端的连接状态却是 ESTABLISHED, 进程就在建立好的连接上发送请求. 只要服务器没有为请求回复 ACK, 请求就会被多次重发. 如果服务器上的进程只是短暂的繁忙造成 accept 队列满, 那么当 accept 队列有空位时, 再次接收到的请求报文由于含有 ACK, 仍然会触发服务器端成功建立连接. 所以, "),t("strong",[s._v("tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率, 只有非常肯定 accept 队列会长期溢出时, 才能设置为 1 以尽快通知客户端.")])]),s._v(" "),t("p",[s._v("那么, 怎样调整 accept 队列的长度呢? **listen 函数的 backlog 参数就可以设置 accept 队列的大小. 事实上, backlog 参数还受限于 Linux 系统级的队列长度上限, 当然这个上限阈值也可以通过 somaxconn 参数修改. **")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("core"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("somaxconn "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("128")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("当下各监听端口上的 accept 队列长度可以通过 "),t("code",[s._v("ss -ltn")]),s._v("​ 命令查看, 但 accept 队列长度是否需要调整该怎么判断呢? 还是通过 netstat -s 命令给出的统计结果, 可以看到究竟有多少个连接因为队列溢出而被丢弃.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("# netstat "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("s "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" grep "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"listen queue"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" times the listen queue of a socket overflowed\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[t("strong",[s._v("如果持续不断地有连接因为 accept 队列溢出被丢弃, 就应该调大 backlog 以及 somaxconn 参数.")])]),s._v(" "),t("h5",{attrs:{id:"_3-tfo技术如何绕过三次握手"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-tfo技术如何绕过三次握手"}},[s._v("#")]),s._v(" 3.TFO技术如何绕过三次握手?")]),s._v(" "),t("p",[s._v("以上只是在对三次握手的过程进行优化. 接下来看看"),t("strong",[s._v("如何绕过三次握手发送数据")]),s._v(".")]),s._v(" "),t("p",[s._v("三次握手建立连接造成的后果就是, HTTP 请求必须在一次 RTT(Round Trip Time, 从客户端到服务器一个往返的时间)后才能发送, Google 对此做的统计显示, 三次握手消耗的时间, 在 HTTP 请求完成的时间占比在 10% 到 30% 之间.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/48439f64e2b7c051a17a303348d14f39-20230731165330-7aj5xba.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, Google 提出了 TCP fast open 方案(简称TFO), 客户端可以在首个 SYN 报文中就携带请求, 这节省了 1 个 RTT 的时间.")]),s._v(" "),t("p",[s._v("接下来就来看看, TFO 具体是怎么实现的.")]),s._v(" "),t("p",[s._v("**为了让客户端在 SYN 报文中携带请求数据, 必须解决服务器的信任问题. **因为此时服务器的 SYN 报文还没有发给客户端, 客户端是否能够正常建立连接还未可知, 但此时服务器需要假定连接已经建立成功, 并把请求交付给进程去处理, 所以服务器必须能够信任这个客户端.")]),s._v(" "),t("p",[s._v("TFO 到底怎样达成这一目的呢? 它把通讯分为两个阶段, 第一阶段为首次建立连接, 这时走正常的三次握手, 但在客户端的 SYN 报文会明确地告诉服务器它想使用 TFO 功能, 这样服务器会把客户端 IP 地址用只有自己知道的密钥加密(比如 AES 加密算法), 作为 Cookie 携带在返回的 SYN+ACK 报文中, 客户端收到后会将 Cookie 缓存在本地.")]),s._v(" "),t("p",[s._v('之后, 如果客户端再次向服务器建立连接, 就可以在第一个 SYN 报文中携带请求数据, 同时还要附带缓存的 Cookie. 很显然, 这种通讯方式下不能再采用经典的 "先 connect 再 write 请求" 这种编程方法, 而要改用 sendto 或者 sendmsg 函数才能实现.')]),s._v(" "),t("p",[s._v("服务器收到后, 会用自己的密钥验证 Cookie 是否合法, 验证通过后连接才算建立成功, 再把请求交给进程处理, 同时给客户端返回 "),t("code",[s._v("SYN+ACK")]),s._v("​. 虽然客户端收到后还会返回 ACK, 但服务器不等收到 ACK 就可以发送 HTTP 响应了, 这就减少了握手带来的 1 个 RTT 的时间消耗.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ae41db8e58953fc355ae342f35ce253c-20230731165330-r4avam7.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, 为了防止 SYN 泛洪攻击, 服务器的 TFO 实现必须能够自动化地定时更新密钥.")]),s._v(" "),t("p",[s._v("Linux 下怎么打开 TFO 功能呢? 这要通过 tcp_fastopen 参数. 由于只有客户端和服务器同时支持时, TFO 功能才能使用, "),t("strong",[s._v("所以 tcp_fastopen 参数是按比特位控制的. 其中, 第 1 个比特位为 1 时, 表示作为客户端时支持 TFO; 第 2 个比特位为 1 时, 表示作为服务器时支持 TFO")]),s._v(", 所以当 tcp_fastopen 的值为 3 时(比特为 0x11)就表示完全支持 TFO 功能.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_fastopen "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h5",{attrs:{id:"_4-小结-5"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-5"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节沿着三次握手的流程, 介绍了 Linux 系统的优化方法.")]),s._v(" "),t("p",[t("strong",[s._v("当客户端通过发送 SYN 发起握手时, 可以通过 tcp_syn_retries 控制重发次数")]),s._v(". 当服务器的 SYN 半连接队列溢出后, SYN 报文会丢失从而导致连接建立失败. 我们可以通过 netstat -s 给出的统计结果判断队列长度是否合适, 进而通过 tcp_max_syn_backlog 参数调整队列的长度. 服务器回复 SYN+ACK 报文的重试次数由 tcp_synack_retries 参数控制, 网络稳定时可以调小它. 为了应对 SYN 泛洪攻击, 应将 tcp_syncookies 参数设置为 1, 它仅在 SYN 队列满后开启 syncookie 功能, 保证连接成功建立.")]),s._v(" "),t("p",[s._v("服务器收到客户端返回的 ACK 后, 会把连接移入 accept 队列, 等待进程调用 accept 函数取出连接. 如果 accept 队列溢出, 默认系统会丢弃 ACK, 也可以通过 tcp_abort_on_overflow 参数用 RST 通知客户端连接建立失败. 如果 netstat 统计信息显示, 大量的 ACK 被丢弃后, 可以通过 listen 函数的 backlog 参数和 somaxconn 系统参数提高队列上限.")]),s._v(" "),t("p",[s._v("TFO 技术绕过三次握手, 使得 HTTP 请求减少了 1 个 RTT 的时间. Linux 下可以通过 tcp_fastopen 参数开启该功能.")]),s._v(" "),t("p",[s._v("从这一讲可以看出, "),t("strong",[s._v("虽然 TCP 是由操作系统实现的, 但 Linux 通过多种方式提供了修改 TCP 功能的接口, 供我们优化 TCP 的性能")]),s._v(". 下一讲再来探讨四次握手关闭连接时, Linux 怎样帮助我们优化其性能.")]),s._v(" "),t("h4",{attrs:{id:"_10-如何提升tcp四次挥手的性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-如何提升tcp四次挥手的性能"}},[s._v("#")]),s._v(" 10-如何提升TCP四次挥手的性能?")]),s._v(" "),t("p",[s._v("本节再来看四次挥手关闭连接时, 如何优化性能.")]),s._v(" "),t("p",[t("strong",[s._v("close 和 shutdown 函数都可以关闭连接")]),s._v(", 但这两种方式关闭的连接, 不只功能上有差异, 控制它们的 Linux 参数也不相同. "),t("strong",[s._v("close 函数会让连接变为孤儿连接, shutdown 函数则允许在半关闭的连接上长时间传输数据")]),s._v(". TCP 之所以具备这个功能, 是因为它是全双工协议, 但这也造成四次挥手非常复杂.")]),s._v(" "),t("p",[s._v("四次挥手中可以用 netstat 命令观察到 6 种状态. 其中, 你多半看到过 TIME_WAIT 状态. 网上有许多文章介绍怎样减少 TIME_WAIT 状态连接的数量, 也有文章说 TIME_WAIT 状态是必不可少, 不能优化掉的. 这两种看似自相矛盾的观点之所以存在, 就在于优化连接关闭时, 不能仅基于主机端的视角, 还必须站在整个网络的层次上, 才能给出正确的解决方案.")]),s._v(" "),t("p",[s._v("Linux 为四次挥手提供了很多控制参数, 有些参数的名称与含义并不相符. 例如 tcp_orphan_retries 参数中有 orphan 孤儿, 却同时对非孤儿连接也生效. 而且错误地配置这些参数, 不只无法针对高并发场景提升性能, 还会降低资源的使用效率, 甚至引发数据错误.")]),s._v(" "),t("p",[s._v("这一讲将"),t("strong",[s._v("基于四次挥手的流程, 介绍 Linux 下的优化方法")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-四次挥手的流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-四次挥手的流程"}},[s._v("#")]),s._v(" 1.四次挥手的流程")]),s._v(" "),t("p",[s._v("你想没想过, "),t("strong",[s._v("为什么建立连接是三次握手, 而关闭连接需要四次挥手呢")]),s._v("?")]),s._v(" "),t("p",[t("strong",[s._v("这是因为 TCP 不允许连接处于半打开状态时就单向传输数据, 所以在三次握手建立连接时, 服务器会把 ACK 和 SYN 放在一起发给客户端, 其中, ACK 用来打开客户端的发送通道, SYN 用来打开服务器的发送通道. 这样, 原本的四次握手就降为三次握手了")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/aaf130690b7a7a95c24f0df485d28489-20230731165330-9gu51wy.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("但是当连接处于半关闭状态时, TCP 是允许单向传输数据的")]),s._v(". 为便于下文描述, "),t("strong",[s._v("接下来把先关闭连接的一方叫做主动方, 后关闭连接的一方叫做被动方.")]),s._v("  当主动方关闭连接时, 被动方仍然可以在不调用 close 函数的状态下, 长时间发送数据, 此时连接处于半关闭状态. "),t("strong",[s._v("这一特性是 TCP 的双向通道互相独立所致, 却也使得关闭连接必须通过四次挥手才能做到")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("互联网中往往服务器才是主动关闭连接的一方.")]),s._v("  这是因为, HTTP 消息是单向传输协议, "),t("strong",[s._v("服务器接收完请求才能生成响应, 发送完响应后就会立刻关闭 TCP 连接")]),s._v(", 这样及时释放了资源, 能够为更多的用户服务.")]),s._v(" "),t("p",[s._v("这就使得服务器的优化策略变得复杂起来. 一方面, 由于被动方有多种应对策略, 从而增加了主动方的处理分支. 另一方面, 服务器同时为成千上万个用户服务, 任何错误都会被庞大的用户数放大. 所以对主动方的关闭连接参数调整时, 需要格外小心.")]),s._v(" "),t("p",[s._v("了解了这一点之后, 再来看四次挥手的流程.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/5fa25b6b889933b99fb44a66c72d6fda-20230731165330-pspngrc.png",alt:""}})]),s._v(" "),t("p",[s._v("**其实四次挥手只涉及两种报文: FIN 和 ACK. **FIN 就是 Finish 结束连接的意思, 谁发出 FIN 报文, 就表示它将不再发送任何数据, 关闭这一方向的传输通道. ACK 是 Acknowledge 确认的意思, 它用来通知对方: 你方的发送通道已经关闭.")]),s._v(" "),t("p",[s._v("当主动方关闭连接时, 会发送 FIN 报文, 此时主动方的连接状态由 ESTABLISHED 变为 FIN_WAIT1. 当被动方收到 FIN 报文后, 内核自动回复 ACK 报文, 连接状态由 ESTABLISHED 变为 CLOSE_WAIT, 顾名思义, 它在等待进程调用 close 函数关闭连接. 当主动方接收到这个 ACK 报文后, 连接状态由 FIN_WAIT1 变为 FIN_WAIT2, 主动方的发送通道就关闭了.")]),s._v(" "),t("p",[s._v("再来看被动方的发送通道是如何关闭的. 当被动方进入 CLOSE_WAIT 状态时, 进程的 read 函数会返回 0, 这样开发人员就会有针对性地调用 close 函数, 进而触发内核发送 FIN 报文, 此时被动方连接的状态变为 LAST_ACK. 当主动方收到这个 FIN 报文时, 内核会自动回复 ACK, 同时连接的状态由 FIN_WAIT2 变为 TIME_WAIT, Linux 系统下大约 1 分钟后 TIME_WAIT 状态的连接才会彻底关闭. 而被动方收到 ACK 报文后, 连接就会关闭.")]),s._v(" "),t("h5",{attrs:{id:"_2-主动方的优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-主动方的优化"}},[s._v("#")]),s._v(" 2.主动方的优化")]),s._v(" "),t("p",[s._v("关闭连接有多种方式, 比如进程异常退出时, 针对它打开的连接, 内核就会发送 RST 报文来关闭. RST 的全称是 Reset 复位的意思, 它可以不走四次挥手强行关闭连接, 但当报文延迟或者重复传输时, 这种方式会导致数据错乱, 所以这是不得已而为之的关闭连接方案.")]),s._v(" "),t("p",[s._v("安全关闭连接的方式必须通过四次挥手, 它由进程调用 close 或者 shutdown 函数发起, 这二者都会向对方发送 FIN 报文(shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN), 区别在于 close 调用后, 哪怕对方在半关闭状态下发送的数据到达主动方, 进程也无法接收.")]),s._v(" "),t("p",[t("strong",[s._v("此时, 这个连接叫做孤儿连接, 如果用 netstat -p 命令, 会发现连接对应的进程名为空. 而 shutdown 函数调用后, 即使连接进入了 FIN_WAIT1 或者 FIN_WAIT2 状态, 它也不是孤儿连接, 进程仍然可以继续接收数据.")]),s._v("  关于孤儿连接的概念, 下文调优参数时还会用到.")]),s._v(" "),t("p",[s._v("主动方发送 FIN 报文后, 连接就处于 FIN_WAIT1 状态下, 该状态通常应在数十毫秒内转为 FIN_WAIT2. 只有迟迟收不到对方返回的 ACK 时, 才能用 netstat 命令观察到 FIN_WAIT1 状态. 此时, "),t("strong",[s._v("内核会定时重发 FIN 报文, 其中重发次数由 tcp_orphan_retries 参数控制")]),s._v("(注意, orphan 虽然是孤儿的意思, 该参数却不只对孤儿连接有效, 事实上, 它对所有 FIN_WAIT1 状态下的连接都有效), 默认值是 0, 特指 8 次:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_orphan_retries "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("如果 FIN_WAIT1 状态连接有很多, 你就需要考虑降低 tcp_orphan_retries 的值. 当重试次数达到 tcp_orphan_retries 时, 连接就会直接关闭掉.")]),s._v(" "),t("p",[s._v("**对于正常情况来说, 调低 tcp_orphan_retries 已经够用, 但如果遇到恶意攻击, FIN 报文根本无法发送出去. **这是由 TCP 的 2 个特性导致的.")]),s._v(" "),t("ol",[t("li",[s._v("首先, TCP 必须保证报文是有序发送的, FIN 报文也不例外, 当发送缓冲区还有数据没发送时, FIN 报文也不能提前发送.")]),s._v(" "),t("li",[s._v("其次, TCP 有流控功能, 当接收方将接收窗口设为 0 时, 发送方就不能再发送数据. 所以, 当攻击者下载大文件时, 就可以通过将接收窗口设为 0, 导致 FIN 报文无法发送, 进而导致连接一直处于 FIN_WAIT1 状态.")])]),s._v(" "),t("p",[s._v("解决这种问题的方案是调整 tcp_max_orphans 参数:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_max_orphans "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16384")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("顾名思义, **tcp_max_orphans 定义了孤儿连接的最大数量. **当进程调用 close 函数关闭连接后, 无论该连接是在 FIN_WAIT1 状态, 还是确实关闭了, 这个连接都与该进程无关了, 它变成了孤儿连接. Linux 系统为防止孤儿连接过多, 导致系统资源长期被占用, 就提供了 tcp_max_orphans 参数. 如果孤儿连接数量大于它, 新增的孤儿连接将不再走四次挥手, 而是直接发送 RST 复位报文强制关闭.")]),s._v(" "),t("p",[s._v("当连接收到 ACK 进入 FIN_WAIT2 状态后, 就表示主动方的发送通道已经关闭, 接下来将等待对方发送 FIN 报文, 关闭对方的发送通道. 这时, **如果连接是用 shutdown 函数关闭的, 连接可以一直处于 FIN_WAIT2 状态. 但对于 close 函数关闭的孤儿连接, 这个状态不可以持续太久, 而 tcp_fin_timeout 控制了这个状态下连接的持续时长. **")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_fin_timeout "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("60")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("它的默认值是 60 秒. 这意味着对于孤儿连接, 如果 60 秒后还没有收到 FIN 报文, 连接就会直接关闭. 这个 60 秒并不是拍脑袋决定的, 它与接下来介绍的 TIME_WAIT 状态的持续时间是相同的, 稍后再来回答 60 秒的由来.")]),s._v(" "),t("p",[s._v("TIME_WAIT 是主动方四次挥手的最后一个状态. 当收到被动方发来的 FIN 报文时, 主动方回复 ACK, 表示确认对方的发送通道已经关闭, 连接随之进入 TIME_WAIT 状态, 等待 60 秒后关闭, 为什么呢? 必须站在整个网络的角度上, 才能回答这个问题.")]),s._v(" "),t("p",[s._v("TIME_WAIT 状态的连接, 在主动方看来确实已经关闭了. 然而, 被动方没有收到 ACK 报文前, 连接还处于 LAST_ACK 状态. 如果这个 ACK 报文没有到达被动方, 被动方就会重发 FIN 报文. 重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制.")]),s._v(" "),t("p",[s._v("如果主动方不保留 TIME_WAIT 状态, 会发生什么呢? 此时连接的端口恢复了自由身, 可以复用于新连接了. 然而, 被动方的 FIN 报文可能再次到达, 这既可能是网络中的路由器重复发送, 也有可能是被动方没收到 ACK 时基于 tcp_orphan_retries 参数重发. 这样, **正常通讯的新连接就可能被重复发送的 FIN 报文误关闭. **保留 TIME_WAIT 状态, 就可以应付重发的 FIN 报文, 当然, 其他数据报文也有可能重发, 所以 TIME_WAIT 状态还能避免数据错乱.")]),s._v(" "),t("p",[s._v("再回过头来看看, 为什么 TIME_WAIT 状态要保持 60 秒呢? 这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的原理是一样的, "),t("strong",[s._v("因为这两个状态都需要保持 2MSL 时长. MSL 全称是 Maximum Segment Lifetime, 它定义了一个报文在网络中的最长生存时间")]),s._v("(报文每经过一次路由器的转发, IP 头部的 TTL 字段就会减 1, 减到 0 时报文就被丢弃, 这就限制了报文的最长存活时间).")]),s._v(" "),t("p",[s._v("为什么是 2 MSL 的时长呢? 这其实是相当于"),t("strong",[s._v("至少允许报文丢失一次")]),s._v(". 比如, 若 ACK 在一个 MSL 内丢失, 这样被动方重发的 FIN 会在第 2 个 MSL 内到达, TIME_WAIT 状态的连接可以应对. 为什么不是 4 或者 8 MSL 的时长呢? 可以想象一个丢包率达到百分之一的糟糕网络, 连续两次丢包的概率只有万分之一, 这个概率实在是太小了, 忽略它比解决它更具性价比.")]),s._v(" "),t("p",[s._v("**因此, TIME_WAIT 和 FIN_WAIT2 状态的最大时长都是 2 MSL, 由于在 Linux 系统中, MSL 的值固定为 30 秒, 所以它们都是 60 秒. **")]),s._v(" "),t("p",[s._v("虽然 TIME_WAIT 状态的存在是有必要的, 但它毕竟在消耗系统资源, 比如 TIME_WAIT 状态的端口就无法供新连接使用. 怎样解决这个问题呢?")]),s._v(" "),t("p",[s._v("**Linux 提供了 tcp_max_tw_buckets 参数, 当 TIME_WAIT 的连接数量超过该参数时, 新关闭的连接就不再经历 TIME_WAIT 而直接关闭. **")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_max_tw_buckets "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("当服务器的并发连接增多时, 相应地, 同时处于 TIME_WAIT 状态的连接数量也会变多, 此时就应当调大 tcp_max_tw_buckets 参数, 减少不同连接间数据错乱的概率")]),s._v(".")]),s._v(" "),t("p",[s._v("当然, tcp_max_tw_buckets 也不是越大越好, 毕竟内存和端口号都是有限的. 有没有办法让新连接复用 TIME_WAIT 状态的端口呢? 如果服务器会主动向上游服务器发起连接的话, 就可以把 tcp_tw_reuse 参数设置为 1, 它允许作为客户端的新连接, 在安全条件下使用 TIME_WAIT 状态下的端口.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_tw_reuse "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("当然, 要想使 tcp_tw_reuse 生效, 还得把 timestamps 参数设置为 1, 它满足安全复用的先决条件(对方也要打开 tcp_timestamps ):")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_timestamps "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("老版本的 Linux 还提供了 tcp_tw_recycle 参数, 它并不要求 TIME_WAIT 状态存在 60 秒, 很容易导致数据错乱, 不建议设置为 1.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_tw_recycle "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("所以在 Linux 4.12 版本后, 直接取消了这一参数.")]),s._v(" "),t("h5",{attrs:{id:"_3-被动方的优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-被动方的优化"}},[s._v("#")]),s._v(" 3.被动方的优化")]),s._v(" "),t("p",[s._v("当被动方收到 FIN 报文时, 就开启了被动方的四次挥手流程. 内核自动回复 ACK 报文后, 连接就进入 CLOSE_WAIT 状态, 顾名思义, 它表示等待进程调用 close 函数关闭连接.")]),s._v(" "),t("p",[s._v("内核没有权力替代进程去关闭连接, 因为若主动方是通过 shutdown 关闭连接, 那么它就是想在半关闭连接上接收数据. **因此, Linux 并没有限制 CLOSE_WAIT 状态的持续时间. **")]),s._v(" "),t("p",[s._v("当然, 大多数应用程序并不使用 shutdown 函数关闭连接, 所以, 当你用 netstat 命令发现大量 CLOSE_WAIT 状态时, 要么是程序出现了 Bug, read 函数返回 0 时忘记调用 close 函数关闭连接, 要么就是程序负载太高, close 函数所在的回调函数被延迟执行了. 此时应当在应用代码层面解决问题.")]),s._v(" "),t("p",[s._v("由于 CLOSE_WAIT 状态下, 连接已经处于半关闭状态, 所以此时进程若要关闭连接, 只能调用 close 函数(再调用 shutdown 关闭单向通道就没有意义了), 内核就会发出 FIN 报文关闭发送通道, 同时连接进入 LAST_ACK 状态, 等待主动方返回 ACK 来确认连接关闭.")]),s._v(" "),t("p",[s._v("如果迟迟等不到 ACK, 内核就会重发 FIN 报文, 重发次数仍然由 tcp_orphan_retries 参数控制, 这与主动方重发 FIN 报文的优化策略一致.")]),s._v(" "),t("p",[s._v("至此, 由一方主动发起四次挥手的流程就介绍完了. 需要注意的是, "),t("strong",[s._v("如果被动方迅速调用 close 函数, 那么被动方的 ACK 和 FIN 有可能在一个报文中发送, 这样看起来, 四次挥手会变成三次挥手, 这只是一种特殊情况, 不用在意.")])]),s._v(" "),t("p",[s._v("再来看一种特例, 如果连接双方同时关闭连接, 会怎么样?")]),s._v(" "),t("p",[s._v("此时, 上面介绍过的优化策略仍然适用. 两方发送 FIN 报文时, 都认为自己是主动方, 所以都进入了 FIN_WAIT1 状态, FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b7ea547f0be8d91cc01ecafb475d51c4-20230731165330-x9ym4ar.png",alt:""}})]),s._v(" "),t("p",[s._v("接下来, 双方在等待 ACK 报文的过程中, 都等来了 FIN 报文. 这是一种新情况, 所以连接会进入一种叫做 "),t("strong",[s._v("CLOSING")]),s._v(" 的新状态, 它替代了 FIN_WAIT2 状态. 此时, 内核回复 ACK 确认对方发送通道的关闭, 仅己方的 FIN 报文对应的 ACK 还没有收到. 所以, CLOSING 状态与 LAST_ACK 状态下的连接很相似, 它会在适时重发 FIN 报文的情况下最终关闭.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-6"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节讲了四次挥手的流程, 需要根据主动方与被动方的连接状态变化来调整系统参数, 使它在特定网络条件下更及时地释放资源.")]),s._v(" "),t("p",[t("strong",[s._v("四次挥手的主动方, 为了应对丢包, 允许在 tcp_orphan_retries 次数内重发 FIN 报文. 当收到 ACK 报文, 连接就进入了 FIN_WAIT2 状态, 此时系统的行为依赖这是否为孤儿连接.")])]),s._v(" "),t("p",[s._v("如果这是 close 函数关闭的孤儿连接, 那么在 tcp_fin_timeout 秒内没有收到对方的 FIN 报文, 连接就直接关闭, 反之 shutdown 函数关闭的连接则不受此限制. 毕竟孤儿连接可能在重发次数内存在数分钟之久, 为了应对孤儿连接占用太多的资源, tcp_max_orphans 定义了最大孤儿连接的数量, 超过时连接就会直接释放.")]),s._v(" "),t("p",[s._v("当接收到 FIN 报文, 并返回 ACK 后, 主动方的连接进入 TIME_WAIT 状态. 这一状态会持续 1 分钟, 为了防止 TIME_WAIT 状态占用太多的资源, tcp_max_tw_buckets 定义了最大数量, 超过时连接也会直接释放. 当 TIME_WAIT 状态过多时, 还可以通过设置 tcp_tw_reuse 和 tcp_timestamps 为 1, 将 TIME_WAIT 状态的端口复用于作为客户端的新连接.")]),s._v(" "),t("p",[s._v("被动关闭的连接方应对非常简单, 它在回复 ACK 后就进入了 CLOSE_WAIT 状态, 等待进程调用 close 函数关闭连接. 因此, 出现大量 CLOSE_WAIT 状态的连接时, 应当从应用程序中找问题. 当被动方发送 FIN 报文后, 连接就进入 LAST_ACK 状态, 在未等来 ACK 时, 会在 tcp_orphan_retries 参数的控制下重发 FIN 报文.")]),s._v(" "),t("p",[s._v("至此, TCP 连接建立, 关闭时的性能优化就介绍完了. 下一讲将专注在 TCP 上传输数据时, 如何优化内存的使用效率.")]),s._v(" "),t("h4",{attrs:{id:"_11-如何修改tcp缓冲区才能兼顾并发数量与传输速度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-如何修改tcp缓冲区才能兼顾并发数量与传输速度"}},[s._v("#")]),s._v(" 11-如何修改TCP缓冲区才能兼顾并发数量与传输速度?")]),s._v(" "),t("p",[s._v("前面讲了如何从 C10K 进一步到 C10M, 不过, 这也意味着 TCP 占用的内存翻了一千倍, "),t("strong",[s._v("服务器的内存资源会非常紧张")]),s._v(".")]),s._v(" "),t("p",[s._v("如果在 Linux 系统中用 free 命令查看内存占用情况, 会发现一栏叫做 "),t("strong",[s._v("buff/cache")]),s._v(", 它是系统内存, 似乎与应用进程无关. 但"),t("strong",[s._v("每当进程新建一个 TCP 连接, buff/cache 中的内存都会上升 4K 左右")]),s._v(". 而且, 当连接传输数据时, 就远不止增加 4K 内存了. 这样, 几十万并发连接, 就在进程内存外又增加了 GB 级别的系统内存消耗.")]),s._v(" "),t("p",[s._v("这是因为 TCP 连接是由内核维护的, 内核为每个连接建立的"),t("strong",[s._v("内存缓冲区")]),s._v(", 既要为网络传输服务, 也要充当进程与网络间的缓冲桥梁. 如果连接的内存配置过小, 就无法充分使用网络带宽, TCP 传输速度就会很慢; 如果连接的内存配置过大, 那么服务器内存会很快用尽, 新连接就无法建立成功. 因此, 只有深入理解 "),t("strong",[s._v("Linux 下 TCP 内存")]),s._v("的用途, 才能正确地配置内存大小.")]),s._v(" "),t("p",[s._v("这一讲就来看看, "),t("strong",[s._v("Linux 下的 TCP 缓冲区该如何修改, 才能在高并发下维持 TCP 的高速传输")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-滑动窗口是怎样影响传输速度的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-滑动窗口是怎样影响传输速度的"}},[s._v("#")]),s._v(" 1.滑动窗口是怎样影响传输速度的?")]),s._v(" "),t("p",[s._v("TCP 必须保证每一个报文都能够到达对方, 它采用的机制就是: 报文发出后, 必须收到接收方返回的 ACK 确认报文(Acknowledge 确认的意思). 如果在一段时间内(称为 RTO, retransmission timeout)没有收到, 这个报文还得"),t("strong",[s._v("重新发送")]),s._v(", 直到收到 ACK 为止.")]),s._v(" "),t("p",[t("strong",[s._v("可见, TCP 报文发出去后, 并不能立刻从内存中删除, 因为重发时还需要用到它.")]),s._v("  由于 TCP 是由内核实现的, 所以报文"),t("strong",[s._v("存放在内核缓冲区")]),s._v("中, 这也是高并发下 buff/cache 内存增加很多的原因.")]),s._v(" "),t("p",[s._v("事实上, 确认报文被收到的机制非常复杂, 它受制于很多因素.")]),s._v(" "),t("p",[s._v("先来看第一个因素, "),t("strong",[s._v("速度")]),s._v(".")]),s._v(" "),t("p",[s._v("如果发送一个报文, 收到 ACK 确认后, 再发送下一个报文, 会有什么问题? 显然, 发送每个报文都需要经历一个 RTT 时延(RTT 的值可以用 ping 命令得到). 要知道, 因为网络设备限制了报文的字节数, 所以每个报文的体积有限.")]),s._v(" "),t("p",[s._v("比如, 以太网报文最大只有 1500 字节, 而发送主机到接收主机间, 要经历多个广域网, 局域网, 其中最小的设备决定了网络报文的最大字节数, 在 TCP 中, 这个值叫做 MSS(Maximum Segment Size), 它通常在 1KB 左右. 如果 RTT 时延是 10ms, 那么它们的传送速度最多只有 1KB/10ms=100KB/s! 可见, 这种确认报文方式太影响传输速度了.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/58070949b64c1135a6ce3c7cca57417e-20230731165330-zcvuo07.png",alt:""}})]),s._v(" "),t("p",[s._v("**提速的方式很简单, 并行地批量发送报文, 再批量确认报文即可. **比如, 发送一个 100MB 的文件, 如果 MSS 值为 1KB, 那么需要发送约 10 万个报文. 发送方大可以同时发送这 10 万个报文, 再等待它们的 ACK 确认. 这样, 发送速度瞬间就达到 100MB/10ms=10GB/s.")]),s._v(" "),t("p",[s._v("然而, 这引出了另一个问题, 接收方有那么强的处理能力吗? "),t("strong",[s._v("接收方的处理能力")]),s._v(", 这是影响确认机制的"),t("strong",[s._v("第二个因素")]),s._v("(网络也没有这么强的处理能力, 下一讲会介绍应对网络瓶颈的拥塞控制技术).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4d941221a37caa5406801a54f09496b9-20230731165330-qqi0vye.png",alt:""}})]),s._v(" "),t("p",[s._v("当接收方硬件不如发送方, 或者系统繁忙, 资源紧张时, 是无法瞬间处理这么多报文的. 于是, 这些报文"),t("strong",[s._v("只能被丢掉")]),s._v(", 网络效率非常低. 怎么限制发送方的速度呢?")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("接收方把它的处理能力告诉发送方, 使其限制发送速度即可, 这就是滑动窗口的由来")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  接收方根据它的缓冲区, 可以计算出后续能够接收多少字节的报文, 这个数字叫做接收窗口. 当内核接收到报文时, 必须用缓冲区存放它们, 这样剩余缓冲区空间变小, 接收窗口也就变小了; 当进程调用 read 函数后, 数据被读入了用户空间, 内核缓冲区就被清空, 这意味着主机可以接收更多的报文, 接收窗口就会变大.")]),s._v(" "),t("p",[s._v("因此, "),t("strong",[s._v("接收窗口并不是恒定不变的, 那么怎么把时刻变化的窗口通知给发送方呢? TCP 报文头部中的窗口字段, 就可以起到通知的作用")]),s._v(".")]),s._v(" "),t("p",[s._v("当发送方从报文中得到接收方的窗口大小时, 就明白了最多能发送多少字节的报文, 这个数字被称为"),t("strong",[s._v("发送方的发送窗口")]),s._v(". 如果不考虑下一讲将要介绍的拥塞控制, 发送方的发送窗口就是接收方的接收窗口(由于报文有传输时延, t1 时刻的接收窗口在 t2 时刻才能到达发送端, 因此这两个窗口并不完全等价).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/21a88c3d29a9a4a14e87a0e40b261155-20230731165330-jyo7gz7.png",alt:""}})]),s._v(" "),t("p",[s._v("从上图中可以看到, 窗口字段只有 2 个字节, 因此它最多能表达 216 即 65535 字节大小的窗口(之所以不是 65536, 是因为窗口可以为 0, 此时叫做窗口关闭, 上一讲提到的关闭连接时让 FIN 报文发不出去, 以致于服务器的连接都处于 FIN_WAIT1 状态, 就是通过窗口关闭技术实现的), 这在 RTT 为 10ms 的网络中也只能到达 6MB/s 的最大速度, 在当今的高速网络中显然并不够用.")]),s._v(" "),t("p",[s._v("RFC1323 定义了扩充窗口的方法, 但 Linux 中打开这一功能, 需要把 tcp_window_scaling 配置设为 1, 此时窗口的最大值可以达到 1GB(230).")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_window_scaling "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("这样看来, 只要进程能及时地调用 read 函数读取数据, 并且接收缓冲区配置得足够大, 那么接收窗口就可以无限地放大, 发送方也就无限地提升发送速度. 很显然, 这是不可能的, 因为网络的传输能力是有限的, 当发送方依据发送窗口, 发送超过网络处理能力的报文时, 路由器会直接丢弃这些报文. 因此, "),t("strong",[s._v("缓冲区的内存并不是越大越好")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_2-带宽时延积如何确定最大传输速度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-带宽时延积如何确定最大传输速度"}},[s._v("#")]),s._v(" 2.带宽时延积如何确定最大传输速度?")]),s._v(" "),t("p",[s._v("缓冲区到底该设置为多大呢? "),t("strong",[s._v("TCP 的传输速度, 受制于发送窗口与接收窗口, 以及网络传输能力")]),s._v(". 其中, 两个窗口由缓冲区大小决定(进程调用 read 函数是否及时也会影响它). 如果缓冲区大小与网络传输能力匹配, 那么缓冲区的利用率就达到了最大值.")]),s._v(" "),t("p",[s._v("怎样计算出网络传输能力呢? 带宽描述了网络传输能力, 但它不能直接使用, 因为它与窗口或者说缓冲区的计量单位不同. 带宽是单位时间内的流量, 它表达的是速度, 比如你家里的宽带 100MB/s, 而窗口和缓冲区的单位是字节. 当网络速度乘以时间才能得到字节数, 差的这个时间, 这就是网络时延.")]),s._v(" "),t("p",[s._v("当最大带宽是 100MB/s, 网络时延是 10ms 时, 这意味着客户端到服务器间的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节. 这个 1MB 是带宽与时延的乘积, 所以它就叫做带宽时延积(缩写为 BDP, Bandwidth Delay Product). 这 1MB 字节存在于飞行中的 TCP 报文, 它们就在网络线路, 路由器等网络设备上. 如果飞行报文超过了 1MB, 就一定会让网络过载, 最终导致丢包.")]),s._v(" "),t("p",[s._v("由于发送缓冲区决定了发送窗口的上限, 而发送窗口又决定了已发送但未确认的飞行报文的上限, 因此, "),t("strong",[s._v("发送缓冲区不能超过带宽时延积")]),s._v(", 因为超出的部分没有办法用于有效的网络传输, 且飞行字节大于带宽时延积还会导致丢包; 而且, "),t("strong",[s._v("缓冲区也不能小于带宽时延积, 否则无法发挥出高速网络的价值")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_3-怎样调整缓冲区去适配滑动窗口"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-怎样调整缓冲区去适配滑动窗口"}},[s._v("#")]),s._v(" 3.怎样调整缓冲区去适配滑动窗口?")]),s._v(" "),t("p",[s._v("这么看来, 只要把缓冲区设置为带宽时延积不就行了吗? 比如, 当做 socket 网络编程时, 通过设置 socket 的 SO_SNDBUF 属性, 就可以设定缓冲区的大小. 然而, 这并不是个好主意, 因为不是每一个请求都能够达到最大传输速度, 比如请求的体积太小时, 在"),t("strong",[s._v("慢启动算法")]),s._v("的影响下, 未达到最大速度时请求就处理完了. 再比如网络本身也会有波动, 未必可以一直保持最大速度.")]),s._v(" "),t("p",[s._v("**因此, 时刻让缓冲区保持最大, 太过浪费内存了. **")]),s._v(" "),t("p",[s._v("到底该如何设置缓冲区呢?")]),s._v(" "),t("p",[s._v("可以使用 Linux 的"),t("strong",[s._v("缓冲区动态调节功能")]),s._v("解决上述问题. 其中, 缓冲区的调节范围是可以设置的. 先来看发送缓冲区, 它的范围通过 tcp_wmem 配置:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_wmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4096")]),s._v("        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16384")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4194304")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[t("strong",[s._v("其中, 第 1 个数值是动态范围的下限, 第 3 个数值是动态范围的上限. 而中间第 2 个数值, 则是初始默认值.")])]),s._v(" "),t("p",[s._v("发送缓冲区完全根据需求自行调整. 比如, 一旦发送出的数据被确认, 而且没有新的数据要发送, 就可以把发送缓冲区的内存释放掉. 而接收缓冲区的调整就要复杂一些, 先来看设置接收缓冲区范围的 tcp_rmem:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_rmem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4096")]),s._v("        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("87380")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6291456")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("它的数值与 tcp_wmem 类似, 第 1, 3 个值是范围的下限和上限, 第 2 个值是初始默认值. 发送缓冲区自动调节的依据是待发送的数据, 接收缓冲区由于只能被动地等待接收数据, 它该如何自动调整呢?")]),s._v(" "),t("p",[s._v("**可以依据空闲系统内存的数量来调节接收窗口. **如果系统的空闲内存很多, 就可以把缓冲区增大一些, 这样传给对方的接收窗口也会变大, 因而对方的发送速度就会通过增加飞行报文来提升. 反之, 内存紧张时就会缩小缓冲区, 这虽然会减慢速度, 但可以保证更多的并发连接正常工作.")]),s._v(" "),t("p",[s._v("发送缓冲区的调节功能是自动开启的, 而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_moderate_rcvbuf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("接收缓冲区调节时, 怎么判断空闲内存的多少呢? 这是通过 tcp_mem 配置完成的:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ipv4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("tcp_mem "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("88560")]),s._v("        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("118080")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("177120")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("tcp_mem 的 3 个值, 是 Linux 判断系统内存是否紧张的依据. 当 TCP 内存小于第 1 个值时, 不需要进行自动调节; 在第 1 和第 2 个值之间时, 内核开始调节接收缓冲区的大小; 大于第 3 个值时, 内核不再为 TCP 分配新内存, 此时新连接是无法建立的.")]),s._v(" "),t("p",[s._v("在高并发服务器中, 为了兼顾网速与大量的并发连接, "),t("mark",[t("strong",[s._v("应当保证缓冲区的动态调整上限达到带宽时延积, 而下限保持默认的 4K 不变即可. 而对于内存紧张的服务而言, 调低默认值是提高并发的有效手段")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("同时, 如果这是网络 IO 型服务器, 那么"),t("strong",[s._v("调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存, 这有利于提升并发能力.")]),s._v("  需要注意的是, tcp_wmem 和 tcp_rmem 的单位是字节, 而 tcp_mem 的单位是页面大小. 而且, "),t("strong",[s._v("千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF, 这样会关闭缓冲区的动态调整功能.")])]),s._v(" "),t("h5",{attrs:{id:"_4-小结-7"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-7"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("实现高并发服务时, 由于必须把大部分内存用在网络传输上, 所以除了关注应用内存的使用, 还必须"),t("strong",[s._v("关注 TCP 内核缓冲区的内存使用")]),s._v("情况.")]),s._v(" "),t("p",[s._v("TCP 使用 ACK 确认报文实现了可靠性, 又依赖滑动窗口既提升了发送速度也兼顾了接收方的处理能力. 然而, 默认的滑动窗口最大只能到 65KB, 要想提升发送速度必须提升滑动窗口的上限, 在 Linux 下是通过设置 tcp_window_scaling 为 1 做到的.")]),s._v(" "),t("p",[s._v("滑动窗口定义了飞行报文的最大字节数, 当它超过带宽时延积时, 就会发生丢包. 而当它小于带宽时延积时, 就无法让 TCP 的传输速度达到网络允许的最大值. 因此, 滑动窗口的设计, 必须参考带宽时延积.")]),s._v(" "),t("p",[s._v("内核缓冲区决定了滑动窗口的上限, 但不能通过 socket 的 SO_SNFBUF 等选项直接把缓冲区大小设置为带宽时延积, 因为 TCP 不会一直维持在最高速上, 过大的缓冲区会减少并发连接数. Linux 带来的缓冲区自动调节功能非常有效, 我们应当把缓冲区的上限设置为带宽时延积. 其中, 发送缓冲区的调节功能是自动打开的, 而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启, 其中调节的依据根据 tcp_mem 而定.")]),s._v(" "),t("p",[s._v("这样高效地配置内存后, 既能够最大程度地保持并发性, 也能让资源充裕时连接传输速度达到最大值. 本节谈了内核缓冲区对传输速度的影响, 下一节再来看如何调节发送速度以匹配不同的网络能力.")]),s._v(" "),t("h4",{attrs:{id:"_12-如何调整tcp拥塞控制的性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-如何调整tcp拥塞控制的性能"}},[s._v("#")]),s._v(" 12-如何调整TCP拥塞控制的性能?")]),s._v(" "),t("p",[s._v("上接谈到"),t("strong",[s._v("接收主机的处理能力不足时, 是通过滑动窗口来减缓对方的发送速度")]),s._v(". 这一接来看看, 当"),t("strong",[s._v("网络处理能力不足时又该如何优化 TCP 的性能")]),s._v(".")]),s._v(" "),t("p",[s._v("如果你阅读过 TCP 协议相关的书籍, 一定看到过慢启动, 拥塞控制等名词. 这些概念似乎离应用开发者很远, 然而, 如果没有拥塞控制, 整个网络将会锁死, 所有消息都无法传输.")]),s._v(" "),t("p",[s._v("而且, 如果你在开发分布式集群中的高并发服务, 理解拥塞控制的工作原理, 就可以在内核的 TCP 层, 提升所有进程的网络性能. 比如, 你可能听过, 2013 年谷歌把初始拥塞窗口从 3 个 MSS(最大报文长度)左右提升到 10 个 MSS, 将 Web 站点的网络性能提升了 10% 以上, 而有些高速 CDN 站点, 甚至"),t("strong",[s._v("把初始拥塞窗口提升到 70 个 MSS")]),s._v(".")]),s._v(" "),t("p",[s._v("特别是, 近年来谷歌提出的 BBR 拥塞控制算法已经应用在高版本的 Linux 内核中, 从它在 YouTube 上的应用可以看到, 在高性能站点上网络时延有 20% 以上的降低, 传输带宽也有提高.")]),s._v(" "),t("p",[s._v("Linux 允许我们调整拥塞控制算法, 但正确地设置参数, 还需要深入理解拥塞控制对 TCP 连接的影响. 这一节将沿着网络如何影响发送速度这条线, 看看如何调整 Linux 下的拥塞控制参数.")]),s._v(" "),t("h5",{attrs:{id:"_1-慢启动阶段如何调整初始拥塞窗口"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-慢启动阶段如何调整初始拥塞窗口"}},[s._v("#")]),s._v(" 1.慢启动阶段如何调整初始拥塞窗口?")]),s._v(" "),t("p",[s._v("上一讲谈到, "),t("strong",[s._v("只要接收方的读缓冲区足够大, 就可以通过报文中的接收窗口, 要求对方更快地发送数据")]),s._v(". 然而, 网络的传输速度是有限的, 它会直接丢弃超过其处理能力的报文. 而发送方只有在重传定时器超时后, 才能发现超发的报文被网络丢弃了, 发送速度提不上去. 更为糟糕的是, 如果网络中的每个连接都按照接收窗口尽可能地发送更多的报文时, 就会形成"),t("strong",[s._v("恶性循环, 最终超高的网络丢包率会使得每个连接都无法发送数据")]),s._v(".")]),s._v(" "),t("p",[s._v("解决这一问题的方案叫做"),t("mark",[t("strong",[s._v("拥塞控制")])]),s._v(", 它包括 4 个阶段, 首先来看 TCP 连接刚建立时的"),t("mark",[t("strong",[s._v("慢启动阶段")])]),s._v(". 由于 TCP 连接会穿越许多网络, 所以最初并不知道网络的传输能力, 为了避免发送超过网络负载的报文, "),t("strong",[s._v("TCP 只能先调低发送窗口")]),s._v(', 减少飞行中的报文来让发送速度变慢, 这也是 "慢启动" 名字的由来.')]),s._v(" "),t("p",[s._v("让发送速度变慢是通过引入"),t("strong",[s._v("拥塞窗口")]),s._v("(全称为 congestion window, 缩写为 "),t("strong",[s._v("CWnd")]),s._v(", 类似地, 接收窗口叫做 "),t("strong",[s._v("rwnd")]),s._v(", 发送窗口叫做 "),t("strong",[s._v("swnd")]),s._v(")实现的, 它用于避免网络出现拥塞. 上一讲说过, "),t("strong",[s._v("如果不考虑网络拥塞, 发送窗口就等于对方的接收窗口, 而考虑了网络拥塞后, 发送窗口则应当是拥塞窗口与对方接收窗口的最小值")]),s._v(":")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("swnd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("min")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cwnd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" rwnd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("这样, "),t("mark",[t("strong",[s._v("发送速度就综合考虑了接收方和网络的处理能力")])]),s._v(".")]),s._v(" "),t("p",[s._v("虽然窗口的计量单位是字节, 但为了方便理解, 通常"),t("strong",[s._v("用 MSS 作为描述窗口大小的单位, 其中 MSS 是 TCP 报文的最大长度")]),s._v(".")]),s._v(" "),t("p",[s._v("如果初始拥塞窗口只有 1 个 MSS, 当 MSS 是 1KB, 而 RTT 时延是 100ms 时, 发送速度只有 10KB/s. 所以, 当没有发生拥塞时, 拥塞窗口必须快速扩大, 才能提高互联网的传输速度. 因此, 慢启动阶段会以"),t("strong",[s._v("指数级扩大")]),s._v("拥塞窗口(扩大规则是这样的: 发送方每收到一个 ACK 确认报文, 拥塞窗口就增加 1 个 MSS), 比如最初的初始拥塞窗口(也称为 initcwnd)是 1 个 MSS, 经过 4 个 RTT 就会变成 16 个 MSS.")]),s._v(" "),t("p",[s._v("虽然指数级提升发送速度很快, 但互联网中的很多资源体积并不大, 多数场景下, 在传输速度没有达到最大时, 资源就已经下载完了. 下图是 2010 年 Google 对 Web 对象大小的 CDF 累积分布统计, 大多数对象在 10KB 左右.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e268eaa677f549c1f490748bbfd56901-20230731165330-ljftkbm.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 当 MSS 是 1KB 时, 多数 HTTP 请求至少包含 10 个报文, 即使以指数级增加拥塞窗口, 也需要至少 4 个 RTT 才能传输完, 参见下图:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f44ba0dc3da9b224924da4c2dbe07349-20230731165330-j79npjw.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, 2013 年 TCP 的初始拥塞窗口调整到了 10 个 MSS(参见 RFC6928), 这样 1 个 RTT 内就可以传输 10KB 的请求. 然而, 如果需要传输的对象体积更大, BDP 带宽时延积很大时, 完全可以继续提高初始拥塞窗口的大小. 下图是 2014 年, 2017 年全球主要 CDN 厂商初始拥塞窗口的变化, 可见随着网速的增加, 初始拥塞窗口也变得更大了.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/811f6266228029056492b7dcd59207d2-20230731165330-3vs4c4t.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, 可以"),t("strong",[s._v("根据网络状况和传输对象的大小, 调整初始拥塞窗口的大小")]),s._v(". 调整前, 先要清楚服务器现在的初始拥塞窗口是多大. 可以通过 ss 命令查看当前拥塞窗口:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ss -nli | fgrep cwnd")]),s._v("\ncubic rto:1000 mss:536 cwnd:10 segs_in:10621866 lastsnd:1716864402 lastrcv:1716864402 lastack:1716864402\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("再通过 "),t("code",[s._v("ip route change")]),s._v("​ 命令修改初始拥塞窗口:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ip route | while read r; do")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ip")]),s._v(" route change "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$r")]),s._v(" initcwnd "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("当然, 更大的初始拥塞窗口以及指数级的提速, 连接很快就会遭遇网络拥塞, 从而导致慢启动阶段的结束.")]),s._v(" "),t("h5",{attrs:{id:"_2-出现网络拥塞时该怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-出现网络拥塞时该怎么办"}},[s._v("#")]),s._v(" 2.出现网络拥塞时该怎么办?")]),s._v(" "),t("p",[s._v("以下 3 种场景都会"),t("strong",[s._v("导致慢启动阶段结束")]),s._v(":")]),s._v(" "),t("ul",[t("li",[s._v("通过定时器明确探测到了"),t("strong",[s._v("丢包")]),s._v(";")]),s._v(" "),t("li",[s._v("拥塞窗口的增长到达了"),t("strong",[s._v("慢启动阈值 ssthresh(全称为 slow start threshold)")]),s._v(" , 也就是之前发现网络拥塞时的窗口大小;")]),s._v(" "),t("li",[s._v("接收到"),t("strong",[s._v("重复的 ACK 报文, 可能存在丢包")]),s._v(".")])]),s._v(" "),t("p",[s._v("先来看第 1 种场景, 在规定时间内没有收到 ACK 报文, 这说明报文丢失了, 网络出现了严重的拥塞, 必须先降低发送速度, 再进入拥塞避免阶段. 不同的拥塞控制算法降低速度的幅度并不相同, 比如 CUBIC 算法会把拥塞窗口降为原先的 0.8 倍(也就是发送速度降到 0.8 倍). 此时, 已经知道了多大的窗口会导致拥塞, 因此可以把慢启动阈值设为发生拥塞前的窗口大小.")]),s._v(" "),t("p",[s._v("再看第 2 种场景, 虽然还没有发生丢包, 但发送方已经达到了"),t("strong",[s._v("曾经发生网络拥塞的速度")]),s._v("(拥塞窗口达到了慢启动阈值), 接下来发生拥塞的概率很高, 所以进入"),t("strong",[s._v("拥塞避免阶段, 此时拥塞窗口不能再以指数方式增长, 而是要以线性方式增长")]),s._v(". 接下来, 拥塞窗口会以每个 RTT 增加 1 个 MSS 的方式, 代替慢启动阶段每收到 1 个 ACK 就增加 1 个 MSS 的方式. 这里可能有同学会有疑问, 在第 1 种场景发生前, 慢启动阈值是多大呢? 事实上, RFC5681 建议最初的慢启动阈值尽可能的大, 这样才能在第 1, 3 种场景里快速发现网络瓶颈.")]),s._v(" "),t("p",[s._v('第 3 种场景最为复杂. TCP 传输的是字节流, 而 "流" 是天然有序的. 因此, 当接收方收到不连续的报文时, 就可能发生报文丢失或者延迟, 等待发送方超时重发太花时间了, 为了缩短重发时间, '),t("strong",[s._v("快速重传算法便应运而生.")])]),s._v(" "),t("p",[s._v("当连续收到 3 个重复 ACK 时, 发送方便得到了网络发生拥塞的明确信号, 通过重复 ACK 报文的序号, 就知道丢失了哪个报文, 这样不等待定时器的触发, "),t("strong",[s._v("立刻重发丢失的报文, 可以让发送速度下降得慢一些, 这就是快速重传算法")]),s._v(".")]),s._v(" "),t("p",[s._v("出现拥塞后, 发送方会缩小拥塞窗口, 再进入前面提到的拥塞避免阶段, 用线性速度慢慢增加拥塞窗口. 然而, **为了平滑地降低速度, 发送方应当先进入快速恢复阶段, 在失序报文到达接收方后, 再进入拥塞避免阶段. **")]),s._v(" "),t("p",[s._v("那什么是快速恢复呢? 不妨把网络看成一个容器(上一讲中说过它可以容纳 BDP 字节的报文), 每当接收方从网络中取出一个报文, 发送方就可以增加一个报文. 当发送方接收到重复 ACK 时, 可以推断有失序报文离开了网络, 到达了接收方的缓冲区, 因此可以再多发送一个报文. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c52e776589003078db017906e53685cd-20230731165330-iqqybmd.png",alt:""}})]),s._v(" "),t("p",[s._v("这里要注意: 第 6 个报文在慢启动阶段丢失, 接收方收到失序的第 7 个报文会触发快速重传算法, 它必须立刻返回 ACK6. 而发送方接收到第 1 个重复 ACK6 报文时, 就从慢启动进入了快速重传阶段, "),t("strong",[s._v("此刻的重复 ACK 不会扩大拥塞窗口.")]),s._v("  当连续收到 3 个 ACK6 时, 发送方会重发报文 6, 并把慢启动阈值和拥塞窗口都降到之前的一半: 3 个 MSS, 再进入快速恢复阶段. 按照规则, 由于收到 3 个重复 ACK, 所以拥塞窗口会增加 3 个 MSS. 之后收到的 2 个 ACK, 让拥塞窗口增加到了 8 个 MSS, 直到收到期待的 ACK12, 发送方才会进入拥塞避免阶段.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("慢启动, 拥塞避免, 快速重传, 快速恢复, 共同构成了拥塞控制算法")])]),s._v(". Linux 上提供了更改拥塞控制算法的配置, 可以通过 tcp_available_congestion_control 配置查看内核支持的算法列表:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.tcp_available_congestion_control "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cubic reno\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("再通过 tcp_congestion_control 配置选择一个具体的拥塞控制算法:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.tcp_congestion_control "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cubic\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("但有件事得清楚, "),t("strong",[s._v("拥塞控制是控制网络流量的算法, 主机间会互相影响, 在生产环境更改之前必须经过完善的测试")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_3-基于测量的拥塞控制算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-基于测量的拥塞控制算法"}},[s._v("#")]),s._v(" 3.基于测量的拥塞控制算法")]),s._v(" "),t("p",[s._v("上文介绍的是传统拥塞控制算法, 它是"),t("strong",[s._v("以丢包作为判断拥塞的依据")]),s._v(". 然而, 网络刚出现拥塞时并不会丢包, 而真的出现丢包时, 拥塞已经非常严重了. 如下图所示, 像路由器这样的网络设备, 都会有缓冲队列应对突发的, 超越处理能力的流量:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/66c8dabd8211ead3a31f0acec827799c-20230731165330-jkc9pyc.png",alt:""}})]),s._v(" "),t("p",[s._v("当缓冲队列为空时, 传输速度最快. 一旦队列开始积压, "),t("strong",[s._v("每个报文的传输时间需要增加排队时间, 网速就变慢了")]),s._v(". 而当队列溢出时, 才会出现丢包, 基于丢包的拥塞控制算法在这个时间点进入拥塞避免阶段, 显然"),t("strong",[s._v("太晚了")]),s._v(". 因为升高的网络时延降低了用户体验, 而且从丢包到重发这段时间, 带宽也会出现下降.")]),s._v(" "),t("p",[t("strong",[s._v("进行拥塞控制的最佳时间点, 是缓冲队列刚出现积压的时刻, 此时网络时延会增高, 但带宽维持不变, 这两个数值的变化可以给出明确的拥塞信号")]),s._v(", 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2fc42322000af336bb08e2b2aa1c94f6-20230731165330-by7dnpr.png",alt:""}})]),s._v(" "),t("p",[s._v("这种以"),t("strong",[s._v("测量带宽, 时延来确定拥塞")]),s._v("的方法, 在丢包率较高的网络中应用效果尤其好. 2016 年 Google 推出的 BBR 算法(全称 Bottleneck Bandwidth and Round-trip propagation time), 就是测量驱动的拥塞控制算法, 它在 YouTube 站点上应用后使得网络时延下降了 20% 以上, 传输带宽也有 5% 左右的提升.")]),s._v(" "),t("p",[s._v("当然, 测量驱动的拥塞算法并没有那么简单, 因为网络会波动, 线路也会变化, 算法必须及时地响应网络变化, 这里不再展开算法细节.")]),s._v(" "),t("p",[s._v("Linux 4.9 版本之后都支持 BBR 算法, 开启 BBR 算法仍然使用 tcp_congestion_control 配置:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("net.ipv4.tcp_congestion_control")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("bbr\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h5",{attrs:{id:"_4-小结-8"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-8"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("对这一讲的内容做个小结.")]),s._v(" "),t("p",[t("strong",[s._v("当 TCP 连接建立成功后, 拥塞控制算法就会发生作用, 首先进入慢启动阶段. 决定连接此时网速的是初始拥塞窗口, Linux 上可以通过 route ip change 命令修改它. 通常, 在带宽时延积较大的网络中, 应当调高初始拥塞窗口")]),s._v(".")]),s._v(" "),t("p",[s._v("丢包以及重复的 ACK 都是明确的拥塞信号, 此时发送方就会调低拥塞窗口减速, 同时修正慢启动阈值. 这样, 将来再次到达这个速度时, 就会自动进入拥塞避免阶段, 用线性速度代替慢启动阶段的指数速度提升窗口大小.")]),s._v(" "),t("p",[s._v("当然, 重复 ACK 意味着发送方可以提前重发丢失报文, 快速重传算法定义了这一行为. 同时, 为了使得重发报文的过程中, 发送速度不至于出现断崖式下降, TCP 又定义了快速恢复算法, 发送方在报文重新变得有序后, 结束快速恢复进入拥塞避免阶段.")]),s._v(" "),t("p",[s._v("但以丢包作为网络拥塞的信号往往为时已晚, 于是以 BBR 算法为代表的"),t("strong",[s._v("测量型拥塞控制算法")]),s._v("应运而生. 当飞行中报文数量不变, 而网络时延升高时, 就说明网络中的缓冲队列出现了积压, 这是进行拥塞控制的最好时机. Linux 高版本支持 BBR 算法, 可以通过 tcp_congestion_control 配置更改拥塞控制算法.")]),s._v(" "),t("h4",{attrs:{id:"_13-实战-单机如何实现管理百万主机的心跳服务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13-实战-单机如何实现管理百万主机的心跳服务"}},[s._v("#")]),s._v(" 13-实战:单机如何实现管理百万主机的心跳服务?")]),s._v(" "),t("p",[s._v("本节将结合前 12 讲, 以一个"),t("strong",[s._v("可管理百万主机集群的心跳服务")]),s._v("作为实战案例, 看看所有高性能服务的设计思路.")]),s._v(" "),t("p",[s._v("首先解释下什么是心跳服务. 集群中的主机如果宕机, 那么管理服务必须及时发现, 并做相应的容灾处理, 比如将宕机主机的业务迁移到新的虚拟机上等等. 怎么做到及时发现呢? 可以要求每台主机定时上报心跳包, 考虑到网络报文的延迟, 如果管理服务在几个上报周期内未收到心跳, 则认为主机宕机. 当新主机加入集群后, 心跳服务也可以及时识别并告知管理服务.")]),s._v(" "),t("p",[s._v("这就是心跳服务要解决的核心问题, 虽然很简单, 可是如果"),t("strong",[s._v("集群规模达到百万台虚拟机或者微服务进程")]),s._v(", 这就不再简单了. 多核 CPU, 内存使用效率, 网络带宽时延积等都必须纳入你的考虑, 因为此时心跳包占用的网络带宽已经接近网卡上限, 仅调动一颗 CPU 的计算力去处理就会大量丢包, 百万级的对象, 网络连接也很容易造成内存 OOM. 甚至判断宕机的算法都要重新设计, 降低时间复杂度后才能够应对超大集群的心跳管理.")]),s._v(" "),t("p",[s._v("解决这种集群规模下的性能问题, 需要深入掌握底层基础知识, 用系统化的全局思维去解决问题, 这也是程序员薪资差异的重要分水岭. 接下来先"),t("mark",[t("strong",[s._v("实现更高效的核心算法, 再设计高并发服务的架构, 最后再来看传输层协议的选择")])]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-如何设计更快的宕机判断算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何设计更快的宕机判断算法"}},[s._v("#")]),s._v(" 1.如何设计更快的宕机判断算法?")]),s._v(" "),t("p",[s._v("通过心跳包找到宕机的主机需要一套算法, 比如用 for 循环做一次遍历, 找到停止上报心跳的主机就可以实现, 然而正如前面所说, "),t("strong",[s._v("当管理的对象数量级很大时, 算法复杂度会严重影响程序性能")]),s._v(", 遍历算法此时并不可取. 我们先分析下这个算法的时间复杂度.")]),s._v(" "),t("p",[s._v("如果用红黑树(这里用红黑树是因为它既支持遍历, 也可以实现对数时间复杂度的查询操作)存放主机及其最近一次上报时间, 那么, 新主机上报心跳被发现的流程, 时间复杂度仅为 O(logN), 这是查询红黑树的成本. 寻找宕机服务的流程, 需要对红黑树做全量遍历, 用当前时间去比较每个主机的上次心跳时间, 时间复杂度就是 O(N)!")]),s._v(" "),t("p",[s._v("如果业务对时间灵敏度要求很高, 就意味着需要频繁地执行 O(N) 级的遍历, 当 N 也就是主机数量很大时, 耗时就很可观了. 而且寻找宕机服务和接收心跳包是两个流程, 如果它们都在单线程中执行, 那么寻找宕机服务的那段时间就不能接收心跳包, 会导致丢包! 如果使用多线程并发执行, 因为两个流程都需要操作红黑树, 所以要使用到互斥锁, 而当这两个流程争抢锁的频率很高时, 性能也会急剧下降.")]),s._v(" "),t("p",[s._v("**其实这个算法的根本问题在于, 判断宕机的流程做了大量的重复工作. **比如, 主机每隔 1 秒上报一次心跳, 而考虑到网络可能丢包, 故 5 秒内失去心跳就认为宕机, 这种情况下, 如果主机 A 在第 10 秒时失去心跳, 那么第 11, 12, 13, 14 这 4 秒对主机 A 的遍历, 都是多余的, 只有第 15 秒对主机 A 的遍历才有意义. 于是, 每次遍历平均浪费了 4/5 的计算量.")]),s._v(" "),t("p",[s._v("如何设计快速的宕机判断算法呢? 其实, 这是一个从一堆主机中寻找宕机服务的信息题. **根据香农的理论, 引入更多的信息, 才能减少不确定性降低信息熵, 从而减少计算量. 就像心跳包间是有时间顺序的, 上面的宕机判断算法显然忽略了接收到它们的顺序. **比如主机 A 的上次心跳包距现在 4 秒了, 而主机 B 距现在只有 1 秒, 显然不应同等对待.")]),s._v(" "),t("p",[s._v("于是, 我们引入存放心跳包的先入先出队列, 这就保存了心跳包的时序关系. "),t("strong",[s._v("新的心跳包进入队列尾部, 而老的心跳包则从队列首部退出")]),s._v(", 这样, 寻找宕机服务时, 只要"),t("strong",[s._v("看队列首部最老的心跳包")]),s._v(", 距现在是否超过 5 秒, 如果超过 5 秒就认定宕机, 同时把它取出队列, 否则证明队列中不存在宕机服务, 维持队列不变.")]),s._v(" "),t("p",[s._v("当然, 这里并没有解决如何"),t("strong",[s._v("发现新主机")]),s._v("的问题. 还需要一个能够执行高效查询的容器, 存放所有主机及其状态. 红黑树虽然不慢, 但由于不再需要遍历容器, 所以可以选择更快的, 查询时间复杂度为 O(1) 的哈希表存放主机信息(非标哈希表的实现参见. 如下图所示.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b027dace15a3dcf6470b7c4d9fb85d7c-20230731165330-ogv1ga8.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, 队列中的心跳包并不是只能从队首删除, 否则判断宕机流程的时间复杂度仍然是 O(N). 实际上, 每当收到心跳包时, 如果对应主机的上一个心跳包还在队列中, 那么可以直接把它从队列中删除. 显然, 计算在线主机何时宕机, 只需要最新的心跳包, 老的心跳包没有必要存在. 因此, 这个队列为每个主机仅保留最新的那个心跳包. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/22e77a14dfd526b3d9c5e5d2f9ec4b82-20230731165330-rn49h29.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 判断宕机的速度会非常快, 它的计算量等于实际发生宕机的主机数量. 同时, 接收心跳包并发现新主机的流程, 因为只需要做一次哈希表查询, 时间复杂度也只有 O(1).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/933c5773be972731b043e6045ce47a7f-20230731165330-e1x9onx.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 新算法通过"),t("strong",[s._v("以空间换时间")]),s._v("的思想, 虽然使用了更加占用空间的哈希表, 并新增了有序队列容器, 但将宕机和新主机发现这两个流程都优化到了常量级的时间复杂度. 尤其是宕机流程的计算量非常小, 它仅与实际宕机服务的数量有关, 这就允许将宕机判断流程插入到心跳包的处理流程中, 以微观上的分时任务实现宏观上的并发, 同时也避免了对哈希表的加锁.")]),s._v(" "),t("h5",{attrs:{id:"_2-如何设计高并发架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何设计高并发架构"}},[s._v("#")]),s._v(" 2.如何设计高并发架构?")]),s._v(" "),t("p",[s._v("有了核心算法, 还需要充分"),t("strong",[s._v("利用服务器资源的架构")]),s._v(", 才能实现高并发.")]),s._v(" "),t("p",[s._v("一颗 1GHZ 主频的 CPU, 意味着一秒钟只有 "),t("strong",[s._v("10 亿个时钟周期")]),s._v("可以工作, 如果心跳服务每秒接收到 100 万心跳包, 就要求它必须在 1000 个时钟周期内处理完一个心跳包. 这无法做到, 因为每一个汇编指令的执行需要多个时钟周期(参见CPI), 一条高级语言的语句又由多条汇编指令构成, 而中间件提供的反序列化等函数又需要很多条语句才能完成. 另外, 内核从网卡上读取报文, 执行协议分析需要的时钟周期也要算到这 1000 个时钟周期里.")]),s._v(" "),t("p",[s._v("因此, 选择只用一颗 CPU 为核心的单线程开发模式, 一定会出现计算力不足, 不能及时接收报文从而使得缓冲区溢出的问题, 最终导致大量丢包. 所以, 必须选择多线程或者多进程开发模式. 多进程之间干扰更小, 但内存不是共享的, 数据同步较为困难, 因此案例中还是选择多线程开发模式.")]),s._v(" "),t("p",[s._v("使用多线程后需要解决 3 个问题.")]),s._v(" "),t("p",[s._v("第一是"),t("strong",[s._v("负载均衡")]),s._v(", 应当把心跳包尽量均匀分配到不同的工作线程上处理. 比如, 接收网络报文的线程基于主机名或者 IP 地址, 用哈希算法将心跳包分发给工作线程处理, 这样每个工作线程只处理特定主机的心跳, 相互间不会互相干扰, 从而可以无锁编程.")]),s._v(" "),t("p",[s._v("第二是"),t("strong",[s._v("多线程同步")]),s._v(". 分发线程与工作线程间可以采用生产者-消费者模型传递心跳包, 然而多线程间传递数据要加锁, 为了减少争抢锁对系统资源的消耗, 需要做到以下两点:")]),s._v(" "),t("ol",[t("li",[s._v("由于工作线程多过分发线程(接收心跳包消耗的资源更少), 所以每个工作线程都配发"),t("strong",[s._v("独立的缓冲队列及操作队列")]),s._v("的互斥锁;")]),s._v(" "),t("li",[s._v("为避免线程执行主动切换, 必须使用"),t("strong",[s._v("自旋锁")]),s._v(". 如下图所示:")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/6635c2703237f022577c3b77e988fa32-20230731165330-bcvf645.png",alt:""}})]),s._v(" "),t("p",[s._v("第三要"),t("strong",[s._v("解决 CPU 亲和性问题")]),s._v(". CPU 缓存对计算速度的影响很大, 如果线程频繁地切换 CPU 会导致缓存命中率下降, 降低性能, 此时"),t("strong",[s._v("将线程绑定到特定的 CPU 就是一个解决方案")]),s._v("(NUMA 架构也会对 CPU 亲和性产生影响, 这里略过).")]),s._v(" "),t("p",[s._v("这样, 通过上述的多线程架构就可以有效地使用 CPU. 当然, 除了 CPU, 内存的使用效率也很重要. 前面提到, TCMalloc 相比 Linux 默认的 PtMalloc2 内存池, 在多线程下分配小块内存的速度要快得多, 所以对于心跳服务应当改用 TCMalloc 申请内存. 而且, 如果心跳包对象的格式已经固定, 还可以建立一个心跳包资源池, 循环往复的使用, 这进一步减少了构造, 销毁心跳包对象所消耗的计算力.")]),s._v(" "),t("h5",{attrs:{id:"_3-如何选择心跳包网络协议"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何选择心跳包网络协议"}},[s._v("#")]),s._v(" 3.如何选择心跳包网络协议?")]),s._v(" "),t("p",[s._v("最后再来看看心跳包的协议该选择 TCP 还是 UDP 实现.")]),s._v(" "),t("p",[t("strong",[s._v("网络报文的长度是受限的, MTU(Maximum Transmission Unit)定义了最大值")]),s._v(". 比如以太网中 MTU 是 1500 字节, 如果 TCP 或者 UDP 试图传送大于 1500 字节的报文, IP 协议就会把报文拆分后再发到网络中, 并在接收方组装回原来的报文. 然而, IP 协议并不擅长做这件事, 拆包组包的效率很低, 因此 TCP 协议宁愿自己拆包.")]),s._v(" "),t("p",[s._v("所以, "),t("strong",[s._v("如果心跳包长度小于 MTU, 那么 UDP 协议是最佳选择. 如果心跳包长度大于 MTU, 那么最好选择 TCP 协议")]),s._v(", 面对复杂的 TCP 协议, 还需要解决以下问题.")]),s._v(" "),t("p",[s._v("首先, 一台服务器到底能同时建立多少 TCP 连接? 要回答这个问题, 得先从 TCP 四元组谈起, 它唯一确定一个 TCP 连接. TCP 四元组分别是 "),t("code",[s._v("<源 IP, 目的 IP, 源端口, 目的端口>")]),s._v("​, 其中前两者在 IP 头部中, 后两者在 TCP 头部中.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/222915b1cd941e50216474d19915e595-20230731165330-cy8y5u0.png",alt:""}})]),s._v(" "),t("p",[s._v("由于 IPv4 地址为 4 个字节, 端口为 2 个字节, 所以当服务器 IP 地址和监听端口固定时, 并发连接数的上限则是 2(32+16).")]),s._v(" "),t("p",[s._v("当然, 这么高的并发连接需要很多条件, 其中之一就是"),t("strong",[s._v("增加单个进程允许打开的最大句柄数")]),s._v("(包括操作系统允许的最大句柄数 "),t("code",[s._v("/proc/sys/fs/file-nr")]),s._v("​), 因为 Linux 下每个连接都要用掉一个文件句柄. 当然, 作为客户端的主机如果想用足 216 端口, 还得修改 ip_local_port_range 配置, 扩大客户端的端口范围:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.ip_local_port_range "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32768")]),s._v("    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("60999")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("其次, 基于 TCP 协议实现百万级别的高并发, 必须使用"),t("strong",[s._v("基于事件驱动的全异步开发模式")]),s._v(". 而且, TCP 协议的默认配置并没有考虑高并发场景, 所以还得在以下 4 个方面优化 TCP 协议:")]),s._v(" "),t("ul",[t("li",[s._v("三次握手建立连接的过程需要优化;")]),s._v(" "),t("li",[s._v("四次挥手关闭连接的过程也需要优化;")]),s._v(" "),t("li",[s._v("依据网络带宽时延积重新设置 TCP 缓冲区;")]),s._v(" "),t("li",[s._v("优化拥塞控制算法.")])]),s._v(" "),t("p",[s._v("最后还有一个问题需要考虑. 网络中断时并没有任何信息通知服务器, 此时该如何发现并清理服务器上的这些僵死连接呢? KeepAlive 机制允许服务器定时向客户端探测连接是否存活. 其中, 每隔 tcp_keepalive_time 秒执行一次探测.")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.tcp_keepalive_time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7200")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("每次探测的最大等待时间是 tcp_keepalive_intvl 秒.")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.tcp_keepalive_intvl "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("75")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("超时后, 内核最多尝试 tcp_keepalive_probes 次, 仍然没有反应就会及时关闭连接.")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("net.ipv4.tcp_keepalive_probes "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("当然, 如果在应用层通过心跳能及时清理僵死 TCP 连接, 效果会更好.")]),s._v(" "),t("p",[s._v("从上述优化方案可见, TCP 协议的高并发优化方案还是比较复杂的, 这也是享受 TCP 优势时必须要付出的代价.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-9"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-9"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节以我实践过的项目为案例, 介绍了高并发服务的设计思路.")]),s._v(" "),t("p",[t("strong",[s._v("核心算法对性能的影响最大")]),s._v(", 为了设计出高效的算法, 必须分析出时间复杂度, 充分寻找, 利用已知信息, 减少算法的计算量. 在心跳服务这个案例中, 利用好心跳包的时序, 就可以把计算宕机的时间复杂度从 O(N) 降为 O(1).")]),s._v(" "),t("p",[s._v("有了好的算法, 还需要"),t("strong",[s._v("好的架构")]),s._v(", 才能高效地调动系统资源. 当摩尔定律在 CPU 频率上失效后, CPU 都在向多核发展, 所以高性能必须充分使用多核的计算力. 此时, 需要谨慎设计多线程间的负载均衡和数据同步, 尽量减少访问共享资源带来的损耗. 选择与业务场景匹配的内存池也很重要, 对于 RPS 上百万的服务来说, 申请内存的时间不再是一个忽略项.")]),s._v(" "),t("p",[s._v("选择网络协议时, 如果消息长度大于 MTU, 那么选择 TCP 更有利, 但 TCP 解决了流控, 可靠性等很多问题, 优化起来较为困难. 对于不要求可靠传输, 长度通常不大的心跳包来说, UDP 协议通常是更好的选择.")]),s._v(" "),t("h3",{attrs:{id:"应用层编解码优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#应用层编解码优化"}},[s._v("#")]),s._v(" 应用层编解码优化")]),s._v(" "),t("h4",{attrs:{id:"_14-优化tls-ssl性能该从何下手"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14-优化tls-ssl性能该从何下手"}},[s._v("#")]),s._v(" 14-优化TLS/SSL性能该从何下手?")]),s._v(" "),t("p",[s._v("从这一讲开始进入"),t("strong",[s._v("应用层协议")]),s._v("的处理.")]),s._v(" "),t("p",[s._v("信息安全在当下越来越重要, 绝大多数站点访问时都使用 "),t("code",[s._v("https://")]),s._v("​ 替代了 "),t("code",[s._v("http://")]),s._v("​, 这就是在用 "),t("code",[s._v("TLS/SSL")]),s._v("​ 协议(下文简称为 TLS 协议)来保障应用层消息的安全. 但另一方面, 你会发现很多图片类门户网站, 还在使用 "),t("code",[s._v("http://")]),s._v("​, 这是因为 TLS 协议在对信息加解密的同时, 必然会降低性能和用户体验, 这些站点在权衡后选择了性能优先.")]),s._v(" "),t("p",[s._v("实际上, TLS 协议由一系列加密算法及规范组成, 这些算法的安全性和性能各不相同, 甚至与你的系统硬件相关. 比如当主机的 CPU 支持 AES-NI 指令集时, 选择 AES 对称加密算法便可以大幅提升性能. 然而, 要想选择合适的算法, 需要了解算法所用到的一些数学知识, 而很多同学由于忽视了数学原理便难以正确地配置 TLS 算法.")]),s._v(" "),t("p",[s._v("同时, TLS 协议优化时也需要了解网络和软件工程知识, 比如可以在网络的不同位置缓存密钥来优化性能. 而且, TLS 协议还可以优化其他应用层协议的性能, 比如从 "),t("code",[s._v("HTTP/1")]),s._v("​ 升级到 "),t("code",[s._v("HTTP/2")]),s._v("​ 协议便可以通过 TLS 协议减少 1 个 RTT 的时间.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("优化 TLS 性能究竟该从何下手呢? 在我看来主要有两个方向, 一是对称加密算法的性能优化, 二是如何高效地协商密钥")])]),s._v(". 下面来详细看看优化细节.")]),s._v(" "),t("h5",{attrs:{id:"_1-如何提升对称加密算法的性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何提升对称加密算法的性能"}},[s._v("#")]),s._v(" 1.如何提升对称加密算法的性能?")]),s._v(" "),t("p",[s._v("如果 Wireshark 等工具对 HTTPS 请求抓包分析, 会发现在 TCP 传输层之上的消息全是乱码, 这是因为 TCP 之上的 TLS 层, 把 HTTP 请求用对称加密算法重新进行了编码. "),t("strong",[s._v("当然, 用 Chrome 浏览器配合 Wireshark 可以解密消息, 进而分析 TLS 协议的细节")]),s._v(".")]),s._v(" "),t("p",[s._v("现代对称加密算法的特点是, 即使把加密流程向全社会公开, 攻击者也从公网上截获到密文, 但只要他没有拿到密钥, 就无法从密文中反推出原始明文. 如何同步密钥稍后在谈, 先来看如何优化对称加密算法.")]),s._v(" "),t("p",[s._v("目前主流的对称加密算法叫做 AES(Advanced Encryption Standard), 它在性能和安全上表现都很优秀. 而且, 它不只在访问网站时最为常用, 甚至日常使用的 WINRAR 等压缩软件也在使用 AES 算法. "),t("strong",[s._v("因此, AES 是首选对称加密算法,")]),s._v("  下面来看看 AES 算法该如何优化.")]),s._v(" "),t("p",[s._v("**AES 只支持 3 种不同的密钥长度, 分别是 128 位, 192 位和 256 位, 它们的安全性依次升高, 运算时间也更长. **比如, 当密钥为 128 比特位时, 需要经过十轮操作, 其中每轮要用移位法, 替换法, 异或操作等对明文做 4 次变换. 而当密钥是 192 位时, 则要经过 12 轮操作, 密钥为 256 比特位时, 则要经过 14 轮操作, 如下图所示.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e95e0cecaf77c4e59f268e1b73056e6e-20230731165330-15l5muj.png",alt:""}})]),s._v(" "),t("p",[s._v("密钥越长, 虽然性能略有下降, 但安全性提升很多. 比如早先的 DES 算法只有 56 位密钥, 在 1999 年便被破解. "),t("strong",[s._v("在 TLS1.2 及更早的版本中, 仍然允许通讯双方使用 DES 算法, 这是非常不安全的行为, 你应该在服务器上限制 DES 算法套件的使用")]),s._v(". 也正因为密钥长度对安全性的巨大影响, 美国政府才不允许出口 256 位密钥的 AES 算法.")]),s._v(" "),t("p",[s._v("只有数百比特的密钥, 到底该如何对任意长度的明文加密呢? 主流对称算法会将原始明文分成等长的多组明文, 再分别用密钥生成密文, 最后把它们拼接在一起形成最终密文. 而 AES 算法是按照 128 比特(16 字节)对明文进行分组的(最后一组不足 128 位时会填充 0 或者随机数). 为了防止分组后密文出现明显的规律, 造成攻击者容易根据概率破解出原文, 我们就需要对每组的密钥做一些变换, "),t("strong",[s._v("这种分组后变换密钥的算法就叫做分组密码工作模式(下文简称为分组模式), 它是影响 AES 性能的另一个因素.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a2dbfb52237f48e29fb7b25f3f2e86ca-20230731165330-2ks6shy.png",alt:""}})]),s._v(" "),t("p",[s._v("比如, CBC 分组模式中, 只有第 1 组明文加密完成后, 才能对第 2 组加密, 因为第 2 组加密时会用到第 1 组生成的密文. 因此, CBC 必然无法并行计算. 在材料科学出现瓶颈, 单核频率不再提升的当下, CPU 都在向多核方向发展, 而 CBC 分组模式无法使用多核的并行计算能力, 性能受到很大影响. "),t("strong",[s._v("所以, 通常应选择可以并行计算的 GCM 分组模式, 这也是当下互联网中最常见的 AES 分组算法.")])]),s._v(" "),t("p",[s._v("由于 AES 算法中的替换法, 行移位等流程对 CPU 指令并不友好, 所以 Intel 在 2008 年推出了支持 AES-NI 指令集的 CPU, 能够将 AES 算法的执行速度从每字节消耗 28 个时钟周期, 降低至 3.5 个时钟周期. 在 Linux 上可以用下面这行命令查看 CPU 是否支持 AES-NI 指令集:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# sort -u /proc/crypto | grep module |grep aes")]),s._v("\nmodule       "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" aesni_intel\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[t("strong",[s._v("因此, 如果 CPU 支持 AES-NI 特性, 那么应选择 AES 算法, 否则可以选择")]),s._v("​******CHACHA20****** "),t("strong",[s._v("对称加密算法, 它主要使用 ARX 操作(add-rotate-xor), CPU 执行起来更快.")])]),s._v(" "),t("h5",{attrs:{id:"_2-如何更快地协商出密钥"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何更快地协商出密钥"}},[s._v("#")]),s._v(" 2.如何更快地协商出密钥?")]),s._v(" "),t("p",[s._v("说完对称加密算法的优化, 再来看"),t("strong",[s._v("加密时的密钥是如何传递的")]),s._v(".")]),s._v(" "),t("p",[s._v("无论对称加密算法有多么安全, 一旦密钥被泄露, 信息安全就是一纸空谈. 所以, TLS 建立会话的第 1 个步骤是"),t("strong",[s._v("在握手阶段协商出密钥")]),s._v(".")]),s._v(" "),t("p",[s._v("早期解决密钥传递的是 RSA 密钥协商算法. 当部署 TLS 证书到服务器上时, 证书文件中包含一对公私钥(参见非对称加密), 其中, "),t("strong",[s._v("公钥会在握手阶段传递给客户端")]),s._v(". 在 RSA 密钥协商算法中, 客户端会"),t("strong",[s._v("生成随机密钥")]),s._v("(事实上是生成密钥的种子参数), "),t("strong",[s._v("并使用服务器的公钥加密后再传给服务器. 根据非对称加密算法, 公钥加密的消息仅能通过私钥解密, 这样服务器解密后, 双方就得到了相同的密钥, 再用它加密应用消息")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("RSA 密钥协商算法的最大问题是不支持前向保密")]),s._v("(Forward Secrecy), 一旦服务器的私钥泄露, 过去被攻击者截获的所有 TLS 通讯密文都会被破解. 解决前向保密的是 "),t("strong",[s._v("DH(Diffie–Hellman)密钥协商算法")]),s._v(".")]),s._v(" "),t("p",[s._v("简单看下 DH 算法的工作流程. 通讯双方各自独立生成随机的数字作为私钥, 而后依据公开的算法计算出各自的公钥, 并通过未加密的 TLS 握手发给对方. 接着, 根据对方的公钥和自己的私钥, 双方各自独立运算后能够获得相同的数字, 这就可以作为后续对称加密时使用的密钥. "),t("strong",[s._v("即使攻击者截获到明文传递的公钥, 查询到公开的 DH 计算公式后, 在不知道私钥的情况下, 也是无法计算出密钥的.")]),s._v("  这样 DH 算法就可以在握手阶段生成随机的新密钥, 实现前向保密.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8a04a9a79df68695f4a6dec8365dc821-20230731165330-n8p2qyu.png",alt:""}})]),s._v(" "),t("p",[s._v("DH 算法的计算速度很慢, 如上图所示, 计算公钥以及最终的密钥时, 需要做大量的乘法运算, 而且为了保障安全性, 这些数字的位数都很长. 为了提升 DH 密钥交换算法的性能, 诞生了当下广为使用的 ECDH 密钥交换算法, "),t("strong",[s._v("ECDH 在 DH 算法的基础上利用")]),s._v("​******ECC 椭圆曲线**"),t("strong",[t("strong",[s._v("​")]),s._v("特性, 可以用更少的计算量计算出公钥以及最终的密钥.")])]),s._v(" "),t("p",[s._v("依据解析几何, 椭圆曲线实际对应一个函数, 而不同的曲线便有不同的函数表达式, 目前不被任何已知专利覆盖的最快椭圆曲线是 X25519 曲线, 它的表达式是 "),t("code",[s._v("y2 = x3 + 486662x2 + x")]),s._v("​. 因此, 当通讯双方协商使用 X25519 曲线用于 ECDH 算法时, 只需要传递 X25519 这个字符串即可. 在 Nginx 上, 可以使用 ssl_ecdh_curve 指令配置想使用的曲线:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("ssl_ecdh_curve X25519:secp384r1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("选择密钥协商算法是通过 ssl_ciphers 指令完成的:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("ssl_ciphers "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'EECDH+ECDSA+AES128+SHA:RSA+AES128+SHA'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("可见, ssl_ciphers 可以同时配置对称加密算法及密钥强度等信息. 注意, 当 ssl_prefer_server_ciphers 设置为 on 时, ssl_ciphers 指定的多个算法是有优先顺序的, "),t("strong",[s._v("应当把性能最快且最安全的算法放在最前面.")])]),s._v(" "),t("p",[s._v("提升密钥协商速度的另一个思路, 是减少密钥协商的次数, 主要包括以下 3 种方式.")]),s._v(" "),t("p",[s._v("首先, 最为简单有效的方式是"),t("strong",[s._v("在一个 TLS 会话中传输多组请求")]),s._v(", 对于 HTTP 协议而言就是使用长连接, 在请求中加入 "),t("code",[s._v("Connection: keep-alive")]),s._v("​ 头部便可以做到.")]),s._v(" "),t("p",[s._v("其次, "),t("strong",[s._v("客户端与服务器在首次会话结束后缓存下 session 密钥, 并用唯一的 session ID 作为标识")]),s._v(". 这样, 下一次握手时, 客户端只要把 session ID 传给服务器, 且服务器在缓存中找到密钥后(为了提升安全性, 缓存会定期失效), 双方就可以加密通讯了. 这种方式的问题在于, 当 N 台服务器通过负载均衡提供 TLS 服务时, 客户端命中上次访问过的服务器的概率只有 1/N, 所以大概率它们还得再次协商密钥.")]),s._v(" "),t("p",[t("strong",[s._v("session ticket 方案可以解决上述问题, 它把服务器缓存密钥, 改为由服务器把密钥加密后作为 ticket 票据发给客户端, 由客户端缓存密文")]),s._v(". 其中, 集群中每台服务器对 session 加密的密钥必须相同, 这样, 客户端携带 ticket 密文访问任意一台服务器时, 都能通过解密 ticket, 获取到密钥.")]),s._v(" "),t("p",[s._v("当然, 使用 session 缓存或者 session ticket 既没有前向安全性, 应对重放攻击也更加困难. 提升 TLS 握手性能的更好方式, 是把 TLS 协议升级到 1.3 版本.")]),s._v(" "),t("h5",{attrs:{id:"_3-为什么应当尽快升级到tls1-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-为什么应当尽快升级到tls1-3"}},[s._v("#")]),s._v(" 3.为什么应当尽快升级到TLS1.3?")]),s._v(" "),t("p",[t("strong",[s._v("TLS1.3(参见 RFC8446)对性能的最大提升, 在于它把 TLS 握手时间从 2 个 RTT 降为 1 个 RTT.")])]),s._v(" "),t("p",[s._v("在 TLS1.2 的握手中, 先要通过 Client Hello 和 Server Hello 消息协商出后续使用的加密算法, 再互相交换公钥并计算出最终密钥. "),t("strong",[s._v("TLS1.3 中把 Hello 消息和公钥交换合并为一步, 这就减少了一半的握手时间")]),s._v(", 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3e7bff22471726a05341466ca078e9f3-20230731165330-bsno9cl.png",alt:""}})]),s._v(" "),t("p",[s._v("那 TLS1.3 握手为什么只需要 1 个 RTT 就可以完成呢? 因为 TLS1.3 "),t("strong",[s._v("支持的密钥协商算法大幅度减少")]),s._v("了, 这样客户端尽"),t("strong",[s._v("可以把常用 DH 算法的公钥计算出来, 并与协商加密算法的 HELLO 消息一起发送给服务器, 服务器也作同样处理, 这样仅用 1 个 RTT 就可以协商出密钥")]),s._v(".")]),s._v(" "),t("p",[s._v("而且, TLS1.3 仅支持目前最安全的几个算法, 比如 openssl 中仅支持下面 5 种安全套件:")]),s._v(" "),t("ol",[t("li",[s._v("TLS_AES_256_GCM_SHA384")]),s._v(" "),t("li",[s._v("TLS_CHACHA20_POLY1305_SHA256")]),s._v(" "),t("li",[s._v("TLS_AES_128_GCM_SHA256")]),s._v(" "),t("li",[s._v("TLS_AES_128_CCM_8_SHA256")]),s._v(" "),t("li",[s._v("TLS_AES_128_CCM_SHA256")])]),s._v(" "),t("p",[s._v("相较起来, TLS1.2 支持各种古老的算法, 中间人可以利用降级攻击, 在握手阶段把加密算法替换为不安全的算法, 从而轻松地破解密文. 如前文提到过的 DES 算法, 由于密钥位数只有 56 位, 很容易破解.")]),s._v(" "),t("p",[s._v("因此, "),t("strong",[s._v("无论从性能还是安全角度上, 都应该尽快把 TLS 版本升级到 1.3.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/54766f30fce2a974ae5ba001a453b8be-20230731165330-xcn13xt.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_4-小结-10"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-10"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节介绍了 TLS 协议的优化方法.")]),s._v(" "),t("p",[s._v("应用消息是通过对称加密算法编码的, 而目前 AES 还是最安全的对称加密算法. 不同的分组模式也会影响 AES 算法的性能, 而 GCM 模式能够充分利用多核 CPU 的并行计算能力, 所以 AES_GCM 是我们的首选. 当 CPU 支持 AES-NI 指令集时, AES 算法的执行会非常快, 否则可以考虑对 CPU 更友好的 CHACHA20 算法.")]),s._v(" "),t("p",[s._v("再来看对称加密算法的密钥是如何传递的, 它决定着 TLS 系统的安全, 也对 HTTP 小对象的传输速度有很大影响. DH 密钥协商算法速度并不快, 因此目前主要使用基于椭圆曲线的 ECDH 密钥协商算法, 其中, 不被任何专利覆盖的 X25519 椭圆曲线速度最快. 为了减少密钥协商次数, 应当尽量"),t("strong",[s._v("通过长连接来复用会话")]),s._v(". 在 TLS1.2 及早期版本中, session 缓存和 session ticket 也能减少密钥协商时的计算量, 但它们既没有前向安全性, 也更难防御重放攻击, 所以为了进一步提升性能, 应当"),t("strong",[s._v("尽快升级到 TLS1.3")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("TLS1.3 将握手时间从 2 个 RTT 降为 1 个 RTT, 而且它限制了目前已经不再安全的算法, 这样中间人就难以用降级攻击来破解密钥.")])]),s._v(" "),t("h4",{attrs:{id:"_15-如何提升http-1-1性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15-如何提升http-1-1性能"}},[s._v("#")]),s._v(" 15-如何提升HTTP/1.1性能?")]),s._v(" "),t("p",[s._v("上一讲介绍了为应用层信息安全保驾护航的 TLS/SSL 协议, 这一讲来看看最常用的"),t("strong",[s._v("应用层协议 HTTP/1.1 该如何优化")]),s._v(".")]),s._v(" "),t("p",[s._v("由于门槛低, 易监控, 自表达等特点, HTTP/1.1 在互联网诞生之初就成为最广泛使用的应用层协议. 然而它的性能却很差, 最为人诟病的是 HTTP 头部的传输占用了大量带宽. 由于 HTTP 头部使用 ASCII 编码方式, 这造成它往往达到几 KB, 而且"),t("strong",[s._v("滥用的 Cookie 头部进一步增大了体积")]),s._v(". 与此同时, REST 架构的无状态特性还要求每个请求都得重传 HTTP 头部, 这就使消息的有效信息比重难以提高.")]),s._v(" "),t("p",[s._v("你可能听说过诸如缓存, 长连接, 图片拼接, 资源压缩等优化 HTTP 协议性能的方式, 这些优化方案有些从底层的传输层优化入手, 有些从用户使用浏览器的体验入手, 有些则从服务器资源的编码入手, 五花八门, 导致我们没有系统化地优化思路, 往往在性能提升上难尽全功.")]),s._v(" "),t("p",[s._v("那么, "),t("strong",[s._v("如何全面地提升 HTTP/1.1 协议的性能呢")]),s._v("? 我认为在不升级协议的情况下, 有 3 种优化思路: "),t("strong",[s._v("首先是通过缓存避免发送 HTTP 请求; 其次, 如果不得不发起请求, 那么就得思考如何才能减少请求的个数; 最后则是减少服务器响应的体积")]),s._v(".")]),s._v(" "),t("p",[s._v("接下来就沿着这 3 个思路看看具体的优化方法.")]),s._v(" "),t("h5",{attrs:{id:"_1-通过缓存避免发送http请求"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-通过缓存避免发送http请求"}},[s._v("#")]),s._v(" 1.通过缓存避免发送HTTP请求")]),s._v(" "),t("p",[s._v("如果不走网络就能获得 HTTP 响应, 这样性能肯定最高. HTTP 协议设计之初就考虑到了这一点, "),t("strong",[s._v("缓存能够让客户端在免于发送 HTTP 请求的情况下获得服务器的资源")]),s._v(".")]),s._v(" "),t("p",[s._v("缓存到底是如何做到的呢? 其实很简单, 它从时间维度上做文章, 把第 1 份请求及其响应保存在客户端的本地磁盘上, 其中请求的 URL 作为关键字(部分 HTTP 头部也会加入关键字, 例如确定服务器域名的 Host 头部), 而响应就是值. 这样, 后续发起相同的请求时, 就可以先在本地磁盘上通过关键字查找, 如果找到了, 就直接将缓存作为服务器响应使用. 读取本地磁盘耗时不过几十毫秒, 这远比慢了上百倍且不稳定的网络请求快得多.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2bb475551410d037f0a7746b4ce44190-20230731165330-mg1fnrt.png",alt:""}})]),s._v(" "),t("p",[s._v("你可能会问, 服务器上的资源更新后, 客户端并不知道, 它若再使用过期的缓存就会出错, 这该如何解决? 因此, "),t("strong",[s._v("服务器会在发送响应时预估一个过期时间并在响应头部中告诉客户端, 而客户端一旦发现缓存过期则重新发起网络请求")]),s._v('. HTTP 协议控制缓存过期的头部非常多, 而且通常这是在服务器端设置的, 这个会在本专栏的第 4 部分 "分布式系统优化" 结合服务器操作再来介绍, 这里暂时略过.')]),s._v(" "),t("p",[s._v("当然, 过期的缓存也仍然可以提升性能, 如下图所示, 当客户端发现缓存过期后, 会取出缓存的摘要(摘要是从第 1 次请求的响应中拿到的), 把它放在请求的 "),t("strong",[s._v("Etag")]),s._v(" 头部中再发给服务器. 而服务器获取到请求后, 会将本地资源的摘要与请求中的 Etag 相比较, "),t("strong",[s._v("如果不同, 那么缓存没有价值, 重新发送最新资源即可")]),s._v("; 如果摘要与 Etag 相同, 那么仅返回不含有包体的 304 Not Modified 响应, 告知客户端缓存仍然有效即可, 这就省去传递可能高达千百兆的文件资源.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8abe0fcb63a1e611e47eea4433059c67-20230731165330-mtenrdj.png",alt:""}})]),s._v(" "),t("p",[s._v("至于 Etag 摘要究竟是怎样生成的, 各类 Web 服务器的处理方式不尽相同, 比如 Nginx 会将文件大小和修改时间拼接为一个字符串作为文件摘要. 过期缓存在分布式系统中可以有效提升可用性, 后面还会站在反向代理的角度介绍过期缓存的用法.")]),s._v(" "),t("p",[t("strong",[s._v("浏览器上的缓存只能为一个用户使用, 故称为私有缓存. 代理服务器上的缓存可以被许多用户使用, 所以称为共享缓存")]),s._v(". 可见, 共享缓存带来的性能收益被庞大的客户端群体放大了. 可以看到在下面的 REST 架构图中, 表示缓存的 "),t("code",[s._v("$")]),s._v("​ 符号(缓存的英文名称是 cache, 由于它的发音与 cash 很像, 所以许多英文文档中用美元符号来表示缓存)既存在于 User Agent 浏览器中, 也存在于 Proxy 正向代理服务器和 Gateway 反向代理上.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0404ee14eb1305640b3acf01cb63f9cc-20230731165330-ik5mmsw.png",alt:""}})]),s._v(" "),t("p",[s._v("可见, 缓存与互联网世界的网络效率密切相关, 用好缓存是提升 HTTP 性能最重要的手段.")]),s._v(" "),t("h5",{attrs:{id:"_2-如何降低http请求的次数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何降低http请求的次数"}},[s._v("#")]),s._v(" 2.如何降低HTTP请求的次数?")]),s._v(" "),t("p",[s._v("如果不得不发起请求, 就应该尽量减少 HTTP 请求的次数, 这可以从"),t("mark",[t("strong",[s._v("减少重定向次数, 合并请求, 延迟发送请求")])]),s._v("等 3 个方面入手.")]),s._v(" "),t("p",[s._v("首先来看看什么是重定向请求, 一个资源由于迁移, 维护等原因从 url1 移至 url2 后, 在客户端访问原先的 url1 时, 服务器不能简单粗暴地返回错误, 而是通过 302 响应码及 Location 头部, 告诉客户端资源已经改到 url2 了, 而客户端再用 url2 发起新的 HTTP 请求.")]),s._v(" "),t("p",[s._v("可见, 重定向增加了请求的数量. 尤其客户端在公网中时, 由于公网速度慢, 成本高, 路径长, 不稳定, 而且为了信息安全性还要用 TLS 协议加密, 这些都降低了网络性能. 从上面的 REST 架构图可以看到, HTTP 请求会经过多个代理服务器, 如果将重定向工作交由代理服务器完成, 就能减少网络消耗, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/5c090e9e80703c094ea7d55ee54faf3e-20230731165330-af0rkk9.png",alt:""}})]),s._v(" "),t("p",[s._v("更进一步, "),t("strong",[s._v("客户端还可以缓存重定向响应")]),s._v(". RFC 规范定义了 5 个重定向响应码(如下表所示), 其中客户端接收到 301 和 308 后都可以将重定向响应缓存至本地, 之后客户端会自动用 url2 替代 url1 访问网络资源.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/9f522af883f5dcd6d28a1dd7311cce35-20230731165330-uoj8laz.png",alt:""}})]),s._v(" "),t("p",[s._v("其次来看如何合并请求. 当多个访问小文件的请求被合并为一个访问大文件的请求时, 这样虽然传输的总资源体积未变, 但减少请求就意味着"),t("strong",[s._v("减少了重复发送的 HTTP 头部, 同时也减少了 TCP 连接的数量")]),s._v(", 因而省去了 TCP 握手和慢启动过程消耗的时间(参见第 12 课). 具体看几种合并请求的方式.")]),s._v(" "),t("p",[s._v("一些 WEB 页面往往含有几十, 上百个小图片, 用 CSS Image Sprites 技术可以将它们合成一张大图片, 而浏览器获得后可以根据 CSS 数据把它切割还原为多张小图片, 这可以大幅减少网络消耗.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7ffc575a3c772747e78ca6cbb38f0890-20230731165330-oto5egc.png",alt:""}})]),s._v(" "),t("p",[s._v("类似地, 在服务器端用 webpack 等打包工具将 Javascript, CSS 等资源合并为大文件, 也能起到同样的效果.")]),s._v(" "),t("p",[s._v("除此以外, 还可以将多媒体资源用 base64 编码后, 以 URL 的方式嵌入 HTML 文件中, 以减少小请求的个数(参见RFC2397).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0d263d1de818917306d490ca3eec016d-20230731165330-79i4rnu.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, 这种合并请求的方式也会带来一个新问题, 即, 当其中一个资源发生变化后, 客户端必须"),t("strong",[s._v("重新下载完整的大文件")]),s._v(", 这显然会带来额外的网络消耗. 在落后的 HTTP/1.1 协议中, 合并请求还算一个不错的解决方案, 在下一讲将介绍的 "),t("strong",[s._v("HTTP/2 出现后, 这种技术就没有用武之地")]),s._v("了.")]),s._v(" "),t("p",[s._v("最后还可以从浏览页面的体验角度上, 减少 HTTP 请求的次数. 比如, 有些 HTML 页面上引用的资源, 其实在当前页面上用不上, 而是供后续页面使用的, 这就可以使用"),t("strong",[s._v("懒加载")]),s._v("(lazy loading) 技术延迟发起请求.")]),s._v(" "),t("p",[s._v("当不得不发起请求时, 还可以从服务器的角度通过减少响应包体的体积来提升性能.")]),s._v(" "),t("h5",{attrs:{id:"_3-如何重新编码以减少响应的大小"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何重新编码以减少响应的大小"}},[s._v("#")]),s._v(" 3.如何重新编码以减少响应的大小?")]),s._v(" "),t("p",[t("strong",[s._v("减少资源体积的唯一方式是对资源重新编码压缩")]),s._v(", 其中又分为无损压缩与有损压缩两种.")]),s._v(" "),t("p",[s._v("先来看无损压缩, 这是指压缩后不会损失任何信息, 可以完全恢复到压缩前的原样. 因此文本文件, 二进制可执行文件都会使用这类压缩方法.")]),s._v(" "),t("p",[s._v("源代码也是文本文件, 但它有自身的语法规则, 所以可以依据语法先做一轮压缩. 比如 jQuery 是用 javascript 语言编写的库, 而标准版的 jQuery.js 为了帮助程序员阅读含有许多空格, 回车等符号, 但机器解释执行时并不需要这些符号. 因此, 根据语法规则将这些多余的符号去除掉, 就可以将 jQuery 文件的体积压缩到原先的三分之一.")]),s._v(" "),t("p",[s._v("接着可以基于信息熵原理进行通用的无损压缩, 这需要对原文建立统计模型, 将出现频率高的数据用较短的二进制比特序列表示, 而将出现频率低的数据用较长的比特序列表示. 最常见的 Huffman 算法就是一种执行速度较快的实践, 在下一讲的 HTTP/2 协议中还会用到它. 在上图中可以看到, 最小版的 jQuery 文件经过 Huffman 等算法压缩后, 体积还会再缩小三分之二.")]),s._v(" "),t("p",[s._v("支持无损压缩算法的客户端会在请求中通过 Accept-Encoding 头部明确地告诉服务器:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("Accept-Encoding: gzip, deflate, br\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("而服务器也会在响应的头部中, 告诉客户端包体中的资源使用了何种压缩算法:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("content-encoding: "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("gzip")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("虽然目前 gzip 使用最为广泛, 但它的压缩效率以及执行速度其实都很一般, Google 于 2015 年推出的 Brotli 算法在这两方面表现都更优秀(也就是上文中的 br), 其对比数据如下:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ff9d21c6c5237f0827dd795b7efc9995-20230731165330-3mtvft2.png",alt:""}})]),s._v(" "),t("p",[s._v("再来看有损压缩, 它通过牺牲质量来提高压缩比, 主要针对的是图片和音视频. HTTP 请求可以通过 Accept 头部中的 q 质量因子(参见 RFC7231), 告诉服务器期望的资源质量:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("Accept: audio/*"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("q")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),s._v(", audio/basic\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("先来看图片的压缩. 目前压缩比较高的开源算法是 Google 在 2010 年推出的 WebP 格式, 你可以在这个页面看到它与 png 格式图片的对比图. 对于大量使用图片的网站, 使用它代替传统格式会有显著的性能提升.")]),s._v(" "),t("p",[s._v("动态的音视频压缩比要比表态的图片高很多! 由于音视频数据有时序关系, 且时间连续的帧之间变化很小, 因此可以在静态的关键帧之后, 使用增量数据表达后续的帧, 因此在质量略有损失的情况下, 音频体积可以压缩到原先的几十分之一, 视频体积则可以压缩到几百分之一, 比图片的压缩比要高得多. 因此, "),t("strong",[s._v("对音视频做有损压缩, 能够大幅提升网络传输的性能")]),s._v(".")]),s._v(" "),t("p",[s._v("对响应资源做压缩不只用于 HTTP/1.1 协议, 事实上它对任何信息传输场景都有效, 消耗一些 CPU 计算力在事前或者事中做压缩, 通常会给性能带来不错的提升.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-11"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-11"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节从三个方面介绍了 HTTP/1.1 协议的优化策略.")]),s._v(" "),t("p",[s._v("首先, "),t("strong",[s._v("客户端缓存响应, 可以在有效期内避免发起 HTTP 请求")]),s._v(". 即使缓存过期后, 如果服务器端资源未改变, 仍然可以通过 304 响应避免发送包体资源. 浏览器上的私有缓存, 服务器上的共享缓存, 都对 HTTP 协议的性能提升有很大意义.")]),s._v(" "),t("p",[s._v("其次是"),t("strong",[s._v("降低请求的数量")]),s._v(", 如将原本由客户端处理的重定向请求, 移至代理服务器处理可以减少重定向请求的数量. 或者从体验角度, 使用懒加载技术延迟加载部分资源, 也可以减少请求数量. 再比如, 将多个文件合并后再传输, 能够少传许多 HTTP 头部, 而且减少 TCP 连接数量后也省去握手和慢启动的消耗. 当然合并文件的副作用是小文件的更新, 会导致整个合并后的大文件重传.")]),s._v(" "),t("p",[s._v("最后可以通过"),t("strong",[s._v("压缩响应来降低传输的字节数")]),s._v(", 选择更优秀的压缩算法能够有效降低传输量, 比如用 Brotli 无损压缩算法替换 gzip, 或者用 WebP 格式替换 png 等格式图片等.")]),s._v(" "),t("p",[s._v("但其实在 "),t("code",[s._v("HTTP/1.1")]),s._v("​ 协议上做优化效果总是有限的, 下一讲还将介绍在 URL, 头部等高层语法上向前兼容的 "),t("code",[s._v("HTTP/2")]),s._v("​ 协议, 它在性能上有大幅度提升, 是如 gRPC 等应用层协议的基础.")]),s._v(" "),t("h4",{attrs:{id:"_16-http-2是怎样提升性能的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_16-http-2是怎样提升性能的"}},[s._v("#")]),s._v(" 16-HTTP/2是怎样提升性能的?")]),s._v(" "),t("p",[s._v("上一讲从多个角度优化 HTTP/1 的性能, 但获得的收益都较为有限, 而直接将其升级到兼容 "),t("code",[s._v("HTTP/1")]),s._v("​ 的 "),t("code",[s._v("HTTP/2")]),s._v("​ 协议, 性能会获得非常大的提升.")]),s._v(" "),t("p",[t("strong",[s._v("HTTP/2 协议既降低了传输时延也提升了并发性, 已经被主流站点广泛使用")]),s._v(". 多数 HTTP 头部都可以被压缩 90% 以上的体积, 这节约了带宽也提升了用户体验, 像 Google 的"),t("strong",[s._v("高性能协议 gRPC 也是基于 HTTP/2 协议实现的")]),s._v(".")]),s._v(" "),t("p",[s._v("目前常用的 Web 中间件都已支持 HTTP/2 协议, 然而如果你不清楚它的原理, 对于 Nginx, Tomcat 等中间件新增的"),t("strong",[s._v("流, 推送, 消息优先级")]),s._v("等 HTTP/2 配置项, 你就不知是否需要调整.")]),s._v(" "),t("p",[s._v("同时, 许多新协议都会参考 HTTP/2 优秀的设计, 如果不清楚 HTTP/2 的性能究竟高在哪里, 也就很难对当下其他应用层协议触类旁通. 而且, HTTP/2 协议也并不是毫无缺点, 到 2020 年 3 月时它的替代协议 HTTP/3 已经经历了 27 个草案, 推出在即. HTTP/3 的目标是优化传输层协议, 它会保留 HTTP/2 协议在应用层上的优秀设计. 如果你不懂 HTTP/2, 也就很难学会未来的 HTTP/3 协议.")]),s._v(" "),t("p",[s._v("所以, 这一讲就将介绍 HTTP/2 对 HTTP/1.1 协议都做了哪些改进, 从"),t("strong",[s._v("消息的编码, 传输等角度")]),s._v("说清楚性能提升点, 这样就能理解支持 HTTP/2 的中间件为什么会提供那些参数, 以及如何权衡 HTTP/2 带来的收益与付出的升级成本.")]),s._v(" "),t("h5",{attrs:{id:"_1-静态表编码能节约多少带宽"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-静态表编码能节约多少带宽"}},[s._v("#")]),s._v(" 1.静态表编码能节约多少带宽?")]),s._v(" "),t("p",[s._v("HTTP/1.1 协议最为人诟病的是 "),t("strong",[s._v("ASCII 头部编码效率太低")]),s._v(", 浪费了大量带宽. HTTP/2 使用了"),t("strong",[s._v("静态表, 动态表两种编码技术(合称为 HPACK), 极大地降低了 HTTP 头部的体积")]),s._v(", 搞清楚编码流程, 自然就会清楚服务器提供的 http2_max_requests 等配置参数的意义.")]),s._v(" "),t("p",[s._v("以一个具体的例子来观察编码流程. 每一个 HTTP/1.1 请求都会有 Host 头部, 它指示了站点的域名, 比如:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("Host: test.taohui.tech"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("r"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("算上冒号空格以及结尾的 "),t("code",[s._v("\\r\\n")]),s._v("​, 它占用了 24 字节. "),t("strong",[s._v("使用静态表及 Huffman 编码, 可以将它压缩为 13 字节, 也就是节约了 46% 的带宽!")]),s._v("  这是如何做到的呢?")]),s._v(" "),t("p",[s._v("用 Chrome 访问站点 test.taohui.tech, 并用 Wireshark 工具抓包后, 下图高亮的头部就是第 1 个请求的 Host 头部, 其中每 8 个蓝色的二进制位是 1 个字节, 报文中用了 13 个字节表示 Host 头部.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d75bbe98415432480ed70d41184f0ad5-20230731165330-c1mmf8l.png",alt:""}})]),s._v(" "),t("p",[s._v("HTTP/2 能够用 13 个字节编码原先的 24 个字节, 是依赖下面这 3 个技术.")]),s._v(" "),t("p",[s._v("首先基于二进制编码, 就不需要冒号, 空格和 \\r\\n 作为分隔符, 转而"),t("strong",[s._v("用表示长度的 1 个字节来分隔")]),s._v("即可. 比如, 上图中的 01000001 就表示 Host, 而 10001011 及随后的 11 个字节表示域名.")]),s._v(" "),t("p",[s._v("其次, 使用静态表来描述 Host 头部. 什么是静态表呢? "),t("mark",[t("strong",[s._v("HTTP/2 将 61 个高频出现的头部, 比如描述浏览器的 User-Agent, GET 或 POST 方法, 返回的 200 SUCCESS 响应等, 分别对应 1 个数字再构造出 1 张表, 并写入 HTTP/2 客户端与服务器的代码中. 由于它不会变化, 所以也称为静态表")])]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3071d7ee20e772ca17f436dc4a47bd9f-20230731165330-9p381cv.png",alt:""}})]),s._v(" "),t("p",[s._v("这样收到 01000001 时, 根据 RFC7541 规范, 前 2 位为 01 时, 表示这是不包含 Value 的静态表头部:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/aad0ca344a06ad65f7ef54fe10d96186-20230731165330-ao38gn5.png",alt:""}})]),s._v(" "),t("p",[s._v("再根据索引 000001 查到 authority 头部(Host 头部在 HTTP/2 协议中被改名为 authority). 紧跟的字节表示域名, 其中首个比特位表示域名是否经过 Huffman 编码, 而后 7 位表示了域名的长度. 在本例中, 10001011 表示域名共有 11 个字节(8+2+1=11), 且使用了 Huffman 编码.")]),s._v(" "),t("p",[s._v("最后, 使用静态 Huffman 编码, 可以将 16 个字节的 test.taohui.tech 压缩为 11 个字节, 这是怎么做到的呢? 根据信息论, 高频出现的信息用较短的编码表示后, 可以压缩体积. 因此, 在统计互联网上传输的大量 HTTP 头部后, HTTP/2 依据统计频率将 ASCII 码重新编码为一张表, 参见这里. test.taohui.tech 域名用到了 10 个字符, 我把这 10 个字符的编码列在下表中.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3c4106d67abbd9de589ae4c7bdd7ac80-20230731165330-82pbhar.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 接收端在收到下面这串比特位(最后 3 位填 1 补位)后, 通过"),t("strong",[s._v("查表")]),s._v("(请注意每个字符的颜色与比特位是一一对应的)就可以快速解码为:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/5b493c6ae485117fdd49e387e2ab915d-20230731165330-gy4jimt.png",alt:""}})]),s._v(" "),t("p",[s._v("由于 8 位的 ASCII 码最小压缩为 5 位, 所以静态 Huffman 的最大压缩比只有 5/8.")]),s._v(" "),t("h5",{attrs:{id:"_2-动态表编码能节约多少带宽"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-动态表编码能节约多少带宽"}},[s._v("#")]),s._v(" 2.动态表编码能节约多少带宽?")]),s._v(" "),t("p",[s._v("虽然静态表已经将 24 字节的 Host 头部压缩到 13 字节, **但动态表可以将它压缩到仅 1 字节, 这就能节省 96% 的带宽! **那动态表是怎么做到的呢?")]),s._v(" "),t("p",[s._v("你可能注意到, 当下许多页面含有上百个对象, 而 REST 架构的无状态特性, 要求下载每个对象时都得携带完整的 HTTP 头部. "),t("mark",[t("strong",[s._v("如果 HTTP/2 能在一个连接上传输所有对象, 那么只要客户端与服务器按照同样的规则, 对首次出现的 HTTP 头部用一个数字标识, 随后再传输它时只传递数字即可, 这就可以实现几十倍的压缩率. 所有被缓存的头部及其标识数字会构成一张表, 它与已经传输过的请求有关, 是动态变化的, 因此被称为动态表")])]),s._v(".")]),s._v(" "),t("p",[s._v("静态表有 61 项, 所以动态表的索引会从 62 起步. 比如下图中的报文中, 访问 test.taohui.tech 的第 1 个请求有 13 个头部需要加入动态表. 其中, Host: test.taohui.tech 被分配到的动态表索引是 74(索引号是倒着分配的).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e33e59d301f97857b114c59eac98d8dd-20230731165330-750365b.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 后续请求使用到 Host 头部时, 只需传输 1 个字节 11001010 即可. 其中, 首位 1 表示它在动态表中, 而后 7 位 1001010 值为 64+8+2=74, "),t("strong",[s._v("指向服务器缓存的动态表第 74 项")]),s._v(":")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/41e455feb95c6c08c317f3c9e2dff4f6-20230731165330-a5vmr3w.png",alt:""}})]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("静态表, Huffman 编码, 动态表共同完成了 HTTP/2 头部的编码")])]),s._v(", 其中, 前两者可以将体积压缩近一半, 而后者可以将反复传输的头部压缩 95% 以上的体积!")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/190c02b5443528d5e88aa151030beae1-20230731165330-cavok5a.png",alt:""}})]),s._v(" "),t("p",[s._v("那么, 是否要让一条连接传输尽量多的请求呢? 并不是这样. "),t("strong",[s._v("动态表会占用很多内存, 影响进程的并发能力, 所以服务器都会提供类似 http2_max_requests 这样的配置, 限制一个连接上能够传输的请求数量")]),s._v(", 通过关闭 HTTP/2 连接来释放内存. "),t("strong",[s._v("因此, http2_max_requests 并不是越大越好, 通常应当根据用户浏览页面时访问的对象数量来设定这个值.")])]),s._v(" "),t("h5",{attrs:{id:"_3-如何并发传输请求"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何并发传输请求"}},[s._v("#")]),s._v(" 3.如何并发传输请求?")]),s._v(" "),t("p",[s._v("HTTP/1.1 中的 KeepAlive 长连接虽然可以传输很多请求, 但它的吞吐量很低, 因为在发出请求等待响应的那段时间里, 这个长连接不能做任何事! 而 "),t("strong",[s._v("HTTP/2 通过 Stream 这一设计, 允许请求并发传输")]),s._v(". 因此, HTTP/1.1 时代 Chrome 通过 6 个连接访问页面的速度, 远远比不上 HTTP/2 单连接的速度.")]),s._v(" "),t("p",[s._v("为了理解 HTTP/2 的并发是怎样实现的, 需要了解 "),t("mark",[t("strong",[s._v("Stream, Message, Frame")])]),s._v(" 这 3 个概念. "),t("strong",[s._v("HTTP 请求和响应都被称为 Message 消息, 它由 HTTP 头部和包体构成, 承载这二者的叫做 Frame 帧, 它是 HTTP/2 中的最小实体")]),s._v(". Frame 的长度是受限的, 比如 Nginx 中默认限制为 8K(http2_chunk_size 配置), 因此我们可以得出 2 个结论: "),t("mark",[t("strong",[s._v("HTTP 消息可以由多个 Frame 构成, 以及 1 个 Frame 可以由多个 TCP 报文构成(TCP MSS 通常小于 1.5K)")])]),s._v(" .")]),s._v(" "),t("p",[s._v("再来看 Stream 流, 它与 HTTP/1.1 中的 TCP 连接非常相似, 当 Stream 作为短连接时, 传输完一个请求和响应后就会关闭; 当它作为长连接存在时, 多个请求之间必须串行传输. "),t("strong",[s._v("在 HTTP/2 连接上, 理论上可以同时运行无数个 Stream, 这就是 HTTP/2 的多路复用能力, 它通过 Stream 实现了请求的并发传输")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c7dab01d09f8ad2da73a76b1c36a15a7-20230731165330-itu5tux.png",alt:""}})]),s._v(" "),t("p",[s._v("虽然 RFC 规范并没有限制并发 Stream 的数量, 但服务器通常都会作出限制, 比如 Nginx 就默认限制并发 Stream 为 128 个(http2_max_concurrent_streams 配置), 以防止并发 Stream 消耗过多的内存, 影响了服务器处理其他连接的能力.")]),s._v(" "),t("p",[s._v("HTTP/2 的并发性能比 HTTP/1.1 通过 TCP 连接实现并发要高. 这是因为, "),t("mark",[t("strong",[s._v("当 HTTP/2 实现 100 个并发 Stream 时, 只经历 1 次 TCP 握手, 1 次 TCP 慢启动以及 1 次 TLS 握手, 但 100 个 TCP 连接会把上述 3 个过程都放大 100 倍!")])]),s._v("   ****")]),s._v(" "),t("p",[s._v("HTTP/2 还可以为每个 Stream 配置 1 到 256 的权重, 权重越高服务器就会为 Stream 分配更多的内存, 流量, 这样按照资源渲染的优先级为并发 Stream 设置权重后, 就可以让用户获得更好的体验. 而且, Stream 间还可以有依赖关系, 比如若资源 A, B 依赖资源 C, 那么设置传输 A, B 的 Stream 依赖传输 C 的 Stream 即可, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7ce65c4c77bc24dd48a7a266fd2f150d-20230731165330-ir10vk8.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_4-服务器如何主动推送资源"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-服务器如何主动推送资源"}},[s._v("#")]),s._v(" 4.服务器如何主动推送资源?")]),s._v(" "),t("p",[s._v("HTTP/1.1 不支持服务器主动推送消息, 因此当客户端需要获取通知时, 只能通过定时器不断地拉取消息. HTTP/2 的消息推送结束了无效率的定时拉取, 节约了大量带宽和服务器资源.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/740f2a1a4fca7a77168c2486599a9c25-20230731165330-g3ene42.png",alt:""}})]),s._v(" "),t("p",[s._v("HTTP/2 的推送是这么实现的. 首先, "),t("strong",[s._v("所有客户端发起的请求, 必须使用单号 Stream 承载; 其次, 所有服务器进行的推送, 必须使用双号 Stream 承载; 最后, 服务器推送消息时, 会通过 PUSH_PROMISE 帧传输 HTTP 头部, 并通过 Promised Stream ID 告知客户端, 接下来会在哪个双号 Stream 中发送包体")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/adedb1fbfaca09a73eef8c8533a0f72b-20230731165330-6u2fcpn.png",alt:""}})]),s._v(" "),t("p",[s._v("在 SDK 中调用相应的 API 即可推送消息, 而在 Web 资源服务器中可以通过配置文件做简单的资源推送. 比如在 Nginx 中, 如果你希望客户端访问 "),t("code",[s._v("/a.js")]),s._v("​ 时, 服务器直接推送 "),t("code",[s._v("/b.js")]),s._v("​, 那么可以这么配置:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("location /a.js "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    http2_push /b.js"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("服务器同样也会控制并发推送的 Stream 数量(如 http2_max_concurrent_pushes 配置), 以减少动态表对内存的占用.")]),s._v(" "),t("h5",{attrs:{id:"_5-小结-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-小结-3"}},[s._v("#")]),s._v(" 5.小结")]),s._v(" "),t("p",[s._v("这一讲介绍了 HTTP/2 的高性能是如何实现的.")]),s._v(" "),t("p",[t("strong",[s._v("静态表和 Huffman 编码可以将 HTTP 头部压缩近一半的体积, 但这只是连接上第 1 个请求的压缩比. 后续请求头部通过动态表可以压缩 90% 以上, 这大大提升了编码效率")]),s._v(". 当然, 动态表也会导致内存占用过大, 影响服务器的总体并发能力, 因此服务器会限制 HTTP/2 连接的使用时长.")]),s._v(" "),t("p",[t("strong",[s._v("HTTP/2 的另一个优势是实现了 Stream 并发, 这节约了 TCP 和 TLS 协议的握手时间, 并减少了 TCP 的慢启动阶段对流量的影响")]),s._v(". 同时, Stream 之间可以用 Weight 权重调节优先级, 还可以直接设置 Stream 间的依赖关系, 这样接收端就可以获得更优秀的体验.")]),s._v(" "),t("p",[t("strong",[s._v("HTTP/2 支持消息推送")]),s._v(", 从 HTTP/1.1 的拉模式到推模式, 信息传输效率有了巨大的提升. HTTP/2 推消息时, 会使用 PUSH_PROMISE 帧传输头部, 并用双号的 Stream 来传递包体, 了解这一点对定位复杂的网络问题很有帮助.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("HTTP/2 的最大问题来自于它下层的 TCP 协议")])]),s._v(". 由于 TCP 是字符流协议, 在前 1 字符未到达时, 后接收到的字符只能存放在内核的缓冲区里, 即使它们是并发的 Stream, 应用层的 HTTP/2 协议也无法收到失序的报文, 这就叫做"),t("strong",[s._v("队头阻塞问题")]),s._v(". "),t("mark",[t("strong",[s._v("解决方案是放弃 TCP 协议, 转而使用 UDP 协议作为传输层协议, 这就是 HTTP/3 协议的由来")])]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e6a8a618409e17c82d4cfc44f98c77da-20230731165330-s9psper.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"_17-protobuf是如何进一步提高编码效率的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_17-protobuf是如何进一步提高编码效率的"}},[s._v("#")]),s._v(" 17-Protobuf是如何进一步提高编码效率的?")]),s._v(" "),t("p",[s._v("上一讲介绍的 HTTP/2 协议在编码上拥有非常高的空间利用率, 这一讲看看, 相比其中的 HPACK 编码技术, "),t("strong",[s._v("Protobuf 又是通过哪些新招式进一步提升编码效率")]),s._v("的.")]),s._v(" "),t("p",[s._v("Google 在 2008 年推出的 Protobuf, 是一个针对具体编程语言的"),t("strong",[s._v("编解码工具")]),s._v(". 它面向 Windows, Linux 等多种平台, 也支持 Java, Python, Golang, C++, Javascript 等多种面向对象编程语言. 使用 Protobuf 编码消息速度很快, 消耗的 CPU 计算力也不多, "),t("strong",[s._v("而且编码后的字符流体积远远小于 JSON 等格式, 能够大量节约昂贵的带宽, 因此 gRPC 也把 Protobuf 作为底层的编解码协议")]),s._v(".")]),s._v(" "),t("p",[s._v("然而, 很多同学并不清楚 Protobuf 到底是怎样做到这一点的. 这样, 当你希望通过更换通讯协议这个高成本手段, 提升整个分布式系统的性能时, 面对可供选择的众多通讯协议, 仅凭第三方的性能测试报告, 你仍将难以作出抉择. 而且, 面对分布式系统中的疑难杂症, 往往需要通过分析抓取到的网络报文, 确定到底是哪个组件出现了问题. 可是由于 Protobuf 编码太过紧凑, 即使对照着 Proto 消息格式文件, 在不清楚编码逻辑时, 你也很难解析出消息内容.")]),s._v(" "),t("p",[s._v("下面, 将基于上一讲介绍过的 HPACK 编码技术, 看看 Protobuf 是怎样"),t("strong",[s._v("进一步缩减编码体积")]),s._v("的.")]),s._v(" "),t("h5",{attrs:{id:"_1-怎样用最少的空间编码字段名"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-怎样用最少的空间编码字段名"}},[s._v("#")]),s._v(" 1.怎样用最少的空间编码字段名?")]),s._v(" "),t("p",[s._v("消息由多个名, 值对组成, 比如 HTTP 请求中, 头部 "),t("code",[s._v("Host: www.taohui.pub")]),s._v("​ 就是一个名值对, 其中, Host 是字段名称, 而 www.taohui.pub 是字段值. 我们先来看 Protobuf 如何编码字段名.")]),s._v(" "),t("p",[s._v("对于多达几十字节的 HTTP 头部, HTTP/2 静态表仅用一个数字来表示, 其中, 映射数字与字符串对应关系的表格, 被写死在 HTTP/2 实现框架中. 这样的编码效率非常高, **但通用的 HTTP/2 框架只能将 61 个最常用的 HTTP 头部映射为数字, 它能发挥出的作用很有限. **")]),s._v(" "),t("p",[s._v("动态表可以让更多的 HTTP 头部编码为数字, 在上一讲的例子中, 动态表将 Host 头部减少了 96% 的体积, 效果惊人. 但动态表生效得有一个前提: 必须在一个会话连接上反复传输完全相同的 HTTP 头部. **如果消息字段在 1 个连接上只发送了 1 次, 或者反复传输时字段总是略有变动, 动态表就无能为力了. **")]),s._v(" "),t("p",[s._v("有没有办法既使用静态表的预定义映射关系, 又享受到动态表的灵活多变呢? **其实只要把由 HTTP/2 框架实现的字段名映射关系, 交由应用程序自行完成即可. **而 Protobuf 就是这么做的. 比如下面这段 39 字节的 JSON 消息, 虽然一目了然, 但字段名 name, id, sex 其实都是多余的, 因为客户端与服务器的处理代码都清楚字段的含义.")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"John"')]),s._v(","),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"id"')]),s._v(":1234,"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sex"')]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"MALE"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("Protobuf 将这 3 个字段名"),t("strong",[s._v("预分配了 3 个数字")]),s._v(", 定义在 proto 文件中:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("message "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Person")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  string name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  uint32 id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("enum")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SexType")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MALE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("FEMALE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SexType")]),s._v(" sex "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[s._v("接着, "),t("strong",[s._v("通过 protoc 程序便可以针对不同平台, 编程语言, 将它生成编解码类, 最后通过类中自动生成的 SerializeToString 方法将消息序列")]),s._v("化, 编码后的信息仅有 11 个字节. 其中, 报文与字段的对应关系我放在下面这张图中.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/647a334ee37887c9f16749572339fb4c-20230731165330-s7we89j.png",alt:""}})]),s._v(" "),t("p",[s._v("从图中可以看出, "),t("strong",[s._v("Protobuf 是按照字段名, 值类型, 字段值的顺序来编码的")]),s._v(", 由于编码极为紧凑, 所以分析时必须基于二进制比特位进行. 比如红色的 00001, 00010, 00011 等前 5 个比特位, 就分别代表着 name, id, sex 字段.")]),s._v(" "),t("p",[s._v("图中字段值的编码方式后面再解释, 这里想必大家会有疑问, 如果只有 5 个比特位表示字段名的值, 那不是限制消息最多只有 31 个(25 - 1)字段吗? 当然不是, 字段名的序号可以从 1 到 536870911(即 229 - 1), 可是, 多数消息不过只有几个字段, 这意味着可以用很小的序号表示它们. 因此, "),t("strong",[s._v("对于小于 16 的序号, Protobuf 仅有 5 个比特位表示, 这样加上 3 位值类型, 只需要 1 个字节表示字段名")]),s._v(". 对于大于 16 小于 2027 的序号, 也只需要 2 个字节表示.")]),s._v(" "),t("p",[t("strong",[s._v("Protobuf 可以用 1 到 5 个字节来表示一个字段名")]),s._v(", 因此, 每个字节的第 1 个比特位保留, 它为 0 时表示这是字段名的最后一个字节. 下表列出了几种典型序号的编码值(请把黑色的二进制位, 从右至左排列, 比如 2049 应为 000100000000001, 即 2048+1).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/28eddb31b50aa98eb7176964cb0dea79-20230731165330-gtzcw42.png",alt:""}})]),s._v(" "),t("p",[s._v("说完字段名, 再来看字段值是如何编码的.")]),s._v(" "),t("h5",{attrs:{id:"_2-怎样高效地编码字段值"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-怎样高效地编码字段值"}},[s._v("#")]),s._v(" 2.怎样高效地编码字段值?")]),s._v(" "),t("p",[s._v("Protobuf 对不同类型的值, 采用 6 种不同的编码方式, 如下表所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/699efa93e085fb14d326042630e4618d-20230731165330-veiofxb.png",alt:""}})]),s._v(" "),t("p",[s._v("字符串用 Length-delimited 方式编码, 顾名思义, 在值长度后顺序添加 ASCII 字节码即可. 比如上文例子中的 John, 对应的 ASCII 码如下表所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3b0ff06fc6fb91b31486d77b099814c8-20230731165330-36wujle.png",alt:""}})]),s._v(" "),t("p",[s._v('这样, "John" 需要 5 个字节进行编码, 如下图所示(绿色表示长度, 紫色表示 ASCII 码):')]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/13535ed6e6c0a6ae897f22df40ea46e9-20230731165330-5f6mn5m.png",alt:""}})]),s._v(" "),t("p",[s._v("这里需要注意, 字符串长度的编码逻辑与字段名相同, 当长度小于 128(27)时, 1 个字节就可以表示长度. 若长度从 128 到 16384(214), 则需要 2 个字节, 以此类推.")]),s._v(" "),t("p",[s._v("由于字符串编码时未做压缩, 所以并不会节约空间, 但胜在速度快. "),t("strong",[s._v("如果消息中含有大量字符串, 那么使用 Huffman 等算法压缩后再编码效果更好.")])]),s._v(" "),t("p",[s._v("再来看 "),t("code",[s._v("id: 1234")]),s._v("​ 这个数字是如何编码的. 其实 Protobuf 中所有数字的编码规则是一致的, "),t("strong",[s._v("字节中第 1 个比特位仅用于指示由哪些字节编码 1 个数字")]),s._v(". 例如图中的 1234, 将由 14 个比特位 00010011010010 表示(1024+128+64+16+2, 正好是 1234).")]),s._v(" "),t("p",[t("strong",[s._v("由于消息中的大量数字都很小, 这种编码方式可以带来很高的空间利用率!")]),s._v("  当然, 如果确定数字很大, 这种编码方式不但不能节约空间, 而且会导致原先 4 个字节的大整数需要用 5 个字节来表示时, 也可以使用 fixed32, fixed64 等类型定义数字.")]),s._v(" "),t("p",[s._v("Protobuf 还可以通过 enum 枚举类型压缩空间. 回到第 1 幅图, sex: FEMALE 仅用 2 个字节就编码完成, 正是枚举值 FEMALE 使用数字 1 表示所达到的效果.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ac2a8c0d4564dd99e25d39760d5622de-20230731165330-v3l5lk4.png",alt:""}})]),s._v(" "),t("p",[s._v("而且, 由于 Protobuf 定义了每个字段的默认值, 因此, 当消息使用字段的默认值时, Protobuf 编码时会略过该字段. 以 "),t("code",[s._v("sex: MALE")]),s._v("​ 为例, 由于 MALE=0 是 sex 的默认值, 因此在第 2 幅示例图中, 这 2 个字节都省去了.")]),s._v(" "),t("p",[s._v("另外, 当使用 repeated 语法将多个数字组成列表时, 还可以通过打包功能提升编码效率. 比如下图中, 对 numbers 字段添加 101, 102, 103, 104 这 4 个值后, 如果不使用打包功能, 共需要 8 个字节编码, 其中每个数字前都需要添加字段名. 而使用打包功能后, 仅用 6 个字节就能完成编码, 显然列表越庞大, 节约的空间越多.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d94260fe39a3cce69c28bdc876684d55-20230731165330-egewh41.png",alt:""}})]),s._v(" "),t("p",[s._v("在 Protobuf2 版本中, 需要显式设置 "),t("code",[s._v("[packed=True]")]),s._v("​ 才能使用打包功能, 而在 Protobuf3 版本中这是默认功能. 在保持高空间利用率的前提下, Protobuf 仍然拥有飞快的速度!")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-3"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了 Protobuf 的编码原理.")]),s._v(" "),t("p",[t("strong",[s._v("通过在 proto 文件中为每个字段预分配 1 个数字, 编码时就省去了完整字段名占用的空间")]),s._v(". 而且, 数字越小编码时用掉的空间也越小, 实际网络中大量传输的是小数字, 这带来了很高的空间利用率. Protobuf 的枚举类型也通过类似的原理, 用数字代替字符串, 可以节约许多空间.")]),s._v(" "),t("p",[t("strong",[s._v("对于字符串 Protobuf 没有做压缩, 因此如果消息中的字符串比重很大时, 建议先压缩后再使用 Protobuf 编码")]),s._v(". 对于拥有默认值的字段, Protobuf 编码时会略过它. 对于 repeated 列表, 使用打包功能可以仅用 1 个字段前缀描述所有数值, 它在列表较大时能带来可观的空间收益.")]),s._v(" "),t("h4",{attrs:{id:"_18-如何通过grpc实现高效远程过程调用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_18-如何通过grpc实现高效远程过程调用"}},[s._v("#")]),s._v(" 18-如何通过gRPC实现高效远程过程调用?")]),s._v(" "),t("p",[s._v("本节将以一个实战案例, 基于前两讲提到的 HTTP/2 和 ProtoBuf 协议, "),t("strong",[s._v("看看 gRPC 如何将结构化消息编码为网络报文")]),s._v(".")]),s._v(" "),t("p",[s._v("直接操作网络协议编程, 容易让业务开发过程陷入复杂的网络处理细节. "),t("strong",[s._v("RPC 框架")]),s._v("以编程语言中的本地函数调用形式, 向应用开发者提供网络访问能力, 这既封装了消息的编解码, 也通过线程模型封装了多路复用, 对业务开发很友好.")]),s._v(" "),t("p",[s._v("其中, Google 推出的 gRPC 是性能最好的 RPC 框架之一, 它支持 Java, Javascript, Python, GoLang, C++, Object-C, Ruby 等多种编程语言, 还支持安全验证等特性, 得到了广泛的应用, 比如微服务中的 Envoy, 分布式机器学习中的 Tensorflow, 都使用了 gRPC 框架.")]),s._v(" "),t("p",[s._v("然而, 网络上 gRPC 框架的教程很多, 却很少去谈 gRPC 是"),t("strong",[s._v("如何编码消息")]),s._v("的. 这样, 一旦在大型分布式系统中出现疑难杂症, 需要通过网络报文去定位问题发生在哪个系统, 主机, 进程中时, 就会毫无头绪. 即使掌握了 HTTP/2 和 Protobuf 协议, 但若不清楚 gRPC 的编码规则, 还是无法分析抓取到的 gRPC 报文. 而且, gRPC 支持单向, 双向的流式 RPC 调用, 编程相对复杂一些, 定位流式 RPC 调用引发的 bug 时, 更需要掌握 gRPC 的编码原理.")]),s._v(" "),t("p",[s._v("这一讲, 就将以 gRPC 官方提供的 "),t("code",[s._v("example: data_transmisstion")]),s._v("​ 为例, 介绍 gRPC 的编码流程. 在这一过程中, 会顺带回顾 HTTP/2 和 Protobuf 协议, 加深对它们的理解. 虽然这个示例使用的是 Python 语言, 但基于 gRPC 框架, 可以轻松地将它们转换为其他编程语言.")]),s._v(" "),t("h5",{attrs:{id:"_1-如何使用grpc框架实现远程调用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何使用grpc框架实现远程调用"}},[s._v("#")]),s._v(" 1.如何使用gRPC框架实现远程调用?")]),s._v(" "),t("p",[s._v("先来简单地看下 gRPC 框架到底是什么. "),t("strong",[s._v("RPC 的全称是 Remote Procedure Call, 即远程过程调用, 它通过本地函数调用, 封装了跨网络, 跨平台, 跨语言的服务访问, 大大简化了应用层编程. 其中, 函数的入参是请求, 而函数的返回值则是响应")]),s._v(".")]),s._v(" "),t("p",[s._v("gRPC 就是一种 RPC 框架, 在定义好消息格式后, 针对选择的编程语言, "),t("strong",[s._v("gRPC 为客户端生成发起 RPC 请求的 Stub 类, 以及为服务器生成处理 RPC 请求的 Service 类(服务器只需要继承, 实现类中处理请求的函数即可)")]),s._v(" . 如下图所示, 很明显, gRPC 主要服务于面向对象的编程语言.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/07e1b29e9e59d8f390ca6340781cb723-20230731165330-vnv6mk1.png",alt:""}})]),s._v(" "),t("p",[s._v("gRPC 支持 QUIC, HTTP/1 等多种协议, 但鉴于 HTTP/2 协议性能好, 应用场景又广泛, 因此 "),t("mark",[t("strong",[s._v("HTTP/2 是 gRPC 的默认传输协议")])]),s._v(". gRPC 也支持 JSON 编码格式, 但在忽略编码细节的 RPC 调用中, 高效的 Protobuf 才是最佳选择! 因此, 这一讲仅基于 HTTP/2 和 Protobuf, 介绍 gRPC 的用法.")]),s._v(" "),t("p",[t("strong",[s._v("gRPC 可以简单地分为三层, 包括底层的数据传输层, 中间的框架层(框架层又包括 C 语言实现的核心功能, 以及上层的编程语言框架), 以及最上层由框架层自动生成的 Stub 和 Service 类")]),s._v(", 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b10836512cbc8f5b0622986845524249-20230731165330-g1q4ikx.png",alt:""}})]),s._v(" "),t("p",[s._v("接下来以官网上的 data_transmisstion 为例, 先看看如何使用 gRPC. 构建 Python 语言的 gRPC 环境很简单, 可以参考官网上的 QuickStart.")]),s._v(" "),t("p",[s._v("使用 gRPC 前, 先要"),t("strong",[s._v("根据 Protobuf 语法, 编写定义消息格式的 proto 文件")]),s._v(". 在这个例子中只有 1 种请求和 1 种响应, 且它们很相似, 各含有 1 个整型数字和 1 个字符串, 如下所示:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("package")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("demo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\nmessage "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Request")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    int64 client_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    string request_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n\nmessage "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    int64 server_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    string response_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("p",[s._v("请注意, 这里的包名 demo 以及字段序号 1, 2, 都与后续的 gRPC 报文分析相关.")]),s._v(" "),t("p",[s._v("接着定义 service, "),t("strong",[s._v("所有的 RPC 方法都要放置在 service 中")]),s._v(", 这里将它取名为 GRPCDemo. GRPCDemo 中有 4 个方法, 后面 3 个流式访问的例子呆会再谈, 先来看简单的一元访问模式 SimpleMethod 方法, 它定义了 1 个请求对应 1 个响应的访问形式. 其中, SimpleMethod 的参数 Request 是请求, 返回值 Response 是响应. 注意, 分析报文时会用到这里的类名 GRPCDemo 以及方法名 SimpleMethod.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("service "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GRPCDemo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    rpc "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SimpleMethod")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Request")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" returns "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("用 grpc_tools 中的 "),t("strong",[s._v("protoc")]),s._v(" 命令, 就可以针对刚刚定义的 service, "),t("strong",[s._v("生成含有 GRPCDemoStub 类和 GRPCDemoServicer 类的 demo_pb2_grpc.py 文件")]),s._v("(实际上还包括完成 Protobuf 编解码的 demo_pb2.py), 应用层将使用这两个类完成 RPC 访问. 我简化了官网上的 Python 客户端代码, 如下所示:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("grpc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("insecure_channel")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"localhost:23333"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" as channel"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n    stub "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("demo_pb2_grpc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("GRPCDemoStub")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("channel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    request "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("demo_pb2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("Request")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("client_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            request_data"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"called by Python client"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    response "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("stub"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("SimpleMethod")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("request"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("示例中客户端与服务器都在同一台机器上, 通过 23333 端口访问. 客户端通过 stub 对象的 SimpleMethod 方法完成了 RPC 访问. 而服务器端的实现也很简单, 只需要实现 GRPCDemoServicer 父类的 SimpleMethod 方法, 返回 response 响应即可:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DemoServer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("demo_pb2_grpc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("GRPCDemoServicer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n    def "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SimpleMethod")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n        response "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("demo_pb2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("Response")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n            server_id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            response_data"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Python server SimpleMethod Ok!!!!"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" response\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("可见, gRPC 的开发效率非常高! 接下来分析这次 RPC 调用中, "),t("strong",[s._v("消息是怎样编码")]),s._v("的.")]),s._v(" "),t("h5",{attrs:{id:"_2-grpc消息是如何编码的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-grpc消息是如何编码的"}},[s._v("#")]),s._v(" 2.gRPC消息是如何编码的?")]),s._v(" "),t("p",[t("strong",[s._v("定位复杂的网络问题, 都需要抓取, 分析网络报文.")]),s._v('  如果在 Windows 上抓取网络报文, 可以使用 Wireshark 工具, 如果在 Linux 上抓包可以使用 tcpdump 工具. 需要注意, 23333 不是 HTTP 常用的 80 或者 443 端口, 所以 Wireshark 默认不会把它解析为 HTTP/2 协议. 需要鼠标右键点击报文, 选择"解码为"(Decode as), 将 23333 端口的报文设置为 HTTP/2 解码器, 如下图所示:')]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8a128b1c494c6d4b288e05f1a46ae294-20230731165330-740w8os.png",alt:""}})]),s._v(" "),t("p",[s._v("重点看红色方框中的 gRPC 请求与响应, 点开请求, 可以看到下图中的信息:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b0695b1561234b74daa14c4efd85aab3-20230731165330-hgc9jol.png",alt:""}})]),s._v(" "),t("p",[s._v("先来分析蓝色方框中的 HTTP/2 头部. 请求中有 2 个关键的 HTTP 头部, "),t("strong",[s._v("path 和 content-type")]),s._v(", 它们决定了 "),t("strong",[s._v("RPC 方法和具体的消息编码格式")]),s._v('. path 的值为 "'),t("code",[s._v("/demo.GRPCDemo/SimpleMethod")]),s._v('​", 通过 "'),t("code",[s._v("/包名.服务名/方法名")]),s._v('​" 的形式确定了 RPC 方法. content-type 的值为 "'),t("code",[s._v("application/grpc")]),s._v('​", 确定消息编码使用 Protobuf 格式.')]),s._v(" "),t("p",[s._v("HTTP/2 包体并不会直接存放 Protobuf 消息, 而是先要添加 5 个字节的 "),t("strong",[s._v("Length-Prefixed Message")]),s._v(" 头部, 其中用 4 个字节明确 Protobuf 消息的长度(1 个字节表示消息是否做过压缩), 即上图中的桔色方框. 为什么要多此一举呢? 这是因为, gRPC 支持流式消息, 即在 HTTP/2 的 1 条 Stream 中, 通过 DATA 帧发送多个 gRPC 消息, 而 Length-Prefixed Message 就可以将不同的消息分离开. 关于流式消息, 后面在介绍完一元模式后, 再加以分析.")]),s._v(" "),t("p",[s._v('最后分析 Protobuf 消息, 这里仅以 client_id 字段为例, 对上一讲的内容做个回顾. 在 proto 文件中 client_id 字段的序号为 1, 因此首字节 00001000 中前 5 位表示序号为 1 的 client_id 字段, 后 3 位表示字段的值类型是 varint 格式的数字, 因此随后的字节 00000001 表示字段值为 1. 序号为 2 的 request_data 字段请结合上一讲的内容, 试着做一下解析, 看看字符串 "called by Python client" 是怎样编码的.')]),s._v(" "),t("p",[s._v("再来看服务器发回的响应, 点开 Wireshark 中的响应报文后如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c0b46eb9b0b64321eea9e91c4f68549d-20230731165330-kreu3mv.png",alt:""}})]),s._v(" "),t("p",[s._v("其中 DATA 帧同样包括 Length-Prefixed Message 和 Protobuf, 与 RPC 请求如出一辙, 这里就不再赘述了, 重点看下 HTTP/2 头部. 你可能留意到, 响应头部被拆成了 2 个部分, "),t("strong",[s._v("其中 grpc-status 和 grpc-message 是在 DATA 帧后发送的, 这样就允许服务器在发送完消息后再给出错误码")]),s._v(".")]),s._v(" "),t("p",[s._v("这种将部分 HTTP 头部放在包体后发送的技术叫做 "),t("strong",[s._v("Trailer")]),s._v(", RFC7230 文档对此有详细的介绍. 其中, RPC 请求中的 "),t("code",[s._v("TE: trailers")]),s._v("​ 头部, 就说明客户端支持 Trailer 头部. 在 RPC 响应中, grpc-status 头部都会放在最后发送, 因此它的帧 flags 的 EndStream 标志位为 1.")]),s._v(" "),t("p",[s._v("可以看到, "),t("strong",[s._v("gRPC 中的 HTTP 头部与普通的 HTTP 请求完全一致, 因此, 它兼容当下互联网中各种七层负载均衡, 这使得 gRPC 可以轻松地跨越公网使用")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_3-grpc流模式的协议编码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-grpc流模式的协议编码"}},[s._v("#")]),s._v(" 3.gRPC流模式的协议编码")]),s._v(" "),t("p",[s._v("说完一元模式, 再来看"),t("strong",[s._v("流模式 RPC 调用的编码方式")]),s._v(".")]),s._v(" "),t("p",[s._v("所谓"),t("strong",[s._v("流模式, 是指 RPC 通讯的一方可以在 1 次 RPC 调用中, 持续不断地发送消息, 这对订阅, 推送等场景很有用")]),s._v(". 流模式共有 3 种类型, 包括"),t("strong",[s._v("客户端流模式, 服务器端流模式, 以及两端双向流模式")]),s._v(". 在 data_transmisstion 官方示例中, 对这 3 种流模式都定义了 RPC 方法, 如下所示:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("service "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GRPCDemo")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    rpc "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ClientStreamingMethod")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("stream "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Request")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" returns "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    rpc "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ServerStreamingMethod")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Request")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" returns "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("stream "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("  \n    rpc "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BidirectionalStreamingMethod")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("stream "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Request")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" returns "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("stream "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("不同的编程语言处理流模式的代码很不一样, 这里就不一一列举了, 但通讯层的流模式消息编码是一样的, 而且很简单. 这是因为, "),t("strong",[s._v("HTTP/2 协议中每个 Stream 就是天然的 1 次 RPC 请求, 每个 RPC 消息又已经通过 Length-Prefixed Message 头部确立了边界")]),s._v(", 这样在 Stream 中连续地发送多个 DATA 帧, 就可以实现流模式 RPC. 下面画了一张示意图, 可以对照它理解抓取到的流模式报文.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/707dd3b01126d83409bf347b9360b784-20230731165330-5gp42jb.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_4-小结-12"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-12"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("这一讲介绍了 gRPC 怎样使用 HTTP/2 和 Protobuf 协议编码消息.")]),s._v(" "),t("p",[t("strong",[s._v("在定义好消息格式, 以及 service 类中的 RPC 方法后, gRPC 框架可以为编程语言生成 Stub 和 Service 类, 而类中的方法就封装了网络调用, 其中方法的参数是请求, 而方法的返回值则是响应.")])]),s._v(" "),t("p",[s._v("发起 RPC 调用后, 可以这么分析抓取到的网络报文. 首先, 分析应用层最外层的 HTTP/2 帧, 根据 Stream ID 找出一次 RPC 调用. 客户端 HTTP 头部的 path 字段指明了 service 和 RPC 方法名, 而 content-type 则指明了消息的编码格式. 服务器端的 HTTP 头部被分成 2 次发送, 其中 DATA 帧发送完毕后, 才会发送 grpc-status 头部, 这样可以明确最终的错误码.")]),s._v(" "),t("p",[s._v("其次, 分析包体时, 可以通过 Stream 中 Length-Prefixed Message 头部, 确认 DATA 帧中含有多少个消息, 因此可以确定这是一元模式还是流式调用. 在 Length-Prefixed Message 头部后, 则是 Protobuf 消息, 按照上一讲的内容进行分析即可.")]),s._v(" "),t("h3",{attrs:{id:"分布式系统优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统优化"}},[s._v("#")]),s._v(" 分布式系统优化")]),s._v(" "),t("h4",{attrs:{id:"_19-如何通过监控找到性能瓶颈"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_19-如何通过监控找到性能瓶颈"}},[s._v("#")]),s._v(" 19-如何通过监控找到性能瓶颈?")]),s._v(" "),t("p",[s._v("从这一讲开始, 将进入"),t("strong",[s._v("分布式系统层面")]),s._v(", 站在更宏观的角度去探讨系统性能的优化.")]),s._v(" "),t("p",[s._v("如果优化系统性能时, 只是依据自己的经验, 对感觉存在性能提升空间的代码, 无一例外地做一遍优化, 这既是一件事倍功半的事, 也很容易遗漏下关键的优化点, 无法大幅提升系统的性能. 根据帕累托法则(也叫二八定律), "),t("mark",[t("strong",[s._v("只有优化处于性能瓶颈的那些少量代码, 才能用最小的成本获得最大的收益")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("然而, 找到性能瓶颈却不是一件容易的事. 一般通常会采用各种监控手段来发现性能瓶颈, 但"),t("strong",[s._v("如果监控动作自身的开发成本过高, 或者施行监控时显著降低了业务请求的性能, 或者无法全面覆盖潜在的问题, 都会影响性能优化目标的实现.")])]),s._v(" "),t("p",[s._v("本节将介绍 2 个简单而又行之有效的方案, 分别"),t("strong",[s._v("从微观上快速地找出进程内的瓶颈函数, 以及从宏观上找出整个分布式系统中的瓶颈组件")]),s._v(". 这样就可以事半功倍地去优化系统性能.")]),s._v(" "),t("h5",{attrs:{id:"_1-单机-如何通过火焰图找到性能瓶颈"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-单机-如何通过火焰图找到性能瓶颈"}},[s._v("#")]),s._v(" 1.单机:如何通过火焰图找到性能瓶颈?")]),s._v(" "),t("p",[s._v("对于工作在一台主机上的进程而言, 有许多监控方案可用于寻找性能瓶颈. 比如在 Linux 下, 可以通过 iostat 命令监控磁盘状态, 也可以通过 top 命令监控 CPU, 内存的使用. 这些方案都是在旁敲侧击着寻找性能瓶颈, 然而, 有一种"),t("strong",[s._v("最直接有效的方式, 就是")]),s._v("​"),t("mark",[t("strong",[s._v("从代码层面直接寻找调用次数最频繁, 耗时最长的函数, 通常它就是性能瓶颈.")])])]),s._v(" "),t("p",[s._v("要完成这样的目标, 通常还有 3 个约束条件.")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("没有代码侵入性.")]),s._v("  比如, 在函数执行的前后, 分别打印一行日志记录时间, 这当然能获取到函数的调用频次和执行时长, 但并不可取, 它的开发, 维护成本太高了.")]),s._v(" "),t("li",[t("strong",[s._v("覆盖到代码中的全部函数.")]),s._v("  如果只是监控事先猜测的, 有限的几个函数, 往往会因为思维死角, 遗漏掉真正的瓶颈函数. 因此, 只有监控所有函数的执行情况, 并以一种全局的, 直观的方式分析聚合后的监控结果, 才能快速, 准确地找到性能瓶颈.")]),s._v(" "),t("li",[t("strong",[s._v("搭建环境的成本足够低.")]),s._v("  我曾经使用过 systemtap 来监控函数的执行状况, 搭建这样的监控环境需要很多步骤, 比如要重新编译 Linux 内核, 这些过于繁琐的成本会阻碍很多应用开发者的性能优化脚步.")])]),s._v(" "),t("p",[s._v("带着这 3 个约束条件, 最合适的方案已经呼之欲出了: 那就是 Brendan Gregg 发明的"),t("strong",[s._v("火焰图")]),s._v(", 以及为火焰图提供监控数据的工具. 先来直观感受下火焰图到底是什么样子:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4a08fef7fb46b52140fbbe0c3d9a9910-20230731165330-fk45ear.png",alt:""}})]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("火焰图可以将监控期间涉及到的所有函数调用栈都列出来")])]),s._v(", 就像上图对 Nginx worker 进程的监控一样, 函数非常密集, 因此通常采用可缩放, 可互动的 SVG 矢量格式图片来展示. 可以点击函数方块, 只查看它相关的函数调用栈.")]),s._v(" "),t("p",[s._v("火焰图中最重要的信息, 就是表示"),t("mark",[t("strong",[s._v("函数执行时间的 X 轴, 以及表示函数调用栈的 Y 轴")])]),s._v(".")]),s._v(" "),t("p",[s._v("先来看 X 轴. X 轴由多个方块组成, 每个方块表示一个函数, "),t("strong",[s._v("其长度是定时采样得到的函数调用频率, 因此可以简单粗暴地把它近似为执行时间.")]),s._v("  需要注意的是, 如果函数 A 中调用了函数 B, C, D, 监控采样时会形成 A->B, A->C, A->D 这 3 个函数调用栈, 但火焰图会将 3 个调用栈中表示 A 函数的方块合并, 并将 B, C, D 放在上一层中, 并以字母表顺序排列它们. 这样更有助于找到耗时最长的函数.")]),s._v(" "),t("p",[s._v("再来"),t("strong",[s._v("看 Y 轴, 它表示函数的调用栈")]),s._v(". 这里既可以看到内核 API 的函数调用栈, 也可以看到用户态函数的调用栈, 非常强大. "),t("strong",[s._v("如果你正在学习开源组件的源码, 推荐你先生成火焰图, 再对照图中的 Y 轴调用栈, 理解源码中函数的调用关系")]),s._v(". 注意, 函数方块的颜色是随机的, 并没有特别的意义, 只是为了在视觉上更容易区分开.")]),s._v(" "),t("p",[s._v("结合 X 轴和 Y 轴, 再来看如何使用火焰图找到性能瓶颈.")]),s._v(" "),t("p",[s._v("首先, 火焰图很容易从全局视角, 通过寻找长方块, 找到调用频率最高的几个函数.")]),s._v(" "),t("p",[s._v("其次, 函数方块长, 有些是因为函数自身执行了很消耗 CPU 的代码, 而有些则是调用的"),t("strong",[s._v("子函数耗时长")]),s._v("造成的. 怎么区分这两种场景呢? 很简单, "),t("mark",[t("strong",[s._v("如果函数方块的长度, 远大于调用栈中子函数方块的长度之和, 那么这个函数就执行了比较耗费 CPU 的计算")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  比如, 下图中执行 TLS 握手的 ngx_ssl_handshake_handler 函数, 自身并没有消耗 CPU 多少计算力.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ad3e520b0802e76f10985be9d019e20e-20230731165330-xpcavse.png",alt:""}})]),s._v(" "),t("p",[s._v("而更新 Nginx 时间的 ngx_time_update 函数就不同, 它在做时间格式转换时消耗了许多 CPU, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/51296a7f75e0a4422d0c6afdef0f0607-20230731165330-svh4z3r.png",alt:""}})]),s._v(" "),t("p",[s._v("这样可以直观地找到最耗时的函数, 再有针对性地优化它的性能.")]),s._v(" "),t("p",[s._v("怎么生成火焰图呢? 在 Linux 上这非常简单, 因为 Linux 内核默认"),t("strong",[s._v("支持 perf 工具")]),s._v(", 可以用 perf 生成函数的采样数据, 再用 FlameGraph 脚本生成火焰图. 当然, 如果在使用 Java, GoLang, Python 等高级语言, 也可以使用各自语言生态中"),t("strong",[s._v("封装过的 Profile 类工具, 生成采样数据")]),s._v(". 这里以最基本的 perf, FlameGraph 为例, 介绍下生成火焰图的 5 步流程.")]),s._v(" "),t("p",[s._v("首先, 可以通过 yum 或者 apt-get 安装 perf 工具, 再通过 git 来下载 FlameGraph:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("yum "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" perf\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("git")]),s._v(" clone "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--depth")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" https://github.com/brendangregg/FlameGraph.git\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("接着, 针对运行中的进程 PID, 使用 perf 采样函数的调用频率(对于 C/C++ 语言, 为了能够显示完整的函数栈, 你需要在编译时加入 -g 选项), 如下所示:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("perf record "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-F")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("99")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-p")]),s._v(" 进程PID "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-g")]),s._v(" --call-graph dwarf\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("再将二进制信息转换为 ASCII 格式的文件, 方便 FlameGraph 处理:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("perf script "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" out.perf\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("再然后, 需要汇聚函数调用栈, 转化为 FlameGraph 生成火焰图的数据格式:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("FlameGraph/stackcollapse-perf.pl out.perf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" out.folded\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("最后一步, 生成 SVG 格式的矢量图片:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("FlameGraph/flamegraph.pl out.folded "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" out.svg\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("需要注意, **上面的火焰图只能找到消耗 CPU 计算力最多的函数, 因此它也叫做 On CPU 火焰图, 由于 CPU 工作时会发热, 所以色块都是暖色调. **有些使用了阻塞 API 的代码, 则会导致进程休眠, On CPU 火焰图无法找到休眠时间最长的函数, 此时可以使用 Off CPU 火焰图, 它按照函数引发进程的休眠时间的长短, 确定函数方块的长度. 由于进程休眠时不使用 CPU, 所以色块会使用冷色调. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/690afc7be0cfef337d112351df1c947f-20230731165330-s9e60km.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_2-分布式系统-如何通过全链路监控找到性能瓶颈"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-分布式系统-如何通过全链路监控找到性能瓶颈"}},[s._v("#")]),s._v(" 2.分布式系统:如何通过全链路监控找到性能瓶颈?")]),s._v(" "),t("p",[s._v("说完微观上性能瓶颈的定位, 再来看"),t("strong",[s._v("宏观上的分布式系统")]),s._v(", 它通过网络把不同类型的硬件, 操作系统, 编程语言组合在一起, 结构很复杂, 因此, 现在的目标变成寻找更大尺度的瓶颈组件.")]),s._v(" "),t("p",[s._v("当然, 与单机不同的是, 找到分布式系统的性能瓶颈组件后, 除了可以继续通过火焰图优化组件中某个进程的性能外, 还有下面这样 3 个新收益.")]),s._v(" "),t("ul",[t("li",[s._v("首先, 可以通过简单的扩容动作, 利用负载均衡机制提升性能.")]),s._v(" "),t("li",[s._v("其次, 在云计算和微服务时代, 扩容可以在分钟级时间内完成. 因此, 如果性能瓶颈可以实时检测到, 就可以自动化地完成扩容和流量迁移. 这可以提升服务器资源的利用率.")]),s._v(" "),t("li",[s._v("最后, 既然能够找到瓶颈组件, 同样也能找出资源富裕的组件, 这样就可以通过反向的缩容, 减少服务器资源的浪费.")])]),s._v(" "),t("p",[s._v("接下来, 将从 4 个角度介绍分布式系统中的性能监控体系.")]),s._v(" "),t("p",[s._v("首先, "),t("strong",[s._v("监控基于日志来做, 对系统的侵入性最低, 因此要把格式多样化的文本日志, 进行结构化管理")]),s._v(". 一个分布式系统会涉及到多种编程语言, 这样各组件基于完全异构的中间件, 产生的日志格式也是五花八门! 如果定义一个统一的日志格式标准, 再要求每个组件遵照它重新开发一个版本, 这样代价太高, 基本无法实现!")]),s._v(" "),t("p",[s._v("比较幸运的是, 几乎每个组件都会输出文本类型的访问日志, 而且它们通常包括访问对象(例如 URL), 错误码, 处理时间等共性信息. 因此, 可以针对每个组件特定格式的文本日志, 写一个正则表达式, 将需要的结构化信息提取出来. 这样结构化数据的提取是在组件之外的, 对于组件中的代码也没有影响.")]),s._v(" "),t("p",[s._v("其次, "),t("strong",[s._v("同时搜集系统中每个组件的日志并汇总在一起")]),s._v(", 这样日志数据的规模就非常可观, 每天可能会产生 TB 级别的数据, 因此关系型数据库并不可取, 因为它们为了照顾事务, 关联查询等操作, 不具备很好的可伸缩性. 同时, 结构化的日志源于必须针对某类请求, 某类组件做聚合分析, 因此纯粹的 Key/Value 数据库也无法实现这类功能. 因此, 像 HBase 这样的半结构化列式数据库往往是监控数据的首选落地形式.")]),s._v(" "),t("p",[s._v("再次, "),t("strong",[s._v("分析日志时, 首先会从横向上, 聚合分析成百上千个组件中时延, 吞吐量, 错误码等数据项的统计值")]),s._v(". 这样, 计算力就是一个很大的问题, 因此通常选择支持 Map Reduce 算法的系统(比如 Hadoop)进行计算, 并将结果以可视化的方式展现出来, 协助性能分析. 由于计算时间比较久, 所以这也称为离线计算. 其次会在纵向上, 监控一个请求在整个生命周期内, 各个参与组件的性能状态. 因此必须设计一个请求 ID, 能够贯穿在各个组件内使用, 由于分布式系统中的请求数量非常大, 这个 ID 的碰撞概率必须足够低. 所以, 请求 ID 通常会同时包含时间和空间元素(比如 IP 地址). 这个方案还有个很威武的名字, 叫做"),t("strong",[s._v("全链路监控")]),s._v(", 它还可以用于组件依赖关系的优化.")]),s._v(" "),t("p",[s._v("最后, 还得"),t("strong",[s._v("对性能瓶颈做实时监控, 这是实现分布式系统自动化扩容, 缩容的前提")]),s._v(". 由于监控数据规模庞大, 所以通常要把流量在时间维度上分片, 仅对每个时间小窗口中有限的数据, 做快速的增量计算. 像 Storm, Spark, Flink 都是这样的实时流计算中间件, 可以基于它们完成实时数据的汇聚分析.")]),s._v(" "),t("p",[s._v("以上是我对分布式系统"),t("strong",[s._v("性能监控方案")]),s._v("的一些思考.")]),s._v(" "),t("p",[s._v("一提到分布式系统, 涉及到的知识点就非常多. 后续还会对 MapReduce, 实时流计算等还有进一步的分析, 因此监控方案中对它们就一带而过了.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-4"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-4"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了单机上如何通过火焰图找到性能瓶颈函数, 以及在分布式系统中, 如何通过全链路监控找到性能瓶颈组件.")]),s._v(" "),t("p",[s._v("在 Linux 系统中, 可以用内核支持的 perf 工具, 快速地生成火焰图. 其他高级编程语言生态中, 都有类似的 Profiler 工具, 可生成火焰图.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("火焰图中可以看到函数调用栈, 它对你分析源码很有帮助. 图中方块的长度表示函数的调用频率, 当采样很密集时, 你可以把它近似为函数的执行时长. 父方块长度减去所有子方块长度的和, 就表示了父函数自身代码对 CPU 计算力的消耗. 因此, 火焰图可以直观地找到调用次数最频繁且最耗时的函数")])]),s._v(".")]),s._v(" "),t("p",[s._v("对于分布式系统, 性能监控还有利于系统的扩容和缩容运维. 搭建性能监控体系包括以下四个关键点: 首先要把五花八门的日志用正则表达式提取为结构化的监控数据; 其次用半结构化的列式数据库存放集群中的所有日志, 便于后续的汇聚分析; 第三, 使用统一的请求 ID 将各组件串联在一起, 并使用 MapReduce 算法对大量的监控数据做离线分析; 最后, 通过实时流计算框架, 对监控数据做实时汇聚分析.")]),s._v(" "),t("h4",{attrs:{id:"_20-cap理论-怎样舍弃一致性去换取性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_20-cap理论-怎样舍弃一致性去换取性能"}},[s._v("#")]),s._v(" 20-CAP理论:怎样舍弃一致性去换取性能?")]),s._v(" "),t("p",[s._v("上一讲介绍了如何通过监控找到性能瓶颈, 从这一讲开始, 将具体讨论"),t("strong",[s._v("如何通过分布式系统来提升性能")]),s._v(".")]),s._v(" "),t("p",[s._v("在第一部分课程中, 介绍了多种提升单机处理性能的途径, 然而, 进程的性能必然受制于一台服务器上各硬件的处理能力上限. 如果需要进一步地提升服务性能, 那只有整合多台主机组成分布式系统才能办到.")]),s._v(" "),t("p",[s._v("然而, 当多台主机通过网络协同处理用户请求时, 如果主机上的进程含有数据状态, 那么必然需要在多台主机之间跨网络同步数据, 由于网络存在时延, 也并不稳定, 因此不可靠的数据同步操作将会增加请求的处理时延.")]),s._v(" "),t("p",[t("strong",[s._v("CAP 理论指出, 当数据同时存放在多个主机上时, 可用性与一致性是不可兼得的. 根据 CAP 的指导性思想, 可以通过牺牲一致性, 来提升可用性中的核心因素: 性能. 当然, 在实践中对一致性与性能并不是非黑即白的选择, 而是从概率上进行不同程度的取舍")]),s._v(".")]),s._v(" "),t("p",[s._v("这一讲将基于分布式系统中的经典理论, 从总体上看看"),t("strong",[s._v("如何设计一致性模型, 通过牺牲部分数据的一致性来提升性能(因为本课程的主题是性能, 所以关注点就偏重这个)")]),s._v(" .")]),s._v(" "),t("h5",{attrs:{id:"_1-如何权衡性能与一致性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何权衡性能与一致性"}},[s._v("#")]),s._v(" 1.如何权衡性能与一致性?")]),s._v(" "),t("p",[s._v("首先, 这节课针对的是"),t("strong",[s._v("有状态服务")]),s._v("的性能优化. 所谓有状态服务, 是指进程会在处理完请求后, 仍然保存着影响下次请求结果的用户数据, 而无状态服务则只从每个请求的输入参数中获取数据, 在请求处理完成后并不保存任何会话信息. 因此, 无状态服务拥有最好的可伸缩性, 但涉及数据持久化时, 则必须由有状态服务处理, 这是 CAP 理论所要解决的问题.")]),s._v(" "),t("p",[s._v("什么是 CAP 理论呢? 这是 2000 年 University of California, Berkeley 的计算机教授 Eric Brewer(也是谷歌基础设施 VP)提出的理论. 所谓 CAP, 是以下 3 个单词的首字母缩写, 它们都是分布式系统最核心的特性:")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("Consistency: 一致性")])]),s._v(" "),t("li",[t("strong",[s._v("Availability: 可用性")])]),s._v(" "),t("li",[t("strong",[s._v("Partition tolerance: 分区容错性")])])]),s._v(" "),t("p",[s._v("可以通过以下 3 张示意图, 快速理解下这 3 个词的意义. 下图中 N1, N2 两台主机上运行着 A 进程和 B 进程, 它们操作着同一个用户的数据(数据的初始值是 V0), 这里 N1 和 N2 主机就处于不同的 Partition 分区中, 如下所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/image-20240302224109-3gmz1f9.png",alt:"image"}})]),s._v(" "),t("p",[s._v("正常情况下, 当用户请求到达 N1 主机上的 A 进程, 并将数据 V0 修改为 V1 后, A 进程将会把这一修改行为"),t("strong",[s._v("同步")]),s._v("到 N2 主机上的 B 进程, 最终 N1, N2 上的数据都是 V1, 这就"),t("strong",[s._v("保持了系统的 Consistency 一致性")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e9f3079352714410e1234082c50b9bad-20230731165330-d120dw3.png",alt:""}})]),s._v(" "),t("p",[s._v("然而, 一旦 N1 和 N2 之间网络异常, 数据"),t("strong",[s._v("同步行为就会失败")]),s._v(". 这时, N1 和 N2 之间数据不一致, 如果希望在分区间网络不通的情况下, N2 能够继续为用户提供服务, 就必须容忍数据的不一致, 此时系统的 Availability 可用性更高, 系统的并发处理能力更强, 比如 Cassandra 数据库.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/14218835a16731c1fa018ad5bcccbb21-20230731165330-lbdikcb.png",alt:""}})]),s._v(" "),t("p",[s._v("反之, 如果 A, B 进程一旦发现数据同步失败, 那么 B 进程自动拒绝新请求, 仅由 A 进程独立提供服务, 那么虽然"),t("strong",[s._v("降低了系统的可用性, 但保证了更强的一致性")]),s._v(", 比如 MySQL 的主备同步模式.")]),s._v(" "),t("p",[s._v("这就是 CAP 中三者只能取其二的简要示意, 对于这一理论, 2002 年 MIT 的Seth Gilbert, Nancy Lynch 在这篇论文中, 证明了这一理论. 当然, 可用性是一个很大的概念, 它描述了分布式系统的持续服务能力, 如下表所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/99cc308d7aad63cb086bdfa22793316e-20230731165330-5b5azko.png",alt:""}})]),s._v(" "),t("p",[s._v("当用户, 流量不断增长时, 系统的性能将变成衡量可用性的关键因素. 当希望拥有更强的性能时, 就不得不牺牲数据的一致性. 当然, 一致性并不是只有是和否这两种属性, 既可以从时间维度上设计短暂不一致的同步模型, 也可以从空间维度上为不含有因果, 时序关系的用户数据设计并发模型.")]),s._v(" "),t("p",[s._v("在学术上, 通常会按照 2 个维度对一致性模型分类. 首先是"),t("strong",[s._v("从数据出发设计出的一致性模型")]),s._v(", 比如顺序一致性必须遵照读写操作的次序来保持一致性, 而弱一些的因果一致性则允许不具备因果关系的读写操作并发执行. 其次是"),t("strong",[s._v("从用户出发设计出的一致性模型")]),s._v(", 比如单调读一致性保证客户端不会读取到旧值, 而单调写一致性则保证写操作是串行的.")]),s._v(" "),t("p",[s._v("实际工程中一致性与可用性的边界会模糊很多, 因此又有了"),t("strong",[s._v("最终一致性")]),s._v('这样一个概念, 这个 "最终" 究竟是多久, 将由业务特性, 网络故障率等因素综合决定. 伴随最终一致性的是 BASE 理论:')]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("B")]),s._v("asically "),t("strong",[s._v("A")]),s._v("vailable: 基本可用性")]),s._v(" "),t("li",[t("strong",[s._v("S")]),s._v("oft state: 软状态")]),s._v(" "),t("li",[t("strong",[s._v("E")]),s._v("ventually consistent: 最终一致性")])]),s._v(" "),t("p",[s._v("BASE 与 CAP 一样并没有很精确的定义, 它们最主要的用途是从大方向上给你指导性的思想. 接下来看看如何通过最终一致性来提升性能.")]),s._v(" "),t("h5",{attrs:{id:"_2-怎样舍弃一致性提升性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-怎样舍弃一致性提升性能"}},[s._v("#")]),s._v(" 2.怎样舍弃一致性提升性能?")]),s._v(" "),t("p",[s._v("服务的性能, 主要体现在"),t("strong",[s._v("请求的时延和系统的并发性")]),s._v("这两个方面, 而它们都与上面提到的最终一致性有关. 我通常会把分布式系统分为"),t("strong",[s._v("纵向, 横向")]),s._v("两个维度, 其中"),t("strong",[s._v("纵向是请求的处理路径, 横向则是同类服务之间的数据同步路径.")]),s._v("  这样, 在纵向上在离客户端更近的位置增加数据的副本, 并把它存放在处理速度更快的物理介质上, 就可以作为"),t("strong",[s._v("缓存")]),s._v("降低请求的时延; 而在横向上对数据增加副本, 并在这些主机间同步数据, 这样工作在数据副本上的进程也可以同时对客户端提供服务, 这就增加了系统的并发性, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/11b8983a203e302eb36972427386c7b1-20230731165330-7z8ffnk.png",alt:""}})]),s._v(" "),t("p",[s._v("先来看纵向上的"),t("strong",[s._v("缓存")]),s._v(", 是如何在降低请求处理时延时, 保持最终一致性的. 缓存可以由读, 写两个操作触发更新, 前面介绍过的 HTTP 私有缓存, 就是工作在浏览器上基于读操作触发的缓存.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2bb475551410d037f0a7746b4ce44190-20230731165330-flqmcjz.png",alt:""}})]),s._v(" "),t("p",[s._v("工作在代理服务器上的 HTTP 共享缓存, 也是由读操作触发的. 这些缓存与源服务器上的数据最终是一致的, 但在 CacheControl 等 HTTP 头部指定的时间内, 缓存完全有可能与源数据不同, 这"),t("strong",[s._v("就是牺牲一致性来提升性能")]),s._v("的典型例子.")]),s._v(" "),t("p",[s._v("事实上, 也有很多以写操作触发缓存更新的设计, 它们通常又分为 write back 和 write through 两种模式. 其中, write back 牺牲了更多的一致性, 但带来了更低的请求时延. 比如前面介绍过的 Linux 磁盘高速缓存就采用了 write back 这种设计, 它虽然是单机内的一种缓存设计, 但在分布式系统中缓存的设计方式也是一样的. write through 会在更新数据成功后再更新缓存, 虽然带来了很好的一致性, 但写操作的时延会更久, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b5e1925b45dee5b2698e56341bcffc70-20230731165330-nwubqk5.png",alt:""}})]),s._v(" "),t("p",[s._v("write through 的一致性非常好, 它常常是我们的首选设计. 然而, 一旦缓存到源数据的路径很长, 延时很高的时候, 就值得考虑 write back 模式, 此时一致性模型虽然复杂了许多, 但可以带来显著的性能提升. 比如机械磁盘相对内存延时高了很多, 因此磁盘高速缓存会采用 write back 模式.")]),s._v(" "),t("p",[s._v("虽然缓存也可以在一定程度上增加系统的并发处理连接, 但这更多是缘于缓存采用了更快的算法以及存储介质带来的收益. 从水平方向上, 在更多的主机上添加数据副本, 并在其上用新的进程提供服务, 这才是提升系统并发处理能力最有效的手段. 此时, 进程间同步数据主要包含两种方式: 同步方式以及异步方式, 前者会在每个更新请求完成前, 将数据成功同步到每个副本后, 请求才会处理完成, 而后者则会在处理完请求后, 才开始异步地同步数据到副本中, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8378112424cecbcb52d98882a1b202a6-20230731165330-dqppaxn.png",alt:""}})]),s._v(" "),t("p",[s._v("同步方式下系统的一致性最好, 但由于请求的处理时延包含了副本间的通讯时长, 所以性能并不好. 而异步方式下系统的一致性要差, 特别是在主进程宕机后, 副本上的进程很容易出现数据丢失, 但异步方式的性能要好得多, 这不只由于更新请求的返回更快, 而且异步化后主进程可以基于合并, 批量操作等技巧, 进行效率更高的数据同步. 比如 MySQL 的主备模式下, 默认就使用异步方式同步数据, 当然也可以改为同步方式, 包括 Full-synchronous Replication(同步所有数据副本后请求才能返回)以及 Semi-synchronous Replication(仅成功同步 1 个副本后请求就可以返回)两种方式.")]),s._v(" "),t("p",[s._v("当然, 在扩容, 宕机恢复等场景下, 副本之间的数据严重不一致, 如果仍然基于单个操作同步数据, 时间会很久, 性能很差. 此时应结合定期更新的 Snapshot 快照, 以及实时的 Oplog 操作日志, 协作同步数据, 这样效率会高很多. 其中, 快照是截止时间 T0 时所有数据的状态, 而操作日志则是 T0 时间到当下 T1 之间的所有更新操作, 这样, 副本载入快照恢复至 T0 时刻的数据后, 再通过有限的操作日志与主进程保持一致.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-5"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-5"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了分布式系统中的 CAP 理论, 以及根据 CAP 如何通过一致性来换取性能.")]),s._v(" "),t("p",[t("strong",[s._v("CAP 理论指出, 可用性, 分区容错性, 一致性三者只能取其二, 因此当分布式系统需要服务更多的用户时, 只能舍弃一致性, 换取可用性中的性能因子")]),s._v(". 当然, 性能与一致性并不是简单的二选一, 而是需要根据网络时延, 故障概率设计出一致性模型, 在提供高性能的同时, 保持时间, 空间上可接受的最终一致性.")]),s._v(" "),t("p",[s._v("具体的设计方法, 可以分为"),t("mark",[t("strong",[s._v("纵向上添加缓存, 横向上添加副本进程")])]),s._v("两种做法. 对于缓存的更新, write through 模式保持一致性更容易, 但写请求的时延偏高, 而一致性模型更复杂的 write back 模式时延则更低, 适用于性能要求很高的场景.")]),s._v(" "),t("p",[s._v("提升系统并发性可以通过添加数据副本, 并让工作在副本上的进程同时对用户提供服务. 副本间的数据同步是由写请求触发的, 其中包括同步, 异步两种同步方式. 异步方式的最终一致性要差一些, 但写请求的处理时延更快. 在宕机恢复, 系统扩容时, 采用快照加操作日志的方式, 系统的性能会好很多.")]),s._v(" "),t("h4",{attrs:{id:"_21-akf立方体-怎样通过可扩展性来提高性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_21-akf立方体-怎样通过可扩展性来提高性能"}},[s._v("#")]),s._v(" 21-AKF立方体:怎样通过可扩展性来提高性能?")]),s._v(" "),t("p",[s._v("上一讲谈到, 调低一致性可以提升有状态服务的性能. 这一讲扩大范围, "),t("strong",[s._v("结合无状态服务, 看看怎样提高分布式系统的整体性能")]),s._v(".")]),s._v(" "),t("p",[s._v("当你接收到运维系统的短信告警, 得知系统性能即将达到瓶颈, 或者会议上收到老板兴奋的通知, 接下来市场开缰拓土, 业务访问量将要上一个大台阶时, 一定会马上拿起计算器, 算算要加多少台机器, 系统才能扛得住新增的流量.")]),s._v(" "),t("p",[s._v("然而, 有些服务虽然可以通过加机器提升性能, 但可能你加了一倍的服务器, 却发现系统的吞吐量没有翻一倍. 甚至有些服务无论你如何扩容, 性能都没有半点提升. 这缘于在扩展分布式系统的方向发生了错误.")]),s._v(" "),t("p",[t("strong",[s._v("当需要分布式系统提供更强的性能时, 该怎样扩展系统呢? 什么时候该加机器? 什么时候该重构代码? 扩容时, 究竟该选择哈希算法还是最小连接数算法, 才能有效提升性能")]),s._v("? 在面对 "),t("strong",[s._v("Scalability 可伸缩性问题")]),s._v("时, 必须有一个系统的方法论, 才能应对日益复杂的分布式系统. 这一讲将介绍 AKF 立方体理论, 它定义了扩展系统的 3 个维度, 可以综合使用它们来优化性能.")]),s._v(" "),t("h5",{attrs:{id:"_1-如何基于akf-x轴扩展系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何基于akf-x轴扩展系统"}},[s._v("#")]),s._v(" 1.如何基于AKF X轴扩展系统?")]),s._v(" "),t("p",[s._v("AKF 立方体也叫做 scala cube, 它在《The Art of Scalability》一书中被首次提出, 旨在"),t("strong",[s._v("提供一个系统化的扩展思路")]),s._v(". AKF 把系统扩展分为以下三个维度:")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("X 轴: 直接水平复制应用进程来扩展系统")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("Y 轴: 将功能拆分出来扩展系统")]),s._v(".")]),s._v(" "),t("li",[t("strong",[s._v("Z 轴: 基于用户信息扩展系统")]),s._v(".")])]),s._v(" "),t("p",[s._v("如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/79d96e3bc718ee79b6b3fa7389b69f90-20230731165330-hcjnapa.png",alt:""}})]),s._v(" "),t("p",[s._v("日常见到的各种系统扩展方案, 都可以归结到 AKF 立方体的这三个维度上. 而且, 可以同时组合这 3 个方向上的扩展动作, 使得系统可以近乎无限地提升性能. 为了避免对 AKF 的介绍过于抽象, 下面用一个实际的例子来看看这 3 个方向的扩展到底该如何应用.")]),s._v(" "),t("p",[s._v("假定需要开发一个博客平台, 用户可以申请自己的博客帐号, 并在其上发布文章. 最初的系统考虑了 MVC 架构, 将数据状态及关系模型交给数据库实现, 应用进程通过 SQL 语言操作数据模型, 经由 HTTP 协议对浏览器客户端提供服务, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/6fe7c3b8248d97f53adad7cd26b1ed91-20230731165330-ew31gyu.png",alt:""}})]),s._v(" "),t("p",[s._v("在这个架构中, 处理业务的应用进程属于"),t("strong",[s._v("无状态服务")]),s._v(", 用户数据全部放在了关系数据库中. 因此, 当在应用进程前加 1 个负载均衡服务后, 就可以通过部署更多的应用进程, 提供更大的吞吐量. 而且, 初期增加应用进程, RPS 可以获得线性增长, 很实用.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ce5e00dd273726deeb01abfbdfa8c4de-20230731165330-kzulouy.png",alt:""}})]),s._v(" "),t("p",[s._v("这就叫做沿 AKF X 轴扩展系统. 这种扩展方式最大的优点, 就是开发成本近乎为零, 而且实施起来速度快! 在搭建好负载均衡后, 只需要在新的物理机, 虚拟机或者微服务上"),t("strong",[s._v("复制")]),s._v("程序, 就可以让新进程分担请求流量, 而且不会影响事务 Transaction 的处理.")]),s._v(" "),t("p",[s._v("当然, AKF X 轴扩展"),t("mark",[t("strong",[s._v("最大的问题是只能扩展无状态服务, 当有状态的数据库出现性能瓶颈时, X 轴是无能为力的")])]),s._v(". 例如, 当用户数据量持续增长, 关系数据库中的表就会达到百万, 千万行数据, SQL 语句会越来越慢, 这时可以"),t("mark",[t("strong",[s._v("沿着 AKF Z 轴去分库分表提升性能")])]),s._v(". 又比如, 当请求用户频率越来越高, 那么"),t("strong",[s._v("可以把单实例数据库扩展为主备多实例, 沿 Y 轴把读写功能分离提升性能")]),s._v(". 下面先来看 AKF Y 轴如何扩展系统.")]),s._v(" "),t("h5",{attrs:{id:"_2-如何基于akf-y轴扩展系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何基于akf-y轴扩展系统"}},[s._v("#")]),s._v(" 2.如何基于AKF Y轴扩展系统?")]),s._v(" "),t("p",[t("strong",[s._v("当有状态的数据库的 CPU, 网络带宽, 内存, 磁盘 IO 等某个指标率先达到上限后, 系统的吞吐量就达到了瓶颈, 此时沿着 AKF X 轴扩展系统, 是没有办法提升性能的")]),s._v(".")]),s._v(" "),t("p",[s._v("在现代经济中, 更细分, 更专业的产业化, 供应链分工, 可以给社会带来更高的效率, 而 AKF Y 轴与之相似, 当遇到上述性能瓶颈后, "),t("strong",[s._v("拆分系统功能, 使得各组件的职责, 分工更细, 也可以提升系统的效率")]),s._v(". 比如, 当将应用进程对数据库的读写操作拆分后, 就可以扩展单机数据库为主备分布式系统, 使得主库支持读写两种 SQL, 而备库只支持读 SQL. 这样主库可以轻松地支持事务操作, 且它将数据同步到备库中也并不复杂, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b85364402bfb6252590856fbf1af0695-20230731165330-brtrfal.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, 上图中如果读性能达到了瓶颈, 可以继续沿着 AKF X 轴, 用复制的方式扩展多个备库, 提升读 SQL 的性能, 可见, AKF 多个轴完全可以搭配着协同使用.")]),s._v(" "),t("p",[t("strong",[s._v("拆分功能是需要重构代码的, 它的实施成本比沿 X 轴简单复制扩展要高得多")]),s._v(". 在上图中, 通常关系数据库的客户端 SDK 已经支持读写分离, 所以实施成本由中间件承担了, 这对理解 Y 轴的实施代价意义不大, 所以再来看从业务上拆分功能的例子.")]),s._v(" "),t("p",[s._v("当这个博客平台访问量越来越大时, 一台主库是无法扛住所有写流量的. 因此, 基于业务特性拆分功能, 就是必须要做的工作. 比如, "),t("strong",[s._v("把用户的个人信息, 身份验证等功能拆分出一个子系统")]),s._v(", 再把文章, 留言发布等功能拆分到另一个子系统, 由无状态的业务层代码分开调用, 并通过事务组合在一起, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f50f5e193d3cf73674431b13d5694ca8-20230731165330-ky9ckd9.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, "),t("strong",[s._v("每个后端的子应用更加聚焦于细分的功能, 它的数据库规模会变小, 也更容易优化性能")]),s._v(". 比如, 针对用户登录功能, 可以再次基于 Y 轴将身份验证功能拆分, 用 Redis 等服务搭建一个基于 LRU 算法淘汰的缓存系统, 快速验证用户身份.")]),s._v(" "),t("p",[s._v("然而, 沿 Y 轴做功能拆分, 实施成本非常高, 需要重构代码并做大量测试工作, 上线部署也很复杂. 比如上例中要对数据模型做拆分(如同一个库中的表拆分到多个库中, 或者表中的字段拆到多张表中), 设计组件之间的 API 交互协议, 重构无状态应用进程中的代码, 为了完成升级还要做数据迁移, 等等.")]),s._v(" "),t("p",[s._v("解决数据增长引发的性能下降问题, 除了成本较高的 AKF Y 轴扩展方式外, 沿 Z 轴扩展系统也很有效, 它的实施成本更低一些, 下面具体看一下.")]),s._v(" "),t("h5",{attrs:{id:"_3-如何基于akf-z轴扩展系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何基于akf-z轴扩展系统"}},[s._v("#")]),s._v(" 3.如何基于AKF Z轴扩展系统?")]),s._v(" "),t("p",[s._v("不同于站在服务角度扩展系统的 X 轴和 Y 轴, AKF Z 轴则"),t("strong",[s._v("从用户维度拆分系统, 它不仅可以提升数据持续增长降低的性能, 还能基于用户的地理位置获得额外收益")]),s._v(".")]),s._v(" "),t("p",[s._v('仍然以上面虚拟的博客平台为例, 当注册用户数量上亿后, 无论你如何基于 Y 轴的功能去拆分表(即"垂直"地拆分表中的字段), 都无法使得关系数据库单个表的行数在千万级以下, 这样表字段的 B 树索引非常庞大, 难以完全放在内存中, 最后大量的磁盘 IO 操作会拖慢 SQL 语句的执行.')]),s._v(" "),t("p",[s._v("这个时候, 关系数据库最常用的"),t("strong",[s._v("分库分表")]),s._v("操作就登场了, 它正是 AKF 沿 Z 轴拆分系统的实践. 比如已经含有上亿行数据的 User 用户信息表, 可以分成 10 个库, 每个库再分成 10 张表, 利用固定的哈希函数, 就可以把每个用户的数据映射到某个库的某张表中. 这样, 单张表的数据量就可以降低到 1 百万行左右, 如果每个库部署在不同的服务器上(具体的部署方式视访问吞吐量以及服务器的配置而定), 它们处理的数据量减少了很多, 却可以独占服务器的硬件资源, 性能自然就有了提升. 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/11f52cde3eab9bde14551bb75206367b-20230731165330-2w3a8se.png",alt:""}})]),s._v(" "),t("p",[s._v("分库分表是关系数据库中解决数据增长压力的最有效办法, 但分库分表同时也导致跨表的查询语句复杂许多, 而跨库的事务几乎难以实现, 因此这种扩展的代价非常高. 当然, 如果使用的是类似 MySQL 这些成熟的关系数据库, 整个生态中会有厂商提供相应的中间件层, 使用它们可以降低 Z 轴扩展的代价.")]),s._v(" "),t("p",[s._v("再比如, 最开始采用 X 轴复制扩展的服务, 它们的负载均衡策略很简单, 只需要选择负载最小的上游服务器即可, 比如 RoundRobin 或者最小连接算法都可以达到目的. 但若上游服务器通过 Y 轴扩展, 开启了缓存功能, 那么考虑到缓存的命中率, 就必须改用 Z 轴扩展的方式, 基于用户信息做哈希规则下的新路由, 尽量将同一个用户的请求命中相同的上游服务器, 才能充分提高缓存命中率.")]),s._v(" "),t("p",[s._v("Z 轴扩展还有一个好处, 就是可以充分利用 IDC 与用户间的网速差, 选择更快的 IDC 为用户提供高性能服务. 网络是基于光速传播的, 当 IDC 跨城市, 国家甚至大洲时, 用户访问不同 IDC 的网速就会有很大差异. 当然, 同一地域内不同的网络运营商之间, 也会有很大的网速差. 例如你在全球都有 IDC 或者公有云服务器时, 就可以通过域名为当地用户就近提供服务, 这样性能会高很多. 事实上, CDN 技术就基于 IP 地址的位置信息, 就近为用户提供静态资源的高速访问.")]),s._v(" "),t("p",[s._v("下图使用了 2 种 Z 轴扩展系统的方式. 首先是基于客户端的地理位置, 选择不同的 IDC 就近提供服务. 其次是将不同的用户分组, 比如免费用户组与付费用户组, 这样在业务上分离用户群体后, 还可以有针对性地提供不同水准的服务.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e65e10ac674cfc3205fe45716f8a614f-20230731165330-xdbdu53.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("沿 AKF Z 轴扩展系统可以解决数据增长带来的性能瓶颈, 也可以基于数据的空间位置提升系统性能, 然而它的实施成本比较高")]),s._v(", 尤其是在系统宕机, 扩容时, 一旦路由规则发生变化, 会带来很大的数据迁移成本, 后面将要介绍的一致性哈希算法, 其实就是用来解决这一问题的.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-13"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-13"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节介绍了如何基于 AKF 立方体的 X, Y, Z 三个轴扩展系统提升性能.")]),s._v(" "),t("p",[t("strong",[s._v("X 轴扩展系统时实施成本最低, 只需要将程序复制到不同的服务器上运行, 再用下游的负载均衡分配流量即可. X 轴只能应用在无状态进程上, 故无法解决数据增长引入的性能瓶颈.")])]),s._v(" "),t("p",[t("strong",[s._v("Y 轴扩展系统时实施成本最高, 通常涉及到部分代码的重构, 但它通过拆分功能, 使系统中的组件分工更细, 因此可以解决数据增长带来的性能压力, 也可以提升系统的总体效率. 比如关系数据库的读写分离, 表字段的垂直拆分, 或者引入缓存, 都属于沿 Y 轴扩展系统.")])]),s._v(" "),t("p",[t("strong",[s._v("Z 轴扩展系统时实施成本也比较高, 但它基于用户信息拆分数据后, 可以在解决数据增长问题的同时, 基于地理位置就近提供服务, 进而大幅度降低请求的时延, 比如常见的 CDN 就是这么提升用户体验的. 但 Z 轴扩展系统后, 一旦发生路由规则的变动导致数据迁移时, 运维成本就会比较高.")])]),s._v(" "),t("p",[s._v("当然, X, Y, Z 轴的扩展并不是孤立的, 可以同时应用这 3 个维度扩展系统. 分布式系统非常复杂, AKF 提供了一种自上而下的方法论, 让我们能够针对不同场景下的性能瓶颈, 以最低的成本提升性能.")]),s._v(" "),t("h4",{attrs:{id:"_22-nwr算法-如何修改读写模型以提升性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-nwr算法-如何修改读写模型以提升性能"}},[s._v("#")]),s._v(" 22-NWR算法:如何修改读写模型以提升性能?")]),s._v(" "),t("p",[s._v("前两讲介绍数据库的扩展时, 写请求仍然在操作中心化的 Master 单点, 这在很多业务场景下都是不可接受的. 这一讲将介绍"),t("strong",[s._v("对于无单点的去中心化系统非常有用的 NWR 算法, 它可以灵活地平衡一致性与性能")]),s._v(".")]),s._v(" "),t("p",[s._v("最初我们仅在单机上部署数据库, 一旦性能到达瓶颈, 可以基于 AKF Y 轴将读写分离, 这样多个 Slave 从库将读操作分流后, 写操作就可以独享 Master 主库的全部性能. 然而主库作为中心化的单点, 一旦宕机, 未及时同步到从库的数据就有可能丢失. 而且这一架构下, 主库的故障还会导致整个系统瘫痪.")]),s._v(" "),t("p",[s._v('去中心化系统中没有 "Master 主库" 这一概念, '),t("strong",[s._v("数据存放在多个 Replication 冗余节点上, 且这些节点间地位均等, 所以没有单点问题")]),s._v(". 为了保持强一致性, 系统可以要求修改数据时, 必须同时写入所有冗余节点, 才能向客户端返回成功. 但这样系统的"),t("strong",[s._v("可用性一定很成问题")]),s._v(", 毕竟大规模分布式系统中, 出现故障是常态, 写入全部节点的操作根本无法容错, 任何 1 个节点宕机都会造成写操作失败. 而且, 同步节点过多也会导致写操作性能低下.")]),s._v(" "),t("p",[s._v("NWR 算法提供了一个很棒的读写模型, 可以解决上述问题. "),t("mark",[t("strong",[s._v('这里的 "NWR", 是指在去中心化系统中将 1 份数据存放在 N 个节点上, 每次操作时, 写 W 个节点, 读 R 个节点, 只要调整 W, R 与 N 的关系, 就能动态地平衡一致性与性能')])]),s._v(". NWR 在 NoSQL 数据库中有很广泛的应用, 比如 Amazon 的 Dynamo 和开源的 Cassandra, 这些数据库往往跨越多个 IDC 数据中心, 包含成千上万个物理机节点, 适用于海量数据的存储与处理.")]),s._v(" "),t("p",[s._v("这一讲将介绍 NWR 算法的原理, 包括它是怎样调整读写模型来提升性能的, 以及 Cassandra 数据库是如何使用 NWR 算法的.")]),s._v(" "),t("h5",{attrs:{id:"_1-从鸽巢原理到nwr算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-从鸽巢原理到nwr算法"}},[s._v("#")]),s._v(" 1.从鸽巢原理到NWR算法")]),s._v(" "),t("p",[s._v("NWR 算法是由鸽巢原理得来的: 如果 10 只鸽子放入 9 个鸽巢, 那么有 1 个鸽巢内至少有 2 只鸽子, 这就是鸽巢原理, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/43eb3dcead30e7c6f8151b7326859866-20230731165330-z6vlyrk.png",alt:""}})]),s._v(" "),t("p",[s._v("你可以用反证法证明它. 鸽巢原理虽然简单, 但它有许多很有用的推论. 比如哈希表有没有可能完全不出现冲突呢? 鸽巢原理告诉我们, 只要哈希函数输入主键的值范围大于输出索引, 出现冲突的概率就一定大于 0; 只要存放元素的数量超过哈希桶的数量, 就必然会发生冲突.")]),s._v(" "),t("p",[s._v("基于鸽巢原理, David K. Gifford 在 1979 年"),t("strong",[s._v("首次提出了 Quorum 算法, 解决去中心化系统冗余数据的一致性问题. 而 Quorum 算法提出, 如果冗余数据存放在 N 个节点上, 且每次写操作成功写入 W 个节点(其他 N - W 个节点将异步地同步数据), 而读操作则从 R 个节点中选择并读出正确的数据, 只要确保 W + R > N, 同 1 条数据的读, 写操作就不能并发执行, 这样客户端就总能读到最新写入的数据. 特别是当 W > N/2 时, 同 1 条数据的修改必然是顺序执行的. 这样, 分布式系统就具备了强一致性, 这也是 NWR 算法的由来")]),s._v(".")]),s._v(" "),t("p",[s._v("比如, 若 N 为 3, 那么设置 W 和 R 为 2 时, 在保障系统强一致性的同时, 还允许 3 个节点中 1 个节点宕机后, 系统仍然可以提供读, 写服务, 这样的系统具备了很高的可用性. 当然, R 和 W 的数值并不需要一致, 如何调整它们, 取决于读, 写请求数量的比例. 比如当 N 为 5 时, 如果系统读多写少时, 可以将 W 设为 4, 而 R 设为 2, 这样读操作的性能会更好.")]),s._v(" "),t("p",[s._v("NWR 算法最早应用在 Amazon 推出的 Dynamo 数据库中. 2008 年 Dynamo 的作者 Avinash Lakshman 跳槽到 FaceBook, 开发了 Dynamo 的开源版数据库 Cassandra, 它是目前最流行的 NoSQL 数据库之一, 在 Apple, Netflix, 360 等公司得到了广泛的应用. 想必你对 NWR 算法的很多细节并不清楚, 那么接下来以 Cassandra 为例, 看看 NWR 是如何应用在实际工程中的.")]),s._v(" "),t("h5",{attrs:{id:"_2-cassandra数据库是如何使用nwr算法的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-cassandra数据库是如何使用nwr算法的"}},[s._v("#")]),s._v(" 2.Cassandra数据库是如何使用NWR算法的?")]),s._v(" "),t("p",[s._v("1 个 Cassandra 分布式系统可以"),t("strong",[s._v("由多个 IDC 数据中心, 数万个服务器节点构成, 这些节点间使用 RPC 框架通信")]),s._v(", 由于 Cassandra 推出时 gRPC还没有诞生, 因此它使用的是性能相对较低的 Thrift RPC 框架. 同时, Cassandra 虽然使用宽列存储模型(每行最多可以包含 20 亿列数据), 但"),t("strong",[s._v("数据的分布是基于行 Key 进行的")]),s._v(", 它和 Dynamo 一样使用了一致性哈希算法, 将 Key 对应的数据存储在多个节点中.")]),s._v(" "),t("p",[s._v("Cassandra 对客户端提供一种类 SQL 的CQL 语言, 可以使用下面这行 CQL 语句设定数据存储的冗余节点个数, 也就是 NWR 算法中的 N(也称为 Replication Factor):")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("CREATE KEYSPACE excalibur\n  WITH REPLICATION "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'class'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'NetworkTopologyStrategy'")]),s._v(", "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'dc1'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("上面这行 CQL 语句设置了每行数据在数据中心 DC1 中存储 3 份冗余, 即 N = 3, 接下来通过下面的 CQL 语句, 将读 R, 写 W 的节点数都设置为 1:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("cqlsh"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" CONSISTENCY ONE\nConsistency level "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" to ONE.\ncqlsh"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" CONSISTENCY\nCurrent consistency level is ONE.\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("**此时, Cassandra 的性能最高, 但达成最终一致性的耗时最长, 丢数据风险也最大. **如果业务上对丢失少量数据不太在意, 可以采用这种模型. 此时修改数据时, 客户端会并发地向 3 个存储节点写入数据, 但只要 1 个节点返回成功, Cassandra 就会向客户端返回写入成功, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/396a4772c6d5bd14919026fb8e2e60f8-20230731165330-uu0mfey.png",alt:""}})]),s._v(" "),t("p",[s._v("上图中的系统由 12 个主机节点构成, 由于数据采用一致性哈希算法分片, 故构成了一个节点环. 其中, 本次写入的数据被分布到 1, 3, 6 这 3 个节点中存储. 客户端可以随机连接到系统中的任何一个节点访问 Cassandra, 此时该节点被称为 Coordinator Node, 由它根据 NWR 的值来选择一致性模型, 访问存储节点.")]),s._v(" "),t("p",[s._v("再来看读取数据的流程. 下图中, 作为 Coordinator Node 的节点 10 首先试图读取节点 1 中的数据, 但发现节点 1 已经宕机, 于是改选节点 6 并获取到数据, 由于 R = 1 于是立刻向客户端返回成功.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/376b25ebd9ec54b360592a5cc850a322-20230731165330-4y9q36x.png",alt:""}})]),s._v(" "),t("p",[s._v("如果将 R, W 都设置成 2, 这就满足了 R + W > N(3) 的场景, 此时系统具备了"),t("strong",[s._v("强一致性")]),s._v(". 客户端读写数据时, 必须有 2 个节点返回, 才算操作成功. 比如下图中读取数据时, 只有接收到节点 1, 节点 6 的返回, 操作才算成功.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/085288ebdb85dc4c523d63bbbca6e5cb-20230731165330-pnsml6z.png",alt:""}})]),s._v(" "),t("p",[s._v("上图中的蓝色线叫做 Read repair, 如果节点 3 上的数据不一致, 那么本次读操作可以将它修复为正确的数据. 说完正常场景, 再来看"),t("strong",[s._v("当一个节点出现异常时")]),s._v(", NWR 是如何保持强一致性的.")]),s._v(" "),t("p",[s._v("下图中, 客户端 1 在第 2 步, 同时向 3 个存储节点写入了数据, 由于节点 1, 3 返回成功, 所以写入操作实际已经完成了, 但是节点 6 由于"),t("strong",[s._v("网络故障")]),s._v(", 却一直没有收到 Coordinator Node 发来的写入操作. 在强一致性的约束下, 客户端 2 在第 5 步发起的读请求, 必须"),t("strong",[s._v("能获取到第 2 步写入的数据")]),s._v(". 然而, 客户端 2 连接的 Coordinator Node 与客户端 1 不同, 它选择了节点 3 和节点 6, 这两个节点上的数据并不一致. "),t("strong",[s._v("根据不同的 timestamp 时间戳, Coordinator Node 发现节点 3 上的数据才是最后写入的数据, 因此选择其上的数据返回客户端. 这也叫 Last-Write-Win 策略.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4024451cdedfba3ef89a1eb9756dc483-20230731165330-qomdwmx.png",alt:""}})]),s._v(" "),t("p",[s._v("Cassandra 提供了一个简单的方法, 用于"),t("strong",[s._v("设置读写节点数量都过半, 满足强一致性的要求")]),s._v(", 如下所示:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("cqlsh"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" CONSISTENCY QUORUM\nConsistency level "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" to QUORUM.\ncqlsh"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" CONSISTENCY\nCurrent consistency level is QUORUM.\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("最后再来看看"),t("strong",[s._v("多数据中心的部署方式")]),s._v(". 下图中 2 个数据中心各设置 N = 3, 其中 R, W 则采用 QUORUM 一致性模型. 当客户端发起写请求到达节点 10 这个 Coordinator Node 后, 它选择本 IDC Alpha 的 1, 3, 6 节点存储数据, 其中节点 3, 6 返回成功后, IDC Alpha 便更新成功. 同时找到另一 IDC Beta 的节点 11 存储数据, 并由节点 11 将数据同步给节点 4 和节点 8. 其中, 只要节点 4 返回成功, IDC Beta 也就成功更新了数据, 此时 Coordinator Node 会向客户端返回写入成功.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e36f7499e77dc33a0aaa12c13e5e1e61-20230731165330-vgy0tch.png",alt:""}})]),s._v(" "),t("p",[s._v("读取数据时, 这 2 个 IDC 内必须由 4 个存储节点返回数据, 才满足 QUORUM 一致性的要求. 下图中, Coordinator Node 获取到了 IDC Alpha 中节点 1, 3, 6 的返回, 以及 IDC Beta 中节点 11 的返回, 就可以基于 timestamp 时间戳选择最新的数据返回客户端. 而且 Coordinator Node 会并发地发起 Read repair, 试图修复 IDC Beta 中可能存在不一致的节点 4 和 8.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8f48b3e1dc2b7661449e93a0fc44a312-20230731165330-31owngd.png",alt:""}})]),s._v(" "),t("p",[s._v("Cassandra 还有许多一致性模型, 比如 LOCAL_QUORUM 只要求本地 IDC 内有多数节点响应即可, 而 EACH_QUORUM 则要求每个 IDC 内都必须有多数节点返回成功(注意, 这与上图中 IDC Alpha 中有 3 个节点返回, 而 IDC Beta 则只有 1 个节点返回的 QUORUM 是不同的). 你可以从这个页面找到 Cassandra 支持的所有一致性模型, 但无论如何变化, 都只是在引入数据中心, 机架等概念后, 局部性地调节 NWR 而已.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-6"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-6"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了鸽巢原理, 以及由此推导出的 NWR 算法, 并以流行的 NoSQL 数据库 Cassandra 为例, 介绍了 NWR 在分布式系统中的实践.")]),s._v(" "),t("p",[s._v("当鸽子的数量超过了鸽巢后, 就要注定某一个鸽巢内一定含有两只以上的鸽子, 同样的道理, "),t("mark",[t("strong",[s._v("只要读, 写操作涉及的节点超过半数, 就注定读写操作总包含一个含有正确数据的节点")])]),s._v(". NWR 算法将这一原理一般化为: "),t("mark",[t("strong",[s._v("只要读节点数 R + 写节点数 W > 存储节点数 N, 特别是 W > N/2 时, 就能使去中心的分布式系统获得强一致性")])]),s._v(".")]),s._v(" "),t("p",[s._v("支持上万节点的 Cassandra 数据库, 就使用了 NWR 算法来保持一致性. 当然, Cassandra 支持多种一致性模型, 当需要更强劲的性能时, 可以令 R + W < N, 当业务变化导致需要增强系统的一致性时, 可以实时地修改 R, W. Cassandra 也支持跨数据中心部署, 此时的一致性模型更为复杂, 但仍然将 NWR 算法作为实现基础.")]),s._v(" "),t("h4",{attrs:{id:"_23-负载均衡-选择nginx还是openresty"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_23-负载均衡-选择nginx还是openresty"}},[s._v("#")]),s._v(" 23-负载均衡:选择Nginx还是OpenResty?")]),s._v(" "),t("p",[s._v("前面介绍 AKF 立方体时, 讲过只有在下游添加负载均衡后, 才能沿着 X, Y, Z 三个轴提升性能. 这一讲, 将介绍最流行的"),t("strong",[s._v("负载均衡 Nginx, OpenResty")]),s._v(", 看看它们是如何支持 AKF 扩展体系的.")]),s._v(" "),t("p",[s._v("负载均衡通过将流量分发给新增的服务器, 提升了系统的性能. 因此, 对负载均衡最基本的要求, 就是它的"),t("strong",[s._v("吞吐量要远大于上游的应用服务器, 否则扩展能力会极为有限")]),s._v(". 因此, 目前性能最好的 Nginx, 以及在 Nginx 之上构建的 OpenResty, 通常是第一选择.")]),s._v(" "),t("p",[s._v("系统接入层的负载均衡, 常通过 Waf 防火墙承担着网络安全职责, 系统内部的负载均衡则通过权限, 流量控制等功能承担着 API 网关的职责, CDN 等边缘节点上的负载均衡还会承担边缘计算的任务. 如果负载均衡不具备高度开放的设计, 或者推出时间短, 社区不活跃, 就无法像搭积木一样, 从整个生态中低成本地构建出符合需求的负载均衡.")]),s._v(" "),t("p",[s._v("很幸运的是, Nginx 完全符合上述要求, 它性能一流而且非常稳定. 从 2004 年诞生之初, Nginx 的"),t("strong",[s._v("模块化设计")]),s._v("就未改变过, 这样 16 年来累积下的各种 Nginx 模块都可以复用. 它的 2-clause BSD-like license 源码许可协议极其开放, 即使修改源码后仍然可作商业用途, 因此 Nginx 之上延伸出了 TEngine, OpenResty, Kong 等生态, 这大大扩展了 Nginx 的能力边界.")]),s._v(" "),t("p",[s._v("接下来, 就以 Nginx 以及建立了 Lua 语言生态的 OpenResty 为例, 看看负载均衡是怎样扩展系统的, 以及 Nginx 和同源的 OpenResty 有何不同.")]),s._v(" "),t("h5",{attrs:{id:"_1-负载均衡是如何扩展系统提升性能的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-负载均衡是如何扩展系统提升性能的"}},[s._v("#")]),s._v(" 1.负载均衡是如何扩展系统提升性能的?")]),s._v(" "),t("p",[s._v("通过 AKF 立方体 X 轴扩展系统时, 负载均衡只需要能够"),t("strong",[s._v("透传协议")]),s._v(", 并选择负载最低的上游应用作为流量分发对象即可. 这样, 三层(网络层), 四层(传输层)负载均衡都可用于扩展系统, 甚至在单个局域网内你还可以使用二层(数据链路层)负载均衡. 其中, "),t("strong",[s._v("分发流量的路由算法既可以使用 RoundRobin 轮转算法, 也可以基于 TCP 连接或者 UDP Session 使用最少连接数算法")]),s._v(", 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f85819ccc2c4d0dabeb7428f0f44b312-20230731165330-lssjps2.png",alt:""}})]),s._v(" "),t("p",[s._v("然而, 基于 AKF Y 轴扩展系统时, 负载均衡必须根据功能来分发请求, 也就是说它必须解析完应用层协议, 才能明白这是什么请求. 因此, 如 LVS 这样工作在三层和四层的负载均衡就无法满足需求了, 就"),t("mark",[t("strong",[s._v("需要 Nginx 这样的七层(应用层)负载均衡, 它能够从请求中获取到描述功能的关键信息, 并以此为依据路由请求")])]),s._v(". 比如当 HTTP 请求中的 URL 描述功能时, Nginx 就可以用 location 匹配 URL, 再基于 location 来路由请求, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f198fbd640791f43d2ab268f629df356-20230731165330-jgvlja7.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("基于 AKF Z 轴扩展时, 如果只是使用了网络报文中的源 IP 地址, 那么三层, 四层负载均衡都能胜任. 然而如果需要帐号, 访问对象等用户信息扩展系统, 仍然只能使用七层负载均衡从请求中获得")]),s._v(". 比如, Nginx 可以通过 "),t("code",[s._v("$")]),s._v("​ 变量获取到 URL 参数或者 HEADER 头部的值, 再以此作为路由算法的输入参数.")]),s._v(" "),t("p",[s._v("因此, **七层负载均衡是分布式系统提升性能的必备工具. **除了基于各种路由策略分发流量, 提高性能及可用性(如宕机迁移)外, 负载均衡还需要完成上, 下游协议间的适配, 转换. 例如考虑到信息安全, 跑在公网上的外部协议常基于 TLS/SSL 协议, 而在效率优先的企业内网中, 一般不会使用大幅降低性能的 TLS 协议, 因此负载均衡需要拥有卸载或者装载 TLS 层的能力.")]),s._v(" "),t("p",[s._v("再比如, 下游客户端多样且难以保持一致(比如 IE6 这个古董浏览器仍然存在于当下的互联网中), 因此常使用 HTTP 协议与服务器通讯, 而上游组件则依据开发团队或者系统架构的特点, 会选择 CGI, uWSGI, gRPC 等协议, 这样负载均衡还得拥有转换各种协议的功能. Nginx 可以通过反向代理模块, 轻松适配各类协议, 如下所示(通过 stream 模块, Nginx 也支持四层负载均衡):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/924e4a5ed4b41d0f5265e20be4fd5f59-20230731165330-01snf1x.png",alt:""}})]),s._v(" "),t("p",[s._v("从性能角度, Nginx 支持 C10M 级别的并发连接. 从功能角度, 良好的模块化设计, 使得 Nginx 可以完成各类协议的适配, 不只包括前面介绍过的通用协议, 甚至支持 Redis, MySQL 等专有协议. 因此, Nginx 是目前最好用的负载均衡.")]),s._v(" "),t("h5",{attrs:{id:"_2-nginx上为什么可以执行lua代码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-nginx上为什么可以执行lua代码"}},[s._v("#")]),s._v(" 2.Nginx上为什么可以执行Lua代码?")]),s._v(" "),t("p",[t("strong",[s._v("OpenResty 也非常流行, 其实它就是 Nginx, 只是通过扩展的 C 模块支持在 Nginx 中嵌入 Lua 语言, 这样 Lua 模块构建出的生态就可以与 C 模块协作使用, 大幅度提升了开发效率")]),s._v(". 先来看下 OpenResty 与 Nginx 之间的关系.")]),s._v(" "),t("p",[s._v("OpenResty 源代码由"),t("strong",[s._v("官方 Nginx, 第三方 C 模块, Lua 语言模块以及一些工具脚本")]),s._v("构成. 编译 Nginx 时, OpenResty 将自己的第三方 C 模块按照 Nginx 的规则添加到可执行文件中, 包括 ngx_http_lua_module 和 ngx_stream_lua_module 这两个 C 模块, 它们允许 Lua 语言运行在 Nginx 进程中, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b0504e7928a274b4a4eff46ad3d9d2c5-20230731165330-4thu6u5.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v('Lua 模块既能够享受 Nginx 的高性能, 又通过"协程", Lua 脚本语言提高了开发效率')]),s._v(", 这也是 OpenResty 最大的优点. 先来看看 Lua 语言是怎么嵌入到 Nginx 中的.")]),s._v(" "),t("p",[s._v("**Nginx 在进程启动, 处理请求时提供了许多钩子函数, 允许第三方 C 模块将其代码放在这些钩子函数中执行. 同时, Nginx 还允许 C 模块自行解析 nginx.conf 中出现的配置项. **这种架构允许 OpenResty 将 Lua 代码写进 nginx.conf 文件, 再基于LuaJIT 即时编译到 Nginx 中执行.")]),s._v(" "),t("p",[s._v("ngx_http_lua_module 模块也正是通过 OpenResty 提供的以下 11 个指令嵌入 Lua 代码的:")]),s._v(" "),t("ol",[t("li",[s._v("在 Nginx 启动时嵌入 Lua 代码, 包括 master 进程启动时执行的 "),t("strong",[s._v("init_by_lua")]),s._v(" 指令, 以及每个 worker 进程启动时执行的 "),t("strong",[s._v("init_worker_by_lua")]),s._v(" 指令.")]),s._v(" "),t("li",[s._v("在重写 URL, 访问权限控制等预处理阶段嵌入 Lua 代码, 包括解析 TLS 协议后的 "),t("strong",[s._v("ssl_certificate_by_lua")]),s._v(" 指令(基于 openssl 的回调函数实现), 设置动态变量的 "),t("strong",[s._v("set_by_lua")]),s._v(" 指令, 重写 URL 阶段的 "),t("strong",[s._v("rewrite_by_lua")]),s._v(" 指令, 以及控制访问权限的 "),t("strong",[s._v("access_by_lua")]),s._v(" 指令.")]),s._v(" "),t("li",[s._v("生成 HTTP 响应时嵌入 Lua 代码, 包括直接生成响应的 "),t("strong",[s._v("content_by_lua")]),s._v(" 指令, 连接上游服务前的 "),t("strong",[s._v("balancer_by_lua")]),s._v(" 指令, 处理响应头部的 "),t("strong",[s._v("header_filter_by_lua")]),s._v(" 指令, 以及处理响应包体的 "),t("strong",[s._v("body_filter_by_lua")]),s._v(" 指令.")]),s._v(" "),t("li",[s._v("记录 access.log 日志时嵌入 Lua 代码, 通过 "),t("strong",[s._v("log_by_lua")]),s._v(" 指令实现.")])]),s._v(" "),t("p",[s._v("如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a370d8265295e0ab87ba2493766ae8fa-20230731165330-bzxtvwm.png",alt:""}})]),s._v(" "),t("p",[s._v("ngx_stream_lua_module 模块与之类似, 这里不再赘述.")]),s._v(" "),t("p",[s._v("当然, 如果 Lua 代码只是可以在 Nginx 进程中执行, 它是无法处理用户请求的. 还需要"),t("strong",[s._v("让 Lua 代码与 Nginx 中的 C 代码互相调用, 去获取, 改变 HTTP 请求, 响应的内容")]),s._v(". 因此, ngx_http_lua_module 和 ngx_stream_lua_module 这两个模块通过 FFI 技术, 将 C 函数通过 Ngx 库中的 Lua API, 暴露给纯 Lua 代码, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7ef8518d8c54801e7ad164d97c3fb33c-20230731165330-tnbeld6.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, 通过 nginx.conf 文件中的 11 个指令, 以及 FFI 技术提供的 SDK, Lua 代码才真正可以处理请求, Lua 生态从这里开始延伸, 因此, OpenResty 上还提供了进一步提高开发效率的 Lua 模块库(参见 "),t("code",[s._v("/usr/local/openresty/lualib/")]),s._v("​ 目录).")]),s._v(" "),t("h5",{attrs:{id:"_3-nginx与openresty的差别在哪里"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-nginx与openresty的差别在哪里"}},[s._v("#")]),s._v(" 3.Nginx与OpenResty的差别在哪里?")]),s._v(" "),t("p",[s._v("清楚了 OpenResty 与 Nginx 间的相同之处, 再来看二者默认编译出的 Nginx 可执行程序有何不同之处.")]),s._v(" "),t("p",[s._v("首先看版本差异. 当在官网下载 Nginx 时, 会发现有 3 类版本: Mainline, Stable 和 Legacy. 其中, Mainline 是单号版本, 它是含有最新功能的主线版本, 迭代速度最快. Stable 是 mainline 版本稳定运行一段时间后, 将单号大版本转换为双号的稳定版本, 比如 1.18.0 就是由 1.17.10 转换而来. Legacy 则是曾经的稳定版本, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/19af6875ccaffcf53d6ebfb916afa2f7-20230731165330-x9sylh7.png",alt:""}})]),s._v(" "),t("p",[s._v("可以通过源代码中的 CHANGES 文件, 通过 4 种不同类型的变更查看版本间的差异, 包括:")]),s._v(" "),t("ol",[t("li",[s._v("表示新功能的 "),t("strong",[s._v("Feature")]),s._v(", 比如下图中 HTTP 服务新增的 auth_delay 指令.")]),s._v(" "),t("li",[s._v("表示已修复问题的 "),t("strong",[s._v("Bugfix")]),s._v(".")]),s._v(" "),t("li",[s._v("表示已知特性变更的 "),t("strong",[s._v("Change")]),s._v(", 比如 Nginx 曾经允许 HTTP 请求头部中出现多个 Host 头部, 但在 1.17.9 这个 Change 之后, 这类 HTTP 请求将作为非法请求处理.")]),s._v(" "),t("li",[s._v("表示安全升级的 "),t("strong",[s._v("Security")]),s._v(", 比如 1.15.6 版本就修复了 CVE-2018-16843 等 3 个安全问题.")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c17dc497d8e5c487d61e5be3b08097eb-20230731165330-2mx53ab.png",alt:""}})]),s._v(" "),t("p",[s._v("当安装好了 OpenResty 或者 Nginx 后, 可以通过 nginx -v 命令查看它们的版本. 你会发现, "),t("strong",[s._v("2014 年以后发布的 OpenResty 都是运行在单号 Mainline 版本上的:")])]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# /usr/local/nginx/sbin/nginx -v")]),s._v("\nnginx version: nginx/1.18.0\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# /usr/local/openresty/nginx/sbin/nginx -v")]),s._v("\nnginx version: openresty/1.15.8.3\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("通常一般会选择稳定的 Stable 版本, OpenResty 为什么会选择单号的 Mainline 版本呢? 这是因为, Nginx 与 OpenResty 的版本发布频率完全不同, 2012 年后 Nginx 每年大约发布 10 多个版本, 如下图所示(versions 统计了每年发布的版本数, 图中其他 3 条拆线统计了每年 feature, bugfix, change 的变更次数):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1ec42336f5e2a7f59a8e4f0d73bc32ca-20230731165330-257hltm.png",alt:""}})]),s._v(" "),t("p",[s._v("OpenResty 每年的版本更新频率是个位数, 特别是从 2018 年到现在, OpenResty 只发布了 4 个版本. 所以**为了使用尽量运行在最新版本上, OpenResty 选择了 Mainline 单号版本. **")]),s._v(" "),t("p",[s._v("你可能会想, OpenResty 并没有修改 Nginx 的源代码, 为什么不能由用户在官方 Nginx 上自行添加 C 模块, 实现 OpenResty 的安装呢? 这源于部分 OpenResty C 模块, 没有按照 Nginx 架构指定的顺序添加到模块列表中, 而且它们的编译环境也过于复杂. 因此, OpenResty 放弃了 Nginx 官方的 configure 文件, 用户需要使用 OpenResty 改造过的 configure 脚本编译 Nginx.")]),s._v(" "),t("p",[s._v("再来看模块间的差异. 如果你留意 OpenResty 与 Nginx 间二进制文件的体积, 会发现使用默认配置时, **OpenResty 的可执行文件大了 5 倍. **")]),s._v(" "),t("p",[s._v("这由 2 个原因所致.")]),s._v(" "),t("p",[s._v("首先, 官方 Nginx 提供的四层负载均衡功能(由 18 个 STREAM 模块实现), TLS 协议处理功能, 默认都是不添加到 Nginx 中的, 而 OpenResty 的 configure 脚本将其改为了默认模块. 当然, 如果在编译官方 Nginx 时, 加入以下选项:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("./configure --with-stream --with-stream_ssl_module --with-stream_ssl_preread_module --with-http_ssl_module\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("那么从官方模块上, Nginx 就与 OpenResty 完全一致了, 此时再观察二进制文件的体积, 会发现它翻了一倍.")]),s._v(" "),t("p",[s._v("其次, OpenResty 添加了近 20 个第三方 C 模块, 除了前文介绍过支持 Lua 语言的 2 个模块外, 还有支持 Redis, Memcached, MySQL 等服务的模块. 这些模块编译时, 还需要链接依赖的软件库, 因此它们又将 Nginx 可执行文件的体积增加了 1 倍多.")]),s._v(" "),t("p",[s._v("除版本, 模块外, OpenResty 与 Nginx 间还有一些小的差异, 比如 Nginx 使用了 GCC 编译器的 -O1 优化参数, 而 OpenResty 则使用了 -O2 优化参数. 再比如, 官方 Nginx 最新版本的 Makefile 支持 upgrade 参数, 简化了热升级操作. 当然, 这些小改动并不重要, 只要修改 configure 脚本就能做到.")]),s._v(" "),t("p",[s._v("到底该如何在二者中选择呢? 我认为, "),t("strong",[s._v("如果不使用 Lua 语言, 那么建议使用 Nginx. 官方 Nginx 的 Stable 版本更稳定, 可执行文件的体积也更小. 如果需要使用 OpenResty, TEngine 中的部分 C 模块, 可以通过 –add-module 选项将其加入到官方 Nginx 中.")])]),s._v(" "),t("p",[s._v("如果所有 C 模块都无法满足业务需求, 就应该选择 OpenResty. 注意, Lua 语言带来极大灵活性的同时, 也会引入许多不确定性. 比如, 如果调用了会导致进程休眠的 Lua 阻塞函数(比如封装了系统调用的原生 Lua 库, 或者第三方服务提供的同步 SDK), 将会导致 Nginx 正在处理数万并发请求的 C 模块同时进入休眠, 从而让服务的性能大幅度下降.")]),s._v(" "),t("h4",{attrs:{id:"_24-一致性哈希-如何高效地均衡负载"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_24-一致性哈希-如何高效地均衡负载"}},[s._v("#")]),s._v(" 24-一致性哈希:如何高效地均衡负载?")]),s._v(" "),t("p",[s._v("前面提到的 Cassandra 数据库将服务器节点组成一个环来存储数据, 所使用的就是一致性哈希算法. 本节就来看看一致性哈希算法是怎样工作的.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("使用哈希算法扩展系统时, 最大的问题在于代表哈希桶的服务器节点数发生变化时, 哈希函数就改变了, 数据与节点间的映射关系自然发生了变化, 结果大量数据就得在服务器间迁移. 特别是含有多份冗余数据的系统, 迁移工作量更是会成倍提高.")])])]),s._v(" "),t("p",[s._v("同时, 为了在整体上更加充分地使用 IT 资源, 必须解决分布式系统扩展时可能出现的两个问题: "),t("strong",[s._v("数据分布不均衡和访问量不均衡")]),s._v(". 比如, 对于包含 10 个服务器节点, 持久化 1 亿条用户数据的有状态服务, 如果采用关键字模 10(key%10) 的哈希算法作为路由策略, 就很难保证每个节点处理 1 千万条数据, 那些可能还未达到一半设计容量的节点会浪费大量磁盘空间.")]),s._v(" "),t("p",[s._v("即使节点间存储的数据非常均匀, 但这些数据间的活跃程度也不相同, 存放热点数据较多的节点访问量非常大, 很容易率先达到 CPU 瓶颈, 在许多主机节点还很空闲时, 就得扩容系统. 特别是很难保证集群内的所有节点都是同构的, 如果哈希算法不能区别对待不同配置的服务器, 也会抬高 IT 成本.")]),s._v(" "),t("p",[s._v("一致性哈希算法可以解决上述问题, 它在许多流行的开源软件上都有很广泛的应用. 这一讲将"),t("strong",[s._v("介绍一致性哈希算法的工作原理, 以及如何通过虚拟节点提升算法的均衡性")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-如何减少扩容-缩容时迁移的数据量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-如何减少扩容-缩容时迁移的数据量"}},[s._v("#")]),s._v(" 1.如何减少扩容,缩容时迁移的数据量?")]),s._v(" "),t("p",[s._v("在主机硬件达到性能瓶颈后, 有状态服务可以沿 AKF 立方体 Z 轴, 基于"),t("strong",[s._v("哈希算法")]),s._v("扩展为分布式系统. 下图系统中拥有 5 个节点, 哈希算法将每条数据的关键字模 5 得出的数字作为哈希桶序号, 从而将数据映射到节点上(如果关键字是字符串或者其他结构化数据, 可以先通过其他哈希算法转换为整数, 再进行模运算):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4b0a12bba795ebb157a768f5333e935c-20230731165330-18x6m0l.png",alt:""}})]),s._v(" "),t("p",[s._v("这个方案实现简单, 运算速度也快, 但它最大的问题是"),t("strong",[s._v("在系统扩容或者缩容时, 必须迁移改变了映射关系的数据")]),s._v(". 然而, 取模哈希函数中基数的变化, 往往会导致绝大部分映射关系改变, 比如上例中的 5 个关键字, 在下图中集群节点数(即基数)从 5 降为 4 时, "),t("strong",[s._v("原映射关系全部失效, 这 5 条数据都得迁移到其他节点")]),s._v(":")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b409ef41ff9f0fdb2e2d560e08be8258-20230731165330-ld2q39t.png",alt:""}})]),s._v(" "),t("p",[s._v("1997 年发布的《Consistent Hashing and Random Trees》论文提出了一致性哈希算法, 可以大幅度减少数据迁移量. 一致性哈希算法是通过以下 2 个步骤来建立数据与主机节点间映射关系的:")]),s._v(" "),t("ol",[t("li",[s._v("首先, "),t("strong",[s._v("将关键字经由通用的哈希函数映射为 32 位整型哈希值. 这些哈希值会形成 1 个环, 最大的数字 232 相当于 0")]),s._v(".")]),s._v(" "),t("li",[s._v("其次, "),t("strong",[s._v("设集群节点数为 N, 将哈希环由小至大分成 N 段, 每个主机节点处理哈希值落在该段内的数据")]),s._v(". 比如下图中, 当节点数 N 等于 3 且均匀地分段时, 节点 0 处理哈希值在 [0, 31​∗232] 范围内的关键字, 节点 1 处理 [31​∗232, 32​∗232] 范围内的关键字, 而节点 2 则处理的范围是 [32​∗232, 232]:")])]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/6c8e30b2a7dca7943c6d679e17a2a310-20230731165330-25ugopo.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("当然, 在生产环境中主机节点很可能是异构的, 所以要给高规格的服务器节点赋予更高的权重. 一致性哈希算法改变节点的权重非常简单, 只需要给每个节点分配更大的弧长即可.")]),s._v("  例如, 如果上图中的节点 0 拥有更高的硬件配置, 那么可以将原本均匀分布的 3 个节点调整为 2:1:1 的权重, 这样节点 0 处理的哈希值范围调整为 [0, 231], 节点 1 的处理范围调整为 [231, 3∗230], 节点 2 的处理范围调整为 [3∗230, 232], 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c8c71a5e4b4f7d7f82128e3c9ddb123d-20230731165330-ravo2et.png",alt:""}})]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("而扩容, 缩容时, 虽然节点数发生了变化, 但只要小幅度调整环上各节点的位置, 就不会导致大量数据的迁移")])]),s._v(". 比如下图中我们将 3 个节点的集群扩容为 4 个节点, 只需要将节点 0 上一半的数据迁移至节点 3 即可, 其他节点不受影响:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b10e3a7346354a219ae4fc37e16befc3-20230731165330-i0yyhca.png",alt:""}})]),s._v(" "),t("p",[s._v("接下来从成本上分析下一致性哈希算法的优劣. 假设总数据条数为 M, 而节点个数为 N, 先来看映射函数的时间复杂度. 传统的哈希算法以 N 为基数执行取模运算, 时间复杂度为 O(1); 一致性哈希算法需要将关键字先转换为 32 位整型(这 1 步的时间复杂度也是 O(1)), 再根据哈希环中各节点的处理范围, 找到所属的节点. "),t("strong",[s._v("由于所有节点是有序排列的, 所以采用二分法, 可以在")]),s._v(" "),t("mark",[t("strong",[s._v("O(logN)")])]),s._v(" "),t("strong",[s._v("时间复杂度内, 完成关键字到节点位置的映射.")])]),s._v(" "),t("p",[s._v("再来评估下数据的迁移规模. 节点变化会导致传统哈希算法的映射结果不可控, 最坏情况下所有数据都需要迁移, 所以它的数据迁移规模是 O(M); 对于一致性哈希算法, 可以通过调整节点位置, 任意设定迁移规模. "),t("strong",[s._v("在环中各节点均匀分布的情况下, 数据迁移规模是")]),s._v(" "),t("mark",[t("strong",[s._v("O(M/N)")])]),s._v("​ "),t("strong",[s._v(".")])]),s._v(" "),t("p",[s._v("因此, 一致性哈希算法的缺点是将映射函数的时间复杂度从 O(1) 提高到了 O(logN), 它的优点是将数据迁移规模从 O(M) 降低至 O(M/N). **由于数据条数 M 远大于主机节点数 N, 而且数据迁移的成本很大, 所以一致性哈希算法更划算, 它的适用场景也更广! **")]),s._v(" "),t("h5",{attrs:{id:"_2-如何通过虚拟节点提高均衡度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何通过虚拟节点提高均衡度"}},[s._v("#")]),s._v(" 2.如何通过虚拟节点提高均衡度?")]),s._v(" "),t("p",[s._v("一致性哈希算法虽然降低了数据的迁移量, 但却"),t("strong",[s._v("遗留了两个问题没有解决")]),s._v(".")]),s._v(" "),t("p",[s._v("首先, "),t("strong",[s._v("如果映射后哈希环中的数字分布不均匀, 就会导致各节点处理的数据不均衡, 从而降低了系统的运行效率与性能")]),s._v(". 在无法找出分布规律时, 也无法通过调整环中节点的权重, 平衡各节点处理的数据量.")]),s._v(" "),t("p",[s._v("其次, "),t("strong",[s._v("容灾与扩容时, 哈希环上的相邻节点容易受到过大影响")]),s._v(". 比如下图中, 当节点 0 宕机后, 根据一致性哈希算法的规则, 其上数据应该全部迁移到相邻的节点 1 上, 这样节点 1 的数据量, 访问量都会迅速增加 1 倍, 一旦新增的压力超过了节点 1 的处理能力上限, 就会导致节点 1 崩溃, 进而形成雪崩式的连锁反应:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/6198f4257c99c19770a129a3c9f8f490-20230731165330-iaolqb3.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("系统扩容时也面临着同样的问题, 除非同时调整环中各节点的位置, 否则扩容节点也只会减轻相邻节点的负载.")])]),s._v(" "),t("p",[s._v("当数据存在多份冗余时, 这两类问题会被进一步放大.")]),s._v(" "),t("p",[s._v("那如何提高均衡性呢? "),t("mark",[t("strong",[s._v("在真实的数据节点与哈希环之间引入一个虚拟节点层")])]),s._v("​ "),t("strong",[s._v(", 就可以解决上述问题.")]),s._v("  例如下图中的集群含"),t("strong",[s._v("有 4 个节点")]),s._v(", 但并不直接将哈希环分为 4 份, 而是将它"),t("strong",[s._v("均匀地分为 32 份并赋予 32 个虚拟节点")]),s._v(", 因此每个虚拟节点会处理 227 个哈希值, 再将 32 个虚拟节点通过某个哈希函数(比如 CRC32)映射到 4 个真实节点上(比如图中 8 个绿色虚拟节点皆由同色的主机节点 0 处理):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0d0010350358f5d42d0b7ce4c7dde26c-20230731165330-6jc5pum.png",alt:""}})]),s._v(" "),t("p",[s._v("这样, "),t("mark",[t("strong",[s._v("如果图中绿色的节点 0 宕机, 按照哈希环上数据的迁移规则, 8 个绿色虚拟节点上的数据就会沿着顺时针方向, 分别迁移至相邻的虚拟节点上, 最终会迁移到真实节点 1(橙色), 节点 2(蓝色), 节点 3(水红色)上")])]),s._v(". 所以, 宕机节点上的数据会迁移到其他所有节点上.")]),s._v(" "),t("p",[t("strong",[s._v("扩容时也是一样的, 通过虚拟节点环, 新增节点可以分担现有全部节点的压力")]),s._v(". 至于虚拟节点为什么可以让数据的分布更均衡, 这是因为在虚拟节点与真实节点间, 又增加了一层哈希映射, 哈希函数会将原本不均匀的数字进一步打散. 上图为了方便你理解, 每个真实节点仅包含 8 个虚拟节点, 这样能起到的均衡效果其实很有限. 而在实际的工程中, 虚拟节点的数量会大很多, 比如 Nginx 的一致性哈希算法, 每个权重为 1 的真实节点就含有 160 个虚拟节点.")]),s._v(" "),t("p",[s._v("当然, 有了虚拟节点后, 为异构的服务器节点设置权重也更方便. 只需要为权重高的真实节点, 赋予更多的虚拟节点即可. 注意, **虚拟节点增多虽然会提升均衡性, 但也会消耗更多的内存与计算力. **")]),s._v(" "),t("p",[s._v("上面仅讨论了数据分布的均衡性, 当热点数据导致访问量不均衡时, 因为这一新维度的信息还没有反馈在系统中, 所以需要搜集各节点的访问量信息, 基于它来动态地调整真实节点的权重, 进而从热点数据更多的节点中迁移出部分数据, 以此提高均衡性.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-7"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-7"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了一致性哈希算法的工作原理.")]),s._v(" "),t("p",[s._v("传统哈希函数中, 主机节点的变化会导致大量数据发生迁移. "),t("strong",[s._v("一致性哈希算法将 32 位哈希值构成环, 并将它分段赋予各节点, 这样, 扩容, 缩容动作就只影响相邻节点, 大幅度减少了数据迁移量. 一致性哈希算法虽然将数据的迁移量从 O(M) 降为 O(M/N), 却也将映射函数的时间复杂度从 O(1) 提高到 O(logN), 但由于节点数量 N 并不会很大, 所以一致性哈希算法的性价比还是很高的")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("当哈希值分布不均匀时, 数据分布也不会均衡. 在哈希环与真实节点间, 添加虚拟节点层, 可以通过新的哈希函数, 分散不均匀的数据. 每个真实节点含有的虚拟节点数越多, 数据分布便会越均衡, 但同时也会消耗更多的内存与计算力. 虚拟节点带来的最大优点, 是宕机时由所有节点共同分担流量缺口, 这避免了可能产生的雪崩效应. 同时, 扩容的新节点也会分流所有节点的压力, 这也提升了系统整体资源的利用率.")])]),s._v(" "),t("h4",{attrs:{id:"_25-过期缓存-如何防止缓存被流量打穿"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_25-过期缓存-如何防止缓存被流量打穿"}},[s._v("#")]),s._v(" 25-过期缓存:如何防止缓存被流量打穿?")]),s._v(" "),t("p",[s._v("本节将对一直零散介绍的"),t("strong",[s._v("缓存")]),s._v("做个全面的总结, 同时讨论"),t("strong",[s._v("如何解决缓存被流量打穿的场景")]),s._v(".")]),s._v(" "),t("p",[s._v("在分布式系统中, 缓存无处不在. 比如, 浏览器会缓存用户 Cookie, CDN 会缓存图片, 负载均衡会缓存 TLS 的握手信息, Redis 会缓存用户的 session, MySQL 会缓存 select 查询出的行数据, HTTP/2 会用动态表缓存传输过的 HTTP 头部, TCP Socket Buffer 会缓存 TCP 报文, Page Cache 会缓存磁盘 IO, CPU 会缓存主存上的数据, 等等.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v("只要系统间的访问速度有较大差异, 缓存就能提升性能")])]),s._v(". 如果你不清楚缓存的存在, 两个组件间重合的缓存就会带来不必要的复杂性, 同时还增大了数据不一致引发错误的概率. 比如, MySQL 为避免自身缓存与 Page Cache 的重合, 就使用直接 IO 绕过了磁盘高速缓存.")]),s._v(" "),t("p",[s._v("缓存提升性能的幅度, 不只取决于存储介质的速度, 还取决于"),t("strong",[s._v("缓存命中率")]),s._v(". 为了提高命中率, 缓存会基于时间, 空间两个维度更新数据. 在时间上可以采用 LRU, FIFO 等算法淘汰数据, 而在空间上则可以预读, 合并连续的数据. 如果只是简单地选择最流行的缓存管理算法, 就很容易忽略业务特性, 从而导致缓存性能的下降.")]),s._v(" "),t("p",[s._v("在分布式系统中, 缓存服务会为上游应用挡住许多流量. 如果只是简单的基于定时器淘汰缓存, 一旦热点数据在缓存中失效, 超载的流量会立刻打垮上游应用, 导致系统不可用.")]),s._v(" "),t("p",[t("strong",[s._v("这一讲会系统地介绍缓存及其数据变更策略, 同时会以 Nginx 为例介绍过期缓存的用法.")])]),s._v(" "),t("h5",{attrs:{id:"_1-缓存是最有效的性能提升工具"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-缓存是最有效的性能提升工具"}},[s._v("#")]),s._v(" 1.缓存是最有效的性能提升工具")]),s._v(" "),t("p",[s._v("在计算机体系中, 各类硬件的访问速度天差地别. 比如:")]),s._v(" "),t("ol",[t("li",[s._v("CPU 访问缓存的耗时在 10 纳秒左右, 访问内存的时延则翻了 10 倍;")]),s._v(" "),t("li",[s._v("如果访问 SSD 固态磁盘, 时间还要再翻个 1000 倍, 达到 100 微秒;")]),s._v(" "),t("li",[s._v("如果访问机械硬盘, 对随机小 IO 的访问要再翻个 100 倍, 时延接近 10 毫秒;")]),s._v(" "),t("li",[s._v("如果跨越网络, 访问时延更要受制于主机之间的物理距离. 比如杭州到伦敦相距 9200 公里, ping 时延接近 200 毫秒. 当然, 网络传输的可靠性低很多, 一旦报文丢失, TCP 还需要至少 1 秒钟才能完成报文重传.")])]),s._v(" "),t("p",[s._v("可见, 最快的 CPU 缓存与最慢的网络传输, 有 1 亿倍的速度差距! 一旦高速, 低速硬件直接互相访问, 前者就会被拖慢运行速度. 因此, 一般"),t("strong",[s._v("会使用高速的存储介质创建缓冲区, 通过预处理, 批处理以及缓冲数据的反复命中, 提升系统的整体性能.")])]),s._v(" "),t("p",[s._v("不只是硬件层面, 软件设计对访问速度的影响更大. 比如, 对关系数据库的非索引列做条件查询, 时间复杂度是 O(N), 而对 Memcached 做 Key/Value 查询, 时间复杂度则是 O(1), 所以在海量数据下, 两者的性能差距远高于硬件. 因此, RabbitMQ, Kafka 这样的消息服务也会充当高速, 低速应用间的缓存.")]),s._v(" "),t("p",[s._v("如果两个实体之间的访问时延差距过大, 还可以通过"),t("strong",[s._v("多级缓存")]),s._v(", 逐级降低访问速度差, 提升整体性能. 比如 CPU 三级缓存, 每级缓存越靠近 CPU 速度越快, 容量也越小, 以此缓解 CPU 频率与主存的速度差, 提升 CPU 的运行效率.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1e8184cfc528dc2d6c40b4226a1e5d35-20230731165330-31a6qd7.png",alt:""}})]),s._v(" "),t("p",[s._v("再比如下图的 Web 场景中, 浏览器的本地缓存, 操作系统内核中的 TCP 缓冲区, 负载均衡中的 TLS 握手缓存, 应用服务中的 HTTP 响应缓存, MySQL 中的查询缓存等, 每一级缓存都缓解了上下游间不均衡的访问速度, 通过缩短访问路径降低了请求时延, 通过异步访问, 批量处理提升了系统效率. 当然, 缓存使用了简单的 Key/Value 结构, 因此可以用哈希表, 查找树等容器做索引, 这也提升了访问速度.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b298b19094503694e01837de33ca254d-20230731165330-9tipyyl.png",alt:""}})]),s._v(" "),t("p",[s._v("这些缓存的应用场景大相径庭, 但数据的更新方式却很相似, 下面来看看"),t("strong",[s._v("缓存是基于哪些原理来更新数据")]),s._v("的.")]),s._v(" "),t("h5",{attrs:{id:"_2-缓存数据的更新方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-缓存数据的更新方式"}},[s._v("#")]),s._v(" 2.缓存数据的更新方式")]),s._v(" "),t("p",[t("strong",[s._v("缓存的存储容量往往小于原始数据集")]),s._v(", 这有许多原因, 比如:")]),s._v(" "),t("ol",[t("li",[s._v("缓存使用了速度更快的存储介质, 而这类硬件的单位容量更昂贵, 因此从经济原因上只能选择更小的存储容量;")]),s._v(" "),t("li",[s._v("负载均衡可以将上游服务的动态响应转换为静态缓存, 从时间维度上看, 上游响应是无限的, 这样负载均衡的缓存容量就一定会不足;")]),s._v(" "),t("li",[s._v("即使桌面主机的磁盘容量达到了 TB 级, 但浏览器要对用户访问的所有站点做缓存, 就不可能缓存一个站点上的全部资源, 在一对多的空间维度下, 缓存一样是稀缺资源.")])]),s._v(" "),t("p",[s._v("因此, 必须"),t("strong",[s._v("保证在有限的缓存空间内, 只存放会被多次访问的")]),s._v("​"),t("mark",[t("strong",[s._v("热点数据")])]),s._v("​ "),t("strong",[s._v(", 通过提高命中率来提升系统性能")]),s._v(". 要完成这个目标, 必须精心设计向缓存中添加哪些数据, 缓存溢出时淘汰出哪些冷数据. 先来看前者.")]),s._v(" "),t("p",[s._v("通常, 缓存数据的添加或者更新, 都是由用户请求触发的, 这往往可以带来更高的命中率. 比如, 当读请求完成后, 将读出的内容放入缓存, 基于"),t("strong",[s._v("时间局部性原理")]),s._v(", 它有很高的概率被后续的读请求命中. 前面介绍过的 HTTP 缓存就采用了这种机制.")]),s._v(" "),t("p",[s._v("对于磁盘操作, 还可以基于"),t("strong",[s._v("空间局部性原理")]),s._v(", 采用预读算法添加缓存数据(参考 PageCache). 比如当统计出连续两次读 IO 的操作范围也是连续的, 就可以判断这是一个顺序读 IO, 如果这个读 IO 获取 32KB 的数据, 就可以在这次磁盘中, 多读出 128KB 的数据放在缓存, 这会带来 2 个收益:")]),s._v(" "),t("ol",[t("li",[s._v("首先, 通过减少定位时间提高了磁盘工作效率. 机械磁盘容量大价格低, 它的顺序读写速度由磁盘旋转速度与存储密度决定, 通常可以达到 100MB/s 左右. 然而, 由于机械转速难以提高(服务器磁盘的转速也只有 10000 转 /s), 磁头定位与旋转延迟大约消耗了 8 毫秒, 因此对于绝大部分时间花在磁头定位上的随机小 IO(比如 4KB), 读写吞吐量只有几 MB.")]),s._v(" "),t("li",[s._v("其次, 当后续的读请求命中提前读入缓存的数据时, 请求时延会大幅度降低, 这提升了用户体验.")])]),s._v(" "),t("p",[s._v("而且, 并不是只有单机进程才能使用预读算法. 比如公有云中的云磁盘, 之所以可以实时地挂载到任意虚拟机上, 就是因为它实际存放在类似 HDFS 这样的分布式文件系统中. 因此, 云服务会在宿主物理机的内存中缓存虚拟机发出的读写 IO, 由于网络传输的成本更高, 所以预读效果也更好.")]),s._v(" "),t("p",[s._v("写请求也可以更新缓存, 可以参考介绍过 write through 和 write back 方式. 其中, write back 采用异步调用回写数据, 能通过批量处理提升性能. 比如 Linux 在合并 IO 的同时, 也会像电梯运行一样, 每次使磁头仅向一个方向旋转写入数据, 提升机械磁盘的工作效率, 因此得名为电梯调度算法.")]),s._v(" "),t("p",[s._v("说完数据的添加, 再来看 2 种最常见的"),t("strong",[s._v("缓存淘汰算法")]),s._v(".")]),s._v(" "),t("p",[s._v("首先来看 FIFO(First In, First Out) 先入先出淘汰算法. 前面介绍的 HTTP/2 动态表, 会将 HTTP/2 连接上首次出现的 HTTP 头部, 缓存在客户端, 服务器的内存中. 由于它们基于相同的规则生成, 所以拥有相同的动态表序号. 这样, 传输 1-2 个字节的表序号, 要比传输几十个字节的头部划算得多. 当内存容量超过 SETTINGS_HEADER_TABLE_SIZE 阈值时, 会基于 FIFO 算法将最早缓存的 HTTP 头部淘汰出动态表.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d76b025807fbcc7db4e2a3704e241a59-20230731165330-z5d0bft.png",alt:""}})]),s._v(" "),t("p",[s._v("再比如 TLS 握手很耗时, 所以可以将密钥缓存在客户端, 服务器中, 等再次建立连接时, 通过 session ID 迅速恢复 TLS 会话. 由于内存有限, 服务器必须及时淘汰过期的密钥, 其中, "),t("strong",[s._v("Nginx 也是采用 FIFO 队列淘汰 TLS 缓存的")]),s._v(".")]),s._v(" "),t("p",[s._v("其次, LRU(Less Recently Used) 也是最常用的淘汰算法, 比如 Redis 服务就通过它来淘汰数据, OpenResty 在进程间共享数据的 shared_dict 在达到共享内存最大值后, 也会通过 LRU 算法淘汰数据. LRU 通常使用双向队列实现(时间复杂度为 O(1)), 队首是最近访问的元素, 队尾就是最少访问, 即将淘汰的元素. 当访问了队列中某个元素时, 可以将其移动到队首. 当缓存溢出需要淘汰元素时, 直接删除队尾元素, 如下所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1360e074ed2f2dbe357ee7e70e6144a4-20230731165330-i2zyywv.png",alt:""}})]),s._v(" "),t("p",[s._v("以上只谈了缓存容量到达上限后的淘汰策略, 为了避免缓存与源数据不一致, 在传输成本高昂的分布式系统中, 通常会"),t("strong",[s._v("基于过期时间")]),s._v("来淘汰缓存. 比如 HTTP 响应中的 Cache-Control, Expires 或者 Last-Modified 头部, 都会用来设置定时器, 响应过期后会被淘汰出缓存. 然而, 一旦热点数据被淘汰出缓存, 那么来自用户的流量就会穿透缓存到达应用服务. 由于缓存服务性能远大于应用服务, 过大的流量很可能会将应用压垮. 因此, 过期缓存并不能简单地淘汰, 下面以 Nginx 为例, 看看如何利用过期缓存提升系统的可用性.")]),s._v(" "),t("h5",{attrs:{id:"_3-nginx是如何防止流量打穿缓存的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-nginx是如何防止流量打穿缓存的"}},[s._v("#")]),s._v(" 3.Nginx是如何防止流量打穿缓存的?")]),s._v(" "),t("p",[t("strong",[s._v("当热点缓存淘汰后, 大量的并发请求会同时回源上游应用")]),s._v(", 其实这是不必要的. 比如下图中 Nginx 的合并回源功能开启后, N"),t("strong",[s._v("ginx 会将多个并发请求合并为 1 条回源请求, 并锁住所有的客户端请求, 直到回源请求返回后, 才会更新缓存, 同时向所有客户端返回响应")]),s._v(". 由于 Nginx 可以支持 C10M 级别的并发连接, 因此可以很轻松地锁住这些并发请求, 降低应用服务的负载.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7dd3bc5d55d9b21464917359cd829c8b-20230731165330-zkldef4.png",alt:""}})]),s._v(" "),t("p",[s._v("启用合并回源功能很简单, 只需要在 nginx.conf 中添加下面这条指令即可:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("proxy_cache_lock on"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v('如果上游服务确实不可用, 那有没有办法可以通过 Nginx 提供降级服务呢? 所谓 "服务降级", 是指部分服务出现故障后, 通过有策略地放弃一些可用性, 来保障核心服务的运行, 这也是 BASE 理论中 Basically Available 的实践. '),t("strong",[s._v("如果 Nginx 上持有着过期的缓存, 那就可以通过牺牲一致性, 向用户返回过期缓存, 以保障基本的可用性")]),s._v(". 比如下图中, Nginx 会直接将过期缓存返回给客户端, 同时也会一直试图更新缓存(proxy_cache_background_update 指令决定是由用户请求还是异步请求回源上游).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/cec61f658f25f4bae9367ad6e4af1a2e-20230731165330-zeo628a.png",alt:""}})]),s._v(" "),t("p",[s._v("开启过期缓存功能也很简单, 添加下面这行指令即可:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[s._v("proxy_cache_use_stale updating"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("h5",{attrs:{id:"_4-小结-14"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-14"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节系统地总结了缓存的工作原理, 以及 "),t("strong",[s._v("Nginx 解决缓存穿透问题")]),s._v("的方案.")]),s._v(" "),t("p",[s._v("当组件间的访问速度差距很大时, 直接访问会降低整体性能, 在二者之间添加更快的缓存是常用的解决方案. 根据时间局部性原理, 将请求结果放入缓存, 会有很大概率被再次命中, 而根据空间局部性原理, 可以将相邻的内容预取至缓存中, 这样既能通过批处理提升效率, 也能降低后续请求的时延.")]),s._v(" "),t("p",[s._v("由于缓存容量小于原始数据集, 因此需要将命中概率较低的数据及时淘汰出去. 其中最常用的淘汰算法是 FIFO 与 LRU, 它们执行的时间复杂度都是 O(1), 效率很高.")]),s._v(" "),t("p",[s._v("由于缓存服务的性能远大于上游应用, 一旦大流量穿透失效的缓存到达上游后, 就可能压垮应用. Nginx 作为 HTTP 缓存使用时, 可以打开合并回源功能, 减轻上游压力. 在上游应用宕机后, 还可以使用过期缓存为用户提供降级服务.")]),s._v(" "),t("h4",{attrs:{id:"_26-应用层多播-如何快速地分发内容"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_26-应用层多播-如何快速地分发内容"}},[s._v("#")]),s._v(" 26-应用层多播:如何快速地分发内容?")]),s._v(" "),t("p",[s._v("前面曾介绍了网络层的 IP 协议是如何支持多播的, 本节再来"),t("strong",[s._v("从应用层看看如何实现多播功能")]),s._v(".")]),s._v(" "),t("p",[s._v("当分布式集群只有十多个节点时, 每次发布版本时, 尽可以从发布服务器, 将新版本的安装包通过 ftp, scp, wget 等工具分发到各个节点中. 可是, 一旦集群规模达到成千上万个节点时, 再这么做就会带来很大的问题, 文件分发的时长高达几个小时, 甚至会打挂文件源终止分发流程. 在微服务环境中这点尤为明显, 毕竟每个 Docker 镜象的体积动辄就在数百兆字节以上.")]),s._v(" "),t("p",[s._v("虽然网络层的 IP 协议允许通过路由器, 交换机实现高效的多播, 但 IP 层很难实现文件的可靠传输, 而且跨越多个局域网时路由器等网络设备对 IP 多播的支持也不好. 此时, 通过应用层的接力传播, 就能通过多播思想大幅提升系统的传输效率, 解决上述问题.")]),s._v(" "),t("p",[s._v("除了分发文件场景外, 应用层多播协议也常用于完全去中心化的分布式系统, 特别是在管理成千上万个节点的状态时非常有用. 比如 Gossip 就是这样一个多播协议, 前面介绍过的 Cassandra 数据库使用它来同步节点间的状态, 比特币通过它传输账本数据, Redis 集群也使用它同步 Redis 进程间的状态.")]),s._v(" "),t("p",[s._v("本节就重点介绍应用层中的多播协议, 并以阿里的蜻蜓, Cassandra 中的 "),t("strong",[s._v("Gossip 协议")]),s._v("为例, 看看它们的工作原理.")]),s._v(" "),t("h5",{attrs:{id:"_1-认识应用层的多播协议"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-认识应用层的多播协议"}},[s._v("#")]),s._v(" 1.认识应用层的多播协议")]),s._v(" "),t("p",[s._v("之所以需要应用层的多播协议, 是因为网络层的 IP 多播功能有以下 4 个方面的问题:")]),s._v(" "),t("ol",[t("li",[s._v("从功能上看, IP 多播缺失了质量控制, 可靠性传输等特性, 无法满足绝大部分场景中的要求;")]),s._v(" "),t("li",[s._v("从管理上看, 监控跨网络的多播报文并不容易, 多播地址的管理也很复杂, 而且多播很容易造成网络洪峰及安全问题;")]),s._v(" "),t("li",[s._v("从市场上看, 单播报文在终端上的计费很成熟, 相反, 运营商对多播报文的计费要困难许多, 相对缺乏推进动力;")]),s._v(" "),t("li",[s._v("从产业协作上看, IP 多播必须由各设备厂商的路由器, 交换机配合, 由于网络层是由内核实现的, 所以还要同步升级操作系统.")])]),s._v(" "),t("p",[s._v("这些因素都使得网络层的多播功能难以推广, 因此, 各类基于 IP 单播功能的应用层多播协议应运而生. 可能有些同学对于单播, 多播这些网络知识还不熟悉, 下图将传统单播, 网络层多播, 应用层多播放在一起对比着看, 可以很容易看到它们的区别.")]),s._v(" "),t("p",[s._v("这里仍然以"),t("strong",[s._v("版本发布场景")]),s._v("为例, 主机 1 是发布节点, 它需要将文件分发到其余 3 台主机上, 其中传统单播协议的玩法, 是在主机 2, 3, 4 上分别向主机 1 发起下载文件命令, 因此主机 1 上有 3 条 TCP 下载链路, 图中用 3 种不同的颜色表示. 很明显, 此时主机 1 的下行流量一定会成为瓶颈, 而且随着集群规模的扩大, 网络链路中的路由器也会很快达到流量瓶颈.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/97ac8c15102246d453178f53d9ba18c8-20230731165330-jomas1b.png",alt:""}})]),s._v(" "),t("p",[s._v("再来看效率最高的网络层多播, 主机 1 可以仅通过 1 次报文传输, 将文件分发到所有主机上. 在整个流程中, 仅由路由器将网络报文扩散到相邻的主机, 路由器上, 没有任何多余的动作. 如同上述所说, 网络层多播的使用有很多困难, 这里列出它是为了方便与应用层多播作对比.")]),s._v(" "),t("p",[s._v("在上图的应用层多播中, 文件传输分为两个阶段. 首先, 主机 2, 3 直接从主机 1 中下载文件(参见绿色与红色线). 其次, 当主机 3 完成下载后, 主机 4 再从主机 3 上下载文件(参见蓝色线). 可见, 相对于 IP 多播, **应用层多播有以下 3 个缺点: **")]),s._v(" "),t("p",[s._v("首先网络效率下降了不少, 这由 2 个原因所致:")]),s._v(" "),t("ol",[t("li",[s._v("数据在网络中有冗余, 比如主机 1 将数据重复发送了 2 次(参见红色, 绿色线), 主机 3 既接收了一次数据, 也发送了一次数据;")]),s._v(" "),t("li",[s._v("虽然图中主机 4 从同一局域网中的主机 3 下载数据, 但在复杂的互联网环境中, 应用层很难掌握完整的路由器组网信息, 主机 4 一旦跨网络从主机 2 上下载数据, 这就增加了路由器 A 及网络链路的负载, 效率进一步下降.")])]),s._v(" "),t("p",[s._v("其次, 由于传输路径变长了, 文件传输的总完成时间也变长了. 比如, 主机 4 的总传输路径是: 主机 1 -> 路由器 A -> 路由器 B -> 主机 3 -> 路由器 B -> 主机 4, 既多出了主机 3, 路由器 B 这两个传输环节, 而且进入主机 3 后, 协议栈的处理深度也增加了.")]),s._v(" "),t("p",[s._v("最后, 单次传输路径中引入了功能复杂的主机, 相比仅由网络设备参与的 IP 多播, 可靠性, 稳定性也降低了.")]),s._v(" "),t("p",[s._v("说完缺点, 再来看应用层多播的优点.")]),s._v(" "),t("ol",[t("li",[s._v("首先, 它回避了 IP 多播的问题, 无须改变现有组网环境, 也不需要管理组播 IP 地址, 立刻就可以应用在当下的生产环境中;")]),s._v(" "),t("li",[s._v("其次, 在数以万计的大规模集群下, 单一发布源很容易被流量打爆, 进而导致分发流程停止, 应用层多播可以避免这一问题;")]),s._v(" "),t("li",[s._v("再次, 通过应用层节点的接力分发, 整个传输带宽被大幅度提高了, 分发速度有了数量级上的飞跃;")]),s._v(" "),t("li",[s._v("最后, 如果分发集群跨越不同传输成本的网络(比如多个区域 IDC 构成的集群), 在应用层也很容易控制分发策略, 进而减少高成本网络的数据传输量, 提升经济性.")])]),s._v(" "),t("p",[s._v("所以, 综合来说, "),t("strong",[s._v("集群规模越大, 应用层多播的优势也越大.")]),s._v("  接下来结合 2 个服务器端的案例, 看看多播协议的实现与应用.")]),s._v(" "),t("h5",{attrs:{id:"_2-应用层多播协议是如何工作的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-应用层多播协议是如何工作的"}},[s._v("#")]),s._v(" 2.应用层多播协议是如何工作的?")]),s._v(" "),t("p",[s._v("其实, 应用层多播主要是指一种 "),t("strong",[s._v("P2P")]),s._v("(Peer to Peer)网络传输思想, 任何基于 IP 单播的通讯协议都可以拿来使用. 比如针对于在分布式集群中分发软件安装包的场景, 完全可以使用 HTTP 协议实现应用层的分发, 阿里巴巴开源的 Dragonfly 蜻蜓就是这么做的.")]),s._v(" "),t("p",[s._v("蜻蜓拥有 1 个中心化的集群服务节点: SuperNode, 其中既可以直接保存着源文件, 也可以通过 HTTP 缓存加速第三方文件源(比如 Docker 仓库). 集群中的每个节点都要启动 dfget 进程(替代了传统的 wget), 它就像平时使用的迅雷, 在下载文件的同时, 也会将自己下载完成的文件传输给其他节点. 其中, 通过 HTTP 的 Range 文件分段下载规范, dfget 就可以实现断点续传, 多线程下载等功能, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/138eccd74942628ff8e650d9e3a0aa9a-20230731165330-j8fgqyh.png",alt:""}})]),s._v(" "),t("p",[s._v("各个 dfget 程序间通过 SuperNode 协调传输关系, 这样绝大部分 dfget 程序并不需要从 SuperNode 节点下载文件. 比如上图中的节点 C, 通过 HTTP Range 协议从节点 A 中下载了文件的第 1 块, 同时并发地从节点 B 中下载了文件的第 2 块, 最后再把这些 Block 块拼接为完整的文件.")]),s._v(" "),t("p",[s._v("这里你可能会想, 这不就是一个 P2P 下载工具么? 是的, 但站在集群运维的角度, 这就是基于应用层多播协议的文件分发工具. 当每个节点部署 dfget 服务后, 新版本安装包发布时, 就可以由 SuperNode 节点推送, 经由各个 dfget 进程以多播的形式分发下去, 此时性能会获得大幅度的提升.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7227792b60bfeee41d4d9d204de218ad-20230731165330-7bb4z3t.png",alt:""}})]),s._v(" "),t("p",[s._v("上图是传统的 wget 单播与蜻蜓多播分发文件的性能对比图. 可以看到, 传统方式下, 分发客户端越多(Y 轴)总分发时长(X 轴)就越大, 特别是 1200 个以上的并发节点下载文件时, 会直接将文件源打爆. 而采用应用层多播方式后, 下载时长要低得多, 而且伴随着节点数的增加, 下载时长也不会增长.")]),s._v(" "),t("p",[s._v("蜻蜓虽然传输效率很高, 但 SuperNode 却是保存着全局信息的中心节点, 一旦宕机就会造成系统不可用. 再来"),t("strong",[s._v("看去中心化的 Gossip 流言协议是如何实现应用层多播的")]),s._v(".")]),s._v(" "),t("p",[s._v("Gossip 协议也叫 epidemic 传染病协议, 工作原理如下图所示. 在这个分布式网络中, 并没有任何中心化节点, 但只要第 1 个种子节点被感染为红色后, 每个节点只需要感染其相邻的, 有限的几个节点, 最终就能快速感染网络中的所有节点(即仅"),t("strong",[s._v("保证最终一致性")]),s._v(").")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/de7b15095cc60549de7107300d651a88-20230731165330-s78ozvt.png",alt:""}})]),s._v(" "),t("p",[s._v('当然, 所谓的"感染"就是数据的传输, 这一算法由 1987 年发布的《Epidemic algorithms for replicated database maintenance》论文提出, 同时证明了算法的收敛概率. '),t("strong",[s._v("Cassandra 数据库, Fabric 区块链, Consul 系统等许多去中心化的分布式系统, 都使用 Gossip 协议管理集群中的节点状态")]),s._v(". 以 Cassandra 为例, 每秒钟每个节点都会随机选择 1 到 3 个相邻节点, 通过默认的 7000 端口传输包含节点状态的心跳信息, 这样集群就可以快速发现宕机或者新增的节点.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/142b6303922ebcb41e26a424f8f914b6-20230731165330-8tsy8p5.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_3-小结-8"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-8"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了应用层的多播协议.")]),s._v(" "),t("p",[s._v("网络层的 IP 多播功能有限, 对网络环境也有过多的要求, 所以很难通过多播协议提升传输效率. 基于 IP 单播协议(如 TCP 或者 UDP), 在应用代码层面实现分布式节点间的接力转发, 就可以实现应用层的多播功能.")]),s._v(" "),t("p",[s._v("在分布式集群的文件分发场景中, 阿里开源的Dragonfly 蜻蜓可以将发布节点上的源文件, 通过 HTTP 协议推送到集群中的每个节点上, 其中每个节点在应用层都参与了多播流量分发的实现. 当节点数到达千, 万级时, 蜻蜓仍然能保持较低的分发时延, 避免发布节点被下行流量打爆.")]),s._v(" "),t("p",[s._v("在完全去中心化的分布式集群中, 每个节点都没有准确的全局信息, 此时可以使用 Gossip 流言协议, 通过仅向有限的相邻节点发送消息, 完成整个集群的数据同步, 实现"),t("strong",[s._v("最终一致性")]),s._v(". 因此, "),t("strong",[s._v("Gossip 协议常用于大规模分布集群中的节点状态同步")]),s._v(".")]),s._v(" "),t("h4",{attrs:{id:"_27-消息队列-如何基于异步消息提升性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_27-消息队列-如何基于异步消息提升性能"}},[s._v("#")]),s._v(" 27-消息队列:如何基于异步消息提升性能?")]),s._v(" "),t("p",[s._v("本节来看看如何通过消息队列提升分布式系统的性能.")]),s._v(" "),t("p",[t("strong",[s._v("异步通讯是最常用的性能提升方式")]),s._v(", 比如 gRPC 提供的异步 API, 或者基于 write-back 模式向缓存写入数据时, 系统性能都可以提高. 然而, 对于复杂的大规模分布式系统, 这些分散, 孤立的异步实现机制, 无法解决以下问题:")]),s._v(" "),t("ol",[t("li",[s._v("组件间耦合在一起, 不只迭代变更时更为困难, 而且当它们之间的性能有差异时, 吞吐量较低的组件就会成为系统瓶颈;")]),s._v(" "),t("li",[s._v("当业务在时间上具有明显的峰谷访问差异时, 实现"),t("strong",[s._v("削峰填谷")]),s._v("需要一定的开发成本;")]),s._v(" "),t("li",[s._v("实现 BASE 理论中的 Basically Available 并不容易;")]),s._v(" "),t("li",[s._v("每个组件都要自行维护负载均衡组件, 以此提供可伸缩性;")]),s._v(" "),t("li",[s._v("每个组件的请求格式, 日志都不尽相同, 因此系统总体的监控成本相对较高;")]),s._v(" "),t("li",[s._v("批量处理请求, 异步化都可以提升性能, 但每个组件独立实现这些基础功能付出的成本并非完全必要.")])]),s._v(" "),t("p",[s._v("想必你肯定听过 Kafka, RabbitMQ, RocketMQ 这些流行的消息队列吧? 通过消息队列实现组件间的异步交互方式, 上述问题就会迎刃而解. 本节就来看看"),t("strong",[s._v("如何在分布式系统中使用消息队列, 以及高可用性又是如何保证的")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-消息队列解决了哪些问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-消息队列解决了哪些问题"}},[s._v("#")]),s._v(" 1.消息队列解决了哪些问题?")]),s._v(" "),t("p",[s._v("当进程中需要交互的两个模块性能差距很大时, 会基于 FIFO 先入先出队列实现生产者消费者模型, 通过调整生产者, 消费者的数量, 实现线程间的负载均衡. 而且, 生产者仅将任务添加至队列首部就可以返回, 这种异步操作释放了它的性能. 比如前面介绍的接收心跳包的分发线程性能要比处理心跳包的工作线程性能高得多, 两者间就通过单机上的消息队列提高了整体性能.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/60017c7a59124a0d6b91a7cec3e7a3d7-20230731165330-juylvh3.png",alt:""}})]),s._v(" "),t("p",[s._v("把单机中的 FIFO 队列放大到分布式系统中, 就形成了独立的消息队列服务. 此时, 生产者, 消费者的角色从线程变成了网络中的独立服务, 如下图所示, 生产者可以向消息队列发布多种消息, 多个消费者也可以订阅同一种消息, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/0a37ce448b6a9be6c3b7c8b84233de9d-20230731165330-ov3607m.png",alt:""}})]),s._v(" "),t("p",[s._v("总结一下的话, 消息队列就具备了以下 7 个优点:")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("降低了系统的耦合性")]),s._v(". 比如上图中, 组件 2 发布了一条用户注册成功消息, 原本只有负责通知用户注册结果的组件 3 在处理, 如果组件 4 需要立刻开启新用户的营销工作, 只需要同时向消息队列订阅即可; 再比如, 组件 2, 组件 3, 组件 4 通讯时并不需要统一应用层协议或者 RPC 接口, 所有参与方只需要与消息队列服务的 SDK 打交道.")]),s._v(" "),t("li",[t("strong",[s._v("可伸缩性很容易实现")]),s._v(". 比如, 当组件 3 的性能不足时, 添加订阅消息的新实例, 就可以通过水平扩展提升消费能力. 反之, 也可以扩展组件 1, 提升消息的生产能力.")]),s._v(" "),t("li",[t("strong",[s._v('天然实现"削峰填谷"功能')]),s._v(". 消息队列服务会将消息持久化存储在磁盘中, 在高峰期来不及处理的消息, 会在低谷期被消费者服务处理完. 通常, 消息队列会使用廉价, 高容量的机械磁盘存放消息, 可以轻松缓存住高峰期超载的全部请求.")]),s._v(" "),t("li",[t("strong",[s._v("提高了系统可用性")]),s._v(". 首先, 持久化到磁盘中的消息, 在宕机故障时比内存中的请求有更高的可用性; 其次, 消息队列可以隔离故障, 比如, 消费者服务宕机后, 生产者服务短期内不会受到影响; 再次, 当总吞吐量超过性能上限时, 还可以设置不同的消息优先级, 通过服务降级保障系统的基本可用性.")]),s._v(" "),t("li",[t("strong",[s._v("消息队列的生产者天然具备异步功能")]),s._v(", 这降低了生产者的请求处理时延, 提升了用户体验.")]),s._v(" "),t("li",[t("strong",[s._v("基于 AKF Y 轴拆分功能可以降低数据规模, 而且组件间分工更细也会带来更深入的性能优化")]),s._v('. 当消息队列作为通讯方式时, 这种"事件驱动"的分布式系统很容易通过消息实现服务拆分, 成本会低很多.')]),s._v(" "),t("li",[t("strong",[s._v("消息队列服务对于各种消息的发布, 消费情况都有统计")]),s._v(", 因此, 从消息中就能获得业务的实时运行状态, 以极低的成本实现系统的监控.")])]),s._v(" "),t("p",[s._v("正是因为这么多的优点, 所以消息队列成为了多数分布式系统必备的基础设施. 而且, 消息队列自身也拥有很高的性能, 比如 RabbitMQ 单机每秒可以处理 10 万条消息, 而 Kafka 单机每秒甚至可以处理百万条消息. 消息队列的性能为什么如此夸张呢? 除了消息队列处理逻辑简单外, 还有一个重要原因, 就是消息的产生, 消费在时间上是连续的, 这让消息队列在以下优化点上能获得很高的收益:")]),s._v(" "),t("ol",[t("li",[s._v("首先, 在网络通讯中, 很容易通过批量处理提高网络效率. 比如生产者快速发布消息时, Kafka 的客户端 SDK 会自动聚集完一批消息, 再一次性发送给 Broker, 这样网络报文的有效载荷比会很高.")]),s._v(" "),t("li",[s._v("其次, 在数据写入磁盘的过程中, 由于时序性特征, 存放消息的文件仅以追加形式变更, 这样多数情况下机械硬盘的磁头仅朝一个方向转动, 这让磁盘写入速度可以轻松达到 100MB/s.")]),s._v(" "),t("li",[s._v("最后, 由于消费者也是按照 FIFO 规则有序接收消息的, 这样消息队列的缓存就可以通过批量预读等优化方式, 大幅提高读操作的缓存命中率.")])]),s._v(" "),t("p",[s._v("而且, 目前主流消息队列都支持集群架构, 因此消息队列自身一般不会是性能瓶颈.")]),s._v(" "),t("h5",{attrs:{id:"_2-消息队列的服务质量是如何保证的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-消息队列的服务质量是如何保证的"}},[s._v("#")]),s._v(" 2.消息队列的服务质量是如何保证的?")]),s._v(" "),t("p",[s._v("为了提升整个分布式系统的性能, 在处理消息时, 还需要在生产端, 消费端以及消息队列的监控上, 做到以下 3 件事:")]),s._v(" "),t("p",[s._v("首先, 虽然生产者会异步地发布消息, 但毕竟需要接收到消息队列的确认, 才构成完整的发布流程. 网络传输是相对漫长, 不可控的, 所以在高性能场景中, 生产者应基于多线程或者非阻塞 Socket 发布消息, 以提高并发能力.")]),s._v(" "),t("p",[s._v("其次, 当消费端性能不足需要"),t("strong",[s._v("扩容")]),s._v("时, 必须同步增加消息队列服务中的队列(在 Kafka 中叫做分区), 才能允许新增的消费节点并行接收消息, 提高消息的处理能力. 否则, 当多个消费者消费同一消息队列时, 消息的有序性会导致多个消费节点串行处理消息, 无法发挥出它们的全部性能, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/9f5d069a2f540558ca85ac1b544030d1-20230731165330-ly8thv5.png",alt:""}})]),s._v(" "),t("p",[s._v("最后, 如果通过监控发现消息的消费能力小于生产能力, 那就必须及时扩容消费端, 或者降低消息的发布速度, 否则消息就会积压, 最终导致系统不可用.")]),s._v(" "),t("p",[s._v("接下来, "),t("mark",[t("strong",[s._v("再来看消息队列的 QoS(Quality of Service)是如何保证的, 即: 消息在传递过程中会不会丢失, 以及接收方会不会重复消费消息. 在MQTT 协议中, 给消息队列定义了三种 QoS 级别")])]),s._v(":")]),s._v(" "),t("ol",[t("li",[s._v("at most once, 每条消息最多只被传送一次, 这意味着消息有可能丢失;")]),s._v(" "),t("li",[t("strong",[s._v("at least once")]),s._v(", 每条消息至少会传送一次, 这意味着消息可能被重复消费;")]),s._v(" "),t("li",[t("strong",[s._v("exactly once")]),s._v(", 每条消息恰好只传送一次, 这是最完美的状态.")])]),s._v(" "),t("p",[s._v("需要 at most once 约束的场景较罕见, 因此"),t("mark",[t("strong",[s._v("目前绝大部分消息队列服务提供的 QoS 约束都是 at least once")])]),s._v(", 它是通过以下 3 点做到的:")]),s._v(" "),t("ol",[t("li",[s._v("生产端发布消息时, 只有消息队列确定写入磁盘后, 才会返回成功;")]),s._v(" "),t("li",[s._v("为防止消息队列服务出现故障后丢消息, 也需要将数据存放在多个副本节点中. 前面介绍的许多高可用策略, 消息队列都会采用, 比如 Kafka 就是使用 NWR 算法来选出副本中的 Leader 节点, 再经由它同步数据副本.")]),s._v(" "),t("li",[s._v("消费端必须在消费完消息(而不是收到消息)后, 才能向消息队列服务返回成功.")])]),s._v(" "),t("p",[s._v('这样, 消息队列就能以很高的可用性提供 at least once 级别的 QoS. 而 exactly once 是在 at least once 的基础上, 通过幂等性 idempotency 实现的. 对于一条 "幂等性消息", 无论消费 1 次还是多次, 结果都是一样的. 因此, Kafka 通过消息事务和幂等性约束实现了 exactly once 语义, 其中, 发布消息时 Kafka 会创建全局唯一的递增 ID, 这样传输消息时它就能低成本地去除重复的消息, 通过幂等性为单队列实现 exactly once 语义; 针对生产者向多个分区发布同一条消息的场景, 消息事务通过 "要么全部成功要么全部失败", 也实现了 exactly once 语义.')]),s._v(" "),t("h5",{attrs:{id:"_3-小结-9"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-9"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了消息队列及其用法.")]),s._v(" "),t("p",[s._v("消息队列可以解耦分布式系统, 其缓存的消息提供了削峰填谷功能, 将消息持久化则提高了系统可用性, 共享队列则为系统提供了可伸缩性, 而且统计消息就可以监控整个系统, 因此消息队列已成为当下分布式系统的必备基础设施.")]),s._v(" "),t("p",[s._v("虽然消息队列自身拥有优秀的性能, 但若想提高使用效率, 我们就需要确保在生产端实现网络传输上的并发, 在消费端扩容时同步增加队列或者分区, 并且需要持续监控系统, 确保消息的生产能力小于消费能力, 防止消息积压.")]),s._v(" "),t("p",[s._v("消息队列的 Qos 提供三种语义, 其中 at most once 很少使用, 而主流的 at least once 由消息持久化时的冗余, 以及生产端, 消息端使用消息的方式共同保障. Kafka 通过幂等性, 事务消息这两个特性, 在 at least once 的基础上提供了 exactly once 语义.")]),s._v(" "),t("h4",{attrs:{id:"_28-mapreduce-如何通过集群实现离线计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_28-mapreduce-如何通过集群实现离线计算"}},[s._v("#")]),s._v(" 28-MapReduce:如何通过集群实现离线计算?")]),s._v(" "),t("p",[s._v("接下来的 2 节将介绍"),t("strong",[s._v("如何通过分布式集群优化计算任务")]),s._v(". 这一讲"),t("strong",[s._v("首先来看对于有边界静态数据的离线计算, 下一讲再来看对无边界数据流的实时计算")]),s._v(".")]),s._v(" "),t("p",[s._v("对大量数据做计算时, 通常会采用"),t("strong",[s._v("分而治之")]),s._v("的策略提升计算速度. 比如单机上基于递归, 分治思想实现的快速排序, 堆排序, 时间复杂度只有 O(N*logN), 这比在原始数据集上工作的插入排序, 冒泡排序要快得多(O(N2)). 然而, 当单机磁盘容量无法存放全部数据, 或者受限于 CPU 频率, 核心数量, 单机的计算时间远大于可接受范围时, 就需要在分布式集群上使用分治策略.")]),s._v(" "),t("p",[s._v("比如, 大规模集群每天产生的日志量是以 TB 为单位计算的, 这种日志分析任务单台服务器的处理能力是远远不够的. "),t("strong",[s._v("需要将计算任务分解成单机可以完成的小任务, 由分布式集群并行处理后, 再从中间结果中归并得到最终的运算结果. 这一过程由 Google 抽象为 MapReduce 模式, 实现在 Hadoop 等分布式系统中.")])]),s._v(" "),t("p",[s._v("虽然 MapReduce 已经有十多个年头的历史了, 但它仍是分布式计算的基石, 这种编程思想在新出现的各种技术中都有广泛的应用. 比如当在单机上使用 TensorFlow 完成一轮深度学习的时间过久, 或者单颗 GPU 显存无法存放完整的神经网络模型时, 就可以通过 Map 思想把数据或者模型分解给多个 TensorFlow 实例, 并行计算后再根据 Reduce 思想合并得到最终结果. 再比如知识图谱也是通过 MapReduce 思想并行完成图计算任务的.")]),s._v(" "),t("p",[s._v("接下来就具体看看如何在分布式集群中实现离线计算, 以及 MapReduce 是怎样提供 SQL 语言接口的.")]),s._v(" "),t("h5",{attrs:{id:"_1-分而治之-如何实现集群中的批量计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-分而治之-如何实现集群中的批量计算"}},[s._v("#")]),s._v(" 1.分而治之:如何实现集群中的批量计算?")]),s._v(" "),t("p",[s._v("分而治之的思想在分布式系统中广为使用, 比如 AKF 立方体 Z 轴扩展, 就是基于用户的请求, 缩小集群中单个节点待处理的数据量, 比如下图中当关系数据库中单表行数达到千万行以上时, 此时不得不存放在磁盘中的索引将会严重降低 SQL 语句的查询速度. 而执行分库分表后, 由应用或者中间层的代理分解查询语句, 待多个不足百万行的表快速返回查询结果后, 再归并为最终的结果集.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/2cb5ddf20917a5c5f5bbaf6fd86c6b70-20230731165330-9qws54y.png",alt:""}})]),s._v(" "),t("p",[s._v("与上述的 IO 类任务不同, 并非所有的计算任务都可以基于分治策略, 分解为可以并发执行的子任务. 比如基于 CBC 分组模式的 AES 加密算法就无法分解执行, 如下图所示, 每 16 个字节的块在加密时, 都依赖前 1 个块的加密结果, 这样的计算过程既无法利用多核 CPU, 也无法基于 MapReduce 思想放在多主机上并发执行.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/9a1bc69e9f0e9e475e4e550e130eb485-20230731165330-s4n4k7f.png",alt:""}})]),s._v(" "),t("p",[s._v("再来看"),t("strong",[s._v("可以使用 MapReduce 的计算任务")]),s._v(", 其中最经典的例子是"),t("strong",[s._v("排序")]),s._v("(Google 在构建倒排索引时要为大量网页排序). 当使用插入排序(不熟悉插入排序的同学, 可以想象自己拿了一手乱牌, 然后在手中一张张重新插入将其整理有序)在整个数据集上操作时, 计算的时间复杂度是 O(N2), 但快排, 堆排序, 归并排序等算法的时间复杂度只有 O(N*logN), 这就是通过分治策略, 缩小子问题数据规模实现的.")]),s._v(" "),t("p",[s._v("比如下图是在 8 个数字上使用归并排序算法进行排序的流程. 将数组递归地进行 3(log8)轮对半拆分后, 每个子数组就只有 2 个元素. 对 2 个元素排序只需要进行 1 次比较就能完成. 接着, 再将有序的子数组不断地合并, 就可以得到完整的有序数组.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ee094fed89ccf55b9995aa548fed45e2-20230731165330-4tmzqt7.png",alt:""}})]),s._v(" "),t("p",[s._v("其中, 将两个含有 N/2 个元素的有序子数组(比如 1, 3, 7, 19 和 4, 8, 11, 25), 合并为一个有序数组时只需要做 N/2 到 N-1 次比较(图中只做了 5 次比较), 速度非常快. 因此, 比较次数乘以迭代轮数就可以得出时间复杂度为 O(N*logN).")]),s._v(" "),t("p",[s._v("同样的道理引申到分布式系统中, 就成为了 MapReduce 模式. 其中, "),t("strong",[s._v("原始数据集要通过 SPLIT 步骤拆分到分布式系统中的多个节点中, 而每个节点并发执行用户预定义的 MAP 函数, 最后将 MAP 运算出的结果通过用户预定义的 REDUCE 函数, 归并为最终的结果")]),s._v(". 比如上例中可以将 8 个元素拆分到 2 个节点中并行计算, 其中每个节点究竟是继续采用归并排序, 还是使用其他排序算法, 这由预定义的 MAP 函数决定. 当 MAP 函数生成有序的子数组后, REDUCE 函数再将它们归并为完整的有序数组, 具体如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/dc0fac38167cfaebe131b09259537247-20230731165330-kghrkd2.png",alt:""}})]),s._v(" "),t("p",[s._v("当面对 TB, PB 级别的数据时, MapReduce 思想就成了唯一的解决方案. 当然, 在实际软件工程中实现 MapReduce 的框架要比上面的示意图复杂许多, 毕竟在大规模分布式系统中, 故障每时每刻都会发生, 如何分发数据, 调度节点执行 MAP 映射, 监控计算节点等, 都需要精心的设计. 特别是, 当单个节点的磁盘无法存放下全部数据时, 常常使用类似 HDFS 的分布式文件系统存放数据, 所以 MapReduce 框架往往还需要对接这样的系统来获取数据, 具体如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/f225742af825b80e1fc32d2880a77dec-20230731165330-0wgek3u.png",alt:""}})]),s._v(" "),t("p",[s._v("而且, 生产环境中的任务远比整数排序复杂得多, 所以写对 Map, Reduce 函数并不容易. 另一方面, 大部分数据分析任务又是高度相似的, 所以没有必要总是直接编写 Map, Reduce 函数, 实现发布式系统的离线计算. 由于 SQL 语言支持聚合分析, 表关联, 还内置了许多统计函数, 很适合用来做数据分析, 它的学习成本又非常低, 所以大部分 MapReduce 框架都提供了类 SQL 语言的接口, 可以替代自行编写 Map, Reduce 函数. 接下来看看, SQL 语言统计数据时, Map, Reduce 函数是怎样工作的.")]),s._v(" "),t("h5",{attrs:{id:"_2-sql是如何简化mapreduce模式的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-sql是如何简化mapreduce模式的"}},[s._v("#")]),s._v(" 2.SQL是如何简化MapReduce模式的?")]),s._v(" "),t("p",[s._v("以最常见的 Web 日志分析为例, 观察用 SQL 语言做统计时, MapReduce 流程是怎样执行的. 举个例子, Nginx 的 access.log 访问日志是这样的(基于默认的 combined 格式):")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1 - - "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v("/Jul/2020:10:16:15 +0800"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"GET /login? userid=101 HTTP/1.1"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("56")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"curl/7.29.0"')]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("可以通过正则表达式取出客户端 IP 地址, 用户名, HTTP 响应码, 这样就可以生成结构化的数据表格:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d69eb5ef234c09633416ac02f0dd1c8c-20230731165330-xhypyms.png",alt:""}})]),s._v(" "),t("p",[s._v("如果想按照客户端 IP, HTTP 响应码聚合统计访问次数, 基于通用的 SQL 规则, 就可以写出下面这行 SQL 语句:")]),s._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" ClientIp, StatusCode, count"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("*"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" from access_log group by ClientIp, StatusCode\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("而建立在 MapReduce 之上的框架(比如 Hive)会将它翻译成如下图所示的 MapReduce 流程:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/75f41c99cba3c796b0e9c5980bce5044-20230731165330-hswtvex.png",alt:""}})]),s._v(" "),t("p",[s._v("其中, 假定 5 行数据被拆分到 2 个节点中执行 Map 函数, 其中它们分别基于 2 行, 3 行这样小规模的数据集, 生成了正确的聚合统计结果. 接着, 在 Shuffle 步骤基于 key 关键字排序后, 再交由 Reduce 函数归并出正确的结果.")]),s._v(" "),t("p",[s._v("除了这个例子中的 count 函数, 像 max(求最大值), min(求最小值), distinct(去重), sum(求和), avg(求平均数), median(求中位数), stddev(求标准差)等函数, 都很容易分解为子任务并发执行, 最后归并出最终结果.")]),s._v(" "),t("p",[s._v("当多个数据集之间需要做"),t("strong",[s._v("交叉统计")]),s._v("时, SQL 中的 join 功能(包括内连接, 左外连接, 右外连接, 全连接四种模式)也很容易做关联查询. 此时可以在并行计算的 Map 函数中, 把 where 条件中的关联字段作为 key 关键字, 经由 Reduce 阶段实现结果的关联.")]),s._v(" "),t("p",[t("strong",[s._v("由于 MapReduce 操作的数据集非常庞大, 还需要经由网络调度多台服务器才能完成计算, 因此任务的执行时延至少在分钟级, 所以通常不会服务于用户的实时请求, 而只是作为离线的异步任务将运算结果写入数据库.")])]),s._v(" "),t("h5",{attrs:{id:"_3-小结-10"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-10"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("这一讲介绍了在集群中使用分治算法统计大规模数据的 MapReduce 模式.")]),s._v(" "),t("p",[s._v("当数据量很大, 或者计算时间过长时, 如果计算过程可以被分解为并发执行的子任务, 就可以基于 MapReduce 思想, 利用分布式集群的计算力完成任务. 其中, 用户可以预定义在节点中并发执行的 Map 函数, 以及将 Map 输出的列表合并为最终结果的 Reduce 函数. 虽然 MapReduce 将并行计算抽象为统一的模型, 但开发 Map, Reduce 函数的成本还是太高了, 于是针对高频场景, 许多 MapReduce 之上的框架提供了类 SQL 语言接口, 通过 group by 的聚合, join 连接以及各种统计函数, 就可以利用整个集群完成数据分析.")]),s._v(" "),t("p",[s._v("MapReduce 模式针对的是静态数据, 也叫有边界数据, 它更多用于业务的事前或者事后处理流程中, 而做事中处理时必须面对实时, 不断增长的无边界数据流, 此时 MapReduce 就无能为力了. 下一讲将介绍处理无边界数据的流式计算框架.")]),s._v(" "),t("h4",{attrs:{id:"_29-流式计算-如何通过集群实现实时计算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_29-流式计算-如何通过集群实现实时计算"}},[s._v("#")]),s._v(" 29-流式计算:如何通过集群实现实时计算?")]),s._v(" "),t("p",[s._v("上节课介绍了在"),t("strong",[s._v("有边界的存量数据")]),s._v("上进行的 MapReduce 离线计算, 本节来看看"),t("strong",[s._v("对于无边界数据, 怎样实时地完成流式计算")]),s._v(".")]),s._v(" "),t("p",[s._v("对于不再变化的存量数据, 可以通过分而治之的 MapReduce 技术将数据划分到多台主机上并行计算, 由于待处理的数据量很大, 只能获得分钟级以上的时延. "),t("strong",[s._v("当面对持续实时产生动态数据的场景时, 业务上通常需要在秒级时延中及时地拿到运算结果")]),s._v(".")]),s._v(" "),t("p",[s._v('比如, 商家为了拉新促活, 会为特定的用户群体(比如新用户或者不活跃用户)推出优惠活动, 为了防止"羊毛党"通过大量主机并行地"薅羊毛", '),t("strong",[s._v('系统要能实时地聚合分析所有优惠券的使用者特点, 再基于业务规则及时地封掉"羊毛党"帐号或者 IP 地址, 才可以控制住风险范围, 提高营销活动的收益')]),s._v(". 那对于整个系统持续生成的大量订单数据, 怎样才能提供秒级的聚合分析结果呢?")]),s._v(" "),t("p",[s._v("最初的流式计算方案, 是在时间维度上定期地将数据分片, 再基于 MapReduce 思想在空间维度的多台主机上实现并行计算, 这样也能获得实时计算结果. 然而, 对每片数据执行批量计算, 想要在秒级甚至毫秒级拿到计算结果并不容易. 当网络不稳定时, 数据会因为报文延误而乱序, 简单的基于时序分片会导致计算结果失真. 当数据之间具有明显的业务关系时, 固定的时间窗口更是难以得到预期的分析结果.")]),s._v(" "),t("p",[s._v("接下来就深入学习一下"),t("strong",[s._v("流式计算的工作原理, 以及流式计算常用的数据分片窗口")]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_1-流式计算是如何实现的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-流式计算是如何实现的"}},[s._v("#")]),s._v(" 1.流式计算是如何实现的?")]),s._v(" "),t("p",[s._v("在数据库, HDFS 等分布式系统中存放的静态数据, 由于拥有清晰的边界, 所以被称为 "),t("strong",[s._v("InBound Data 有边界数据")]),s._v(". 然而, 线上运行中的互联网产品生命周期并不确定, 它产生的数据有明确的开始, 却没有截止时间点. 对于这样有始无终的"),t("strong",[s._v("实时数据流, 把它称为 OutBound Data 无边界数据")]),s._v(", 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e965124dd76b6769a5b9b53ad53ab639-20230731165330-4wes34w.png",alt:""}})]),s._v(" "),t("p",[s._v("从业务需求上看, 有边界数据与无边界数据的计算目的是完全不同的. 比如对于分布式监控系统, 需要基于 IP 地址, 用户帐号, 请求类型等许多特征进行"),t("strong",[s._v("定时的聚合统计")]),s._v(", 例如获取每分钟内所有请求处理时延的平均值, 中位数, 最大值等, 监控系统性能. 此时, 可以根据请求执行结果的产生时间对数据进行分片计算. 比如, 下表中有 7 条监控数据, 需要求出每分钟请求时延的平均值.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d3fdb80afc4cbf46c5954349ddc67ebd-20230731165330-m4b3thz.png",alt:""}})]),s._v(" "),t("p",[s._v("如果按照分钟整点对数据进行分片, 就可以在 02:00 时对蓝色的消息 1, 2 求出窗口内的平均时延 192 毫秒, 并立刻返回结果. 之后当接收完红色的消息 3, 4, 5 后, 在第 2 分钟结束时再对 3 个数字求出平均值. 以此类推.")]),s._v(" "),t("p",[t("strong",[s._v("这种设计思想就是基于固定时间窗口的批处理解决方案.")]),s._v("  当然, 并不是一定要等到时间窗口结束时, 才对这一批次的所有数据统一计算. 完全可以在每个消息到来时, 就计算出中间状态, 当所在的时间窗口结束时, 再将中间状态转换为最终结果. 仍然以上表为例, 可以在每个监控事件到达时, 计算出请求时延和以及当前窗口内的事件个数, 这样, 在窗口结束时只需要将时延和除以事件个数, 就能得到平均值.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e51ddd917c5a25cc198a6c48489e6231-20230731165330-rnxcyxh.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, "),t("strong",[s._v("中间状态可以更均衡地使用计算资源, 提高流式计算的整体性能")]),s._v(". 既可以把中间状态放在内存中, 也可以把它持久化到本地磁盘中获取更高的可用性, 为了方便计算节点的调度, 通常还会将备份状态存放至远端的数据库.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/07bb839d3369015edfbfb0b5e2cb2746-20230731165330-4vdynxy.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, "),t("strong",[s._v("流式计算最主要的性能提升思路, 还是基于 MapReduce 思想, 将同一窗口的数据从空间维度中分发到不同的计算节点进行并行的 Map 计算, 再将 Map 映射出的结果 Reduce 为最终结果")]),s._v(". 由于流式计算天然是基于消息事件驱动的, 因此它往往直接从 Kafka 等消息队列中获取输入数据, 消息队列很容易协助流式计算实现数据拆分.")]),s._v(" "),t("p",[s._v("到这里, 已经看到了实现流式计算的基本思路, 其中基于固定时间窗口的数据划分方式还有很大的改进空间, 目前它还无法解决较为复杂的有状态计算. 所谓"),t("strong",[s._v("有状态计算, 是指在时间窗口内, 不同的消息之间会互相作用并影响最终的计算结果, 比如求平均值就是这样一个例子, 每个新到达的数据都会影响中间状态值")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1e2ef4e99337e97fe5703c1c8672d6da-20230731165330-wf0q0s4.png",alt:""}})]),s._v(" "),t("p",[s._v("相反, 无状态计算处理到达的数据时, 并不涉及窗口内的其他数据, 处理流程要简单的多. 例如, 当监控到请求时延超过 3 秒时, 就产生一条告警. 此时, 只需要单独地判断每个消息中的时延数据, 就能够得到计算结果.")]),s._v(" "),t("p",[s._v("在真实的业务场景中, 有状态计算还要更复杂. 比如, 对两个不同的数据源(可以理解为数据库中的表)做 join 连接时, 采用内连接, 外连接这两种不同的连接方式, 就会影响到时间窗口长度. 再比如, 当不同的事件具有逻辑关系时, 窗口长度则应该由业务规则确定, 不同的请求可能拥有不等的窗口大小. 接下来再来看看流式计算中的几种常见窗口.")]),s._v(" "),t("h5",{attrs:{id:"_2-如何通过窗口确定待计算的数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-如何通过窗口确定待计算的数据"}},[s._v("#")]),s._v(" 2.如何通过窗口确定待计算的数据?")]),s._v(" "),t("p",[s._v("首先来看"),t("strong",[s._v("滑动窗口")]),s._v(", 它是从固定窗口衍生出的一种窗口. 继续延续求每分钟平均值的例子, 当业务上需要更平滑的曲线时, 可以通过每 20 秒求最近 1 分钟请求时延的平均值实现, 这就是滑动窗口, 其中窗口长度则是 1 分钟, 但每次计算完并不会淘汰窗口中的全部数据, 而只是将步长向后移动 20 秒, 即只淘汰最早 20 秒中的数据. 当窗口长度与步长一致时, 滑动窗口就退化成了"),t("strong",[s._v("固定窗口")]),s._v(".")]),s._v(" "),t("p",[s._v("当然, 还可以把窗口的计量单位从时间改为事件个数, 此时可以称为"),t("strong",[s._v("计数窗口")]),s._v(". 仍然延续上面的例子, 固定计数窗口可以改为求每 100 个访问记录的平均时延, 滑动计数窗口可以改为每 10 条记录中求最近 100 个记录的平均时延. 由于消息本身是有时序的, 所以这些都可以称为"),t("strong",[s._v("时间驱动的窗口")]),s._v(". 事实上, 还有另外一种事件驱动的窗口与此完全不同, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e3e596920ec4029b66052d0ec53d2af7-20230731165330-6xcecuz.png",alt:""}})]),s._v(" "),t("p",[s._v("固定窗口, 滑动窗口并不会解析业务字段, 区别对待图中不同的 Key 关键字, 这就很难解决以下这类场景: 当需要统计用户在一个店铺内浏览的商品数量时, 就需要针对用户的店铺停留时长来设计动态的窗口大小. 毕竟不同的用户在不同的店铺内停留时长不可能相同, 此时, 动态的窗口大小可以通过事件来驱动, 这称为会话窗口.")]),s._v(" "),t("p",[s._v("事实上, 还面临着信息"),t("strong",[s._v("统计准确性")]),s._v("上的问题. 在基于时间驱动的窗口中, 这里的时间其实是事件到达流式系统时产生的系统处理时间, 而不是事件发生的时间. 仍然以访问日志为例, 每条日志都有明确的请求访问时间, 但在分布式系统传输时, 由于网络波动的传输时延, 以及各主机节点应用层的处理时延, 这些事件到达流式计算框架的顺序已经发生了变化. 如果仍然以固定的时间窗口来处理, 就会得到错误的统计结果.")]),s._v(" "),t("p",[s._v("为了避免乱序事件扰乱统计结果, 可以使用水位线 Watermark 减少乱序概率. 比如下图中, 消息队列中的数字表示事件时间, 其中事件 7 先于事件 3, 5 到达了流式计算系统:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1f3a85ac4e8be9d3b8f4703b4b2614d8-20230731165330-fsptakp.png",alt:""}})]),s._v(" "),t("p",[s._v("如果设置了水位 4, 窗口就不再以事件顺序严格划分, 而是通过水位上的时间来划分窗口, 这样事件 7 就会放在第 2 个窗口中处理:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/74eddba0fcc61b54adb9dc93533bbd54-20230731165330-2buteis.png",alt:""}})]),s._v(" "),t("p",[s._v("当然, 并不是有了水位线, 第 1 个窗口就会无限制的等下去. 在经历一个时间段后, 第 1 个窗口会认定窗口关闭(这未必准确), 它会处理 3, 1, 3, 2 这 4 个事件. 基于业务规则, 下一个水位被设置为 9:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e26e6bdcec84577a6e842b61a1507739-20230731165330-qg284jn.png",alt:""}})]),s._v(" "),t("p",[s._v("这样第 2 个窗口会处理 6, 5, 7 事件, 而事件 9 就放在了第 3 个窗口中处理:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b8cad1de29a6b3d8cb5560af35742f70-20230731165330-o5g85pr.png",alt:""}})]),s._v(" "),t("p",[s._v("以此类推. 根据业务特性和经验值, 找到最大乱序时间差, 再基于此设置合适的水位线, 就能减轻乱序事件的影响.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-11"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-11"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节介绍了流式计算的实现原理, 以及常用的几种分片窗口.")]),s._v(" "),t("p",[s._v("对于无边界的实时数据流, 可以"),t("strong",[s._v("在时间维度上将其切分到不同的窗口中, 再将每个窗口内的数据从空间维度上分发到不同的节点并行计算, 在窗口结束时汇总结果, 这就实现了流式计算")]),s._v(". Apache Flink, Spark, Storm 等开源产品都是这样的流式计算框架.")]),s._v(" "),t("p",[s._v("通过不同的窗口划分规则, 可以实现不同的计算目的, 包括以时间驱动的固定窗口, 滑动窗口和计数窗口, 以及以事件驱动的会话窗口. 为了避免乱序事件的影响, 还可以通过携带超时时间的 Watermark 水位, 基于事件发生时间更精准地划分窗口.")]),s._v(" "),t("h4",{attrs:{id:"_30-如何权衡关系数据库与nosql数据库"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_30-如何权衡关系数据库与nosql数据库"}},[s._v("#")]),s._v(" 30-如何权衡关系数据库与NoSQL数据库?")]),s._v(" "),t("p",[s._v("本节来结合前面介绍过的知识点, 看看"),t("strong",[s._v("面对 NoSQL, 关系数据库时该如何选择")]),s._v(".")]),s._v(" "),t("p",[s._v("在分布式系统中, 会同时使用多种数据库. 比如, 你可能会在 Redis 中存放用户 Session 会话, 将业务数据拆解为由行, 列构成的二维表存储在 MySQL 中, 将需要全文检索的数据放在 ElasticSearch 中, 将知识图谱放在 Neo4j 图数据库中, 将数据量, 访问量很大的数据放在 Cassandra 列式数据库或者 MongoDB 文档型数据库中, 等等.")]),s._v(" "),t("p",[s._v("选择数据库时, 我们的依据可能是访问速度, 比如基于哈希表的 Redis 查询复杂度只有 O(1), 也可能从事务的支持程度上选择了关系数据库, 甚至从应用层的开发效率上还给它添加了 Hibernate 等 ORM 框架, 也可能从处理数据的体量上选择了 NoSQL 数据库. 可是, 除了各种实现层面上的差异外, 各类 NoSQL 与关系数据库之间, 有没有最本质的区别? 在实际工程中, 可否从此入手确定大方向, 再从细微处选择不同的实现?")]),s._v(" "),t("p",[s._v("在我看来, "),t("strong",[s._v('答案就在于 "关系" 这两个字, 这也是我权衡数据库时最先考虑的前提')]),s._v(". 接下来就沿着关系数据库的特性, 看看 NoSQL 数据库究竟做了哪些改变, 又该如何选择它们.")]),s._v(" "),t("h5",{attrs:{id:"_1-关系数据库的优点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-关系数据库的优点"}},[s._v("#")]),s._v(" 1.关系数据库的优点")]),s._v(" "),t("p",[s._v("关系数据库对业务层开发效率的提升有很大帮助. 下面先基于一个简单的例子, 看看关系数据库有何优点. 疫情期间新增了一批能够测量体温的考勤机, 通过关系数据库新建了用户, 考勤机, 考勤记录三张表, 如下图所示:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1f839f3f2c687676103a8a36d28d6e42-20230731165330-cot1ydg.png",alt:""}})]),s._v(" "),t("p",[s._v("在关系数据库中, 表中的每行数据由多个从属于列的单一值(比如数字, 字符串)构成. 虽然表中可以存放任意行数据, 但列却是预先定义且不变的, 因此很容易通过行, 列交汇处的单一值进行关联操作, 进而完成各类业务目的不同的查询. 比如, 业务开发者可以通过下面这行 SQL 语句, 找到体温超过 37 度的员工, 上报其姓名, 测量时间以及所在地理位置:")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("time")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("location "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" machine "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("user")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("machine_id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("and")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("temporature "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("37")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("运营人员则可以通过下面这行 SQL 语句, 找出各类考勤机的使用频率:")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("machine_id "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("group")]),s._v(" py machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("因此, 关系数据库"),t("strong",[s._v("可以通过预定义的关系, 由数据库自身完成复杂的逻辑计算, 为不同的场景提供数据服务.")]),s._v('  由于不同的数据间具有了关系, 关系数据库还提供了 "Transaction 事务", 用于保证相关数据间的一致性, 这大大释放了应用开发者的生产力. 所谓"事务", 会同时具有 ACID 4 个特性:')]),s._v(" "),t("p",[t("strong",[s._v("Atomicity 原子性")]),s._v(", 指多个 SQL 语句组成了一个逻辑单位, 执行时要么全部成功, 要么全部失败.")]),s._v(" "),t("p",[t("strong",[s._v("Consistency 一致性")]),s._v(", 指数据库只能从一个一致性状态转换到另一个一致性状态. 即使数据库发生了重启, 仍然得维持一致性.")]),s._v(" "),t("p",[t("strong",[s._v("Isolation 隔离性")]),s._v(", 由于数据库可以支持多个连接并发操作, 因此并发的事务间必须互相隔离才有意义. SQL 标准定义了以下 4 种隔离级别:")]),s._v(" "),t("ol",[t("li",[s._v("READ UNCOMMITTED 未提交读, 它表示在事务 A 还未提交时, 并发执行的事务 B 已经可以看到事务 A 改变的数据. 这种隔离级别会带来很多问题, 因此很少使用.")]),s._v(" "),t("li",[s._v("READ COMMITTED 提交读, 它表示当事务 A 未提交时, 事务 B 看不到事务 A 改变的任何数据, 这是 PostgreSQL 数据库的默认隔离级别.")]),s._v(" "),t("li",[s._v("REPEATABLE READ 可重复读, 指在 READ COMMITTED 的基础上解决了脏读问题. 所谓脏读, 是指在一个事务内, 多次读取到同一数据时, 结果可能不一致. 这是 MySQL 数据库的默认隔离级别.")]),s._v(" "),t("li",[s._v("SERIALIZABLE 可串行化, 它通过对每一行数据加锁, 使得所有事务串行执行, 虽然隔离性最好, 但也大大降低了数据库的并发性, 所以很少使用.")])]),s._v(" "),t("p",[t("strong",[s._v("Durability 持久性")]),s._v(", 指一旦事务提交, 事务所做的修改必须永久性地保存到数据库中.")]),s._v(" "),t("p",[s._v("可见, "),t("mark",[t("strong",[s._v("事务的 ACID 特性简化了本应由应用层完成的流程! 这也是关系数据库与 NoSQL 数据库之间最大的差别")])]),s._v(". 除事务外, 关系数据库还在以下 4 点上降低了应用层的开发成本:")]),s._v(" "),t("ol",[t("li",[s._v("无论是商业版的 Oracle, 还是开源的 MySQL, PostgreSQL, 只要是关系数据库就拥有同样的数据模型, 因此它们可以"),t("strong",[s._v("通过 SQL 语言为应用层提供标准化, 几乎没有差异的访问接口")]),s._v(";")]),s._v(" "),t("li",[s._v("生产级的数据库对持久化都有良好的支持, 全面的冷备, 热备方案提供了很高的可用性;")]),s._v(" "),t("li",[s._v("通过索引, 缓存等特性, 当行数在亿级以下时, 关系数据库的性能并不低;")]),s._v(" "),t("li",[s._v("关系数据库支持还不错的并发度, 一般可以服务于上千个并发连接.")])]),s._v(" "),t("p",[s._v("所以应用层会将许多计算任务放在关系数据库中, 在此基础上还诞生了 MVC 等将数据层从业务中剥离, 以关系数据库为中心的架构.")]),s._v(" "),t("h5",{attrs:{id:"_2-关系数据库的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-关系数据库的问题"}},[s._v("#")]),s._v(" 2.关系数据库的问题")]),s._v(" "),t("p",[s._v("虽然基于单一值的关系映射提供了事务等许多功能, 但同时也引入了 3 个问题.")]),s._v(" "),t("p",[s._v("首先, 内存中的数据结构非常多样, 难以直接映射到行列交汇处的单一值上. 不过, "),t("strong",[s._v("这个问题可以通过")]),s._v(" ORM(Object-relational mapping)"),t("strong",[s._v("框架解决.")]),s._v("  比如, Python 中的 Django ORM 框架, 可以将上述 3 张表映射为内存中的 3 个类:")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("db "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("User")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Machine")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    location "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Record")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    time "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DateTimeField"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    temporature "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FloatField"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    user "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ForeignKey"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("User"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    machine"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ForeignKey"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("p",[s._v("ORM 框架会为每张表生成 id 字段, 而 Record 表将 User 和 Machine 表中的 id 字段作为外键(ForeignKey)互相关联在一起. 于是, 这 3 个类就映射了数据库中的那 3 张表, 而内存中的对象(即类的实例)则映射为每张表中的一行数据. 在 ORM 框架下, 找到体温大于 37 度员工的那串长 SQL, 可以转化为 OOP 中的函数调用, 如下所示:")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# gte表示大于等于")]),s._v("\nrecords "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("temporature__gte "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("37")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" r "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("r"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("user"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" r"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("machine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("location"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" r"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("time"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("相比起 SQL 语句, 映射后的 OO 编程要简单许多.")]),s._v(" "),t("p",[s._v("其次, 为了实现关系映射, 每张表中的字段都得预先定义好, 一旦在产品迭代过程中数据模型发生了变化, 便需要同步完成以下 3 件事:")]),s._v(" "),t("ol",[t("li",[s._v("修改表结构;")]),s._v(" "),t("li",[s._v("修改应用层操作数据的代码;")]),s._v(" "),t("li",[s._v("根据新的规则转换, 迁移已有数据.")])]),s._v(" "),t("p",[s._v("在 ORM 中可以把这 3 步放在一个 migration 迁移脚本中完成. 当然, 如果数据迁移成本高, 时间长, 可以设计更复杂的灰度迁移方案.")]),s._v(" "),t("p",[t("strong",[s._v("最后是关系数据库固有的可伸缩性问题, 这是各类 NoSQL 数据库不断诞生的主要原因.")]),s._v("  前面"),t("strong",[s._v("介绍过沿 AKF X 轴扩展的复制型主从结构, 然而单点主库无法解决数据持续增长引入的性能问题")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8eea1987f198ff848bf20b49b7c85765-20230731165330-681rwb1.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("沿 AKF Z 轴扩展数据库虽然能够降低数据规模, 但分库分表后, 单一值关系引申出的 ACID 事务不能基于高时延, 会抖动的网络传输强行实现, 否则会导致性能大幅下降, 这样的可用性是分布式系统无法接受的")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/3b78b013c5c5bd09528c02319eca2b5b-20230731165330-c7nzall.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, "),t("mark",[t("strong",[s._v("在单机上设计出的关系数据库, 难以处理 PB 级的大数据. 而 NoSQL 数据库放弃了单一值数据模型, 非常适合部署在成千上万个节点的分布式环境中")])]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_3-nosql数据库是如何解决上述问题的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-nosql数据库是如何解决上述问题的"}},[s._v("#")]),s._v(" 3.NoSQL数据库是如何解决上述问题的?")]),s._v(" "),t("p",[s._v('虽然所有的 NoSQL 数据库都无法实现标准的 SQL 语言接口, 但 NoSQL 绝不是 "No SQL: 拒绝 SQL 语言" 的意思. 当然, NoSQL 也不是 "Not Only SQL: 不只是 SQL 语言" 的意思, 否则 Oracle 也能算 NoSQL 数据库了. 实际上, 没有必要纠结 NoSQL 的字面含义, NoSQL 数据库只是放弃了与分布式环境相悖的 ACID 事务, 提供了另一种聚合数据模型, 从而拥有可伸缩性的非关系数据库.')]),s._v(" "),t("p",[s._v("NoSQL 数据库可以分为以下 4 类:")]),s._v(" "),t("ul",[t("li",[t("mark",[t("strong",[s._v("Key/Value 数据库")])]),s._v(", 通常基于哈希表实现, 性能非常好. 其中 Value 的类型通常由应用层代码决定, 当然, Redis 这样的 Key/Value 数据库还可以将 Value 定义为列表, 哈希等复合结构.")]),s._v(" "),t("li",[t("mark",[t("strong",[s._v("文档型数据库")])]),s._v(", 在 Key/Value 数据库中, 由于没有预定义的值结构, 所以只能针对 Key 执行查询, 这大大限制了使用场景. 文档型数据库将 Value 扩展为 XML, JSON(比如 MongoDB)等数据结构, 于是允许使用者在文档型数据库的内部解析复合型的 Value 结构, 再通过其中的单一值进行查询, 这就兼具了部分关系数据库的功能.  ****")]),s._v(" "),t("li",[t("mark",[t("strong",[s._v("列式数据库")])]),s._v(", 比如前面介绍过的 Cassandra. 列式数据库基于 Key 来映射行, 再通过列名进行二级映射, 同时它基于列来安排存储的拓扑结构, 这样当仅读写大量行中某个列时, 操作的数据节点, 磁盘非常集中, 磁盘 IO, 网络 IO 都会少很多. 列式数据库的应用场景非常有针对性, 比如博客文章标签的行数很多, 但在做数据分析时往往只读取标签列, 这就很适合使用列式数据库. 再比如, "),t("strong",[s._v("通过倒排索引实现了全文检索的 ElasticSearch, 就适合使用列式存储存放 Doc Values, 这样做排序, 聚合时非常高效.")])]),s._v(" "),t("li",[t("mark",[t("strong",[s._v("图数据库")])]),s._v(", 在社交关系, 知识图谱等场景中, 携带各种属性的边可以表示节点间的关系, 由于节点的关系数量多, 而且非常容易变化, 所以关系数据库的实现成本很高, 而图数据库既没有固定的数据模型, 遍历关系的速度也非常快, 很适合处理这类问题. 当然, 日常见到的主要是前 3 类 NoSQL 数据库.")])]),s._v(" "),t("p",[s._v("相对于关系数据库, NoSQL 在性能和易用性上都有明显的优点.")]),s._v(" "),t("p",[s._v("首先来看可用性及性能, 这是 NoSQL 数据库快速发展的核心原因:")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("NoSQL 数据库的可伸缩性都非常好")]),s._v(". 虽然许多文档型, 列式数据库都提供了类 SQL 语言接口, 但这只是为了降低用户的学习成本, 它们对跨节点事务的支持极其有限. 因此, 这些 NoSQL 数据库可以放开手脚, 基于 Key/Value 模型沿 AKF Z 轴将系统扩展到上万个节点.")]),s._v(" "),t("li",[t("strong",[s._v("在数据基于 Key 分片后, 很容易通过 MapReduce 思想, 提高系统的计算能力")]),s._v(". 比如, MongoDB 很自然的就在查询接口中, 提供了MapReduce 函数.")]),s._v(" "),t("li",[t("strong",[s._v("通过冗余备份, NoSQL 可以提供优秀的容灾能力")]),s._v(". 比如, Redis, Cassandra 等数据库, 都可以基于前面介绍过的 NWR 算法, 灵活地调整 CAP 权重.")]),s._v(" "),t("li",[s._v("如果每个 Key 中 Value 存放的复合数据已经能满足全部业务需求, 那么 NoSQL 的单机查询速度也会优于关系数据库.")])]),s._v(" "),t("p",[s._v("其次再来看易用性, 这主要体现在可以低成本地变更 Value 结构. 虽然 NoSQL 数据库支持复合型 Value 结构, 但并不限定结构类型. 比如, 文档型数据库中, 同一个表中的两行数据, 其值可以是完全不同的 JSON 结构; 同样的, 列式数据库中两行数据也可以拥有不同的列数. 因此, 当数据结构改变时, 只需要修改应用层操作数据的代码, 并不需要像关系数据库那样同时修改表结构以及迁移数据.")]),s._v(" "),t("p",[s._v('那么, 到底该如何选择关系数据库与 NoSQL 数据库呢? 其实, 沿着 "单一值关系" 这一线索, 就已经找到了各自适用的场景.')]),s._v(" "),t("p",[t("strong",[s._v("如果多个业务数据间互相关联, 需要从多个不同的角度分析, 计算, 并保持住相关数据的一致性, 那么关系数据库最为适合. 一旦数据行数到了亿级别以上, 就需要放弃单一值结构, 将单行数据聚合为复合结构, 放在可以自由伸缩的 NoSQL 数据库中. 此时, 无法寄希望于 NoSQL 数据库提供 ACID 事务, 只能基于二段式提交等算法在应用层代码中自行实现事务.")])]),s._v(" "),t("h5",{attrs:{id:"_4-小结-15"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-15"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("本节介绍了关系数据库与 NoSQL 数据库各自的特点及其适用场景.")]),s._v(" "),t("p",[s._v("关系数据库通过行, 列交汇处的单一值, 实现了多种数据间的关联. 通过统一的 SQL 接口, 用户可以在数据库中实现复杂的计算任务. 为了维持关联数据间的一致性, 关系数据库提供了拥有 ACID 特性的事务, 提升了应用层的开发效率.")]),s._v(" "),t("p",[s._v("虽然单一值无法映射内存中的复合数据结构, 但通过 ORM 框架, 关系数据库可以将表映射为面向对象编程中的类, 将每行数据映射为对象, 继续降低开发成本. 然而, 关系数据库是为单机设计的, 一旦将事务延伸到分布式系统中, 执行成本就会高到影响基本的可用性. "),t("strong",[s._v("因此关系数据库的可伸缩性是很差")]),s._v("的.")]),s._v(" "),t("p",[s._v("NoSQL 数据库基于 Key/Value 数据模型, 可以提供几乎无限的可伸缩性. 同时, 将 Value 值进一步设计为复合结构后, 既可以增加查询方式的多样性, 也可以通过 MapReduce 提升系统的计算能力. 实际上, 关系数据库与每一类 NoSQL 数据库都有明显的优缺点, 可以从数据模型, 访问方式, 数据容量上观察它们, 结合具体的应用场景权衡取舍.")]),s._v(" "),t("h3",{attrs:{id:"加餐"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#加餐"}},[s._v("#")]),s._v(" 加餐")]),s._v(" "),t("h4",{attrs:{id:"加餐3-百万并发下nginx的优化之道"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#加餐3-百万并发下nginx的优化之道"}},[s._v("#")]),s._v(" 加餐3-百万并发下Nginx的优化之道")]),s._v(" "),t("p",[s._v("本节的内容主要集中在 Nginx 的性能方面, 希望能给你带来一些系统化的思考, 帮助你更有效地去做 Nginx.")]),s._v(" "),t("h5",{attrs:{id:"_1-优化方法论"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-优化方法论"}},[s._v("#")]),s._v(" 1.优化方法论")]),s._v(" "),t("p",[s._v("今天的分享重点会看这样两个问题:")]),s._v(" "),t("ol",[t("li",[s._v("第一, "),t("strong",[s._v("如何有效使用每个连接分配的内存, 以此实现高并发")]),s._v(".")]),s._v(" "),t("li",[s._v("第二, "),t("strong",[s._v("在高并发的同时, 怎样提高 QPS")]),s._v(".")])]),s._v(" "),t("p",[s._v("当然, 实现这两个目标, 既可以从单机中的应用, 框架, 内核优化入手, 也可以使用类似 F5 这样的硬件设备, 或者通过 DNS 等方案实现分布式集群.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ce2df8f762653a56240e132673040a50-20230731165330-zun9k94.png",alt:""}})]),s._v(" "),t("p",[s._v("而 Nginx 最大的限制是网络, 所以将网卡升级到万兆, 比如 10G 或者 40G 吞吐量就会有很大提升. 作为静态资源, 缓存服务时, 磁盘也是重点关注对象, 比如固态硬盘的 IOPS 或者 BPS, 要比不超过 1 万转每秒的机械磁盘高出许多.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a09422c875074b31f5581e6d981d09a3-20230731165330-9xnfpj9.png",alt:""}})]),s._v(" "),t("p",[s._v("这里重点看下 CPU, 如果由操作系统切换进程实现并发, 代价太大, 毕竟每次都有 5 微秒左右的切换成本. Nginx 将其改到进程内部, 由 epoll 切换 ngx_connection_t 连接的处理, 成本会非常低. OpenResty 切换 Lua 协程, 也是基于同样的方式. 这样 CPU 的计算力会更多地用在业务处理上.")]),s._v(" "),t("p",[s._v("从整体上看, 只有充分, 高效地使用各类 IT 资源, 才能减少 RTT 时延, 提升并发连接.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/944a1fcf618e6df3359df9da08930fa2-20230731165330-9z1z143.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_2-请求的-一生"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-请求的-一生"}},[s._v("#")]),s._v(' 2.请求的"一生"')]),s._v(" "),t("p",[s._v("只有熟悉 Nginx 处理 HTTP 请求的流程, 优化时才能做到有的放矢.")]),s._v(" "),t("p",[s._v("首先要搞清楚 Nginx 的"),t("strong",[s._v("模块架构")]),s._v(". Nginx 是一个极其开放的生态, 它允许第三方编写的 C 模块与框架协作, 共同处理 1 个 HTTP 请求. 比如, "),t("strong",[s._v("所有的请求处理模块会构成一个链表")]),s._v(", 以 PipeAndFilter 这种架构依次处理请求. 再比如, 生成 HTTP 响应后, 所有过滤模块也会依次加工.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/bbf0564c3d12cd4ddf693a8d6de36fea-20230731165330-olgzrni.png",alt:""}})]),s._v(" "),t("h6",{attrs:{id:"_1-请求到来"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-请求到来"}},[s._v("#")]),s._v(" (1)请求到来")]),s._v(" "),t("p",[s._v("试想一下, 当用户请求到来时, 服务器到底会做哪些事呢? 首先, "),t("strong",[s._v("操作系统内核会将完成三次握手的连接 socket, 放入 1 个 ACCEPT 队列(如果打开了 reuseport, 内核会选择某个 worker 进程对应的队列), 某个 Nginx Worker 进程事件模块中的代码, 需要调用 accept 函数取出 socket")]),s._v(".")]),s._v(" "),t("p",[s._v("建立好连接并分配 ngx_connection_t 对象后, Nginx 会为它分配 1 个"),t("strong",[s._v("内存池")]),s._v(", 它的默认大小是 512 字节(可以由 connection_pool_size 指令修改), 只有这个连接关闭的时候才会去释放.")]),s._v(" "),t("p",[t("strong",[s._v("接下来 Nginx 会为这个连接添加一个默认 60 秒(client_header_timeout 指令可以配置)的定时器, 其中, 需要将内核的 socket 读缓冲区里的 TCP 报文, 拷贝到用户态内存中")]),s._v(". 所以, 此时会将连接内存池扩展到 1KB(client_header_buffer_size 指令可以配置)来拷贝消息内容, 如果在这段时间之内没有接收完请求, 则返回失败并关闭连接.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/ab2149f4c8aeb234dfc7a8e55bb510da-20230731165330-jw3fsi7.png",alt:""}})]),s._v(" "),t("h6",{attrs:{id:"_2-处理请求"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-处理请求"}},[s._v("#")]),s._v(" (2)处理请求")]),s._v(" "),t("p",[s._v("当接收完 HTTP 请求行和 HEADER 后, 就清楚了这是一个什么样的请求, 此时会再分配另一个默认为 4KB(request_pool_size 指令可以修改, 这里请思考为什么这个请求内存池比连接内存池的初始字节数多了 8 倍?) 的内存池.")]),s._v(" "),t("p",[t("strong",[s._v("Nginx 会通过协议状态机解析接收到的字符流, 如果 1KB 内存还没有接收到完整的 HTTP 头部, 就会再从请求内存池上分配出 32KB, 继续接收字符流")]),s._v(". 其中, 这 32KB 默认是分成 4 次分配, 每次分配 8KB(可以通过 large_client_header_buffers 指令修改), 这样可以避免为少量的请求浪费过大的内存.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/d7defd897494a46a0923e4a80532c4c9-20230731165330-ghde1bm.png",alt:""}})]),s._v(" "),t("p",[s._v("接下来, "),t("strong",[s._v("各类 HTTP 处理模块登场")]),s._v(". 当然, 它们并不是简单构成 1 个链表, 而是通过 11 个阶段构成了一个"),t("strong",[s._v("二维链表")]),s._v(". 其中, 第 1 维长度是与 Web 业务场景相关的 11 个阶段, 第 2 维的长度与每个阶段中注册的 HTTP 模块有关.")]),s._v(" "),t("p",[s._v("这 11 个阶段不用刻意死记, 只要掌握 3 个关键词, 就能够轻松地把他们分解开. 首先是 "),t("strong",[s._v("5 个阶段的")]),s._v("​"),t("mark",[t("strong",[s._v("预处理")])]),s._v(", 包括 post_read, 以及与 rewrite 重写 URL 相关的 3 个阶段, 以及 URL 与 location 相匹配的 find_config 阶段.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4cea04cac067e92373321ea60ba8f043-20230731165330-yqpmomx.png",alt:""}})]),s._v(" "),t("p",[s._v("其次是"),t("mark",[t("strong",[s._v("访问控制")])]),s._v(", 包括限流限速的 preaccess 阶段, 控制 IP 访问范围的 access 阶段和做完访问控制后的 post_access 阶段.")]),s._v(" "),t("p",[s._v("最后则是"),t("mark",[t("strong",[s._v("内容处理")])]),s._v(", 比如执行镜象分流的 precontent 阶段, 生成响应的 content 阶段, 记录处理结果的 log 阶段.")]),s._v(" "),t("p",[s._v("每个阶段中的 HTTP 模块, 会在 configure 脚本执行时就构成链表, 顺序地处理 HTTP 请求. 其中, HTTP 框架允许某个模块跳过其后链接的本阶段模块, 直接进入下一个阶段的第 1 个模块.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/136fef5e246dd5b33f921324f6986465-20230731165330-b8gwkzw.png",alt:""}})]),s._v(" "),t("p",[t("strong",[s._v("content 阶段会生成 HTTP 响应")]),s._v(". 当然, 其他阶段也有可能生成 HTTP 响应返回给客户端, 它们通常都是非 200 的错误响应. 接下来, 会由 HTTP 过滤模块加工这些响应的内容, 并由 write_filter 过滤模块最终发送到网络中.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8bc542eebf5c2c3c2a7816100ab6e431-20230731165330-d7fx6kv.png",alt:""}})]),s._v(" "),t("h6",{attrs:{id:"_3-请求的反向代理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-请求的反向代理"}},[s._v("#")]),s._v(" (3)请求的反向代理")]),s._v(" "),t("p",[s._v("Nginx 由于性能高, 常用来做分布式集群的负载均衡服务. 由于 Nginx 下游通常是公网, 网络带宽小, 延迟大, 抖动大, 而上游的企业内网则带宽大, 延迟小, 非常稳定, 因此 Nginx 需要区别对待这两端的网络, 以求尽可能地减轻上游应用的负载.")]),s._v(" "),t("p",[s._v("比如, 当配置 proxy_request_buffering on 指令(默认就是打开的)后, Nginx 会先试图将完整的 HTTP BODY 接收完, 当内存不够(默认是 16KB, 可以通过 client_body_buffer_size 指令修改)时还会保存到磁盘中. 这样, 在公网上漫长的接收 BODY 流程中, 上游应用都不会有任何流量压力.")]),s._v(" "),t("p",[s._v("接收完请求后, 会向上游应用建立连接. 当然, Nginx 也会通过定时器来保护自己, 比如建立连接的最长超时时间是 60 秒(可以通过 proxy_connect_timeout 指令修改).")]),s._v(" "),t("p",[s._v("当上游生成 HTTP 响应后, 考虑到不同的网络特点, 如果打开了 proxy_buffering on(该功能也是默认打开的)功能, Nginx 会优先将内网传来的上游响应接收完毕(包括存储到磁盘上), 这样就可以关闭与上游之间的 TCP 连接, 减轻上游应用的并发压力. 最后再通过缓慢的公网将响应发送给客户端. 当然, 针对下游客户端与上游应用, 还可以通过 proxy_limit_rate 与 limit_rate 指令限制传输速度. 如果设置 proxy_buffering off, Nginx 会从上游接收到一点响应, 就立刻往下游发一些.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/37364b09c06fc63a7b6ebbf5bf704a39-20230731165330-aqs60v5.png",alt:""}})]),s._v(" "),t("h6",{attrs:{id:"_4-返回响应"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-返回响应"}},[s._v("#")]),s._v(" (4)返回响应")]),s._v(" "),t("p",[t("strong",[s._v("当生成 HTTP 响应后, 会由注册为 HTTP 响应的模块依次加工响应")]),s._v(". 同样, 这些模块的顺序也是由 configure 脚本决定的. 由于 HTTP 响应分为 HEADER(包括响应行和头部两部分), BODY, 所以每个过滤模块也可以决定是仅处理 HEADER, 还是同时处理 HEADER 和 BODY.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8ba56efeb294e1dde3a830f7422dc427-20230731165330-l578x0c.png",alt:""}})]),s._v(" "),t("p",[s._v("因此, OpenResty 中会提供有 header_filter_by_lua 和 body_filter_by_lua 这两个指令.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/656a3530ebbd8242e91b1961abfb936e-20230731165330-ri497gx.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_3-应用层优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-应用层优化"}},[s._v("#")]),s._v(" 3.应用层优化")]),s._v(" "),t("blockquote",[t("p",[s._v("协议")])]),s._v(" "),t("p",[s._v("应用层协议的优化可以带来非常大的收益. 比如 HTTP/1 HEADER 的编码方式低效, REST 架构又放大了这一点, "),t("strong",[s._v("改为 HTTP/2 协议后就大有改善")]),s._v(". Nginx 对 HTTP/2 有良好的支持, 包括上游, 下游, 以及基于 HTTP/2 的 gRPC 协议.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/5111fbd74c14e7793b4b4c92ca676057-20230731165330-rnhebe4.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("压缩")])]),s._v(" "),t("p",[t("strong",[s._v("对于无损压缩, 信息熵越大, 压缩效果就越好")]),s._v(". 对于文本文件的压缩来说, Google 的 Brotli 就比 Gzip 效果好, 可以通过 https://github.com/google/ngx_brotli 模块, 让 Nginx 支持 Brotli 压缩算法.")]),s._v(" "),t("p",[s._v("对于静态图片通常会采用有损压缩, 这里不同压缩算法的效果差距更大. 目前 Webp 的压缩效果要比 jpeg 好不少. 对于音频, 视频则可以基于关键帧, 做动态增量压缩. 当然, 只要是在 Nginx 中做实时压缩, 就会大幅降低性能. 除了每次压缩对 CPU 的消耗外, 也不能使用 sendfile 零拷贝技术, 因为从磁盘中读出资源后, copy_filter 过滤模块必须将其拷贝到内存中做压缩, 这增加了上下文切换的次数. 更好的做法是提前在磁盘中压缩好, 然后通过 add_header 等指令在响应头部中告诉客户端该如何解压.")]),s._v(" "),t("blockquote",[t("p",[s._v("提高内存使用率")])]),s._v(" "),t("p",[s._v("只在需要时分配恰当的内存, 可以提高内存效率. 所以下图中 Nginx 提供的这些内存相关的指令, 需要根据业务场景谨慎配置. 当然, Nginx 的内存池已经将内存碎片, 小内存分配次数过多等问题解决了. 必要时, 通过 TcMalloc 可以进一步提升 Nginx 申请系统内存的效率.")]),s._v(" "),t("p",[s._v("同样, 提升 CPU 缓存命中率, 也可以提升内存的读取速度. 基于 cpu cache line 来设置哈希表的桶大小, 就可以提高多核 CPU 下的缓存命中率.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/414df32c8d38e2f38f2e024bc5fe3282-20230731165330-agzeif1.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("限速")])]),s._v(" "),t("p",[s._v("作为负载均衡, Nginx 可以通过各类模块提供丰富的限速功能. 比如 limit_conn 可以限制并发连接, 而 limit_req 可以基于 leacky bucket 漏斗原理限速. 对于向客户端发送 HTTP 响应, 可以通过 limit_rate 指令限速, 而对于 HTTP 上游应用, 可以使用 proxy_limit_rate 限制发送响应的速度, 对于 TCP 上游应用, 则可以分别使用 proxy_upload_rate 和 proxy_download_rate 指令限制上行, 下行速度.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1e77d49ee6878c2861bb193424ff5313-20230731165330-1kwk11m.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("Worker 间负载均衡")])]),s._v(" "),t("p",[s._v('当 Worker 进程通过 epoll_wait 的读事件获取新连接时, 就由内核挑选 1 个 Worker 进程处理新连接. 早期 Linux 内核的挑选算法很糟糕, 特别是 1 个新连接建立完成时, 内核会唤醒所有阻塞在 epoll_wait 函数上的 Worker 进程, 然而, 只有 1 个 Worker 进程, 可以通过 accept 函数获取到新连接, 其他进程获取失败后重新休眠, 这就是曾经广为人知的"惊群"现象. 同时, 这也很容易造成 Worker 进程间负载不均衡, 由于每个 Worker 进程绑定 1 个 CPU 核心, 当部分 Worker 进程中的并发 TCP 连接过少时, 意味着 CPU 的计算力被闲置了, 所以这也降低了系统的吞吐量.')]),s._v(" "),t("p",[s._v("Nginx 早期解决这一问题, 是通过应用层 accept_mutex 锁完成的, 在 1.11.3 版本前它是默认开启的: "),t("code",[s._v("accept_mutex on")]),s._v("​;")]),s._v(" "),t("p",[s._v("其中负载均衡功能, 是在连接数达到 worker_connections 的八分之七后, 进行次数限制实现的.")]),s._v(" "),t("p",[s._v("还可以通过 accept_mutex_delay 配置控制负载均衡的执行频率, 它的默认值是 500 毫秒, 也就是最多 500 毫秒后, 并发连接数较少的 Worker 进程会尝试处理新连接: accept_mutex_delay 500ms;")]),s._v(" "),t("p",[s._v("当然, 在 1.11.3 版本后, Nginx 默认关闭了 accept_mutex 锁, 这是因为操作系统提供了 reuseport(Linux3.9 版本后才提供这一功能)这个更好的解决方案.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/a5ad28e356285031fd17dd46b02d6b70-20230731165330-n39nws5.png",alt:""}})]),s._v(" "),t("p",[s._v("图中, 横轴中的 default 项开启了 accept_mutex 锁. 可以看到, 使用 reuseport 后, QPS 吞吐量有了 3 倍的提高, 同时处理时延有明显的下降, 特别是时延的波动(蓝色的标准差线)有大幅度的下降.")]),s._v(" "),t("blockquote",[t("p",[s._v("超时")])]),s._v(" "),t("p",[s._v("Nginx 通过红黑树高效地管理着定时器, 这里既有面对 TCP 报文层面的配置指令, 比如面对下游的 send_timeout 指令, 也有面对 UDP 报文层面的配置指令, 比如 proxy_responses, 还有面对业务层面的配置指令, 比如面对下游 HTTP 协议的 client_header_timeout.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/13c88cc2f61c8fc319d34d617b6433bb-20230731165330-kv8gv5r.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("缓存")])]),s._v(" "),t("p",[s._v("只要想提升性能必须要在缓存上下工夫. Nginx 对于七层负载均衡, 提供各种 HTTP 缓存, 比如 http_proxy 模块, uwsgi_proxy 模块, fastcgi_proxy 模块, scgi_proxy 模块等等. 由于 Nginx 中可以通过变量来命名日志文件, 因此 Nginx 很有可能会并行打开上百个文件, 此时通过 open_file_cache, Nginx 可以将文件句柄, 统计信息等写入缓存中, 提升性能.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/848f4c8572ce0b161a4df8dcd1dc97b5-20230731165330-k4tmrgx.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("减少磁盘 IO")])]),s._v(" "),t("p",[s._v("Nginx 虽然读写磁盘远没有数据库等服务要多, 但由于它对性能的极致追求, 仍然提供了许多优化策略. 比如为方便统计和定位错误, 每条 HTTP 请求的执行结果都会写入 access.log 日志文件. 为了减少 access.log 日志对写磁盘造成的压力, Nginx 提供了批量写入, 实时压缩后写入等功能, 甚至你可以在另一个服务器上搭建 rsyslog 服务, 然后配置 Nginx 通过 UDP 协议, 将 access.log 日志文件从网络写入到 rsyslog 中, 这完全移除了日志磁盘 IO.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/1fe5258e0881375e19c6709c77c8ba56-20230731165330-5if1ayl.png",alt:""}})]),s._v(" "),t("h5",{attrs:{id:"_3-系统优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-系统优化"}},[s._v("#")]),s._v(" 3.系统优化")]),s._v(" "),t("p",[s._v("最后来看看针对操作系统内核的优化.")]),s._v(" "),t("p",[s._v("首先是为由内核实现的 OSI 网络层(IP 协议), 传输层(TCP 与 UDP 协议)修改影响并发性的配置. 毕竟操作系统并不知道自己会作为高并发服务, 所以很多配置都需要进一步调整.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/8b2c90f488b5ddf9787af3b34821df99-20230731165330-s5jefbv.png",alt:""}})]),s._v(" "),t("p",[s._v("其次, 优化 CPU 缓存的亲和性, 对于 Numa 架构的服务器, 如果 Nginx 只使用一半以下的 CPU 核心, 那么就"),t("strong",[s._v("让 Worker 进程只绑定一颗 CPU 上的核心")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/bcce77d89b91c4bc364c7fa444d8a539-20230731165330-j8mn309.png",alt:""}})]),s._v(" "),t("p",[s._v("再次, "),t("strong",[s._v("调整默认的 TCP 网络选项, 更快速地发现错误, 重试, 释放资源")]),s._v(".")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/361c6a3204bf3699874a67e5581fd913-20230731165330-aah6kho.png",alt:""}})]),s._v(" "),t("p",[s._v("还可以"),t("strong",[s._v("减少 TCP 报文的往返次数")]),s._v(". 比如 FastOpen 技术可以减少三次握手中 1 个 RTT 的时延, 而增大初始拥塞窗口可以更快地达到带宽峰值.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7a0adba3d9496e05c73bceb63460db89-20230731165330-a4n25uj.png",alt:""}})]),s._v(" "),t("p",[s._v("还可以提高硬件资源的利用效率, 比如当在 listen 指令后加入 defer 选项后, 就使用了 TCP_DEFER_ACCEPT 功能, 这样 epoll_wait 并不会返回仅完成三次握手的连接, 只有连接上接收到的 TCP 数据报文后, 它才会返回 socket, 这样 Worker 进程就将原本 2 次切换就降为 1 次了, 虽然会牺牲一些即时性, 但提高了 CPU 的效率.")]),s._v(" "),t("p",[s._v("Linux 为 TCP 内存提供了动态调整功能, 这样高负载下我们更强调并发性, 而低负载下则可以更强调高传输速度.")]),s._v(" "),t("p",[s._v("还可以将小报文合并后批量发送, 通过减少 IP 与 TCP 头部的占比, 提高网络效率. 在 nginx.conf 文件中打开 tcp_nopush, tcp_nodelay 功能后, 都可以实现这些目的.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e4bbb12d9d47b764e7ffda0a6bd3a7b5-20230731165330-xtc924a.png",alt:""}})]),s._v(" "),t("p",[s._v("为了防止处理系统层网络栈的 CPU 过载, 还可以通过多队列网卡, 将负载分担到多个 CPU 中.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7dbbcc4cf5863d067e15eba3a1efd4ee-20230731165330-gpha65m.png",alt:""}})]),s._v(" "),t("p",[s._v("为了提高内存, 带宽的利用率, 必须更精确地计算出 BDP, 也就是通过带宽与 ping 时延算出的带宽时延积, 决定 socket 读写缓冲区(影响滑动窗口大小).")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/aa38498d0bd0d338b2425ddcbba3fa15-20230731165330-3yoc3wz.png",alt:""}})]),s._v(" "),t("p",[s._v("Nginx 上多使用小于 256KB 的小内存, 而且通常会按照 CPU 核数开启 Worker 进程, 这样一种场景下, TCMalloc 的性能要远高于 Linux 默认的 PTMalloc2 内存池.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/872274c36420eb37578b532b91fb595b-20230731165330-f4qmx53.png",alt:""}})]),s._v(" "),t("p",[s._v("作为 Web 服务器, Nginx 必须重写 URL 以应对网址变化, 或者应用的维护, 这需要正则表达式的支持. 做复杂的 URL 或者域名匹配时, 也会用到正则表达式. 优秀的正则表达式库, 可以提供更好的执行性能.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/4ff02fe22c5b17c3bbb870b12c5b4b34-20230731165330-s6h7smd.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"加餐6-分布式系统的本质是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#加餐6-分布式系统的本质是什么"}},[s._v("#")]),s._v(" 加餐6-分布式系统的本质是什么?")]),s._v(" "),t("p",[s._v("这期加餐带来了张帆老师的另一篇文章, 进一步聊聊分布式系统的本质.")]),s._v(" "),t("h5",{attrs:{id:"_1-分布式系统的价值"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-分布式系统的价值"}},[s._v("#")]),s._v(" 1.分布式系统的价值")]),s._v(" "),t("p",[s._v("进入到互联网快速发展的时期, 我们看到了分布式系统相比集中式系统的另一个更明显的优势: "),t("mark",[t("strong",[s._v("更高的可用性")])]),s._v(". 例如, 有 10 个能够承载 10000 流量的相同的节点, 如果其中的 2 个挂了, 只要实际流量不超过 8000, 系统依然能够正常运转.")]),s._v(" "),t("p",[t("mark",[t("strong",[s._v('而这一切的价值, 都是建立在分布式系统的"分治"和"冗余"之上的. 从全局角度来看, 这其实就是分布式系统的本质')])]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_2-分治"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-分治"}},[s._v("#")]),s._v(" 2.分治")]),s._v(" "),t("p",[s._v('分治, 字面意思是"分而治之", 和大脑在解决问题时的思考方式是一样的. 可以将整个过程分为 3 步: 分解 -> 治理 -> 归并. 而分治思想的表现形式多样, 分层, 分块都是它的体现.')]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/200abbd057f379238fb24d5d68deaf07-20230731165330-uvx5h4y.png",alt:""}})]),s._v(" "),t("p",[s._v("这么做的好处是: "),t("strong",[s._v("问题越小越容易被解决")]),s._v(", 并且, 只要解决了所有子问题, 父问题就都可以被解决了. 但是, 这么做的时候, 需要满足一个最重要的条件: "),t("mark",[t("strong",[s._v("不同分支上的子问题, 不能相互依赖, 需要各自独立")])]),s._v("​ "),t("strong",[s._v(".")]),s._v('  因为一旦包含了依赖关系, 子问题和父问题之间就失去了可以被"归并"的意义. 在软件开发领域, 可以把这个概念称为"'),t("strong",[s._v("耦合度")]),s._v('"和"'),t("strong",[s._v("内聚度")]),s._v('", 这两个度量概念非常重要.')]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("耦合度, 指的是软件模块之间相互依赖的程度")]),s._v(". 比如, 每次调用方法 A 之后都需要同步调用方法 B, 那么此时方法 A 和 B 间的耦合度是高的.")]),s._v(" "),t("li",[t("strong",[s._v("内聚度, 指的是模块内的元素具有的共同点的相似程度")]),s._v(". 比如, 一个类中的多个方法有很多的共同之处, 都是做支付相关的处理, 那么这个类的内聚度是高的.")])]),s._v(" "),t("p",[s._v("**内聚度通常与耦合度形成对比. 低耦合通常与高内聚相关, 反之亦然. **")]),s._v(" "),t("p",[s._v("所以, 当你打算进行分治的时候, 耦合度和内聚度就是需要考虑的重点.")]),s._v(" "),t("p",[s._v("下面来看个例子, 体会一下耦合度和内聚度的含义(图仅用于表达含义, 切勿作其他参考). 假设一个电商平台, 为了应对更大的访问量, 需要拆分一个同时包含商品, 促销的系统. 如果"),t("strong",[s._v("垂直拆分")]),s._v(", 是这样:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/237bce5cfb6d543e1250117aa7ce7595-20230731165330-v72bscf.png",alt:""}})]),s._v(" "),t("p",[s._v("而如果"),t("strong",[s._v("水平拆分")]),s._v(", 则是这样的:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/357c6d17bd7f740e9811de0d9e986843-20230731165330-is9f9gq.png",alt:""}})]),s._v(" "),t("p",[s._v("假如面对的场景仅仅是具体的商品详情展示页面, 很显然, 用水平拆分的效果会更好. 因为传统的商品展示必然会同时展示促销, 所以, 如果用水平拆分, 一次请求即可获取所有数据, 内聚度非常高, 并且此时模块间完全没有耦合. 而如果是垂直拆分的话, 就需要同时请求 2 个节点的数据并进行组合, 因此耦合度更高, 内聚度更差.")]),s._v(" "),t("p",[s._v("但是, 这样的假设在真实的电商场景中是不存在的. 从全局来看, 订单, 购物车, 商品列表等许多其他场景也需要促销信息. 并且这个时候我们发现引入了一些新的主体, 诸如订单, 购物车, 商品分类等等. 这个时候, 水平拆分带来的好处越来越小, 因为这样只解决了多个耦合中的一个, 低耦合丧失了. 并且随着商品和促销与外界的关联越来越多, 必然有些场景仅仅涉及到商品和促销的其中一个, 但是处理的时候, 还需要避免受到另一个的影响. 如此, 高内聚也丧失了.")]),s._v(" "),t("p",[s._v("这个时候, 反而通过垂直拆分可以获得更优的耦合度和内聚度, 如下图.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/c5eddffba0e886658a989aaab57d8b56-20230731165330-wal07b1.png",alt:""}})]),s._v(" "),t("p",[s._v("最高的耦合关系从原先的 6 降到了 4, 并且商品和促销各自的处理相互不受影响.")]),s._v(" "),t("p",[s._v("所以, 可以发现随着业务的变化, 耦合度与内聚度也会发生变化. 因此, "),t("mark",[t("strong",[s._v('及时地进行梳理和调整, 可以避免系统的复杂度快速增长, 这样才能最大程度地发挥"分治"带来的好处')])]),s._v(".")]),s._v(" "),t("p",[s._v("综上, "),t("strong",[s._v('分治可以简化解题的难度, 通过高内聚, 低耦合的协作关系达到更好的"性能与经济比", 来承载更大的流量. 而"冗余"则带来了系统可以 7*24 小时不间断运作的希望')]),s._v(".")]),s._v(" "),t("h5",{attrs:{id:"_3-冗余"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-冗余"}},[s._v("#")]),s._v(" 3.冗余")]),s._v(" "),t("p",[s._v("这里的冗余并不等同于代码的冗余, 无意义的重复劳动, 而是我们有意去做的, 人为增加的重复部分. 其目的是容许在一定范围内出现故障, 而系统不受影响, 如下图.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/39613a6cdf63438337cec65b1a503e4f-20230731165330-xg3hb3n.png",alt:""}})]),s._v(" "),t("p",[s._v("此时, 可以将冗余的节点部署在一个独立的环境中. 这个独立的环境, 可能是处于同一个局域网内的不同主机, 也可能是在不同的局域网, 还可能是在不同的机房. 很显然, 它们能够应对的故障范围是逐步递增的.")]),s._v(" "),t("p",[s._v("但是, 像这种单纯为了备用而做的冗余, 最大的弊端是, 如果没有出现故障, 那么冗余的这部分资源就白白浪费了, 不能发挥任何作用. 所以才提出了诸如双主多活, 读写分离之类的概念, 以提高资源利用率.")]),s._v(" "),t("p",[s._v("当然, 除了软件层面, 硬件层面的冗余也是同样的道理. 比如, 磁盘阵列可以容忍几块之内磁盘损坏, 而不会影响整体.")]),s._v(" "),t("p",[s._v("不过也很显然, 当故障影响范围大于冗余的容量时, 系统依然会挂. 所以, "),t("strong",[s._v("既然无法预知故障的发生情况, 那么做冗余的时候需要平衡的另一端就是成本")]),s._v(". 相比更多的冗余, 追求更好的性价比更合理一些.")]),s._v(" "),t("p",[s._v("在生活中的冗余也到处存在. 比如, 大部分的飞机和直升机的发动机都是偶数的, 汽车中的电子控制系统的冗余机制等. 就好比替身与真身的关系, 冗余的就是替身. 它可以和真身同时活动, 也可以代替真身活动.")]),s._v(" "),t("p",[t("strong",[s._v('分治和冗余讲究的都是分散化, 最终形成一个完整的系统还需要将它们"连接"起来')]),s._v('. 天下没有免费的午餐, 获得分布式系统价值的同时, 这个"再连接"的过程就是相比集中式系统要做的额外工作.')]),s._v(" "),t("blockquote",[t("p",[s._v("再连接")])]),s._v(" "),t("p",[s._v("如何将拆分后的各个节点再次连接起来, 从模式上来说, 主要是去中心化与中心化之分.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/529dec99b7db0b4c04b8b80bdbc9f73c-20230731165330-5lmikl1.png",alt:""}})]),s._v(" "),t("p",[s._v("前者完全消除了中心节点故障带来的全盘出错的风险, 却带来了更高的节点间"),t("strong",[s._v("协作成本")]),s._v(". 后者通过中心节点的集中式管理大大降低了协作成本, 但是一旦中心节点故障则全盘出错.")]),s._v(" "),t("p",[s._v("另外, 从技术角度来说, 如何选择通信协议和序列化机制, 也是非常重要的.")]),s._v(" "),t("p",[s._v("虽然很多通讯协议和序列化机制完全可以承担任何场景的连接责任, 但是不同的协议和序列化机制在适合的场景下才能发挥它最大的优势. 比如, 需要更高性能的场景运用 TCP 协议优于 HTTP 协议; 需要更高吞吐量的场景运用 UDP 协议优于 TCP 协议, 等等.")]),s._v(" "),t("h5",{attrs:{id:"_4-小结-16"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-小结-16"}},[s._v("#")]),s._v(" 4.小结")]),s._v(" "),t("p",[s._v("不管系统的规模发展到多大, 合理的拆分, 加上合适的连接方式, 那么至少会是一个运转顺畅, 协作舒服的系统, 至少能够正常发挥分布式系统应有的价值.")]),s._v(" "),t("p",[s._v("如今, 我们发现分布式系统还可以发挥更多的作用. 比如, 只要基于一个统一的上层通信协议, 其下层的不同节点可以运用不同的技术栈来发挥不同技术各自的优势, 比如用 Go 来应对高并发场景, 用 Python 来做数据分析等. 再比如, 提高交付的速度, 如下图.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b008b9e9a15c742498cdc3e745102a65-20230731165330-07zz52a.png",alt:""}})]),s._v(" "),t("p",[s._v("通过分配不同的团队, 人员同时进行多个模块的开发, 虽然总的耗时增加了, 但是整体的交付速度加快了.")]),s._v(" "),t("p",[s._v('事物最本质的东西是恒定的, 不变的, 可以指引我们的工作方向. 分布式系统的本质也是这样. 例如, 这样的"分治"方案耦合度和内聚度是否最优, 这样做"冗余"带来的收益是否成本能够接受. 只要持续带着这些思考, 我们就好像拿着一杆秤, 基于它, 就可以去衡量各种变量影响, 然后作权衡. 比如成本, 时间, 人员, 性能, 易维护等等. 也可以基于它去判断什么样的框架, 组件, 协议更适合当前的环境.')]),s._v(" "),t("p",[s._v("需要不断的权衡, 也意味着分布式系统的设计工作一定不是一步到位, 而是循序渐进的. 因为过分为未知的未来做更多的考量, 最终可能都会打水漂. 所以, 建议以多考虑 1~2 步为宜. 假如以你所在的团队中对重大技术升级的频率来作为参考的话, 做可供 2 个升级周期的设计, 花一个升级周期的时间先实现第一阶段, 下个阶段可以选择直接实现剩下的部分, 也可继续进行 2 个升级周期设计, 开启一个循环, 持续迭代, 并且不断修正方向以更贴近现实的发展, 就如下图这样.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/b25bcc8a2b30af994c0fcca3522ab811-20230731165330-2u8bxsy.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"大咖助场-李玥-高并发场景下如何优化微服务的性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大咖助场-李玥-高并发场景下如何优化微服务的性能"}},[s._v("#")]),s._v(" 大咖助场-李玥:高并发场景下如何优化微服务的性能?")]),s._v(" "),t("p",[s._v('陶辉老师的这门课程, 其中的知识点都是非常"硬核", 因为涉及到计算机操作系统底层的这些运行机制, 确实非常抽象. 我也看到有些同学在留言区提到, 希望能通过一些例子来帮助大家更好地消化一下这些知识. 那么这期分享呢, 我就来帮陶辉老师做一次科普, 帮助同学们把"基础设施优化"这一部分中讲到的一些抽象的概念和方法, 用举例子的方式来梳理一遍. 总结下的话, 就是帮你理清这些问题:')]),s._v(" "),t("ol",[t("li",[s._v("线程到底是如何在 CPU 中执行的?")]),s._v(" "),t("li",[s._v("线程上下文切换为什么会影响性能?")]),s._v(" "),t("li",[s._v("为什么说异步比同步的性能好?")]),s._v(" "),t("li",[s._v("BIO, NIO, AIO 到底有什么区别?")])]),s._v(" "),t("h5",{attrs:{id:"_1-为什么线程数越多反而性能越差"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-为什么线程数越多反而性能越差"}},[s._v("#")]),s._v(" 1.为什么线程数越多反而性能越差?")]),s._v(" "),t("p",[s._v("今天的课程, 从一个选择题开始. 假设有一个服务, 服务的业务逻辑就是根据传入的参数去数据库查询数据, 然后执行一些简单的业务逻辑后返回. 这个服务需要能支撑 10,000TPS 的请求数量, 那么"),t("strong",[s._v("数据库的连接池")]),s._v("设置成多大合适呢? 有二个选项:")]),s._v(" "),t("ol",[t("li",[s._v("A. 32")]),s._v(" "),t("li",[s._v("B. 2048")])]),s._v(" "),t("p",[s._v("直接公布答案, 选项 A 是性能更好的选择. "),t("strong",[s._v("连接池的大小直接影响的是, 同时请求到数据库服务器的并发数量")]),s._v(". 大家直觉的第一印象可能是, 并发越多总体性能应该越好才对, 事实真的是这样吗? 下面通过一个例子来探究一下这个问题的答案.")]),s._v(" "),t("p",[s._v("说有一个工厂, 要新上一个车间, 车间里面设置了 8 条流水生产线, 每个流水线设置 1 个工位, 那需要安排多少个工人才能达到最佳的效率呢? 显然是需要 8 个工人是吧? 工人少了生产线闲置, 工人多了也没有工位让他们去工作, 工人闲置, 8 个工人对 8 条流水线是效率最优解. 这里面的车间, 就可以类比为一台计算机, 工位就是线程, 工人就是 "),t("strong",[s._v("CPU 的核心")]),s._v(". 通过这个类比, 就可以得出这样一个结论: "),t("strong",[s._v("一个 8 核的 CPU, 8 个线程的情况下效率是最高的.")]),s._v("   这时, "),t("strong",[s._v("每个 CPU 核心正好对应一个线程")]),s._v(".")]),s._v(" "),t("p",[s._v("这是一个非常理想的情况, 它有一个前提就是, 流水线上的工人(CPU 核心)一直有事情做, 没有任何等待. 而现实情况下, 绝大部分的计算程序都做不到像工厂流水线那么高效. 一般开发的程序几乎是"),t("strong",[s._v("请求/响应")]),s._v("的模型, 对应到车间的例子, 生产模式不太像流水线, 更像是来料加工. 工人在工位上等着, 来了一件原料, 工人开始加工, 加工完成后, 成品被送走, 然后再等待下一件, 周而复始. 对应到计算机程序中, "),t("strong",[s._v("原料就是请求, 工人在工位上加工原料的过程, 相当于 CPU 在线程上执行业务逻辑的过程, 成品就是响应, 或者说是请求的返回值")]),s._v(". 可以对照下面这个图来理解这个例子, 以及对应到计算机程序中的概念.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/26d9ff2aeb64ac73fe3b0c5dd30f3ed7-20230731165330-qhej1m8.png",alt:""}})]),s._v(" "),t("p",[s._v("来料加工这种情况下, 只有 8 个工位并不能保证 8 个工人一直满负荷的工作. 因为, 工人每加工完成一件产品之后, 需要等待成品被送出去, 下一件原料被送进来, 才能开始继续工作. 在同一个工位上加工每件产品之间的等待是不可避免的, 那怎么才能最大化工人的效率, 尽量减少工人等待呢? 很简单, "),t("strong",[s._v("增加一些工位就可以了. 工人在 A 工位加工完成一件产品之后, 不在 A 工位等着, 马上去另外一个原料已经就绪的 B 工位继续工作, 这样只要工位设置得足够多, 就可以保证 8 个工人一直满负荷工作.")])]),s._v(" "),t("p",[s._v("那同样是 8 个工人满负荷工作, 多工位来料加工这种方式, 和上面提到的 8 条流水线作业的方式, 哪种效率更高呢? 还是流水线的效率高, 是不是? 原因是, 虽然在这两种方式下, 工人们都在满负荷工作, 但是, 来料加工这种方式下, "),t("strong",[s._v("工人在不同的工位之间切换, 也是需要一点点时间的")]),s._v(", 相比于流水线作业, 这部分工时相当于被浪费掉了.")]),s._v(" "),t("p",[s._v("工人在工位间切换, 对应到计算机执行程序的过程, 就是 CPU 在不同的线程之间切换, 称为"),t("strong",[s._v("线程上下文切换")]),s._v(". 一次线程上下文切换的时间耗时非常短, 大约只有几百个纳秒(ns). 一般来说并不需要太关注这个短到不可感知的切换时间, 但如果在多线程高并发的场景下, 如果没有很好的优化, 就有可能出现, CPU 在大量线程间频繁地发生切换, 累积下来, 这个切换时间就很可观了, 严重的话就会拖慢服务的总体性能.")]),s._v(" "),t("p",[s._v("再来思考另外一个问题: 设置多少个工位最合适呢? "),t("mark",[t("strong",[s._v("工位数量不足时, 工人不能满负荷工作, 工位数量太多了也不行, 工人需要频繁地切换工位, 浪费时间")])]),s._v(". 这里面一定存在一个最优工位数, 可以让所有工人正好不需要等待且满负荷工作. 最优工位数取决于工人的加工速度, 等待原料的时长等因素. 如果这些参数是确定的, 那确定这个最佳工位数就不太难了. 一般来说, 工位的数量设置成工人数量的两三倍就差不多了, 如果等待的时间比较长, 可能需要五六倍, 大致是这样一个数量级. 把这个结论对应到计算机系统中就是, "),t("mark",[t("strong",[s._v("对于一个请求/响应模型的服务, 并发线程数设置为 CPU 核数 N 倍时性能最佳, N 的大致的经验值范围是[2, 10]")])]),s._v(" .")]),s._v(" "),t("p",[s._v('有了这个结论, 再回过头来看开始提到的那个数据库连接池问题. 数据库服务符合 "请求/响应模型", 所以它的并发数量并不是越多越好, 根据上面得出的结论, 大约是 CPU 核数的几倍时达到最佳性能. 这个问题来自于数据库连接池 HikariCP 的一篇 Wiki: About Pool Sizing, 里面有详细的性能测试数据和计算最佳连接池数量的公式, 强烈推荐去看一下.')]),s._v(" "),t("h5",{attrs:{id:"_2-为什么说异步比同步的性能好"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么说异步比同步的性能好"}},[s._v("#")]),s._v(" 2.为什么说异步比同步的性能好?")]),s._v(" "),t("p",[s._v("然后再来思考这样一个问题. "),t("strong",[s._v("大家开发的很多业务服务实际的情况是, 并发线程数越多总体性能越好, 几百甚至上千个线程才达到最佳性能. 这并不符合上面说的那个结论啊? 什么原因?")])]),s._v(" "),t("p",[s._v("原因是这样的, 上面这个结论它有一个适用范围, 它的适用范围是, 像数据库服务这样, "),t("strong",[s._v("只依赖于本地计算资源")]),s._v("的服务.")]),s._v(" "),t("p",[s._v('**如果我们的业务服务在处理请求过程中, 还需要去调用其他服务, 这种情况就不适用于上面所说的结论. 这里面的其它服务包括数据库服务或者是下游的业务服务等等. 不适用的原因是, 线程在执行业务逻辑过程中, 很大一部分时间都花在等待外部服务上了, 在这个等待的过程中, 几乎不需要 CPU 参与. 换句话说, 每个线程需要的 CPU 时间是非常少的, 这样的情况下, 一个 CPU 核心需要非常多的线程才能把它"喂饱", 这就是为什么这些业务服务需要非常多的线程数, 才能达到最佳性能的原因. **')]),s._v(" "),t("p",[s._v("刚刚讲过, 线程数过多很容易导致 CPU 频繁的在这些线程之间切换, 虽然 CPU 看起来已经在满负荷运行了, 但 CPU 并没有把所有的时间都用在执行业务逻辑上, 其中一部分 CPU 时间浪费在线程上下文切换上了. 怎么来优化这种情况呢? 要想让 CPU 高效地执行业务逻辑, 最佳方式就是开头提到的流水线, 用和 CPU 核数相同的线程数, 通过源源不断地供给请求, 让 CPU 一直不停地执行业务逻辑. "),t("strong",[s._v("所以优化的关键点是, 减少线程的数量")]),s._v(", 把线程数量控制在和 CPU 核数相同的数量级这样一个范围.")]),s._v(" "),t("p",[s._v("要减少线程数量, 有这样两个问题需要解决.")]),s._v(" "),t("p",[s._v("第一个问题是, 如何用少量的线程来处理大量并发请求呢? "),t("strong",[s._v("可以用一个请求队列, 和一组数量固定的执行线程, 来解决这个问题")]),s._v(". 线程的数量就等于 CPU 的核数. 接收到的请求先放入请求队列, 然后分配给执行线程去处理. 这样基本上能达到, 让每个 CPU 的核心相对固定到一个线程上, 不停地执行业务逻辑这样一个效果.")]),s._v(" "),t("p",[s._v("第二个问题是, 执行线程在需要调用外部服务的时候, "),t("strong",[s._v("如何避免线程等待外部服务")]),s._v(", 同时还要保证及时处理返回的响应呢? 大家希望的情况是, 执行线程需要调用外部服务的时候, 把请求发送出去之后, 不要去等待响应, 而是去继续处理下一个请求. 等外部请求的响应回来之后, 能有一个通知, 来触发执行线程再执行后续的业务逻辑, 直到给客户端返回响应. 这其实就是通常所说的"),t("strong",[s._v("异步 IO 模型(AIO, Asynchronous I/O)")]),s._v(" , 这个模型的关键就是, 线程不去等待 Socket 通道上的数据, 而是待数据到达时, 由操作系统来发起一个通知, 触发业务线程来处理. Linux 内核从 2.6 开始才加入了 AIO 的支持, 到目前为止 AIO 还没有被广泛使用.")]),s._v(" "),t("p",[s._v("使用更广泛的是 "),t("strong",[s._v("IO 多路复用模型(IO Multiplexing)")]),s._v(" , IO 多路复用本质上还是一种同步 IO 模型. 但是, 它允许一个线程同时等待多个 Socket 通道, 任意一个通道上有数据到来, 就解除等待去处理. IO 多路复用没有 AIO 那么理想化, 但也只是多了一个线程用于等待响应, 相比 AIO 来说, 效果也差不了多少, 在内核 AIO 支持还不完善的时代, 是一个非常务实且高效的网络 IO 模型.")]),s._v(" "),t("p",[s._v("很多编程语言中, 都有一些网络 IO 框架, 封装了这些 IO 模型来解决这个问题, 比如 Java 语言中的 BIO, NIO, AIO 分别对应了同步 IO 模型, IO 多路复用模型和异步 IO 模型.")]),s._v(" "),t("p",[s._v("解决了上面这两个问题之后, 用很少量的线程就可以处理大量的并发请求. 这种情况下, 负责返回响应的线程和接收请求的线程, 不再是同一个线程, 这其实就是"),t("strong",[s._v("异步模型")]),s._v(". 可以看到, "),t("mark",[t("strong",[s._v("异步模型并不会让程序的业务逻辑执行得更快, 但是它可以非常有效地避免线程等待, 大幅减少 CPU 在线程上下文切换上浪费的时间")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  这样, 在同样的计算机配置下, 异步模型相比同步模型, 可以更高效地利用计算机资源, 从而拥有更好的总体的吞吐能力.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-12"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-12"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("理论上, 线程数量设置为 CPU 核数, 并且线程没有等待的情况下, CPU 几乎不会发生线程上下文切换, 这个时候程序的执行效率是最高的. 实际情况下, 对于一个请求/响应模型的服务, 并发线程数设置为 CPU 核数 N 倍时性能最佳. 这个 N 取决于业务逻辑的执行时间, 线程等待时间等因素, N 的大致的经验值范围是[2, 10].")]),s._v(" "),t("p",[t("strong",[s._v("使用异步模型编写微服务, 配合异步 IO 或者 IO 多路复用, 可以有效地避免线程等待, 用少量的线程处理大量并发请求, 大幅减少线程上下文切换的开销, 从而达到提升服务总体性能的效果.")])]),s._v(" "),t("h4",{attrs:{id:"大咖助场-傅健-那些年影响我们达到性能巅峰的常见绊脚石"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大咖助场-傅健-那些年影响我们达到性能巅峰的常见绊脚石"}},[s._v("#")]),s._v(" 大咖助场-傅健:那些年影响我们达到性能巅峰的常见绊脚石")]),s._v(" "),t("p",[s._v('其实说起性能调优, 往往有很多理论依据可以参考, 例如针对分布式系统的 NWR, CAP 等, 也有很多实践的"套路", 如绘制火焰图, 监控调用链等. 实际上, 不管方式, 方法有多少, 终极目标都是一致的, 那就是'),t("strong",[s._v("在固定的资源条件下, 将系统的响应速度调整到极致")]),s._v(".")]),s._v(" "),t("p",[s._v("但是在严谨地评价一个系统性能时, 很少粗略地使用这种表述: 在压力 A(如 1000 TPS)下, 基于软硬件配置 B, 应用的 C 操作响应时间是 D 毫秒. 而是加上一个百分位, 例如: 在压力 A(如 1000 TPS)下, 基于软硬件配置 B, 我们应用的 C 操作响应时间 "),t("strong",[s._v("99%")]),s._v("  已经达到 D 毫秒. 或者当需要提供更为详细的性能报告时, 提供的往往是类似于下面表格形式的数据来反映性能: 不仅包括常见的百分比(95%, 99% 等或者常见的四分位), 也包括平均数, 中位数, 最大值等.")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/148341f8de223fd782039224e70e594f-20230731165330-7ndnzdw.png",alt:""}})]),s._v(" "),t("p",[s._v('那为什么要如此"严谨"? 不可以直接说达到了某某水平吗? 究其原因, 还是系统很难达到一个完美的极致, 总有一些请求的处理时间超出了"预期", 让系统不够平滑(即常说的系统有"'),t("strong",[s._v("毛刺")]),s._v('"). 所以在追求极致的路上, 工作重心已经不再是"大刀阔斧"地进行主动性能调优以满足 99% 的需求, 而是着重观察, '),t("strong",[s._v('分析那掉队的 1% 请求, 找出这些"绊脚石"')]),s._v(' , 再各个击破, 从而提高系统性能的"百分比". 例如, 从 2 个 9(99%)再进一步提高到 3 个 9(99.9%). 而实际上不难发现, 这些所谓的绊脚石其实都是类似的, 所以这期就带你看看究竟有哪些绊脚石, 结合具体场景总结应对策略.')]),s._v(" "),t("h5",{attrs:{id:"场景1-重试-重定向"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景1-重试-重定向"}},[s._v("#")]),s._v(" 场景1:重试,重定向")]),s._v(" "),t("blockquote",[t("p",[s._v("案例")])]),s._v(" "),t("p",[s._v("当使用下游服务的 API 接口时, 偶尔会出现延时较大的情况, 而这些延时较大的调用最后也能成功, 且没有任何明显的时间规律. 例如响应延时正常时, API 调用性能度量数据如下:")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"stepName"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"CallRemoteService"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"values"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentType"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"RemoteService"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"startTime"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2020-07-06T10:50:41.102Z"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"totalDurationInMS"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"success"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" true\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("p",[s._v("而响应延时超出预期时, 度量数据如下:")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"stepName"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"CallRemoteService"')]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"values"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentType"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"RemoteService"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"startTime"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2020-07-06T04:31:55.805Z"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"totalDurationInMS"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2005")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"success"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" true\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("p",[s._v('解析这种情况可以说非常典型了, 单从以上度量数据来看, 没有什么参考意义, 因为所有的性能问题都是这样的特征, 即延时增大了. 这里面可能的原因也有许多, 例如 GC 影响, 网络抖动等等, 但是除了这些原因之外, 其实最常见, 最简单的原因往往都是 "重试". '),t("strong",[s._v("重试成功前的访问往往都是很慢的, 因为可能遇到了各种需要重试的错误, 同时重试本身也会增加响应时间")]),s._v(". 那作为第一个绊脚石, 现在就对它进行一个简单的分析.")]),s._v(" "),t("p",[s._v("以这个案例为例, 经过查询后你会发现: 虽然最终是成功的, 但是中途进行了重试, 具体而言就是在使用 HttpClient 访问下游服务时, 自定义了重试的策略: 当遇到 ConnectTimeoutException, SocketTimeoutException 等错误时直接进行重试.")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 构建http client")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CloseableHttpClient")]),s._v(" httpClient "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpClients")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("custom")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setConnectionTimeToLive")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TimeUnit")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MINUTES")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 省略其它非关键代码")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setServiceUnavailableRetryStrategy")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DefaultServiceUnavailableRetryStrategy")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 设置了一个自定义的重试规则")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setRetryHandler")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CustomizedHttpRequestRetryHandler")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("build")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 自定义的重试规则")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Immutable")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CustomizedHttpRequestRetryHandler")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpRequestRetryHandler")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("RETRY_COUNT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CustomizedHttpRequestRetryHandler")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("boolean")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("retryRequest")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")]),s._v(" exception"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" executionCount"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpContext")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 控制重试次数")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("executionCount "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("RETRY_COUNT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 遇到下面这些异常情况时, 进行重试")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectTimeoutException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NoHttpResponseException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" exception "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SocketTimeoutException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 省略其它非关键代码")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("p",[s._v("如果查询日志的话(由 org.apache.http.impl.execchain.RetryExec#execute 输出), 确实发现了重试的痕迹, 且可以完全匹配上请求和时间:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("57.808")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("threadpool"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("INFO")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RetryExec")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("I")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("O")]),s._v(" exception "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("http"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")])]),s._v("ConnectTimeoutException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" caught when processing request "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("http"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".86")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".130")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8080")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Connect")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".86")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".130")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8080")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".86")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".130")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" failed"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" connect timed out\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("57.808")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("threadpool"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("INFO")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RetryExec")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Retrying")]),s._v(" request "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("http"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".86")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".130")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8080")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("另外除了针对异常的重试外, 有时候也需要对于服务的短暂不可用(返回 503: SC_SERVICE_UNAVAILABLE)进行重试, 正如上文贴出的代码中设置了 DefaultServiceUnavailableRetryStrategy.")]),s._v(" "),t("p",[s._v('这个案例极其简单且常见, 但是这里需要额外补充下: 假设遇到这种问题, 又没有明确给出重试的痕迹(日志等)时, 应该怎么去判断是不是重试"捣鬼"的呢?')]),s._v(" "),t("p",[s._v("一般而言, 可以直接通过下游服务的调用次数数据来核对是否发生了重试. 但是如果下游也没有记录, 在排除完其它可能原因后, 仍然不能排除掉重试的原因, 因为重试的痕迹可能由于某种原因被隐藏起来了, 例如使用的开源组件压根没有打印日志, 或者是打印了但是我们应用层的日志框架没有输出. 这个时候, 也没有更好的方法, 只能翻阅源码查找线索.")]),s._v(" "),t("p",[s._v('另外除了直接的重试导致延时增加外, 还有一种类似情况也经常发生, 即"重定向", 而比较坑的是, 对于重定向行为, 很多都被"内置"起来了: 即不输出 INFO 日志. 例如 Apache HttpClient 对响应码 3XX 的处理(参考 org.apache.http.impl.client.DefaultRedirectStrategy)只打印了 Debug 日志:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" location "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" locationHeader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isDebugEnabled")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("debug")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Redirect requested to location \'"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" location "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\'"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v('再如, 当使用 Jedis 访问 Redis 集群中的结点时, 如果数据不在当前的节点了, 也会发生"重定向", 而它并没有打印出日志让我们知道这件事的发生(参考 redis.clients.jedis.JedisClusterCommand):')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("T")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("runWithRetries")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" slot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" attempts"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("boolean")]),s._v(" tryRandomNode"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("JedisRedirectionException")]),s._v(" redirect"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 省略非关键代码")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("JedisRedirectionException")]),s._v(" jre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// if MOVED redirection occurred,")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("jre "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("JedisMovedDataException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 此处没有输入任何日志指明接下来的执行会“跳转”了. ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// it rebuilds cluster's slot cache recommended by Redis cluster specification")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("connectionHandler"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("renewSlotCache")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("connection"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 省略非关键代码")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("runWithRetries")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("slot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attempts "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" jre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("finally")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("releaseConnection")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("connection"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("p",[s._v('综上, 重试是最普通的, 也是最简单的导致延时增加的"绊脚石", 而重试问题的界定难度取决于自身和下游服务是否有明显的痕迹指明. 而对于这种绊脚石的消除, 一方面应该主动出击, 尽量减少引发重试的因素. 另一方面, 一定要控制好重试, 例如:')]),s._v(" "),t("ol",[t("li",[s._v("控制好重试的次数;")]),s._v(" "),t("li",[s._v("错峰重试的时间;")]),s._v(" "),t("li",[s._v('尽可能准确识别出重试的成功率, 以减少不必要的重试, 例如可以通过"熔断""快速失败"等机制来实现.')])]),s._v(" "),t("h5",{attrs:{id:"场景2-失败引发轮询"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景2-失败引发轮询"}},[s._v("#")]),s._v(" 场景2:失败引发轮询")]),s._v(" "),t("blockquote",[t("p",[s._v("案例")])]),s._v(" "),t("p",[s._v("在使用 Apache HttpClient 发送 HTTP 请求时, 稍有经验的程序员都知道去控制下"),t("strong",[s._v("超时时间")]),s._v(", 这样, 在连接不上服务器或者服务器无响应时, 响应延时都会得到有效的控制, 例如会使用下面的代码来配置 HttpClient:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RequestConfig")]),s._v(" requestConfig "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RequestConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("custom")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setConnectTimeout")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 控制连接建立时间")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setConnectionRequestTimeout")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 控制获取连接时间")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setSocketTimeout")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v('// 控制"读取"数据等待时间')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("build")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("以上面的代码为例, 你能估算出响应时间最大是多少么? 上面的代码实际设置了三个参数, 是否直接相加就能计算出最大延时时间? 即所有请求 100% 控制在 6 秒.")]),s._v(" "),t("p",[s._v('先不说结论, 通过实际的生产线观察, 会发现大多符合预期: 可以说 99.9% 的响应都控制在 6 秒以内, 但是总有一些"某年某月某天", 发现有一些零星的请求甚至超过了 10 秒, 这又是为什么?')]),s._v(" "),t("blockquote",[t("p",[s._v("解析")])]),s._v(" "),t("p",[s._v("经过问题跟踪, 可以发现我们访问的 URL 是一个下游服务的域名(大多如此, 并不稀奇), 而这个域名本身有点特殊, 由于负载均衡等因素的考虑, 我们将它绑定到了多个 IP 地址. 所以假设这些 IP 地址中, 一些 IP 地址指向的服务临时不服务时, 则会引发轮询, 即轮询其它 IP 地址直到最终成功或失败, 而每一次轮询中的失败都会额外增加一倍 ConnectTimeout, 所以我们发现超过 6 秒甚至 10 秒的请求也不稀奇了. 可以通过 HttpClient 的源码来验证下这个逻辑(参考 org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect 方·法):")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("connect")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ManagedHttpClientConnection")]),s._v(" conn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpHost")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetSocketAddress")]),s._v(" localAddress"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" connectTimeout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SocketConfig")]),s._v(" socketConfig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpContext")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throws")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IOException")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Lookup")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectionSocketFactory")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" registry "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getSocketFactoryRegistry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectionSocketFactory")]),s._v(" sf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" registry"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("lookup")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getSchemeName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 域名解析, 可能解析出多个地址")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetAddress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" addresses "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getAddress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetAddress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getAddress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dnsResolver"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("resolve")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getHostName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" port "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("schemePortResolver"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("resolve")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 对于解析出的地址, 进行连接, 如果中途有失败, 尝试下一个")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetAddress")]),s._v(" address "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("boolean")]),s._v(" last "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Socket")]),s._v(" sock "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("createSocket")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        conn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bind")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetSocketAddress")]),s._v(" remoteAddress "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("InetSocketAddress")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("address"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" port"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isDebugEnabled")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("debug")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Connecting to "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" remoteAddress"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 使用解析出的地址执行连接")]),s._v("\n            sock "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("connectSocket")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                    connectTimeout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" sock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" remoteAddress"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" localAddress"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" context"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            conn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("bind")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sock"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isDebugEnabled")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("debug")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Connection established "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" conn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果连接成功, 则直接退出, 不继续尝试其它地址")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SocketTimeoutException")]),s._v(" ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("last"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throw")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectTimeoutException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectException")]),s._v(" ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("last"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 如果连接到最后一个地址, 还是失败, 则抛出异常. 如果不是最后一个, 则轮询下一个地址进行连接. ")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" msg "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getMessage")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Connection timed out"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throw")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConnectTimeoutException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throw")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HttpHostConnectException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ex"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" host"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" addresses"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isDebugEnabled")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("log"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("debug")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Connect to "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" remoteAddress "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('" timed out. "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("\n                    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Connection will be retried using another IP address"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br")])]),t("p",[s._v("通过以上代码, 可以清晰地看出: "),t("strong",[s._v("在一个域名能解析出多个 IP 地址的场景下, 如果其中部分 IP 指向的服务不可达时, 延时就可能会增加")]),s._v(". 这里不妨再举个例子, 对于 Redis 集群, 会在客户端配置多个连接节点(例如在 SpringBoot 中配置 spring.redis.cluster.nodes=10.224.56.101:8001,10.224.56.102:8001), 通过连接节点来获取整个集群的信息(其它所有节点). 正常情况下, 都会连接成功, 所以没有看到长延时情况, 但是假设刚初始化时, 连接的部分节点不服务了, 那这个时候就会连接其它配置的节点, 从而导致延时倍增.")]),s._v(" "),t("blockquote",[t("p",[s._v("小结")])]),s._v(" "),t("p",[s._v("这部分主要看了失败引发轮询造成的长延时案例, 细心的同学可能会觉得这不就是上一部分介绍的重试么? 但是实际上, 你仔细体会, 两者虽然都旨在提供系统可靠性, 但却略有区别: "),t("strong",[s._v("重试一般指的是针对同一个目标进行的再次尝试, 而轮询则更侧重对同类目标的遍历")]),s._v(".")]),s._v(" "),t("p",[t("strong",[s._v("假设配置了多个同种资源, 那么就很有可能存在轮询情况, 这种轮询会让延时远超出我们的预期.")]),s._v("  只是幸运的是, 在大多情况下, 轮询第一次就成功了, 所以很难观察到长延时的情况. 针对这种情况造成的延时, 除了在根源上消除外因, 还要特别注意控制好超时时间, 假设不知道这种情况, 而乐观地设置了一个很大的时间, 则实际发生轮询时, 这个时间会被放大很多倍.")]),s._v(" "),t("h5",{attrs:{id:"场景3-gc的-stw-停顿"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景3-gc的-stw-停顿"}},[s._v("#")]),s._v(' 场景3:GC的"STW"停顿')]),s._v(" "),t("blockquote",[t("p",[s._v("案例")])]),s._v(" "),t("p",[s._v('系统之间调用是服务最常见的方式, 但这也是最容易发生"掐架"的斗争之地. 例如对于组件 A, 运维或者测试工程师反映某接口偶然性能稍差, 而对于这个接口而言, 实际逻辑"简单至极", 直接调用组件 B 的接口, 而对于这个接口的调用, 平时确实都是接近 1ms 的:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16.495")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3160")]),s._v(" tid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3078502112")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Info")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentA")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Send")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Component")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16.496")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3160")]),s._v(" tid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3078502112")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Info")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentA")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Receive")]),s._v(" response from "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("而反映的性能掉队不经常发生, 而且发生时, 也没有没有特别的信息, 例如下面这段日志, 延时达到了 400ms:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27.222")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4725")]),s._v(" tid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3078407904")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Info")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentA")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Send")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Component")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27.669")]),s._v(" pid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4725")]),s._v(" tid"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3078407904")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Info")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentA")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Receive")]),s._v(" response from "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("同时, 对比下, 也发现这 2 次请求其实很近, 只有 2 分钟的差距. 那么这又是什么导致的呢?")]),s._v(" "),t("blockquote",[t("p",[s._v("解析")])]),s._v(" "),t("p",[s._v('对于这种情况, 很明显, A 组件往往会直接"甩锅"给 B 组件. 于是, B 组件工程师查询了日志:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27.669")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("nioEventLoopGroup"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("INFO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Received")]),s._v(" request from "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Component")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("A")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("04")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("07")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("27.669")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("nioEventLoopGroup"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("INFO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ComponentB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Response")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Component")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("B")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("然后 B 组件也开始甩锅: 鉴于双方组件传输层都是可靠的, 且 N 年没有改动, 那这次的慢肯定是网络抖动造成的了. 貌似双方也都得到了理想的理由, 但是问题还是没有解决, 这种类似的情况还是时而发生, 那问题到底还有别的什么原因么?")]),s._v(" "),t("p",[s._v("鉴于我之前的经验, 其实我们早先就知道 Java 的 "),t("strong",[s._v("STW")]),s._v("(Stop The World)现象, 可以说 Java 最省心的地方也是最容易让人诟病的地方. 即不管怎么优化, 或采用更先进的垃圾回收算法, "),t("strong",[s._v("都避免不了 GC, 而 GC 会引发停顿")]),s._v(". 其实上面这个案例, 真实的原因确实就是 B 组件的 GC 导致了它的处理停顿, 从而没有及时接受到 A 发出的信息, 何以见得呢?")]),s._v(" "),t("p",[s._v("早先在设计 B 组件时, 就考虑到未来某天可能会发生类似的事情, 所以加了一个 GC 的跟踪日志, 先来看看日志:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"metricName"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"java_gc"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentType"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"B"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentAddress"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"10.224.3.10"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentVer"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1.0"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"poolName"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"test001"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"trackingID"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"269"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"metricType"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"innerApi"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"timestamp"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2020-07-04T07:16:27.219Z"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"values"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"steps"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("   \n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"totalDurationInMS"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("428")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("p",[s._v("在 07:16:27.219 时, 发生了 GC, 且一直持续了 428ms, 所以最悲观的停顿时间是从 219ms 到 647ms, 而我们观察下 A 组件的请求发送时间 222 是落在这个区域的, 再核对 B 组件接收这个请求的时间是 669, 是 GC 结束后的时间. 所以很明显, 排除其它原因以后, 这明显是受了 GC 的影响.")]),s._v(" "),t("blockquote",[t("p",[s._v("小结")])]),s._v(" "),t("p",[s._v('假设某天看到零星请求有"掉队", 且没有什么规律, 但是又持续发生, 大家往往都会怀疑是网络抖动, 但是假设组件是部署在同一个网络内, 实际上, 不大可能是网络原因导致的, 而更可能是 GC 的原因. 当然, 跟踪 GC 有 N 多方法, 这里只是额外贴上了组件 B 使用的跟踪代码:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("List")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GarbageCollectorMXBean")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" gcbeans "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ManagementFactory")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getGarbageCollectorMXBeans")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GarbageCollectorMXBean")]),s._v(" gcbean "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" gcbeans"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("LOGGER")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("info")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"GC bean: "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" gcbean"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("gcbean "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationEmitter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("continue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n   "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationEmitter")]),s._v(" emitter "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationEmitter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" gcbean"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n   \n   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//注册一个GC(垃圾回收)的通知回调")]),s._v("\n   emitter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("addNotificationListener")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationListenerImplementation")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" notification "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GarbageCollectionNotificationInfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("GARBAGE_COLLECTION_NOTIFICATION")]),s._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("notification"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getType")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationListenerImplementation")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("NotificationListener")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   \n   "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handleNotification")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Notification")]),s._v(" notification"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" handback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GarbageCollectionNotificationInfo")]),s._v(" info "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("GarbageCollectionNotificationInfo")]),s._v("\n               "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("from")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CompositeData")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" notification"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getUserData")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" gctype "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" info"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getGcAction")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("replace")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"end of "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//此处只获取major gc的相关信息")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("gctype"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toLowerCase")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("contains")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"major"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" id "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" info"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getGcInfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getId")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" startTime "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" info"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getGcInfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getStartTime")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" duration "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" info"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getGcInfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getDuration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//省略非关键代码, 记录GC相关信息, 如耗费多久, 开始时间点等. ")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("h5",{attrs:{id:"场景4-资源争用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景4-资源争用"}},[s._v("#")]),s._v(" 场景4:资源争用")]),s._v(" "),t("blockquote",[t("p",[s._v("案例")])]),s._v(" "),t("p",[s._v('一段时间, 我们总是监控到一些性能"掉队"的请求, 例如平时访问 Cassandra 数据库都在 10ms 以内, 但是偶尔能达到 3s, 可以参考下面这个度量数据:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"stepName"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"QueryInformation"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n   "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"values"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"componentType"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Cassandra"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"totalDurationInMS"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3548")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"startTime"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2018-05-11T08:20:28.889Z"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"success"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("p",[s._v('持续观察后, 可以发现这些掉队的请求都集中在每天 8 点 20 分, 话说"百果必有因", 这又是什么情况呢?')]),s._v(" "),t("blockquote",[t("p",[s._v("解析")])]),s._v(" "),t("p",[s._v("这种问题, 其实相对好查, 因为它们有其发生的"),t("strong",[s._v("规律")]),s._v(", 这也是定位性能问题最基本的手段, 即找规律: 发生在某一套环境? 某一套机器? 某个时间点? 等等, 这些都是非常有用的线索. 而这个案例就是固定发生在某个时间点. 既然是固定时间点, 说明肯定有某件事固定发生在这个点, 所以查找问题的方向自然就明了了.")]),s._v(" "),t("p",[s._v("首先排除了应用程序及其下游应用程序定时去做任务的情况. 那么除了应用程序自身做事情外, 还能是什么? 可能我们会想到: "),t("strong",[s._v("运行应用程序的机器在定时做事情")]),s._v(". 果然, 查询了机器的 CronJob, 发现服务器在每天的 8 点 20 分(业务低峰期)都会去归档业务的日志, 而这波集中的日志归档操作, 又带来了什么影响呢?")]),s._v(" "),t("p",[s._v("日志备份明显是"),t("strong",[s._v("磁盘操作")]),s._v(", 所以要查看的是磁盘的性能影响, 如果磁盘都转不动了, 可想而知会引发什么. 一般都会有图形化的界面去监控磁盘性能, 但是这里为了更为通用的演示问题, 所以使用了 SAR 的结果来展示当时的大致情况(说是大致, 是因为 SAR 的历史记录结果默认是以 10 分钟为间隔, 所以只显示 8: 20 分的数据, 可能 8: 21 分才是尖峰, 但是却不能准确反映):")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/e8ded2abad14f88056f3df2cfec17529-20230731165330-bh9ftve.png",alt:""}})]),s._v(" "),t("p",[s._v("从上面的结果可以看出, 平时磁盘 await 只要 2ms, 而 8: 20 分的磁盘操作达到了几百毫秒. 磁盘性能的急剧下降影响了应用程序的性能.")]),s._v(" "),t("blockquote",[t("p",[s._v("小结")])]),s._v(" "),t("p",[s._v("在这个案例中, "),t("strong",[s._v("服务器上的定时日志归档抢占了资源, 导致应用程序速度临时下降, 即资源争用导致了性能掉队")]),s._v(". 再延伸一点来看, 除了这种情况外, 还有许多类似的资源争用都有可能引起这类问题, 例如有时候会在机器上装一些 logstash, collectd 等监控软件, 而这些监控软件如果不限制它们对资源的使用, 同样也可能会争用很多的资源. 诸如此类, 不一一枚举, 而针对这种问题, 很明显有好几种方法可以供我们去尝试解决, 以当前的案例为例:")]),s._v(" "),t("ol",[t("li",[t("strong",[s._v("降低资源争用")]),s._v(", 例如让备份慢一点;")]),s._v(" "),t("li",[t("strong",[s._v("错峰")]),s._v(", 错开备份时间, 例如不让每个机器都是 8 点 20 分去备份, 而是在大致一个时间范围内随机时间进行;")]),s._v(" "),t("li",[t("strong",[s._v("避免资源共享")]),s._v(", 避免多个机器/虚拟机使用同一块磁盘.")])]),s._v(" "),t("p",[s._v("上面讨论的争用都发生在一个机器内部, 实际上, 资源争用也常发生在同一资源(宿主, NFS 磁盘等)的不同虚拟机之间, 这也是值得注意的一个点.")]),s._v(" "),t("h5",{attrs:{id:"场景5-延时加载"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景5-延时加载"}},[s._v("#")]),s._v(" 场景5:延时加载")]),s._v(" "),t("blockquote",[t("p",[s._v("案例")])]),s._v(" "),t("p",[s._v('某日, 某测试工程师胸有成竹地抱怨: "你这个 API 接口性能不行啊, 每次执行自动化测试时, 总有响应很慢的请求." 于是一个常见的争执场景出现了: 当面演示调用某个 API 若干次, 结果都是响应极快, 测试工程师坚持他真的看到了请求很慢的时候, 但是开发又坚定说在我的机器上它就是可以啊. 于是互掐不停.')]),s._v(" "),t("blockquote",[t("p",[s._v("解析")])]),s._v(" "),t("p",[s._v("开发者后来苦思冥想很久, 和测试工程师一起比较了下到底他们的测试有什么不同, 唯一的区别在于测试的时机不同: "),t("strong",[s._v("自动化测试需要做的是回归测试, 所以每次都会部署新的包并执行重启")]),s._v(", 而开发者复现问题用的系统已经运行若干天, 那这有什么区别呢? 这就引入了这部分要讨论的内容——"),t("strong",[s._v("延时加载")]),s._v(".")]),s._v(" "),t("p",[s._v('当系统去执行某个操作时, 例如访问某个服务, 往往都是"按需执行", 这非常符合我们的行为习惯. 例如, 需要外卖点餐时, 才打开某 APP, 我们一般不会在还没有点餐的时候, 就把 APP 打开"守株待兔"某次点餐的发生. 这种思路写出来的系统, 会让系统在上线之时, 可以轻装上阵.')]),s._v(" "),t("p",[s._v("但这里的问题是什么呢? 假设打开 APP 的操作非常慢, 那等需要点餐的时候, 就会额外耗费更长的时间(而一旦打开运行在后台, 后面不管怎么点都会很快). 这点和这个案例其实是非常类似的.")]),s._v(" "),t("p",[s._v("现在回到案例, 持续观察发现, "),t("strong",[s._v("这个有性能问题的 API 只出现在第一次访问, 或者说只出现在系统重启后的第一次访问")]),s._v(". 当它的 API 被触发时, 它会看看本地有没有授权相关的信息, 如果没有则远程访问一个授权服务拿到相关的认证信息, 然后缓存认证信息, 最后再使用这个认证信息去访问其它组件. 而问题恰巧就出现在访问授权服务器完成初始化操作耗时比较久, 所以呈现出第一次访问较慢, 后续由于已缓存消息而变快的现象.")]),s._v(" "),t("p",[s._v('那这个问题怎么解决呢? 可以写一个"加速器", 说白了, 就是'),t("strong",[s._v('把 "延时加载" 变为 "主动加载"')]),s._v(" . 在系统启动之后, 正常提供服务之前, 就提前访问授权服务器拿到授权信息, 这样等系统提供服务之后, 第一个请求就很快了.")]),s._v(" "),t("p",[s._v('延时加载固然很好, 可以让系统轻装上阵, 写出的程序也符合我们的行为习惯, 但是它常常带来的问题是, 在第一次访问时可能性能不符合预期. 当遇到这种问题时, 也可以根据它的出现特征来分析是不是属于这类问题, 即是否是启动完成后的第一次请求. 如果是此类问题, 可以通过变"被动加载"为"主动加载"的方式来加速访问, 从而解决问题.')]),s._v(" "),t("h5",{attrs:{id:"场景6-网络抖动"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#场景6-网络抖动"}},[s._v("#")]),s._v(" 场景6:网络抖动")]),s._v(" "),t("p",[s._v("什么是网络抖动呢? "),t("strong",[s._v("网络抖动是衡量网络服务质量的一个指标")]),s._v(". 假设网络最大延迟为 100ms, 最小延迟为 10ms, 那么网络抖动就是 90ms, "),t("strong",[s._v("即网络延时的最大值与最小值的差值")]),s._v('. 差值越小, 意味着抖动越小, 网络越稳定. 反之, 当网络不稳定时, 抖动就会越大, 网络延时差距也就越大, 反映到上层应用自然是响应速度的"掉队".')]),s._v(" "),t("p",[s._v("为什么网络抖动如此难以避免? 这是因为网络的延迟包括两个方面: "),t("strong",[s._v("传输延时和处理延时")]),s._v('. 忽略处理延时这个因素, 假设一个主机进行一次服务调用, 需要跨越千山万水才能到达服务器, 中间出"岔子"的情况就会越多. 在 Linux 下面可以使用 traceroute 命令来查看跋山涉水的情况, 例如从我的 Linux 机器到百度的情况是这样的:')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root"),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@linux")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("~")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("# traceroute "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("T")]),s._v(" www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("baidu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com\ntraceroute "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("baidu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("119.63")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".197")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".139")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v(" hops max"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("60")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("byte")]),s._v(" packets\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.452")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.864")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.914")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.1")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.733")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.774")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.817")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".16")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".193")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.361")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.369")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.362")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".32")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".9")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.355")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.414")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.478")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.140")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".199")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".77")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.400")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.396")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.544")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.124")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".104")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".244")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.937")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.655")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.706")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.124")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".104")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".195")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.736")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.628")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.851")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.124")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".104")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".217")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13.093")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.857")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.954")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.112")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".4")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".65")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.586")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.510")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.609")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.112")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".8")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".222")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.250")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.183")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.174")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.112")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".122")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.926")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.360")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.479")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.112")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".78")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.433")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.320")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.508")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.75")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".216")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".50")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.295")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.194")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.386")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.75")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".202")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.191")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.135")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.042")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("119.63")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".197")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".139")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("44.095")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("43.999")]),s._v(" ms  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("43.927")]),s._v(" ms\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br")])]),t("p",[s._v('通过上面的命令结果可以看出, 我的机器到百度需要很多"路". 当然大多数人并不喜欢使用 traceroute 来评估这段路的艰辛程度, 而是直接使用 ping 来简单看看"路"的远近. 例如通过以下结果可以看出, 我们的网络延时达到了 40ms, 这时网络延时就可能是一个问题了.')]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root"),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@linux")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("~")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("# ping www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("baidu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("PING")]),s._v(" www"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("wshifen"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("103.235")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".46")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".39")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("56")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("84")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" bytes of data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" bytes from "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("103.235")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".46")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".39")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" icmp_seq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" ttl"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("41")]),s._v(" time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.2")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" bytes from "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("103.235")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".46")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".39")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" icmp_seq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" ttl"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("41")]),s._v(" time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.3")]),s._v(" ms\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("其实上面这两个工具的使用只是直观反映网络延时, 它们都默认了一个潜规则: "),t("strong",[s._v("网络延时越大, 网络越抖动")]),s._v(". 且不说这个规则是否完全正确, 至少从结果来看, 评估网络抖动并不够直观.")]),s._v(" "),t("p",[s._v('所以可以再寻求一些其它的工具. 例如可以使用 MTR 工具, 它集合了 tractroute 和 ping. 可以看下执行结果: 下图中的 best 和 wrst 字段, 即为最好的情况与最坏的情况, 两者的差值也能在一定程度上反映出抖动情况, 其中不同的 host 相当于 traceroute 经过的"路".')]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/43d1e78fcf6a5484762b3ac01d323a51-20230731165330-76yloe8.png",alt:""}})]),s._v(" "),t("blockquote",[t("p",[s._v("小结")])]),s._v(" "),t("p",[s._v('对于网络延时造成的抖动, 特别是传输延迟造成的抖动, 一般都是 "有心无力" 的. 只能说需要做好网络延时的抖动监测, 从而能真正定位到这个问题, 避免直接无证据就"甩锅"于网络.')]),s._v(" "),t("p",[s._v('另外, 在做设计和部署时, 除了容灾和真正的业务需求, 应尽量避免或者说减少"太远"的访问, 尽量将服务就近到一个机房甚至一个机柜, 这样就能大幅度降低网络延迟, 抖动情况也会降低许多, 这也是为什么 CDN 等技术兴起的原因.')]),s._v(" "),t("p",[s._v("那同一网络的网络延时可以有多好呢? 可以自己测试下. 例如, 我的 Linux 机器如果 ping 同一个网段的机器, 是连 1ms 都不到的:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root"),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@linux")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("~")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("# ping "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("PING")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("56")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("84")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" bytes of data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" bytes from "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" icmp_seq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" ttl"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.212")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" bytes from "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" icmp_seq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" ttl"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.219")]),s._v(" ms\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" bytes from "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.224")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".2")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v(".146")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" icmp_seq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" ttl"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),s._v(" time"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.154")]),s._v(" ms\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("h4",{attrs:{id:"特别放送-大厂面试到底在考些什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#特别放送-大厂面试到底在考些什么"}},[s._v("#")]),s._v(" 特别放送-大厂面试到底在考些什么?")]),s._v(" "),t("p",[s._v("2004 年我毕业于西安交通大学计算机科学与技术专业, 此后 16 年来既在华为, 腾讯, 思科, 阿里巴巴这样的大厂工作过, 也在两家几十人的创业公司工作过, 在这种对比下, 我对大厂面试的考核点很有心得体会.")]),s._v(" "),t("p",[s._v("作为候选人我拿到过很多大厂 offer, 作为面试官也考核过数百位同学的技术水平, 因此, 本节会兼顾面试官与候选人的视角, 分享如何拿下一线大厂的技术面试.")]),s._v(" "),t("h5",{attrs:{id:"_1-大厂面试到底在考些什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-大厂面试到底在考些什么"}},[s._v("#")]),s._v(" 1.大厂面试到底在考些什么?")]),s._v(" "),t("p",[s._v("相信绝大多数同学都经历过技术面试, 你肯定发现, 小厂与大厂的面试题差距很大, 其中, "),t("strong",[s._v("大厂特别关注程序性能")]),s._v(", 为什么呢? 在我看来有这样 3 个原因:")]),s._v(" "),t("p",[s._v("首先, 大厂产品的用户基数大, 任何微小的性能提升都会被庞大的用户数放大. 因此, 员工具备性能优先的思维, 有利于提升产品竞争力.")]),s._v(" "),t("p",[s._v("其次, 大厂经常会重新造轮子, 不管原因是什么, 造轮子都需要深厚的底层知识, 而性能是其中的核心要素. 而且, 愿意花时间去掌握底层知识的候选人, 学习动力更强, 潜力也会更好.")]),s._v(" "),t("p",[s._v("最后, 大厂待遇好, 成长空间大, 是典型的稀缺资源, 大家都打破了头往里挤. 在这样优中选优的情况下, 有区分度的性能题就是最好的面试题, 通过快速筛选不同档次的候选人, 可以节约招聘成本.")]),s._v(" "),t("p",[s._v("那么, 对于候选人来说, "),t("strong",[s._v("到底怎样才能答好性能面试题呢")]),s._v("? 首先, 背网上流传的大厂面试题, 绝对不是个好主意, 这是因为大厂的面试题并不是固定的, 往往都是考官自备的面试题, 这与每位考官的个人经历有关, 所以押中面试题的概率非常低.")]),s._v(" "),t("p",[s._v("而且, 面试并不是为了找出最优秀的那位候选人(这样的候选人手里往往拿着许多优厚的 offer, 签下他并不容易), 而是将大量的候选人分出层次, 再按照团队的业务发展, 技术方向, 薪资规划来发放 offer. 这样的话, 面试题就必须是开放的, 在各个层次上都有考核点, 有内涵更有外延, 任何一个点考官都可以展开了聊上个把小时. 你背的知识点, 未必是考官感兴趣会展开了问的点.")]),s._v(" "),t("p",[s._v("所以, "),t("strong",[s._v("大厂面试考核的是技能, 潜力, 而不是知识, 面试前的刷题不是为了背答案, 而是通过练习来提升技能")]),s._v("!")]),s._v(" "),t("p",[s._v("下面就以 1 道算法题为例, 带你看看大厂面试中都在考哪些技能点.")]),s._v(" "),t("h5",{attrs:{id:"_2-举例-1道算法题可以考核多少知识点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-举例-1道算法题可以考核多少知识点"}},[s._v("#")]),s._v(" 2.举例:1道算法题可以考核多少知识点?")]),s._v(" "),t("p",[s._v("题目: 请用熟悉的一门编程语言实现 Fibnacci 函数. Fibnacci 是中学代数提过的一个函数, 在自然界中广泛存在, 美学中的黄金分割点也与它相关. 可能有些同学还不熟悉 Fibnacci 函数, 它的定义如下:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/382d3bce5f741538c1b6bce90f044f92-20230731165330-gh4aqxm.png",alt:""}})]),s._v(" "),t("p",[s._v("比如 Fib(6)=Fib(5)+Fib(4)=5+3=8.")]),s._v(" "),t("p",[s._v("我个人非常喜欢用这道面试题, 因为它有很好的区分度, 至少能考核候选人 6 个方面的能力.")]),s._v(" "),t("p",[s._v("首先它像所有编码题一样, 可以判断候选人是否至少熟练使用一门编程语言, 特别是在不依赖编辑器错误提示的情况下, 能不能在白板上手写出高质量的代码. 这通常是大厂的基本要求.")]),s._v(" "),t("p",[s._v("其次, Fibnacci 函数很显然非常适合用"),t("strong",[s._v("递归函数")]),s._v("实现, 大多数候选人都可以写出递归函数, 比如:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Fib")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Fib")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Fib")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("可以看到递归函数其实并不难, 然而面试官会很自然地追问 2 个问题, 这才是考核点:")]),s._v(" "),t("p",[s._v("首先, 递归函数在系统层面有什么问题?")]),s._v(" "),t("p",[s._v("这其实是在考你是否知道"),t("strong",[s._v("栈溢出")]),s._v("问题. 每调用一次函数, 需要将函数参数, 返回值压栈, 而操作系统为每个线程分配的栈空间是有限的, 比如 Linux 通常只有 8MB. 因此, 当数字 n 过大时, 很容易导致 StackOverFlow 错误.")]),s._v(" "),t("p",[s._v("其次, 这段递归代码的"),t("strong",[s._v("时间复杂度")]),s._v("是多少?")]),s._v(" "),t("p",[s._v("《算法导论》中的递归树很适合用于猜测算法的时间复杂度, 下图是 Fibnacci(6) 展开的计算量, 可见, "),t("strong",[s._v("递归树中所有节点的数量, 就是递归函数的时间复杂度")]),s._v(":")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/7de71d489eb55bb8a5042d6e4f3acedb-20230731165330-9u0uzqn.png",alt:""}})]),s._v(" "),t("p",[s._v("如果仔细数一数, 会发现随着 n 的增大, 节点数大致接近 2n 个, 因此其"),t("strong",[s._v("时间复杂度为 O(2n)")]),s._v(" . 当然, 树中的节点数与 Fibnacci 数列相关, 大致为 O(1.618n) 个.")]),s._v(" "),t("p",[s._v("最后, 这道题还可以考察候选人能否运用"),t("strong",[s._v("逆向思维")]),s._v(", 通过一个循环实现递归函数的效果. 递归法的时间复杂度之所以达到了 O(2n), 是因为做了大量的重复运算. 比如求 Fibnacci(6) 时, Fibnacci(2) 重复执行了 4 次. 如果对 n 从小向大做递推运算, 重复使用已经计算完成的数字, 就能大大减少计算量, 如下所示:")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Fib")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  prev "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  cur "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<=")]),s._v(" n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cur "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" prev"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    prev "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cur"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    cur "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[s._v("这样, 只通过 1 次循环, 就能以 O(n) 的时间复杂度完成 Fibnacci 数列的计算. 这与动态规划的实现思路是一致的. 注意, 使用递推法时如果不小心, 会采用数组存放计算出的每个结果, 这样空间复杂度就从 O(1) 到了 O(n), 这也是一个考核点.")]),s._v(" "),t("p",[s._v("当然, 还可以通过公式直接计算出数列的值:")]),s._v(" "),t("p",[t("img",{attrs:{src:"/img/82d9839419c0ecb66388b51e7a755a10-20230731165330-o0xwy7w.png",alt:""}})]),s._v(" "),t("p",[s._v("但纯粹背下这个公式并没有意义, 因为你写出来后, 会有 2 个问题等着你:")]),s._v(" "),t("p",[s._v("首先, 如何使用高等数学推导出这个公式? 如果你能够答出来, 那么证明你的数学功底很好, 在数据挖掘, 人工智能人才短缺的当下, 这对你在大厂内部的职业发展很有好处!")]),s._v(" "),t("p",[s._v("其次, 上面这个公式有大量的浮点运算, 在数学中数字可以是无限长的, 但在计算机工程体系中, 任何类型都有最大长度(比如浮点类型通常是 64 个比特位), 所以对于根号 5 这样的无理数, 小数点后的数字会出现四舍五入而不精确, 而且当 n 非常大时, 有限的内存还会导致数据溢出. 因此上述的公式法并不能直接使用, 如果你能回答出适合计算机使用的矩阵解法(请参考wiki, 这里不再列出矩阵法的细节), 那就更完美了.")]),s._v(" "),t("p",[s._v("可见, 这么一道简单的题目, 就可以考察递归编码能力, 递推解法, 公式解法, 矩阵解法, 时间复杂度的推算, 计算机浮点运算特性等许多知识点. 而且, 随着你回答时涉及到更多的知识点, 面试官会基于自己的经验进一步延伸提问. 所以我不推荐你押题, 把基础技能掌握好才是最有效的面试备战法.")]),s._v(" "),t("p",[s._v("这道题目只是入门的算法题, 如果你应聘的是 Google, 头条之类非常重视算法的公司, 那么你还必须掌握动态规划, 贪心算法, 图算法等高级算法等等.")]),s._v(" "),t("h5",{attrs:{id:"_3-小结-13"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-小结-13"}},[s._v("#")]),s._v(" 3.小结")]),s._v(" "),t("p",[s._v("本节只是详细讲解了算法题, 其实从系统工程, 网络协议上也可以从性能优化这个方向快速区分出候选人的能力水平. 比如:")]),s._v(" "),t("ol",[t("li",[s._v("我在开课直播时提出的关于并发的问题, 多进程和多线程, 协程实现的并发编程, 各自的优势和劣势是什么?")]),s._v(" "),t("li",[s._v("或者 TCP 连接的 close_wait 状态出现时应当如何解决?")])]),s._v(" "),t("p",[s._v("这些都在考察你如何通过操作系统, 协调使用系统资源的能力.")]),s._v(" "),t("p",[s._v("另外, 除了硬核的知识技能外, 也不要忽略软技能, 这也能在面试中加分. 比如, 任何大厂都非常强调团队协作, 如果员工遇到难题时, 只会闷头冥想, 这样的时间成本太高, 既有可能延迟项目进度, 也不利于充分发挥大厂高手如林, 资源丰富的优势. 所以, 如果你在面试中, 表现出"),t("strong",[s._v("善于沟通, 乐于求助")]),s._v("的特性, 都是加分项.")]),s._v(" "),t("h4",{attrs:{id:"结束语-从业it-20年后-我将最看重什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#结束语-从业it-20年后-我将最看重什么"}},[s._v("#")]),s._v(" 结束语-从业IT 20年后,我将最看重什么?")]),s._v(" "),t("p",[s._v("走到今天, 我入行已经有 20 年了, 那作为结束语, 最后我特别想和你聊聊我的一些心得体会, 就说说我最看重的两大能力吧, 希望能给你的未来发展带来一些正反馈!")]),s._v(" "),t("p",[s._v("每次聊天提到程序员, 大部分人的脑海中总会跳出两个词: 996 与 35 岁危机, 它们都反应了 1 个现实: 程序员的竞争压力太大了. **其实, 老板是无法逼迫你 996 的, 只有大量虎视眈眈盯着你职位, 薪酬包的竞争者, 才能让你心甘情愿的加班, 让你为了度过 35 岁危机而不停地试图突破天花板! **为什么程序员的供给量这么大呢? 这既来源于中国庞大的人口基数, 也因为资本, 人才密集的互联网行业, 为年轻人提供了罕见的高薪资, 高成长机会.")]),s._v(" "),t("p",[s._v("程序员的平均薪资远高于其他职业, 这造成大量职场新人转行入互联网, 从 Javascript, Android, Python 等工程师做起(这些语言形成闭环的路径更短, 入门更快), 寻求更好的个人发展. 我有一些半路转行的朋友, 经常见到他们凌晨还在提交代码, 痛苦的转行过程让他们的自我驱动力无比强大.")]),s._v(" "),t("p",[s._v("各类院校也在为这个职业输送大量人才. 在我上大学那会, 只有计算机科学与技术这一个编程专业. 现在, 软件工程, 网页设计各类专业层出不穷, 而且, 计算机课程已经成为各理工专业必修的基础课.")]),s._v(" "),t("p",[s._v('所以程序员普遍年轻, 35+ 的我已经是我们团队年纪最大的程序员了, 这在其他行业实在是不可思议的事! 另一方面, 互联网仍然是一个朝阳行业, 变化是永恒的主题. 在开源盛行的当下, 注定会有层出不穷却又不太稳定的新框架, 只有深入的学习才能用好, 改进它. 所以, 我们常常会让自己"忙"起来, "学"起来, 这样似乎可以忘却焦虑.')]),s._v(" "),t("p",[s._v("**那焦虑是什么呢? 在我看来, 就是对未来的自己是否仍具备竞争力的不确定感. **如果只是在不停地学习新语言, 新框架, 那么 35 岁的你, 竞争力一定不如 25 岁的你, 因为对框架的熟练度是不值几倍薪资差距的. 我认为, 有两个能力可以消除这种不确定性, 它们不会因为新技术迭代, 每次都让你数据清零后重新开始.")]),s._v(" "),t("h5",{attrs:{id:"_1-构建知识体系最需要什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-构建知识体系最需要什么"}},[s._v("#")]),s._v(" 1.构建知识体系最需要什么?")]),s._v(" "),t("p",[t("strong",[s._v("首先,")]),s._v(" "),t("mark",[t("strong",[s._v("是不局限于一招一式, 构建知识体系的能力")])]),s._v("​ "),t("strong",[s._v(".")]),s._v("  当你还未对某个领域形成知识体系时, 只能解决曾经遇到过的相似问题, 或者仅涉及单一知识点, 能够从网上查询到答案的简单问题. 而基于新技术做架构设计, 或者定位涉及多个系统的复杂问题时, 知识体系是最值得依赖的灯塔, 它能指引你前进的方向.")]),s._v(" "),t("p",[s._v("知识体系可以将散落在脑海中的知识, 通过逻辑联系在一起, 形成庞大的网络. "),t("mark",[t("strong",[s._v("知识点之间的联系线条越多, 网络就越健壮, 越能应对不确定性; 网络越大, 覆盖的领域越广, 你能解决问题的价值就越高")])]),s._v("​ "),t("strong",[s._v("!")]),s._v("  所以, 我们需要结网的能力!")]),s._v(" "),t("p",[s._v("比如, 你学习了某个人脸识别框架的用法, 通过 API 把它集成到系统中, 此时该技术与已有知识体系是割裂的. 在你了解 CNN 网络, 知道它只不过是一种聚类函数后, 就能通过数学知识把它联结到知识网络中; 在了解到密集浮点运算下保持精度的方案, 与主流 IEEE-754 方案间的差别后, 你又可以从数值计算维度上与常用的编程语言关联起来; 从 GPU, CPU 对并行计算的设计差别上, 你还可以在计算体系架构这条线上增强知识体系; 从分布式模型训练系统中找到分而治之的思想, 你就可以从算法上连接网络, 等等.")]),s._v(" "),t("p",[s._v("概括下的话, 我认为"),t("mark",[t("strong",[s._v("构建知识体系最需要的其实是底层知识")])]),s._v("! 两个看似无关的技术, 可以再往下看一层, 找找它们共同的理论基础, 建立逻辑关联. 我认为, 下面 3 个底层知识对结网的帮助最大:")]),s._v(" "),t("ol",[t("li",[t("mark",[t("strong",[s._v("数据结构与算法")])]),s._v(", 我推荐你精读《算法导论》这本书, 程序是由数据与算法构成的, 这条线几乎可以连接所有技术点.")]),s._v(" "),t("li",[t("mark",[t("strong",[s._v("计算机网络知识")])]),s._v(", 它可以连接所有涉及互联网的技术.")]),s._v(" "),t("li",[s._v("最后是"),t("mark",[t("strong",[s._v("操作系统知识")])]),s._v(", 毕竟所有的软件都需要通过操作系统才能操作硬件.")])]),s._v(" "),t("p",[s._v("另外, 在给知识体系添砖加瓦时, 一定要注意"),t("strong",[s._v("知识的正确性, 否则网络越密, 后续修复成本就越高")]),s._v('. 建议尽量去源头寻找第一手知识, 虽然有时这并不容易. 比如学习 HTTP/3 协议时, 就只能去看那 5 份 RFC 文档, 但 RFC 文档的结构设计是作为参考手册使用的, 它并不适合首次学习, 此时还可以借鉴一些权威高手基于一手知识分享的"二手"文章, 这能让你更快地看懂 RFC.')]),s._v(" "),t("h5",{attrs:{id:"_2-好的-表达力-能为你插上翅膀"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-好的-表达力-能为你插上翅膀"}},[s._v("#")]),s._v(' 2.好的"表达力"能为你插上翅膀')]),s._v(" "),t("p",[s._v('**第 2 个最能对抗"焦虑"的是表达力. **做技术的同学通常对跟自己技术水平差不多, 但因为表达力更好, 从而拥有更高职位的同学不屑一顾, 我曾经也是这样, 总觉得咱靠的是"真才实料", 不是嘴皮子. 这是一个很大的误区, 它与你的职业发展密切相关.')]),s._v(" "),t("p",[s._v("如果团队里有 3 位同学: 1 位技术最好却不擅言辞, 1 位擅长管理, 调动团队氛围, 1 位擅长表达, 你觉得谁的职业发展最好呢? 其实是最后那位, 因为当团队向上级汇报工作时, 他最容易让团队的工作得到认可, 从而获取更多的资源把事情做成, 使人人都有好处. 久而久之, 他就会获得更多的提拔机会.")]),s._v(" "),t("p",[s._v('我想你多半遇到过那种沟通起来特"费劲"的人, 说话总是找不到重点, 这样他就只能做一些简单的, 不需要协作的工作. 现代社会是需要高度协作的, 如果没办法说清楚你的工作成果, 你的价值就会大大缩水. 当然, 好的表达力不是无中生有, 也不是能说会道, 毕竟你面对的都是专业人士.')]),s._v(" "),t("p",[s._v("在职场中, 由于沟通对象时间有限, 所以采用金字塔方式表达效果最好. 比如, 当我向老板汇报工作时, 我会在第一时间讲结论, 然后再按照重要性顺序讲论据. 否则, 他同时要处理的事务比我广得多, 如果我不能快速让他抓住重点, 就很容易失去这次沟通机会. 再比如我写这个专栏时, 大家同时订阅了那么多课程, 时间非常珍贵, 我必须在每节课起始就开宗明义地给出场景, 把各种对立面引发的冲突列出来, 如果它能聚焦你的视线, 我就会在正文中层层递进地讲下去, 每一段总是为了引出下一段, 防止在碎片化阅读时代里丢掉你的注意力.")]),s._v(" "),t("p",[s._v("那如果你想学习金字塔表达方式的话, 我十分建议你精读《金字塔原理》这本书, 这也是写作本专栏时, 我的编辑推荐给我的, 对我的帮助非常大, 现学现卖推荐给你.")]),s._v(" "),t("p",[s._v('总结而言, 我希望你拥有"结网能力". 构建广泛, 结实的知识网络, 可以帮助你提升竞争力, 减轻"焦虑", 面对新技术时不用清零重来; 但当你无法将新学的知识纳入已有知识体系时, 不妨把眼光放低点, 从底层技术中找找关联.  我还希望你拥有"表达能力". 再硬核的知识体系也需要通过优秀的表达力, 转换为动听的语言和精练的文字, 再通过互联网跨越时空, 让你跳出公司, 在整个行业中提升影响力, 竞争力.')]),s._v(" "),t("p",[s._v("‍")]),s._v(" "),t("p",[s._v("‍")])])}),[],!1,null,null,null);t.default=e.exports}}]);