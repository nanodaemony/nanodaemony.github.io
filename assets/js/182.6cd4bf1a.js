(window.webpackJsonp=window.webpackJsonp||[]).push([[182],{627:function(_,v,t){"use strict";t.r(v);var a=t(7),s=Object(a.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h1",{attrs:{id:"_279-后端工程师的高阶面经-极客时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_279-后端工程师的高阶面经-极客时间"}},[_._v("#")]),_._v(" 279-后端工程师的高阶面经(极客时间)")]),_._v(" "),v("h3",{attrs:{id:"开篇词"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#开篇词"}},[_._v("#")]),_._v(" 开篇词")]),_._v(" "),v("h4",{attrs:{id:"开篇词-面试如戏-台上一分钟-台下十年功"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#开篇词-面试如戏-台上一分钟-台下十年功"}},[_._v("#")]),_._v(" 开篇词-面试如戏,台上一分钟,台下十年功")]),_._v(" "),v("p",[_._v("你好, 我是大明, 一名热爱开源的 IT 猛男. 欢迎你的加入, 从今天开始我们一起升级打怪, 通关后端技术面试.")]),_._v(" "),v("p",[_._v("作为一名早期从事业务开发转型成为中间件研发的工程师, 我一直奋战在互联网一线, 擅长设计和实现中间件, 包括 Web, ORM, 微服务框架, 网关, 分库分表, IM 等, 积累了很多造高并发, 大流量轮子的经验. 除了工作之外, 我也一直活跃在开源社区, 学习, 交流最新的技术, 现在是 Beego 的 PMC 和 Apache Dubbo 的 Committer.")]),_._v(" "),v("p",[_._v('在我的职业生涯中曾跳过几次槽, 都很幸运地得到了自己理想的岗位, 甚至被朋友笑称 "offer 收割机", 因为几乎每次跳槽我都是手捏好几个大厂 offer, 按心意选择. 如果你也想像我一样拥有选择的权利, 可以加入进来, 我会把我自己多年珍藏的经历分享给你, 助你顺利通关.')]),_._v(" "),v("blockquote",[v("p",[_._v("机会永远留给有准备的人")])]),_._v(" "),v("p",[_._v("那怎样做才能成为下一个 offer 收割机呢?")]),_._v(" "),v("p",[_._v("我想除了平时工作中的稳扎稳打, 面试前的准备工作也是必要的. 因为面试从来都不是件简单的事, 好的岗位永远是竞争最激烈的地方. 想要在高手如云的竞技场上展现自己的优势, 让自己脱颖而出, 以下几点必不可少:")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("扎实的基础知识")]),_._v(", 基础是一切的开始, 平时就要做好技术积累.")]),_._v(" "),v("li",[v("strong",[_._v("一些成功或失败的项目经历")]),_._v(", 这些经历能让你看到更多细节, 无论是经验还是教训都很有价值.")]),_._v(" "),v("li",[v("strong",[_._v("所在领域的最佳实践")]),_._v(", 让我们的工作更加专业, 高效, 避免很多问题.")]),_._v(" "),v("li",[v("strong",[_._v("一些独到的观点或创新性的方案")]),_._v(", 这是让你崭露头角的关键.")])]),_._v(" "),v("p",[_._v("可其实很多人都做不到这几点. 这些年我一直担任极客时间训练营的讲师, 带过2000多个学员, 这个过程中我发现 "),v("strong",[_._v("很多人不知道怎么面试, 也不知道怎么准备面试.")])]),_._v(" "),v("ul",[v("li",[_._v("有的人明明知道有一些问题肯定会被问到, 但面试前还是不好好准备, 要么回答得模棱两可, 要么答非所问, 从而错失 offer.")]),_._v(" "),v("li",[_._v("有的人不知道怎么包装自己的项目经历, 凸显自己解决方案的优点, 以至于看上去非常平淡, 没办法给人留下深刻印象.")]),_._v(" "),v("li",[_._v("还有人简历写得花里胡哨, 但是实际上一问三不知, 简历和经历完全对不上.")])]),_._v(" "),v("p",[_._v("比如之前我曾看到有的人简历上写了"),v("strong",[_._v("微服务架构")]),_._v(', 但当我问他们服务治理的时候, 他们的反应让我非常诧异. 他们有的说: "啊, 服务治理是啥?", 有的说: "啊! 我们公司体量太小了, 都不需要服务治理", 一句话就暴露了短板.')]),_._v(" "),v("p",[_._v("在发现这些问题之后, 我就开始有意识地整理后端技术面试中的重难点, 梳理面试的思路和亮点方案, 并辅以一些经典案例来佐证. 希望能够帮助更多的人在面试过程中有条理地表达自己, 突显自身优势, 并最终获得理想的职位. 下面这张微服务架构面试思路图, 就是我的成果之一. 后面每学完一章的内容, 我都会整理出一张这样的图片, 来帮助你梳理知识点, 建立起自己的知识框架.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/21dd6b903c7421505be505yy14a7a549-20231223175002-9vdxlvx.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里还要单独强调一下这门课程的一个特殊的设计——"),v("strong",[_._v("亮点方案")]),_._v(". 虽然面试成功很大程度上取决于对面试官的问题是否能做到对答如流, 但别忘了, 并不是说回答出全部问题就能拿到 offer, 更重要的一点是要比别的候选者回答得更出彩. 因此在上述每一个主题之下, 都会教你如何展示自己的亮点.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6b51b186e2d60461c257c508b0caf7b1-20231223175002-erwo7ng.png",alt:""}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("从实践中来,到实践中去")])]),_._v(" "),v("p",[_._v("说了这么多关于面试的事情, 是不是整个课程就只能用在面试上呢?")]),_._v(" "),v("p",[_._v("当然不是, 课程中展示的所有案例都是我在工作场景中摸爬滚打多年摸索出来的, 可以说这门课程是来自于实践, 最终也将回归实践. "),v("strong",[_._v("所有的案例和方案都是可以拿到生产环境中去实践的")]),_._v(".")]),_._v(" "),v("ul",[v("li",[_._v("如果你是工作不久, 经验不足的小白, 可以把前面的知识点当作台阶, 把里面的最佳实践作为样板, 去大刀阔斧地应用在实际的生产环境中.")]),_._v(" "),v("li",[_._v("如果你已经有了一些基础和经验, 就可以通过前面系统的知识夯实自己的基础, 通过里面的亮点方案, 为自己目前的工作找到新的解决思路.")]),_._v(" "),v("li",[_._v("如果你正准备跳槽, 那这门课程可以说是为你量身打造的了, 它将成为你的助手, 帮你快速搭建起自己的知识框架, 助你面试通关.")])]),_._v(" "),v("p",[_._v("课程中也多次强调, 这些方案应该尽可能地去应用一下, 并不只是为了面试, 也是为了提高自身技术实力. 所以不要只关注课程中的套路和话术, 其中的知识点和经典案例也需要你好好消化, 以应对未来真实工作场景中复杂多变的情况.")]),_._v(" "),v("h5",{attrs:{id:"课程设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#课程设计"}},[_._v("#")]),_._v(" 课程设计")]),_._v(" "),v("p",[_._v("为了满足这些需求, 我选取了后端工程师在面试和工作场景中必知必会的 5 个热点领域: "),v("strong",[_._v("微服务, 数据库, 消息队列, 缓存和 NoSQL")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("第一章: 微服务架构")])]),_._v(" "),v("p",[_._v("微服务架构可以将大型应用拆分为多个小型服务, 提高开发效率与性能. 这个部分将学习最重要的几个服务治理手段, 包括"),v("strong",[_._v("服务注册与发现, 负载均衡, 熔断, 降级, 限流, 优雅调用第三方")]),_._v("等. 可以根据具体情况选择不同的服务治理策略, 来保证服务的高可用.")]),_._v(" "),v("blockquote",[v("p",[_._v("第二章: 数据库与 MySQL")])]),_._v(" "),v("p",[_._v("数据库和 MySQL 是存储数据的技术基础, 其性能和稳定性关系到整个系统的效率和可靠性. 这部分主要了解数据库索引, 事务, SQL 优化, 不停机数据迁移, 分库分表等核心知识点与解决方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("第三章: 消息队列")])]),_._v(" "),v("p",[_._v("消息队列和 Kafka 在分布式系统中担任着异步处理, 流式计算等重要的角色, 是构建高性能, 可靠的分布式系统的必要工具. 这部分会了解消息队列的高可用和高性能原理以及实践中常见的问题, 如积压, 重复消费, 消息可靠性等.")]),_._v(" "),v("blockquote",[v("p",[_._v("第四章: 缓存")])]),_._v(" "),v("p",[_._v("所谓缓存用得好, 性能没烦恼. 缓存可以大大提高系统的访问速度, 减轻数据库访问压力. 这部分内容基本涵盖了最热门的缓存模式, 缓存击穿, 雪崩, 穿透等问题的解决方案, 将深入 Redis 的高可用和高性能原理.")]),_._v(" "),v("blockquote",[v("p",[_._v("第五章: NoSQL")])]),_._v(" "),v("p",[_._v("随着这些年行业技术栈演进, NoSQL 已经变得日益重要. 这一模块会在掌握了基本的 NoSQL 概念和原理的基础上, 对 MongoDB 和 Elasticsearch 常见的面试热点进行探讨, 包括性能调优, 高可用和高性能方案.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f930381d24f51cbe3dcff301031c2949-20231223175002-r74l98t.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("工作中的重难点也必然会成为面试中的常考点, 所以这门课程也并不是只会教你面试的套路, 更多的是 "),v("strong",[_._v("技术之间的联系, 灵活多变的方案, 处理问题的思路, 以及沟通时的引导策略")]),_._v(". 如果你可以透过表面的知识点和面试的话术, 掌握这些更深层次的技能, 那么你收获的就不只是一两个 offer 那么简单了.")]),_._v(" "),v("p",[_._v('古人讲究 "兵马未动, 粮草先行", 这门课就是 "广积粮" 的好机会. 现在就业市场变化莫测, 前有互联网领域增速放缓, 后有 AI 技术大爆发, 企业也在时刻准备着调整自己的方向. 不过无论怎样变化和调整, 高端人才始终是稀缺资源, 只有花时间做好充足的准备, 坚定地拓展自己的技术面, 才能让自己拥有超强的竞争力, 为未来的自己赢得选择的权利.')]),_._v(" "),v("h3",{attrs:{id:"微服务架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#微服务架构"}},[_._v("#")]),_._v(" 微服务架构")]),_._v(" "),v("h4",{attrs:{id:"_01-服务注册与发现-ap和cp-你选哪个"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_01-服务注册与发现-ap和cp-你选哪个"}},[_._v("#")]),_._v(" 01-服务注册与发现:AP和CP,你选哪个?")]),_._v(" "),v("p",[_._v("本节来聊一聊微服务架构下的"),v("strong",[_._v("服务注册与发现")]),_._v(".")]),_._v(" "),v("p",[_._v("服务注册与发现在微服务架构中处于一个非常核心的地位, 也是面试中的常见问题. 不过因为微服务架构大行其道, 现在大家多少都能回答出来一些服务注册与发现的内容, 也因此不容易在面试中刷出亮点, 拉开和其他面试者的差距.")]),_._v(" "),v("p",[_._v("所以这一节课就要深入剖析服务注册与发现, "),v("strong",[_._v("学习服务注册与发现的基本模型, 然后在服务端崩溃检测, 客户端容错和注册中心选型三个角度找到高可用微服务架构的亮点")]),_._v(".")]),_._v(" "),v("p",[_._v("那么先来看看服务注册与发现的基本模型.")]),_._v(" "),v("h5",{attrs:{id:"前置知识"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[_._v("为什么会需要服务注册与发现呢? 设想这样一个场景, 你的服务部署在不同的机房, 不同的机器上, 监听不同的端口. 现在你的客户端收到了一个请求, 要发送给服务端, 那么你的"),v("strong",[_._v("客户端怎么知道哪些服务端能够处理这个请求呢")]),_._v("?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/be4c280fcdb6d64cfd5fd2649cfd0990-20231223175001-znqerlz.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("举一个例子, 你去一个陌生的城市出差, 下班了想去吃个火锅, 还得是重庆火锅. 那么你怎么知道这个城市哪里有重庆火锅?")]),_._v(" "),v("p",[_._v("你可能会说, 我在 App 里面搜一下. 那么 App 又怎么知道这里有一家重庆火锅店呢? 你继续说, 这肯定是"),v("strong",[_._v("商家去这个 App 注册过了")]),_._v("呀! 对, 服务注册与发现模型就是这样. 你扮演了客户端的角色, 火锅店扮演了服务端的角色, 而 App 则是扮演了注册中心的角色.")]),_._v(" "),v("p",[_._v("那现在就容易理解基本的服务注册与发现模型了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3dc0cb7a9cb57a19526d305614967a88-20231223175001-8s5a298.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("可以看一下这张图, 要牢牢记住这张图还有里面的具体步骤.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("服务端启动的时候, 需要往注册中心里注册自身的信息, 主要是定位信息")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("注册成功之后, 注册中心和服务端要保持心跳")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("客户端第一次发起对某个服务的调用之前, 要先找注册中心获得所有可用服务节点列表, 随后客户端会在本地缓存每个服务对应的可用节点列表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("客户端和注册中心要保持心跳和数据同步, 后续服务端有任何变动, 注册中心都会通知客户端, 客户端会更新本地的可用节点列表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("客户端发送请求")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("服务端返回响应")]),_._v(".")])]),_._v(" "),v("p",[_._v('上面的这个步骤可以看作是一个 "正向" 的步骤, 而对应的反向步骤则是指服务端下线的过程.')]),_._v(" "),v("p",[_._v("还是用前面的例子来描述, 一家门店准备关张不再营业了, 那么它需要做一些什么? 显然它需要告诉 App 自己不再营业了, 那么你在平台上也就再也搜索不到它了.")]),_._v(" "),v("p",[_._v("所以, 服务端"),v("strong",[_._v("下线")]),_._v("的过程可以总结为 4 步.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("服务端通知注册中心自己准备下线了")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("注册中心通知客户端某个服务端下线了")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("客户端收到通知之后, 新来的请求就不会再给该服务端发过去")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("服务端等待一段时间之后, 暂停服务并下线")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4f0c79c6e93e9c9f0cd5182218bc10e5-20231223175001-ocke0mo.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("需要注意的是, "),v("strong",[_._v("服务端必须要等待一段时间才能下线. 因为从它通知注册中心自己要下线, 到客户端收到通知, 是有一段延时的, 这段延时就是服务端要等待的最小时间")]),_._v(".")]),_._v(" "),v("p",[_._v("如果你觉得这些步骤很复杂, 那么可以教你一个小技巧. 你可以把整个模型看作是"),v("strong",[_._v("三角形")]),_._v(", 三个顶点分别是"),v("strong",[_._v("客户端, 注册中心和服务端")]),_._v(". 三角形的三条边分别是客户端-注册中心, 注册中心-服务端, 客户端-服务端. 而"),v("mark",[v("strong",[_._v("后面讨论的高可用方案, 无非就是仔细思考三角形的任何一个顶点, 或者任何一条边出问题了该怎么办")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/28b257dcbab7c5c3bce8a2c6fb7604aa-20231223175001-mq7978y.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 如果你们公司确实是使用了注册中心, 那么要弄清楚一些数据和信息.")]),_._v(" "),v("ul",[v("li",[_._v("用了什么"),v("strong",[_._v("中间件作为注册中心以及该中间件的优缺点")]),_._v('. 确保自己在回答 "你为什么用某个中间价作为注册中心" 的时候, 能够综合这些优缺点来回答.')]),_._v(" "),v("li",[v("strong",[_._v("注册中心的集群规模")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("读写 QPS(每秒查询率)")]),_._v(" .")]),_._v(" "),v("li",[v("strong",[_._v("机器性能")]),_._v(", 如 CPU 和内存大小.")]),_._v(" "),v("li",[_._v("最好准备一个注册中心出故障之后排查和后续优化的案例. 在讨论使用注册中心的注意事项, 或者遇到过什么 Bug 的时候可以用这个案例.")])]),_._v(" "),v("p",[_._v("如果你所在的公司没有采用微服务架构, 那么可以在 ZooKeeper, Nacos 或者 etcd 里面选择一个大概学习一下它们的基本特性. 在面试的时候可以用它们来解释注册中心. 这样就算你没接触过服务注册与发现, 但是你对此也是有相当深入的理解的.")]),_._v(" "),v("p",[_._v("在面试过程中, 可以尝试从这些角度把话题引到服务注册与发现这个主题上.")]),_._v(" "),v("ul",[v("li",[_._v("第一种情况, "),v("strong",[_._v("面试官问到了某一个可以作为注册中心的中间件")]),_._v(". 举例来说, 如果用 ZooKeeper 作为注册中心, 那么如果面试官问到了 ZooKeeper, 可以主动提起你把它作为了注册中心; 如果面试官问了 etcd, 那么可以主动提起 etcd 虽好, 但是你用的是 ZooKeeper. 这个时候面试官很有可能会继续追问你, 为什么最终选择 ZooKeeper 作为注册中心, 这时候说一下它的优缺点就好了.")]),_._v(" "),v("li",[_._v("还有一种情况, "),v("strong",[_._v("面试官问了你微服务高可用的问题")]),_._v(", 那么可以把高可用的服务注册与发现作为保证整个微服务架构高可用的一个环节来叙述.")])]),_._v(" "),v("h5",{attrs:{id:"基本模型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本模型"}},[_._v("#")]),_._v(" 基本模型")]),_._v(" "),v("p",[_._v('一般而言, 在最开始的阶段, 面试官会问你 "你知道服务注册与发现吗?" 或者 "你知道注册中心吗?" 等问题, 其实都是希望你回答'),v("strong",[_._v("服务注册与发现的基本模型")]),_._v(".")]),_._v(" "),v("p",[_._v("那么可以回答前置知识里面的服务上线和服务下线这两个流程的具体步骤, 而后可以简单描述一下你所在公司的注册中心, 也就是罗列一下你准备的那些数据和信息. 基本内容说完之后, 可以先浅刷一个亮点, 关键词是"),v("strong",[_._v("注册数据")]),_._v(".")]),_._v(" "),v("p",[_._v('在说第一个步骤的时候, 我提到 "主要是定位信息". 既然用到了关键词 "主要", 那自然有不那么主要的数据. 非主要数据取决于微服务框架的功能特性. 例如常见的分组功能, 就是依赖于服务端在注册的时候同时注册自己的分组信息.')]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8f249118549d96856dc7068fb919d664-20231223175001-fhbjq62.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以用一个例子来解释, 关键词是"),v("strong",[_._v("分组")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("服务端注册的数据除了定位信息是必需的以外, 剩下需要什么数据都是根据微服务框架本身的功能和业务来设计的. 比如说很多微服务框架支持分组功能, 那么就可以让服务端在注册的时候同时注册自己的分组信息, 比如说当前节点是 VIP 节点. 那么客户端在收到 VIP 请求之后就会把请求发给 VIP 节点.")])]),_._v(" "),v("p",[_._v("这一段说完之后, 要稍微总结一下, 引导面试官追问下去.")]),_._v(" "),v("blockquote",[v("p",[_._v("服务注册与发现的整个模型比较简单, 不过要在实践中做到高可用还是很不容易的.")])]),_._v(" "),v("p",[_._v("至于为什么不容易, 怎么不容易就等着面试官继续问. 而 "),v("strong",[_._v("高可用")]),_._v(" 就是要刷的亮点.")]),_._v(" "),v("h5",{attrs:{id:"高可用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#高可用"}},[_._v("#")]),_._v(" 高可用")]),_._v(" "),v("p",[_._v('不出所料的话, 面试官就可能追问: "服务注册与发现怎么保证高可用呢?", 那么就可以回答三个点, 高可用的服务注册与发现要围绕 '),v("strong",[_._v("注册服务端崩溃检测, 客户端容错和注册中心选型")]),_._v(" 三个方面进行. 接下来一个点一个点地看.")]),_._v(" "),v("h6",{attrs:{id:"服务端崩溃检测"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#服务端崩溃检测"}},[_._v("#")]),_._v(" 服务端崩溃检测")]),_._v(" "),v("p",[_._v("前面在基本模型里面说到在正常情况下, 服务端下线都需要通知注册中心. 那么"),v("strong",[_._v("万一服务端宕机")]),_._v("了呢? 比如说运维大哥不小心一脚把服务器电源线踢掉了, 服务器直接停电了. 在这种情况下, 服务端是没办法通知注册中心的, 注册中心自然也就不会通知客户端. 那么客户端就会继续把请求发送给服务端, 而这些请求显然都会失败.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ee1e78cc51d9f3c5010c2fdf8dced843-20231223175001-h3yac0z.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("因此为了提高可用性, 需要"),v("strong",[_._v("让注册中心尽快发现服务端已经崩溃")]),_._v("了, 而后通知客户端. 所以问题的关键就在于 "),v("mark",[v("strong",[_._v("注册中心怎么判断服务端已经崩溃了")])]),_._v("​ "),v("strong",[_._v(".")])]),_._v(" "),v("p",[_._v("你可能在上面这张图片里注意到了, 服务端崩溃之后注册中心和服务端之间的"),v("strong",[_._v("心跳就无法继续保持")]),_._v("了. 所以你得出一个简单的结论: "),v("strong",[_._v("如果注册中心和服务端之间的心跳断了, 就认为服务端已经崩溃了")]),_._v(".")]),_._v(" "),v("p",[_._v("但如果注册中心和服务端之间的"),v("strong",[_._v("网络出现偶发性的抖动")]),_._v(", 那么心跳也会失败. 此时服务端并没有真的崩溃, 还活得好好的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1d5e31f804a0f70a7f48767e1774cf7e-20231223175001-jovijbt.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("显然, 心跳断了则服务端崩溃的判断并不能成立. 这时候你可能会想到能不能多发几次心跳呢? "),v("strong",[_._v("答案是可以, 但是次数越多, 心跳间隔越长, 注册中心断定服务端已经崩溃的时间就越长")]),_._v(". 而时间越长, 就有越多请求发送给服务端. 万一这个时候服务端真的崩溃了, 这些请求都会失败. 所以这就陷入两难境地了. 要么是误以为服务端崩溃, 要么是误以为服务端还活着.")]),_._v(" "),v("p",[_._v("那么怎么走出这个窘境呢?")]),_._v(" "),v("p",[_._v("一方面, 注册中心在和服务端进行心跳的时候失败了, 就要 "),v("strong",[_._v("立刻通知客户端")]),_._v(" 该服务端"),v("strong",[_._v("已经不可用")]),_._v("了, 那么客户端就"),v("strong",[_._v("不会再发请求过来")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/93bd54dee1ca2a896811c25aae1da285-20231223175001-quoklq2.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("另外一方面,  "),v("strong",[_._v("注册中心还要继续往服务端发心跳")]),_._v(". 如果只是偶发性的心跳失败, 那么"),v("strong",[_._v("注册中心后面心跳是肯定能够连上的, 这时候注册中心再通知客户端这个服务端是可用的")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/77c80fb1519962604eae95357f260a3b-20231223175001-e67296d.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("不过注册中心并不是无限制发心跳直到连接上, 而是发了一段时间之后发现心跳还是失败就不再发了, 这意味着注册中心认定服务端彻底崩溃了. "),v("strong",[_._v("在彻底崩溃的场景下, 注册中心不需要再次通知客户端, 因为在之前注册中心就已经通知过了")]),_._v(".")]),_._v(" "),v("p",[_._v("所以关键词就是 "),v("strong",[_._v("心跳")]),_._v(", 可以这样回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("影响到可用性的另一个关键点是注册中心需要"),v("mark",[_._v("尽快发现服务端宕机")]),_._v(". 在基本模型里面, 如果服务端突然宕机, 那么服务端是来不及通知注册中心的. 所以注册中心需要有一种检测机制, 判断服务端有没有崩溃. 在服务端崩溃的情况下, 要及时通知客户端, 不然客户端就会继续把请求发送到已经崩溃的节点上.")])]),_._v(" "),v("blockquote",[v("p",[_._v("这种检测就是利用"),v("mark",[_._v("心跳")]),_._v("来进行的. 当注册中心发现和服务端的心跳失败了, 那么它就应该认为服务端可能已经崩溃了, 就"),v("mark",[_._v("立刻通知客户端停止使用该服务端")]),_._v(". 但是这种失败可能是偶发性的失败, 比如说因为网络偶尔不稳定造成的. 所以注册中心要"),v("mark",[_._v("继续保持心跳")]),_._v(". 如果几次心跳都失败了, 那么就可以认为服务端已经彻底不可用了. 但是如果心跳再次恢复了, 那么注册中心就要再次告诉客户端这个服务端是可用的.")])]),_._v(" "),v("p",[_._v("回答到这里, 亮点已经有了, 不过还可以继续钓鱼, 稍微升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("实际上, 在所有有心跳机制的分布式系统里面判断节点是否崩溃都是一个棘手的问题. 比如说心跳失败了要不要继续重试, 是立刻重试还是间隔重试, 重试的话试几次?")])]),_._v(" "),v("blockquote",[v("p",[_._v("理论上来说, 在心跳失败之后如果不进行重试就直接判定服务端崩溃, 那么就难以处理偶发性网络不通的问题. 而如果要重试, 比如说在注册中心和服务端的模型里面, 重试三次, 而且重试间隔是十秒钟, 那么注册中心确定服务端崩溃就需要三十秒. 在这三十秒内, 客户端估计有成千上万的请求尝试发到崩溃的服务端, 结果都失败了.")])]),_._v(" "),v("p",[_._v("这时候, 面试官很自然地就会觉得不要搞重试间隔, 而是直接发起连续几次重试, 这时候你就要无情地击碎这种幻想.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果不考虑重试间隔的话, 就难以避开偶发性的失败. 比如说注册中心和服务端之间网络抖动, 那么第一次心跳失败之后, 立刻重试多半也是失败的, 因为此时网络很可能还是不稳定.")])]),_._v(" "),v("blockquote",[v("p",[_._v("所以比较好的策略是立刻重试几次, 如果都失败了就再间隔一段时间继续重试. 所有的重试机制实际上也是要谨慎考虑重试次数和重试间隔的, 确保在业务可以接受的范围内重试成功. 不过再怎么样, 从服务端崩溃到客户端知道, 中间总是存在一个时间误差的, 这时候就需要客户端来做容错了.")])]),_._v(" "),v("p",[_._v("这个回答里面, 最后的一句话, 就是为了引出下面这个亮点: "),v("strong",[_._v("客户端容错")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"客户端容错"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#客户端容错"}},[_._v("#")]),_._v(" 客户端容错")]),_._v(" "),v("p",[_._v("客户端容错是指 "),v("strong",[_._v("尽量在注册中心或者服务端节点出现问题的时候, 依旧保证请求能够发送到正确的服务端节点上")]),_._v(".")]),_._v(" "),v("p",[_._v("在前一个亮点里面, 你已经知道"),v("strong",[_._v("从服务端崩溃到客户端最终知道是有一段延时的")]),_._v(". 在这段延时内, 客户端还是会把请求发送到已经崩溃的服务端节点上.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/eda58e1f3958e182daee3a47e7ecb68c-20231223175001-rk5w7py.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以要紧接着前面刷的亮点继续回答, 关键词是"),v("mark",[v("strong",[_._v("换节点")])]),_._v(", 也就是所谓的 "),v("strong",[_._v("failover")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("客户端容错第一个要考虑的是如果某个服务端节点崩溃了该怎么办. 在服务端节点崩溃之后, 到注册中心发现, 再到客户端收到通知, 是存在一段延时的, 这个延时是能算出来的. "),v("mark",[_._v("在这段延时内, 客户端发送请求给这个服务端节点都会失败")]),_._v(".")])]),_._v(" "),v("blockquote",[v("p",[_._v("这个时候需要"),v("mark",[_._v("客户端来做一些容错")]),_._v(". 一般的策略是客户端在发现调不通之后, 应该尝试换另外一个节点进行重试. 如果客户端上的服务发现组件或者负载均衡器能够根据调用结果来做一些容错的话, 那么它们应该要尝试将这个节点挪出可用节点列表, 在短时间内不要再使用这个节点了. 后面再考虑将这个节点挪回去.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/eac0a80b59d9ea0be7afaeb67df9d38f-20231223175001-x65oh91.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("在上面那段话中留了两个口子. 第一个是延时怎么计算, 非常简单, 从图里面就能看出来.")]),_._v(" "),v("blockquote",[v("p",[_._v("最坏的情况下, 延时等于服务端和注册中心心跳间隔加上注册中心通知客户端的时间. 大多数时候, 注册中心通知客户端都是很快的, 在毫秒级以内. 因此可以认为服务端和注册中心的心跳间隔就是这个延时.")])]),_._v(" "),v("p",[_._v("第二个点就是"),v("strong",[_._v("什么时候再将这个节点挪回可用列表")]),_._v(", 在上图中就是 A 什么时候会被重新放回可用列表.")]),_._v(" "),v("p",[_._v("显然, 如果注册中心最终发现服务端崩溃, 然后通知了客户端, 那么客户端就不用放回去了. "),v("strong",[_._v("等到注册中心发现服务端再次恢复了, 那么注册中心会通知客户端")]),_._v(", 此时客户端更新可用节点列表就可以了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bd662b5087aaec8f7c3b24171ced4eb3-20231223175001-hv43gvs.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("但是有一种情况是"),v("strong",[_._v("需要客户端主动检测的")]),_._v(". 这种情况就是服务端节点还活着, 注册中心也还活着, 唯独 "),v("strong",[_._v("客户端和服务端之间的网络有问题")]),_._v(", 导致客户端调用不通.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1e6f7a380e3572372f3b2a65e565a9c1-20231223175001-7dt32ct.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("在这种情况下, 类似于注册中心和服务端心跳失败, 客户端也要朝着那个疑似崩溃的服务端节点继续发送心跳. 如果心跳成功了, 就将节点放回可用列表. 如果连续几次心跳都没有成功, 那么就不用放回去了, 直接认为这个节点已经崩溃了.")]),_._v(" "),v("p",[_._v("这个分析也适用于客户端和注册中心心跳失败的场景. 很显然在这种情况下, 客户端可以直接使用本地缓存的可用节点列表, 而后如果调不通了则处理方式完全一样. 但是不同的是, 如果客户端长期连不上注册中心, 那么客户端本身应该考虑整个退出.")]),_._v(" "),v("h6",{attrs:{id:"注册中心选型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#注册中心选型"}},[_._v("#")]),_._v(" 注册中心选型")]),_._v(" "),v("p",[_._v("注册中心选型类似于其他中间件选型, 要考虑的因素非常多. 比如说中间件成熟度, 社区活跃度, 性能等因素. 相比之下, "),v("mark",[v("strong",[_._v("注册中心更加关注 CAP 中选 CP 还是选 AP 的问题")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("C: Consistency, 数据一致性")]),_._v(" "),v("p",[_._v("A: Availability, 服务可用性")]),_._v(" "),v("p",[_._v("P: Partition-tolerance, 分区容错性")]),_._v(" "),v("p",[_._v("CAP 理论表示一个分布式系统不可能同时满足数据一致性, 服务可用性和分区容错性这三个基本需求, 最多只能同时满足其中的两个.")])]),_._v(" "),v("p",[_._v("简单来说, "),v("mark",[v("strong",[_._v("选择 CP 就是选了一致性和分区容错性, 而选择 AP 就相当于选了可用性和分区容错性")])]),_._v(".")]),_._v(" "),v("p",[_._v("看上去 P 分区容错性是肯定要选的, 那么剩下的就是选 C(一致性) 还是选 A(可用性) 了. 那么要先理解在注册中心选型里面, 一致性和可用性究竟哪个更加重要? 标准答案是"),v("mark",[v("strong",[_._v("可用性")])]),_._v(", 也就意味着 CP 和 AP 应该选 AP.")]),_._v(" "),v("p",[_._v("前面讨论了客户端容错, 那么显然"),v("strong",[_._v("在选择 AP 的情况下, 客户端就可能拿到错误的可用节点列表")]),_._v(". 如果客户端将请求发到错误的可用节点上, 就会出现错误, 此时客户端自然可以执行容错, 换一个可用节点重试.")]),_._v(" "),v("p",[_._v("所以要抓住关键词 "),v("strong",[_._v("客户端容错")]),_._v(" 进行回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在注册中心选型上, 重要的是 CAP 原理中应该选择 AP, 比如说 Eureka, 又或者 Nacos 启用 AP 模式.")])]),_._v(" "),v("p",[_._v("万一你公司并没有使用 AP 模型的注册中心, 比如说用了 CP 模型的 ZooKeeper, 那么就可以进一步解释, 关键词是 "),v("strong",[_._v("体量小")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我司之所以用 ZooKeeper, 主要是因为体量小, 集群规模也不大, ZooKeeper 虽然不是 AP 的, 但是在这种体量下也够用了. 不过我也尝试在公司内部推动看能否换一个中间件, 比如说用 Nacos 的 AP 模式.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节课的重点内容.")]),_._v(" "),v("p",[_._v("这节主要解决的是服务注册与发现的问题. 我给出了基本的服务注册与发现模型, 然后从服务端崩溃检测, 客户端容错, 注册中心选型三个角度来保证了服务注册与发现的高可用. 其中提到了几个关键词, 分别是 "),v("strong",[_._v("注册数据, 分组, 心跳, 换节点, 客户端容错, 体量小")]),_._v(". 可以从这几个关键词出发, 根据自己的项目经验, 梳理思路.")]),_._v(" "),v("p",[_._v("最后再提醒一下, 如果你觉得服务注册与发现实在难以记忆, 可以 "),v("strong",[_._v("把整个模型想成是一个三角形, 而解决高可用问题的关键就是这个三角形任何一条边出问题了该怎么办")]),_._v(". 非常建议画一画这个三角形, 并且手写一下你能想到的各种容错措施.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bd074d5e639520330b22081e8eba72f1-20231223175001-3d3t3k9.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考 2 个问题.")]),_._v(" "),v("ol",[v("li",[_._v('我在客户端容错里提到这个分析也适用于注册中心崩溃, 你能组织一下语言尝试回答 "如果注册中心崩溃, 你的系统会怎样?" 这个问题吗?')]),_._v(" "),v("li",[_._v("可以再举出一个心跳频率, 心跳重试机制对系统可用性影响的例子吗?")])]),_._v(" "),v("h4",{attrs:{id:"_02-负载均衡-调用结果-缓存机制是怎么影响负载均衡的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_02-负载均衡-调用结果-缓存机制是怎么影响负载均衡的"}},[_._v("#")]),_._v(" 02-负载均衡:调用结果,缓存机制是怎么影响负载均衡的?")]),_._v(" "),v("p",[_._v("今天来聊一聊微服务架构下的负载均衡.")]),_._v(" "),v("p",[_._v("负载均衡在微服务架构里也处于一个核心位置. 一般在准备调用任何服务的时候, 第一个要解决的问题就是"),v("strong",[_._v("负载均衡该怎么做")]),_._v(". 负载均衡在微服务架构的面试中, 也属于必面题目.")]),_._v(" "),v("p",[_._v("可惜的是, 即便都知道负载均衡在面试中是必考点, 但是在每一次面试的时候都还是难以刷出亮点. 大多数的回答都仅仅是简单罗列一下负载均衡的算法, 稍微有些亮点的则是讨论一下不同算法的优缺点. 但是这并不能让你在面试官心里留下深刻印象.")]),_._v(" "),v("p",[_._v("所以今天就来介绍一下负载均衡算法里面一些可以用于面试的微妙细节, 同时给出一个本地缓存和负载均衡结合的案例, 让你在面试的时候刷出亮点. 下面先来介绍微服务架构里面常见的负载均衡算法.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-2"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[_._v("负载均衡, 本质上就是回答一个问题: "),v("strong",[_._v("我该把请求发给哪个服务端")]),_._v("? 理论上来说, 你会希望把请求发给某个能够最快返回响应的客户端.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c81a1b0f95fae9407a280a76fbf589fc-20231223175001-zpbd9d3.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("这里你可能会觉得有些困惑, 因为之前都听过轮询和加权轮询, 随机和加权随机, 哈希和一致性哈希这些负载均衡算法, 但看上去它们"),v("strong",[_._v("并没有试图去判断哪个节点才是最合适的节点")]),_._v(".")]),_._v(" "),v("p",[_._v("确实, 这一类算法也叫做 "),v("strong",[_._v("静态负载均衡算法")]),_._v('. 它们依靠的是统计学上的 "最合适". 也就是说, 如果请求都差不多, 请求数量也足够多, 那么它们能够挑选出比较合适的节点.')]),_._v(" "),v("p",[_._v("还有一类算法, 是 "),v("strong",[_._v("动态负载均衡算法")]),_._v(", 或者说是"),v("strong",[_._v("实时检测负载均衡算法")]),_._v(". 这一类算法依赖于实时判断所有候选节点的状态, 并且从里面挑选出最合适的节点. 这一类算法包含"),v("strong",[_._v("最少连接数, 最少活跃请求数, 最快响应时间等算法")]),_._v(".")]),_._v(" "),v("p",[_._v("接下来一个个看.")]),_._v(" "),v("h6",{attrs:{id:"轮询与加权轮询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#轮询与加权轮询"}},[_._v("#")]),_._v(" 轮询与加权轮询")]),_._v(" "),v("p",[_._v('轮询本身是一个非常简单的算法, 用一句俗话讲, 就是 "排排坐, 分果果". 也就是说, '),v("strong",[_._v("所有的候选节点轮流作为负载均衡的目标节点")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ac0d265b04f1eee5d1f9f9587088c8d2-20231223175001-l5l8blx.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("你可能想到, "),v("strong",[_._v("每个节点的实际处理能力可能并不一样")]),_._v(". 于是就有了一个加权的版本, 就是所谓的加权轮询. 这个算法就不再是节点轮流, 而是"),v("mark",[v("strong",[_._v("根据权重来轮流")])]),_._v(". 比如说, 如果一个节点的权重是另外一个节点的两倍, 那么最终这个节点被选中的次数也会是另外一个节点的两倍.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b8c851f1a60efd5e7e7a902252743644-20231223175001-lxbke7b.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("图中节点 1 的权重是其他两个节点的三倍, 所以相应地被选中的机会也是三倍.")]),_._v(" "),v("p",[_._v("在加权算法里面, 有一个改进叫做"),v("strong",[_._v("平滑的加权轮询算法")]),_._v(". 在图里也可以看出来, 因为服务端节点 1 的权重是别的节点的三倍, 所以如果不做任何措施, 那么会"),v("strong",[_._v("连续三次")]),_._v("将请求发送到同一个节点.")]),_._v(" "),v("p",[_._v("而这个平滑的加权轮询算法就是为了解决这个问题. 每个节点会有两个权重, 初始权重(weight)和当前权重(currrentWeight). 算法的过程稍微有点复杂, 每一次挑选节点都执行这些步骤.")]),_._v(" "),v("ol",[v("li",[_._v("对每一个节点, 执行 currrentWeight = currrentWeight + weight.")]),_._v(" "),v("li",[_._v("挑选最大 currrentWeight 的节点作为目标节点.")]),_._v(" "),v("li",[_._v("将目标节点的 currrentWeight 修改为 currrentWeight= currrentWeight - sum(weight).")])]),_._v(" "),v("p",[_._v("那么简单理解就是, "),v("strong",[_._v("对于一个节点来说, 每次被挑选之后, 它的 currrentWeight 就会下降, 那么下一次就不会选中它")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"随机与加权随机"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#随机与加权随机"}},[_._v("#")]),_._v(" 随机与加权随机")]),_._v(" "),v("p",[_._v("随机可以看作是随便挑选一个作为目标节点, 加权随机则是利用不同的权重来设置选中的概率. 权重越大, 那么被选中的机会也就越大.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a62d17ff294b41b27827e8f31dafffc5-20231223175001-qz717q7.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("可以看到, 轮询算法相比之下可控性更强. 一般来说, "),v("strong",[_._v("在实践中轮询和随机, 加权轮询和加权随机是可以互相替代的")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"哈希与一致性哈希"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#哈希与一致性哈希"}},[_._v("#")]),_._v(" 哈希与一致性哈希")]),_._v(" "),v("p",[_._v("哈希算法比较简单, 一般就是选取请求里面某几个参数来计算一个哈希值, 然后除以节点数量取余. 这个过程几乎和随机一样, 区别就在于随机算法里面用的是随机数, 这里用的是根据参数计算出来的哈希值.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b9be136e06184aee8b8e3a51fdeaa54-20231223175001-58zx61a.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("哈希算法的选取会严重影响负载均衡的效果")]),_._v(". 假如计算哈希值的算法不太好, 就容易导致某几个节点上负载特别高, 而其他节点的负载就比较低. 所以要尽"),v("strong",[_._v("可能保证哈希值计算出来的结果是均匀")]),_._v("的.")]),_._v(" "),v("p",[_._v("相比之下 "),v("mark",[v("strong",[_._v("一致性哈希负载均衡")])]),_._v(" 才算是真正的面试热点.")]),_._v(" "),v("p",[_._v("一致性哈希负载均衡引入了一个哈希环的概念, 服务端节点会落在环的某些位置上. 客户端根据请求参数, 计算一个哈希值. "),v("strong",[_._v("这个哈希值会落在哈希环的某个位置. 从这个位置出发, 顺时针查找, 遇到的第一个服务端节点就是目标节点")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/316ff080931a487161a2c02d87fcd1bf-20231223175001-3wa713a.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("注意, 在一致性哈希负载均衡算法里面, 并不要求服务端节点是均匀分散在哈希环上的. 实际上, 我们是希望所有的节点负载是均衡的, 但是不同节点之间的间隔"),v("strong",[_._v("可以是不均匀")]),_._v("的.")]),_._v(" "),v("p",[_._v("这里用一个比喻来简单描述这个算法. "),v("strong",[_._v("一致性哈希负载均衡算法就像是钟表, 它的过程就有点儿像你的朋友约你吃火锅, 说下一个整点到火锅店集合. 那么看一下现在的时间, 是下午三点四十五分, 那么自然下一个整点就是下午四点了")]),_._v(".")]),_._v(" "),v("p",[_._v("在面试的时候, 如果实在记不住一致性哈希负载均衡算法, 那么可以用这个比喻来向面试官解释一下.")]),_._v(" "),v("h6",{attrs:{id:"最少连接数"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#最少连接数"}},[_._v("#")]),_._v(" 最少连接数")]),_._v(" "),v("p",[_._v("最少连接数基于一个基本假设: 如果一个服务端节点上的连接数越多, 那么这个节点的负载就越高. 因此在做负载均衡的时候就是"),v("strong",[_._v("看一下客户端和各个节点的连接数量, 从中挑选出连接数数量最少的节点")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8393ed56670377a0f281f6cb5b09b982-20231223175001-lnrka1m.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("最少连接数算法的缺陷在于, "),v("strong",[_._v("连接数并不能代表节点的实际负载, 尤其是在连接多路复用的情况下")]),_._v(". 比如这张示意图里, 理论上来说新来的请求就会落到服务端节点 1 上, 而后连接数变成 11. 实际上在连接复用的情况下, 客户端可能连续发 10 个请求到服务端节点 1 上, 才会创建一个新连接.")]),_._v(" "),v("p",[_._v("那么很显然, 在这种情况下, 服务端节点 1 的负载会比其他两个节点高一截.")]),_._v(" "),v("h6",{attrs:{id:"最少活跃数"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#最少活跃数"}},[_._v("#")]),_._v(" 最少活跃数")]),_._v(" "),v("p",[_._v("最少活跃数算法则是用当前活跃请求数来代表服务端节点的负载. "),v("strong",[_._v("所谓的活跃请求, 就是已经接收但是还没有返回的请求. 客户端会维持一个自己发过去但是还没返回的请求数量, 然后每次挑选活跃请求最少的那个服务端节点")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fc8d4d259060363099217032e462cd18-20231223175001-mc8c7al.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("类似地, "),v("strong",[_._v("活跃请求数量也不能真正代表服务端节点的负载")]),_._v(". 比如说图中, 服务端节点 1 虽然只有 10 个请求, 但是万一这 10 个请求都是大请求, 例如大商家, 大买家或者千万粉丝 UP 主的请求, 那么服务端节点 1 的负载也会显著高于其他两个节点.")]),_._v(" "),v("h6",{attrs:{id:"最快响应时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#最快响应时间"}},[_._v("#")]),_._v(" 最快响应时间")]),_._v(" "),v("p",[v("strong",[_._v("最快响应时间算法就是客户端维持每个节点的响应时间, 而后每次挑选响应时间最短的")]),_._v(".")]),_._v(" "),v("p",[_._v("相比前两个算法, 最快响应时间算法则要好很多, 它用的是"),v("mark",[v("strong",[_._v("响应时间来代表服务端节点的负载")])]),_._v(". 响应时间和前面的两个指标比起来, 是一种"),v("strong",[_._v("综合性")]),_._v("的指标, 所以用响应时间来代表服务端节点负载要更加准确.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6fe95cc36d7949159a128901f59fcyy9-20231223175001-2jk9vy1.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("这里的响应时间, 可以是平均响应时间, 也可以是 99 线之类的, 选择什么其实效果并不会相差很多.")]),_._v(" "),v("p",[_._v("但是在实现上, 要注意"),v("strong",[_._v("响应时间的时效性")]),_._v(". 一般来说统计响应时间时应该只用近期请求的响应时间, 并且越近的响应时间, 权重应该越高. 换句话说, "),v("strong",[_._v("就是采集的响应时间效用应该随着时间衰减")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"小结一下"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#小结一下"}},[_._v("#")]),_._v(" 小结一下")]),_._v(" "),v("p",[_._v("最少连接数, 最少活跃请求数和最快响应时间, 都可以看作是选择了单一的指标来代表一个节点的负载.")]),_._v(" "),v("p",[_._v("那么你在实际工作中也可以利用这个思路来设计自己的负载均衡算法. 比如说在 CPU 密集型的应用里面, 可以设计一个负载均衡算法, 每次筛选 CPU 负载最低的节点. 难点则是需要考虑 "),v("strong",[_._v("怎么采集到所有服务端节点的 CPU 负载数据")]),_._v(".")]),_._v(" "),v("p",[_._v("这三个算法还有一个问题, 就是它们都是客户端来采集数据的. "),v("strong",[_._v("那么不同的客户端就可能采集到不同的数据")]),_._v(". 如图所示, 因为客户端 1 本身并不知道客户端 2 上还有 30 个连接, 因此它选择了服务端节点 1. 而实际上它应该选择服务端节点 2.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a297920cde1278deb9f8f8b72439bf72-20231223175001-9pklya3.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("那怎么解决这两个问题呢?")]),_._v(" "),v("p",[_._v("答案是"),v("strong",[_._v("让服务端上报指标, 而不是客户端采集")]),_._v(". 总体上有两种思路.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("第一种思路是服务端在返回响应的时候顺便把服务端上的一些信息一并返回")]),_._v(". 这种思路需要微服务框架支持从服务端往客户端回传链路元数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8e08986652ea01f0e42c81d2518ee472-20231223175001-vi4rgvj.png",alt:""}}),_._v("​")]),_._v(" "),v("ul",[v("li",[_._v("第二种思路是"),v("strong",[_._v("从观测平台上查询")]),_._v(". 例如通过查询 Prometheus 来获得各种指标数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6cd2c61a17c4146b8009ec7518ce58b5-20231223175001-lhcgetl.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("不过目前业界"),v("strong",[_._v("很少用")]),_._v("这种复杂的负载均衡算法, 也因此几乎所有的微服务框架都没有服务端上报指标到客户端的机制.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-2"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("首先前面提到的这些算法都要记下来. 尤其要对这几个算法格外上心一些.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("轮询和加权轮询")]),_._v(": 对应的平滑加权轮询算是一个小亮点.")]),_._v(" "),v("li",[v("strong",[_._v("一致性哈希负载均衡")]),_._v(": 这个可以结合 Redis 之类的使用了一致性哈希算法的中间件一起理解.")]),_._v(" "),v("li",[v("strong",[_._v("最快响应时间算法")]),_._v(": 这个算法体现了"),v("strong",[_._v("采集指标随着时间准确性衰减的特性")]),_._v(", 后面在服务治理的部分会再次接触到类似的东西.")])]),_._v(" "),v("p",[_._v("对这些算法的简单分析也要记住, 尤其是在小结里提到的 "),v("strong",[_._v("采集指标")]),_._v(" 的问题. 然后在准备项目经验的时候要搞清楚公司以下几种情况.")]),_._v(" "),v("ul",[v("li",[_._v("如果公司有 Nginx 之类的网关, 或者微服务网关, 那么用的是什么负载均衡算法?")]),_._v(" "),v("li",[_._v("如果公司用"),v("strong",[_._v("客户端负载均衡")]),_._v("的话, 用的是什么负载均衡算法?")]),_._v(" "),v("li",[_._v("有没有出过和负载均衡相关的事故, 如果有, 那么是什么原因导致的, 怎么解决的这个事故, 它体现了负载均衡算法的什么缺陷?")])]),_._v(" "),v("p",[_._v("另外, 还可以尝试根据业务设计一个独一无二的负载均衡算法. 即便用的是最简单的轮询之类的算法, 也不用担心. 因为目前大规模应用的就是这种简单的算法, 那些花里胡哨的算法在面试和汇报晋升的时候很有用, 但是实际上落地的并不多.")]),_._v(" "),v("p",[_._v("如果现在有足够的时间, 那么前面这些算法都可以试着实现一下. 尤其建议在 gRPC 里接入一下自己写的算法, 做个小实验. 一方面是加深理解, 另一方面是防止面试官要求你现场写算法实现.")]),_._v(" "),v("p",[_._v("小结中讨论的内容可以作为一个亮点, 但是稍微有点理论化, 所以还需要掌握一些实践方面的答题亮点.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("怎么根据调用结果来调整权重, 从而影响负载均衡的效果")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("怎么利用一致性哈希负载均衡算法, 来提高本地缓存命中率, 缓解数据不一致性问题")]),_._v("?")])]),_._v(" "),v("p",[_._v("这两个问题可以从后面找找答案.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v('正常来说, 面试官会先问你 "是否了解负载均衡", "知道哪些负载均衡算法" 之类的问题, 那么就可以列举前置知识里面提到的算法, 然后要结合自己公司的实际情况, 说明自己用的是什么负载均衡算法.')]),_._v(" "),v("p",[_._v("如果你准备了一个负载均衡引发的线上事故案例, 那么一定要记得展开聊一聊. 这里用轮询作为例子, 可以参考这个例子来准备.")]),_._v(" "),v("p",[_._v("首先在回答里面要先描述各种基本算法以及简要分析, 然后再加上一句总结引导.")]),_._v(" "),v("blockquote",[v("p",[_._v("一般来说, 加权类的算法都要考虑权重的设置和调整.")])]),_._v(" "),v("p",[_._v("紧接着你开始说你们公司的负载均衡算法, 关键词是"),v("strong",[_._v("大请求")]),_._v(", 你可以这么说.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司用的是轮询来作为负载均衡. 不过因为轮询没有实际查询服务端节点的负载, 所以难免会出现偶发性的负载不均衡的问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("比如说我们之前发现线上的响应时间总体来说是非常均匀的, 但是每隔一段时间就会出现响应时间特别慢的情况. 而且时间间隔是不固定的, 慢的程度也不一样, 所以就很奇怪. 后来经过排查之后, 发现是因为当一个大请求落到一个节点的时候, 它会占据大量的内存和 CPU. 如果这时候再有请求打到同一个节点上, 这部分请求的响应时间就会非常慢.")])]),_._v(" "),v("p",[_._v("在这个回答里用的这个例子说明了"),v("mark",[v("strong",[_._v("所有负载均衡算法都有的缺点, 即没有考虑请求本身")])]),_._v(". 一个大商家拉当日成交订单数据, 和一个长尾商家拉当日成交订单数据, 能是一回事吗? 显然不是.")]),_._v(" "),v("p",[_._v("在这个例子里面, 并没有说怎么解决问题, 其实这也是在引导面试官进一步问. 如果他问如何解决, 那么可以从 "),v("strong",[_._v("业务拆分")]),_._v(" 或者 "),v("strong",[_._v("隔离")]),_._v(" 的角度回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("(业务拆分)这个大请求其实是一个大的批量请求. 后来限制一批最多只能取 100 个就解决了这个问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("(隔离角度)我们稍微魔改了一下负载均衡算法, 不再是单纯的轮询了. 我们每天计算一批大客户, 这部分大客户的请求会在负载均衡里面被打到专门的几个节点上. 虽然大客户的请求依旧很慢, 但是至少别的客户不会再受到他们的影响了.")])]),_._v(" "),v("p",[_._v("隔离角度的回答相比之下会更加高级一点, 因为可以借此机会将这个回答引到服务治理中的隔离措施这个话题上. 同时, 这个角度还体现了一个魔改负载均衡的创新点. 但如果你不太熟悉服务治理类的话题, 那么用业务拆分的角度来回答会更加合适.")]),_._v(" "),v("p",[_._v("这时候你可以补上一句总结, 升华一下回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("负载均衡算法有些时候用得好, 是能够解决一些技术问题的, 比如说缓存.")])]),_._v(" "),v("p",[_._v('这里你应该能够看出来, 不论是刚刚说的 "加权类的算法都要考虑权重设置和调整" 还是这个 "能够解决一些技术问题的", 都是在钓鱼. 这两个点也就是你能彻底拉开和其他候选者差距的亮点.')]),_._v(" "),v("h6",{attrs:{id:"调用结果对负载均衡的影响"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#调用结果对负载均衡的影响"}},[_._v("#")]),_._v(" 调用结果对负载均衡的影响")]),_._v(" "),v("p",[_._v("前面提到过在负载均衡里面有对应的加权版本, 比如说轮询有对应的加权轮询版本, "),v("strong",[_._v("随机也有对应的加权随机版本")]),_._v(".")]),_._v(" "),v("p",[_._v("而实际上在工作中可以考虑根据调用结果来动态调整这个权重. 所以如果面试官问怎么设置权重或者怎么调整权重, 抓住关键词"),v("mark",[v("strong",[_._v("成加败减")])]),_._v("就可以了.")]),_._v(" "),v("blockquote",[v("p",[_._v("权重代表节点的处理能力, 当然在一些场景下它也代表节点的可用性或者重要性. 所以权重根据节点的实际情况来设置值就可以. 权重的要点在于体现不同节点的差异性, 它的绝对值并不重要.")])]),_._v(" "),v("blockquote",[v("p",[_._v("一般来说为了进一步提高可用性, "),v("mark",[_._v("加权类的负载均衡算法都会考虑根据调用结果来动态调整权重. 如果调用成功了, 那么就增加权重; 如果调用失败了, 那么就减少权重")]),_._v(".")])]),_._v(" "),v("blockquote",[v("p",[_._v("这里调用成功与否是一种非业务相关的概念, 也就是说即便拿到了一个失败的响应, 但是本身也算是调用成功了. 调用失败了大多数时候是指网络错误, 超时等. 而在实际落地的时候, 也可以考虑如果是网络引起的失败, 那么权重下调就多一点, 因为这一类的错误意味着问题更加严重. 如果是超时这种, 那么权重就下调少一点, 因为这种错误是比较容易恢复过来的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/77f5ace88c1184bc8b199eyycf26e615-20231223175001-6yu15m5.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("这里稍微解释一下为什么说绝对值不重要. 比如说一个方案是 A 的权重是 100, B 的权重是 200, 与另一个方案 A 的权重是 1000, 而 B 的权重是 2000, 负载均衡的效果是一样的. 但是在调整权重的时候要按"),v("strong",[_._v("比例来调")]),_._v(". 比如说前一个方案调整权重可能每次调 10, 而后一个方案就要每次调 100.")]),_._v(" "),v("p",[_._v("回答到这里, 还有一个很多开发者都意识不到以至于经常有人踩坑的点: "),v("strong",[_._v("权重的调整要设置好上限和下限")]),_._v(". 那么你可以揭开这个业界经常忽略的问题, 关键词是 "),v("strong",[_._v("上下限")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("调整权重的算法都要考虑安全问题, 即权重的调整应该有上限和下限. 比如说一般下限不能为 0, 因为一个节点的权重为 0 的话, 它可能永远也不会被选中, 又或者和 0 的数学运算会出现问题导致负载均衡失败. 上限一般不超过初始权重的几倍, 比如说两倍或者三倍, 防止该节点一直被连续选中.")])]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 如果在实现的时候使用了 uint 或者 Int8 之类的数字, 还要进一步考虑溢出的问题. 之前挺多公司因为没有控制上下限而引起了线上故障.")])]),_._v(" "),v("p",[_._v("这里你如果对服务注册与发现烂熟于心, 那么就可以尝试将话题引导到服务注册与发现中, 关键词是"),v("strong",[_._v("可用性.")])]),_._v(" "),v("blockquote",[v("p",[_._v("这种根据调用结果来调整权重的方式, 有点类似于在服务中将暂时调用不通的节点挪出可用节点列表, 本质上都是为了进一步提高系统的可用性.")])]),_._v(" "),v("h6",{attrs:{id:"哈希一致性结合本地缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#哈希一致性结合本地缓存"}},[_._v("#")]),_._v(" 哈希一致性结合本地缓存")]),_._v(" "),v("p",[_._v("这算是一个微创新的方案. 正常情况下, 如果使用本地缓存, 那么同一个 key 对应的请求, 可能会被打到不同的节点上. 这就会造成两个问题, 一个是严重的缓存未命中, 一个是不同节点都要缓存同样的数据, 导致内存浪费和极其严重的数据一致性问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f821d3fac5c7249yy5f9ebe13b5433cb-20231223175001-yldi7tc.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以在这种情况下, 一个很自然的想法就是能不能把类似的请求都让同一个节点来处理. 比如说对某个用户数据的请求都打到同一个节点上.")]),_._v(" "),v("p",[_._v("显然适合的负载均衡算法就两个: "),v("mark",[v("strong",[_._v("哈希或者一致性哈希")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2a8c6ec2c66dd170dbaea845cea0ba83-20231223175001-be5dobn.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("如果考虑节点可能上线, 下线的情况, 那么一致性哈希负载均衡就是最优选择")]),_._v(". 所以可以先简单介绍一下方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("在性能非常苛刻的时候会考虑使用本地缓存. 但是使用本地缓存的数据一致性问题会非常严重, 这样可以尝试将一致性哈希负载均衡算法和本地缓存结合在一起, 以提高缓存命中率, 并且降低本地缓存的总体内存消耗. 比如说针对用户的本地缓存, 可以使用用户 ID 来计算哈希值, 那么可以确保同一个用户的本地缓存必然在同一个节点上. 不过即便是采用了一致性哈希负载均衡算法, 依旧不能彻底解决数据一致性的问题, 只能缓解一下.")])]),_._v(" "),v("p",[_._v("最后一句就是留下的鱼饵. 如果面试官追问"),v("strong",[_._v("为什么不能彻底解决")]),_._v(", 那么就可以这样回答, 关键词是"),v("strong",[_._v("应用发布")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("当整个集群的节点数量发生变化的时候, 就难免会导致同样的数据缓存在多个节点上.")])]),_._v(" "),v("blockquote",[v("p",[_._v("例如在用户这个例子中, 假如最开始有一个请求需要 user_id 为 1 的昵称小明, 这个请求最开始会命中老节点. 但是此时还没有查询到数据. 紧接着扩容. 此时又来了一个请求, 那么它会被导去新节点. 这一个请求会将 user_id 为 1 的昵称改为小刚. 如果这时候第一个请求从老节点的缓存上读出了数据, 那么它拿到的就还是老的数据. 而应用发布是引起节点数量变化最常见的原因. 毕竟应用发布可以看作先下线一个节点, 再上线一个节点.")])]),_._v(" "),v("blockquote",[v("p",[_._v("不过同时也可以看出来, 在本地缓存结合了一致性哈希负载均衡算法之后数据一致性的问题已经被大大缓解了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f0f41de133fa3c076a9095db181a32f8-20231223175001-724yt31.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("在这个方案中, 你已经主动聊起了缓存和数据一致性的问题, 那么面试官很可能就把话题转到缓存和一致性相关的问题. 不过也不用慌, 在后面的内容里面会告诉你如何应对.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-2"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节主要解决的是负载均衡的问题. 我给出了负载均衡的基本算法, 面试的思路和亮点方案. 其中提到几个关键词, 分别是 "),v("strong",[_._v("大请求, 成加败减, 上下限, 可用性, 应用发布")]),_._v(". 可以从这几个关键词出发, 加上自身真实的案例, 梳理自己的面试思路.")]),_._v(" "),v("p",[_._v("最后整理了这一节内容的思维导图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/34078573e4f9fccd22f2fd6598a0a3a0-20231223175001-xxpde6x.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-2"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("ul",[v("li",[_._v("如果单纯从算法效果看, 随机和轮询其实差不多. 而现在据我观察, 使用轮询要比使用随机多得多, 你觉得这是为什么?")]),_._v(" "),v("li",[_._v("在基本算法总结里面我用最少连接数算法举了一个反面例子, 但是同样的算法用在网关负载均衡上, 就没有类似的问题, 为什么?")])]),_._v(" "),v("h4",{attrs:{id:"_03-熔断-熔断-恢复-熔断-恢复-抖来抖去怎么办"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_03-熔断-熔断-恢复-熔断-恢复-抖来抖去怎么办"}},[_._v("#")]),_._v(" 03-熔断:熔断-恢复-熔断-恢复,抖来抖去怎么办?")]),_._v(" "),v("p",[_._v("这节讨论一个新的主题: 熔断.")]),_._v(" "),v("p",[_._v("在微服务架构里面, "),v("strong",[_._v("熔断-限流-降级")]),_._v("一般是连在一起讨论的, 熔断作为微服务架构可用性保障的重要手段之一, 是必须要掌握的, 而且要能够说清楚自己在实践中是怎么利用熔断来提高系统的可用性的.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-3"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[v("strong",[_._v("熔断在微服务架构里面是指当微服务本身出现问题的时候, 它会拒绝新的请求, 直到微服务恢复")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5cd51264668d564aa59b7c4630e3913f-20231223175001-h55fz14.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("图中服务端明明返回了错误的响应, 怎么还说熔断提高了系统的可用性呢?")]),_._v(" "),v("p",[_._v("答案就是"),v("strong",[_._v("熔断可以给服务端恢复的机会")]),_._v(". 试想这么一个场景, CPU 使用率已经 100% 了, 服务端因此触发了熔断. 那么拒绝了新来的请求之后, 服务端的 CPU 使用率就会在一段时间内降到 100% 以内.")]),_._v(" "),v("p",[_._v("回到熔断的基本定义上来, 可以提炼出两个点进一步讨论.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("怎么判断微服务出现了问题")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("怎么知道微服务恢复了")]),_._v("?")])]),_._v(" "),v("p",[_._v("接下来要讨论的亮点也是围绕这两个方面来进行的.")]),_._v(" "),v("h6",{attrs:{id:"判定服务的健康状态"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#判定服务的健康状态"}},[_._v("#")]),_._v(" 判定服务的健康状态")]),_._v(" "),v("p",[_._v("第一个问题, 判断微服务是否出现了问题, 它有点儿像在负载均衡里面讨论的动态算法. 本质上也是要求"),v("strong",[_._v("根据自己的业务来选择一些指标, 代表这个服务器的健康程度")]),_._v(". 比如说一般可以考虑使用响应时间, 错误率.")]),_._v(" "),v("p",[_._v("不管选择什么指标, 都要考虑两个因素: "),v("strong",[_._v("一是阈值如何选择; 二是超过阈值之后, 要不要持续一段时间才触发熔断")]),_._v(".")]),_._v(" "),v("p",[_._v("比如把响应时间作为指标, 那么响应时间超过多少应该触发熔断呢? 这是"),v("strong",[_._v("根据业务来决定")]),_._v("的. 比如说如果业务对响应时间的要求是在 1s 以内, 那么阈值就可以设定在 1s, 或者稍高一点, 留点容错的余地也可以.")]),_._v(" "),v("p",[_._v("那么如果产品经理没跟你说这个业务对响应时间的要求, 就可以根据它的整体响应时间设定一个阈值, 原则上"),v("strong",[_._v("阈值应该明显超过正常响应时间")]),_._v(". 比如经过一段时间的观测之后, 发现这个服务的 99 线是 1s, 那么可以考虑将熔断阈值设定为 1.2s.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4a67fbc83dd9ab5743b103b4d6d7f016-20231223175001-cb6wm0x.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么是不是响应时间一旦超过了阈值就立刻熔断呢? 一般也不是, 而是"),v("strong",[_._v("要求响应时间超过一段时间之后才触发熔断")]),_._v(". 这主要是出于两个考虑, 一个是响应时间可能是偶发性地突然增长; 另外一个则是防止抖动. 防止抖动这个问题后面会进一步讨论.")]),_._v(" "),v("p",[_._v('那么这个 "一段时间" 究竟有多长, 很大程度上就依赖个人经验了. 如果时间过短, 可能会频繁触发熔断, 然后又恢复, 再熔断, 再恢复...反过来, 如果时间过长, 那就可能会导致该触发熔断的时候迟迟没有触发.')]),_._v(" "),v("p",[_._v("可以"),v("strong",[_._v("根据经验来设定一个值, 比如说三十秒或者一分钟")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/eee791ac63348392cd1ea51d433258c9-20231223175001-56h5y11.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然最简单的做法就是超过阈值就直接触发熔断, 但是采取这种策略就要更加小心抖动问题.")]),_._v(" "),v("h6",{attrs:{id:"服务恢复正常"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#服务恢复正常"}},[_._v("#")]),_._v(" 服务恢复正常")]),_._v(" "),v("p",[_._v("第二个问题, 一个服务熔断之后要考虑恢复. 比如说如果判断一个服务响应时间过长, 进入了熔断状态. 那么十分钟过后, 已接收的请求已经被处理完了, 即服务恢复正常了, 那么它就要退出熔断状态, 继续接收新请求.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a7c20f51242185d023a304e502a0012e-20231223175001-5e4f57m.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此在触发熔断之后, 就要"),v("strong",[_._v("考虑检测服务是否已经恢复正常")]),_._v(". 很可惜, 这方面微服务框架都做得比较差. "),v("strong",[_._v("大多数情况下就是触发熔断之后保持一段时间")]),_._v(", 比如说一分钟, 一分钟之后就认为服务已经恢复正常, 继续处理新请求.")]),_._v(" "),v("p",[_._v("不过这里就涉及前面多次提到的抖动问题了. 所谓"),v("strong",[_._v("抖动就是服务频繁地在正常-熔断两个状态之间切换")]),_._v(".")]),_._v(" "),v("p",[_._v('引起抖动的原因是多样的, 比如说前面提到的一旦超过阈值就进入熔断状态, 或者这里说的恢复策略不当也会引起抖动. 再比如刚刚提到的 "一分钟后就认为服务已经恢复正常, 继续处理新请求" 就容易引发抖动问题.')]),_._v(" "),v("p",[_._v("试想一下, 如果本身熔断是高并发引起的. 那么在一分钟后, 并发依旧很高, 这时一旦直接恢复正常, 然后高并发的流量打过来, 服务是不是又会触发熔断?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73be149c40be65f2e66d4bbde0d492df-20231223175001-d4dm6ni.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而要解决这个抖动问题, 就需要"),v("strong",[_._v("在恢复之后控制住流量")]),_._v(". 比如说按照 10%, 20%, 30%...逐步递增, 而不是立刻恢复 100% 的流量.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/14a54365c9739b664fa35789434a131a-20231223175001-c1ss1qh.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("显然你能够看出来这种做法还是不够好. 因为在这种逐步放开流量的措施下, 依旧有请求因为熔断不会被处理. 那么一个自然的想法就是, "),v("strong",[_._v("能不能让客户端来控制这个流量")]),_._v("? 简单来说就是服务端触发熔断之后, "),v("strong",[_._v("客户端就直接不再请求这个节点了, 而是换一个节点")]),_._v(". 等到恢复了之后, 客户端再逐步对这个节点放开流量.")]),_._v(" "),v("p",[_._v("当然可以, 这也是下面给出的亮点方案.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-3"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("这些就是关于熔断要了解的基础知识, 不过如果想要彻底掌握, 还需要把这些知识点和实际工作联系在一起. 所以建议在面试之前, 要弄清楚所在的公司"),v("strong",[_._v("有没有用熔断来治理微服务")]),_._v(". 如果有, 那么需要进一步弄清楚下面这些情况.")]),_._v(" "),v("ol",[v("li",[_._v("你们公司是"),v("strong",[_._v("怎么判断微服务出现故障的")]),_._v("? 比如说错误率, 响应时间等等.")]),_._v(" "),v("li",[_._v("你们公司是"),v("strong",[_._v("怎么判断微服务已经从故障中恢复过来的")]),_._v("?")]),_._v(" "),v("li",[_._v("在"),v("strong",[_._v("判断微服务已经恢复过来之后, 有没有采取什么措施来防止抖动的问题")]),_._v("?")])]),_._v(" "),v("p",[_._v("关于熔断最佳的面试策略是把它作为你构建一个高可用微服务架构的一环. 例如在介绍某一个微服务项目的时候可以这样说.")]),_._v(" "),v("blockquote",[v("p",[_._v("这是一个高可用的微服务系统, 为了保证它的可用性, 我采取了限流, 降级, 熔断等措施.")])]),_._v(" "),v("p",[_._v("此外, 如果面试官问到"),v("strong",[_._v("服务治理以及提高系统可用性的方法之类")]),_._v("的问题, 也可以用熔断来回答. 又或者面试官问到了限流或者降级, 那就可以尝试把话题引到熔断上面. 此外, 如果面试官问到"),v("strong",[_._v("某个服务崩溃了怎么办")]),_._v("? 这个问题相当于是在问"),v("strong",[_._v("怎么提高可用性防止服务崩溃")]),_._v(", 以及万一服务真崩溃了也要有措施防止拖累别的服务, 那么熔断就是一个可用的手段.")]),_._v(" "),v("p",[_._v("在学完这节课的内容之后, 就可以尝试在公司内部落地一下熔断, 并且可以试试亮点方案, 来加深印象以及对细节的把控.")]),_._v(" "),v("h5",{attrs:{id:"基本思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v('当面试官问 "'),v("strong",[_._v("你有没有用过熔断")]),_._v('" 或者 "'),v("strong",[_._v("怎么保障微服务可用性")]),_._v('" 的时候, 就可以介绍你使用的熔断. 但是要根据前置知识里面的提示, 在面试的时候要'),v("strong",[_._v("说清楚什么时候判定服务需要触发熔断, 为什么选用这个指标")]),_._v(".")]),_._v(" "),v("p",[_._v("假如准备用 "),v("mark",[v("strong",[_._v("响应时间")])]),_._v(" 来作为指标, 那么可以这么回答, 关键词是 "),v("mark",[v("strong",[_._v("持续超过阈值")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("为了保障微服务的可用性, 我在我的核心服务里面接入了熔断. 针对不同的服务, 设计了不同的微服务熔断策略.")])]),_._v(" "),v("blockquote",[v("p",[_._v("比如说最简单的熔断策略就是根据响应时间来进行. 当响应时间超过阈值一段时间之后就会触发熔断. 我一般会根据业务情况来选择这个阈值, 例如, 如果产品经理要求响应时间是1s, 那么会把阈值设定在 1.2s. 如果响应时间超过 1.2s, 并且持续三十秒, 就会触发熔断. 在触发熔断的情况下, 新请求会被拒绝, 而已有的请求还是会被继续处理, 直到服务恢复正常.")])]),_._v(" "),v("p",[_._v("这里面试官就可能有很多种问法, 但是前置知识里面都讨论到了. 虽然他的问题可能千奇百怪, 不过万变不离这几问.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("这阈值还可以怎么确定")]),_._v("? 那就回答还可以根据观测到的响应时间数据来确定.")]),_._v(" "),v("li",[v("strong",[_._v("这个持续三十秒是如何计算出来的")]),_._v("? 这个问题其实可以坦白回答是基于个人经验, 然后解释一下过长或者过短的弊端就可以了.")]),_._v(" "),v("li",[v("strong",[_._v("为什么多了0.2s")]),_._v("? 那么可以解释是留了余地, 防止偶发性的响应时间变长的情况.")]),_._v(" "),v("li",[v("strong",[_._v("怎么判断服务已经恢复正常了")]),_._v("? 那么可以回答等待一段固定的时间, 然后尝试逐渐放开流量.")])]),_._v(" "),v("p",[_._v("如果在实践中根据自己的业务特征选用了一些比较罕见的指标, 或者设计的触发熔断的条件比较有特色, 那么也可以用自己的实际方案.")]),_._v(" "),v("p",[_._v("这里给你另外一个微创新的方案, 关键词是 "),v("mark",[v("strong",[_._v("缓存崩溃")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我还设计过一个很有趣的熔断方案. 我的一个接口并发很高, 对缓存的依赖度非常严重. 所以我的熔断策略是要是缓存不可用, 比如说 Redis 崩溃了, 那么我就会触发熔断. 这里如果不熔断的话, 请求会因为 Redis 崩溃而全部落到 MySQL 上, 基本上会压垮 MySQL.")])]),_._v(" "),v("blockquote",[v("p",[_._v("在触发熔断之后, 我会额外开启一个线程(如果是 Go 就换成 Goroutine)持续不断地 ping Redis. 如果 Redis 恢复了, 那么就会退出熔断状态, 新来的请求就不会被拒绝了.")])]),_._v(" "),v("p",[_._v("这里用 Redis 来作为例子, 可以将 Redis 替换为业务上任何一个关键的第三方依赖.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4f4211f38c9b7130bf5116270e6fed85-20231223175001-vhgjkvf.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个方案里面还留了一些可以引导的点.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("缓存问题")]),_._v(": 在这里提到了 Redis 失效, 这种情况类似于缓存雪崩, 那么很自然地就可以把话题引导到如何处理缓存击穿, 穿透, 雪崩这些经典问题上.")]),_._v(" "),v("li",[v("strong",[_._v("高可用 MySQL")]),_._v(": 在这里使用的是熔断来保护 MySQL, 类似地也可以考虑用限流来保护 MySQL.")])]),_._v(" "),v("p",[_._v('最后提到了退出熔断状态, 如果面试官了解抖动问题, 那么他就肯定会追问 "你是一次性放开全部流量吗?", 那么就可以阐述抖动的问题, 然后总结一下.')]),_._v(" "),v("blockquote",[v("p",[_._v("我这种逐步放开流量的方案其实还是有缺陷的, 还有一些更加高级的做法, 但是需要负载均衡来配合.")])]),_._v(" "),v("p",[_._v("这个总结就是留下的鱼饵, 为了引出下面的亮点方案.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-2"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("前面的基本思路如果你能答好, 差不多也能通过跟熔断有关的面试了, 而且有不小的概率能够给面试官留下你技术很不错的印象. 但是还可以进一步展示你在服务治理和服务可用性保证上的独到见解. 这就需要用到下面要讲的"),v("strong",[_._v("综合了负载均衡算法和熔断措施的方案")]),_._v("了.")]),_._v(" "),v("p",[_._v("这个方案很简单, 在落地的时候也不是很难.")]),_._v(" "),v("p",[_._v("在讲抖动与恢复的时候提到, "),v("strong",[_._v("恢复的时候可以逐步放开流量")]),_._v(". 那么你是否注意到, 这个放开流量是在服务端处理的, 也就是说"),v("strong",[_._v("服务端还是收到了 100% 的流量, 只不过只有部分流量会被放过去并且被正常处理")]),_._v(".")]),_._v(" "),v("p",[_._v("那么一个自然的想法就是"),v("mark",[v("strong",[_._v("为什么不直接让客户端来控制这个流量呢")])]),_._v("?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ec05dc00f892bde08a739e2yy3cee3d1-20231223175001-9ojftj4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("进一步结合在负载均衡里面谈到的"),v("strong",[_._v("根据调用结果来调整负载均衡策略的讨论")]),_._v(", 是不是可以让客户端也采用这种负载均衡策略? 答案是可以的.")]),_._v(" "),v("p",[_._v("整体流程:")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("服务端在触发熔断的时候, 会返回一个代表熔断的错误")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("客户端在收到这个错误之后, 就会把这个服务端节点暂时挪出可用节点列表")]),_._v(". 后续所有的新请求都不会再打到这个触发了熔断的服务端节点上了.")]),_._v(" "),v("li",[v("strong",[_._v("客户端在等待一段时间后, 逐步放开流量")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果服务端正常处理了新来的请求, 那么客户端就加大流量")]),_._v(".")]),_._v(" "),v("li",[_._v("如果服务端再次返回了熔断响应, 那么客户端就会再一次将这个节点挪出可用列表.")]),_._v(" "),v("li",[_._v("如此循环, 直到服务端完全恢复正常, 客户端也正常发送请求到该服务端节点.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bd829a2832df33c1c92b8d3165c06968-20231223175001-iuidisg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/230c1329cd5d273fb79cbcc50f8a0002-20231223175001-ygstxu4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/59f6be80174afd9cd57d5f4c8b2ea5cd-20231223175001-drj0plp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么这里就可以这样回答, 关键词是"),v("strong",[_._v("负载均衡")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("整体思路是利用负载均衡来控制流量. 如果一个服务端节点触发了熔断, 那么客户端在做负载均衡的时候就可以将这个节点挪出可用列表, 后续请求会发给别的节点. 在经过一段时间之后, 客户端可以尝试发请求给该节点. 如果该节点正确处理了, 那客户端就可以加大流量. 否则客户端就要再一次等待一段时间.")])]),_._v(" "),v("p",[_._v("到这里还可以自己杠自己一下, 就是"),v("strong",[_._v("万一所有可用节点都触发熔断了, 应该怎么办")]),_._v("?  就可以这样来说.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案是需要兜底的, 比如说如果因为某些原因数据库出问题, 导致某个服务所有的节点都触发了熔断, 那么客户端就完全没有可用节点了. 不过这个问题本身熔断解决不了, 负载均衡也解决不了, 只能通过监控告警之后人手工介入处理了.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-3"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节主要解决的是熔断问题. 讨论了熔断的基本概念, 怎么判定服务是否熔断, 以及熔断后如何恢复的问题. 其中的难点是抖动的问题, 为了防止抖动, 需要合理判定节点的健康状况, 在恢复期间尽可能等待一段时间, 然后逐步放开流量.")]),_._v(" "),v("p",[_._v("最后给出了一个 "),v("strong",[_._v("综合运用负载均衡和熔断的方案, 重点在于客户端控制流量, 并根据服务端节点的状况来操作可用节点列表")]),_._v(". 在学习的时候注意把亮点方案和前面学习的负载均衡内容结合在一起, 同时也非常建议在实际工作中尝试应用一下熔断, 让它来保护系统, 提高系统可用性.")]),_._v(" "),v("p",[_._v("下面整理了这节课的思维导图, 可以参考.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4f5yy2ae950f35d03af485d1b1bbd3a0-20231223175001-lnpmhic.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("最后我再强调一下, 熔断面试的最好方案是把它作为你 "),v("strong",[_._v("构建高可用微服务")]),_._v(" 的一环, 也就是说, 可以认为前面讨论的负载均衡, 还有接下来要讨论的限流, 降级, 隔离等措施, 都是整个"),v("strong",[_._v("高可用方案的一环")]),_._v(".")]),_._v(" "),v("h4",{attrs:{id:"_04-降级-为什么每次大促的时候总是要把退款之类的服务停掉"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_04-降级-为什么每次大促的时候总是要把退款之类的服务停掉"}},[_._v("#")]),_._v(" 04-降级:为什么每次大促的时候总是要把退款之类的服务停掉?")]),_._v(" "),v("p",[_._v("今天来聊一聊微服务架构下的降级功能.")]),_._v(" "),v("p",[_._v("上节讨论熔断的时候, 就提到过"),v("mark",[v("strong",[_._v("熔断, 降级, 限流")])]),_._v("是三个经常合并在一起讨论的 "),v("strong",[_._v("可用性")]),_._v(" 保障措施. 所以如果想要掌握高可用微服务架构, 那么降级也是其中必不可少的一环.")]),_._v(" "),v("p",[_._v("可惜的是, 大部分人在聊起降级的时候只是简单讲一下概念, 选择的降级案例也不够精巧, 所以很难给面试官留下深刻的印象. 那么这节课来深入讨论降级的各个方面, 同时也会给出具体的亮点的方案.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-4"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[_._v('还是从降级的基本概念讲起. 如果用一句俏皮话来形容降级, 那就是 "'),v("strong",[_._v("凑合过呗, 还能离咋的")]),_._v('", 就比如在双十一之类的大促高峰, 平台是会关闭一些服务的, 比如退款服务.')]),_._v(" "),v("p",[_._v("这就是降级的典型应用, 不过它是一种手动的跨服务降级. 你可能会觉得困惑, 这为什么也算是降级呢? 这是因为"),v("strong",[_._v("对于整个系统来说, 它提供了一部分服务, 但是没有提供另外一部分服务, 所以它在整个系统层面上是降级的")]),_._v(".")]),_._v(" "),v("p",[_._v("这种降级的好处有两方面. 一方面是腾出了服务器资源, 可以给订单服务或者支付服务; 另外一方面是减少了对公共组件的压力, 比如说减少了对数据库的写入压力.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0346e6be20c3bb85ecafb5dfca0a34ff-20231223175001-axjsbph.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不过如果仅仅是针对退款服务而言, 那么也可以认为"),v("strong",[_._v("退款服务是整个熔断")]),_._v("了.")]),_._v(" "),v("h5",{attrs:{id:"降级与熔断"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#降级与熔断"}},[_._v("#")]),_._v(" 降级与熔断")]),_._v(" "),v("p",[_._v("事实上, 降级和熔断非常像. 熔断重点讨论的两个点, 降级也有讨论.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("如何判定服务健康, 在降级中则是判定一个服务要不要降级")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("降级之后怎么恢复, 也是要考虑抖动的问题")]),_._v(".")])]),_._v(" "),v("p",[_._v("所以在一些场景下, 既"),v("strong",[_._v("可以用熔断, 也可以用降级")]),_._v(". 比如说在"),v("mark",[v("strong",[_._v("响应时间超过阈值之后, 可以考虑选择熔断, 完全不提供服务; 也可以考虑降级, 提供有损服务")])]),_._v(".")]),_._v(" "),v("p",[_._v("原则上来说, 是应该优先考虑使用降级的. 然而有些服务是无法降级的, 尤其是写服务. 例如从前端接收数据, 然后写到数据库, 这种场景是无法降级的. 另外, 如果希望系统负载尽快降低, 那么熔断要优于降级.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/38be3714422ba8e3a6f835e678e484fc-20231223175001-y7o9pn7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从具体实践上来说, "),v("strong",[_._v("降级可以玩出的花样要比熔断多很多. 毕竟熔断是彻底不提供服务, 而降级则是尽量提供服务")]),_._v(". 所以"),v("strong",[_._v("怎么降")]),_._v("就有很多千奇百怪的做法了.")]),_._v(" "),v("h6",{attrs:{id:"如何降级"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何降级"}},[_._v("#")]),_._v(" 如何降级?")]),_._v(" "),v("p",[_._v("怎么降这个问题的答案又可以分成两大类.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("跨服务降级")]),_._v(", 当资源不够的时候可以暂停某些服务, 将腾出来的资源给其他更加重要, 更加核心的服务使用. 这里提到的大促暂停退款服务就是跨服务降级的例子. "),v("mark",[v("strong",[_._v("这种策略的要点是必须知道一个服务比另外一个服务更有业务价值, 或者更加重要")])]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("本服务提供有损服务")]),_._v(", 例如各大 App 的首页都会有降级的策略. 在没有触发降级的时候, App 首页是针对个人用户画像的个性化推荐. 而在触发了降级之后, 则可能是使用榜单数据, 或者使用一个运营提前配置好的静态页面. "),v("mark",[v("strong",[_._v("这种策略的要点是得知道服务调用者能够接受什么程度的有损")])]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6d33dd4340564d4b136aa6acc061cf07-20231223175001-0ymmmbq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("跨服务降级的措施是很粗暴的, 常见的做法有三个.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("整个服务停掉")]),_._v(", 例如前面提到的停掉退款服务.")]),_._v(" "),v("li",[v("strong",[_._v("停掉服务的部分节点")]),_._v(", 例如十个节点, 停掉其中五个节点, 这五个节点被挪作他用.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("停止访问某些资源")])]),_._v(". 例如日志中心压力很大的时候, 发信号给某些不重要的服务, 让它们停止上传日志, 只在本地保存日志.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/930e93374499368f56499463e61acb22-20231223175001-txzaurm.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而针对服务本身, 也有一些常见的降级思路.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("返回默认值")]),_._v(", 这算是最简单的一种状况.")]),_._v(" "),v("li",[v("strong",[_._v("禁用可观测性组件")]),_._v(", 正常来说在业务里面都充斥了各种各样的埋点. 这些埋点本身其实是会带来消耗的, 所以在性能达到瓶颈的时候, 就可以考虑停用, 或者降低采样率.")]),_._v(" "),v("li",[v("strong",[_._v("同步转异步")]),_._v(', 即正常情况下, 服务收到请求之后会立刻处理. 但是在降级的情况下, 服务在收到请求之后只会返回一个代表 "已接收" 的响应. 后续服务会异步地开启线程来处理, 或者依赖于定时任务来处理.')]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("简化流程")])]),_._v(", 如果处理一个请求需要很多步骤, 后续如果有一些步骤不关键的话, 可以考虑不执行, 或者异步执行. 例如在内容生产平台, 一般新内容要被推送到推荐系统里面. 那么在降级的情况下可以不推, 而后可以考虑异步推送过去, 也可以考虑等系统恢复之后再推送过去.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2bb62da8ec10584a02e552b2d79a47af-20231223175001-26mc3cf.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-4"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要了解清楚你所在公司使用降级的情况.")]),_._v(" "),v("ul",[v("li",[_._v("如果你所在公司有 App, 网站之类的产品, 那么去了解一下在"),v("strong",[_._v("首页, 核心页面有没有采取降级措施")]),_._v(". 如果采用了降级, 那么降级前后的逻辑是什么样的.")]),_._v(" "),v("li",[_._v("提前了解公司有没有使用降级来保护系统. 如果有, 那么需要了解清楚"),v("strong",[_._v("什么情况下会触发降级, 降级后的逻辑是怎样的, 以及怎样从降级中恢复过来")]),_._v(".")])]),_._v(" "),v("p",[_._v("这些降级的东西可能你没做过, 不过你只需要了解清楚每一种降级的前因后果即可.")]),_._v(" "),v("p",[_._v("如果你维护的服务没有使用任何降级措施, 那么可以考虑为这些服务接入降级措施. 这样做不仅可以给你的 KPI 或者 OKR 添上一笔, 还能让你在实践过程中加深对降级的理解, 掌握更多的细节.")]),_._v(" "),v("p",[_._v("最佳面试策略是把降级作为构建高可用微服务架构的一个措施, 例如在项目介绍中说:")]),_._v(" "),v("blockquote",[v("p",[_._v("A 系统是公司的核心系统, 而我的主要职责是保障该系统的高可用. 为了达到这一个目标, 我综合运用了熔断, 降级, 隔离等措施.")])]),_._v(" "),v("p",[_._v("等面试官询问某个具体措施的时候再详细解答.")]),_._v(" "),v("p",[_._v("知己知彼, 方能百战不殆. 当面试官问哪些问题时可以用降级来回答呢?")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("你是否了解服务治理")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("如何提高系统的可用性")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("如果系统负载很高该怎么办")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("依赖的下游服务或者下游中间件崩溃了怎么办")]),_._v("?")])]),_._v(" "),v("p",[_._v("这些问题是不是很熟悉, 其实已经在熔断里面聊过了. 就像上节课说的, 这些知识之间是相通的, 任何优秀的方案都是这些内容的完美整合. 所以这些问题同样可以用降级来回答.")]),_._v(" "),v("p",[_._v("同时为了展示亮点, 需要记住后面的两个方案: "),v("mark",[v("strong",[_._v("读写服务降级写服务和快慢路径降级慢路径")])]),_._v(". 非常建议参考这两个方案的思路, 基于自己的实际业务情况设计自己独有的降级面试案例.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-2"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("如果面试官问到了降级, 或者说你将话题引导到了降级, 那么可以先介绍降级的基本概念, 同时可以举前面提到的大促和 App 首页的例子. 如果之前没有和面试官聊过熔断, 那么可以在这里补充熔断里面讨论判断服务健康的要点, 然后结合自己公司内部使用降级的例子, 或者即便不是自己亲手落地但是自己也了解详情的案例.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在公司也用了降级来保护我维护的服务. 举例来说, 正常情况下服务都会全量采集各种监控指标. 那么在系统触及性能瓶颈的时候, 我就会调整采集的比率. 甚至在关键的时候, 会直接停用掉所有的指标采集, 将资源集中在提供服务上.")])]),_._v(" "),v("p",[_._v("这里给的示例比较简单, 可以考虑换成前面提到的其他降级思路. 当然, 如果公司内部本身就使用了降级的话, 那么使用自己的案例会更好. 讲完一个案例之后, 可以进一步总结常规的降级思路, 也就是在前置知识里面列举出来的.")]),_._v(" "),v("p",[_._v("前面列举出来的这些措施你不一定都用过, 那么万一面试官问到其中一个, 你不了解细节的话, 你可以大方承认这就是听说过的措施, 并没有实际落地. 毕竟, 技术行业乱七八糟, 千奇百怪的解决思路数不胜数, 不一定非得都亲手实践过.")]),_._v(" "),v("p",[_._v("紧接着, 还有一个关键问题——"),v("strong",[_._v("抖动")]),_._v(", 千万别忘记参考熔断中的话术提一下. 而后可以将熔断与降级结合, 总结升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("总的来说, 在任何的故障处理里面, 都要考虑恢复策略会不会引起抖动问题.")])]),_._v(" "),v("p",[_._v("总结是必不可少的, "),v("strong",[_._v("任何总结都代表你对问题更加抽象, 更加深层次的认知")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-3"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("到这一步, 从理论上来说你基本上已经答得很好, 唯一美中不足的就是案例过于简单. 所以这里准备了两个比较好的案例. 这两个案例都可以根据你所在公司的实际情况进行调整, 用真实的服务来替代这里使用的服务.")]),_._v(" "),v("h6",{attrs:{id:"读写服务降级写服务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#读写服务降级写服务"}},[_._v("#")]),_._v(" 读写服务降级写服务")]),_._v(" "),v("p",[_._v("这个案例的基本思路是如果某个服务是"),v("mark",[v("strong",[_._v("同时提供了读服务和写服务, 并且读服务明显比写服务更加重要, 那么这时候就可以考虑降级写服务")])]),_._v(".")]),_._v(" "),v("p",[_._v("假如现在有一个针对商家的服务, 商家调用这些 API 来录入一些数据, 比如他们门店的基本信息, 上传一些门店图片等. 同时还有一个针对 C 端普通用户的服务, 这个服务就是把商家录入的数据展示在商家门店的首页上. 所以可以看到在这个场景下, "),v("strong",[_._v("读服务 QPS 更高")]),_._v(", "),v("strong",[_._v("也更加重要")]),_._v(".")]),_._v(" "),v("p",[_._v("那么如果这两个服务是一起部署的, 在需要降级的时候, 就可以考虑将针对商家的写服务停掉, 将资源都腾出来给针对 C 端用户的读服务.")]),_._v(" "),v("p",[_._v("所以可以介绍这个方案, 关键词是"),v("mark",[v("strong",[_._v("降级写服务")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我在公司维护了一个服务, 它的接口可以分成两类: 一类是给 B 端商家使用的录入数据的接口, 另外一类是给 C 端用户展示这些录入的数据. 所以从重要性上来说, 读服务要比写服务重要得多, 而且读服务也是一个高并发的服务.")])]),_._v(" "),v("blockquote",[v("p",[_._v("于是我接入了一个跨服务的降级策略. 当发现读服务的响应时间超过了阈值的时候, 或者响应时间开始显著上升的时候, 就会将针对 B 端商家用户的服务临时停掉, 腾出来的资源都给 C 端用户使用. 对于 B 端用户来说, 他们这个阶段是没有办法修改已经录入的数据的. 但是这并不是一个特别大的问题. 当 C 端接口的响应时间恢复正常之后, 会自动恢复 B 端商家接口, 商家又可以修改或者录入数据了.")])]),_._v(" "),v("p",[_._v("同时可以考虑从"),v("strong",[_._v("对数据库性能影响")]),_._v("的角度来进一步解释降级写服务的优点.")]),_._v(" "),v("blockquote",[v("p",[_._v("虽然整体来说写服务 QPS 占比很低, 但是对于数据库来说, 一次写请求对性能的压力要远比一次读请求大. 所以暂停了写服务之后, 数据库的负载能够减轻不少.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/01b0d76f59c68e631c5229f15fc843f9-20231223175001-827ubxr.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("除了这种 B 端录入 C 端查询的场景, 还有很多类似的场景也适用.")]),_._v(" "),v("ul",[v("li",[_._v("在内容生产平台, 作者生产内容, C 端用户查看生产的内容. 那么在资源不足的情况下可以考虑停掉内容生产端的服务, 只保留 C 端用户查看内容的功能.")]),_._v(" "),v("li",[v("strong",[_._v("如果用户分成普通用户和 VIP 用户, 那么也可以考虑停掉给普通用户的服务")]),_._v(". 甚至, 如果一个服务既提供给普通用户, 也提供给 VIP 用户, 也可以考虑将普通用户请求拒绝掉, 只服务 VIP 用户.")])]),_._v(" "),v("p",[_._v("如果你负责的业务也有其他类似的场景, 那么可以将里面的商家服务和 C 端服务换成自己的服务.")]),_._v(" "),v("p",[_._v("在讲完这一个方案之后, 要稍微总结一下, 在理论层面上拔高一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案就是典型的跨服务降级. 跨服务降级可以在大部分合并部署的服务里面使用, 一般的原则就是 B, C 端合并部署降级 B 端; 付费服务和非付费服务降级非付费服务. 当然也可以根据自己的业务价值, 将这些部署在同一个节点上的服务分成三六九等. 而后在触发降级的时候从不重要的服务开始降级, 将资源调配给重要服务.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8e72f4ebf9c469c49e19eb6e73105ab4-20231223175001-4lvumn5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("有时候面试官可能会问"),v("strong",[_._v("怎么确定一个服务的业务价值")]),_._v(", 又或者可以自己引出这个话题, 关键词就是"),v("mark",[v("strong",[_._v("赚钱")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("判断一个服务的业务价值最简单的方法就是问产品经理")]),_._v(", 产品经理自然是清楚什么东西带来了多少业务价值. 又或者根据公司的主要营收来源确定服务的业务价值, 越是能赚钱的就越重要. 唯一的例外是跟合规相关的. 比如说内容审核, 它不仅不赚钱, 还是一块巨大的成本支出. 但是不管怎么降级, 内容审核是绝对不敢降级的, 不然就等着被请去喝茶交代问题吧.")])]),_._v(" "),v("p",[_._v("这里还可以进一步展示亮点, 让人感觉你对微服务框架有很深研究. 关键词就是"),v("strong",[_._v("跨节点")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("不过这种跨服务降级都是只能降级处在同一个节点的不同服务. 而如果服务本身就分布在不同节点上的话, 是比较难设计这种降级方案的. 比如说大促时关闭退款服务这种, 就需要人手工介入.")])]),_._v(" "),v("blockquote",[v("p",[_._v("从理论上来说, 网关其实是可以考虑支持这种跨节点的服务降级的. 假如有 A, B 两个服务, A 比 B 更加有业务价值. 那么在 A 服务所需资源不足的时候, 网关可以考虑停掉 B 的一部分节点, 而后在这些节点上部署 A 服务. 对于 B 服务来说, 它只剩下一部分节点, 所以也算是被降级了. 很可惜, 大部分网关的降级设计都没考虑过这种跨服务降级的功能.")])]),_._v(" "),v("blockquote",[v("p",[_._v("微服务框架做得就更差了. 大部分微服务框架提供的降级功能都是针对本服务的, 比如说在触发降级的时候返回一个默认值.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/370d59aa2a4b2f0c6c26495d54e9b7f8-20231223175001-kcpat4z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后对网关的评价可能会让面试官将话题引向网关, 所以要在对面试"),v("strong",[_._v("网关")]),_._v("内容有把握的情况下再说.")]),_._v(" "),v("h6",{attrs:{id:"快慢路径降级慢路径"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#快慢路径降级慢路径"}},[_._v("#")]),_._v(" 快慢路径降级慢路径")]),_._v(" "),v("p",[_._v("在熔断里面提到了一个例子, 即如果 Redis 崩溃了, 那么就可以直接触发熔断. 这种做法主要是为了保护数据库, 防止 Redis 崩溃把所有的请求都直接落到数据库上, 把数据库打崩.")]),_._v(" "),v("p",[_._v("也可以考虑使用降级来保护这个缓存-数据库结构. 正常来说, 一般使用缓存基本上都是先从缓存里面读数据, 如果缓存里面没有数据, 就从数据库中读取.")]),_._v(" "),v("p",[_._v("那么"),v("strong",[_._v("在触发降级的情况下, 可以考虑只从缓存里面读取")]),_._v(". 如果缓存里面没有数据, 那么就直接返回, 而不会再去数据库里读取. 这样可以保证在缓存里面有数据的那部分请求可以得到正常处理, 也就是提供了有损服务.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9ee2730a08373c5d7a2460a4bcfb41e0-20231223175001-io5qtmj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种降级方案背后的逻辑也很简单. 如果完全不考虑从数据库里取数据, 那么性能瓶颈就完全取决于缓存或者说 Redis, 那么服务能够撑住的 QPS 会非常高.")]),_._v(" "),v("p",[_._v("但如果缓存不命中的时候要去数据库取数据, 那么服务的性能会衰退得非常快, 即极少数缓存未命中的请求会占据大部分的系统资源.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/889a52912627c93830ee0795625984c6-20231223175001-m6d42v4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这样回答, 关键词是"),v("strong",[_._v("只查缓存")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我还用过另外一个降级方案. 正常来说在我的业务里面, 就是查询缓存, 如果缓存有数据, 那么就直接返回. 如果缓存没有, 那么就需要去数据库查询. 如果此时系统的并发非常高, 那么就会采取降级策略, 将请求标记为降级请求. 降级请求只会查询缓存, 而不会查询数据库. 如果缓存没有, 那就直接返回错误. 这样能够有效防止因为少部分请求缓存未命中而占据大量系统资源, 导致系统吞吐量下降和响应时间显著升高.")])]),_._v(" "),v("p",[_._v("同样也需要总结拔高一下, 关键词是"),v("strong",[_._v("快慢路径")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种思路其实可以在很多微服务里面应用. 如果一个服务可以分成快路径和慢路径两种逻辑, 那么在降级之前就可以先走快路径, 再走慢路径. 而触发了降级之后, 就只允许走快路径. 在前面的例子里面, 从缓存里加载数据就是快路径, 从数据库里面加载数据就是慢路径.")])]),_._v(" "),v("blockquote",[v("p",[_._v("慢路径还可以是发起服务调用或者复杂计算. 比如说一个服务快路径是直接查询缓存, 而慢路径可能是发起很多微服务调用, 拿到所有响应之后一起计算, 算出来一个结果并缓存起来. 那么在降级的时候, 可以有效提高吞吐量. 不过这种吞吐量是有损的, 毕竟部分请求如果没有在缓存中找到数据, 那么就会直接返回失败响应.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1d4a9e6474f1715090a1cabf3350f093-20231223175001-ihv9mpg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("很自然地, 你的关键服务都应该有类似的降级措施. 当任何下游崩溃, 或者第三方中间件崩溃, 都可以不再调用这些崩溃的下游服务或中间件, 以确保提供有损服务.")]),_._v(" "),v("p",[_._v("如果选择这个作为亮点方案的话, 那么自然就可以将话题引导到"),v("strong",[_._v("缓存")]),_._v("的使用上来, 就可以使用课程后面缓存相关的内容来阐述了.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-4"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节已经讨论清楚了降级的基本概念, 常见做法.")]),_._v(" "),v("p",[_._v("降级和熔断是很像的, 它也要考虑判定服务健康, 如何恢复以及怎么降级. 需要记住的是从系统整体上看, 可以考虑"),v("strong",[_._v("跨服务降级")]),_._v(", 例如大促的时候关闭退款服务. 针对单一服务, 也可以考虑"),v("strong",[_._v("提供有损服务")]),_._v(".")]),_._v(" "),v("p",[_._v("那么不管是跨服务降级还是提供有损服务, "),v("mark",[v("strong",[_._v("根源都在于要识别出来, 一部分比另外一部分更加重要")])]),_._v(". 这样就可以牺牲不那么重要的部分来保障更加重要的部分.")]),_._v(" "),v("p",[_._v("最后给出了两个亮点方案: "),v("strong",[_._v("读写服务降级写服务")]),_._v(", "),v("strong",[_._v("快慢路径降级慢路径")]),_._v(". 可以把这两个方案记下来, 也可以根据自己的业务特征来设计类似的降级方案.")]),_._v(" "),v("p",[_._v("再强调一点, 这些方案本身都是可以在公司内部落地的. 所以即便没有机会也应该创造机会在公司内部实践一下.")]),_._v(" "),v("p",[_._v("本节内容的思维导图如下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a954b507c2f7ae46b9eb6230d4b54d29-20231223175001-r6ewrlt.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"思考题-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-3"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("ul",[v("li",[_._v("前面讲了一个读写服务降级写服务的例子, 那么你觉得写服务内部可以考虑降级吗? 比如说我的写服务是写多个数据源, 那我可以降级为只写一个数据源吗?")]),_._v(" "),v("li",[_._v("这节课我还解释了一下熔断和降级的联系和区别, 那么你是怎么看待这两者的关系的? 你能举一些可以降级或者只能熔断的服务的例子吗?")])]),_._v(" "),v("h4",{attrs:{id:"_05-限流-别说算法了-就问你-阈值-怎么算"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_05-限流-别说算法了-就问你-阈值-怎么算"}},[_._v("#")]),_._v(' 05-限流:别说算法了,就问你"阈值"怎么算?')]),_._v(" "),v("p",[_._v("今天来聊一聊微服务架构下的限流功能.")]),_._v(" "),v("p",[_._v("熔断, 降级和限流是最常见的三种微服务架构可用性保障措施. 和熔断, 降级比起来, 限流要更加复杂一些. 大部分情况下, 面试官面试限流就是随便问问算法, 最多就是问问 BBR 之类的动态算法. 但是有一个问题, 很多人都答不好, 就是"),v("mark",[v("strong",[_._v("限流需要确定一个流量阈值, 这个阈值该怎么算")])]),_._v("?")]),_._v(" "),v("p",[_._v("今天就深入讨论限流的这个问题.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-5"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[_._v("限流是通过限制住流量大小来保护系统, 它尤其能够"),v("strong",[_._v("解决异常突发流量打崩系统的问题")]),_._v(". 例如常见的某个攻击者攻击系统, 那么限流就能极大程度上保护住你的系统.")]),_._v(" "),v("p",[_._v("要想全面掌握限流这个知识点, 需要深入理解"),v("strong",[_._v("限流的算法, 对象, 以及限流后的做法")]),_._v(". 下面一个个来看.")]),_._v(" "),v("h6",{attrs:{id:"算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#算法"}},[_._v("#")]),_._v(" 算法")]),_._v(" "),v("p",[_._v("限流算法也可以像负载均衡算法那样, 划分成"),v("strong",[_._v("静态算法和动态算法")]),_._v("两类.")]),_._v(" "),v("ul",[v("li",[v("mark",[v("strong",[_._v("静态算法包含令牌桶, 漏桶, 固定窗口和滑动窗口")])]),_._v(". 这些算法就是要求研发人员提前设置好阈值. 在算法运行期间它是不会管服务器的真实负载的.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("动态算法也叫做自适应限流算法, 典型的是 BBR 算法")])]),_._v(". 这一类算法利用一系列指标来判定是否应该减少流量或者放大流量. 动态算法和 TCP 的拥塞控制是非常接近的, 只不过 TCP 控制的是报文流量, 而微服务控制的是请求流量.")])]),_._v(" "),v("p",[_._v("除了这里列举的算法, 也可以考虑参考熔断和降级里面的思路, 选用一些指标来设计自己的限流算法. 例如业务需要很多内存, 那么可以根据剩余空闲内存来判断要不要执行限流.")]),_._v(" "),v("p",[_._v("下面就从静态算法中的令牌桶看起, 掌握限流中常见的算法.")]),_._v(" "),v("blockquote",[v("p",[_._v("令牌桶")])]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("系统会以一个恒定的速率产生令牌, 这些令牌会放到一个桶里面, 每个请求只有拿到了令牌才会被执行")])]),_._v(". 每当一个请求过来的时候, 就需要尝试从桶里面拿一个令牌. 如果拿到了令牌, 那么请求就会被处理; 如果没有拿到, 那么这个请求就被限流了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/aba7bdeb91f372d5edca85b2fb689b7f-20231223175001-x68zblx.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("你需要注意, "),v("strong",[_._v("本身令牌桶是可以积攒一定数量的令牌的")]),_._v(". 比如说桶的容量是 100, 也就是这里面最多积攒 100 个令牌. 那么当某一时刻突然来了 100 个请求, 它们"),v("strong",[_._v("都能拿到令牌")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("漏桶")])]),_._v(" "),v("p",[v("strong",[_._v("漏桶是指当请求以不均匀的速度到达服务器之后, 限流器会以固定的速率转交给业务逻辑")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bba1cbc3cf682e09a18098e3da96e18c-20231223175001-1i7wt8u.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("某种程度上, 可以将漏桶算法看作是令牌桶算法的一种特殊形态. 将令牌桶中桶的容量设想为 0, 就是漏桶了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ea8c6daacd9fa20c26a1cf96990b88bd-20231223175001-honwnn0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以看到, 在漏桶里面, 令牌产生之后就需要取走, 没取走的话也不会积攒下来. "),v("mark",[v("strong",[_._v("因此漏桶是绝对均匀的, 而令牌桶不是绝对均匀的")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("固定窗口与滑动窗口")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8a76e55b50edcyyf6c7d3789d6b49f68-20231223175001-yrfqpag.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("固定窗口是指在一个固定时间段, 只允许执行固定数量的请求")]),_._v(". 比如说在一秒钟之内只能执行 100 个请求.")]),_._v(" "),v("p",[_._v("滑动窗口类似于固定窗口, "),v("strong",[_._v("也是指在一个固定时间段内, 只允许执行固定数量的请求")]),_._v(". 区别就在于, 滑动窗口是"),v("strong",[_._v("平滑地挪动窗口")]),_._v(", 而不像固定窗口那样突然地挪动窗口.")]),_._v(" "),v("p",[_._v("假设窗口大小是一分钟. 此时时间是 t1, 那么窗口的起始位置是 t1-1 分钟. 过了 2 秒之后, 窗口大小依旧是 1 分钟, 但是窗口的起始位置也向后挪动了 2 秒, 变成了 t1 - 1 分钟 + 2 秒. 这也就是滑动的含义.")]),_._v(" "),v("h6",{attrs:{id:"限流对象"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#限流对象"}},[_._v("#")]),_._v(" 限流对象")]),_._v(" "),v("p",[_._v("此外还要进一步"),v("strong",[_._v("考虑限流对象, 也就是针对什么来进行限流")]),_._v(".")]),_._v(" "),v("p",[_._v("从单机或者集群的角度看, 可以分为"),v("mark",[v("strong",[_._v("单机限流或者集群限流")])]),_._v(". 集群限流一般需要借助 Redis 之类的中间件来记录流量和阈值. 换句话说, 就是需要用 Redis 等工具来实现前面提到的限流算法. "),v("strong",[_._v("当然如果是利用网关来实现集群限流, 那么可以摆脱 Redis")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/621c771862ce464cde5eb0627ed109f8-20231223175001-3ynnbct.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("针对"),v("strong",[_._v("业务对象")]),_._v("限流, 这一类限流对象就非常多样.")]),_._v(" "),v("ul",[v("li",[_._v("VIP 用户不限流而普通用户限流.")]),_._v(" "),v("li",[v("strong",[_._v("针对 IP 限流")]),_._v(". 用户登录或者参与秒杀都可以使用这种限流, 比方说设置一秒钟最多只能有 50 个请求, 即便考虑到公共 IP 的问题, 正常的用户手速也是没那么快的.")]),_._v(" "),v("li",[v("strong",[_._v("针对业务 ID 限流")]),_._v(", 例如针对用户 ID 进行限流.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f52b2265cd34769a594c9ceeb05d9ce5-20231223175001-9z86017.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"限流后的做法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#限流后的做法"}},[_._v("#")]),_._v(" 限流后的做法")]),_._v(" "),v("p",[_._v("即使一个请求被限流了, 那么也可以设计一些精巧的方案来处理.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("同步阻塞等待一段时间")]),_._v(". 如果是偶发性地触发了限流, 那么稍微阻塞等待一会儿, 后面就有极大的概率能得到处理. 比如说限流设置为一秒钟 100 个请求, 恰好来了 101 个请求. 多出来的一个请求只需要等一秒钟, 下一秒钟就会被处理. 但是要注意控制住超时, 也就是说不能让人无限期地等待下去.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/795d6977dc03e134e0894080c57b577d-20231223175001-j63840i.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("同步转异步")]),_._v(". 这里又一次看到了这个手段, 它是指如果一个请求没被限流, 那就直接同步处理; 而如果被限流了, "),v("strong",[_._v("那么这个请求就会被存储起来, 等到业务低峰期的时候再处理")]),_._v(". 这个其实跟降级差不多.")]),_._v(" "),v("li",[v("strong",[_._v("调整负载均衡算法")]),_._v(". 如果某个请求被限流了, 那么就相当于告诉负载均衡器, 应该尽可能少给这个节点发送请求. 在熔断里面讲过类似的方案. 不过在熔断里面是负载均衡器后续不再发请求, 而"),v("strong",[_._v("在限流这里还是会发送请求, 只是会降低转发请求到该节点的概率. 调整节点的权重就能达成这种效果")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/479c735177d75bd9782c8187e753da01-20231223175001-3pi191j.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-5"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("理论上, 你要能够说出各种算法的基本原理. 但动态算法, 比如 BBR, 就不作硬性的要求了. 这主要是因为 BBR 的原理和实现都很有难度, 大多数微服务框架都没提供 BBR 的限流器实现. 不过要是有时间和精力, 还是可以了解一下 BBR 的基本原理.")]),_._v(" "),v("p",[v("strong",[_._v("有些时候面试官可能会让你手写限流算法, 那么漏桶, 令牌桶, 滑动窗口和固定窗口这几个算法都要能写出来, 至少要能把基本思路写清楚")]),_._v(". 如果还有时间和精力, 那么建议为一些开源框架提供限流插件, 比如说为 gRPC 提供各种限流算法实现的插件.")]),_._v(" "),v("p",[_._v("你可能会说现在开源的那么多, 你写出来的插件还有人用吗? 大概率没人用, 但是你的目标也不是让人用, 而是 "),v("strong",[_._v("作为一个证据")]),_._v(", 来证明你懂限流, 你很熟悉 gRPC, 你喜欢开源.")]),_._v(" "),v("p",[_._v("除了这些基本的知识, 在面试前, 还需要了解清楚你们公司"),v("strong",[_._v("使用限流的情况")]),_._v(". 正常来说, "),v("strong",[_._v("核心 HTTP 请求和核心服务都应该使用限流来保障系统的可用性")]),_._v(". 对于每一个限流, 你都要了解这些信息.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("限流的阈值是多少, 为什么设定成这个阈值")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("被限流的请求会被怎么处理, 是直接拒绝还是阻塞直到超时, 还是转为异步处理")]),_._v("?")])]),_._v(" "),v("p",[_._v("同样, 面试限流的最好策略就是为自己打造一个掌握了高可用微服务架构的人设. 而限流就是在提高系统可用性时的一个具体策略. 如果前面和面试官已经聊到了熔断和降级, 那么就可以直接把话题引导到限流上. 比如:")]),_._v(" "),v("ul",[v("li",[_._v("在讨论对外的 API, 如 HTTP 接口或者公共 API 时, 可以"),v("strong",[_._v("强调使用限流来保护系统")]),_._v(".")]),_._v(" "),v("li",[_._v("在讨论 TCP 拥塞控制时, 可以提起在服务治理上限流也借鉴了 TCP 拥塞控制的一些思想.")]),_._v(" "),v("li",[_._v("在讨论 Redis 或者类似产品的时候, 可以提"),v("strong",[_._v("用 Redis 实现过集群限流")]),_._v(".")])]),_._v(" "),v("p",[_._v("如果维护的服务或者接口还没有使用限流来保护系统, 那么就可以考虑加上限流. 而为了确定具体的阈值, 可以尝试对接口进行压力测试, 找准限流的阈值. 这个也是需要通过实践来加深印象, 把握细节的.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-3"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("如果面试官问到了限流, 那么就可以先阐述限流的总体目标, 然后回答前置知识里面的三个点: "),v("mark",[v("strong",[_._v("算法, 限流对象和限流后的做法, 最后再把话题引到计算阈值上")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("限流是为了保证系统可用性, 防止系统因为流量过大而崩溃的一种服务治理手段.")]),_._v(" "),v("p",[_._v("从"),v("mark",[_._v("算法")]),_._v("上来说, 有令牌桶, 漏桶, 固定窗口和滑动窗口算法. 还有动态限流算法, 或者说自适应限流算法, 比较有名的就是参考了 TCP 拥塞控制算法 BBR 衍生出来的算法, 比如说 B 站开源的 Kratos 框架就有一个实现. 这些算法之间比较重要的一个区别是"),v("mark",[_._v("能否处理小规模的突发流量")]),_._v(".")]),_._v(" "),v("p",[_._v("从"),v("mark",[_._v("限流对象")]),_._v("上来说, 可以是集群限流或者单机限流, 也可以是针对具体业务来做限流. 比如说在登录的时候, 我们经常针对 IP 进行限流. 又或者在一些增值服务里面, 非付费用户也会被限流.")]),_._v(" "),v("p",[v("mark",[_._v("触发限流之后")]),_._v(", 具体的措施也可以非常灵活. 被限流的请求可以同步阻塞一段时间, 也可以考虑同步转异步. 如果负载均衡算法灵活的话, 也可以做一些调整, 减少发到该节点的概率.")]),_._v(" "),v("p",[_._v("用好限流的一个重要前提是能够设置准确的"),v("mark",[_._v("阈值")]),_._v(", 例如每秒钟限制在 100 个请求还是限制在 200 个请求. 如果阈值过低, 那么系统资源就容易闲置浪费; 如果阈值太高, 那么系统可能撑不住那么多流量, 导致崩溃.")])]),_._v(" "),v("p",[_._v("同时还要补充一个简单的例子, 关键词是 "),v("strong",[_._v("IP 限流")]),_._v(". 也可以考虑使用你的真实案例.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在我们公司的登录接口里面就引入了限流机制. 正常情况下, 一个用户在一秒钟内最多点击一次登录, 所以针对每一个 IP, 我限制它最多只能在一秒内提交 50 次登录请求. 这个 50 充分考虑到了公共 IP 的问题, 正常用户是不可能触发这个阈值的. 这个限流虽然很简单, 但是能够有效防范一些攻击. 不过限流再怎么防范, 还是会出现系统撑不住流量的情况.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f5db9767957167ffee24685a233dddbc-20231223175001-8pp988n.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("注意在上面的回答里, 没有说任何的细节, 只是宽泛地介绍了一下限流, 那么面试官接下来大概会问每一个算法, 不同的限流对象, 以及限流后的不同做法的细节. 这部分按照前置知识里面的内容来回答就可以.")]),_._v(" "),v("p",[_._v("接下来是一些对限流的深入讨论, 这部分内容能让你刷出不少的亮点.")]),_._v(" "),v("h6",{attrs:{id:"突发流量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#突发流量"}},[_._v("#")]),_._v(" 突发流量")]),_._v(" "),v("p",[_._v('前面提到了 "算法之间比较重要的一个区别是能否处理小规模的突发流量", 就是为这个部分的详细阐述留下了一个引子.')]),_._v(" "),v("p",[_._v("假如说正常限流是一秒钟 100 个请求, 但是如果某一秒钟来了 101 个请求, 你依旧会觉得第 101 个请求应该尽可能处理掉. 在这种场景下, 漏桶是做不到的, 因为漏桶是非常均匀的. 一秒钟 100 个请求在漏桶里面就是 10 毫秒一个请求, 绝对不会多也不会少.")]),_._v(" "),v("p",[v("strong",[_._v("而令牌桶就能够处理")]),_._v(". 比如说"),v("strong",[_._v("令牌桶产生令牌的速率是 100 个每秒, 但是桶的容量是 20 个, 那么也就是说某一秒钟内, 最多可以处理 120 个请求")]),_._v(".")]),_._v(" "),v("div",{staticClass:"language-java line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-java"}},[v("code",[v("span",{pre:!0,attrs:{class:"token function"}},[_._v("20")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("前一秒攒的令牌"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("+")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("100")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("当下这一秒"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("120")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("​"),v("img",{attrs:{src:"/img/813cb06153d11bccb3abca6e394c5df9-20231223175001-sc70pni.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("固定窗口和滑动窗口则有另外一个类似的问题, 就是"),v("strong",[_._v("毛刺问题")]),_._v(".")]),_._v(" "),v("p",[_._v("假如一个窗口大小是一分钟 1000 个请求, 你预计这 1000 个请求会均匀分散在这一分钟内. 那么有没有可能第一秒钟就来了 1000 个请求? 当然可能. 那当下这一秒系统有没有可能崩溃? 自然也是可能的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6e474byy5b9f9769d49f0c41f075ab53-20231223175001-z8vjx0l.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("所以固定窗口和滑动窗口的窗口时间不能太长. 比如说以秒为单位是合适的")]),_._v(", 但是以分钟作为单位就是不合适的.")]),_._v(" "),v("p",[_._v("那么在面试官问到, 或者在介绍了漏桶或令牌桶算法之后, 就可以补充这一段.")]),_._v(" "),v("blockquote",[v("p",[_._v("漏桶算法非常均匀, 但是令牌桶相比之下就没那么均匀. 令牌桶本身允许积攒一部分令牌, 所以如果有偶发的突发流量, 那么这一部分请求也能得到正常处理. 但是要小心令牌桶的容量, 不能设置太大. 不然积攒的令牌太多的话就起不到限流效果了. 例如容量设置为 1000, 那么要是积攒了 1000 个令牌之后真的突然来了 1000 个请求, 它们都能拿到令牌, 那么系统可能撑不住这突如其来的 1000 个请求.")])]),_._v(" "),v("h6",{attrs:{id:"请求大小"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#请求大小"}},[_._v("#")]),_._v(" 请求大小")]),_._v(" "),v("p",[_._v("刚刚讨论的限流是针对请求的个数进行的, 但并没有考虑到另一个非常关键的问题, 就是"),v("strong",[_._v("请求的大小")]),_._v(". 在负载均衡里曾提过到这个问题, 就是"),v("strong",[_._v("负载均衡算法基本上都没有考虑请求所需的资源")]),_._v(". 同理在限流算法也是如此.")]),_._v(" "),v("p",[_._v("限流是针对请求个数进行的, 那么显然, 如果有两台实例, 一台实例处理的都是小请求, 另一台实例处理的都是大请求, 那么都限流在每秒 100 个请求. 可能第一台实例什么问题都没有, 而第二台实例就崩溃了.")]),_._v(" "),v("p",[_._v("所以如果面试官问到为什么使用了限流, 系统还是有可能崩溃, 或者在负载均衡里面聊到了请求大小的问题, 都可以这样来回答, 关键词是 "),v("mark",[v("strong",[_._v("请求大小")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("限流和负载均衡有点像, 基本没有考虑请求的资源消耗问题. 所以负载均衡不管怎么样, 都会有偶发性负载不均衡的问题, 限流也是如此. 例如即便我将一个实例限制在每秒 100 个请求, 但是万一这个 100 个请求都是消耗资源很多的请求, 那么最终这个实例也可能会承受不住负载而崩溃. 动态限流算法一定程度上能够缓解这个问题, 但是也无法根治, 因为一个请求只有到它被执行的时候, 我们才知道它是不是大请求.")])]),_._v(" "),v("p",[_._v("以上就是我们在回答限流相关问题时的基本思路, 如果可以回答出来, 基本上就可以拿到一个70分的成绩, 你满意吗? 相信你和我一样, 还想要更加出类拔萃一点, 那这时候就要从计算阈值上面下功夫了.")]),_._v(" "),v("h5",{attrs:{id:"计算阈值"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#计算阈值"}},[_._v("#")]),_._v(" 计算阈值")]),_._v(" "),v("p",[_._v("在面试限流的基本回答里面, 已经主动提起了限流阈值难以确定. 那么不出所料, 面试官就会问你怎么确定阈值. 又或者你使用了限流的不同案例, 那么面试官也会问你"),v("strong",[_._v("限流的阈值是怎么确定的")]),_._v(".")]),_._v(" "),v("p",[_._v("总体上思路有四个: "),v("mark",[v("strong",[_._v("看服务的观测数据, 压测, 借鉴, 手动计算")])]),_._v(".")]),_._v(" "),v("p",[_._v("看服务的性能数据属于常规解法, 基本上就是"),v("strong",[_._v("看业务高峰期的 QPS 来确定整个集群的阈值")]),_._v(". 如果要确定单机的阈值, 那就再除以实例个数. 所以可以这样来回答, 关键词是 "),v("strong",[_._v("业务性能数据")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司有完善的监控, 所以可以通过观测到的性能数据来确定阈值. 比如说观察线上的数据, 如果在业务高峰期整个集群的 QPS 都没超过 1000, 那么就可以考虑将阈值设定在 1200, 多出来的 200 就是余量.")]),_._v(" "),v("p",[_._v("不过这种方式有一个要求, 就是服务必须先上线, 有了线上的观测数据才能确定阈值. 并且整个阈值很有可能是偏低的. 因为业务巅峰并不意味着是集群性能的瓶颈. 如果集群本身可以承受每秒 3000 个请求, 但是因为业务量不够, 每秒只有 1000 个请求, 那么这里预估出来的阈值是显著低于集群真实瓶颈 QPS 的.")])]),_._v(" "),v("p",[_._v("注意在回答的时候也解释了这种方法的缺陷, 这算是一个小亮点. 然后可以继续讨论其他的思路, 关键词是 "),v("strong",[_._v("压测")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("不过我个人觉得, 最好的方式应该是在线上执行全链路压测, 测试出瓶颈. 即便不能做全链路压测, 也可以考虑模拟线上环境进行压测, 再差也应该在测试环境做一个压力测试.")])]),_._v(" "),v("p",[_._v("在这个回答里面其实已经回答出了"),v("mark",[v("strong",[_._v("最正确的思路: 做压测, 而且要强调全链路压测")])]),_._v(". 理由很简单, 限流针对的是线上环境, 那么自然要尽可能模拟"),v("strong",[_._v("线上环境")]),_._v(". 最符合这个要求的就是全链路压测了, 它就是直接在线上环境执行的, 因此结果也是最准的.")]),_._v(" "),v("p",[_._v("然后需要进一步解释, "),v("strong",[_._v("怎么利用压测结果")]),_._v(". 大部分性能测试的结果类似于图片里展示的这样, 当然不太可能搞出来那么优雅的图形, 多少会有些偏差.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f2aae0a1846ae59b4ff218b8b742b778-20231223175001-4zf1qn9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从理论上来说, "),v("strong",[_._v("可以选择 A, B, C 当中的任何一个点作为限流的阈值")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("A 是性能最好的点")]),_._v(". A 之前 QPS 虽然在上升, 但是响应时间稳定不变. 在这个时候资源利用率也在提升, 所以选择 A 可以得到"),v("strong",[_._v("最好的性能和较高的资源利用率")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("B 是系统快要崩溃的临界点")]),_._v(". 很多人会选择这个点作为限流的阈值. 这个点响应时间已经比较长了, 但是系统还能撑住. "),v("strong",[_._v("选择这个点意味着能撑住更高的并发, 但是性能不是最好的, 吞吐量也不是最高的")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("C 是吞吐量最高的点")]),_._v(". 实际上, 有些时候压测出来的 B 和 C 可能对应到同一个 QPS 的值. 选择这个点作为限流阈值, 可以得到"),v("strong",[_._v("最好的吞吐量")]),_._v(".")])]),_._v(" "),v("p",[_._v("在回答怎么选之前, 最好给面试官比划一下上面这张图中的三条曲线, 然后解释这三个点, 口诀就是 "),v("strong",[_._v("性能 A, 并发 B, 吞吐量 C")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("综合来说, 如果是性能苛刻的服务, 我会选择 A 点. 如果是追求最高并发的服务, 我会选择 B 点, 如果是追求吞吐量的服务, 我会选择 C 点.")])]),_._v(" "),v("p",[_._v("面试官多半会杠你, 压力测试特别难, 或者有些服务根本测不了, 那怎么办. 这个时候, 需要说点正确但没用的废话, 关键词 "),v("strong",[_._v("压测是基操")]),_._v(". 在表述的时候语气要委婉, 态度要坚决.")]),_._v(" "),v("blockquote",[v("p",[_._v("一般我会认为一家公司应该把压测作为提高系统性能和可用性的一个关键措施, "),v("mark",[_._v("毕竟没有压测数据, 性能优化和可用性改进也不知道怎么下手.")]),_._v(" 所以还是比较建议尽可能把压测搞起来, 反正压测这个东西是迟早要有的.")])]),_._v(" "),v("p",[_._v("然后就要转过话头, 顺着面试官的话往下说, 讨论"),v("strong",[_._v("真的做不了压测的时候怎么确定阈值")]),_._v(". 关键词就是 "),v("mark",[v("strong",[_._v("借鉴")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("不过如果真的做不了, 或者来不及, 或者没资源, 那么还可以考虑参考类似服务的阈值. 比如说如果 A, B 服务是紧密相关的, 也就是通常调用了 A 服务就会调用 B 服务, 那么可以用 A 已经确定的阈值作为 B 的阈值. 又或者 A 服务到 B 服务之间有一个转化关系. 比如说创建订单到支付, 会有一个转化率, 假如说是 90%, 如果创建订单的接口阈值是 100, 那么支付的接口就可以设置为 90.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0c61db166f5445570c28f134c73096c8-20231223175001-4pj8pod.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个时候面试官可能会继续问: 如果这是一个全新的业务呢? 也就是说, 你都没得借鉴. 这个时候就只剩下最后一招了-"),v("mark",[v("strong",[_._v("手动计算")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("实在没办法了, 就只能手动计算了. 也就是沿着整条调用链路统计出现了多少次数据库查询, 多少次微服务调用, 多少次第三方中间件访问, 如 Redis, Kafka 等. 举一个最简单的例子, 假如说一个非常简单的服务, 整个链路只有一次数据库查询, 这是一个会回表的数据库查询, 根据公司的平均数据这一次查询会耗时 10ms, 那么再增加 10 ms 作为 CPU 计算耗时. 也就是说这一个接口预期的响应时间是 20ms. 如果一个实例是 4 核, 那么就可以简单用 1000ms / 10ms * 4 = 400 得到阈值.")])]),_._v(" "),v("p",[_._v("这个时候还可以进一步补充一些手动计算要考虑的事情.")]),_._v(" "),v("blockquote",[v("p",[_._v("手动计算准确度是很差的. 比如说垃圾回收类型语言, 还要刨除垃圾回收的开销, 相当于 400 打个折扣. 折扣多大又取决于垃圾回收频率和消耗.")])]),_._v(" "),v("p",[_._v("最后再升华一下主题.")]),_._v(" "),v("blockquote",[v("p",[_._v("最好还是把阈值做成可以"),v("mark",[_._v("动态调整")]),_._v("的. 那么在最开始上线的时候就可以把阈值设置得比较小. 后面通过观测发现系统还很健康, 就可以继续上调阈值.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-5"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节讨论了限流的主要问题, 包括限流算法, 限流对象以及限流之后的做法. 在讨论怎么计算阈值的问题时, 尤其要 "),v("strong",[_._v("记住里面提到的 ABC 三个点")]),_._v(". 不仅仅是面试中, 在你实际工作中也用得上的.")]),_._v(" "),v("p",[_._v("再次强调一下, 应该在面试前尽可能在公司里面应用一下限流, 同时尝试做一做压测. 如果公司没有这种压测的环境, 那么这正好是你刷 KPI 的机会. 把压测环境准备好, 流程标准化之后, 这件事情本身也可以作为面试时候的一个亮点.")]),_._v(" "),v("p",[_._v("整理的思维导图如下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8f957b9ae283f9bdac1ce4395e3e0f4d-20231223175001-2mfo6t2.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-4"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后你来思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("针对 IP 限流是一个非常常见的限流方案, 那么"),v("strong",[_._v("怎么获得用户的 IP 呢")]),_._v("? 尤其是在请求经过了网关的情况下, 怎么避免自己拿到的是网关的 IP?")]),_._v(" "),v("li",[_._v("我在阈值里面提到的 ABC 三个点, 你能说出你的业务应该使用哪个点吗?")])]),_._v(" "),v("h4",{attrs:{id:"_06-隔离-怎么保证尊贵的vip用户体验不受损"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_06-隔离-怎么保证尊贵的vip用户体验不受损"}},[_._v("#")]),_._v(" 06-隔离:怎么保证尊贵的VIP用户体验不受损?")]),_._v(" "),v("p",[_._v('隔离和前面讨论的熔断, 降级, 限流比起来, 在面试中要 "冷" 一点. 一个很重要的原因是隔离在实际中的应用要比限流这种措施少很多. 尤其是'),v("strong",[_._v("在中小型公司, 很多时候是用不到隔离的")]),_._v(". 但隔离依旧是构建高可用和高性能的微服务架构中的一环, 因为"),v("strong",[_._v("在出现故障的时候, 隔离可以把影响限制在一个可以忍受的范围内")]),_._v(".")]),_._v(" "),v("p",[_._v("比如为 VIP 用户提供单独的服务集群, 普通用户共享一个服务集群. 那么普通用户集群出了问题, VIP 用户一点感觉都没有, 依旧可以正常使用, 这样就可以保证 VIP 用户体验不受损. "),v("strong",[_._v("特别是复杂的, 核心的和规模庞大的服务, 隔离机制就更加重要了")]),_._v(". 否则, 一个小小的故障都能蔓延到整个系统, 就离喜提大礼包不远了.")]),_._v(" "),v("p",[_._v("所以今天就看看隔离在实际工作中形形色色的用法以及两个比较出彩的隔离方案.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-6"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[v("strong",[_._v("隔离是通过资源划分, 在不同服务之间建立边界, 防止相互影响的一种治理措施")]),_._v(".")]),_._v(" "),v("p",[_._v("隔离在实际工作中有很多种做法, "),v("strong",[_._v("从不同的角度可以进行不同类型的隔离")]),_._v(". 一般来说, 使用隔离策略主要是为了达到 3 个目的.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("提升可用性")]),_._v(", 也就是说防止被影响或防止影响别人. 这部分也叫做故障隔离.")]),_._v(" "),v("li",[v("strong",[_._v("提升性能")]),_._v(", 这是隔离和熔断, 降级, 限流不同的地方, 一些隔离方案能够提高系统性能, 而且有时候甚至能做到数量级提升.")]),_._v(" "),v("li",[v("strong",[_._v("提升安全性")]),_._v(", 也就是为安全性比较高的系统提供单独的集群, 使用更加严苛的权限控制, 迎合当地的数据合规要求等.")])]),_._v(" "),v("p",[_._v("一般的原则是 "),v("mark",[v("strong",[_._v("核心与核心隔离, 核心与非核心隔离")])]),_._v(".")]),_._v(" "),v("p",[_._v("注意, 这里有一个常见的误解, 很多人认为核心服务可以放在一起, 实际上并不是. 举例来说, 如果核心服务都放在同一台机器上, 那么这台机器一宕机, 所有的核心服务就都宕机了. 反过来说, 如果核心服务部署在了不同的机器上, 那么其中一台机器宕机了, 也就只有这台机器上的服务崩了, 而其他机器上的服务还是可以继续运行.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/82796c9aa06aaa384f3d7ff371177320-20231223175001-t3fcq3j.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么隔离究竟该怎么样做才能达成提升可用性, 提升性能和提升安全性的目标呢? 其实可以采取的措施也是非常多的, 下面一个个看.")]),_._v(" "),v("h6",{attrs:{id:"机房隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#机房隔离"}},[_._v("#")]),_._v(" 机房隔离")]),_._v(" "),v("p",[_._v("机房隔离也就是会把核心业务单独放进一个机房隔离, 不会和其他不重要的服务混在一起. 这个机房可能会有更加严格的变更流程, 管理措施和权限控制, 所以它的安全性会更高.")]),_._v(" "),v("p",[_._v("一些公司的金融支付业务, 个人隐私类的往往会有独立的机房, 或者至少在逻辑上它们会有完全不同的安全策略和保护措施. 还有一些公司受制于当地的法律法规, 例如数据必须留在本地. 那么这些公司也只能说一个国家或一个地区一个机房.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5357b14148df20e6443987ec88fd380f-20231223175001-v6qmzns.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这种形态下, 其中一个机房崩溃了自然不会对另外一个机房有任何影响.")]),_._v(" "),v("p",[_._v("机房隔离和多活看起来有点像, 但是从概念上来说差异还是挺大的. 这里的"),v("strong",[_._v("隔离指的是不同服务分散在不同的机房, 而多活强调的是同一个服务在不同的城市, 不同的机房里面有副本")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/abe9ed8b43af446279b9c1d2c6f249a5-20231223175001-9ixw7db.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"实例隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#实例隔离"}},[_._v("#")]),_._v(" 实例隔离")]),_._v(" "),v("p",[v("strong",[_._v("实例隔离是指某个服务独享某个实例的全部资源")]),_._v(". 当然这里指的是常规意义上的实例, 比如说在云厂商里面买了一个 4C8G 的机器, 实例隔离就是指服务独享了这个实例, 没有和其他组件共享.")]),_._v(" "),v("p",[_._v("但是这种隔离并没有考虑到这么一种情况, 就是虽然买了很多实例, 但是这些实例在云厂商那里都是同一个物理机虚拟出来的. 这种情况下, 如果物理机有故障, 那么这些虚拟机都会出问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0e83d1ddfe0938766cd78a8672310745-20231223175001-6pbvzi3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在早期还没有云服务的时候, 也有机器隔离的说法. 它指的就是核心服务独享一整个物理机的资源.")]),_._v(" "),v("p",[_._v("在一些小公司里面, 为了节省成本, 一些不太重要的服务就可能会共享同一个实例, 特别是测试环境, 经常在一台机器上部署多个服务, 如果一个服务消耗资源过多, 比如说把 CPU 打满, 所有人的测试服务就都跟着崩了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2e4321221643866yyca302b54c516d80-20231223175001-b90hyxu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而同一个服务的实例合并在一起就构成了集群, 那么这个集群自然也是隔离的.")]),_._v(" "),v("h6",{attrs:{id:"分组隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分组隔离"}},[_._v("#")]),_._v(" 分组隔离")]),_._v(" "),v("p",[_._v("分组隔离其实就是典型的微服务框架分组功能的应用. 它通常是"),v("strong",[_._v("指一起部署的服务上有多个接口或者方法, 那么就可以利用分组机制来达成隔离的效果")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("B 端一个组, C 端一个组")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("普通用户一个组, VIP 用户一个组")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("读接口一个组, 写接口一个组")]),_._v(". 这种也叫做读写隔离. 比如说在生产内容的业务里面, 没有实行制作库和线上库分离的话, 那么就可以简单地把读取内容划分成一个组, 编辑内容划分成另外一个组.")]),_._v(" "),v("li",[v("strong",[_._v("快接口一个组, 慢接口一个组")]),_._v(". 这个和前面的读写隔离可能会重叠, 因为一般来说读接口就是比较快.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/190893a807ed8f7475fdfa4b49c32a11-20231223175001-r4jgvke.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("分组隔离非常灵活, 完全可以根据自己的实际业务来设计不同的隔离策略.")]),_._v(" "),v("h6",{attrs:{id:"连接池隔离和线程池隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#连接池隔离和线程池隔离"}},[_._v("#")]),_._v(" 连接池隔离和线程池隔离")]),_._v(" "),v("p",[_._v("这两种都可以看作是"),v("strong",[_._v("池子隔离")]),_._v(", 只不过一个池子里面放的是"),v("strong",[_._v("连接")]),_._v(", 另一个池子里面放的是"),v("strong",[_._v("线程")]),_._v(". 而且连接池和线程池都不必局限在微服务领域, 例如数据库连接池也是同样可以做隔离的.")]),_._v(" "),v("p",[_._v("这两种措施针对的是同一个进程内的不同服务, 一般的做法都是给核心服务单独的连接池和线程池. 这么做对于性能的改进也是很有帮助的, 尤其是连接池隔离.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/526557d6b9d1c4a90744b362bb4f095f-20231223175001-qnahv6k.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("线程池隔离在 Java 里面被广泛使用, 而在另外一些语言里面则根本没有线程池隔离的概念. 比如说 Go 语言, 虽然 Go 存在所谓的 GMP 调度, 里面有线程的概念, 但是开发者是操作不了线程的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e02664826111c7931ac60cb1b5fbc0c6-20231223175001-5u8lds8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么在 Go 这种语言里面有没有类似的策略呢? 理论上来说, 可以做"),v("strong",[_._v("协程隔离")]),_._v(", 但是就我对大多数框架的了解, 它们都没有提供类似的功能. 毕竟协程过于廉价了, 似乎不太值得做池化. 但是在后面慢任务隔离的案例里面, 可以看到协程池隔离在一些场景下还是有必要的.")]),_._v(" "),v("p",[_._v("与这两个类似的还有"),v("strong",[_._v("进程隔离")]),_._v(", 顾名思义它是指为不同的服务或者业务准备独立的进程. 这种措施在 PHP 里面更加常见. 另外有一种说法是认为"),v("strong",[_._v("容器化本身也属于进程隔离的一种")]),_._v(". 那么这么看起来, 在云原生时代进程隔离就算是应用最广泛的隔离策略了.")]),_._v(" "),v("h6",{attrs:{id:"第三方依赖隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第三方依赖隔离"}},[_._v("#")]),_._v(" 第三方依赖隔离")]),_._v(" "),v("p",[v("strong",[_._v("第三方依赖隔离是指为核心服务或者热点专门提供数据库集群, 消息队列集群等第三方依赖集群")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b388e6316f6c6a27112fab40c3a02066-20231223175001-39o638r.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("正常来说, "),v("strong",[_._v("越是关键的业务, 业务上越是关键的路径, 就越要小心隔离")]),_._v(". 比如经常听到某家公司因为 Redis 共用, 导致某个业务把 Redis 搞崩了, 结果其他更加重要的服务也一起崩溃了的事故报告.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-6"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("首先要记住这些策略, 然后要考虑这些策略能不能用在你维护的服务里面. 如果能, 但是你还没有做, 那么就可以在面试的时候说你计划将来用隔离来保护你的服务.")]),_._v(" "),v("p",[_._v("其次要弄清楚隔离机制在公司的应用情况, 例如可以从以下这些方面去了解.")]),_._v(" "),v("ol",[v("li",[_._v("数据库方面: "),v("strong",[_._v("公司有几个物理上的数据库(包括主从集群), 有没有业务是独享某一个物理数据库的")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("公司有没有准备多个 Redis 实例或者多个集群")]),_._v(". 另外理论上来说开启了持久化功能或者被用作消息队列的 Redis 最好是一个独立的集群, 防止影响正常将 Redis 用作缓存的业务.")]),_._v(" "),v("li",[_._v("其他类似的中间件, "),v("strong",[_._v("包括消息队列, Elasticsearch 等, 是否针对不同业务启用了不同的集群")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("对核心业务, 热点业务在资源配置上有没有什么特别之处")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("在业务上, 有没有针对高价值用户做什么资源倾斜")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("在具体的系统上, 有没有使用连接池隔离, 线程池隔离等机制")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("因为缺乏隔离机制引起的事故报告")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e74038c4ba2598a32f495e17068481f1-20231223175001-lq1prxm.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("其实现实中还有因为"),v("strong",[_._v("组织关系")]),_._v("引起的隔离. 比如公司 A 部门和 B 部门各自有独立的 Redis 集群, 但这并不是出于隔离的目的有意设计的, 而是纯粹因为两个部门的利益冲突才各自维护了一个 Redis 集群. 这一点要注意区分.")]),_._v(" "),v("p",[_._v("隔离最佳的面试策略是"),v("strong",[_._v("把隔离作为构建高可用和高性能微服务的手段之一")]),_._v(", 和熔断, 降级, 限流合并在一起作为一个方案.")]),_._v(" "),v("p",[_._v("如果面试官问到了微服务架构可用性和性能的问题, 那么隔离都可以作为你的回答. 如果前面已经讨论到了熔断, 降级, 限流中的任何一种, 这里都可以顺带提起隔离.")]),_._v(" "),v("p",[_._v("除此之外, 通过"),v("strong",[_._v("下面这些问题把话题引导到隔离")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("连接池和线程池相关的问题")]),_._v(", 可以把隔离作为例子, 证明在连接池和线程池的使用上是很有心得体会的.")]),_._v(" "),v("li",[v("strong",[_._v("如何处理热点")]),_._v("? 可以回答隔离, 一方面可以提升性能, 另一方面可以防止热点被别的业务影响, 同时也可以防止别的业务影响到热点.")]),_._v(" "),v("li",[v("strong",[_._v("某个第三方中间件, 比如 Redis 崩溃之后怎么办")]),_._v("? 那这个时候可以强调给核心业务不同的 Redis 集群, 能够一定程度上缓解这个问题, 毕竟只要核心业务的 Redis 没有崩溃, 不重要的业务的 Redis 崩溃也不是那么难以接受.")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-4"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("不管是面试官直接问隔离, 还是问到如何提高微服务可用性, 都可以列举前面提到的那些隔离措施. 要注意, 为了方便面试官理解, 需要尽可能举例子, 最好是用公司的例子.")]),_._v(" "),v("p",[_._v("这里提供一个例子做参考, 关键词是 "),v("strong",[_._v("BC 端隔离")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前为了保障 C 端用户的服务体验, 我在服务上利用微服务框架的分组功能做了一个简单的隔离. 我们的服务本身部署了八个实例, 我将其中三台实例分组为 B 端. 于是商家过来的请求就只会落在这三台机器上, 而 C 端用户的请求就可以落到八台中的任意一台. 这么做的核心目的是限制住 B 端使用的资源, 但是 C 端就没有做任何限制.")])]),_._v(" "),v("p",[_._v("如果你收集到了一些因为缺乏隔离机制而引起的事故报告, 那么可以进一步讲述这些案例. 这里用 Redis 来举一个例子, 关键词是 "),v("strong",[_._v("大对象")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我在公司的时候就遇到过一个事故. 当时服务原本运行得很好, 结果突然之间 Redis 就卡住了, 导致 Redis 请求大部分超时, 请求都落到了数据库上, 数据库负载猛增, 导致数据库查询也超时. 后来运维排查, 确认了 Redis 在那段时间因为别的业务上线了一个新功能, 这个功能会批量计算数据, 产生的结果会存储在 Redis. 但是这个结果非常庞大, 所以在这个功能运行的时候, Redis 就相当于在频繁操作大对象.")]),_._v(" "),v("p",[_._v("也不仅仅是我们, 所有使用那个 Redis 的业务都受到了影响. 后来再使用 Redis 的时候, 就分成了核心与非核心. 核心 Redis 有更加严格的接入机制和代码 review 机制, 而非核心的就比较随意. 不仅如此, 我们还为高并发的服务设计了数据库限流, 防止再来一次 Redis 失效导致 MySQL 被打崩的事故.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6b3450e83a1f6058afd99fe9dc7b5368-20231223175001-4qypvdo.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以注意到, 我在最后还补充了一段使用限流来保护数据库的话, 那么这就可以将话题带到限流那边. 就像我前面说的, 熔断, 降级, 限流, 隔离 这些保证微服务的高可用措施并不是互相割裂了, 任何问题的解法也不是单一的, 需要将这几种手段内化于心, 融会贯通, 达到收缩自如的效果.")]),_._v(" "),v("p",[_._v("好了, 前面一直在说隔离的方式还有它能达到的目标, 那"),v("strong",[_._v("隔离就没有什么缺点了")]),_._v("吗? 当然有, 关键词就是 "),v("mark",[v("strong",[_._v("贵且浪费")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("隔离本身并不是没有代价的. 一方面, 隔离往往会带来资源浪费. 例如为核心业务准备一个独立的 Redis 集群, 它的效果确实很好, 性能很好, 可用性也很好. 代价就是需要更多钱, Redis 本身需要钱, 维护它也需要钱. 另外一方面, 隔离还容易引起资源不均衡的问题. 比如说在连接池隔离里面, 可能两个连接池其中一个已经满负荷了, 另外一个还是非常轻松. 当然, 公司有钱的话就没有什么缺点了.")])]),_._v(" "),v("p",[_._v("这一段内容可以在整个隔离面试快要结束的时候补充上. 做完前面这些工作, 基本操作就完成了.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-4"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("前面的只是基本操作. 如果想让自己的回答更加出彩, 肯定少不了亮点的加持. 在这里给出两个亮点方案, "),v("strong",[_._v("一是慢任务隔离, 二是制作库与线上库分离")]),_._v(". 可以考虑选择其中一个在面试中使用.")]),_._v(" "),v("h6",{attrs:{id:"慢任务隔离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#慢任务隔离"}},[_._v("#")]),_._v(" 慢任务隔离")]),_._v(" "),v("p",[_._v("这个案例本质上就是"),v("strong",[_._v("线程池隔离")]),_._v(". 你在实际工作中也会经常遇到类似的场景. 其中有两种很常见的场景, 我们会考虑开启一个线程池来处理.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("异步任务")]),_._v(", 比如说收到请求之后直接返回一个已接收的响应, 而后往线程池里面提交一个任务, 异步处理这个请求.")]),_._v(" "),v("li",[v("strong",[_._v("定时任务")]),_._v(", 比如说每天计算一下热榜等.")])]),_._v(" "),v("p",[_._v("这一类场景有一个潜在的隐患, 就是"),v("strong",[_._v("慢任务可能把所有的线程都占掉")]),_._v(". 举一个极端的例子, 假如线程池里最多有 100 个线程, 而绝大多数任务在一秒内就可以执行完毕. 如果说某一个时刻, 来了 100 个至少需要一分钟的慢任务, 这 100 个慢任务就会占据全部的线程, 那么其他普通的任务全都得不到执行.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b266066a7e6f8671987ec62474bfb445-20231223175001-m0rocta.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以要解决这种问题, 就是要考虑甄别出慢任务之后, "),v("strong",[_._v("将这些任务丢到一个单独的线程池里")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们遇到过一个 Bug, 就是定时任务总不能及时得到调度. 后来加上监控之后, 发现是因为存在少数执行很慢的任务, 将线程池中的线程都占满了. 所以我后来引入了线程池隔离机制, 核心就是让慢任务在一个专门的线程池里面执行.")]),_._v(" "),v("p",[_._v("我准备了两个线程池, 一个线程池专门执行慢任务, 一个是执行快任务. 而当任务开始执行的时候, 先在快任务线程池里执行一些简单的逻辑, 确定任务规模, 这一步也就是为了识别慢任务. 比如说根据要处理的数据量的大小, 分出慢任务. "),v("mark",[_._v("如果是快任务, 就继续执行. 否则, 转交给慢任务线程池")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6b5a23bd8da3e577fd9f8087907e3b9c-20231223175001-0qm3opd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以进一步补充如何识别慢任务, 关键词是 "),v("mark",[v("strong",[_._v("时长数据量")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种方案的关键是如何识别慢任务. 最简单的做法就是如果运行时间超过了一个阈值, 那么就转交给慢任务线程池. 这在识别循环处理数据里面比较好用. 只需要在每次进入循环之前检测一下执行时长就可以了. 而其他情况比较难, 因为没办法无侵入式地中断当前执行的代码, 然后查看执行时长.")]),_._v(" "),v("p",[_._v("另外一种方案是根据要处理的数据量来判断. 比如说任务是找到数据库里面符合条件的数据, 然后逐条处理. 那么可以先统计一下数据库有多少行是符合条件的. 如果数据量很多, 就转交给慢任务处理.")])]),_._v(" "),v("p",[_._v("此外这里还有一个可能被面试官问到的问题--业务中断, 业务中断只能依赖于人在业务代码里面嵌入检测代码, 无法做到自动化, 智能化检测并中断. 你会在下节课超时控制里再次见到这个问题.")]),_._v(" "),v("h6",{attrs:{id:"制作库与线上库分离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#制作库与线上库分离"}},[_._v("#")]),_._v(" 制作库与线上库分离")]),_._v(" "),v("p",[_._v("在正常的内容生产平台或者电商平台, 一般都会有"),v("strong",[_._v("制作库和线上库")]),_._v("的概念. 这里就用"),v("strong",[_._v("内容生产平台")]),_._v("来作为例子.")]),_._v(" "),v("p",[_._v("当创作者正在创作的时候, 他们的文章, 视频等内容是存放在制作库的. 等到他们完成创作之后, 点击发布的时候, 就会保存到线上库. 当然现实中从制作库到线上库的步骤并不是那么简单的. "),v("strong",[_._v("比如说内容生产平台都需要经过审核之后才能真正发布到线上库")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1866d9eca66949056d4393944b27a12c-20231223175001-qpjn1cy.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("并且因为本身线上库的数据是只有在制作库同步的时候才会变更, 所以缓存可以做得更加细致. 比如说在真正发布的时候, 就直接同步写入到缓存. 这样阅读请求会直接命中缓存, 就不需要回表了.")]),_._v(" "),v("p",[_._v("在电商领域, 这个过程可能是商家修改商品信息而后发布, 在金融领域可能是录入金融方案再发布. 基本上一端在生产信息, 另外一端在查看信息的业务, 都可以用这个架构来提高可用性和性能.")]),_._v(" "),v("p",[_._v("所以可以参考这个方案来介绍你类似的业务.")]),_._v(" "),v("blockquote",[v("p",[_._v("在我们的业务里面, 采用了制作库和线上库分离的方案来保证业务的可用性和性能. 大体来说, "),v("mark",[_._v("作者在 B 端写作, 操作的都是制作库, 这个过程 C 端读者是没有任何感知的. 当作者点击发布之后, 就会开始同步给审核, 审核通过之后就会同步给线上库. 在同步给线上库的时候, 还会直接同步到缓存, 这样作者的关注者阅读文章的时候就会直接命中缓存")]),_._v(".")]),_._v(" "),v("p",[_._v("后面如果作者要修改文章, 修改的也是 B 端制作库, 等他修改完毕, 就会再次提交审核. 审核完成之前, C 端用户看到的都是历史版本, 这样 B 端和 C 端隔离保证了两边的用户体验. 同时拆成两个数据库之后, C 端线上库几乎都是读流量, 性能很好.")])]),_._v(" "),v("p",[_._v("如果你的公司有类似的业务但是还没有引入这个这种方案, 那么也可以考虑在公司内部重构一下, 加深理解.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-6"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节讨论了常见的隔离方案, 分别是机房隔离, 实例隔离, 分组隔离, 连接池隔离和线程池隔离, 以及第三方依赖隔离, 并且给出了两个方案: "),v("strong",[_._v("慢任务隔离和制作库与线上库分离")]),_._v(". 慢任务隔离可以增加系统的稳定性, 避免因为线程问题影响系统中的其他任务; 而制作库与线上库分离的方式可以保证信息生成端和信息查看端的性能和体验. 在实际工作中有很多类似的业务场景, 如果你已经有类似的案例了, 那么你就采用你的案例来说明问题.")]),_._v(" "),v("p",[_._v("基本面试思路里面强调了应该在最后补充一下隔离的缺点, 这也算是一个面试技巧. 即不管你是在讲自己的方案, 同事的方案, 还是你和面试官在讨论业界的某个方案, 都不要只讲好处不讲缺点. 最佳的策略是"),v("mark",[v("strong",[_._v("讲完优点讲缺点, 讲完缺点讲改进")])]),_._v(". 例如在介绍自己的某个解决方案的时候就可以用这个模板.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/42db9379748bbf90f431ced2a8c5f533-20231223175001-42r8y5t.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("本节思维导图如下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b81ac994cdd7701334c405e678a81e0b-20231223175001-qo88c4y.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-5"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在分组功能里面举了几个例子, 那么如果热点的放一组, 非热点的放一组, 你觉得可不可行? 为什么?")]),_._v(" "),v("li",[_._v("连接池隔离虽然很厉害, 但是很多微服务框架并不支持连接池隔离. 那么你用的微服务框架支持吗? 你可以分析一下原因.")])]),_._v(" "),v("h4",{attrs:{id:"_07-超时控制-怎么保证用户一定能在1s内拿到响应"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_07-超时控制-怎么保证用户一定能在1s内拿到响应"}},[_._v("#")]),_._v(" 07-超时控制:怎么保证用户一定能在1s内拿到响应?")]),_._v(" "),v("p",[_._v("和前面讲的熔断, 限流, 降级和隔离一样, 超时控制也是构建高可用系统的一环, 因为 "),v("strong",[_._v("它能够节省系统资源, 提高资源的有效利用率")]),_._v(".")]),_._v(" "),v("p",[_._v("一般在面试的时候, 关于超时控制, 被问得最多的问题就是调用某个接口时的超时时间是多长, 以及你为什么认为这个超时设置是合理的. 一般我们都能给出一个差不多的回答, 不过如果你能够在超时控制的话题下稍微深入一点, 比如聊一聊"),v("strong",[_._v("监听超时时间, 链路超时控制")]),_._v(", 那你绝对能成为所有候选人中最靓的仔.")]),_._v(" "),v("p",[_._v("所以就来了解超时控制的方方面面, 同时会给出全链路超时控制方案.")]),_._v(" "),v("h5",{attrs:{id:"基础知识"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[v("strong",[_._v("超时控制指在规定的时间内完成操作, 如果不能完成, 那么就返回一个超时响应")]),_._v(".")]),_._v(" "),v("p",[_._v("和超时控制有关的内容, 需要记住以下几点:")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("超时控制的目标或者说好处")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("超时控制的形态")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如何确定超时时间")]),_._v("? 这会是一个面试热点.")]),_._v(" "),v("li",[v("strong",[_._v("超时之后能不能中断业务")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("谁来监听超时时间")]),_._v("?")])]),_._v(" "),v("p",[_._v("下面一个个看.")]),_._v(" "),v("h6",{attrs:{id:"超时控制目标"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#超时控制目标"}},[_._v("#")]),_._v(" 超时控制目标")]),_._v(" "),v("p",[_._v("超时控制有两个目标, 一是"),v("strong",[_._v("确保客户端能在预期的时间内拿到响应")]),_._v('. 这其实是用户体验一个重要理念 "坏响应也比没响应好" 的体现.')]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b4541b78dc513da2591028a317404d49-20231223175001-yeksntq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("二是 "),v("strong",[_._v("及时释放资源")]),_._v(". 这其中影响最大的是"),v("strong",[_._v("线程和连接")]),_._v("两种资源.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("释放线程")]),_._v(": 在超时的情况下, 客户端收到了超时响应之后就可以继续往后执行, 等执行完毕, 这个线程就可以被用于执行别的业务. 而如果没有超时控制, 那么这个线程就会被一直占有. 而像 Go 这种语言, 协程会被一直占有.")]),_._v(" "),v("li",[v("strong",[_._v("释放连接")]),_._v(": 连接可以是 RPC 连接, 也可以是数据库连接. 类似的道理, 如果没有拿到响应, 客户端会一直占据这个连接.")])]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("及时释放资源是提高系统可用性的有效做法")])]),_._v(", 现实中经常遇到的一类事故就是因为缺乏超时控制引起了连接泄露, 线程泄露.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/294bf1836d832237c5192528d3f764d7-20231223175001-shcjahs.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"超时控制形态"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#超时控制形态"}},[_._v("#")]),_._v(" 超时控制形态")]),_._v(" "),v("p",[_._v("超时控制从形态上来看分成两种.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("调用超时控制")]),_._v(", 比如说在"),v("strong",[_._v("调用下游接口")]),_._v("的时候, 为这一次调用设置一个超时时间.")]),_._v(" "),v("li",[v("strong",[_._v("链路超时控制")]),_._v(", 是指"),v("strong",[_._v("整条调用链路被一个超时时间控制")]),_._v(". 比如说业务有一条链路是 A 调用 B, B 调用 C. 如果链路超时时间是 1s, 首先 A 调用 B 的超时时间是 1s, 如果 B 收到请求的时候已经过去了 200ms, 那么 B 调用 C 的超时时间就不能超过 800ms.")])]),_._v(" "),v("p",[_._v("链路超时控制在微服务架构里面用得比较多, 一般在核心服务或者非常看重响应时间的服务里面采用.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/468d49acc6e79ec7a9c75431552a0084-20231223175001-1twocix.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("比如大厂的 App "),v("strong",[_._v("首页接口响应时间都有硬性规定")]),_._v(". 就像某司的要求是 50ms, 也就是说不管后端多复杂, 不管后面调用多少个服务, 响应时间都必须控制在 50ms 以内. 后面会再深入讨论这个问题.")]),_._v(" "),v("h6",{attrs:{id:"确定超时时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#确定超时时间"}},[_._v("#")]),_._v(" 确定超时时间")]),_._v(" "),v("p",[_._v("确定超时时间是一个面试中经常碰到的问题, 常见的 4 种确定超时时间的方式是 "),v("mark",[v("strong",[_._v("根据用户体验来确定, 根据被调用接口的响应时间来确定, 根据压测结果来确定, 根据代码来确定")])]),_._v(".")]),_._v(" "),v("p",[_._v("超时时间要设置合理, 过长可能会因为资源释放不及时而出事故, 过短可能调用者会频繁超时, 业务几乎没有办法执行.")]),_._v(" "),v("blockquote",[v("p",[_._v("方法一：根据用户体验")])]),_._v(" "),v("p",[_._v("一般的做法就是"),v("strong",[_._v("根据用户体验来决定超时时间, 和用户体验有关的性能问题都可以征求产品经理的意见")]),_._v(". 比如产品经理认为这个用户最多只能在这里等待 300ms, 那么超时时间就最多设置为 300ms.")]),_._v(" "),v("p",[_._v("但如果仅仅依靠用户体验来决定超时时间也是不现实的, 比如去问产品经理某个接口对性能要求的时候, 他让你看着办. 那么这个时候就要选择下一种策略了.")]),_._v(" "),v("blockquote",[v("p",[_._v("方法二：根据响应时间")])]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("在实践中, 大多数时候都是根据被调用接口的响应时间来确定超时时间. 一般情况下, 可以选择使用 99 线 或者 999 线 来作为超时时间")])]),_._v(".")]),_._v(" "),v("p",[_._v("所谓的 99 线是指 99% 的请求, 响应时间都在这个值以内. 比如说 99 线为 1s, 那么意味着 99% 的请求响应时间都在 1s 以内. 999 线也是类似的含义.")]),_._v(" "),v("p",[_._v("但是使用这种方式要求这个接口已经接入了类似 Prometheus 之类的可观测性工具, 能够算出 99 线或者 999 线. 如果一个接口是新接口, 你要调用它, 而这时候根本没有 99 线或者 999 线的数据. 那么可以考虑使用压力测试.")]),_._v(" "),v("blockquote",[v("p",[_._v("方法三：压力测试")])]),_._v(" "),v("p",[_._v("简单来说, 可以"),v("strong",[_._v("通过压力测试来找到被调用接口的 99 线和 999 线")]),_._v(". 而且压力测试应该尽可能在和线上一样的环境下进行.")]),_._v(" "),v("p",[_._v("但是就像在限流里面提到的, 很多公司其实内部没有什么压测环境, 也不可能让你停下新功能开发去做压力测试. 那么就无法采用压力测试来采集到响应时间数据. 所以就只剩下最后一个手段, 根据代码来计算.")]),_._v(" "),v("blockquote",[v("p",[_._v("方法四：根据代码计算")])]),_._v(" "),v("p",[_._v("根据代码计算和在限流里面讲的差不多. 假如有一个接口, 里面有三次数据库操作, 还有一次访问 Redis 的操作和一次发送消息的操作, 那么接口的响应时间就应该这样计算:")]),_._v(" "),v("div",{staticClass:"language-bash line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-bash"}},[v("code",[_._v("接口的响应时间 "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" 数据库响应时间 * "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),_._v(" + Redis响应时间 + 发送消息的响应时间\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("如果你觉得不保险, 那么可以在计算出来的结果上再加一点作为余量. 比如通过分析代码认为响应时间应该在 200ms, 那么完全可以加上 100ms 作为余量. 可以告诉这个接口的调用者, 将超时时间设置为 300ms.")]),_._v(" "),v("h6",{attrs:{id:"超时中断业务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#超时中断业务"}},[_._v("#")]),_._v(" 超时中断业务")]),_._v(" "),v("p",[_._v("在面试的时候, 还有一个值得和面试官深入讨论的问题--超时中断业务. "),v("strong",[_._v("所谓的中断业务是指, 当调用一个服务超时之后, 这个服务还会继续执行吗")]),_._v("?")]),_._v(" "),v("p",[_._v("答案是基本上会继续执行, 除非服务端自己主动检测一下本次收到的请求是否已经超时了.")]),_._v(" "),v("p",[_._v("举例来说, 如果业务逻辑有 A, B, C 三个步骤. 假如执行到 B 的时候超时了, 如果代码里面没有检测到, 那么还是会继续执行 C. 但如果 "),v("strong",[_._v("主动")]),_._v(" 检测了超时, 那么就可以在 B 执行之后就返回.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a7581ccd86b90323e8e7053edb06905d-20231223175001-m876xf2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是正常在实践中, 是不会写这种手动检测的繁琐代码的. 所以经常出现一个问题, 就是"),v("strong",[_._v("客户端虽然超时了, 但是实际上服务端已经执行成功了")]),_._v(".")]),_._v(" "),v("p",[_._v("可以看一下这张示意图, 用户第一次提交注册的时候拿到了超时响应, 但是实际上他注册成功了, 数据库写入了注册信息. 所以当他第二次尝试重试的时候, 立刻遇到了重复手机号码的错误.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/182364b44ec65fa6a9ac40862961edb2-20231223175001-rgquace.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不过如果中间件监听超时时间部分设计得好, 它可以帮我们中断一些步骤.")]),_._v(" "),v("h6",{attrs:{id:"监听超时时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#监听超时时间"}},[_._v("#")]),_._v(" 监听超时时间")]),_._v(" "),v("p",[_._v("在微服务框架里面, 一般都是"),v("strong",[_._v("微服务框架客户端来监听超时时间")]),_._v(". 在一些特殊的微服务框架里面, 框架服务端也会同步监听超时时间.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/41997c02b991a271232eb8c29131be89-20231223175001-2762die.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("框架客户端监听超时时间的情况下, 如果在发起请求之前, 就已经超时了, 那么框架客户端根本不会发起请求, 而是"),v("strong",[_._v("直接返回超时响应")]),_._v(". 这等于直接中断了业务的后续步骤.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4d0237cdc6ab4330aaf328024f44a975-20231223175001-nniz9fl.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果框架客户端已经发出了请求, 之后触发了超时时间, 那么框架客户端就会直接返回一个超时错误给应用代码. 后续服务端返回了响应, 框架客户端会直接丢弃.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d85df1a056b5ec775d4f1383c992bfbd-20231223175001-uhkq5o2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而"),v("strong",[_._v("框架服务端监听超时的情况下, 如果在收到请求的时候就已经超时了, 那么框架服务端根本不会调用服务端应用代码, 而是直接给框架客户端返回一个超时响应")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4d5431398940776d93981a1eed6a28d3-20231223175001-jrt3kwh.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而如果在等待业务响应的时候触发了超时, 框架服务端会立刻释放连接, 继续处理下一个请求. 那么当应用返回响应的时候, 它会直接丢弃, 不会再回写响应.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c0cd1c7a467b58149d3dyy123d395ef2-20231223175001-tepqcrp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以看出来"),v("strong",[_._v("不管是客户端根本不发请求, 还是服务端根本不把请求转交给业务, 都能够避免把资源花在没有意义的超时请求上")]),_._v(". 为什么超时请求没有意义呢? 因为用户都已经看到超时的页面了, 所以后端继续处理已经没有意义了.")]),_._v(" "),v("p",[_._v("总体来说, 监听超时时间这个知识点面试官还是不太容易能想到的, 所以在面试的时候如果能深入讨论一下这个问题, 应该可以增加一些亮点.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-7"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("前面讲到的超时控制的目标, 两种形态以及确定超时时间的方法都要记住. 此外要弄清楚公司内是怎么使用超时时间的, 可以收集一些资料.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("你所在公司的核心业务, 尤其是 App 首页之类的, 公司层面上的性能要求是什么? 也就是说响应时间必须控制在多少以内, 然后进一步了解有没有采用链路超时控制")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("自己维护的服务调用下游的时候有没有设置超时时间, 超时时间都是多长")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("数据库查询有没有设置超时时间")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("跟任何第三方中间件打交道的代码有没有设置超时时间")]),_._v("? 例如查询 Redis, 发送消息到 Kafka 等.")])]),_._v(" "),v("p",[_._v("然后要注意在公司里面"),v("mark",[v("strong",[_._v("收集一些跟超时控制相关的事故报告")])]),_._v(". 例如因为没有设置超时时间, 导致数据库连接耗尽或者线程数量飙升等事故报告. 这些事故报告可以在面试的过程中用来解释超时控制的必要性, 或者用来凸显你解决事故的能力.")]),_._v(" "),v("p",[_._v("在面试前也需要提前设想一下, 关于超时控制, 面试官会问到哪些问题? 下面整理了一下最常见的几个问题, 也可以借助这几个问题回忆一下前面的几个知识点.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("如何提高系统的可用性")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("如何防止连接泄露/线程泄露")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("为什么要使用超时? 缺乏超时控制会有什么问题")]),_._v("?(回答超时控制的目标)")]),_._v(" "),v("li",[v("strong",[_._v("怎么确定超时时间")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("超时时间过长有什么问题? 过短有什么问题")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("超时控制应该在客户端还是服务端控制")]),_._v("?")])]),_._v(" "),v("p",[_._v("如果现在"),v("mark",[v("strong",[_._v("调用别的服务, 第三方接口, 中间件")])]),_._v("都没有设置任何超时时间, 或者使用的是默认超时时间, 那就可以尝试自己先手动设置一下超时时间.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-5"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("大多数时候面试官可能就是随便问一下你在调用别的服务的时候有没有设置超时时间, 那么可以简单回答, 关键词是"),v("strong",[_._v("超时控制目标")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我会设置超时时间, 一般来说设置超时时间是为了用户体验和及时释放资源. 比如有一个接口是提供给首页使用的, 整个接口要求的超时时间是不超过 100ms. 这个 100ms 就是公司规定的, 是从用户体验出发确定的超时时间.")])]),_._v(" "),v("p",[_._v('这一步只是说了一个硬性规定 100ms 的例子, 换句话说是从用户体验出发确定的 100ms. 那么面试官就可能会追问: "'),v("strong",[_._v("如果公司没这种规定怎么确定合理的超时时间呢")]),_._v('?". 这时候就可以回答前置知识里面提到的 '),v("strong",[_._v("四种手段")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("没有规定的话, 最好的办法就是从用户体验的角度出发确定超时时间, 这个可以考虑咨询一下产品经理. 如果这个方式不行的话, 就可以考虑根据被调用接口的响应时间, 来确定调用者的超时时间. 比如要调用 A 接口, 如果 A 接口的 999 线是 200ms, 那么就可以把这一次调用的超时时间设置成 200ms. 除了 999 线, 99 线也可以作为超时时间.")]),_._v(" "),v("p",[_._v("如果要调用的是一个新接口, 没有性能数据, 那么就可以考虑执行压测, 然后根据结果选用 99 线或者 999 线. 压测的结果也不仅仅可以用在这里, 也可以用在限流那里. 实在没办法, 还可以根据代码里面的复杂操作来计算一个时间.")])]),_._v(" "),v("p",[_._v("在这个回答里面, 面试官可能从两个角度继续深挖. 第一个是 99 线和 999 线究竟选哪个比较好. 那么可以抓住关键词 "),v("strong",[_._v("可用性")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("原则上是看公司的可用性要求, 要求几个 9 就要几个 9. 如果没有硬性规定, 那么看 99 线和 999 线相差多不多. 不多的话就用 999 线, 多的话就用 99 线.")])]),_._v(" "),v("p",[_._v("第二个是面试官可能会把问题切换到限流相关的内容上, 因为这里提到了 限流, 所以需要做好被提问的心理准备.")]),_._v(" "),v("p",[_._v("紧接可以补一个"),v("strong",[_._v("因为超时控制设置不合理而出现的事故")]),_._v(". 这里提供一个数据库超时的例子供参考, 关键词是 "),v("strong",[_._v("数据库连接")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说, 对任何第三方的调用我都会设置超时时间. 如果没有设置超时时间或者超时时间过长, 都可能引起资源泄露. 比如说早期我们公司就出现过一个事故, 某个同事的数据库查询超时时间设置得过长, 在数据库性能出现抖动的时候, 客户端的所有查询都被长时间阻塞, 导致连接池中的连接耗尽.")])]),_._v(" "),v("p",[_._v("可以把这个案例替换成实际工作中发生的事故, 它能够进一步"),v("strong",[_._v("说明超时控制在保障系统可用性中的作用")]),_._v(".")]),_._v(" "),v("p",[_._v("如果想要尽量避免这样的事故发生, 更好地用超时保护系统, 那就需要一个更加周全的方案了, 就是为系统接入链路超时控制, 这样做用户体验会更好.")]),_._v(" "),v("h5",{attrs:{id:"链路超时控制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#链路超时控制"}},[_._v("#")]),_._v(" 链路超时控制")]),_._v(" "),v("p",[_._v('链路超时控制就是今天的亮点方案, 本身链路超时就是一个非常适合 "一杆子" 打到底的话题. 也就是说从链路超时控制本身可以延伸出许多问题, 所以千万要记得做好话术引导. 当面试官问链路超时控制是什么的时候, 就可以先简单介绍链路超时的'),v("strong",[_._v("基本特征")]),_._v(", 关键词是 "),v("strong",[_._v("链路")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("链路超时控制和普通超时控制最大的区别是链路超时控制会作用于整条链路上的任何一环. 例如在 A 调用 B, B 调用 C 的链路中, 如果 A 设置了超时时间 1s, 那么 A 调用 B 不能超过 1s. 然后当 B 收到请求之后, 如果已经过去了 200ms, 那么 B 调用 C 的超时时间就不能超过 800ms. 因此链路超时的关键是"),v("mark",[_._v("在链路中传递超时时间")]),_._v(".")])]),_._v(" "),v("p",[_._v("最后一句话提到了传递超时时间, 但并没有说怎么传递超时时间, 这就是给面试官追问的机会. 如果面试官追问了, 可以这么回答, 关键词是"),v("strong",[_._v("协议头")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("大部分情况下, 链路超时时间在网络中传递是放在协议头的. 如果是 RPC 协议, 那么就放在 RPC 协议头, 比如说 Dubbo 的头部; 如果是 HTTP 那么就是放在 HTTP 头部. 比较特殊的是 gRPC 这种基于 HTTP 的 RPC 协议, 它是利用 HTTP 头部作为 RPC 的头部, 所以也是放在 HTTP 头部的. 至于放的是什么东西, 就取决于不同的协议是如何设计的了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/08f6c43b8344e63166805b4ea54fa211-20231223175001-ywinfg0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/557433a1f110b645f4ab81cffe9324b0-20231223175001-lrerdvb.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("在最后一句依旧留了一个小尾巴. 这句话是引导向超时时间传递的值究竟是什么的问题. 正常来说, 在链路中传递的可以是"),v("strong",[_._v("剩余超时时间")]),_._v(", 也可以是"),v("strong",[_._v("超时时间戳")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/30492551b757691bffb1cde3b629d847-20231223175001-r4i5cih.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这两者是各有优缺点的. 目前来说"),v("strong",[_._v("剩余超时时间")]),_._v("用得比较多, 一般是以毫秒作为单位传递一个数值. 它的缺点是服务端收到请求之后需要减去网络传输时间, 得到真正的超时时间.")]),_._v(" "),v("p",[_._v("而超时时间戳则涉及到时钟同步的问题, 不过大多数情况下时钟之间的差值都很小, 和超时时间动辄几百毫秒比起来, 不值一提. 所以如果面试官感兴趣, 就继续回答, 关键词是"),v("strong",[_._v("剩余超时时间或超时时间戳")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("一般超时时间传递的就两种: 剩余超时时间或者超时时间戳. 比如剩余 1s, 那么就用毫秒作为单位, 数值是 1000. 这种做法的缺陷就是服务端收到请求之后, 要减去请求在网络中传输的时间. 比如说 C 收到请求, 剩余超时时间是 500ms, 如果它知道 B 到 C 之间请求传输要花去 10ms, 那么 C 应该用 500ms 减去 10 ms 作为真实的剩余超时时间. 不过现实中比较难知道网络传输花了 10ms 这件事.")]),_._v(" "),v("p",[_._v("而传递超时时间戳, 那么就会受到时钟同步影响. 假如说此时此刻, A 的时钟是 00:00:00, 而 B 的时钟是 00:00:01, 也就是 A 的时钟比 B 的时钟慢了一秒. 那么如果 A 传递的超时时间戳是 00:00:01, 那么 B 一收到请求, 就会认为这个请求已经超时了.")]),_._v(" "),v("p",[_._v("当然, 正常来说时钟同步不至于出现那么大的偏差, 大多数时钟偏差几乎可以忽略不计. 不过在时钟回拨的场景下, 还是会有问题. 我之前听说不同云服务商之间的时钟同步问题比较严重, 可能也需要注意.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0729f5336243806eaf335031fbba4e93-20231223175001-l1mxgdv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这个回答里面, 提到了难以知道 10ms 的问题, 那么面试官自然就会问该怎么知道网络传输耗时 10ms. 换句话来说, 怎么计算请求的网络传输时间. 就可以这样回答:")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("计算网络传输时间最好的方式就是使用性能测试")]),_._v(". 在模拟线上环境的情况下, 让客户端发送平均大小的请求到服务端, 采集传输时间, 取一个平均值作为网络传输时间. 另外一个方式就是不管. 比如说正常情况下, A 调用 B, A 和 B 都在同一个机房, 网络传输连 1ms 都不用. 相比超时时间动辄设置为几百毫秒, 这一点时间完全可以忽略不计. 不过万一服务涉及到了跨机房, 尤其是那种机房在两个城市的, 城市还离得远的, 这部分时间就要计算在内.")])]),_._v(" "),v("p",[_._v("还可以额外强调一下, 性能测试要完全模拟线上环境, 否则计算就会有偏差.")]),_._v(" "),v("blockquote",[v("p",[_._v("性能测试一定要尽可能模拟线上环境, 尤其是线上环境可能会有更加复杂的网关和防火墙设置, 这部分也会影响传输速率.")])]),_._v(" "),v("p",[v("strong",[_._v("链路超时还有一个弊端")]),_._v(", 也是面试官经常问的, 就是如果 A 调用 B, B 调用 C 的这条链路的超时时间设置为 1s, 但是 B 这个服务的提供者就说自己是不可能在 1s 内返回响应的, 那么该怎么办?")]),_._v(" "),v("p",[_._v("这时候要坚持最正确的做法, 要求 B "),v("strong",[_._v("优化性能")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这个时候最好的做法是强制要求 B 优化它的性能. 比如说产品经理明确说这条链路就是要在 1s 内返回, 那么 B 就应该去优化性能, 而不是在这里抱怨不可能在 1s 内返回. 不过要是 A 本身超时时间可以妥协的话, 那么 A 调大一点也可以.")])]),_._v(" "),v("p",[_._v("最后的妥协话术, 就是想表达你并不是完全不通人情的. 如果面试你的人是 CTO 之类的领导, 那么他们可能会看重软技能, 就会问如何推动 B 优化性能. 这方面按照公司的跨部门合作流程来回答就可以.")]),_._v(" "),v("p",[_._v("不过还有一个不那么正统充满了人情世故的解决方案, 可以参考.")]),_._v(" "),v("blockquote",[v("p",[_._v("可以考虑请 B 的维护者喝杯奶茶, 吃顿小烧烤, 基本上都能解决问题. 实在不行, 就只能走官方渠道, 找领导和产品经理出面, 去找 B 的维护者的上级. 不过闹到这一步关系就会比较僵, 还是优先考虑请奶茶小烧烤的方案.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-7"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("现在再来问怎么保证用户能够在 1 秒内拿到响应, 你应该对答案了然于胸了吧? 这也是这节课的主题超时控制的目标之一, 也就是"),v("strong",[_._v("确保客户端能在预期的时间内拿到响应, 保证用户的体验")]),_._v(". 此外超时控制还能通过在客户端或服务端监听超时时间来感应到系统超时, 及时释放线程和连接, 保证系统的可用性.")]),_._v(" "),v("p",[_._v("而这个 1 秒又是怎么算出来的呢? 实际上可以通过用户体验, 响应时间, 压力测试和根据代码计算这四种方式来确定具体的超时时间, "),v("strong",[_._v("不宜过长或过短, 过长会浪费客户端资源; 过短可能导致客户端无法处理响应")]),_._v(".")]),_._v(" "),v("p",[_._v("在实际的工作场景中, 超时控制有调用超时控制和链路超时控制两种形态, 而在微服务架构中链路超时控制比较常用. 所以在亮点方案部分对链路超时控制进行了深入的讨论, 需要记住里面的几个关键词: "),v("strong",[_._v("链路, 协议头, 剩余超时时间与超时时间戳")]),_._v(". 可以从这几个关键词出发, 整理自己的思路.")]),_._v(" "),v("p",[_._v("本节思维导图如下：")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6a130372a33674045441yyd254f3b216-20231223175001-i49xriv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-6"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在根据被调用接口的响应时间来确定超时时间里面, 说到可以使用 99 线或者 999 线来作为超时时间. 那么平均响应时间和响应时间中位数, 能不能作为超时时间?")]),_._v(" "),v("li",[_._v("在监听超时那里, 能不能只在服务端那边监听超时, 而客户端完全不管?")])]),_._v(" "),v("h4",{attrs:{id:"_08-调用第三方-下游的接口不稳定性能又差怎么办"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_08-调用第三方-下游的接口不稳定性能又差怎么办"}},[_._v("#")]),_._v(" 08-调用第三方:下游的接口不稳定性能又差怎么办?")]),_._v(" "),v("p",[_._v("今天来聊一个跟微服务架构有很强关联的话题: "),v("strong",[_._v("如何保证调用第三方接口的可用性")]),_._v(".")]),_._v(" "),v("p",[_._v("几乎任何一个系统都难免要跟第三方打交道.")]),_._v(" "),v("ul",[v("li",[_._v("登录注册要跟微信开放平台打交道, 接入扫码登录.")]),_._v(" "),v("li",[_._v("金融要跟银行打交道, 比如结算.")]),_._v(" "),v("li",[_._v("重要功能发验证码, 要跟短信服务商打交道.")]),_._v(" "),v("li",[_._v("人脸识别, 身份认证也要跟供应商打交道.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/12a67b35cee3d228ecaf265c87d95426-20231223175001-e18to69.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以早期我就注意到很多人的简历上都写了自己对接过这一类的 API. 但是我还注意到大多数人对接这些 API 的时候只是简单实现了功能. 换句话来说, 就是"),v("strong",[_._v("完全没有考虑可用性和容错之类的问题")]),_._v(".")]),_._v(" "),v("p",[_._v("实际上, 调用第三方接口是一个常见的场景, 面试官很容易理解, 所以在面试的时候谈到这样的项目, 很容易取得共鸣. 而且"),v("strong",[_._v("可以在上面应用非常多的微服务治理措施")]),_._v(", 和前面学过的内容形成呼应.")]),_._v(" "),v("p",[_._v("所以今天就来深入讨论一下, 如果需要调用一些第三方接口, 而难以推动这个第三方接口的提供者做一些事情的时候, 如何保证自己系统的高可用.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-2"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("正常来说, 和第三方平台打交道的是一个独立的模块还是一个独立的服务, 取决于维护的是一个单体应用还是微服务应用.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2d7c8fff9339e24709079caac6d824b6-20231223175001-whh5qav.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("对于自己系统内这样一个第三方模块或者第三方服务来说, 它要解决的问题也很直观.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("提供一个一致性抽象")]),_._v(", 屏蔽不同第三方平台 API 之间的差异.")]),_._v(" "),v("li",[v("strong",[_._v("提供客户端治理")]),_._v(", 即提供调用第三方平台 API 的重试, 限流等功能.")]),_._v(" "),v("li",[v("strong",[_._v("提供可观测性支持")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("提供测试支持")]),_._v(".")])]),_._v(" "),v("h6",{attrs:{id:"一致性抽象"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一致性抽象"}},[_._v("#")]),_._v(" 一致性抽象")]),_._v(" "),v("p",[_._v("这算是这个模块或者服务最基本的目标. 举个例子, 如果调用的是第三方支付平台, 你们公司支持多种接入方式, 包括微信支付, 支付宝支付.")]),_._v(" "),v("p",[_._v("在这种情况下, 业务方只希望调用你的某个接口, 然后告诉你支付所需要的基本信息, 比如说金额和方式. "),v("strong",[_._v("这个接口的实现就能根据具体的支付方式发起调用, 业务方完全不需要关心其中的任何细节")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/34384ebe0c3a50c27d1f9926aa23084c-20231223175001-3b7xqkj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种一致性抽象会统一解决很多细节问题. 比如不同的通信协议, 不同的加密解密算法, 不同的请求和响应格式, 不同的身份认证和鉴权机制, 不同的回调机制等等. 这会带来两个好处.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("研发效率大幅提高")]),_._v(", 因为业务方不需要了解第三方的任何细节, 所以他们接入一个第三方会是一件很简单的事情.")]),_._v(" "),v("li",[v("strong",[_._v("高可扩展性")]),_._v(", 可以通过扩展接口的方式轻松接入新的第三方, 而已有的业务完全不会受到影响.")])]),_._v(" "),v("p",[_._v("提供了一致性抽象之后, 就可以在这种一致性抽象上做很多事情, 比如说客户端治理.")]),_._v(" "),v("h6",{attrs:{id:"客户端治理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#客户端治理"}},[_._v("#")]),_._v(" 客户端治理")]),_._v(" "),v("p",[_._v("前面讲熔断, 降级, 限流的时候, 实际上都是在"),v("strong",[_._v("服务端或者网关")]),_._v("进行的. 那么这一次就需要在客户端进行治理了. 一般来说, "),v("mark",[v("strong",[_._v("客户端治理有两个关键措施: 限流 和 重试")])]),_._v(".")]),_._v(" "),v("p",[_._v("就拿限流来说, 大部分的第三方平台 API 为了保护自己的系统, 是不允许你频繁发送请求的. 比如说某些银行的接口只允许你一秒钟发送十个请求, 多了就会拒绝服务. 那么自然地, 其实可以在发起调用之前就开启限流, 这样就可以省去一次必然失败的调用.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c0495f7f18b1dbb7e462967ea8b3b0bd-20231223175001-008ebgz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("另外一个重要的措施是"),v("strong",[_._v("重试")]),_._v(". 当调用第三方平台超时的时候, 业务方肯定不希望你直接返回超时响应, 因为他们还要自己处理超时, 比如发起重试等.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a06e5387c108899b8d8ab5d53cdc5dfd-20231223175001-zf7ls4r.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以"),v("strong",[_._v("可以提供重试机制, 并且可以对业务方保持透明")]),_._v(". 但要小心的是, 只有当第三方接口是幂等的时候才能发起重试.")]),_._v(" "),v("p",[_._v("当完成客户端治理之后, 一般是不会出问题的. 但万一业务出问题了怎么办? 这时候就需要可观测性支持, 告诉业务方你的接口稳如泰山, 把锅甩出去.")]),_._v(" "),v("h6",{attrs:{id:"可观测性支持"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#可观测性支持"}},[_._v("#")]),_._v(" 可观测性支持")]),_._v(" "),v("p",[_._v("第三方接口一般都不在自己的控制范围内, 所以一定要做好监控, 比如说接入 Prometheus 和 SkyWalking 等工具. 同时还要考虑提供便利的查询工具, 让自己和业务方都能够快速定位问题.")]),_._v(" "),v("p",[v("strong",[_._v("告警")]),_._v("也是必不可少的. 这些告警分成两类, 一类是给维护这个功能的同事使用的, 另外一类是给业务方用的. 例如, 当监控系统发现第三方平台突然不可用了, 那么它会发出两个告警, 一个是告诉你出事了; 另外一个则是通知业务方第三方平台目前不稳定, 那么业务方就需要确认对他们业务的影响范围, 以及他们是否需要启动一些容错措施.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ff642b6de22yy785ae7d36e695003f53-20231223175001-3dh47uh.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可观测性做得好, 定位和解决问题就会变得很简单. 但是能不能进一步降低一点出问题的概率呢?")]),_._v(" "),v("p",[_._v("当然是可以的, 把测试支持做好, 让业务方多测测, 省得出了问题甩锅给你.")]),_._v(" "),v("h6",{attrs:{id:"测试支持"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#测试支持"}},[_._v("#")]),_._v(" 测试支持")]),_._v(" "),v("p",[_._v("测试支持的核心是要提供 "),v("strong",[_._v("mock 服务")]),_._v(". 例如正常情况下, 业务方调用你的接口, 你会真的调用第三方 API. 但是在测试环境下, 就要考虑返回 mock 响应.")]),_._v(" "),v("p",[_._v("如果第三方平台还有回调机制, 并且在收到回调之后还要通知业务方, 那么还需要模拟这个回调. 比如说信支付接口后面会回调你的一个接口, 告知你支付结果.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7562f3a1bb1a663beb5ffd5f0e60996d-20231223175001-qrxu046.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("使用 mock 服务有很多好处.")]),_._v(" "),v("ul",[v("li",[_._v("没有额外开支. 比如说发短信之类的, 短信是收费的, 那么测试服务如果能避免真的发送短信, 多少也能省一点.")]),_._v(" "),v("li",[_._v("不受制于第三方平台. 有些第三方平台的认证和鉴权机制非常复杂, 在测试环境要发起一次调用几乎不可能, 那么只能用 mock 服务.")]),_._v(" "),v("li",[_._v("可以返回业务方任何预期的响应, 包括成功响应, 失败响应, 甚至还能返回模拟第三方平台超时的响应.")])]),_._v(" "),v("p",[_._v("如果考虑到压测之类的问题, 那么这个 mock 功能就更加必不可少了, 毕竟第三方是不可能配合你做压测的.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-8"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("如果业务需要和第三方平台打交道, 那么你需要了解清楚以下信息.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("你们是否构建了一个一致性的抽象, 屏蔽了不同平台之间的差异")]),_._v("? 比如和短信服务商打交道, 如果你们公司决定换一家短信服务商, 那么你需要做哪些事情, 业务方能否不受影响?")]),_._v(" "),v("li",[v("strong",[_._v("第三方平台有没有治理措施")]),_._v("? 比如说有没有限流机制, 如果有是怎么限流的, 你有没有针对这个限流做对应的客户端限流?")]),_._v(" "),v("li",[v("strong",[_._v("你有没有在和第三方打交道的时候引入重试机制, 以及重试几次, 重试间隔如何, 如果重试最终都失败了怎么办")]),_._v("?")])]),_._v(" "),v("p",[_._v("面试调用第三方这个话题的最佳策略就是将它包装成你整个系统可用性的关键一环. 所以在面试官问到可用性相关内容的时候, 或者直接问你是怎么和第三方打交道的时候, 就可以和他深入讨论这节课的内容.")]),_._v(" "),v("blockquote",[v("p",[_._v("调用第三方相关题目")])]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("你的系统是怎么保证高可用的")]),_._v("? 这个问题要结合前面的熔断、降级、限流和超时控制的内容来起回答。")]),_._v(" "),v("li",[v("strong",[_._v("你在和 xxx 平台打交道的时候，如果他们的服务出现了问题你的系统会怎样")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("在做压测的时候，你怎么解决调用第三方的问题")]),_._v("?")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-6"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("面试官有些时候不一定会想到要深入考察你和第三方打交道的内容, 因为可能他们公司做得就比较差, 所以要考虑主动出击. 这种主动出击和前面的熔断, 降级, 限流, 超时控制差不多. 比如在自我介绍或者在项目介绍的时候, 强调一下系统是一个 "),v("strong",[_._v("高可用")]),_._v(" 的微服务架构.")]),_._v(" "),v("blockquote",[v("p",[_._v("我的系统对可用性要求非常高, 为此我综合使用了熔断, 限流, 降级, 超时控制等措施. 并且这个系统还有一个特别之处, 就是它需要和很多第三方平台打交道. 所以要想保证系统的可用性, 就需要保证和第三方打交道是高可用的.")])]),_._v(" "),v("p",[_._v("这种话术已经在前面的内容里见过了. 当将自己的项目说成是高可用的项目的时候, 那么面试官肯定会逮着你往死里问高可用, 那就能将话题全方位展开, 并且限定在自己熟悉的战场内.")]),_._v(" "),v("p",[_._v("比如当聊到了调用第三方的时候, 可以考虑采用这个话术来介绍你的做法, 关键词是"),v("strong",[_._v("前后对比")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我在刚接手这个项目的时候, 这一块的设计和实现不太行. 总体来说可扩展性, 可用性, 可观测性和可测试性都非常差. 为了解决这个问题, 全方位提高系统的可扩展性, 可用性, 可观测性和可测试性, 我做了比较大的重构.")]),_._v(" "),v("ol",[v("li",[_._v("我重新设计了接口, 提供了一个一致性抽象. (这里可以补充你设计了哪些接口, 然后强调一下效果)重构之后, 研发效率提高了 30%, 并且接入一个全新的第三方, 也能对业务方做到完全没感知.")]),_._v(" "),v("li",[_._v("我引入客户端治理措施, 主要是限流和重试, 并且针对一些特殊的第三方接口, 我还设计了一些特殊的容错方案.")]),_._v(" "),v("li",[_._v("我全方面接入了可观测性平台, 包括 Prometheus 和 Skywalking, 并且配置了告警. 和原来比起来, 现在能够做到快速响应故障了.")]),_._v(" "),v("li",[_._v("我还进一步提供了测试工具, 可以按照业务方的预期返回响应, 比如说成功响应, 失败响应以及模拟接口超时. 针对压测, 我也做了一些改进.")])])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fe24e52f0f8bacddfcd525f9af49c3a8-20231223175001-b026efa.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("注意, 在介绍任何一点的时候都要"),v("strong",[_._v("强调一下最终取得的效果")]),_._v(". 这样能够凸显在改进系统的时候是有计划的, 成体系的.")]),_._v(" "),v("p",[_._v("另外这段话里面有一个地方需要小心, 就是研发效率提升 30%, 这是举例子说的, 而现实中研发效率是很难衡量的. 所以可以换一种说法, 用具体例子来说明研发效率的提高.")]),_._v(" "),v("blockquote",[v("p",[_._v("在重构之前, 原本公司的 A 组要接入我们的接口, 搞了大概一个星期. 后面重构之后, B 组接入我们的接口, 只用了两天. 而且稳定性更好, Bug 更少.")])]),_._v(" "),v("p",[_._v("类似地, 在告警那里也可以强调在完成重构前后的对比.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我们调用第三方接口的时候, 缺乏监控和告警, 以至于只有等用户出现问题联系客服的时候, 或者业务方发现我们出现故障报告过来的时候, 才知道出问题了. 后面我们接入了监控和告警之后, 在第三方接口出问题的短时间内, 就能得到通知, 然后快速启动各种容错预案, 并且通知业务方和第三方.")])]),_._v(" "),v("p",[_._v("最后要进一步总结和引导.")]),_._v(" "),v("blockquote",[v("p",[_._v("在任何跟第三方打交道的场景之下, 都要考虑好第三方崩溃的时候自己的系统怎么容错. 公司或者部门内部的调用出现问题了, 还可以推动同事快速修复. 但是第三方是推不动的, 所以只能是我们调用者考虑容错.")])]),_._v(" "),v("p",[_._v("这里依旧留了一个话柄, 就等着面试官来问"),v("strong",[_._v("怎么容错")]),_._v(", 这也就是在亮点方案里面写的前两点, 可以考虑选择其中符合你业务的来回答.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-5"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这里提供三个可以刷亮点的方向, 分别是 "),v("mark",[v("strong",[_._v("同步转异步, 自动替换第三方和压测支持")])]),_._v(". 可以根据需要与面试的情况, 选择其中一两个.")]),_._v(" "),v("h6",{attrs:{id:"同步转异步"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#同步转异步"}},[_._v("#")]),_._v(" 同步转异步")]),_._v(" "),v("p",[v("strong",[_._v("在一些不需要立刻拿到响应的场景, 如果发现第三方已经崩溃了, 可以将业务方的请求临时存储起来. 等后面第三方恢复了再继续调用第三方处理")]),_._v(". 这种方案一般用于对时效性要求不高的业务. 比如业务方只是要求上报数据, 不要求立刻成功, 那么就可以采用这种方案.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/547aee02b70c135f3ccbd2503779224b-20231223175001-821dvn6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以仔细介绍你的容错方案, 关键词就是 "),v("strong",[_._v("同步转异步")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说推送数据都是尽可能实时推过去, 但是有些时候业务方推过来的数据太多, 又或者第三方崩溃, 那么我就会临时将数据存起来. 后面第三方恢复过来了, 再逐步将数据同步过去. 这算是比较典型的同步转异步用法.")])]),_._v(" "),v("p",[_._v("更进一步, 可以阐述对这个做法的进一步改进, 关键词是 "),v("strong",[_._v("解耦")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种容错机制其实完全可以做成利用消息队列来彻底解耦的形式. 在这种解耦的架构下, 业务方不再是同步调用一个接口, 而是把消息丢到消息队列里面. 然后服务不断消费消息, 调用第三方接口处理业务. 等处理完毕再将响应通过消息队列通知业务方.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8697172b4c7e1f2a2cc9d02ac11e2d99-20231223175001-nkyr60v.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么这种解耦的方式和直接调用的方式合并在一起, 其实就是正常系统对接业务方的两个方案. 所以可以再次总结拔高一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("同步调用与异步解耦两种方式, 可以看作是对接不同业务方的通用范式. 一般而言但凡能异步解耦的, 我绝不搞什么同步调用.")])]),_._v(" "),v("h6",{attrs:{id:"自动替换第三方"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#自动替换第三方"}},[_._v("#")]),_._v(" 自动替换第三方")]),_._v(" "),v("p",[_._v("这种策略和在负载均衡里面提到的有些类似, "),v("strong",[_._v("即调用一个第三方的接口失败的时候, 可以考虑换一个第三方")]),_._v(".")]),_._v(" "),v("p",[_._v("举例来说, 你们公司有 A, B, C 三个短信供应商. 选择使用 A 的时候, 发现 A 一直返回失败的响应, 或者说响应时间很长, 那么就可以考虑自动切换到 B 上.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7f5680e92e2740527582d405ccdyy57d-20231223175001-oy1lr5o.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是这种策略是受制于公司的情况的, 大多数时候公司是没有这种可以切换的服务供应商的. 早期就听过某司使用的短信服务商服务异常, 导致网站在一段时间内都无法发送验证码, 引发了严重事故. 所以可以这样介绍你的方案, 关键词是 "),v("strong",[_._v("自动替换")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高可用性, 降低因为第三方故障引起事故的概率, 我在调用第三方这里引入了自动替换机制. 我们本来有多个第三方, 相互之间是可以替换的, 于是我就做了一个简单的自动切换机制. 当发现第三方接口出现故障的时候, 就会切换到一个新的第三方.")])]),_._v(" "),v("p",[_._v("这里有一些面试官可能会追问的点.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("你怎么知道第三方出问题了")]),_._v("? 这个问题可以参考前面讲过多次的"),v("strong",[_._v("判断服务健康与否")]),_._v("的方式, 比如用响应时间, 错误率, 超时率. 那么自然可以将话题引导到"),v("strong",[_._v("熔断, 降级, 限流")]),_._v("那边.")]),_._v(" "),v("li",[v("strong",[_._v("如果全部可用的第三方都崩溃了怎么办")]),_._v("? 这种问题直接认怂就可以. 因为一家出故障是小概率, 多家同时出故障那就更是小概率事件了, 在这种情况下除了告警也没有别的办法了. 也就是所谓的尽人事, 听天命.")])]),_._v(" "),v("h6",{attrs:{id:"压测支持"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#压测支持"}},[_._v("#")]),_._v(" 压测支持")]),_._v(" "),v("p",[_._v("每当想搞压测的时候, 就会发现"),v("strong",[_._v("第三方接口都是压测路上的拦路虎")]),_._v(".")]),_._v(" "),v("p",[_._v("正常来说, 不能指望第三方会配合你的压测. 可以设想, 类似于微信之类的开放平台是不可能配合你搞什么压力测试的. 甚至即便你是非常强硬的甲方, 你想让乙方配合你做压力测试, 也是不现实的. 所以只能考虑通过 mock 来提供压测支持. 和正常的测试支持比起来, 压测需要做到三件事.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("模拟第三方的响应时间")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("模拟触发你的容错机制")]),_._v(". 如果采用了同步转异步这种容错机制, 那么需要确保在流量很大的情况下, 你确实转异步了; 如果采用的是自动切换第三方, 那也要确保真的如同你设想的那样真的切换了新的第三方.")]),_._v(" "),v("li",[v("strong",[_._v("流量分发")]),_._v(". 如果是在全链路压测的情况下, 压测流量会分发到 mock 逻辑, 而真实业务请求你是真的调用第三方.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73cac15e253c7326f52cda9576196f10-20231223175001-jgl1fz0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么在介绍你的测试支持的时候可以强调一下这个特性.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期为了弄清楚服务的吞吐量和响应时间瓶颈, 我搞过一些压测. 但这些流量不能真的调用第三方, 所以为了解决压测这个问题, 我设计了两个东西.")]),_._v(" "),v("p",[_._v("一个是模拟第三方的响应时间. 不过这种模拟是比较简单的, 就是在代码里面睡眠一段时间, 这段时间是第三方接口的平均响应时间加上一个随机偏移量计算得出的. 另一个是在并发非常高的情况下, 会触发我的容错机制.")]),_._v(" "),v("p",[_._v("而且这里留好了接口, 万一我们公司要做全链路压测了, 我这边也可以根据链路元数据将压测流量转发到 mock 逻辑, 而真实业务请求则会发起真实调用.")])]),_._v(" "),v("p",[_._v('最后一段是假设你并没有实际接触过全链路压测. 如果你接触过, 那么就可以改成 "你已经做到", 而不是 "留好了接口".')]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-8"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节讨论了调用第三方平台接口如何保证可用性的问题. 当和第三方平台打交道的时候, 要做到这四点:  "),v("strong",[_._v("一致性抽象, 客户端治理, 可观测性支持 和 测试支持")]),_._v(". 同时在后面进一步提供了 "),v("strong",[_._v("同步转异步, 自动替换第三方 和 压测支持 三个亮点方案")]),_._v(".")]),_._v(" "),v("p",[_._v("这节课也可以看作是前面讲的熔断, 限流, 降级和超时控制在一个具体场景下的综合运用. 不管你们公司用不用得上这些治理手段, 都要自己去尝试一下, 因为面试需要你用上这些治理手段. 不然整个项目经历平平无奇, 那么连面试的机会都难得, 更加不要说刷出亮点了.")]),_._v(" "),v("p",[_._v("此外, 在这节课还有一个点需要额外注意, 就是"),v("strong",[_._v("强调自己对研发效率的改进")]),_._v(". 研发效率是一个比较难量化的东西, 所以在面试的时候要想办法说服面试官相信你确实提高了研发效率.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fea784a0c5dc685a62bd5a9d9ba4930f-20231223175001-hsguij0.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-7"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考 2 个问题.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司有没有出现什么因为第三方服务不可用引发的故障? 后面你们有没有设计什么改进方案?")]),_._v(" "),v("li",[_._v("你的工作经历中有没有什么内容主要是提高同事研发效率的? 如果有, 你是怎么向面试官介绍这个项目并且让他相信你确实提高了研发效率的?")])]),_._v(" "),v("h4",{attrs:{id:"_09-综合服务治理方案-怎么保证微服务应用的高可用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_09-综合服务治理方案-怎么保证微服务应用的高可用"}},[_._v("#")]),_._v(" 09-综合服务治理方案:怎么保证微服务应用的高可用?")]),_._v(" "),v("p",[_._v("今天来聊一个综合性的话题: 给你一个微服务应用, 你怎么保证它的高可用?")]),_._v(" "),v("p",[_._v("在面试互联网相关岗位的时候, 大部分公司都会看重 "),v("strong",[_._v("高并发, 高可用 和 大数据")]),_._v(" 相关的经验. 不过有没有高并发和大数据的项目经验有点看命. 因为如果你不是在大厂的核心部门, 你是很难遇到真正的高并发和大数据场景的.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("高可用不一样, 即便你维护的系统月活只有一万人, 依旧可以把自己的系统做成高可用的")])]),_._v(". 所以相比之下, 高可用就可以成为面试的主要发力点.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2e2fa14105e4af15de328b87c0467f87-20231223175001-mlja6bg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然也需要意识到, 一个类似淘宝那种量级的系统的高可用和一个简单的后台管理系统的高可用, 含金量是不一样的. 但还是那句话, 又有几个人真的有机会接触到淘宝那种项目呢? 所以如果真的不知道怎么把自己平凡的项目说得比较有特色, 那么就可以参考这节课的内容.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-3"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("一般"),v("mark",[v("strong",[_._v("衡量可用性, 都是用 SLA(Service Level Aggrement)指标, 通常用 N 个九来说明")])]),_._v(". 例如, 当说微服务的可用性是三个九, 是指系统在一段时间内(一般是一年)正常提供服务的时间超过了 99.9%.")]),_._v(" "),v("p",[v("strong",[_._v("那么高可用究竟有多高? 一般是指可用性需要达到三个九")]),_._v(". 当然有些人会认为需要达到四个九, 这并没有硬性的标准. 那么怎么做到高可用呢?")]),_._v(" "),v("p",[_._v("核心有四点:")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("容错")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("限制故障影响范围")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("出现故障可以快速发现, 快速修复")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("规范变更流程")]),_._v(".")])]),_._v(" "),v("h6",{attrs:{id:"容错"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#容错"}},[_._v("#")]),_._v(" 容错")]),_._v(" "),v("p",[_._v("容错是指不管发生了什么, 系统都能正常提供服务, 也就是所谓的 Design for Failure. 用一句俗语来说, 就是"),v("strong",[_._v("凑合用")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/de1f096c592227f7a3e3dfd4f370yyfa-20231223175001-vywhdfu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("系统中可能出问题的组件包括服务本身, 依赖的服务, 还包括依赖的硬件基础设施和软件基础设施")]),_._v(".")]),_._v(" "),v("p",[_._v("在面试的时候, 最重要的是描述怎么"),v("mark",[v("strong",[_._v("保证自己的服务即便在遇到了一些故障的情况下, 整个系统也能继续为用户提供服务")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/aae42b530ca0ebaced69c0aff8308a55-20231223175001-i282h5g.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("其次是软件基础设施如果出问题了, 是否能保证服务还能正常运作. 如果服务不能正常运作, 系统整体也要能运作, 这主要考虑两个点.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("在公司内使用软件基础设施的高可用方案")]),_._v(". 比如在使用 Redis 的时候就不再是使用单机 Redis, 而是改成 Redis Cluster 或直接使用云厂商的 Redis 服务.")]),_._v(" "),v("li",[v("strong",[_._v("做好万一软件崩溃的容错手段")]),_._v(". 比如前面提到如果 Redis 崩溃了, 可以使用限流来保护数据库.")])]),_._v(" "),v("p",[_._v("剩余的内容除了依赖第三方这一个特殊的场景外, 在面试中出现得很少, 这里就不展开说了.")]),_._v(" "),v("p",[_._v("容错的问题就是不管怎么容错, 最终都有可能出错, 所以到了真出错的时候, 就要考虑"),v("strong",[_._v("限制故障影响范围")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"限制故障影响范围"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#限制故障影响范围"}},[_._v("#")]),_._v(" 限制故障影响范围")]),_._v(" "),v("p",[v("strong",[_._v("限制故障影响范围是指万一真的出现了故障, 也要尽可能减轻它的影响范围")]),_._v(". 影响范围可以从三个角度来考虑, "),v("strong",[_._v("尽可能使故障造成的业务损失更小, 被影响的用户更少, 还有被影响的其他组件更少")]),_._v(".")]),_._v(" "),v("p",[_._v("限制影响范围的最佳策略就是"),v("strong",[_._v("隔离")]),_._v(". 一个复杂的系统被划分成独立的不同的服务, 服务内部再进一步细分模块, 核心服务与非核心服务, 尽量降低相互之间的影响.")]),_._v(" "),v("p",[_._v("但是普遍来说, 想要缩小影响范围总是面临两个难点.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("服务互相依赖")]),_._v(", 这种依赖一部分源自业务本身的复杂度, 另外一部分则源自设计不合理. 可以通过改进设计来降低服务之间的依赖, 但是不可能做到彻底没有依赖. 比如说后面提到的解耦方案, 就是通过改进设计来降低服务之间依赖的一个例子.")]),_._v(" "),v("li",[v("strong",[_._v("服务共享一部分基础设施")]),_._v(". 理论上只要有足够多的钱, 能够为每一个服务提供完全独立的基础设施, 就可以彻底解决这个问题. 但是实际中大部分公司连部署两套 Redis 都舍不得, 所以经常听到某某公司因为共享基础设施导致系统崩溃的事故.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/488ba4e9766d8452decf16e724185aa3-20231223175001-uixj0sg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在限制了故障影响范围后, 就要考虑"),v("mark",[v("strong",[_._v("快速发现和快速修复故障")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"快速发现和快速修复故障"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#快速发现和快速修复故障"}},[_._v("#")]),_._v(" 快速发现和快速修复故障")]),_._v(" "),v("p",[_._v("快速发现强调的是"),v("strong",[_._v("完备的观测和告警系统")]),_._v(". 观测"),v("strong",[_._v("不仅要观测服务本身, 也要对各种基础设施, 第三方依赖进行观测")]),_._v(". 尤其是在核心链路上依赖的东西, 都需要进行全方位地观测. 有了观测之后, 还要设置合理的告警. "),v("strong",[_._v("没有告警的观测是没有灵魂的")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("快速恢复则是尽可能减少服务不可用的时间")]),_._v(". 快速修复与其说是一个工程技术问题, 不如说是一个组织建设问题. 它实际上要求每一个组都需要安排人 24 小时值班, 并且每个值班的人都需要了解整个组所维护的项目的细节, 否则出了故障都没人响应, 或者不知道怎么响应.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2a573b2267a765de820bee344fa0b3b1-20231223175001-i69vzxy.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以要想真正做到快速修复, 不能依赖于研发个人的自觉性, 而是要"),v("strong",[_._v("依赖于自动处理故障的机制")]),_._v(", 后面再详细介绍这一机制.")]),_._v(" "),v("h6",{attrs:{id:"规范变更流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#规范变更流程"}},[_._v("#")]),_._v(" 规范变更流程")]),_._v(" "),v("p",[_._v("规范变更流程是指任何一个人都不能随意发布新版本, 也不能随意修改配置. 任何一个变更都要经过 review, 并且做好回退的准备.")]),_._v(" "),v("p",[_._v("实际上, 在实践中最害怕的就是发布新版本或者新配置. 因为原本系统都运作得非常好, 但是一旦上线新功能或者变更配置, 就很容易出现线上故障. 特别是有些时候因为急着修 Bug, 根本没有测试就直接发布新代码或者配置, 导致不仅已有的 Bug 没修好, 还造成了新的问题.")]),_._v(" "),v("p",[_._v("因此"),v("strong",[_._v("变更流程是一定要搞好的, 搞好了变更流程, 可用性就能大幅提升")]),_._v(". 不过这一点和快速修复一样, 都是一个组织问题而不是一个工程技术问题.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-9"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-9"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要准备一个"),v("strong",[_._v("从前端到后端全方位的, 完整的")]),_._v("高可用方案, 而且要仔细思考其中的几个环节.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("所有面向前端用户的接口有没有限流之类的措施, 防止攻击者伪造大量请求把你的系统搞崩")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("所依赖的第三方组件, 包括缓存(如 Redis), 数据库(如 MySQL), 消息队列(如 Kafka)是否启用了高可用方案")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果依赖的某个第三方组件崩溃了, 服务会发生什么事情, 整个系统是否还能正常提供服务")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("所有服务是否选择了合适的负载均衡算法, 是否有熔断, 降级, 限流和超时控制等治理措施")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("你所在公司的上线流程, 配置变更流程等和研发息息相关的流程, 或者说你认为会对系统可用性产生影响的各种流程")]),_._v(".")])]),_._v(" "),v("p",[_._v("接下来的内容里就给出了一个非常全面的高可用方案, 要做的就是根据真实项目经历来改造一下, 并且重新组织一下语言.")]),_._v(" "),v("p",[_._v("在这里使用的都是一些比较普适的例子, 也就是说即便在中小企业也能用上这些例子. 但如果你在大厂, 有机会接触到一些更加高级的高可用方案, 此时应该优先使用那些高级高可用方案. 建议在面试前将整个内容写出来. 面试讲究的是有备无患, 千万别考验自己的临机应变能力.")]),_._v(" "),v("p",[_._v("最佳的面试策略就是在自我介绍的时候提到自己在高可用微服务架构方面的经历, 然后在介绍项目的时候, 展示自己在入职之后大幅度提高了系统可用性的成果. 之后面试官大概率会详细问你这个项目, 以及是怎么提高可用性的. 这时候就可以用到下面的话术了.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-7"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("整个思路可以拆解成几个部分, 分别是"),v("mark",[v("strong",[_._v("发现问题, 计划方案, 落地实施, 取得效果, 后续改进")])]),_._v(". 而且发现问题和取得效果这两个步骤可以通过前后对比来凸显你在这个过程中起到的作用.")]),_._v(" "),v("h6",{attrs:{id:"发现问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#发现问题"}},[_._v("#")]),_._v(" 发现问题")]),_._v(" "),v("p",[_._v("第一个部分发现问题由项目的核心困难, 困难的具体体现, 具体难点三个部分组成.")]),_._v(" "),v("blockquote",[v("p",[_._v("某某业务是公司的核心业务, 它的核心困难是需要保证高可用. 在我刚入职的时候, 这个系统的可用性还是比较低的. 比如说我刚入职的第一个月就出了一个比较严重的线上故障, 别的业务组突然上线了一个功能, 带来了非常多的 Redis 大对象操作, 以至于 Redis 响应非常慢, 把核心服务搞超时了.")]),_._v(" "),v("p",[_._v("后面经过调研, 我总结下来, 系统可用性不高主要是这三个原因导致的.")]),_._v(" "),v("ol",[v("li",[_._v("缺乏监控和告警, 导致难以发现问题, 难以定位问题, 难以解决问题.")]),_._v(" "),v("li",[_._v("缺乏服务治理, 导致某一个服务出现故障的时候, 整个系统都不可用了.")]),_._v(" "),v("li",[_._v("缺乏合理的变更流程. 每次复盘 Bug 时候, 都觉得如果有更加合理的变更流程的话, 那么大部分事故都是可以避免的.")])])]),_._v(" "),v("h6",{attrs:{id:"计划方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#计划方案"}},[_._v("#")]),_._v(" 计划方案")]),_._v(" "),v("p",[_._v("这里有一个常见的误区, 就是在现实中可能做过类似的事情, 但是都是东一榔头西一棒槌, 也就是说想到了啥就做啥. 但是面试的时候, 一定要将这些内容组织得非常有条理, 有计划.")]),_._v(" "),v("p",[_._v("要给面试官留下的印象不仅仅是你能解决问题, 更是你能够有计划地解决问题. 所以一定要有一个非常清晰的, 可执行性高的"),v("strong",[_._v("计划")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("针对这些具体的点, 我的可用性改进计划分成了几个步骤.")]),_._v(" "),v("ol",[v("li",[_._v("引入全方位的监控与告警, 这一步是为了快速发现问题和定位问题.")]),_._v(" "),v("li",[_._v("引入各种服务治理措施, 这一步是为了提高服务本身的可用性, 并且降低不同服务相互之间的影响.")]),_._v(" "),v("li",[_._v("为所有第三方依赖引入高可用方案, 这一步是为了提高第三方依赖的可用性.")]),_._v(" "),v("li",[_._v("拆分核心业务与非核心业务的共同依赖. 这一步是为了进一步提高核心业务的可用性.")]),_._v(" "),v("li",[_._v("规范变更流程, 降低因为变更而引入 Bug 的可能性.")])])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9ec68bf7207dfc2byy0e72945648ff20-20231223175001-d98djh2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果你们公司有非常完善的基础设施和强大的技术实力, 那么可以加上像"),v("strong",[_._v("全链路压测, 混沌工程, 故障演练")]),_._v("等高端方案, 作为整个计划中的一部分.")]),_._v(" "),v("h6",{attrs:{id:"落地实施"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#落地实施"}},[_._v("#")]),_._v(" 落地实施")]),_._v(" "),v("p",[_._v("然后再讲落地实施. 落地实施的时候要补充细节, 同时也可以掺杂一些"),v("strong",[_._v("落地过程中的痛点")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在第一个步骤里面, 就监控来说, 既要为业务服务添加监控和告警, 又要为第三方依赖增加监控, 比如说监控数据库, Redis 和消息队列. 而告警则要综合考虑告警频率, 告警方式以及告警信息的内容是否足够充足, 减少误报和谎报. 本身这个东西并不是很难, 就是非常琐碎, 要一个个链路捋过去, 一个个业务查漏补缺.")]),_._v(" "),v("p",[_._v("就第二个步骤来说, 服务治理包括的范围比较广, 我使用过的方案也比较多, 比如说限流熔断等等.")]),_._v(" "),v("p",[_._v("第三个步骤遇到了比较大的阻力, 主要是大部分第三方依赖的高可用方案都需要资金投入. 比如说最开始使用的 Redis 就是一个单机 Redis, 那么后面我尝试引入 Redis Cluster 的时候, 就需要部署更多的实例.")]),_._v(" "),v("p",[_._v("第四个步骤也是执行得不彻底. 现在的策略就是新的核心业务会启用新的第三方依赖集群, 比如说 Redis 集群, 但是老的核心业务就保持不动.")])]),_._v(" "),v("p",[_._v("你可能发现了, 在上面的回答中, 谈到第三点和第四点的时候都说"),v("strong",[_._v("执行得不太好")]),_._v(". 这会不会给面试官留下不好的印象呢?")]),_._v(" "),v("p",[_._v("其实不会. 因为我陈述的基本上都是事实, 这些困难都是实打实的, 而且也是面试官能理解的. 另一方面, "),v("strong",[_._v("一个方案不可能十全十美, 适当地暴露一些问题能够增强说服力")]),_._v(".")]),_._v(" "),v("p",[_._v('第五个步骤有点特殊, 取决于你在公司的地位. 如果在公司很有话语权, 甚至本身就在带团队, 那么可以直接说你推行了新的变更流程. 如果你是一个纯粹的 "搬砖" 工程师, 那么可以参考这个回答, 关键词是'),v("strong",[_._v("建议")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("第五个步骤是我在公司站稳脚跟之后跟领导建议过几次, 后来领导就制定了新的规范, 主要是上线规范, 包括上线流程, 回滚计划等内容.")])]),_._v(" "),v("h6",{attrs:{id:"取得效果"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#取得效果"}},[_._v("#")]),_._v(" 取得效果")]),_._v(" "),v("p",[_._v("既然这里讨论的是可用性, 那么取得的效果肯定就是可用性方面有多大的改进. 一般来说, "),v("mark",[v("strong",[_._v("建议说可用性达到了三个九")])]),_._v(", 四个九的可用性有点过于夸张了.")]),_._v(" "),v("blockquote",[v("p",[_._v("经过我的改进之后, 现在我维护的服务的可用性从原来不足两个九提升到了三个九.")])]),_._v(" "),v("p",[_._v("同时还可以强调一下, 系统中超出你影响力范围的部分, 可用性还是比较差.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过我的服务还依赖于一些同事提供的服务, 而他们的服务可用性就还是比较差. 我这边只能是说尽量做到容错, 比如说提供有损服务. 后面要想进一步提高可用性, 还是得推动同事去提高可用性.")])]),_._v(" "),v("p",[_._v("如果面试官质疑你"),v("strong",[_._v("为什么三个九也敢说是高可用")]),_._v(", 要怎么回答呢?")]),_._v(" "),v("p",[_._v("其实不用慌, 可以解释一下, 也可以理解为认怂, 关键词是"),v("strong",[_._v("影响力有限")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我也一直在想办法进一步提高可用性, 但是整个系统要做到四个九还是非常难的, 需要整个公司技术人员一起努力才能达到. 我在公司的影响力还局限在我们部门, 困难比较多, 暂时做不到那么高的可用性.")])]),_._v(" "),v("h6",{attrs:{id:"后续改进"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#后续改进"}},[_._v("#")]),_._v(" 后续改进")]),_._v(" "),v("p",[_._v("最后要补充一下你的改进计划. 一般来说, 改进计划都是针对已有方案的缺点, 所以要先讲已有方案的缺点.")]),_._v(" "),v("blockquote",[v("p",[_._v("目前我的服务, 尤其是一些老服务, 相互之间还是在共享一些基础设施. 一个出问题就很容易牵连其他服务, 所以还需要进一步将这些老服务解耦.")])]),_._v(" "),v("p",[_._v("然后可以再举一个非常具体的改进措施, 来增强说服力.")]),_._v(" "),v("blockquote",[v("p",[_._v("比如说, 我一定要让我的全部服务都使用自己所在组的数据库实例, 省得因为别组的同事搞崩了数据库, 牵连到我的业务. 大家一起用一个东西, 出了事别人死不认账, 甩锅都甩不出去.")])]),_._v(" "),v("p",[_._v("讲改进方案有一个好处, 就是它还没实施, 你就可以随便讲, 什么高大上就讲什么.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-6"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("掌握了面试的基本思路之后, 实际上你在这次面试中就基本上能给面试官留下一个不错的印象了. 这里再额外补充一些方案, 可以选择其中一两个来进一步强化你在面试官心目中的形象.")]),_._v(" "),v("h6",{attrs:{id:"异步-解耦"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#异步-解耦"}},[_._v("#")]),_._v(" 异步/解耦")]),_._v(" "),v("p",[_._v("这个方案适用于什么情况呢? 就是"),v("strong",[_._v("某一个业务可以分成两部分. 一部分是必须要同步执行成功的关键步骤, 另外一部分则是可以异步执行的非关键步骤")]),_._v(".")]),_._v(" "),v("p",[_._v("比如在一个简单的创建订单的场景中, 创建订单, 支付是必须要同步执行成功的. 但是另外一些部分, 比如说发邮件通知下单成功, 增加积分这种就不是一定要立刻执行成功的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0c508239245d52f804a17728b28c17aa-20231223175001-2hw63ds.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此在"),v("strong",[_._v("设计高可用微服务的时候有一个技巧或者说原则, 就是能够异步执行的绝对异步执行, 能够解耦的必须解耦")]),_._v(".")]),_._v(" "),v("p",[_._v("这种理念用一句话来形容就是 "),v("strong",[_._v("多做多错, 少做少错, 不做不错")]),_._v(".")]),_._v(" "),v("p",[_._v("因此可以用这个话术来介绍方案, 关键词是 "),v("strong",[_._v("异步/解耦")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我还全面推行了异步/解耦. 我将核心业务的逻辑一个个捋过去, 再找产品经理确认, 最终将所有的核心业务中能够异步执行的都异步执行, 能够解耦的都解耦. 这样在业务里面, 需要同步执行的步骤就大大减少了. 而后续异步执行的动作, 即便失败了也可以引入重试机制, 所以整个可用性都大幅度提升了.")]),_._v(" "),v("p",[_._v("比如在某个场景下, 整个逻辑可以分成很明显的两部分, 必须要同步执行的 A 步骤和可以异步执行的 B 步骤. 那么在 A 步骤成功之后, 再发一条消息到消息队列. 另外一边消费消息, 执行 B 步骤.")])]),_._v(" "),v("h6",{attrs:{id:"自动故障处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#自动故障处理"}},[_._v("#")]),_._v(" 自动故障处理")]),_._v(" "),v("p",[_._v("严格来说, 熔断, 限流和降级也算是自动故障处理. 不过这里说的是有一个"),v("strong",[_._v("独立的系统")]),_._v("来处理业务系统发生的故障.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1d5263e9a4a27yy28f557747bdd80ce6-20231223175001-w4is47f.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("一个问题从发现到找出临时应对方案, 再到付诸实施, 一不留神一个小时就过去了. 所以在达成三个九以后, 如果还想进一步提升可用性, 那就"),v("strong",[_._v("要么降低出事故的概率, 要么提高反应速度")]),_._v(".")]),_._v(" "),v("p",[_._v("人本身做不到长时间精神紧绷 24 小时待命, 并且同一个项目组的项目也很难说了如指掌, 所以自动故障处理机制的重要性不言而喻. 甚至可以说, 如果没有自动故障处理机制, 是不可能达到四个九的可用性的.")]),_._v(" "),v("p",[_._v("这里给一个例子: "),v("mark",[v("strong",[_._v("微服务集群自动扩容")])]),_._v(". 它是指对整个微服务集群进行监控, 如果发现集群负载过高那么就会自动扩容.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/yy9e3fcb6775fc66e45f906e109893d4-20231223175001-pe7o7sn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这么回答, 关键词是 "),v("strong",[_._v("自动扩容")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高整个集群服务的可用性, 我跟运维团队进行密切合作, 让他们支持了自动扩容. 整个设计方案是允许不同的业务方设置不同的扩容条件, 满足条件之后运维就会自动扩容. 比如说我为我的服务设置了 CPU 90% 的指标. 如果这个服务所有节点的 CPU 使用率都已经超过了 90%, 并且持续了一段时间, 那么就会触发自动扩容, 每次扩容会新增一个节点.")])]),_._v(" "),v("p",[_._v("这里用的例子比较简单, 决策的理由也比较简单.")]),_._v(" "),v("blockquote",[v("p",[_._v("CPU 使用率长期处于高位, 基本上代表节点处于高负载状态. 并且强调的是集群里面的节点都超过了这个指标, 防止单一节点超过该指标之后引起不必要的扩容. 比如万一某个节点非常不幸, 处理的都是复杂的请求, 那么它就会处于高负载的状态, 但是其他节点其实负载还很低. 那么这个时候扩容, 并没有什么效果.")])]),_._v(" "),v("p",[_._v("还有一些常见的方案可以参考.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("自动修复数据")]),_._v(", 最常见的就是有一个定时任务比对不同的业务数据, 如果数据不一致, 就会发出告警, 同时触发自动修复动作.")]),_._v(" "),v("li",[v("strong",[_._v("自动补发消息")]),_._v(", 也是通过定时任务等机制来比对业务数据, 如果发现某条消息还没发, 就会触发告警, 同时触发补发消息动作.")])]),_._v(" "),v("p",[_._v("但凡业务有很多需要人手工介入处理的数据问题, 都可以考虑设计一个自动恢复程序, 去自动地发现和修复不一致的数据.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-9"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-9"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("强调一下, 这里给出的整个话术和方案, 要根据实际经验来做调整. 业界有非常多的高可用方案, 可以多学几个, 纳入面试方案里面.")]),_._v(" "),v("p",[_._v("不需要掌握全部的高可用方案, 因为实在太多学不过来. 只需要重点掌握几种, 然后在面试的时候注重引导和把控面试节奏, 将面试内容限制在自己所了解的那几种上就可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6fda777a320e3289dd9169e85b1a99da-20231223175001-uxib0q0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-8"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("四个九代表全年不可用时间不超过 53 分钟")]),_._v(", 那么你知道三个九和五个九又各自代表多少时间吗? 从你个人经历出发, 你认为四个九的可用性, 究竟难不难达成?")]),_._v(" "),v("li",[_._v("除了我这里提到的各种措施以外, 你自己有没有做过其他提高可用性的事情? 你怎么把它整合进你的面试方案里面?")])]),_._v(" "),v("h3",{attrs:{id:"数据库与mysql"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库与mysql"}},[_._v("#")]),_._v(" 数据库与MySQL")]),_._v(" "),v("h4",{attrs:{id:"_10-数据库索引-为什么mysql用b-树而不用b树-🆗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_10-数据库索引-为什么mysql用b-树而不用b树-🆗"}},[_._v("#")]),_._v(" 10-数据库索引:为什么MySQL用B+树而不用B树?🆗")]),_._v(" "),v("p",[_._v("从这节开始将进入数据库这一章. 在实际工作中, 数据库设计得好不好, SQL 写得好不好将极大程度影响系统性能.")]),_._v(" "),v("p",[_._v("所以今天来聊一聊数据库中的第一个话题-索引.")]),_._v(" "),v("p",[_._v("索引在数据库面试中占据了相当大的比重. 但是大部分人面试索引的时候都非常机械, 所以难以在面试官心中留下深刻印象. 索引是一个理论和实践的结合, 今天这节课先分析索引的基本原理, 下节再在 SQL 优化这一个大主题下进一步分析索引设计和优化的实战案例.")]),_._v(" "),v("p",[_._v("索引的内容还是非常多的, 尤其是有很多非常细碎的, 不成体系的点, 记起来非常难. 所以这一节课就会尽量用非常简单的话, 以及一些奇妙的比喻来帮助记忆和索引有关的内容.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-4"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("索引是用来加速查找的数据结构. 绝大多数跟存储, 查找有关的中间件都有索引功能, 但是它们的原理不尽相同.")]),_._v(" "),v("p",[_._v("先来了解一下 B+ 树的定义与特征.")]),_._v(" "),v("h6",{attrs:{id:"b-树"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b-树"}},[_._v("#")]),_._v(" B+树")]),_._v(" "),v("p",[_._v("B+ 树是一种多叉树, 一棵 m 阶的 B+ 树定义如下:")]),_._v(" "),v("ol",[v("li",[_._v("每个节点最多有 m 个子女.")]),_._v(" "),v("li",[_._v("除根节点外, 每个节点至少有 "),v("code",[_._v("[m/2]")]),_._v("​ 个子女, 根节点至少有两个子女.")]),_._v(" "),v("li",[_._v("有 k 个子女的节点必有 k 个关键字.")])]),_._v(" "),v("p",[_._v("这里的关键字可以直观地理解为就是索引全部列的值. B+ 树还有两个特征.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("叶子存放了数据, 而非叶子节点只是存放了关键字")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("叶子节点被链表串联起来了.")])])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4f847baca3d0791yy3f09e3c63yy602d-20231223175001-j4x4j7w.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("前面 B+ 树的定义记不住没关系, 但这两个特征一定要记住. 为了帮助理解和记忆, 下面打个比方.")]),_._v(" "),v("p",[_._v("一棵 B+ 树就像是一个部门. 部门分成管理人员(非叶子节点)和基层员工(叶子节点), 而管理人员只是负责传达命令(只放索引关键字), 具体的事务(存放数据)都是由基层员工来执行的.")]),_._v(" "),v("p",[_._v("基层员工之间为了合作顺畅, 私底下互相都有联系, 对应到 B+ 树上就是叶子节点被链表连在一起.")]),_._v(" "),v("p",[_._v("B+ 树用于数据库索引有 3 大优势.")]),_._v(" "),v("ol",[v("li",[_._v("B+ 树的高度和二叉树之类的比起来更低, 树的高度代表了查询的耗时, 所以"),v("strong",[_._v("查询性能更好")]),_._v(".")]),_._v(" "),v("li",[_._v("B+ 树的叶子节点都被串联起来了, "),v("strong",[_._v("适合范围查询")]),_._v(".")]),_._v(" "),v("li",[_._v("B+ 树的非叶子节点没有存放数据, 所以"),v("strong",[_._v("适合放入内存中")]),_._v(".")])]),_._v(" "),v("p",[_._v("很多人都能记住 B+ 树的前两个优势, 但是很容易忽略第三个优势. 事实上, 在讨论使用索引提高查询性能的时候, "),v("strong",[_._v("一个默认的前提就是索引本身会全部装进内存中, 只有真实的数据行会放在磁盘上")]),_._v(". 否则索引也放在磁盘上的话, 使用索引的效果也就不明显了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/8be51ff8f95900e1a1597431b5e6a025-20231223175001-sy9w53g.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"索引分类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引分类"}},[_._v("#")]),_._v(" 索引分类")]),_._v(" "),v("p",[_._v("索引是在学习索引过程中一个非常容易迷惘的点, 因为 MySQL 的索引站在不同的角度, 就有不同的说法.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("根据叶子节点是否存储数据来划分")]),_._v(", 可以分成"),v("strong",[_._v("聚簇索引")]),_._v("和"),v("strong",[_._v("非聚簇索引")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果某个索引包含某个查询的所有列")]),_._v(", 那么这个索引就是"),v("strong",[_._v("覆盖索引")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果索引的值必须是唯一的")]),_._v(", 不能重复, 那么这个索引就是"),v("strong",[_._v("唯一索引.")])]),_._v(" "),v("li",[v("strong",[_._v("如果索引的某个列, 只包含该列值的前一部分")]),_._v(", 那么这个索引就是"),v("strong",[_._v("前缀索引")]),_._v(". 比如在一个类型是 varchar(128) 的列上, 选择前 64 个字符作为索引.")]),_._v(" "),v("li",[v("strong",[_._v("如果某个索引由多个列组成")]),_._v(", 那么这个索引就是联合索引.")]),_._v(" "),v("li",[v("strong",[_._v("全文索引")]),_._v(" 是指用于支持文本模糊查询的索引.")]),_._v(" "),v("li",[v("strong",[_._v("哈希索引")]),_._v(" 是指使用哈希算法的索引, 但是 MySQL 的 InnoDB 引擎并不支持这种索引.")])]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("一个索引可以同时是覆盖索引, 唯一索引, 前缀索引和组合索引, 站在不同的角度去看待索引就会有不同的说法")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"聚簇索引和非聚簇索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#聚簇索引和非聚簇索引"}},[_._v("#")]),_._v(" 聚簇索引和非聚簇索引")]),_._v(" "),v("p",[v("strong",[_._v("如果索引叶子节点存储的是数据行, 那么它就是聚簇索引, 否则就是非聚簇索引")]),_._v(".")]),_._v(" "),v("p",[_._v("简单来说, 某个数据表本身就可以看作是一棵使用主键搭建起来 B+ 树, 这棵树的叶子节点放着表的所有行. 而其他索引也是 B+ 树, 不同的是它们的"),v("strong",[_._v("叶子节点存放的是主键")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b678418551507cf9a91519b524fed0c0-20231223175001-6myv678.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("有了这种区分, 就能理解所谓"),v("mark",[v("strong",[_._v("回表")])]),_._v("了. 如果查询一张表用到了索引, 那么数据库就会"),v("strong",[_._v("先在索引里面找到主键, 然后再根据主键去聚簇索引中查找, 最终找出数据")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ea5f8fe7644f030bbe4ef1f03348yy63-20231223175001-0zwtv15.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如图所示, 查询的时候先沿着绿色的线条"),v("strong",[_._v("在非聚簇索引中找到主键")]),_._v(". 然后拿着主键再去下面沿着黄色的线条找到数据行. "),v("strong",[_._v("这个数据行存放在磁盘里, 所以触发磁盘 IO 之后能够读取出来. 磁盘 IO 是非常慢的, 因此回表性能极差, 在实践中要尽可能避免回表")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"覆盖索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#覆盖索引"}},[_._v("#")]),_._v(" 覆盖索引")]),_._v(" "),v("p",[_._v("如果查询的列全部都在某个索引里面, 那么数据库可以直接把索引存储的这些列的值给你, 而不必回表.")]),_._v(" "),v("p",[_._v("比如有一个用户表 user_tab, 在上面的 id 和 name 两列上创建了一个组合索引 "),v("code",[_._v("<id, name>")]),_._v("​, 那么对于这个查询来说 "),v("code",[_._v("SELECT id, name FROM user_tab WHERE id = 123")]),_._v("​, SELECT 关键字后面的 id 和 name 两列都在这个索引里, 那么就可以直接用索引的数据, 不必回表查询了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ef6b9fbf89221a8d069e6cac5cb9f87b-20231223175001-pj114h9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么"),v("strong",[_._v("这个索引在这个查询下就是一个覆盖索引")]),_._v(". 所以覆盖索引并不是一个独立的索引, 而是某个索引相对于某个查询而言的.")]),_._v(" "),v("p",[_._v("针对这个特性, 优化 SQL 性能里面有两种常见的说法.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("只查询需要的列")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("针对最频繁的查询来设计覆盖索引")]),_._v(".")])]),_._v(" "),v("p",[_._v("这两种说法本质上都是为了"),v("mark",[v("strong",[_._v("避免回表")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"索引的最左匹配原则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引的最左匹配原则"}},[_._v("#")]),_._v(" 索引的最左匹配原则")]),_._v(" "),v("p",[_._v("索引在查询中是按照最左匹配原则来使用的, 细究起来这个原则还是有点难以理解. 用一个例子来解释最左匹配原则的运行机制. 比如创建了一个在 A, B, C 三个列上的组合索引 "),v("code",[_._v("<A, B, C>")]),_._v("​. 下面用一个表格来展示一下索引列的值的关系.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/47eb1d5a892461ac54ee312937293c9d-20231223175001-ij999cd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以看到: "),v("strong",[_._v("A 是绝对有序的; 在 A 确定的情况下, B 是有序的; 在 A 和 B 都确定的情况下, C 是有序的")]),_._v(".")]),_._v(" "),v("p",[_._v("那么反过来说:")]),_._v(" "),v("ul",[v("li",[_._v("如果 A 的值不确定, 那么 B 和 C 都是无序的. 例如当 A 取值可能为 1 或者 2 的时候, B 的取值可能是 "),v("code",[_._v("(23, 44, 31)")]),_._v("​.")]),_._v(" "),v("li",[_._v("如果 A 的值确定, 但是 B 的值不确定, 那么 C 是无序的. 例如当 A=1 而 B 可能是 44 或者 31 的时候, C 的值可能是 "),v("code",[_._v("(122, 132, 109)")]),_._v("​.")])]),_._v(" "),v("p",[_._v("所以执行一个 "),v("code",[_._v("WHERE A=a1 AND B=b1 AND C=c1")]),_._v("​ 的查询就类似于:")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" a in A "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),_._v("mark"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" a1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" b in B "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("/")]),_._v("mark"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" b1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" c in C "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" c "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" c1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n              "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 这就是要的数据, 拿到主键之后去磁盘里面加载出来")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br"),v("span",{staticClass:"line-number"},[_._v("12")]),v("br"),v("span",{staticClass:"line-number"},[_._v("13")]),v("br")])]),v("p",[_._v("从这个角度出发就能理解其他最左匹配原则的情况了.")]),_._v(" "),v("ul",[v("li",[_._v("如果查询条件是 "),v("code",[_._v("WHERE A = a1 AND B = b1")]),_._v("​, 那么可以推断出来, 数据库只会应用外层的两重循环, 不会对 C 进行过滤.")])]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" a in A "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),_._v("mark"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" a1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" b in B "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("/")]),_._v("mark"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" b1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 这就是要的结果, 去磁盘里面读取")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br")])]),v("ul",[v("li",[_._v("如果查询条件是 "),v("code",[_._v("WHERE A = a1 OR B = b1")]),_._v("​, 那么这个查询"),v("strong",[_._v("并不会")]),_._v("使用这个索引.")])]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" a in A "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" a1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      as "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("append")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("as"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" a"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" b in B "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" b1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      bs "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("append")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("bs"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" b"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// as 和 bs 的并集就是要的结果")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br")])]),v("ul",[v("li",[_._v("如果查询条件是 "),v("code",[_._v("WHERE A=a1 AND B > b1 AND C = c1")]),_._v("​, 那么这个查询只会使用索引的 A 和 B 两列.")])]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" a in A "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" a1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" b in B "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" b1 "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// C 是无序的, 所以用不了. 可以从前面的表格里面看出来")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 比如 b > 23 之后, 对应的 C 是乱序的")]),_._v("\n          "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 这就是要的结果, 去磁盘里面读取")]),_._v("\n        "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br")])]),v("ul",[v("li",[_._v("如果查询条件是 "),v("code",[_._v("WHERE A !=a1")]),_._v("​, 那么这个查询也不会使用索引.")])]),_._v(" "),v("p",[_._v("这里整理了一个简单的口诀用于判断会不会使用索引. 按照组成索引的列的顺序, 从左往右: "),v("mark",[v("strong",[_._v("AND 用 OR 不用, 正用反不用, 范围则中断")])]),_._v(".")]),_._v(" "),v("p",[_._v("这个口诀是一个简化之后的版本, 还有一些意外情况是不符合这个口诀描述的规律的. 比如 "),v("code",[_._v("M = 1 OR N = 2")]),_._v("​, 如果单列 M 上有一个索引, 并且单列 N 上也有一个索引, 那么还是可能会使用 M 和 N 上的两个索引.")]),_._v(" "),v("p",[_._v("在实践中, 用索引还是不用索引, 就一个原则: "),v("mark",[v("strong",[_._v("看 EXPLAIN 命令的输出")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"索引的代价"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引的代价"}},[_._v("#")]),_._v(" 索引的代价")]),_._v(" "),v("p",[_._v("索引并不是没有代价的, 它会消耗很多的系统资源.")]),_._v(" "),v("ol",[v("li",[_._v("索引本身需要存储起来, 消耗"),v("strong",[_._v("磁盘空间")]),_._v(".")]),_._v(" "),v("li",[_._v("在运行的时候, 索引会被加载到内存里面, 消耗"),v("strong",[_._v("内存空间")]),_._v(".")]),_._v(" "),v("li",[_._v("在增删改的时候, 数据库还需要"),v("strong",[_._v("同步维护索引")]),_._v(", 引入额外的消耗.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7c55f215a48235fba933b87b591d38cf-20231223175001-w6788t2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v('这部分内容也需要记住, 因为现在有一些面试官的套路就是突然问你违反直觉的问题. 例如正常都认为索引非常好, 有很多优点, 那么面试官就可能突然问你 "使用索引有什么问题", "索引有什么坏处" 等问题.')]),_._v(" "),v("h5",{attrs:{id:"面试准备-10"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-10"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("首先要弄清楚公司内使用索引的情况, 或者你所在公司使用过的各种索引, 以及"),v("strong",[_._v("有没有出现索引设计不当引发的线上故障")]),_._v(".")]),_._v(" "),v("p",[_._v("如果有意为自己打造掌握了高性能架构的人设, 那么面试索引的最佳策略就是在自我介绍或者介绍项目的时候提及索引和索引优化.")]),_._v(" "),v("p",[_._v("在面试中有一种情况是比较棘手的, 即面试官给出一个表定义, 然后手写一个 SQL, 要你判断这个 SQL 会不会使用索引. 平时要刻意练习一下, 省得面试的时候被打个措手不及. 遇到这种题目, 还要注意强调一点, 就是回答都是建立在"),v("strong",[_._v("一般情况")]),_._v("下. 因为有些面试官会故意不告诉你表中数据大小, 有没有其他索引等情况.")]),_._v(" "),v("p",[_._v("在回答完之后, 他可能会批评你没有考虑到数据库压根不使用索引的可能性. 所以回答完他的问题之后, 你加一段话.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("我刚才的分析都是基于一般情况, 但是如果说数据库还有别的索引, 或者查询条件过滤效果不好导致数据库压根不使用索引的情况, 那就是另外一个问题了")]),_._v(".")])]),_._v(" "),v("p",[_._v('这个 "免责声明" 也能够将面试官引导到后面的进阶亮点 "为什么数据库不使用索引" 中.')]),_._v(" "),v("p",[_._v("如果面试官问到了这些问题, 那么可以将话题引导到索引下.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("你有没有做过性能优化")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("你是否了解 B 树, B+ 树")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("你知道聚簇索引, 覆盖索引吗")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("数据库一定会使用索引吗")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("使用索引性能一定好吗")]),_._v("? 这个问题要综合考虑索引本身的开销, 以及数据库压根不用索引的情况.")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-8"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("如果你在简历, 自我介绍或者项目介绍任何一个地方提及了自己懂索引原理, 索引设计和优化技巧, 那么面试官肯定就会问你索引有关的东西.")]),_._v(" "),v("p",[_._v('如果面试官问索引问得非常细, 例如 "什么是覆盖索引" 这种, 只需要按照前置知识里面的内容回答就可以.')]),_._v(" "),v("p",[_._v("如果面试官问得比较笼统, 就可以用这里介绍索引的话术, 可以根据自己的需要选择回答全部或者只使用一部分. 这个话术由 "),v("strong",[_._v("B+树, 索引分类, 最左匹配原则")]),_._v(" 三个部分组成.")]),_._v(" "),v("blockquote",[v("p",[_._v("从数据结构上来说, 在 MySQL 里面索引主要是 B+ 树索引. 它的查询性能更好, 适合范围查询, 也适合放在内存里.")]),_._v(" "),v("p",[_._v("MySQL 的索引又可以从不同的角度进一步划分. 比如说根据叶子节点是否包含数据分成聚簇索引和非聚簇索引, 还有包含某个查询的所有列的覆盖索引等等. 数据库使用索引遵循最左匹配原则. 但是最终数据库会不会用索引, 也是一个比较难说的事情, 跟查询有关, 也跟数据量有关. 在实践中, 是否使用索引以及使用什么索引, 都要以 EXPLAIN 为准.")])]),_._v(" "),v("p",[_._v("在这样一个话术中设计了几个可以引导的点, 面试官是比较有可能进一步追问的.")]),_._v(" "),v("ol",[v("li",[_._v("为什么 MySQL 用了 B+ 树, 而没有用 B 树? 在这个问题的基础上, 面试官可能会进一步问, 二叉树, 红黑树和跳表之类的数据结构用作索引是否合适.")]),_._v(" "),v("li",[v("strong",[_._v("回表以及和回表密切相关的覆盖索引")]),_._v(". 从这一个问题又可以进一步引申到索引优化和 SQL 优化上. 这些索引的内容下节会学习.")]),_._v(" "),v("li",[_._v("数据库不使用索引的几种可能.")])]),_._v(" "),v("p",[_._v("这些问题来一一解决.")]),_._v(" "),v("h5",{attrs:{id:"亮点1-mysql为什么使用b-树"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点1-mysql为什么使用b-树"}},[_._v("#")]),_._v(" 亮点1:MySQL为什么使用B+树?")]),_._v(" "),v("p",[_._v("回答这个问题, 就不能仅仅局限在 B+ 树和 B 树上, "),v("strong",[_._v("要连带着二叉树, 红黑树, 跳表一起讨论")]),_._v(". 总结起来, 在用作索引的时候, 其他数据结构都有一些难以容忍的缺陷.")]),_._v(" "),v("ul",[v("li",[_._v("与 B+ 树相比, 平衡二叉树, "),v("strong",[_._v("红黑树在同等数据量下, 高度更高, 性能更差")]),_._v(", 而且它们会频繁执行再平衡过程, 来保证树形结构平衡.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/98e3c18b24a864cd47c500553d01e9b3-20231223175001-liq7oas.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[_._v("与 B+ 树相比, "),v("strong",[_._v("跳表在极端情况下会退化为链表, 平衡性差")]),_._v(", 而数据库查询需要一个可预期的查询时间, 并且跳表需要更多的内存.")]),_._v(" "),v("li",[_._v("与 B+ 树相比, "),v("strong",[_._v("B 树的数据存储在全部节点中, 对范围查询不友好")]),_._v(". 非叶子节点存储了数据, "),v("strong",[_._v("导致内存中难以放下全部非叶子节点")]),_._v(". 如果内存放不下非叶子节点, 那么就意味着查询非叶子节点的时候都需要磁盘 IO.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4aae0280d5c58035e387e9027577e92b-20231223175001-v2ldwrn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此一个数据结构是否适合数据库索引, 取决于这种数据结构的增删改查性能. 并且在关系型数据库里面, 还额外要求对范围查询友好, 减少内存消耗.")]),_._v(" "),v("h5",{attrs:{id:"亮点2-为什么数据库不使用索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点2-为什么数据库不使用索引"}},[_._v("#")]),_._v(" 亮点2:为什么数据库不使用索引?")]),_._v(" "),v("p",[_._v("实际上, 数据库在一些特殊的情况下可能并不会使用任何索引. 例如在前面的索引 "),v("code",[_._v("<A, B, C>")]),_._v("​ 的例子中, 假设 A 的所有值都是正数, 然后查询条件 "),v("code",[_._v("WHERE A > -1")]),_._v("​, 那么这个时候数据库会觉得还不如直接全表扫描, 那么虽然有一个索引看起来能用, 但是最终并不会用.")]),_._v(" "),v("p",[_._v("我也在面试准备那部分提醒过, 要小心面试官挖坑. 总结起来, 数据库可能不使用索引的原因有以下几种:")]),_._v(" "),v("ul",[v("li",[_._v("使用了 "),v("code",[_._v("!=")]),_._v("​, "),v("code",[_._v("LIKE")]),_._v("​ 之类的查询.")]),_._v(" "),v("li",[v("strong",[_._v("字段区分度不大")]),_._v(". 比如 status 列只有 0 和 1 两个值, 那么数据库也有可能不用.")]),_._v(" "),v("li",[v("strong",[_._v("使用了特殊表达式")]),_._v(", 包括数学运算和函数调用.")]),_._v(" "),v("li",[v("strong",[_._v("数据量太小")]),_._v(", 或者 MySQL 觉得全表扫描反而更快的时候.")])]),_._v(" "),v("p",[_._v('稍微强调一下, 这里说的是 "'),v("strong",[_._v("可能")]),_._v('不使用索引", 不是说一定不使用索引. 比如说 LIKE 查询, 如果只是 '),v("code",[_._v("LIKE abc%")]),_._v("​ 这种前缀查询, 那么还是可能用索引的.")]),_._v(" "),v("p",[_._v("还可以进一步解释 FORCE INDEX(强迫使用索引), USE INDEX(使用索引)或者 IGNORE INDEX(忽略索引)之类的 SQL 提示, 关键词是"),v("strong",[_._v("取决于数据库.")])]),_._v(" "),v("blockquote",[v("p",[_._v("虽然很多数据库都支持类似于 FORCE INDEX, USE INDEX 和 IGNORE INDEX 之类的特性, 但是使用这一类功能的时候, 要千万注意数据库是怎么支持的. 有些数据库是根本不管这些提示, 有些则是特定情况下不管. 当然最佳实践还是不要用这些东西, 逼不得已的时候比如说要优化性能了再考虑使用.")])]),_._v(" "),v("p",[_._v("然后可以以一种比较轻松的语气来引导到下一个亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("有一种说法是含有 NULL 的列上的索引会失效, 不过这个说法并不准确, 实际上 MySQL 还是会尽可能用索引的.")])]),_._v(" "),v("p",[_._v("之所以要让语气比较轻松, 是害怕对面的面试官就抱有这种错误的观点. 语气轻松比较不容易激起逆反心理.")]),_._v(" "),v("h5",{attrs:{id:"亮点3-索引与null"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点3-索引与null"}},[_._v("#")]),_._v(" 亮点3:索引与NULL")]),_._v(" "),v("p",[_._v('通常用 NULL 来表达 "不知道", "不存在" 等语义. 而数据库通常也会针对 NULL 来做一些特殊的处理.')]),_._v(" "),v("p",[_._v("MySQL 的索引对 NULL 的支持稍微有点与众不同. 首先 MySQL 本身会尽可能使用索引, 即便索引的某个列里面有零值, 并且 IS NULL 和 IS NOT NULL 都可以使用索引.")]),_._v(" "),v("p",[_._v("其次 MySQL 的唯一索引允许有多行的值都是 NULL. 也就是说可以有很多行唯一索引的列的值都是 NULL. 但不管怎么说, "),v("strong",[_._v("使用 NULL 都是一个比较差的实践")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-10"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-10"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节主要学习了索引的基本原理. 需要重点掌握索引的数据结构, B+ 树原理, 索引分类, 回表, 以及索引在查询中的运行原理.")]),_._v(" "),v("p",[_._v("此外如果想要在面试中刷出亮点, 需要从下面几个方向去努力.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("MySQL 为什么使用 B+ 树")]),_._v("? 要综合对比不同的数据结构的特性.")]),_._v(" "),v("li",[v("strong",[_._v("为什么数据库不使用索引")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("索引与 NULL 的特殊之处")]),_._v(".")])]),_._v(" "),v("p",[_._v("前面还提到了一个有趣的面试场景. 即面试官会问某个具体场景的问题, 但是不会告诉你细节和约束. 比如说给一个查询语句, 让你判断会不会走索引.")]),_._v(" "),v("p",[_._v("虽然我不太喜欢这种面试套路, 但是不得不说很多面试官就喜欢这样搞. 他们的出发点是希望考察候选人思维是否缜密, 能不能考虑到各种异常情况, 边缘场景.")]),_._v(" "),v("p",[_._v("但是很多时候面试官出题根本没有考虑到候选人的技术背景. 比如说你本职是做支付相关的, 而他出的题是订单相关的. 那么在这种专业不对口的情况下, 你基本上不可能答好. 这也是我认为这种面试套路实际上并不太能考察出候选人真实水平的核心原因.")]),_._v(" "),v("p",[_._v("应付这种面试套路也很简单, 只需要保持警惕. "),v("mark",[v("strong",[_._v("当面试官问你一个具体问题的时候, 先尽可能问清楚一些约束条件, 最常见的就是并发量有多高, 数据量有多大, 可用性要求多高, 一致性要求多高")])]),_._v(".")]),_._v(" "),v("p",[_._v("如果面试官不告诉你, 让你考虑. 或者你自己不打算问, 那么可以采用防御性的面试策略, 在回答具体方案的时候先自己交代清楚这个方案的约束.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cc086d6a776dfe5d72f7bfc94d70eyyb-20231223175001-y4as89w.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"思考题-9"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-9"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("ul",[v("li",[_._v("你有没有遇到过索引设计不合理引发的线上故障? 如果有, 当时你是怎么定位问题, 怎么解决问题的?")]),_._v(" "),v("li",[_._v("你有没有因为 NULL 而出现过奇奇怪怪的问题?")])]),_._v(" "),v("h4",{attrs:{id:"_11-sql优化-如何发现sql中的问题-🆗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_11-sql优化-如何发现sql中的问题-🆗"}},[_._v("#")]),_._v(" 11-SQL优化:如何发现SQL中的问题?🆗")]),_._v(" "),v("p",[_._v("今天来聊聊数据库中的 SQL 优化.")]),_._v(" "),v("p",[_._v("一般而言, 在面试过程中, 都是鼓励尽可能为自己打造熟练掌握性能优化技巧的人设. 高并发项目经验可遇不可求, 但是高性能是可以勉强追求的, 性能优化就是追求高性能的方法. 和在微服务里面讲到的高可用相结合, 在写简历, 自我介绍和面试过程中, 可以有意识地展示自己在高可用和高性能方面的知识和积累.")]),_._v(" "),v("p",[_._v("而 SQL 优化是性能优化中最平易近人, 最好准备的点. 所以今天就来学习一下 SQL 优化的多种方案.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-7"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("p",[_._v('SQL 优化可以看作是一个更大的主题 "数据库优化" 下的一个子议题. 数据库优化主要包含以下内容:')]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("硬件资源优化")]),_._v(": 换更大更强的机器.")]),_._v(" "),v("li",[v("strong",[_._v("操作系统优化")]),_._v(": 调整操作系统的某些设置.")]),_._v(" "),v("li",[v("strong",[_._v("服务器/引擎优化")]),_._v(": 也就是针对数据库软件本体进行优化, 比如说调整事务隔离级别. 在 MySQL 里面还可以针对不同的引擎做优化, 比如说调整 InnoDB 引擎的日志刷盘时机.")]),_._v(" "),v("li",[v("strong",[_._v("SQL 优化")]),_._v(": 针对的就是 SQL 本身了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ea9337b3727f69fb1e494af845882ff7-20231223175001-xtoa2eu.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("如果站在数据库的角度, 那么 SQL 优化就是为了达到两个目标.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("减少磁盘 IO")]),_._v(", 这个又可以说是尽量避免全表扫描, 尽量使用索引以及尽量使用覆盖索引.")]),_._v(" "),v("li",[v("strong",[_._v("减少内存 CPU 消耗")]),_._v(", 这一部分主要是尽可能减少排序, 分组, 去重之类的操作.")])]),_._v(" "),v("p",[_._v("这部分只需要有一个概念就可以, 在面试的时候倒是不经常用到. SQL 优化是一个实践为主的面试主题, 很少讨论这种纯理论的内容.")]),_._v(" "),v("p",[_._v("如果想要知道优化后的效果, 就需要掌握一个工具, 就是 EXPLAIN 命令.")]),_._v(" "),v("h6",{attrs:{id:"explain命令"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#explain命令"}},[_._v("#")]),_._v(" EXPLAIN命令")]),_._v(" "),v("p",[_._v("每一个后端研发都应该掌握 EXPLAIN 命令. EXPALIN 命令的大概用法是 EXPLAIN your_sql, 然后数据库就会返回一个"),v("strong",[_._v("执行计划")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ab344a50a2a03332fc243b42d30901e9-20231223175001-zctjnc8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("执行计划有很多字段, 下面把最关键的地方列出来, 面试的时候只需要记住这几个就可以了.")]),_._v(" "),v("ol",[v("li",[v("mark",[v("strong",[_._v("type")])]),_._v(": 指的是查询到所需行的方式, 从好到坏依次是 "),v("code",[_._v("system > const > eq_ref > ref > range > index > ALL")]),_._v("​. "),v("strong",[_._v("system 和 const")]),_._v(" 都可以理解为数据库只会返回一行数据, 所以查询时间是固定的. "),v("strong",[_._v("eq_ref 和 ref")]),_._v(" 字面意思是根据索引的值来查找. "),v("strong",[_._v("range")]),_._v(": 索引范围扫描. "),v("strong",[_._v("index")]),_._v(": 索引全表扫描, 也就是扫描整棵索引. "),v("strong",[_._v("ALL")]),_._v(": 全表扫描, 发起磁盘 IO 的那种全表扫描.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("possible_keys")])]),_._v(": 候选的索引.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("key")])]),_._v(": 实际使用的索引.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("rows")])]),_._v(": 扫描的行数. 数据库可能扫描了很多行之后才找到你需要的数据.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("filtered")])]),_._v(": 查找到你所需的数据占 rows 的比例.")])]),_._v(" "),v("p",[_._v("在实践中, 没有必要将这些东西都死记硬背下来. 等要解读 EXPLAIN 的返回结果的时候, 再去搜索一下就行了.")]),_._v(" "),v("p",[_._v("一般优化 SQL 都是在 "),v("strong",[_._v("EXPLAIN 查看执行计划, 尝试优化")]),_._v("两个步骤之间循环往复, 直到发现 SQL 性能达标.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/3bc7f7d1f70494957272092cc643d1fa-20231223175001-dhwx9gd.png",alt:""}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"选择索引列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#选择索引列"}},[_._v("#")]),_._v(" 选择索引列")]),_._v(" "),v("p",[_._v("设计索引的时候, 列的选择非常关键, 但是目前来说并没有特别统一的说法. 可以参考以下规则.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("外键")]),_._v(", 一般都会用于关联, 过滤数据, 所以正常来说都会为表的外键创建索引.")]),_._v(" "),v("li",[_._v("频繁出现在 "),v("strong",[_._v("WHERE 中的列")]),_._v(", 主要是为了避免全表扫描.")]),_._v(" "),v("li",[_._v("频繁出现在 "),v("strong",[_._v("ORDER BY 的列")]),_._v(", 这是为了避免数据库在查询出来结果之后再次排序.")]),_._v(" "),v("li",[_._v("频繁出现在关联查询的关联条件中的列. 不过一般都不建议使用关联查询, 所以几乎可以忽略这个.")]),_._v(" "),v("li",[v("strong",[_._v("区分度很高的列")]),_._v(". 比如每一行的数据都不同的列, 并且在创建组合索引的时候, 区分度很高的列应该尽可能放到左边.")])]),_._v(" "),v("h6",{attrs:{id:"大表表定义变更"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大表表定义变更"}},[_._v("#")]),_._v(" 大表表定义变更")]),_._v(" "),v("p",[_._v("优化 SQL 很多手段都是围绕索引来进行的. 比如后面给出的案例要么是修改已有的索引, 要么是加索引. 但在修改索引的时候, 数据量大的表修改索引和数据量小的表修改索引, 实施方案是完全不一样的.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("修改索引或者说表定义变更的核心问题是数据库会加表锁, 直到修改完成")])]),_._v(".")]),_._v(" "),v("p",[_._v("所以当发现 MySQL 性能不行了, 准备新加一个索引的时候, 如果这个表的数据很多, 那么在执行加索引的命令的时候, "),v("strong",[_._v("整张表可能都会被锁住几分钟甚至几个小时")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8003705c2240717b018563d97bfa6b7e-20231223175001-yijkkbg.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("可见"),v("strong",[_._v("大表的表结构变更")]),_._v("是一件很麻烦的事情, 一般可以考虑的方案有 3 种.")]),_._v(" "),v("ol",[v("li",[_._v("停机变更, 就是把业务停下来, 然后更新表结构. 如果做得更加精细一点, 那么就可以说只把和这个表有关的功能下线, 但不需要将整个服务或者系统下线.")]),_._v(" "),v("li",[_._v("在业务低谷变更, 比停机更新好一点, 但是业务依旧受到了影响. 而且万一你以为在低谷能完成变更, 结果并没有, 那么就面临着业务在高峰期也不能用的问题.")]),_._v(" "),v("li",[v("strong",[_._v("创建新表, 这是不停机又不想业务受到影响的方案. 具体来说就是创建一张新表, 这张新表就是你准备用的新的表定义. 然后将旧表的数据迁移过去")]),_._v(". 后面会专门讨论数据迁移方案.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/fe056a99acd3e0f248a5d98a222a4571-20231223175001-7mvpezw.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备-11"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-11"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("你需要准备很多个 SQL 优化的案例, 这些案例可以体现你对 SQL 和数据库底层不同技术点的理解. 为此需要收集和整理好一些信息:")]),_._v(" "),v("ul",[v("li",[_._v("你维护的业务的所有表结构定义(包含索引定义), 每张表上执行最频繁的三个 SQL 是否用到了索引.")]),_._v(" "),v("li",[v("strong",[_._v("公司内部曾经或者已有的慢 SQL 是怎么发现, 分析和优化的")]),_._v(". 然后要记住 SQL 优化前后的执行时间, 以凸显优化的效果.")]),_._v(" "),v("li",[_._v("每一个 SQL 优化案例都要考虑清楚面试官如果要深挖, 那么会朝着什么方向深挖.")])]),_._v(" "),v("p",[_._v("整体上来说, SQL 优化的手段是非常多而且非常细碎的. 但是在面试中, "),v("strong",[_._v("不需要全部掌握")]),_._v(". 只需要在面试前精心设计一下在整个 SQL 优化里面的面试节奏就可以了.")]),_._v(" "),v("p",[_._v("当面试官问到这些问题的时候, 都可以将话题引导到 SQL 优化中.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("你是否做过性能优化")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("接口的响应时间是多少? 有没有优化的空间")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("你是否了解索引? 是否用过索引")]),_._v("?")])]),_._v(" "),v("p",[_._v("还有一种比较罕见的面试方式是面试官会要求你手写 SQL. 手写之后, 面试官会进一步考察在特定的一些场景下, 你的 SQL 是否会有问题. 记住, 但凡让你手写 SQL 的题目, 你都要谨慎考虑 SQL 有没有改进的空间.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-9"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-9"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("面试 SQL 优化的最佳策略就是把它作为自己全方面优化系统性能的一个举措. 可以考虑这样说:")]),_._v(" "),v("blockquote",[v("p",[_._v("某某系统是一个核心系统, 对性能有很高的要求. 为了让服务的响应时间降低到 100ms 以内, 我做了很多性能优化的事情, 比如 SQL 优化.")])]),_._v(" "),v("p",[_._v("如果这个系统同时还要求高可用, 那么就将高可用和性能优化融合在一起.")]),_._v(" "),v("blockquote",[v("p",[_._v("某某系统是一个核心系统, 对可用性和性能都有很高的要求. 公司对可用性的要求是希望能达到三个九, 平均响应时间控制在 100ms 内.")])]),_._v(" "),v("p",[_._v('接下来面试官就会问一些具体的措施. 比如说他可能会问: "你是怎么优化你的 SQL 查询的?" 那么可以这样回答.')]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司有 SQL 的慢查询监控, 当发现接口响应时间比较差的时候, 就会去排查 SQL 的问题. 我们主要是使用 EXPLAIN 命令来查看 SQL 的执行计划, 看看它有没有走索引, 走了什么索引, 是否有内存排序, 去重之类的操作.")]),_._v(" "),v("p",[_._v("初步判定了问题所在之后, 我们尝试优化, 包括改写 SQL 或者修改, 创建索引. 之后再次运行 SQL 看看效果. 如果效果不好, 就继续使用 EXPLAIN 命令, 再尝试修改. 如此循环往复, 直到 SQL 性能达到预期.")])]),_._v(" "),v("p",[_._v("可以用实际接触过的案例补充说明一下.")]),_._v(" "),v("p",[_._v("如果案例中涉及到了变更表结构定义, 增加索引或者修改索引, 那么面试官就可能问你怎么找出合适的列来创建索引, 以及在大表里面怎么变更表结构.")]),_._v(" "),v("p",[_._v("如果面试的内容比较基础, 那么面试官还会问 EXPLAIN 命令返回了什么数据.")]),_._v(" "),v("p",[_._v("此外, 如果你了解怎么优化操作系统, 怎么优化数据库本身, 那么可以把这些内容结合起来, 将自己打造成数据库优化高手.")]),_._v(" "),v("p",[_._v("即便你真不会, 也有一个取巧的办法. 就是去"),v("strong",[_._v("找公司的 DBA, 问清楚公司的数据库和数据库所在的操作系统有没有设置过什么参数")]),_._v(". 弄清楚每一个参数的含义, 修改背后的逻辑, 对面试也大有裨益.")]),_._v(" "),v("h5",{attrs:{id:"优化案例"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化案例"}},[_._v("#")]),_._v(" 优化案例")]),_._v(" "),v("p",[_._v("这里给一些具体的优化案例, 这些案例和方法都是可以用在生产实践中的, 如果之前没有尝试过, 建议你自己亲手实现一下.")]),_._v(" "),v("h6",{attrs:{id:"覆盖索引-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#覆盖索引-2"}},[_._v("#")]),_._v(" 覆盖索引")]),_._v(" "),v("p",[_._v("覆盖索引是最为常见的优化. 比如执行最多的 SELECT 语句是 "),v("code",[_._v("SELECT A, B, C 三个列")]),_._v("​, 而且 WHERE 里面也只有这三个列的条件, 那么就可以考虑直接创建一个 "),v("code",[_._v("<A, B, C>")]),_._v("​ 组合索引.")]),_._v(" "),v("p",[_._v("那么可以这么介绍你的案例, 关键词是"),v("strong",[_._v("覆盖索引.")])]),_._v(" "),v("blockquote",[v("p",[_._v("原来有一个执行非常频繁的 SQL. 这个 SQL 查询全部的列, 但是业务只会用到其中的三个列 A B C, 而且 WHERE 条件里面主要的过滤条件也是这三个列组成的, 所以我后面就在这三个列上创建了一个组合索引.")]),_._v(" "),v("p",[_._v("对于这个高频 SQL 来说, 新的组合索引就是一个覆盖索引. 所以我在创建了索引之后, 将 SQL 由 "),v("code",[_._v("SELECT *")]),_._v("​ 改成了 "),v("code",[_._v("SELECT A, B, C")]),_._v("​, 完全避免了回表. 这么一来, 整个查询的查询时间就直接降到了 1ms 以内.")])]),_._v(" "),v("p",[_._v("然后再进一步总结.")]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说, 对于非常高频的 SQL, 都要考虑避免回表, 那么设计一个合适的覆盖索引就非常重要了.")])]),_._v(" "),v("p",[_._v("除了覆盖索引, 还可以用索引来优化排序, 也就是下面的优化 ORDER BY 案例.")]),_._v(" "),v("h6",{attrs:{id:"优化order-by"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化order-by"}},[_._v("#")]),_._v(" 优化ORDER BY")]),_._v(" "),v("p",[_._v("这算是一个非常典型的案例. 在很多场景中, 查询一些数据之后, 都要求对数据进行一定的排序, 比如说按照更新时间来排序. 那么就可以这样说, 关键词是"),v("strong",[_._v("将排序列加入索引")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我在公司优化过一个 SQL, 这个 SQL 非常简单, 就是将某个人的数据搜索出来, 然后按照数据的最后更新时间来排序. SQL 大概是 "),v("code",[_._v("SELECT * FROM xxx WHERE uid = 123 ORDER BY update_time")]),_._v("​.")]),_._v(" "),v("p",[_._v("如果用户的数据比较多, 那么这个语句执行的速度还是比较慢的. 后来我们做了一个比较简单的优化, 就是用 uid 和 update_time 创建一个新的索引. 从数据库原理上说, 在 uid 确认之后, 索引内的 update_time 本身就是有序的, 所以避免了数据库再次排序的消耗. 这样一个优化之后, 查询时间从秒级降到了数十毫秒.")])]),_._v(" "),v("p",[_._v("这种优化在现实中非常容易遇到. 它的底层原理就是"),v("strong",[_._v("索引本身就是有序的")]),_._v(". 如果用表格来形容 "),v("code",[_._v("<uid, update_time>")]),_._v("​ 这个索引的数据组织形式, 那么看起来大概是这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b372ca5bfff7e5dyyec6b364f7b6c2b6-20231223175001-k32mwit.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以在 uid 确定之后, 数据库可以直接按照 update_time 在索引中的顺序来返回结果. 在优化前, 数据库就只能自己将对应 uid 的数据都读过来之后再次进行排序. 优化后则是省了一次排序过程.")]),_._v(" "),v("p",[_._v("最后也可以总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("在所有的排序场景中, 都应该尽量利用索引来排序, 这样能够有效减轻数据库的负担, 加快响应速度. 进一步来说, 像 ORDER BY, DISTINCT 等这样的操作也可以用类似的思路.")])]),_._v(" "),v("h6",{attrs:{id:"优化count"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化count"}},[_._v("#")]),_._v(" 优化COUNT")]),_._v(" "),v("p",[_._v("​"),v("code",[_._v("SELECT COUNT(*)")]),_._v("​ 也算是一个很常用的语句了. 很不幸的是, 最常使用的 MySQL InnoDB 引擎并"),v("strong",[_._v("没有存储数据总数")]),_._v(". 所以类似的语句在 MySQL InnoDB 引擎上执行起来特别慢.")]),_._v(" "),v("p",[_._v("那么优化 COUNT 的思路也比较简单. 第一种方法是用估计值取代精确值, 关键词是"),v("strong",[_._v("预估")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我的这个场景对数据的准确性不是很高, 所以我用了一个奇诡的方法, 即用 EXPLAIN your_sql, 之后用 EXPLAIN 返回的预估行数. 比如说 "),v("code",[_._v("SELECT COUNT(*) FROM xxx WHERE uid= 123")]),_._v("​, 就可以用 "),v("code",[_._v("EXPLAIN SELECT * FROM xxx WHERE uid = 123")]),_._v("​ 来拿到一个预估值.")])]),_._v(" "),v("p",[_._v("后面还可以进一步描述其他可行的优化.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过如果需要精确值, 那么就可以考虑使用 Redis 之类的 NoSQL 来直接记录总数. 或者直接有一个额外的表来记录总数也可以.")])]),_._v(" "),v("p",[_._v("这种优化就跟优化 SQL 本身没什么关系了, 但也可以认为是一种性能优化, 或者架构层面的优化.")]),_._v(" "),v("p",[_._v("在这个回答里面, 还有一个地方要小心, 那就是如果用了 Redis 来维持总数, 那么就会涉及"),v("strong",[_._v("数据一致性")]),_._v("的问题. 也就是说, 如果插入数据库成功, 但是更新 Redis 上的总数失败了, 应该怎么办?")]),_._v(" "),v("p",[_._v("这本质上是一个分布式事务的问题. 主要思路有两个:")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("如果数据短时间不一致但是业务可以接受的话, 那么就可以考虑异步刷新 Redis 上的总数")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("使用 Canal 之类的工具监听 MySQL binlog, 然后刷新 Redis 上的总数")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dd662132438dc94eed3263fc022de2c3-20231223175001-unwzdzr.png",alt:""}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"索引提示优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引提示优化"}},[_._v("#")]),_._v(" 索引提示优化")]),_._v(" "),v("p",[_._v("在上一节讲到了 FORCE INDEX, USE INDEX 和 IGNORE INDEX 三个索引提示, 当然也强调了这个不是什么好的实践, 尽量少用.")]),_._v(" "),v("p",[_._v("但是在实际工作中有些时候数据库的执行就很奇怪, 要么不用索引, 要么用了错误的索引, 那么在这种情况下就可以考虑使用这些索引提示来纠正数据库的行为.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我们有一个表结构定义, 上面有 A, B 两个索引. 原本按照预期, 这个查询应该会走 A 这个索引. 结果实际用 EXPLAIN 命令之后, MySQL 却使用了 B 索引. 所以我使用了 FORCE INDEX 之后强制查询使用 A 索引, 果然查询的响应时间降低到了毫秒级.")])]),_._v(" "),v("p",[_._v("同时还是需要强调一下, 这个不是很好的实践, 不到逼不得已都不要使用.")]),_._v(" "),v("blockquote",[v("p",[_._v("类似于 FORCE INDEX 之类的索引提示, 本身并不是什么好的实践, 还是要谨慎使用.")])]),_._v(" "),v("h6",{attrs:{id:"用where替换having"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#用where替换having"}},[_._v("#")]),_._v(" 用WHERE替换HAVING")]),_._v(" "),v("p",[_._v("一般来说, 数据库都是先根据 WHERE 条件找到候选的列, 再根据 HAVING 条件进行二次过滤.")]),_._v(" "),v("p",[_._v("那么应该可以意识到, 如果能够将 HAVING 中部分条件提前到 WHERE 里, 那么就可以提前将不符合条件的数据过滤掉了.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期有一个历史系统, 里面有一个 SQL 是很早以前的员工写的, 比较随意. 他将原本可以用在 WHERE 里面的普通的相等判断写到了 HAVING 里面. 后来我将这个条件挪到了 WHERE 之后查询时间降低了40%.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a9886f43ac7e8cd8bb3315cba217884c-20231223175001-6siy16z.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("然后可以总结出一般的规律.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果不是使用聚合函数来作为过滤条件, 最好还是将过滤条件优先写到 WHERE 里面.")])]),_._v(" "),v("p",[_._v("在这个案例里面提到了 SQL 的执行顺序, 那么面试官可能会问 SQL 执行顺序的问题, 需要有一个心理准备.")]),_._v(" "),v("h6",{attrs:{id:"优化分页中的偏移量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化分页中的偏移量"}},[_._v("#")]),_._v(" 优化分页中的偏移量")]),_._v(" "),v("p",[_._v("有一些 SQL 在不断执行中会产生极大的偏移量, 比如说非常简单的文章列表分页, 一页 50 条数据, 那么当要拿第 101 页的数据, 需要写成 LIMIT 50000, 50. 50000 就是偏移量. 实际执行中数据库就需要"),v("strong",[_._v("读出 50050 条数据, 然后将前面的 50000 都丢掉, 只保留 50 条")]),_._v(".")]),_._v(" "),v("p",[_._v("因此优化思路就是"),v("strong",[_._v("使用小偏移量")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在我们的系统里面, 最开始有一个分页查询, 那时候数据量还不大, 所以一直没出什么问题. 后来数据量大了之后, 发现如果往后翻页, 页码越大查询越慢. 问题关键就在于用的 LIMIT 偏移量太大了.")]),_._v(" "),v("p",[_._v("所以后来我就在原本的查询语句的 WHERE 里面加上了一个 "),v("code",[_._v("WHERE id > max_id")]),_._v("​ 的条件. 这个 max_id 就是上一批的最大 ID. 这样就可以保证 LIMIT 的偏移量永远是 0. 这样修改之后, 查询的速度非常稳定, 一直保持在毫秒级.")])]),_._v(" "),v("p",[_._v("同样可以总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("很多时候因为测试环境数据量太小, 这种性能问题根本不会被发现. 所以所有使用分页的查询都应该考虑引入类似的查询条件.")])]),_._v(" "),v("p",[_._v("这种优化手段还可以用于分库分表中的分页查询, 后面会再次讨论.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-11"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-11"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("今天这节讲了 SQL 优化里面比较容易遇到的三个点: "),v("strong",[_._v("EXPLAIN 命令, 选择索引列和大表表结构变更")]),_._v(", 并提供了覆盖索引, 优化 ORDER BY, 优化 COUNT, 优化索引提示, 用 WHERE 替换 HAVING, 优化分页中的偏移量六个案例.")]),_._v(" "),v("p",[_._v("此外还有一点需要注意: "),v("strong",[_._v("花样繁多的东西, 并不需要全部掌握")]),_._v(". 比如有很多 SQL 优化的手段可能我都没听过. 因此在面试过程中需要注意把控节奏, 要掌握整个面试的主动权. 或者说虽然看上去面试官还在频繁问你问题, 但是他问的问题都是你心中有数的, 所以实际上是你在暗中控制整个面试的过程.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1570060c8a090753fd71778b19668a4e-20231223175001-2usibls.png",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_12-数据库锁-明明有行锁-怎么突然就加了表锁-🆗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_12-数据库锁-明明有行锁-怎么突然就加了表锁-🆗"}},[_._v("#")]),_._v(" 12-数据库锁:明明有行锁,怎么突然就加了表锁?🆗")]),_._v(" "),v("p",[_._v("锁在整个数据库面试中都是属于偏难, 而且偏琐碎的一类问题. 但是偏偏锁又很重要, 比如说实践中遇到死锁影响了性能, 这就要求必须对锁有一定的了解. 并且锁的原理和索引, 隔离级别都有关, 所以很容易从锁这个角度联想到另外两个地方, 又或者从索引和隔离级别里面跳到锁这里.")]),_._v(" "),v("p",[_._v("因此, 一句话总结就是"),v("strong",[_._v("锁既难又琐碎还热门")]),_._v(". 那么今天这节会彻底捋清楚锁, 并且告诉你在面试过程中如何展示出亮点.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-5"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-5"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("h6",{attrs:{id:"锁与索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#锁与索引"}},[_._v("#")]),_._v(" 锁与索引")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("在 MySQL 的 InnoDB 引擎里面, 锁是借助索引来实现的. 或者说加锁锁住的其实是索引项, 更加具体地来说, 就是锁住了叶子节点")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/0be4ab811c14f01f477f9ea2267fbefe-20231223175001-pm3bn8z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从这个角度出发, 就能理解大部分跟锁有关的千奇百怪的问题了.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("一个表有很多索引, 锁的是哪个索引呢? 其实就是查询最终使用的那个索引. 万一查询没有使用任何索引呢? 那么锁住的就是整个表, 也就是此时退化为表锁")])]),_._v(".")]),_._v(" "),v("p",[_._v("如果查询条件的值并不存在, 例如:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("15")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("id = 15 的值根本不存在, 那么怎么锁? InnoDB 引擎会利用最接近 15 的相邻的两个节点, 构造一个"),v("strong",[_._v("临键锁")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/eb2c722f039d8962ae6d7c8e29ff7e8a-20231223175001-6qmtahu.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("此时"),v("strong",[_._v("如果别的事务想要插入一个 id=15 的记录, 就不会成功")]),_._v(".")]),_._v(" "),v("p",[_._v("那么范围查询呢? 也是利用索引上的数据, "),v("strong",[_._v("构造一个恰好能够装下这个范围的临键锁")]),_._v(". 例如:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("33")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("InnoDB 引擎会构造一个 (33, supremum] 的临键锁, 锁住整个范围. supremum 可以直观理解为 MySQL 认为的一个虚拟的最大值.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/c081d44794e712b4f4d0c7196b9b85d8-20231223175001-m51en98.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("因此, 可以得出了一个结论: "),v("mark",[v("strong",[_._v("锁和索引密切相关")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"释放锁时机"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#释放锁时机"}},[_._v("#")]),_._v(" 释放锁时机")]),_._v(" "),v("p",[_._v("大部分人在学习锁的时候有一个误区, 就是认为锁是在语句执行完毕之后就立刻释放掉的. 其实并不是, 它是在"),v("strong",[_._v("整个事务结束之后才释放")]),_._v("的. 换句话来说, "),v("mark",[v("strong",[_._v("当一个事务内部给数据加上锁之后, 只有在执行 Rollback 或者 Commit 的时候, 锁才会被释放掉")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/147aab4d2904995f473919e089e64cca-20231223175001-s60p1oc.png",alt:""}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"乐观锁与悲观锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#乐观锁与悲观锁"}},[_._v("#")]),_._v(" 乐观锁与悲观锁")]),_._v(" "),v("p",[_._v("乐观锁和悲观锁实际上是一种逻辑概念, 它们是并发控制中常用的两种锁机制.")]),_._v(" "),v("ul",[v("li",[_._v("乐观锁是直到要修改数据的时候, 才检测数据是否已经被别人修改过.")]),_._v(" "),v("li",[_._v("悲观锁是在初始时刻就直接加锁保护好临界资源.")])]),_._v(" "),v("p",[_._v("乐观锁在数据库中通常指利用 CAS 的思路进行的更新操作. 一般的使用形态就是下面这样的.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 在这里拿到了 a = 1")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 一大堆的业务操作")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SET")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br")])]),v("p",[_._v("在上面的这个语句里面, 预期数据库中 a 的值为 1 才会进行更新. 如果此时数据库中的值已经被修改了, 那么这个 UPDATE 语句就会失败. 业务方通过检测受影响的行数是否为 0, 来判断更新是否成功.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a70a9488094109fc351b07be14544edb-20231223175001-xig6021.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("悲观锁是指在写入数据时直接加锁")]),_._v(". 还拿上面这个例子来说, 就是从最开始的 SELECT 语句就直接加上了锁.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 在这里拿到了 a = 1")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 一大堆的业务操作")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SET")]),_._v(" a "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" b "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br")])]),v("p",[_._v("在加上锁之后, 就可以直接更新了. 这个时候不需要担心别人可以在 SELECT 和 UPDATE 之间将 a 更新为别的值.")]),_._v(" "),v("p",[_._v("在使用乐观锁和悲观锁时, 需要考虑数据一致性和并发性的问题. "),v("strong",[_._v("乐观锁适用于读多写少的场景")]),_._v(", 互联网中大部分应用都属于这一类. "),v("strong",[_._v("而悲观锁则适用于写多读少的场景, 比如在金融领域里面对金额的操作就是以写为主")]),_._v(".")]),_._v(" "),v("p",[_._v("相比之下, 乐观锁的性能要比悲观锁好很多. 不过因为乐观锁的代码写起来比较复杂, 所以很多人偷懒就会直接使用悲观锁.")]),_._v(" "),v("h6",{attrs:{id:"行锁与表锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#行锁与表锁"}},[_._v("#")]),_._v(" 行锁与表锁")]),_._v(" "),v("p",[_._v("行锁与表锁都是根据锁的范围来划分的. 一般来说, "),v("mark",[v("strong",[_._v("行锁是指锁住行, 可能是锁住一行, 也可能是锁住多行. 表锁则是直接将整个表都锁住")])]),_._v(".")]),_._v(" "),v("p",[_._v("那么在 MySQL 里面, InnoDB 引擎同时支持行锁和表锁. "),v("strong",[_._v("但是行锁是借助索引来实现的, 也就是说, 如果查询没有命中任何的索引, 那么 InnoDB 引擎是用不了行锁的, 只能使用表锁")]),_._v(". 当然, 如果用的是 MySQL, 类似于 MyISAM 引擎, 那么只能使用表锁, 因为这些引擎不支持行锁.")]),_._v(" "),v("h6",{attrs:{id:"共享锁与排它锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#共享锁与排它锁"}},[_._v("#")]),_._v(" 共享锁与排它锁")]),_._v(" "),v("p",[_._v("共享锁和排它锁是在互斥的角度上看待锁的.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("共享锁")]),_._v("是指一个线程加锁之后, 其他线程还是可以继续"),v("strong",[_._v("加同类型的锁")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("排它锁")]),_._v("是指一个线程加锁之后, 其他线程就不能再加锁了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ca46fd9ab293db1fd3f64225994bc4a5-20231223175001-5qumy6l.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("这两个概念非常接近读锁和写锁. "),v("strong",[_._v("因为读锁本身就是共享的, 而写锁就是排它的")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"意向锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#意向锁"}},[_._v("#")]),_._v(" 意向锁")]),_._v(" "),v("p",[_._v("意向锁相当于一个"),v("strong",[_._v("信号")]),_._v(", 就是告诉别人我要加锁了, 所以"),v("strong",[_._v("意向锁并不是一个真正物理意义上的锁")]),_._v(".")]),_._v(" "),v("p",[_._v("意向锁和共享锁, 排它锁相结合, 就有了意向共享锁和意向排它锁.")]),_._v(" "),v("ul",[v("li",[_._v("意向共享锁即你希望获得一个共享锁.")]),_._v(" "),v("li",[_._v("意向排它锁即你希望获得一个排它锁.")])]),_._v(" "),v("p",[_._v("注意, 意向锁的意向强调的就是想要拿到这个锁, 但是"),v("strong",[_._v("最终能否拿到这个锁是不确定的")]),_._v(".")]),_._v(" "),v("p",[_._v("在 MySQL 里面, "),v("mark",[v("strong",[_._v("使用意向锁的典型场景是在增删改查的时候, 对表结构定义加一个意向共享锁, 防止在查询的时候有人修改表结构. 而在修改表结构的时候, 则会加一个意向排它锁. 这也就是修改表结构的时候会直接阻塞掉所有的增删改查语句的原因. 使用意向锁能够提高数据库的并发性能, 并且避免死锁问题")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"记录锁-间隙锁和临键锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#记录锁-间隙锁和临键锁"}},[_._v("#")]),_._v(" 记录锁,间隙锁和临键锁")]),_._v(" "),v("p",[_._v("这是面试中最难理解的三个概念, 而且要是面试官对细节非常了解, 那就很容易挂在这一个部分. 但是反过来说, 如果能将这部分的细节都说清楚, 本身就是一个很大的亮点了.")]),_._v(" "),v("blockquote",[v("p",[_._v("记录锁")])]),_._v(" "),v("p",[v("strong",[_._v("记录锁是指锁住了特定的某一条记录的锁")]),_._v(". 例如这样一条语句:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("31")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("在使用了主键作为查询条件, 并且是相等条件下, "),v("strong",[_._v("将只命中一条记录")]),_._v(". 这一条记录就会被加上记录锁.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/57af4ccedf9b2270decb19235c8a4e08-20231223175001-x2ggvy9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是"),v("strong",[_._v("如果查询条件没有命中任何记录, 那么就不会使用记录锁, 而是使用间隙锁")]),_._v(". 又或者使用了唯一索引作为条件, 比如说在 user 表里面在列 email 上有一个唯一索引.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" email"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token string"}},[_._v("'your_email'")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("那么这条查询语句此时也是使用了记录锁. 类似地, 如果 email='your_email' 这条记录不存在, 那么会变成一个间隙锁.")]),_._v(" "),v("p",[_._v("举个例子, 如果数据库中只有 id 为(1, 4, 7)的三条记录, 也就是 id = 3 这个条件没有命中任何数据, 那么这条语句会在 (1, 4) 加上间隙锁. 所以可以看到, "),v("strong",[_._v("在生产环境里面遇到了未命中索引的情况, 对性能影响极大")]),_._v(".")]),_._v(" "),v("p",[_._v("这里稍微解释一下, 实际上 MySQL 本身是加上临键锁的, 但是"),v("strong",[_._v("临键锁本身是由间隙锁和记录锁合并组成的")]),_._v(", 所以这里就先用间隙锁来描述了.")]),_._v(" "),v("blockquote",[v("p",[_._v("间隙锁")])]),_._v(" "),v("p",[v("strong",[_._v("间隙锁是锁住了某一段记录的锁")]),_._v(". 直观来说就是锁住了一个范围的记录. 比如在查询的时候使用了 "),v("code",[_._v("<, <=, BETWEEN")]),_._v("​ 之类的范围查询条件, 就会使用间隙锁.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" your_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("BETWEEN")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("100")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("间隙锁会锁住 (50, 100) 之间的数据, 而 50 和 100 "),v("strong",[_._v("本身")]),_._v("会被记录锁锁住. 类似地, <= 这种查询也可以认为 = 的那个值会被记录锁锁住.")]),_._v(" "),v("p",[_._v("如果表里面没有 50, 那么数据库就会"),v("strong",[_._v("一直向左")]),_._v(", 找到第一个存在的数据, 比如说 40; 如果表里面没有 100, 那么数据库就会"),v("strong",[_._v("一直向右")]),_._v(", 找到第一个存在的数据, 比如说 120. 那么使用的间隙锁就是 (40, 120). 如果此时有人想要插入一个主键为 70 的行, 是无法插入的, 它需要"),v("strong",[_._v("等这个 SELECT 语句释放掉间隙锁")]),_._v(".")]),_._v(" "),v("p",[_._v("间隙锁一般都说两边都是开的, 即端点是没有被间隙锁锁住的. "),v("mark",[v("strong",[_._v("记录锁和记录锁是排它的, 但是间隙锁和间隙锁不是排它的")])]),_._v(". 也就是说两个间隙锁之间即便重叠了, 也还是可以加锁成功的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/4a3e1d90160bb31cd91edcd720dcbac9-20231223175001-h15ww8v.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("临键锁")])]),_._v(" "),v("p",[_._v("临键锁(Next-Key Locks)是很独特的一种锁, 直观上来说可以看做是一个"),v("strong",[_._v("记录锁和间隙锁的组合")]),_._v(". 也就是说"),v("strong",[_._v("临键锁不仅仅是会用记录锁锁住命中的记录, 也会用间隙锁锁住记录之间的空隙")]),_._v(". 临键锁和数据库隔离级别的联系最为紧密, 它可以解决在可重复读隔离级别之下的幻读问题.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("间隙锁是左开右开, 而临键锁是左开右闭")])]),_._v(". 还是用前面的例子来说明. 如果 id 只有 (1, 4, 7) 三条记录, 那么临键锁就将 (1, 4] 锁住.")]),_._v(" "),v("h6",{attrs:{id:"小结一下-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#小结一下-2"}},[_._v("#")]),_._v(" 小结一下")]),_._v(" "),v("p",[_._v("这里依旧准备了简洁版的记忆口诀, 用来判断使用的是记录锁, 间隙锁还是临键锁.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("遇事不决临键锁")]),_._v(". 可以认为, 全部都是加临键锁的, 除了下面两个子句提到的例外情况.")]),_._v(" "),v("li",[v("strong",[_._v("右边缺省间隙锁")]),_._v(". 例如值只有 (1, 4, 7) 三个, 但查询的条件是 "),v("code",[_._v("WHERE id < 5")]),_._v("​, 那么加的其实是间隙锁, 因为 7 本身不在条件范围内.")]),_._v(" "),v("li",[v("strong",[_._v("等值查询记录锁")]),_._v(". 这个其实针对的是主键和唯一索引, 普通索引只适用上面两条.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/53a2b8b61d03783231af0e764ayy64e1-20231223175001-sxtyf1r.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-12"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("为了更好地面试锁, 需要在公司内部收集一些信息.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("公司出现过的死锁, 包含排查过程, 解决方案")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("其他锁使用不当的场景")]),_._v(", 比如因为锁使用不当造成的一些性能问题.")]),_._v(" "),v("li",[v("strong",[_._v("收集至少一个使用乐观锁的场景")]),_._v(", 并且看看相关的 SQL 是怎么写的, 做到心中有数.")]),_._v(" "),v("li",[v("strong",[_._v("收集公司内使用悲观锁的场景")]),_._v(", 并且尝试使用乐观锁来进行优化.")])]),_._v(" "),v("p",[_._v("这些案例非常重要, 如果自己没有亲自遇到, 也要找同事问清楚, 或者在互联网上搜集一些案例来实际看看锁的应用.")]),_._v(" "),v("p",[_._v("类似索引, 面试官可能会直接写一个 SQL 语句, 问你可能加什么锁. 这种问题总体上还是偏难的, 在准备面试的时候可以先刻意练习一下.")]),_._v(" "),v("ul",[v("li",[_._v("在主键或唯一索引上使用等值查询, 例如 "),v("code",[_._v("WHERE email = 'abc@qq.com'")]),_._v("​, 区分记录存在与不存在两种情况.")]),_._v(" "),v("li",[_._v("在主键或唯一索引上使用范围查询, 例如 "),v("code",[_._v("WHERE email >= 'abc@qq.com'")]),_._v("​.")]),_._v(" "),v("li",[_._v("在普通索引上使用等值查询.")]),_._v(" "),v("li",[_._v("在普通索引上使用范围查询.")]),_._v(" "),v("li",[_._v("执行查询, 但是该查询不会使用任何索引.")])]),_._v(" "),v("p",[_._v("不管怎么回答, 都要记得"),v("strong",[_._v("强调间隙锁和临键锁是在可重复读的隔离级别下才有效果")]),_._v("的.")]),_._v(" "),v("p",[_._v("此外, 和面试官在聊到一些话题的时候, 可以尝试把话题引导到锁机制上.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("索引")]),_._v(": MySQL 的 InnoDB 引擎是借助索引来实现行锁的.")]),_._v(" "),v("li",[v("strong",[_._v("性能问题")]),_._v(": 锁使用不当引起的性能问题.")]),_._v(" "),v("li",[v("strong",[_._v("乐观锁")]),_._v(": 比如说原子操作中的 CAS 操作, 可以借助 CAS 这个关键词, 聊一聊在 MySQL 层面上怎么利用类似的 CAS 操作来实现一个乐观锁.")]),_._v(" "),v("li",[v("strong",[_._v("语言相关的锁")]),_._v(": 比如说 Go 语言的 mutex 和 Java 的 Lock, 都可以引申到数据库的锁.")]),_._v(" "),v("li",[v("strong",[_._v("死锁")]),_._v(": 聊一聊公司的数据库死锁案例.")])]),_._v(" "),v("p",[_._v("整体来说, 数据库锁优化在整个性能优化领域里面也算是一个比较高级的点了, 很有竞争优势, 不可错过.")]),_._v(" "),v("h5",{attrs:{id:"基本面试"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本面试"}},[_._v("#")]),_._v(" 基本面试")]),_._v(" "),v("p",[_._v("锁这边的问题会有非常多的问法. 一开始引起锁的话题的时候, 面试官可能这么问.")]),_._v(" "),v("ul",[v("li",[_._v("你知道 MySQL 的锁机制吗?")]),_._v(" "),v("li",[_._v("你了解 MySQL 的锁吗?")])]),_._v(" "),v("p",[_._v("那么类似的问题就可以先综合回答, 介绍一下 MySQL 里面的五花八门的锁.")]),_._v(" "),v("blockquote",[v("p",[_._v("MySQL 里面的锁机制特别丰富, 这里我以 InnoDB 引擎为例. 首先, 从锁的范围来看, 可以分成行锁和表锁. 其次, 从排它性来看, 可以分成排它锁和共享锁. 还有意向锁, 结合排它性, 就分为排它意向锁和共享意向锁. 还有三个重要的锁概念, 记录锁, 间隙锁和临键锁. 记录锁, 是指锁住某条记录; 间隙锁, 是指锁住两条记录之间的位置; 临键锁可以看成是记录锁与间隙锁的组合情况.")]),_._v(" "),v("p",[_._v("还有一种分类方法, 是乐观锁和悲观锁. 那么在数据库里面使用乐观锁, 本质上是一种应用层面的 CAS 操作.")])]),_._v(" "),v("p",[_._v("紧接着, 不要深入去解释各种锁, 而是先从大方向上解释清楚锁的根本特性: "),v("strong",[_._v("锁是和索引, 隔离级别密切相关的")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在 MySQL 的 InnoDB 引擎里面, 锁和索引, 隔离级别都是有密切关系的. 在 InnoDB 引擎里面, 锁是依赖于索引来实现的. 或者说, 锁都是加在索引项上的. 因此, 如果一个查询用了索引, 那么会用行锁, 如果没用到任何索引, 那么就会用表锁. 此外, 在 MySQL 里面, 间隙锁和临键锁是只工作在可重复读这个隔离级别下的.")])]),_._v(" "),v("p",[_._v("然后就等着面试官进一步追问细节. 正常情况下, 他可能问下面这些问题.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("某一种锁的具体含义")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("某一种锁的使用场景")]),_._v(", 这里稍微注意一点意向锁就可以, 其他的都比较简单.")]),_._v(" "),v("li",[v("strong",[_._v("怎么在数据库里面使用乐观锁")]),_._v(", 或者你用乐观锁解决过什么问题?")]),_._v(" "),v("li",[v("strong",[_._v("你有没有优化过锁, 或者解决过死锁")]),_._v("?")]),_._v(" "),v("li",[_._v("详细介绍记录锁, 间隙锁和临键锁, 也有可能问 MySQL 在可重复读的隔离级别下, 会不会有幻读问题?")])]),_._v(" "),v("p",[_._v("这里可以详细分析记录锁, 间隙锁和临键锁, 不过如果想要百分之百征服面试官, 还是需要用一些实际的锁优化的案例来证明你的能力.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-7"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这里先说一个最简单的锁优化的方案. 前面提到, MySQL 的锁是依赖索引机制来实现的. 而如果查询没有使用任何索引, 就会使用表锁. 那么很显然最简单的方案就是"),v("strong",[_._v("给这种查询创建一个索引, 避免使用表锁")]),_._v(".")]),_._v(" "),v("p",[_._v("可以这么回答, 关键词是"),v("strong",[_._v("缺索引")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我发现我们的业务有一个神奇的性能问题, 就是响应时间偶尔会突然延长. 后来经过排查, 确认响应时间是因为数据库查询变慢引起的. 但是这些变长的查询, SQL 完全没有问题, 用 EXPLAIN 去分析, 都很正常, 也走了索引.")]),_._v(" "),v("p",[_._v("直到后面去排查业务代码的提交记录, 才发现新加了一个功能, 这个功能会执行一个 SQL, 但是这个 SQL 本身不会命中任何索引. 于是数据库就会使用表锁, 偏偏这个 SQL 因为本身没有命中索引, 又很慢, 导致表锁一直得不到释放. 结果其他正常的 SQL 反而被它拖累了. 最终我们重新优化了这个使用表锁的 SQL, 让它走了一个索引, 就解决了这个问题.")])]),_._v(" "),v("p",[_._v("不过这个方案说起来还是太简单, 需要一些更复杂的方案来打动面试官. 那么接下来再提供两个稍微复杂一些的方案: 临键锁引发的死锁和弃用悲观锁.")]),_._v(" "),v("h6",{attrs:{id:"临键锁引发的死锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#临键锁引发的死锁"}},[_._v("#")]),_._v(" 临键锁引发的死锁")]),_._v(" "),v("p",[_._v("在一个业务中, 有一个场景是"),v("strong",[_._v("先从数据库中查询数据并锁住")]),_._v(". 如果"),v("strong",[_._v("这个数据不存在, 那么就需要执行一段逻辑, 计算出一个数据, 然后插入. 如果已经有数据了, 那么就将原始的数据取出来, 再利用这个数据执行一段逻辑, 计算出来一个结果, 执行更新")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"https://nano-note.oss-cn-beijing.aliyuncs.com/images/0519d4897c4b8b985d6f54e79yy9ba3e-20231223175001-uegh1ta.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因为两段运算逻辑不同, 所以不能简单地使用 INSERT ON DUPLICATE 的语句来取代.")]),_._v(" "),v("p",[_._v("只看没有数据的逻辑, 在计算之后插入新数据, 如果用伪代码来描述, 就是下面这样的.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BEGIN")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" biz "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" ? "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FOR")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 中间有很多业务操作")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("INSERT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("INTO")]),_._v(" biz"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("data")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("VALUE")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("?"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" ?"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("COMMIT")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br")])]),v("p",[_._v("看起来是不是没有任何问题? 实际上, 这个地方会引起"),v("strong",[_._v("死锁")]),_._v(".")]),_._v(" "),v("p",[_._v("假设说现在数据库中 ID 最大的值是 78. 那么"),v("strong",[_._v("如果两个业务进来, 同时执行这个逻辑")]),_._v(". 一个准备插入 id = 79 的数据, 一个准备插入 id = 80 的数据. 如果它们的执行时序如下图, 那就会得到一个死锁错误.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f585706c073yyf00128b91876ff410fc-20231223175001-fpuuh2m.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("[")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("40001")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("]")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("[")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1213")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("]")]),_._v(" Deadlock found when trying to get lock"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v(" try restarting transaction\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("造成死锁的原因也很简单. 在线程 1 执行 SELECT FOR UPDATE 的时候, 因为 id = 79 的数据"),v("strong",[_._v("不存在")]),_._v(", 所以实际上"),v("strong",[_._v("数据库会产生一个 (78, supremum] 的临键锁")]),_._v(". 类似地, 线程 2 也会"),v("strong",[_._v("产生一个 (78, supremum] 临键锁")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("==当线程 1 想要执行插入的时候, 它想要获得 id = 79 的行锁. 当线程 2 想要执行插入的时候, 它想要获得 id = 80 的行锁, 这个时候就会出现死锁. 因为线程 1 和线程 2 同时还在等着对方释放掉持有的间隙锁==")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/31cee3eb57ff5e8f4ddf49757a072d46-20231223175001-5bxdeud.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从理论上来说, 解决方案有三种.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("不管有没有数据, 先插入一个默认的数据")]),_._v(". 如果没有数据, 那么会插入成功; 如果有数据, 那么会出现主键冲突或者唯一索引冲突, 插入失败. 那么在插入成功的时候, 执行以前数据不存在的逻辑, 但是因为此时数据库中有数据, 所以不会使用间隙锁, 而是使用行锁, 从而规避了死锁问题.")]),_._v(" "),v("li",[_._v("调整数据库的隔离级别, 降低为已提交读, 那么就没有间隙锁了. 这种解决方案也可以, 而且你可以将话题进一步引申到 MVCC 中.")]),_._v(" "),v("li",[v("strong",[_._v("放弃悲观锁, 使用乐观锁")]),_._v(". 这也是亮点方案.")])]),_._v(" "),v("p",[_._v("可以通过一个案例来说明, 关键词是"),v("strong",[_._v("临键锁.")])]),_._v(" "),v("blockquote",[v("p",[_._v("早期我优化过一个死锁问题, 是临键锁引起的. 业务逻辑很简单, 先用 SELECT FOR UPDATE 查询数据. 如果查询到了数据, 那么就执行一段业务逻辑, 然后更新结果; 如果没有查询到, 那么就执行另外一段业务逻辑, 然后插入计算结果.")]),_._v(" "),v("p",[_._v("那么如果 SELECT FOR UPDATE 查找的数据不存在, 那么数据库会使用一个临键锁. 此时, 如果有两个线程加了临键锁, 然后又希望插入计算结果, 那么就会造成死锁.")]),_._v(" "),v("p",[_._v("这个优化也很简单, 就是上来先不管三七二十一, 直接插入数据. 如果插入成功, 那么就执行没有数据的逻辑, 此时不会再持有临键锁, 而是持有了行锁. 如果插入不成功, 那么就执行有数据的业务逻辑.")]),_._v(" "),v("p",[_._v("此外, 还有两个思路. 一个是修改数据库的隔离级别为 RC, 那么自然不存在临键锁了, 但是这个修改影响太大, 被 DBA 否决了. 另外一个思路就是使用乐观锁, 不过代码改起来要更加复杂, 所以就没有使用.")])]),_._v(" "),v("p",[_._v("这么回答的话, 面试官接下来就可能追问隔离级别的事情, 或者乐观锁的细节, 那么就有机会继续展示了.")]),_._v(" "),v("h6",{attrs:{id:"弃用悲观锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#弃用悲观锁"}},[_._v("#")]),_._v(" 弃用悲观锁")]),_._v(" "),v("p",[_._v("很多人为了省事会在开发的时候直接使用悲观锁. 最为典型的例子就是在事务里面存在 "),v("code",[_._v("SELECT ... FOR UPDATE")]),_._v("​ 的语句, 而后会紧跟着一个 UPDATE 语句.")]),_._v(" "),v("p",[_._v("伪代码:")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 开启事务")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Begin")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 查询到已有的数据 SELECT * FROM xxx WHERE id = 1 FOR UPDATE")]),_._v("\ndata "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("SelectForUpdate")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\nnewData "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("calculate")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("data"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 一大通计算")]),_._v("\n\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 将新数据写回去数据库 UPDATE xxx SET data = newData WHERE id =1")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Update")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" newData"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Commit")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br")])]),v("p",[_._v("那么这一类代码"),v("strong",[_._v("可以考虑将整个事务都去掉, 纯粹依赖 CAS 操作")]),_._v(".")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 查询到已有的数据 SELECT * FROM xxx WHERE id = 1")]),_._v("\n  data "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Select")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  newData "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("calculate")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("data"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 一大通计算")]),_._v("\n\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 将新数据写回去数据库")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// UPDATE xxx SET data = newData WHERE id =1 AND data=oldData")]),_._v("\n  success "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("CAS")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" newData"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" data"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 确实更新成功, 代表在业务执行过程中没有人修改过这个 data. ")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 适合读多写少的情况")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" success "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("break")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br"),v("span",{staticClass:"line-number"},[_._v("12")]),v("br"),v("span",{staticClass:"line-number"},[_._v("13")]),v("br"),v("span",{staticClass:"line-number"},[_._v("14")]),v("br")])]),v("p",[_._v("这里是直接用的 data 来比较的, 实践中也可能是引入了 version 列, 或者使用 update_time 来确保数据没有发生变更.")]),_._v(" "),v("p",[_._v("可以在聊到乐观锁的情况下, 使用这个案例.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在入职这家公司之后, 曾经系统地清理过公司内部使用悲观锁的场景, 改用乐观锁. 正常的悲观锁都是使用了 "),v("code",[_._v("SELECT FOR UPDATE")]),_._v("​ 语句, 查询到数据之后, 进行一串计算, 再将结果写回去. 那么改造的方案很简单, 查询的时候使用 SELECT 语句直接查询, 然后进行计算. 但是在写回去的时候, 就要用到数据库的 CAS 操作, 即 UPDATE 的时候要确认之前查询出来的结果并没有实际被修改过.")]),_._v(" "),v("p",[_._v("一般来说就是 "),v("code",[_._v("UPDATE xxx SET data = newData WHERE id = 1 AND data = oldData")]),_._v("​. 这种改造效果非常好, 性能提升了 30%. 当然并不是所有的悲观锁场景都能清理, 还有一部分实在没办法, 只能是考虑别的手段了.")])]),_._v(" "),v("p",[_._v("这里最后留了一个尾巴, 也就是将话题引导到你准备的其他优化锁的案例上.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-12"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节学习了面试中的重难点问题--锁, 锁与索引的关系十分密切, 可以说锁是借助索引来实现的. 锁的形式五花八门, 有乐观锁, 悲观锁, 行锁, 表锁, 共享锁, 排它锁, 意向锁, 记录锁, 间隙锁和临键锁等多种类型, 它们各有用途, 这里要注意分辨它们各自的能力, 学会分析什么场景下使用哪一种锁.")]),_._v(" "),v("p",[_._v("此外还提供了两个比较复杂的亮点方案: "),v("strong",[_._v("临键锁引发的死锁, 弃用悲观锁")]),_._v(". 在实际面试中可以考虑替换为自己的案例.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d550dfb25714cbfb8dccfyyde8cfcef7-20231223175001-heg1hhs.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-10"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-10"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("你在公司有没有优化过什么锁? 可以分享一下你的案例吗?")]),_._v(" "),v("li",[_._v("你有没有使用过乐观锁? 用于解决什么问题? 相比直接使用悲观锁, 你认为代码量有没有变化?")])]),_._v(" "),v("h5",{attrs:{id:"题外话-面试锦囊"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#题外话-面试锦囊"}},[_._v("#")]),_._v(" 题外话:面试锦囊")]),_._v(" "),v("p",[_._v("最后再来聊点题外话, 就是面试时的一个小技巧--"),v("strong",[_._v("能示之不能, 不能示之能")]),_._v('. 在前面很多讲里, 都在回答中都故意点到即止, 或者故意留出破绽, 就是 "能示之不能", 引诱面试官追问.')]),_._v(" "),v("p",[_._v('那么反过来 "不能示之能" 就是纯粹地唬人. 就是说实际上并不是很了解某一些方面的东西, 但是你假装你非常了解, 胸有成竹. 那么在这种情况下, 如果面试官被你的假象迷惑住了, 那么他就不会继续追问这方面的东西.')]),_._v(" "),v("p",[_._v("这跟面试流程是有关的. 很多人出去面候选者, 讲究的是问到候选者无话可说. 那么既然你表现得一副我还有很多话说, 快来问我的样子, 他们自然不会问你了.")]),_._v(" "),v("p",[_._v('不过 "不能示之能" 策略要慎用. 一场面试可一不可二, 可二千万别三. 因为你装多了, 面试官就会好奇你怎么什么都知道, 或者激起了逆反心理, 深挖下来你就挡不住了.')]),_._v(" "),v("p",[_._v('但是 "能而示之不能" 就可以随便用. 尤其是一些公司有所谓的 "压薪面". 就是本身你已经通过了基本的技术面试, 但是公司不想给你高薪, 就会故意面你一些很难的问题, 打击你, 这样好压价. 那么如果你能够在压薪面里面将面试官引导到你熟悉的领域, 立于不败之地, 那么接下来谈薪酬就更有主动权.')]),_._v(" "),v("h4",{attrs:{id:"_13-mvcc协议-mysql在修改数据的时候-还能不能读到这条数据-🆗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_13-mvcc协议-mysql在修改数据的时候-还能不能读到这条数据-🆗"}},[_._v("#")]),_._v(" 13-MVCC协议:MySQL在修改数据的时候,还能不能读到这条数据?🆗")]),_._v(" "),v("p",[_._v("今天来学习 MySQL 面试中非常重要的一个内容---MVCC 协议.")]),_._v(" "),v("p",[_._v("MVCC(Multi-Version Concurrency Control)中文叫做多版本并发控制协议, 是 MySQL InnoDB 引擎用于控制数据并发访问的协议. 它在面试中属于必面题, 而且从 MVCC 出发能够将话题引申到事务, 隔离级别两个重头戏上, 所以掌握 MVCC 能让你进可攻退可守.")]),_._v(" "),v("p",[_._v("那么今天就从 MVCC 的基本原理开始讲起. 在开始之前, 先思考一个问题, "),v("strong",[_._v("为什么 InnoDB 会需要 MVCC")]),_._v("?")]),_._v(" "),v("h5",{attrs:{id:"为什么需要mvcc"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么需要mvcc"}},[_._v("#")]),_._v(" 为什么需要MVCC?")]),_._v(" "),v("p",[_._v("前面已经学过了锁, 知道锁本身就是用于并发控制的, 那么为什么 InnoDB 还需要引入 MVCC, 读写都加锁不就可以控制住并发吗?")]),_._v(" "),v("p",[v("strong",[_._v("锁确实可以, 但是性能太差")]),_._v(". 如果是纯粹的锁, 那么写和写, 读和写, 读和读之间都是互斥的. 如果是读写锁, 那么写和写, 读和写之间依旧是互斥的.")]),_._v(" "),v("p",[_._v("数据库和一般的应用有一个很大的区别, 就是"),v("strong",[_._v("数据库即便是读, 也不能被写阻塞住")]),_._v(". 试想一下, 如果一个线程准备执行 UPDATE 一行数据, 如果这时候阻塞住了所有的 SELECT 语句, 这个性能你能接受吗?")]),_._v(" "),v("p",[_._v("显然接受不了, 所以"),v("mark",[v("strong",[_._v("数据库要有一种机制, 避免读写阻塞")])]),_._v(". 在理解了为什么 MVCC 必不可少之后, 现在需要进一步了解一个和 MVCC 紧密关联的概念: "),v("strong",[_._v("隔离级别")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"隔离级别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#隔离级别"}},[_._v("#")]),_._v(" 隔离级别")]),_._v(" "),v("p",[v("strong",[_._v("数据库的隔离级别是一组规则, 用来控制并发访问数据库时如何分配, 保护和共享资源")]),_._v(". 不同的隔离级别在不同的并发控制策略之间进行调整, 从而提供了不同的读写隔离级别和安全性. 用人话来说, 就是"),v("strong",[_._v("隔离级别代表了一个事务是否了解别的事务以及了解程度怎么样")]),_._v(".")]),_._v(" "),v("p",[_._v("MySQL 的隔离级别有四个.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("读未提交")]),_._v("(Read Uncommitted)是指一个事务可以看到另外一个事务尚未提交的修改.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/475451d533257d436459775e714e9bfc-20231223175001-c6u5xqd.png",alt:""}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[v("strong",[_._v("读已提交")]),_._v("(Read Committed, 简写 RC)是指一个事务只能看到已经提交的事务的修改. 这意味着 "),v("strong",[_._v("如果在事务执行过程中有别的事务提交了, 那么事务还是能够看到别的事务最新提交的修改")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a7c6736fa83ebc72715044257739f975-20231223175001-artngzf.png",alt:""}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[v("strong",[_._v("可重复读")]),_._v("(Repeatable Read, 简写 RR)是指在这一个事务内部读同一个数据多次, 读到的结果都是同一个. 这意味着即便 "),v("strong",[_._v("在事务执行过程中有别的事务提交, 这个事务依旧看不到别的事务提交的修改")]),_._v(". 这是 MySQL 默认的隔离级别.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/37e7909f2a72a63d0538bf32ceb4ca5d-20231223175001-bb6naj9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[v("strong",[_._v("串行化")]),_._v("(Serializable)是指事务对数据的读写都是串行化的.")])]),_._v(" "),v("p",[_._v("从上到下, "),v("strong",[_._v("隔离性变强但是性能变差")]),_._v("了. 所以一个提升 MySQL 性能最简单的方式, 就是将隔离级别往下调, 这也是一个亮点方案.")]),_._v(" "),v("p",[_._v("和隔离级别密切相关的概念是"),v("strong",[_._v("脏读, 幻读和不可重复读")]),_._v("这三个"),v("strong",[_._v("读异常")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("脏读")]),_._v('是指读到了别的事务还没有提交的数据. 之所以叫做 "脏" 读, 就是因为未提交数据可能会被回滚掉.')]),_._v(" "),v("li",[v("strong",[_._v("不可重复读")]),_._v("是指在一个事务执行过程中, 对同一行数据读到的结果不同.")]),_._v(" "),v("li",[v("strong",[_._v("幻读")]),_._v("是指在事务执行过程中, 别的事务插入了新的数据并且提交了, 然后事务在后续步骤中读到了这个新的数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0a0b5343f602f202b75084187c74cff3-20231223175001-ydx8qwd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以用一个表来描述隔离级别和这三种读异常的关系.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3cec4b180e2a0a92bc6aa1c0d2de2c4b-20231223175001-1m73zc4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里尤其要注意一点, 就是"),v("strong",[_._v("理论上来说可重复读是没有解决幻读的. 但是 MySQL 因为使用了临键锁, 因此它的可重复读隔离级别已经解决了幻读问题")]),_._v(". 在面试的过程中不要忘了强调这一点.")]),_._v(" "),v("p",[_._v("此外还有两个相似的概念: "),v("mark",[v("strong",[_._v("快照读和当前读")])]),_._v(". 简单来说, "),v("mark",[v("strong",[_._v("快照读就是在事务开始的时候创建了一个数据的快照, 在整个事务过程中都读这个快照; 而当前读, 则是每次都去读最新数据")])]),_._v(". MySQL 在可重复读这个隔离级别下, 查询的执行效果和快照读非常接近.")]),_._v(" "),v("h5",{attrs:{id:"版本链"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#版本链"}},[_._v("#")]),_._v(" 版本链")]),_._v(" "),v("p",[_._v("为了实现 MVCC, InnoDB 引擎给每一行都加了两个额外的字段 "),v("strong",[_._v("trx_id 和 roll_ptr")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("trx_id: 事务 ID, 也叫做事务版本号")]),_._v(". MVCC 里面的 V 指的就是这个数字. 每一个事务在开始的时候就会获得一个 ID, 然后这个事务内操作的行的事务 ID, 都会被修改为这个事务的 ID.")]),_._v(" "),v("li",[v("strong",[_._v("roll_ptr: 回滚指针")]),_._v(". InnoDB 通过 roll_ptr "),v("strong",[_._v("把每一行的历史版本串联在一起")]),_._v(".")])]),_._v(" "),v("p",[_._v("实际上, InnoDB 引擎还隐式地插入了另外一个列 row_id, 如果没有设置任何主键, 那么这个列就会被当成主键来使用. 但是它其实和 MVCC 没太大的关系, 所以不需要关注.")]),_._v(" "),v("p",[_._v("下面用一个例子来说明 MVCC 是如何利用这两个列的.")]),_._v(" "),v("p",[_._v("假设最开始插入了一行数据, 插入数据的这个事务的 ID 是 100, 那么这个时候数据行看起来是这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fcb04eaf546734e2a0e3143063cc81eb-20231223175001-phhsmju.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("假设有一个事务 A 拿到了 ID 101, 然后把 x 的值修改为 15, 那么就会变成这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a5cdc04ab6b35170c298a9ffffba9f19-20231223175001-lj8qel9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个时候, "),v("strong",[_._v("事务 A 修改后的 roll_ptr 会指向初始状态的数据")]),_._v(". 假如现在再来一个事务 B 拿到 ID 102, 要把数据 x 修改成 20, 那么就会变成下面这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fc2f56b6dec20bbc2524ec8f479fd3ae-20231223175001-nylrfie.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这条链就是大名鼎鼎的"),v("strong",[_._v("版本链")]),_._v(". 这个"),v("mark",[v("strong",[_._v("版本链存储在所谓的 undolog 里面")])]),_._v(", undolog 下一节会详细讨论.")]),_._v(" "),v("p",[_._v("现在问题来了, 假如这个时候有一个新的事务 C, 要读 x 的值, 那么该读取 trx_id 为几的数据呢? 这就涉及到了另外一个和 MVCC 紧密相关的概念: "),v("mark",[v("strong",[_._v("Read View")])]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"read-view"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#read-view"}},[_._v("#")]),_._v(" Read View")]),_._v(" "),v("p",[v("strong",[_._v("Read View 可以理解成是一种可见性规则")]),_._v(". 回滚日志(undo log)里面存放着历史版本的数据, 当事务内部要读取数据的时候, "),v("strong",[_._v("Read View 就被用来控制这个事务应该读取哪个版本的数据")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("Read View 最关键的字段叫做 m_ids, 它代表的是当前已经开始, 但是还没有结束的事务的 ID, 也叫做活跃事务 ID")]),_._v(".")]),_._v(" "),v("p",[_._v("Read View "),v("strong",[_._v("只用于已提交读和可重复读")]),_._v("两个隔离级别, 它用于这两个隔离级别的不同点就在于"),v("strong",[_._v("什么时候生成 Read View")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("已提交读")]),_._v(": 事务"),v("strong",[_._v("每次发起查询的时候, 都会重新创建一个新的 Read View")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("可重复读")]),_._v(": 事务"),v("strong",[_._v("开始的时候, 创建出 Read View")]),_._v(".")])]),_._v(" "),v("p",[_._v("已提交读就像你的渣男朋友, 你每次见到他, 他都会换一个新对象; 而可重复读就是一个痴情男, 你每次见到他, 看到的都是他高中时候谈的对象.")]),_._v(" "),v("h6",{attrs:{id:"read-view与已提交读"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#read-view与已提交读"}},[_._v("#")]),_._v(" Read View与已提交读")]),_._v(" "),v("p",[_._v("在已提交读的隔离级别下, "),v("strong",[_._v("每一次")]),_._v("​"),v("mark",[v("strong",[_._v("查询语句")])]),_._v("​"),v("strong",[_._v("都会重新生成一个 Read View")]),_._v(". 这意味着在事务执行过程中, Read View 是在不断变动的. 现在来看一个例子, 假如现在已经有三个事务了, 状态分别是已提交, 未提交, 未提交.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/28d8fa3fca19cd6aa074060a166949d2-20231223175001-ibvuhun.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("假如说现在新开了一个事务 A, 分配给它的 ID 是 4. 如果这个时候 A 开始查询 x 的值, 那么 MySQL 会创建一个新的 Read View, 其中 "),v("code",[_._v("m_ids = 2,3")]),_._v("​. 事务 A 发现最后一个已经提交的是事务 "),v("code",[_._v("trx_id = 1")]),_._v("​, 对应的 x 的值是 1. 于是事务 A 读到 x = 1.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c226080b4a200eeecd01a623365dd2d5-20231223175001-7cjsl5g.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("如果这个时候事务 2 提交了, 事务 A 再次读取 x, 这个时候 MySQL "),v("strong",[_._v("又会生成一个新的 Read View")]),_._v(" "),v("code",[_._v("m_ids=3")]),_._v("​. 因此事务 A 会读取到 x = 4.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e2f5cf70f686e1cd9e67b8f90d5e9e4e-20231223175001-zar75y9.png",alt:""}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"read-view与可重复读"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#read-view与可重复读"}},[_._v("#")]),_._v(" Read View与可重复读")]),_._v(" "),v("p",[_._v("在可重复读的隔离级别下, 数据库会"),v("mark",[v("strong",[_._v("在事务开始的时候")])]),_._v("​"),v("strong",[_._v("生成一个 Read View")]),_._v(". 这意味着"),v("strong",[_._v("整个 Read View 在事务执行过程中都是稳定不变的")]),_._v(". 用前面的例子来说明, 就是在事务 A 开始的时候就会创建出来一个 Read View "),v("code",[_._v("m_ids=2,3")]),_._v("​.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7a7e1a1b069dbab48dbb52939ecffe6c-20231223175001-fj866fo.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果这时候事务 A 去读 x 的数据, 毫无疑问, 读出来的是 x=1.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c226080b4a200eeecd01a623365dd2d5-20231223175001-7cjsl5g.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果这时候事务 2 提交了, 然后事务 A 想要再去读 x 的值, Read View 不会发生变化, 还是 "),v("code",[_._v("m_ids = 2,3")]),_._v("​. 所以可以看到, 虽然事务 2 提交了, 但是事务 A "),v("strong",[_._v("完全不知道这回事")]),_._v(", 因此它还是读到 x=1.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9d5c4983202b2077b53579c8eddfc733-20231223175001-p4f0s4e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("万一这时候有一个新事务 ID = 5 开始了, 并且也提交了. "),v("strong",[_._v("那么事务 A 并不会读取这个新事务的数据, 因为新事务 ID 已经大于事务 A 的 ID 了(5 > 4)")]),_._v(" , 事务 A 知道这是一个比它还要晚的事务, 所以会忽略新的事务的修改.")]),_._v(" "),v("h6",{attrs:{id:"read-view小结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#read-view小结"}},[_._v("#")]),_._v(" Read View小结")]),_._v(" "),v("p",[_._v("下面把前面的内容整合在一起画成了图, 可以参考.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0370dd5c3b73da1a06e62e175ae2410a-20231223175001-p7klkye.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/619e22884e6719182afaf90ba92a4c7a-20231223175001-3rgzq4m.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里只提到了 m_ids, 实际上和 Read View 相关的概念还有三个.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("m_up_limit_id 是指 m_ids 中的最小值")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("m_low_limit_id 是指下一个分配的事务 ID")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("m_creator_trx_id 当前事务 ID")]),_._v(".")])]),_._v(" "),v("p",[_._v("那么可见性如下图所示:")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cd9e5fc6dccb166f3894ce0a7fb27f19-20231223175001-ykq9vit.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("m_up_limit_id 在左边, 而 m_low_limit_id 在右边, 不要记错了. 实际上, m_up_limit_id 和 m_low_limit_id 记不住也没关系, 它不影响对 MVCC 和 ReadView 核心逻辑的理解.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-13"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-13"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("有了前面基础知识的铺垫, 现在可以分清重点了. 那么在面试中应该关注哪些细节呢?")]),_._v(" "),v("p",[_._v("首先需要了解清楚你们公司"),v("strong",[_._v("数据库的隔离级别")]),_._v(", 如果设置的不是默认的隔离级别, 那么就要搞清楚为什么不使用默认隔离级别. 尤其是用了未提交读, 串行化两个隔离级别, 更加要弄清楚为什么决定使用这两个隔离级别.")]),_._v(" "),v("p",[_._v("在面试过程中, 面试官会出一些让人很难反应过来的问题. 比如说面试官会口头构造一条版本链.")]),_._v(" "),v("blockquote",[v("p",[_._v("我现在有三个事务, ID 分别是 101, 102, 103. 如果事务 101 已经提交了, 但是 102, 103 还没提交. 这个时候开启了一个事务, 准备读取数据, 那么读到的是哪个事务的数据?")])]),_._v(" "),v("p",[_._v("如果这时候回答读取到事务 101 的数据, 那么面试官就进一步追问.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果这时候事务 103 提交了, 但是 102 还没提交, 那么会读到谁的呢?")])]),_._v(" "),v("p",[_._v("下面就要回答根据隔离级别来了.")]),_._v(" "),v("p",[_._v("这种问题很难反应过来是因为需要快速在脑海里面建立起整个版本链, 然后综合考虑隔离级别以及谁先提交谁后提交, 才能正确回答出来. 想一下刚才读到那一段话的时候, 是不是有一种迷糊的感觉? 在面试那种紧张的氛围下, 只会觉得迷糊, 难以反应过来.")]),_._v(" "),v("p",[_._v("建议是只要对这一类问题有一个心理预期就可以了. 在面试的时候要是一时半会没办法回答出来, 可以"),v("strong",[_._v("请求面试官再说一遍, 并且说慢一点")]),_._v(". 如果面试官好说话, 还可以借助纸笔, 直接将这个东西画出来, 再来分析最终读到的是什么数据.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-10"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-10"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("有些时候面试官会在面了锁之后, 将话题引到 MVCC, 问"),v("strong",[_._v("为什么有了锁, 还需要 MVCC")]),_._v("? 在回答的时候要答出关键词"),v("strong",[_._v("避免读写阻塞.")])]),_._v(" "),v("blockquote",[v("p",[_._v("单纯使用锁的时候, 并发性能会比较差. 即便是在读写锁这种机制下, 读和写依旧是互斥的. 而数据库是一个性能非常关键的中间件, 如果某个线程修改某条数据就让其他线程都不能读这条数据, 这种性能损耗是无法接受的. 所以 InnoDB 引擎引入了 MVCC, 就是为了减少读写阻塞.")])]),_._v(" "),v("p",[_._v("大部分时候, 面试官在问 MVCC 的时候, 都是直接问这几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("你是否了解 MVCC?")]),_._v(" "),v("li",[_._v("MVCC 是什么?")]),_._v(" "),v("li",[_._v("MySQL 的 InnoDB 引擎是怎么控制数据并发访问的?")]),_._v(" "),v("li",[_._v("当一个线程在修改数据的时候, 另外一个线程还能不能读到数据?")])]),_._v(" "),v("p",[_._v("这时候就要简明扼要地把原理解释清楚. 按照 "),v("strong",[_._v("基本定义, 实现机制, 隔离级别")]),_._v(" 的逻辑顺序来回答.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("MVCC 是 MySQL InnoDB 引擎用于控制数据并发访问的协议. MVCC 主要是借助于版本链来实现的. 在 InnoDB 引擎里面, 每一行都有两个额外的列, 一个是 trx_id, 代表的是修改这一行数据的事务 ID. 另外一个是 roll_ptr, 代表的是回滚指针. InnoDB 引擎通过回滚指针, 将数据的不同版本串联在一起, 也就是版本链. 这些串联起来的历史版本, 被放到了 undolog 里面. 当某一个事务发起查询的时候, MVCC 会根据事务的隔离级别来生成不同的 Read View, 从而控制事务查询最终得到的结果")]),_._v(".")])]),_._v(" "),v("p",[_._v("这里的话术非常简洁, 基本上没有涉及任何细节, 但是又提及了足够多的关键词.")]),_._v(" "),v("p",[_._v("首先, 在回答里提到了 undolog, 那么接着面试官就可能追问 undolog, redolog 或者 binlog 的细节, 这一部分可以把话题引到下一节的内容.")]),_._v(" "),v("p",[_._v("其次, 在回答中提到了隔离级别, 并且提到了 Read View 是和隔离级别有关的东西, 那么面试官就会非常深入地问隔离级别的基本定义, MVCC 是怎么利用 Read View 来实现已提交读和可重复读的.")]),_._v(" "),v("p",[_._v("在回答的时候, 要先解释清楚 "),v("strong",[_._v("四个隔离级别和三个读异常")]),_._v(", 然后强调一下 InnoDB 引擎.")]),_._v(" "),v("blockquote",[v("p",[_._v("在 MySQL 的 InnoDB 引擎里面, 使用了临键锁来解决幻读的问题, 所以实际上 MySQL InnoDB 引擎的可重复读隔离级别也没有幻读的问题. 一般来说, 隔离级别越高, 性能越差. 所以我之前在公司做的一个很重要的事情, 就是推动隔离级别降低为已提交读.")])]),_._v(" "),v("p",[_._v("这个回答的最后, 就可以尝试将话题引导到下面的亮点方案中.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-8"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这一个亮点方案重点在于描述清楚两方面的内容.")]),_._v(" "),v("ol",[v("li",[_._v("推动公司将隔离级别从默认的可重复读降低为已提交读.")]),_._v(" "),v("li",[_._v("在已提交读的基础上, 万一需要利用可重复读的特性, 该怎么办?")])]),_._v(" "),v("p",[_._v("从前面的内容中已经知道, MySQL 的默认隔离级别是可重复读, 实际上互联网的"),v("strong",[_._v("很多应用都调整过这个隔离级别, 降低为已提交读")]),_._v(".")]),_._v(" "),v("p",[_._v("那么在面试的时候可以考虑使用这个来作为亮点方案. 首先要强调"),v("mark",[v("strong",[_._v("为什么要改")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始我来到公司的时候, 数据库隔离级别都是使用默认的隔离级别, 也就是可重复读. 但其实我们的业务场景很少利用可重复读的特性, 比如说几乎全部事务内部对某一个数据都是只读一次的.")]),_._v(" "),v("p",[_._v("并且, 可重复读比已提交读更加容易引起死锁的问题, 比如之前就出现过一个因为临键锁引发的死锁问题. 而且已提交读的性能要比可重复读更好. 所以综合之下, 我就推动公司去调整隔离级别, 将数据库的默认隔离级别降低为已提交读.")])]),_._v(" "),v("p",[_._v('在这种情况下, 面试官可能会追问你: "在调整了事务级别之后, 万一需要可重复读的特性了, 你怎么办?"')]),_._v(" "),v("p",[_._v("首先要理解"),v("strong",[_._v("在什么样的场景下才会需要可重复读这个隔离级别")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("需要在事务中发起两次同样的查询, 并且希望两次得到的结果是一样的")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("需要避开幻读")]),_._v(", 也就是事务开始之后, 即便有别的事务插入了数据并且提交了, 也不希望读到这个新数据.")])]),_._v(" "),v("p",[_._v("但是仔细想想, 真的存在这种场景吗? 或者说, 你真的没得选, 以至于一定要使用可重复读这个隔离级别吗?")]),_._v(" "),v("p",[_._v("答案是几乎没有. 大部分出现可重复读的需求都是因为代码没有写好, 或者说至少可以通过改造业务来实现. 比如说常见的可重复读, "),v("strong",[_._v("既然需要读多次, 那么自然可以在第一次读完之后缓存起来")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("不过幻读是没有办法通过业务改造来解决的")]),_._v(". 但是在业务层面上, 幻读一般不会被认为是一个问题, 原因有两点: 一是你分不清是不是幻读. 比如在事务 A 里面读到了一条数据, 你"),v("strong",[_._v("判断不出来它是在事务 A 开始之前就插入的, 还是在事务 A 开始之后, 事务 B 才插入并且提交的")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73ae591deec6d782d2e690f0585565e6-20231223175001-615q4a8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("二是事务提交往往意味着业务已经结束, 所以读到一个已经提交的事务的数据, 不会损害业务的正确性. 也就是说, 如果事务 A 在开始之后, 事务 B 才插入数据并且提交. 那么这个时候事务 A 完全可以认为事务 B 所在的整个业务已经结束了, 那么读出来也没什么问题.")]),_._v(" "),v("p",[_._v("所以可以这么回答, 关键词是 "),v("strong",[_._v("改造业务.")])]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说是不推荐使用可重复读的, 因为在业务环境下想不到有什么场景非得使用可重复读这个隔离级别.")]),_._v(" "),v("p",[_._v("之前在推动降低隔离级别的时候, 我其实重构过一些业务. 这一类业务就是在一个事务里面发起了两个同样的查询, 比如说在 UPDATE 之后又立刻查询, 这种查询还必须走主库, 不然会有主从延迟的问题.")]),_._v(" "),v("p",[_._v("这种业务可以通过缓存第一次查询的数据来避免第二次查询. 但是这种改造一般是避不开幻读的. 不过在业务上幻读一般不是问题. 一方面是业务层面上区分不出来是否是幻读. 另外一方面, 事务提交了往往代表业务已经结束, 那么发生幻读了, 业务依旧是正常的. 比如说事务 A 读到了事务 B 新插入的数据, 但事务 B 本身已经提交了, 那么事务 A 就认为事务 B 所在的业务已经完结了, 那么读到了就读到了, 并不会出什么问题.")])]),_._v(" "),v("p",[_._v("但这种回答, 如果遇上较真的面试官, 他依旧会觉得不满意, 那么就可以使出最后的兜底手段, 关键词是"),v("strong",[_._v("指定隔离级别.")])]),_._v(" "),v("blockquote",[v("p",[_._v("万一不能改造业务, 那么还有一个方法, 就是直接在创建事务的时候指定隔离级别. 前面调整的都是数据库的默认隔离级别, 实际上还可以在 Session 或者事务这两个维度上指定隔离级别.")])]),_._v(" "),v("p",[_._v("如果记不住或者难以理解如何改造业务代码, 只需要回答这一点就可以.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-13"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-13"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("今天重点学习了 MVCC 的基本原理, 这里总结一下这节课的主要内容.")]),_._v(" "),v("ol",[v("li",[_._v("需要记住"),v("strong",[_._v("为什么需要 MVCC")]),_._v(", 尤其是在有锁机制的情况下, 为什么还需要 MVCC? 主要是为了读写并发.")]),_._v(" "),v("li",[_._v("需要记住"),v("strong",[_._v("四个隔离级别")]),_._v(": 未提交读, 已提交读, 可重复读, 串行化, 以及和隔离级别密切相关的三个读异常: 脏读, 不可重复读, 幻读.")]),_._v(" "),v("li",[_._v("需要"),v("strong",[_._v("记住 MVCC 是如何构造版本链")]),_._v("的.")]),_._v(" "),v("li",[_._v("需要"),v("strong",[_._v("记住 Read View 在不同的隔离级别下是如何运作的")]),_._v(".")])]),_._v(" "),v("p",[_._v("最后也给出一个调整隔离级别的亮点方案, 面试的时候要抓住两个关键点.")]),_._v(" "),v("ul",[v("li",[_._v("为什么要调整为已提交读? 主要原因有两个: 一是因为业务用不上, 二是为了提升性能.")]),_._v(" "),v("li",[_._v("在调整之后真的需要可重复读隔离级别该怎么办? 就按照给出的话术回答就好了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3ef1f8997756f958930d73ec310c9fe0-20231223175001-omr1a9l.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-11"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-11"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("MVCC 只作用于已提交读和可重复读, 那么 InnoDB 是怎么处理其他两个隔离级别的?")]),_._v(" "),v("li",[_._v("你有没有遇到过看起来真的要可重复读这个隔离级别的问题? 如果遇到了, 你现在有办法在已提交读这个隔离级别上解决这个问题吗?")])]),_._v(" "),v("p",[_._v("欢迎你把你的答案分享在评论区, 也欢迎你把这节课的内容分享给需要的朋友, 我们下节课再见!")]),_._v(" "),v("h5",{attrs:{id:"面试锦囊"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试锦囊"}},[_._v("#")]),_._v(" 面试锦囊")]),_._v(" "),v("p",[_._v("到了后面的几面, 面试官很有可能会问你这种影响很大的事情你是怎么推进的? 你是如何说服同事的? 你是如何说服上司的? 这一类问题就属于软技能. 类似这种推进某件事情的策略, 基本上都可以按照准备充分, 公开决议, 小步推进, 全面铺开四步来回答.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("准备充分")]),_._v(": 当准备推进一件事的时候, 要充分调研实际情况, 提出针对性的方案. 需要强调你知道为什么不做不行, 以及如果要做该怎么做. 就拿这节的内容来说, 你已经调研清楚了业务上确实用不到可重复读这个隔离级别, 并且公司也的确出过死锁的案例. 而你的计划是先从比较简单的不重要的数据库开始, 降低隔离级别, 经过验证之后再推广. 或者采用更简单的方案, 就是老的数据库不变, 新的数据库就使用已提交读来作为默认的隔离级别.")]),_._v(" "),v("li",[v("strong",[_._v("公开决议")]),_._v(": 正常来说, 一般要先和关键人物沟通, 取得支持. 然后在公开会议上抛出议题, 取得大多数人的支持. 这一步其实有点自保的意味, 因为群体决策就意味着群体负责. 并且取得大多数人的支持之后, 推进一件事会更加容易.")]),_._v(" "),v("li",[v("strong",[_._v("小步推进")]),_._v(": 放到这节课就是按照你的计划, 先改造不重要业务的数据库, 或者只在新的数据库上应用. 也就是说在实施的初期, 先小规模推进. 这样可以验证方案的正确性, 也可以在出事的时候将影响范围控制住.")]),_._v(" "),v("li",[v("strong",[_._v("全面铺开")]),_._v(": 你有了成熟的改造经验之后, 就可以制定操作规范之类的东西了, 让业务的负责人自己选择合适的时机进行切换. 在经过了前一个步骤的验证之后, 你对方案的弊病, 落地可能出现的问题就都心中有数了. 这时候就可以全面铺开了.")])]),_._v(" "),v("p",[_._v("软技能面试在整个面试过程中, 有一点成事不足败事有余的味道. 意思是说, 如果你硬实力-技术实力不达标, 软技能面出花来, 也没用, 这就是成事不足; 但是如果硬实力很强, 但是后面老大和部门负责人面试你的时候觉得你软技能不行, 那你依旧会被淘汰, 这就是败事有余.")]),_._v(" "),v("h4",{attrs:{id:"_14-数据库事务-事务提交了-你的数据就一定不会丢吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_14-数据库事务-事务提交了-你的数据就一定不会丢吗"}},[_._v("#")]),_._v(" 14-数据库事务:事务提交了,你的数据就一定不会丢吗?")]),_._v(" "),v("p",[_._v("今天来学习数据库中非常重要的一部分-数据库事务. 这节课的内容和前面 MVCC 的内容联系很紧密, 要结合在一起学习.")]),_._v(" "),v("p",[_._v("数据库事务在面试中占据了比较重的分量. 如果面的是非常初级的岗位, 那么可能就是问问事务的 ACID 特性. 不然基本上都要深入 redo log 和 undo log 这种事务实现机制上去. 所以这一节课会深入分析 redo log 和 undo log. 同时也会告诉你, 哪些知识是比较基础的, 一定要掌握; 哪些知识是比较高级的, 尽量记住, 面试时作为亮点来展示.")]),_._v(" "),v("p",[_._v("最后会给出两个比较高级的方案, 一个是侧重理论的写入语义大讨论, 一个是侧重实践的调整 MySQL 参数. 先从 undo log 开始说起.")]),_._v(" "),v("h5",{attrs:{id:"前置知识-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#前置知识-8"}},[_._v("#")]),_._v(" 前置知识")]),_._v(" "),v("h6",{attrs:{id:"undo-log"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#undo-log"}},[_._v("#")]),_._v(" undo log")]),_._v(" "),v("p",[_._v("上一节说过"),v("strong",[_._v("版本链是存放在的 undo log 里面的")]),_._v(". 那么 undo log 到底是什么呢?")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("undo log 是指回滚日志")])]),_._v(", 用一个比喻来说, 就是后悔药, "),v("strong",[_._v("它记录着事务执行过程中被修改的数据. 当事务回滚的时候, InnoDB 会根据 undo log 里的数据撤销事务的更改, 把数据库恢复到原来的状态")]),_._v(".")]),_._v(" "),v("p",[_._v("既然 undo log 是用来回滚的, 那么不同的语句对应的 undo log 形态会不一样.")]),_._v(" "),v("ul",[v("li",[_._v("对于 INSERT 来说, 对应的 undo log 应该是 DELETE.")]),_._v(" "),v("li",[_._v("对于 DELETE 来说, 对应的 undo log 应该是 INSERT.")]),_._v(" "),v("li",[_._v("对于 UPDATE 来说, 对应的 undo log 也应该是 UPDATE. 比如说有一个数据的值原本是 3, 要把它更新成 5. 那么对应的 undo log 就是把数据更新回 3.")])]),_._v(" "),v("p",[_._v("但是实际上 undo log 的实现机制要更复杂一点, 这里简化一下模型帮助记忆. 对于 INSERT 来说, 对应的 undo log 记录了该行的主键. 那么后续只需要根据 undo log 里面的主键去原本的聚簇索引里面删掉记录, 就可以实现回滚效果.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/70aa62a4cf4dc18778a6d0eba05dyye3-20231223175001-wtrls0u.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("对于 DELETE 来说, 对应的 undo log 记录了该行的主键. 因为在事务执行 DELETE 的时候, 实际上并没有真的把记录删除, 只是把原记录的"),v("strong",[_._v("删除标记位设置成了 true")]),_._v(". 所以这里 undo log 记录了主键之后, 在回滚的时候就可以根据 undo log 找到原本的记录, 然后再把删除标记位设置成 false.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b3a99a0f107b926c2cdd47699c62bd6-20231223175001-ikzq30g.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("对于 UPDATE 来说, 要更加复杂一些. 分为两种情况, 如果没有更新主键, 那么 "),v("strong",[_._v("undo log 里面就记录原记录的主键和被修改的列的原值")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c55e16e624ff158536111af9764ef591-20231223175001-59utcvi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果更新了主键, 那么可以看作是删除了原本的行, 然后插入了一个新行. 因此 undo log 可以看作是一个 DELETE 原数据的 undo log 再加上插入一个新行的 undo log.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1f8df91aab280230e4a1ea4512570018-20231223175001-1qmz9sq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从上面大概也能看出来, "),v("strong",[_._v("undo log 和 MVCC 中版本链的关系")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b6c9ec706fyy62d235f2d5c590536368-20231223175001-m6amhu1.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这部分知识有些难, 如果不是数据库岗位或者专家岗, 了解这部分就可以了. 接下来看一个和事务有关的另外一个日志 redo log.")]),_._v(" "),v("h6",{attrs:{id:"redo-log"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redo-log"}},[_._v("#")]),_._v(" redo log")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("InnoDB 引擎在数据库发生更改的时候, 把更改操作记录在 redo log 里, 以便在数据库发生崩溃或出现其他问题的时候, 能够通过 redo log 来重做")])]),_._v(".")]),_._v(" "),v("p",[_._v("你可能会觉得奇怪, InnoDB 引擎不是直接修改了数据吗? 为什么需要 redo log? 答案是 "),v("mark",[v("strong",[_._v("InnoDB 引擎读写都不是直接操作磁盘的, 而是读写内存里的 buffer pool, 后面再把 buffer pool 里面修改过的数据刷新到磁盘里面. 这是两个步骤, 所以就可能会出现 buffer pool 中的数据修改了, 但是还没来得及刷新到磁盘数据库就崩溃了的情况")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e7e24d9bb6cce4d66c3d747f4919f54d-20231223175001-d85rzb2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了解决这个问题, InnoDB 引擎就引入了 redo log. "),v("strong",[_._v("相当于 InnoDB 先把 buffer pool 里面的数据更新了, 再写一份 redo log. 等到事务结束之后, 就把 buffer pool 的数据刷新到磁盘里面. 万一事务提交了, 但是 buffer pool 的数据没写回去, 就可以用 redo log 来恢复")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1d45b0f67230ba7957c450198b324db5-20231223175001-5252f4z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("你可能会困惑, redo log 不需要写磁盘吗? 如果 redo log 也要写磁盘, 干嘛不直接修改数据呢? redo log 是需要写磁盘的, 但是 redo log 是 "),v("mark",[v("strong",[_._v("顺序写")])]),_._v(" 的, 所以也是 "),v("strong",[_._v("WAL")]),_._v("(write-ahead-log) 的一种. "),v("strong",[_._v("也就是不管要修改什么数据, 一会修改这条数据, 一会修改另外一条数据, redo log 在磁盘上都是紧挨着的")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/22f603543b8e3dc0eb1a0d9a7a3cc0be-20231223175001-zqxby4i.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这是中间件设计里常用的技巧--顺序写取代随机写. "),v("strong",[_._v("顺序写的性能比随机写要好很多")]),_._v(", 即便是在 SSD 上, 顺序写也能比随机写速度快上一个数量级. 但是还要考虑一点: redo log 是直接一步到位写到磁盘的吗?")]),_._v(" "),v("p",[_._v("并不是的, "),v("mark",[v("strong",[_._v("redo log 本身也是先写进 redo log buffer, 后面再刷新到操作系统的 page cache, 或者一步到位刷新到磁盘")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/513ac0409bcc8c0f9800365659a3f221-20231223175001-7todys2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("InnoDB 引擎本身提供了参数 "),v("mark",[v("strong",[_._v("innodb_flush_log_at_trx_commit")])]),_._v(" 来控制写到磁盘的时机, 里面有三个不同值.")]),_._v(" "),v("ul",[v("li",[_._v("0: "),v("strong",[_._v("每秒刷新到磁盘")]),_._v(", 是从 redo log buffer 到磁盘.")]),_._v(" "),v("li",[_._v("1: "),v("strong",[_._v("每次提交的时候刷新到磁盘上")]),_._v(", 也就是最安全的选项, InnoDB 的 "),v("strong",[_._v("默认值")]),_._v(".")]),_._v(" "),v("li",[_._v("2: "),v("strong",[_._v("每次提交的时候刷新到 page cache 里, 依赖于操作系统后续刷新到磁盘")]),_._v(".")])]),_._v(" "),v("p",[_._v("这时候你就应该意识到这样一个问题, "),v("strong",[_._v("除非把 innodb_flush_log_at_trx_commit 设置成 1, 否则其他两个都有丢失的风险")]),_._v(".")]),_._v(" "),v("ul",[v("li",[_._v("0: 提交之后, InnoDB 还没把 redo log buffer 中的数据刷新到磁盘, 就宕机了.")]),_._v(" "),v("li",[_._v("2: 提交之后, InnoDB 把 redo log 刷新到了 page cache 里面, 紧接着宕机了.")])]),_._v(" "),v("p",[_._v("在这两个场景下, "),v("strong",[_._v("你的业务都认为事务提交成功了, 但是数据库实际上丢失了这个事务")]),_._v(". 但是并不是说 InnoDB 引擎会严格遵循参数说明的那样来刷新磁盘, 还有两种例外情况.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("如果 redo log buffer 快要满了, 也会触发把 redo log 刷新到磁盘里这个动作")]),_._v(". 一般来说, 默认放一半了就会刷新.")]),_._v(" "),v("li",[v("strong",[_._v("如果某个事务提交的时候触发了刷新到磁盘的动作, 那么当下所有事务的 redo log 也会一并刷新")]),_._v(". 毕竟大家的 redo log 都是放在 redo log buffer 里, 有人需要刷新了, 就顺手一起刷新了. 类似于你去买奶茶, 顺手帮你同事带一杯.")])]),_._v(" "),v("p",[_._v("现在已经了解了 undo log 和 redo log 的用法和机制, 那来总结一下 InnoDB 是如何综合利用它们来实现事务的.")]),_._v(" "),v("h6",{attrs:{id:"事务执行过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#事务执行过程"}},[_._v("#")]),_._v(" 事务执行过程")]),_._v(" "),v("p",[_._v("这里用一个 UPDATE 语句执行的例子来介绍事务执行过程. 假如原本 a = 3, 现在要执行 "),v("code",[_._v("UPDATE tab SET a = 5 WHERE id = 1")]),_._v("​.")]),_._v(" "),v("ol",[v("li",[_._v("事务开始, 在执行 UPDATE 语句之前会先查找到"),v("strong",[_._v("目标行, 加上锁, 然后写入到 buffer pool 里面")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/90f4e190b125805c35301b2fed37207d-20231223175001-hloo9o0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[v("strong",[_._v("写 undo log")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/17bdcbef72866926af4d5eda4979380e-20231223175001-jn3bxil.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[_._v("InnoDB 引擎"),v("strong",[_._v("在内存上更新值, 实际上就是把 buffer pool 的值更新为目标值 5")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7f29be5e8642431fa32c753091543f0c-20231223175001-7etjl4d.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[v("strong",[_._v("写 redo log")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/93e4cef542b1c6068cb41117ec290941-20231223175001-52o9r2s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"5"}},[v("li",[v("strong",[_._v("提交事务, 根据 innodb_flush_log_at_trx_commit 决定是否刷新 redo log")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4e20de0c7eb22d8394e3edf9555d4150-20231223175001-aq74zxw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"6"}},[v("li",[v("strong",[_._v("刷新 buffer pool 到磁盘")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f0e5f266b4117f0e32cde46afae1e0cb-20231223175001-xd8yxee.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("上面这个是最正常的流程. 那么它还有两个比较重要的"),v("strong",[_._v("子流程")]),_._v(".")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("如果在 redo log 已经刷新到磁盘, 然后数据库宕机了, buffer pool 丢失了修改, 那么在 MySQL 重启之后就会回放这个 redo log, 从而纠正数据库里的数据")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果都没有提交, 中途回滚, 就可以利用 undo log 去修复 buffer pool 和磁盘上的数据")]),_._v(". 因为有时 buffer pool 脏页会在事务提交前刷新磁盘, 所以 undo log 也可以用来修复磁盘数据.")])]),_._v(" "),v("p",[_._v("实际上, 事务执行过程有很多细节, 也要比这里描述得复杂很多. 如果感兴趣, 可以再继续深挖下去. 不过如果是为了在面试中展示, 上面的这些内容也够用了.")]),_._v(" "),v("h6",{attrs:{id:"binlog"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#binlog"}},[_._v("#")]),_._v(" binlog")]),_._v(" "),v("p",[_._v("binlog 是一个看起来和 redo log, undo log 很像的东西, 但是它们之间的差异还是挺大的. "),v("mark",[v("strong",[_._v("binlog 是用于存储 MySQL 中二进制日志(Binary Log)的操作日志文件, 它是 MySQL Server 级别的日志, 也就是说所有引擎都有. 它记录了 MySQL 中数据库的增删改操作, 因此 binlog 主要有两个用途, 一是在数据库出现故障时恢复数据. 二是用于主从同步, 即便是 Canal 这一类的中间件本质上也是把自己伪装成一个从节点")])]),_._v(".")]),_._v(" "),v("p",[_._v("在事务执行过程中, 写入 binlog 的时机有点巧妙. "),v("mark",[v("strong",[_._v("它和 redo log 的提交过程结合在一起称为 MySQL 的两阶段提交")])]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("第一阶段: redo log Prepare(准备)")])]),_._v(" "),v("li",[v("strong",[_._v("第二阶段: redo log Commit(提交)")])])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/30yy9f0yyfa99c0f8a5378e4b62af263-20231223175001-gr82uj6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("如果 redo log Prepare 执行完毕后, binlog 已经写成功了, 那么即便 redo log 提交失败, MySQL 也会认为事务已经提交了")]),_._v(". 如果 binlog 没写成功, 那么 MySQL 就认为提交失败了. 比较简单的记忆方式就是看"),v("mark",[v("strong",[_._v("binlog 写成功了没有")])]),_._v(". binlog 本身有一些完整性校验的规则, 所以"),v("strong",[_._v("在 MySQL 看来, 写 binlog 要么成功, 要么失败, 不存在中间状态")]),_._v(".")]),_._v(" "),v("p",[_._v("下面用正统的两阶段提交图来说明一下, 在这个图里"),v("strong",[_._v("把写入 binlog 拆成了 Prepare 和 Commit 两个阶段")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1911847117dbf63e07923649b9f80e1a-20231223175001-ardhd0e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从图里就可以看出来, 之所以以 binlog 为判断标准, 是因为"),v("strong",[_._v("在两阶段提交里面, 两个参与方 binlog 和 redo log 中, binlog 已经提交成功了, 那么 redo log 自然可以认为也提交成功了")]),_._v(". 但是要强调, 这只是为了方便理解, "),v("strong",[_._v("实际上 binlog 没有显式的 Prepare 和 Commit 两个阶段")]),_._v(".")]),_._v(" "),v("p",[_._v("binlog 也有刷新磁盘的问题, 不过可以通过 "),v("strong",[_._v("sync_binlog")]),_._v(" 参数来控制它.")]),_._v(" "),v("ul",[v("li",[_._v("0: 由操作系统决定, 写入 page cache 就认为成功了. 0 也是默认值, 这个时候数据库的性能最好.")]),_._v(" "),v("li",[_._v("N: 每 N 次提交就刷新到磁盘, N 越小性能越差. 如果 N = 1, 那么就是每次事务提交都把 binlog 刷新到磁盘.")])]),_._v(" "),v("p",[_._v("可以对比一下 sync_binlog 和 redo log 的 innodb_flush_log_at_trx_commit 参数, 加深印象. 最后再补充一点非常基础的事务的 ACID 特性.")]),_._v(" "),v("h6",{attrs:{id:"acid特性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#acid特性"}},[_._v("#")]),_._v(" ACID特性")]),_._v(" "),v("p",[_._v("事务的 ACID 特性是指原子性(Atomicity), 一致性 (Consistency), 隔离性(Isolation)还有持久性(Durability).")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("原子性")]),_._v(": 事务是一个不可分割的整体, 它在执行过程中不能被中断或推迟, 它的所有操作都必须一次性执行, 要么都成功, 要么都失败.")]),_._v(" "),v("li",[v("strong",[_._v("一致性")]),_._v(": 事务执行的结果必须满足数据约束条件, 不会出现矛盾的结果. 注意这里的一致性和我们讨论的分布式环境下的一致性语义有所差别, 后者强调的是不同数据源之间数据一致.")]),_._v(" "),v("li",[v("strong",[_._v("隔离性")]),_._v(": 事务在执行的时候可以隔离其他事务的干扰, 也就是不同事务之间不会相互影响.")]),_._v(" "),v("li",[v("strong",[_._v("持久性")]),_._v(": 事务执行的结果必须保证在数据库里永久保存, 即使系统出现故障或者数据库被删除, 事务的结果也不会丢失.")])]),_._v(" "),v("p",[_._v("这个知识点就比较基础, 是一定要记住的.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-14"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-14"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("需要弄清楚自己公司内部的一些配置.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("有没有修改过 sync_binlog, innodb_flush_log_at_trx_commit 的值? 如果修改过, 为什么修改")]),_._v("?")]),_._v(" "),v("li",[_._v("你"),v("strong",[_._v("使用过的中间件有没有类似 redo log, binlog 的刷盘机制")]),_._v("?")])]),_._v(" "),v("p",[_._v("因为事务的机制比较复杂, 涉及 redo log 和 undo log 的各种配合, 所以要提前思考一下事务执行过程的各种异常情况, 就是当中途某个操作执行成功了, 万一数据库宕机, 数据库恢复过来之后会怎么处理这个事务.")]),_._v(" "),v("p",[_._v("这里给你一个极简版口令, 非常好记.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("在 redo log 刷新到磁盘之前, 都是回滚")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果 redo log 刷新到了磁盘, 那么就是重放 redo log")]),_._v(".")])]),_._v(" "),v("p",[v("strong",[_._v("进一步结合 binlog, 就是如果 binlog 都已经提交成功了, 那么就重放, 确保事务一定成功了, 否则回滚")]),_._v(". 而回滚就是一句话: "),v("strong",[_._v("用 undo log 来恢复数据")]),_._v(".")]),_._v(" "),v("p",[_._v("上面这些极简描述, 是不管怎样都要记住的. 但是如果有时间的话最好记住前置知识里面提到的所有细节.")]),_._v(" "),v("p",[_._v("此外要对 undo log, redo log 的必要性有深刻理解. 因为面试官可能会问出一些反直觉的问题.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("没有 undo log 会怎样")]),_._v("? 没有 undo log 就没有后悔药, "),v("strong",[_._v("没有办法回滚")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("没有 redo log 会怎样")]),_._v("? 没有 redo log 的话, 写到 buffer pool, 宕机了就会"),v("strong",[_._v("丢失数据")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("为什么非得引入 redo log")]),_._v(", 干嘛不直接修改数据? "),v("strong",[_._v("直接修改数据就是随机写, 性能极差")]),_._v(".")])]),_._v(" "),v("p",[_._v("在面试过程中, 如果面试官聊起了操作系统中的写入操作, 谈到了 page cache 等内容, 那就可以谈 redo log, undo log 和 binlog 的写入语义, 还可以直接把话题引到后面的写入语义亮点上. 如果聊到了其他中间件的刷盘问题, 那就可以用 redo log 和 binlog 作为例子来说明. 如果提到了两阶段提交协议, 那么可以把话题引导到 redo log 和 binlog 的两阶段提交协议上.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-11"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-11"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("事务的面试可以说是方向多, 细节多. 比较常见的是问 ACID 中四个基本特性. 这里其实可以抓住机会来展示一个亮点, 关键词是"),v("strong",[_._v("隔离级别")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("ACID 中的隔离性是比较有意思的, 它和数据库的隔离级别概念密切相关. 我个人认为隔离级别中未提交读和已提交读看起来不太符合这里隔离性的定义. 按理来说, 可重复读也不满足. 但是 MySQL InnoDB 引擎的可重复读解决了幻读问题, 所以我认为 MySQL 的可重复读和串行化才算是满足了这里隔离性的要求.")])]),_._v(" "),v("p",[_._v("这里大概率会把话题引到隔离级别上, 这一部分内容已经学过了, 这里不再重复.")]),_._v(" "),v("p",[_._v("有些时候面试官就会直接问你 undo log, redo log, 或者直接问 InnoDB 的事务实现机制.")]),_._v(" "),v("p",[_._v("那么就可以先介绍 undo log, 然后可以进一步补充, 聊一聊 undo log 在 INSERT, DELETE 和 UPDATE 下是如何运作的, 这算是一个小亮点. 其次介绍 redo log, 这里可以进一步介绍 redo log 的刷盘问题, 也算是一个小亮点. 大体上来说能够解释清楚 undo log 和 redo log 就可以了. 如果面试官此时还没有打断的意思, 就继续介绍事务执行过程, 可以用给出的那个 UPDATE 例子来说明.")]),_._v(" "),v("p",[_._v("就事务执行而言, 到这一步基本上已经把核心知识都交代清楚了. 剩下的就是面试官会根据回答中的一些进行深挖. 一般的面试不太可能超出前置知识的范畴, 做好心理准备就可以. 至于 binlog, 完全可以等面试官进一步问. "),v("strong",[_._v("如果能记住 binlog 和 redo log 的两阶段提交协议")]),_._v(", 那么也算是回答中的一个小亮点.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-9"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-9"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("其实如果能在面试的时候把前置知识都用上, 那么至少能够得到一个 MySQL 基础扎实的评价. 不过还是可以进一步展示更加高级的亮点. 这里给出了两个, 第一个是写入语义, 第二个调整刷盘时机.")]),_._v(" "),v("h6",{attrs:{id:"写入语义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写入语义"}},[_._v("#")]),_._v(" 写入语义")]),_._v(" "),v("p",[_._v("在前面的分析中已经知道了, 当说写入 redo log 成功的时候, 实际上有不同的含义. "),v("strong",[_._v("比如说可能只是写到了 redo log buffer, 也可能是写到了 page cache, 还可能是一步到位写到了磁盘上")]),_._v(".")]),_._v(" "),v("p",[_._v("综合来说, 中间件的写入语义可能是以下 3 种.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("中间件写到自身的日志中或者缓冲区")]),_._v(", 就认为写入成功了.")]),_._v(" "),v("li",[v("strong",[_._v("中间件发起了系统调用, 写到了操作系统的 page cache 里面")]),_._v(", 就认为写入成功了.")]),_._v(" "),v("li",[v("strong",[_._v("中间件强制发起刷盘, 数据被持久化到了磁盘上")]),_._v(", 才认为写入成功了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8ed3ca780ff900b1b18c9fa15c481227-20231223175001-qta0bnu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("除了一步到位直接写到磁盘, 其他两种都要考虑一个问题, 就是最终什么时候把数据刷到磁盘呢")])]),_._v("? 思路也有两个, 一个是"),v("strong",[_._v("定时")]),_._v(", 比如说每秒刷到磁盘. 另一个是"),v("strong",[_._v("定量")]),_._v(", 这个就很灵活了, 比如说在事务这里基本都是按照提交次数. 而在消息队列里面, 就可以按照消息条数.")]),_._v(" "),v("p",[_._v("但这里并没有考虑到另外一个问题, 即在"),v("strong",[_._v("分布式环境下, 写入一份数据, 往往是指要写入主节点, 也要写入从节点")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8bbc229b85dbd11703a604c86e808dc8-20231223175001-8yj8kqf.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以在分布式环境下的写入语义更加含糊.")]),_._v(" "),v("ul",[v("li",[_._v("主节点写入成功, 就认为写入成功了.")]),_._v(" "),v("li",[_._v("主节点写入成功, 至少有一个从节点写入成功了, 就认为写入成功了.")]),_._v(" "),v("li",[_._v("主节点写入成功, 大多数从节点写入成功了, 就认为写入成功了.")]),_._v(" "),v("li",[_._v('主节点写入成功, 特定数量的从节点写入成功了, 就认为写入成功了. 一般来说, 这个"特定数量"是可配置的.')]),_._v(" "),v("li",[_._v("主节点写入成功, 全部从节点也写入成功了, 才认为写入成功了.")])]),_._v(" "),v("p",[_._v('那么不管是主节点还是从节点的 "写入成功", 都要考虑前面说到的刷盘问题. 所以就可以在谈到刷盘的时候进一步引申到这里.')]),_._v(" "),v("blockquote",[v("p",[_._v("redo log 和 binlog 的刷盘问题, 在中间件里面经常遇到. 一般来说, 中间件的写入语义可能是中间件写入到自身的日志中或者缓冲区, 中间件发起了系统调用, 写入操作系统的 page cache, 中间件强制发起刷盘, 数据被持久化到了磁盘上这3种. 如果不是直接写到磁盘, 那么中间件就会考虑定时或者定量刷新数据到磁盘.")]),_._v(" "),v("p",[_._v("在分布式环境下, 写入语义会更加复杂, 因为要考虑是否写从节点, 以及写多少个从节点的问题. 比如说在 Kafka 里面 acks 机制, 就是控制写入的时候要不要同步写入到从分区里面, 或者 Redis 里面控制 AOF 刷盘时机.")])]),_._v(" "),v("p",[_._v("在最后举了 Kafka 和 Redis 的例子, 这里可以考虑换成自己了解的其他例子.")]),_._v(" "),v("h6",{attrs:{id:"调整刷盘时机"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#调整刷盘时机"}},[_._v("#")]),_._v(" 调整刷盘时机")]),_._v(" "),v("p",[_._v("这类似于在上一节刷亮点的技巧, 也就是要结合公司的实际情况, 考虑调整 redo log 和 binlog 的刷盘时机. 那么基本方向有两个. "),v("strong",[_._v("第一个是对数据不丢失, 一致性要求高的业务, 可以考虑调整 sync_binlog 的值为 1")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在我的系统里面, 有一个业务对数据不丢失, 一致性要求非常高. 因此我们尝试调整 sync_binlog 为 1. 但是代价就是数据库的性能比较差, 因为每次提交都需要刷新 binlog 到磁盘上. 当然这时候 innodb_flush_log_at_trx_commit 也要使用默认值 1.")])]),_._v(" "),v("p",[_._v("另外一个是"),v("strong",[_._v("性能优先, 能够容忍一定数据丢失的")]),_._v(". 那么可以考虑将 "),v("strong",[_._v("innodb_flush_log_at_trx_commit 调整为 0 或者 2")]),_._v(", 同时还可以把 "),v("strong",[_._v("sync_binlog 调整为比较大的值")]),_._v(", 比如说调到 100.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们有一个对性能非常敏感, 但是对数据丢失容忍度比较高的业务, 那么就尝试将 innodb_flush_log_at_trx_commit 设置为 2, 让操作系统来决定什么时候刷新 redo log. 同时还把 sync_binlog 的值调整为 100, 进一步提高数据库的性能.")])]),_._v(" "),v("p",[_._v("或者综合两者.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们有一个数据库, 给两类业务使用. 一类业务对数据不丢失, 一致性要求极高, 另外一类对性能敏感, 但是可以容忍一定程度的数据丢失. 后来我将这两类业务的表分开, 放在两个数据库上.")])]),_._v(" "),v("p",[_._v("然后再分别阐述对应的调整策略就好了. 当然这个方案和数据库的性能有关, 也可以做成 MySQL 性能调优方案中的一环.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-14"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-14"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节课的思路要难一些, 下面列举的这些知识点是一定要记住的.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("undo log, redo log 的原理, 作用")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("事务执行过程")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("binlog, 尽量结合 redo log 一起理解两阶段提交协议")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("ACID 特性")]),_._v(", 绝对不能忘的基本功.")])]),_._v(" "),v("p",[_._v("此外还给出了两个在面试中可以展示的亮点. 一个是"),v("strong",[_._v("写入语义")]),_._v(", 要综合考虑单机写到哪里, 分布式写不写从节点, 写多少从节点的问题. 另一个是"),v("strong",[_._v("调整刷盘时机")]),_._v(", 看重数据的就调小 sync_binlog, 看重性能的就调大 sync_binlog 以及调整 innodb_flush_log_at_trx_commit.")]),_._v(" "),v("p",[_._v("在写入语义这个亮点演示了在面试中刷亮点的另外一种思路: "),v("strong",[_._v("充分地横向对比")]),_._v(". 简单来说就是计算机行业里面其实很多设计理念, 解决方法都是充满了套路的. 要做的就是找出这个套路, 然后在面试中说出来, 并且举不同中间件作为例子佐证.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9912c7af6f82899e8610298f0f96ec6e-20231223175001-ygd4hmd.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-12"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("你用过的中间件是怎么处理刷盘的? 如果有主从结构, 如何控制写入到从节点?")]),_._v(" "),v("li",[_._v("在聊到隔离性和隔离级别的时候我说到一个个人观点, 即未提交读和已提交读, 不能看作完全实现了隔离性, 你怎么看待这两者?")])]),_._v(" "),v("h4",{attrs:{id:"_15-数据迁移-如何在不停机的情况下保证迁移数据的一致性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_15-数据迁移-如何在不停机的情况下保证迁移数据的一致性"}},[_._v("#")]),_._v(" 15-数据迁移:如何在不停机的情况下保证迁移数据的一致性?")]),_._v(" "),v("p",[_._v("今天来聊聊数据迁移的问题. 很多人的简历里面都会提到数据迁移方面的内容. 比如:")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("重构老系统")]),_._v(": 使用新的表结构来存储数据;")]),_._v(" "),v("li",[v("strong",[_._v("单库拆分分库分表, 分库分表扩容")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("大表修改表结构定义")]),_._v(".")])]),_._v(" "),v("p",[_._v("但是在面试的时候, 他们就是说不清楚数据迁移究竟应该怎么做, 又或者说自己是停机迁移数据的.")]),_._v(" "),v("p",[_._v("这就是小看了数据迁移这个面试点. 数据迁移其实是一个很能够综合体现设计复杂方案解决棘手问题的点, 它能进一步凸显你在数据库方面的积累, 所以千万不能忽视. 今天就展示一个"),v("strong",[_._v("非常全面的不停机数据迁移的方案")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"数据备份工具"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据备份工具"}},[_._v("#")]),_._v(" 数据备份工具")]),_._v(" "),v("p",[_._v("这里先来介绍一下 MySQL 上常用的两款数据备份工具: mysqldump 和 XtraBackup.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("mysqldump")]),_._v(": 一个用于备份和恢复 MySQL 数据库的命令行工具. 它允许用户导出 MySQL 数据库的结构, 数据以及表之间的关系, 以便在数据库发生问题时进行恢复. 它是一个逻辑备份工具, 导出的内容是一条条 SQL.")]),_._v(" "),v("li",[v("strong",[_._v("XtraBackup")]),_._v(": 它使用了 InnoDB 存储引擎的数据备份技术, 支持增量备份和恢复, 并且支持多主机备份和恢复. 它是一个物理备份工具, 相当于直接复制 InnoDB 的底层存储文件.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e341443c3cc11c3b04d17a28134cbbd0-20231223175001-3efqmtx.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"innodb-autoinc-lock-mode"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb-autoinc-lock-mode"}},[_._v("#")]),_._v(" innodb_autoinc_lock_mode")]),_._v(" "),v("p",[_._v("innodb_autoinc_lock_mode 是 InnoDB 引擎里面"),v("strong",[_._v("控制自增主键生成策略的参数")]),_._v(", 它有三个取值.")]),_._v(" "),v("ul",[v("li",[_._v("0: 使用表自增锁, 但是锁在 INSERT 语句结束之后就释放了.")]),_._v(" "),v("li",[_._v("1: 使用表自增锁, 如果是普通的 INSERT INTO VALUE 或者 INSERT INTO VALUES 语句, 申请了主键就释放锁, 而不是整个 INSERT 语句执行完毕才释放. 如果是 INSERT SELECT 等语句, 因为无法确定究竟要插入多少行, 所以都是整个 INSERT 语句执行完毕才释放.")]),_._v(" "),v("li",[_._v("2: 使用表自增锁, 所有的语句都是申请了主键就立刻释放.")])]),_._v(" "),v("p",[_._v("这里额外提一点, 就是在执行 INSERT INTO VALUES 的时候, "),v("strong",[_._v("不管插入多少行, 都只申请一次主键")]),_._v(", 一次申请够, 这些主键"),v("strong",[_._v("必然是连续的")]),_._v(". 所以可以从返回的最后一个 ID 推测出全部 ID.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-15"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试之前, 需要了解清楚几个信息.")]),_._v(" "),v("ul",[v("li",[_._v("innodb_autoinc_lock_mode 的值, 这会"),v("strong",[_._v("影响主键生成策略")]),_._v(", 而在数据迁移的时候是需要考虑处理主键问题的.")]),_._v(" "),v("li",[v("strong",[_._v("公司 binlog 的模式")]),_._v(", 在后面增量校验和修复数据里面使用的是行模式的 binlog.")]),_._v(" "),v("li",[v("strong",[_._v("公司是否有统一的数据库规范")]),_._v(", 比如说必须要更新时间戳, 不能硬删除, 只能软删除.")]),_._v(" "),v("li",[_._v("你"),v("strong",[_._v("使用的 ORM 框架怎么实现双写")]),_._v("?")]),_._v(" "),v("li",[_._v("公司是否做过数据迁移? 如果做过, 具体的方案是什么? 如果做过数据迁移, 那就最好不过了.")])]),_._v(" "),v("p",[_._v("正常来说, 如果你真的解决过复杂的数据迁移, 那么它完全可以作为一个独立的项目写到简历里面. 又或者在讲到某个项目的时候, 可以说自己设计过一个非常复杂的数据迁移方案. 用重构系统作为例子展示一下这个话术.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个系统是我们公司的一个核心系统, 但是又有非常悠久的历史. 在我刚接手的时候, 它已经处于无法维护的边缘了. 但是不管是重构这个系统, 还是重新写一个类似的系统, 已有的数据都是不能丢的. 所以我的核心任务就是重新设计表结构, 并且完成数据迁移. 为此我设计了一个高效, 稳定的数据迁移方案.")])]),_._v(" "),v("p",[_._v("如果你实际落地了单库拆分分库分表, 或者你们公司单库拆分了分库分表, 你也可以这样说.")]),_._v(" "),v("blockquote",[v("p",[_._v("我进公司的时候, 刚好遇上单库拆分分库分表. 我主要负责的事情就是设计一个数据迁移方案, 把数据从单库迁移到分库分表上.")])]),_._v(" "),v("p",[_._v("建议在实践中推演一下这个方案. 有条件的话, 自己准备两个数据库尝试一下会更好.")]),_._v(" "),v("h5",{attrs:{id:"解决方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[_._v("#")]),_._v(" 解决方案")]),_._v(" "),v("p",[_._v("下面来看一看"),v("strong",[_._v("数据迁移方案的基本步骤")]),_._v(".")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("创建目标表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("用源表的数据初始化目标表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("执行一次校验")]),_._v(", 并且修复数据, 此时用源表数据修复目标表数据.")]),_._v(" "),v("li",[v("strong",[_._v("业务代码开启双写, 此时读源表, 并且先写源表, 数据以源表为准")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("开启增量校验和数据修复, 保持一段时间")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("切换双写顺序, 此时读目标表, 并且先写目标表, 数据以目标表为准")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("继续保持增量校验和数据修复")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("切换为目标表单写, 读写都只操作目标表")]),_._v(".")])]),_._v(" "),v("p",[_._v("如果不考虑数据校验, 那么整个数据迁移过程是这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b23d430a4284b860be2876f11174c20-20231223175001-wku34im.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以比较简单的方式就是记住图里的四步, 图右边的两步"),v("mark",[v("strong",[_._v("都要考虑校验和修复数据")])]),_._v("的问题. 接下来分析一下方案里的关键步骤.")]),_._v(" "),v("h6",{attrs:{id:"初始化目标表数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#初始化目标表数据"}},[_._v("#")]),_._v(" 初始化目标表数据")]),_._v(" "),v("p",[_._v("在创建了一个目标表之后, 第一步是先尝试初始化目标数据, 问题是"),v("strong",[_._v("怎么拿到源表数据")]),_._v("? 那么基本思路有两个: 一是使用源表的历史备份, 基本上数据库都会有备份机制, 那么自然可以利用这些备份来初始化目标表的数据. 二是源表导出数据, 导出数据的时候, 可以使用介绍的那些工具. 大部分情况下, 使用 mysqldump 是不会出问题的, 无非就是导出导入慢一些, 而这也恰好是你刷亮点的地方.")]),_._v(" "),v("p",[_._v("那就以 mysqldump 为例来聊一下, 这里的关键词就是"),v("strong",[_._v("加快导入和导出速度")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我选择了从源表导出数据, 使用的是 mysqldump 工具. mysqldump 是一个开源的逻辑备份工具, 优点是使用简单, 能够直接导出整个数据库. 缺点则是导出和导入的速度都比较慢, 尤其是在数据量非常大的情况下. 所以我针对 mysqldump 做了一些优化, 来提高导出和导入的性能. 加快导出速度能做的事情并不多, 主要就是开启 extended-insert 选项, 将多行合并为一个 INSERT 语句.")]),_._v(" "),v("p",[_._v("加快导入速度就可以做比较多的事情.")]),_._v(" "),v("ol",[v("li",[_._v("关闭唯一性检查和外键检查, 源表已经保证了这两项, 所以目标表并不需要检查.")]),_._v(" "),v("li",[_._v("关闭 binlog, 毕竟导入数据用不着 binlog.")]),_._v(" "),v("li",[_._v("调整 redo log 的刷盘时机, 把 innodb_flush_log_at_trx_commit 设置为 0.")])])]),_._v(" "),v("p",[_._v("注意在第 2, 3 点里面, 可以把话题引向上一节课的 binlog 和 redolog 内容. 反过来也可以利用 binlog 和 redolog 把话题引导到这一节课的内容, 灵活应对就可以.")]),_._v(" "),v("h6",{attrs:{id:"第一次校验与修复"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第一次校验与修复"}},[_._v("#")]),_._v(" 第一次校验与修复")]),_._v(" "),v("p",[_._v("在初始化数据之后, 可以先尝试"),v("strong",[_._v("立刻校验和修复一下数据")]),_._v(", 因为如果前面用的是备份数据, 那么备份数据已经落后生产数据了. 比如用的是昨天的备份, 那么今天的修改目标表就没有. 还有如果是导出的数据, 那么导出数据到导入数据这段时间, 数据发生了变化, 目标表依旧是没有的.")]),_._v(" "),v("p",[_._v("如果你们公司有明确的数据库规范的话, 比如说所有的表都需要有 update_time 这个字段, 那么在校验和修复的时候就可以采用增量的方案. 因为只有 update_time 晚于导出数据的那个时间点, 才说明这一行的数据已经发生了变更. 在修复的时候就"),v("strong",[_._v("直接用源表的数据覆盖掉目标表的数据")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"业务开启双写-以源表为准"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#业务开启双写-以源表为准"}},[_._v("#")]),_._v(" 业务开启双写,以源表为准")]),_._v(" "),v("p",[_._v("首先要解释清楚是怎么做到双写的. 支持双写大体上有两个方向: 侵入式和非侵入式两种. "),v("strong",[_._v("侵入式方案就是直接修改业务代码")]),_._v(". 要求业务代码在写了源表之后再写目标表. 但是侵入式方案是不太可行的, 或者说代价很高. 因为这意味着所有的业务都要检查一遍, 然后修改. 既然修改了, 那自然还要测试. 所以, 一句话总结就是工作量大还容易出错.")]),_._v(" "),v("p",[v("strong",[_._v("非侵入式一般和使用的数据库中间件有关")]),_._v(", 比如说 ORM 框架. 这一类框架一般会提供两种方式来解决类似的问题.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("AOP(Aspect Oriented Program 面向切面编程)方案")]),_._v(": 不同框架有不同叫法, 比如说可能叫做 interceptor, middleware, hook, handler, filter. 这个方案的关键就是捕捉到发起的增删改调用, 篡改为双写模式.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a4dd67afc39b5664d12yyd487c960d17-20231223175001-xyunvp3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("数据库操作抽象")]),_._v(": 可能叫做 Session, Connection, Connection Pool, Executor 等, 就是将对源表的操作修改为双写模式.")])]),_._v(" "),v("p",[_._v("不管采用哪个方案, 都要确保一个东西, 就是"),v("strong",[_._v("双写可以在运行期随时切换状态, 单写源表, 先写源表, 先写目标表, 单写目标表都可以")]),_._v(".")]),_._v(" "),v("p",[_._v("大多数时候都是利用一个标记位, 然后可以通过配置中心或者接口直接修改它的值.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dce6cf90a5123bcc29c7bcbf3b5741dd-20231223175001-9tuf8x2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("以 Go 语言的 GORM 为例展示基本的回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("开启双写在 GORM 上面还是比较容易做到的. 最开始我觉得可以考虑使用 GORM 的 Hook 机制, 用 DELETE 和 SAVE 两个 Hook 就可以了. 但是这要求我必须给每一个模型或表都定义类似的 Hook, 还是比较麻烦的. 后来我仔细翻了 GORM 的文档, 确认可以考虑使用 GORM 的 ConnPool 接口. 所以我用装饰器模式封装了两个数据源, 每次执行语句的时候, 都根据标记位来执行双写逻辑.")])]),_._v(" "),v("p",[_._v("这里看一个伪代码, 可以有一个直观的认知.")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("func")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("m "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v("DouleWritePool"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("QueryContext")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("ctx context"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("Context"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" query "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("string")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" args "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("...")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("interface")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v("sql"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("Rows"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("error")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" m"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("mode "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token char"}},[_._v("'源表优先'")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      err "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" m"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("source"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("QueryContext")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("ctx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" query"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" args"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("...")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" err "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token boolean"}},[_._v("nil")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n         m"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("target"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("QueryContext")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("ctx"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" query"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" args"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("...")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("else")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("//...")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br")])]),v("p",[_._v("很多时候, 在简历里面写上自己精通某个框架, 但是都缺乏说服力, 那么这个就可以作为一个证明. 在双写的时候, 可以往两个方向进一步刷亮点: "),v("strong",[_._v("数据一致性问题和主键问题")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1：数据一致性问题")])]),_._v(" "),v("p",[_._v("正常面试官都可能会问到, 如果在双写过程中, 写入源表成功了, 但是写入目标表失败了, 该怎么办? 那么最基础的回答就是"),v("strong",[_._v("不管.")])]),_._v(" "),v("blockquote",[v("p",[_._v("写入源表成功, 但是写入目标表失败, 这个是可以不管的. 因为后面有数据校验和修复机制, 还有增量校验和修复机制, 都可以发现这个问题.")])]),_._v(" "),v("p",[_._v("然后可以提出一个曾经思考过但是最终没有实施的方案, 这能够证明你在数据一致性上有过很深入的思考, 关键词是"),v("strong",[_._v("难以确定被影响的行")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在设计方案的时候, 我考虑过在写入目标表失败的时候, 发一个消息到消息队列, 然后尝试修复数据. 但是这个其实很难做到, 因为我不知道该修复哪些数据. 比如说一个 UPDATE 语句在目标表上执行失败, 我没办法根据 UPDATE 语句推断出源表上哪些行被影响到了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/29f5c51cc8575a35f55e1fc0d3eb80e3-20231223175001-p3bcg3s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2：主键问题")])]),_._v(" "),v("p",[_._v("如果在源表中使用的是自增主键, 那么"),v("strong",[_._v("在双写的时候写入目标表要不要写入主键? 答案是要的")]),_._v(". 也就是说, 需要"),v("strong",[_._v("在写入源表的时候拿到自增主键, 然后写入目标表的时候设置好主键")]),_._v(". 因为其实并不能确保目标表自增的主键, 和源表自增的主键是同一个值. 比如在并发场景下, 两次插入.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4d4975674fb45806d0b89d1e33311530-20231223175001-mzz480f.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此可以介绍你是如何处理这个问题的.")]),_._v(" "),v("blockquote",[v("p",[_._v("在双写的时候比较难以处理的问题是自增主键问题. 为了保持源表和目标表的数据完全一致, 需要在源表插入的时候拿到自增主键的值, 然后用这个值作为目标表插入的主键.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f30c10ab32ce6fab3081yy1176189294-20231223175001-2aa85dq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("此外还可以进一步展示一个更加高级的亮点, 也就是在前置知识里面说到的 "),v("strong",[_._v("innodb_autoinc_lock_mode")]),_._v(" 取值会影响自增主键的连续性, 抓住关键词"),v("strong",[_._v("自增主键的连续性")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在处理批量插入的时候要更加小心一些. 正常来说, 批量插入如果用的是 VALUES 语法, 那么生成的主键是连续的, 就可以从返回的最后一个主键推测出前面其他行的主键. 即便 innodb_autoinc_lock_mode 取值是 2 也能保证这一点. 但是如果用的是多个 INSERT INTO VALUE 语句, 或者 INSERT SELECT 语句, 这些语句生成的主键就可能不连续. 在双写之前, 就要先改造这一类的业务.")])]),_._v(" "),v("h6",{attrs:{id:"增量校验和数据修复"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#增量校验和数据修复"}},[_._v("#")]),_._v(" 增量校验和数据修复")]),_._v(" "),v("p",[v("strong",[_._v("增量校验基本上就是一边保持双写, 一边校验最新修改的数据, 如果不一致, 就要进行修复")]),_._v(". 这里也有两个方案. 第一个方案是利用更新时间戳, 比如说 update_time 这种列; 第二个方案是"),v("strong",[_._v("利用 binlog")]),_._v(". 相比之下 binlog 更加高级一点, 在面试的时候应该优先考虑用这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("利用更新时间戳")])]),_._v(" "),v("p",[_._v("利用更新时间戳的思路很简单, 就是定时查询每一张表, 然后根据更新时间戳来判断某一行数据有没有发生变化. 用伪代码来描述一下.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" {\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 执行查询")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// SELECT * FROM xx WHERE update_time >= last_time")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("rows")]),_._v(" :"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" findUpdatedRows"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("row")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("in")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("rows")]),_._v(" {\n    "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 找到目标行, 要用主键来找, 用唯一索引也可以, 看你支持到什么程度")]),_._v("\n    tgtRow "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" findTgt"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("row")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("row")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("!=")]),_._v(" tgtRow {\n      "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 修复数据")]),_._v("\n      fix"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n    }\n  }\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 用这一批数据里面最大的更新时间戳作为下一次的起始时间戳")]),_._v("\n  last_time "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" maxUpdateTime"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("row")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 睡眠一下")]),_._v("\n  sleep"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("s"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n}\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br"),v("span",{staticClass:"line-number"},[_._v("12")]),v("br"),v("span",{staticClass:"line-number"},[_._v("13")]),v("br"),v("span",{staticClass:"line-number"},[_._v("14")]),v("br"),v("span",{staticClass:"line-number"},[_._v("15")]),v("br"),v("span",{staticClass:"line-number"},[_._v("16")]),v("br"),v("span",{staticClass:"line-number"},[_._v("17")]),v("br")])]),v("p",[_._v("所以可以介绍基本的策略, 关键词是"),v("strong",[_._v("更新时间戳.")])]),_._v(" "),v("blockquote",[v("p",[_._v("我们采用的方案是利用更新时间戳找出最近更新过的记录, 然后再去目标表里面找到对应的数据, 如果两者不相等, 就用源表的数据去修复目标表的数据. 这个方案有两个条件: 所有的表都是有更新时间戳的, 并且删除是软删除的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/29b2341c9dc65b165e036cc46949cc40-20231223175001-iui75ux.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这里提到的第二个条件就是准备展示的第一个亮点. 可以等面试官追问为什么必须是软删除, 也可以自己接着回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果不是软删除的, 那么源表删掉数据之后, 如果目标表没删除, 在匹配逻辑里面是找不到的. 在这种场景下, 还有一个补救措施, 就是反向全量校验. 也就是说从目标表里面再次查询全量数据, 再去源表里找对应的数据. 如果源表里面没有找到, 就说明源表已经删了数据, 那么目标表就可以删除数据了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/83a2d7e9373a93f3a6290107be69af43-20231223175001-tgimmyt.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("接下来可以进一步展示第二个亮点, 这个亮点就是"),v("strong",[_._v("主从同步延迟")]),_._v("引发的问题. 假设在校验和修复的时候, 读的都是从库, 那么会遇到两种异常情况. "),v("strong",[_._v("一种是目标表主从延迟, 另一种是源表主从延迟")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f7289b8470e352yy329a000de2b3038c-20231223175001-ad2gyku.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么怎么解决呢? 简单粗暴的方法就是全部读主库, 校验和修复都以主库数据为准. "),v("strong",[_._v("缺点就是对主库的压力会比较大")]),_._v(".")]),_._v(" "),v("p",[_._v("这里给一个更加高级的方案: "),v("strong",[_._v("双重校验")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("校验和修复的时候都要小心主从同步的问题, 如果校验和修复都使用从库的话, 那么就会出现校验出错, 或者修复出错的情况. 按照道理来说, 强制走主库就可以解决问题, 但是这样对主库的压力是比较大的.")]),_._v(" "),v("p",[_._v("所以我采用的是双重校验方案. 第一次校验的时候读从库, 如果发现数据不一致, 再读主库, 用主库的数据再校验一次. 修复的时候就只能以主库数据为准. 这种方案的基本前提是, 主从延迟和数据不一致的情况是小概率的, 所以最终会走到主库也是小概率的.")])]),_._v(" "),v("p",[_._v("在这个回答里面没有提到任何异常情况的具体场景, 如果面试官问到了, 就回答上面图里面的两种情况. 这个亮点能够凸显你在主从延迟方面的积累, 也会把话题引到"),v("strong",[_._v("主从模式和主从同步")]),_._v("上, 所以要做好准备.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1：利用 binlog")])]),_._v(" "),v("p",[_._v("binlog 是一个更加高级的方案, 它还有一些变种, 所以理解和记忆的难度也更高一些. 注意, 这里说的 binlog 是指"),v("strong",[_._v("基于行的 binlog 模式")]),_._v(". 先从最简单的形态说起.")]),_._v(" "),v("p",[_._v("最简单的形态就是将 binlog 当做一个触发器, 回答的关键词就是 "),v("strong",[_._v("binlog 触发.")])]),_._v(" "),v("blockquote",[v("p",[_._v("在校验和修复的数据时候, 采用的是监听 binlog 的方案. binlog 只用于触发校验和修复这个动作, 当收到 binlog 之后, 会用 binlog 中的主键, 去查询源表和目标表, 再比较两者的数据. 如果不一致, 就用源表的数据去修复目标表.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a55512d1a5bc219fac47c7b7f7652eb3-20231223175001-pxbfgpt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果更进一步, 会觉得 binlog 里面本来就有数据, 那么干嘛不直接用 binlog 里面的数据呢? 所以就有了第二个形态: "),v("strong",[_._v("binlog 的数据被看作源表数据")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("拿到 binlog 之后, 我用主键去目标表查询数据, 然后把 binlog 里面的内容和目标表的数据进行比较. 如果数据不一致, 再用 binlog 的主键去源表里面查询到数据, 直接覆盖目标表的数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/da5e3799cca5372d3218773464ba4e01-20231223175001-o5t0x58.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里有一点不同, 就是你发现不一样之后, 需要查询源表, 再用查询到的数据去覆盖目标表的数据, 而不是直接用 binlog 的数据去覆盖目标表的数据. 因为要防止 binlog 是很古老的数据, 而目标表是更加新的数据这种情况.")]),_._v(" "),v("p",[_._v("紧接着, 你会发现目标表也有 binlog, 所以干嘛不直接比较源表的 binlog 和目标表的 binlog? 如果 binlog 不一样, 那不就是说明目标表那边出了问题吗?")]),_._v(" "),v("p",[_._v("这种方案理论上是可行的, 但是它有两个非常棘手的问题.")]),_._v(" "),v("ol",[v("li",[_._v("一次双写, 你可能立刻就收到了源表的 binlog, 但是过了好久才收到目标表的 binlog. 反过来, 先收到目标表的 binlog, 隔了很久才收到源表的 binlog 也一样. 所以你需要缓存住一端的 binlog, 再等待另外一端的 binlog.")]),_._v(" "),v("li",[_._v("顺序问题, 如果有两次双写操作的是同一行, 那么可能先收到源表第一次的 binlog, 再收到目标表第二次双写的 binlog, 怎么解决这个问题呢? 只能考虑利用消息队列之类的东西给 binlog 排个序, 确保 binlog 收到的顺序和产生的顺序一致.")])]),_._v(" "),v("p",[_._v("它虽然能够进一步减轻数据库查询的压力, 但是实在过于复杂, 得不偿失. 所以不管是实践, 还是面试, 都建议不要使用这个方案.")]),_._v(" "),v("h6",{attrs:{id:"切换双写顺序"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#切换双写顺序"}},[_._v("#")]),_._v(" 切换双写顺序")]),_._v(" "),v("p",[_._v("这一步本身就是一个亮点. 因为很多人都是"),v("strong",[_._v("在双写的时候直接切换到目标表单写")]),_._v(". 但是这样直接切换的风险太大了, 万一出了问题都没法回滚.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/abe7d3cf65906e6ffc3b0f566700b75d-20231223175001-xfiwogo.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以中间要引入一个双写的时候先写目标表, 且业务读目标表的步骤. 这样万一切换到写目标表出了问题还可以回滚. 也就是有后悔药可以吃.")]),_._v(" "),v("p",[_._v("所以可以考虑在介绍这一步的时候补充说明一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("引入这一步, 是为了能够在切换到以目标表为准之前, 有一个过渡阶段. 也就是说, 通过先写目标表, 再写源表这种方式, 万一发现数据迁移出现了问题, 还可以回滚为先写源表, 再写目标表, 确保业务没有问题.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/26555ec60ae4bdea9ca51d6c529910c5-20231223175001-utv8r7t.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"保持增量校验和修复"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#保持增量校验和修复"}},[_._v("#")]),_._v(" 保持增量校验和修复")]),_._v(" "),v("p",[_._v("在切换了双写顺序之后, "),v("strong",[_._v("保持增量校验和修复是顺理成章的")]),_._v(", 方案和步骤 5 一样. 不过步骤 5 的校验和修复都是以源表为准, 那么在这一步, 就是以目标表为准.")]),_._v(" "),v("p",[_._v("下面整理了一些能够帮助进一步理解整个方案的要点.")]),_._v(" "),v("ul",[v("li",[_._v("不管什么先后顺序问题, 什么并发问题, 在修复的时候永远用主表的最新数据去修复, 绝对不会出问题.")]),_._v(" "),v("li",[_._v("如果源表或者目标表本身也是分库分表的, 那么无非就是查询, 修复数据的时候使用对应的分库分表规则而已.")]),_._v(" "),v("li",[_._v("整个方案在第八步之前, 都是可以回滚的. 但是一旦切换到第八步, 就不可能回滚了.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-15"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节介绍了数据备份工具和影响到主键生成策略的 "),v("strong",[_._v("innodb_autoinc_lock_mode 参数")]),_._v(", 还给出了 "),v("strong",[_._v("数据迁移的完整方案")]),_._v(", 可以参考思维导图自己整理一下.")]),_._v(" "),v("p",[_._v("在讲这节的时候, 我想起了之前我在做简历辅导的时候, 遇到过好几个同学他们的简历里面都涉及了数据迁移, 然后我问他们数据迁移怎么做的, 他们的答案都是停机迁移. 但如果你是面试官, 听到答案是停机迁移, 你会觉得候选人实力不错吗?")]),_._v(" "),v("p",[_._v("不会的, 所以实际上即便你真的是停机迁移, 你也要回答不停机迁移的方案. 至少要在回答了停机迁移之后, 提起你做过不停机迁移的方案, 只是没有采用而已. 在类似的场景下, 虽然你的公司可能用的是低端解决方案, 但面试的时候一定要记得强调你了解高端方案或者曾经实施过高端方案, 因为高端的东西才是拉开差距的地方.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ba4ed5baf976bcffbf2ba73a62c5cf21-20231223175001-7x92vxa.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-13"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-13"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后请你思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在方案第二步, 我提到要先初始化一下目标表, 那么如果直接把目标表做成源表的一个从库会出现什么问题呢?")]),_._v(" "),v("li",[_._v("我在开启双写那里说过一个不可行的消息队列修复数据的方案, 不可行的原因是难以确定受影响的行. 那么我能不能在消息里面放源表执行的 SQL, 然后在消费消息的时候, 在目标表上执行相同的 SQL 呢?")])]),_._v(" "),v("h4",{attrs:{id:"_16-分库分表主键生成-如何设计一个主键生成算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_16-分库分表主键生成-如何设计一个主键生成算法"}},[_._v("#")]),_._v(" 16-分库分表主键生成:如何设计一个主键生成算法?")]),_._v(" "),v("p",[_._v("分库分表在面试里是一个非常热门, 而且偏难的一个话题. 这节课我就来攻克这个难题, 带你了解 UUID, 自增主键和雪花算法的特点, 并且教你在面试的时候刷出亮点. 在这些基础上, 会进一步给出一个微创新的主键生成方案, 可以作为面试时候的主要突破口.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-6"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-6"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("所谓的分库分表 "),v("strong",[_._v("严格来说是分数据源, 分库和分表")]),_._v(". 例如某个公司订单表的分库分表策略就是用了 8 个主从集群, 每个主从集群 4 个库, 每个库有 32 张表, 合在一起可以说成是 8 * 4 * 32。")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/132cf957e23d300ac59c35d982bbyyb2-20250116210756-sc36wla.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不过根据数据规模和读写压力, 也可以"),v("strong",[_._v("共享一个主从集群, 然后只分库或者只分表")]),_._v(". 如果面试面到了分库分表的内容, 那么主键生成基本上就是一个绕不开的话题. 显然, 在没有分库分表的时候, 都可以使用自增主键.")]),_._v(" "),v("p",[_._v("比如在 MySQL 里面的建表语句, 指定了 AUTO_INCREMENT.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("CREATE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("TABLE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("order")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("\n   id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BIGINT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PRIMARY")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("KEY")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("AUTO_INCREMENT")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n   buyer_id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BIGINT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("NOT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token boolean"}},[_._v("NULL")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br")])]),v("p",[_._v("那么在分库分表的场景下, 这种自增主键就无法运作了, 因为存在冲突的可能. 举个最简单的例子, 假如分库分表只分表, 而且按照 buyer_id 除以 2 的余数来分成两张表, 分别是 order_tab_0 和 order_tab_1.")]),_._v(" "),v("p",[_._v("如果这两张表都依赖于自增生成主键, 那么"),v("strong",[_._v("两张表会生成相同的 ID")]),_._v(". 比如说两张表插入第一行数据的时候, ID 都是 1. 而问题在于订单这一类的业务, 则需要一个全局唯一的 ID.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dfd3e0bf2775ac77692155173b76f4e9-20250116210756-0222b5c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("主键生成一般还伴随着两个要点.")]),_._v(" "),v("ul",[v("li",[_._v("一般希望"),v("strong",[_._v("全局唯一的 ID 依旧能够保持自增")]),_._v(", 因为自增与否会显著影响插入的性能.")]),_._v(" "),v("li",[_._v("因为"),v("strong",[_._v("只有数据量大的才会考虑分库分表, 而数据量大一般意味着并发高")]),_._v(", 所以还要考虑怎么支持高并发.")])]),_._v(" "),v("p",[_._v("接下来就会在这两个要点下教你怎么在面试的时候刷出亮点来.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-16"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-16"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("首先需要把话题引到主键生成上来. 如果你接触过使用分库分表的项目, 那么在简历和项目介绍的时候一定要提及分库分表关键词, 后面就等面试官主动问你主键是如何生成的. 如果在面试过程中被问到了数据库自增主键相关的问题, 那么要主动提起自增主键不适用于分库分表场景, 然后面试官自然就会追问分库分表场景下主键的生成问题.")]),_._v(" "),v("p",[_._v("那在面试官问到这些问题的时候怎样才能抓住这个机会, 展现自己的实力呢? 这就需要提前做一些准备工作了.")]),_._v(" "),v("ol",[v("li",[_._v("深入理解市面上常见的"),v("strong",[_._v("主键生成策略")]),_._v(".")]),_._v(" "),v("li",[_._v("准备一个有亮点的, 微创新的主键生成方案.")]),_._v(" "),v("li",[_._v("记住一些可行的优化方案.")])]),_._v(" "),v("p",[_._v("下面就一步一步来, 先来看看市面上一些常见的主键生成策略.")]),_._v(" "),v("h5",{attrs:{id:"常见思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#常见思路"}},[_._v("#")]),_._v(" 常见思路")]),_._v(" "),v("p",[_._v("如果面试官问, 在分库分表里面, 怎么解决主键问题, 或者分库分表可以怎么生成主键, 又或者问如何设计一个发号器, 基本上都是希望你回答主键生成的常见思路, 也就是 "),v("strong",[_._v("UUID, 数据库自增和雪花算法")]),_._v(". 接下来一个个分析.")]),_._v(" "),v("h6",{attrs:{id:"uuid"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#uuid"}},[_._v("#")]),_._v(" UUID")]),_._v(" "),v("p",[_._v("UUID 是最简单粗暴的方案, 也是面试的时候必须要回答出来的一种策略.")]),_._v(" "),v("p",[_._v("如果想和其他人拉开差距, 那么即便是最简单的 UUID 方案也可以下一番功夫, 首先需要详细地解释 UUID 的两个弊端.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("过长")]),_._v(": 这个弊端其实在面试里面讨论得比较少, 毕竟会采用 UUID 的地方就不会在意它的长度了.")]),_._v(" "),v("li",[v("strong",[_._v("UUID 不是递增的")]),_._v(": 这个弊端是面试时要重点描述的, 并且要尝试刷出亮点来.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1: 页分裂")])]),_._v(" "),v("p",[_._v("UUID 不是递增的这个弊端, 要想讲清楚, 就要先描述"),v("strong",[_._v("为什么会希望在数据库里面使用自增主键")]),_._v(". 那么可以引用数据库为什么使用自增主键的知识点来回答这个问题, 关键词就是"),v("strong",[_._v("页分裂.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/02b6030c5e376b3c8e9fe17328a21382-20250116210756-sxzlkik.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如图所示, 在尝试往 23 之后插入一个 25 的时候, 这个叶子节点已经放不下了, 逼不得已就只能分裂成 (20, 21) 和 (22, 23, 25) 两个节点. 如果再仔细观察一下, 就会发现, 原本的 (10, 20, 30) 多了一个元素之后变成了 (10, 20, 22, 30). 你想到了什么?")]),_._v(" "),v("p",[v("strong",[_._v("即页分裂这个东西是可能会引起连锁反应的")]),_._v(", 从叶子节点沿着树结构一路分裂到根节点.")]),_._v(" "),v("p",[_._v("所以可以这样回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("UUID 最大的缺陷是它产生的 ID 不是递增的. 一般来说倾向于在数据库中使用自增主键, 因为这样可以迫使数据库的树朝着一个方向增长, 而不会造成中间叶节点分裂, 这样插入性能最好. 而整体上 UUID 生成的 ID 可以看作是随机, 那么就会导致数据往页中间插入, 引起更加频繁地页分裂, 在糟糕的情况下, 这种分裂可能引起连锁反应, 整棵树的树形结构都会受到影响. 所以普遍倾向于采用递增的主键.")])]),_._v(" "),v("p",[_._v("如果这样回答, 那么算是"),v("strong",[_._v("基本达标了")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2: 顺序读")])]),_._v(" "),v("p",[_._v("此外还可以从一个比较新奇的角度, 解释为什么要使用自增主键, 关键词就是"),v("strong",[_._v("顺序读")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/87c0c587c2133c0acb9c534291778966-20250116210756-m5n61bq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这样回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("自增主键还有一个好处, 就是数据会有更大的概率按照主键的大小排序, 两条主键相近的记录, 在磁盘上位置也是相近的. 那么可以预计, 在范围查询的时候, 能够更加充分地利用到磁盘的顺序读特性.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点3: InnoDB的数据组织")])]),_._v(" "),v("p",[_._v("如果希望在面试官面前树立你在数据库方面积累比较多的形象, 那么就要"),v("strong",[_._v("进一步解释数据库的页分裂究竟是怎么一回事")]),_._v(", 这时候可以用 MySQL InnoDB 引擎来举例子.")]),_._v(" "),v("blockquote",[v("p",[_._v("MySQL 的 InnoDB 引擎, 每一个页上按照主键的大小放着数据. 假如现在有一个页放着主键 1, 2, 3, 5, 6, 7 这六行数据, 并且这一页已经放满了. 现在要插入一个 ID 为 4 的行, 那么 InnoDB 引擎就会发现, 这一页已经放不下 4 这行数据了, 于是逼不得已, 就要将原本的页分成两页, 比如说 1, 2, 3 放到一页, 5, 6, 7 放到另外一页, 然后可以把 4 放到第一页.")]),_._v(" "),v("p",[_._v("这种页分裂会造成一个问题, 就是虽然从逻辑上来说 1, 2, 3 这一页和 5, 6, 7 这一页是邻近的两个页, 但是在真实存储的磁盘上, 它们可能离得很远.")])]),_._v(" "),v("p",[_._v("这个回答基本上就是前面图片的一个口语化表述.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/87c0c587c2133c0acb9c534291778966-20250116210756-m5n61bq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("到这一步就已经算是可以了. 面试官如果想要进一步探讨, 那么可能会继续追问 InnoDB 引擎上的页这种数据结构有什么字段, 各自有什么用处. 如果现在是临时抱佛脚准备面试, 那么就没必要去背这些八股文. 但是如果只是平常在学习技术知识, 想要夯实基础, 那么建议深入去看看这部分内容.")]),_._v(" "),v("h6",{attrs:{id:"数据库自增"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库自增"}},[_._v("#")]),_._v(" 数据库自增")]),_._v(" "),v("p",[_._v("除了 UUID 这种方案以外, 还有另外一种常见的方案也叫做自增. 不过这种自增有点特殊, 它是设置了"),v("strong",[_._v("步长的自增")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/12e15b2707f0e41527d318259674df98-20250116210756-vwlq6wt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以用一个例子来说明这种方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("经过分库分表之后有十个表, 那么可以让每一个表按照步长来生成自增 ID. 比如第一个表就是生成 1, 11, 21, 31 这种 ID, 第二个表就是生成 2, 12, 22, 32 这种 ID.")])]),_._v(" "),v("p",[_._v("紧接着还可以简单评价一下这种方案, 关键词是"),v("strong",[_._v("表内部自增.")])]),_._v(" "),v("blockquote",[v("p",[_._v("这种方案非常简单, 而且本身我们在应用层面并不需要做任何事情, 只是需要在创建表的时候指定好步长就可以了. ID 虽然并不一定是全局递增的, 但是在一个表内部, 它肯定是递增的. 这个方案的性能基本取决于数据库性能, 应用层面上也不需要关注.")])]),_._v(" "),v("h6",{attrs:{id:"雪花算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#雪花算法"}},[_._v("#")]),_._v(" 雪花算法")]),_._v(" "),v("p",[_._v("除了 UUID 和数据库自增之外, 还可以从雪花类算法上找找亮点.")]),_._v(" "),v("p",[_._v("要注意的是, 以目前的内卷情况, 即便答出了雪花算法, 可能还是很普通. 不过别担心, 这就教你怎么让自己的回答变得不普通.")]),_._v(" "),v("p",[_._v("雪花算法的原理倒不难, 它的关键点在于"),v("strong",[_._v("分段.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/715c3d92bc98293a7995978063899ac6-20250116210756-pdh25df.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么雪花算法保证 ID 唯一性的理由也很充分了.")]),_._v(" "),v("ul",[v("li",[_._v("时间戳是递增的, 不同时刻产生的 ID 肯定是不同的.")]),_._v(" "),v("li",[v("strong",[_._v("机器 ID 是不同的")]),_._v(", 同一时刻不同机器产生的 ID 肯定也是不同的.")]),_._v(" "),v("li",[v("strong",[_._v("同一时刻同一机器上, 可以轻易控制序列号")]),_._v(".")])]),_._v(" "),v("p",[_._v("在面试中要先回答这几个理由, 然后解释.")]),_._v(" "),v("blockquote",[v("p",[_._v("雪花算法采用 64 位来表示一个 ID, 其中 1 比特保留, 41 比特表示时间戳, 10 比特作为机器 ID, 12 比特作为序列号.")])]),_._v(" "),v("p",[_._v("基本解释清楚之后, 刷亮点有很多个方向, 可以根据自己掌握相关知识的程度来选择.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1: 调整分段")])]),_._v(" "),v("p",[_._v("第一个方向是深入讨论每个字段, 关键点就是"),v("mark",[v("strong",[_._v("根据需求自定义各个字段含义, 长度")])]),_._v(".")]),_._v(" "),v("p",[_._v("大多数情况下, 如果自己设计一个类似的算法, 那么每个字段的含义, 长度都是可以灵活控制的. 比如时间戳 41 比特可以改得更短或者更长, 比如说 39 比特也能表示十几年, 其实也够用了.")]),_._v(" "),v("blockquote",[v("p",[_._v("机器 ID 虽然明面上是机器 ID, 但是实际上并不是指物理机器, 准确说是"),v("mark",[_._v("算法实例")]),_._v(". 例如, 一台机器部署两个进程, 每个进程的 ID 是不同的; 又或者进一步切割, 机器 ID 前半部分表示机器, 后半部分可以表示这个机器上用于产生 ID 的进程, 线程或者协程. 甚至机器 ID 也并不一定非得表示机器, 也可以引入一些特定的业务含义. 而序列号也是可以考虑加长或者缩短的.")])]),_._v(" "),v("p",[_._v("说完这些, 最好再加上一句总结, 升华一下主题.")]),_._v(" "),v("blockquote",[v("p",[_._v("雪花算法可以算是一种思想, 借助时间戳和分段, 可以自由切割 ID 的不同比特位, 赋予其不同的含义, 灵活设计自己的 ID 算法.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cf334b92d7db27f2ed73fcc5a4fa50f0-20250116210756-gqpd563.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2: 序列号耗尽")])]),_._v(" "),v("p",[_._v("但是这里还有一个问题, 就是"),v("strong",[_._v("不管怎么设计雪花算法, 序列号长度都有可能不够")]),_._v(". 比如说前面标准的是 12 比特, 那么有没有可能并发非常高, 以至于 12 比特在某一个特定的时刻机器上的比特全都用完了呢?")]),_._v(" "),v("p",[_._v("显然, 理论上是存在这种可能的, 所以亮点就要从"),v("strong",[_._v("如何解决这个问题")]),_._v("入手. 这个问题解决起来倒也很简单.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("如果 12 比特不够, 就给更多比特")]),_._v(", 这部分比特可以从时间戳里面拿出来。")]),_._v(" "),v("li",[v("strong",[_._v("如果还不够, 那么就让业务方等待一下")]),_._v(", 到下一个时刻, 自然又可以生成新的 ID 了, 也就是时间戳变了, 这也是一种变相的限流.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7a1e909a40cfbb175533fb517805896c-20250116210756-y8smle9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ea6ea3fdc8d5e8e86c8447b780387d9c-20250116210756-wzbhjd3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这样回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("一般来说可以考虑加长序列号的长度, 比如说缩减时间戳, 然后挪给序列号 ID. 当然也可以更加简单粗暴地将 64 位的 ID 改成 96 位的 ID, 那么序列号 ID 就可以有三四十位, 即便是国际大厂也不可能用完了. 不过, 彻底的兜底方案还是要有的. 可以考虑引入类似限流的做法, 在当前时刻的 ID 已经耗尽之后, 可以让业务方等一下. 时间戳一般都是毫秒数, 那么业务方最多就会等一毫秒.")])]),_._v(" "),v("p",[_._v("这里面试官可能会继续杠, 问这里让业务方等一下会有什么问题? 或者说如果面试官不主动杠, 也可以自己说明一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("业务方等待算是一个比较危险的方案, 因为这可能导致大量业务方阻塞住, 导致线程耗尽或者协程耗尽之类的问题. 不过如果是偶发性的序列号不够, 那么问题不大, 因为阻塞的业务方很快就能拿到 ID.")]),_._v(" "),v("p",[_._v("那么如果序列号耗尽不是一个偶发性的问题, 是长期的问题, 那么还是要考虑从业务角度切割, 不同业务使用不同的 ID 生成, 就不要共享了. 甚至逼不得已还是用 96 或者 128 位的, 一了百了.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点3: 数据堆积")])]),_._v(" "),v("p",[_._v("设想这么一个场景: 你的分库分表是按照 ID 除以 32 的余数来进行的, 那么如果你的业务非常低频, 以至于每一个时刻都只生成了尾号为 1 的 ID, 那么是不是所有的数据都分到了一张表里面呢?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4d62daafdacff825cb6becf3928657a1-20250116210756-8qqsfus.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("没错, 不过解决方案也很简单.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("某一个时刻使用随机数作为起点")]),_._v(", 而不是每次从 0 开始计数.")]),_._v(" "),v("li",[_._v("使用上一个序列号作为起点. 比如说上一个序列号只分到了 3, 那么下一个时刻的序列号就从 4 开始.")])]),_._v(" "),v("p",[_._v("随机数算是正统方案, 第二个方案看起来稍微有点儿奇怪.")]),_._v(" "),v("p",[_._v("可以这样来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在低频场景下, 很容易出现序列号几乎没有增长, 从而导致数据在经过分库分表之后只落到某一张表里面的情况. 为了解决这种问题, 可以考虑这么做, 序列号部分不再是从 0 开始增长, 而是从一个随机数开始增长. 还有一个策略就是序列号从上一时刻的序列号开始增长, 但是如果上一时刻序列号已经很大了, 那么就可以退化为从 0 开始增长. 这样的话要比随机数更可控一点, 并且性能也要更好一点.")])]),_._v(" "),v("p",[_._v('接下来, 你有一个 "亮剑" 的机会, 补充一句话.')]),_._v(" "),v("blockquote",[v("p",[_._v("一般来说, 这个问题只在利用 ID 进行哈希的分库分表里面有解决的意义. 在利用 ID 进行范围分库分表的情况下, 很显然某一段时间内产生的 ID 都会落到同一张表里面. 不过这也是使用范围分库分表预期的行为, 不需要解决.")])]),_._v(" "),v("p",[_._v("做完前面这些工作, 基本操作就完成了.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-主键内嵌分库分表键"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-主键内嵌分库分表键"}},[_._v("#")]),_._v(" 亮点方案:主键内嵌分库分表键")]),_._v(" "),v("p",[_._v("看到这里你是不是在想, 前面的回答都还不够有亮点吗? 都回答出来雪花算法了还不够吗? 答案是有亮点但是还不够拉开差距. 既然寻求刺激, 那就要贯彻到底.")]),_._v(" "),v("p",[_._v("这里直接给一个方案-"),v("strong",[_._v("主键内嵌分库分表键.")])]),_._v(" "),v("blockquote",[v("p",[_._v("大多数时候, 我们会面临一个问题, 就是"),v("mark",[_._v("分库分表的键和主键并不是同一个")]),_._v(". 比如在 C 端的订单分库分表, 可以采用买家 ID 来进行分库分表. 但是一些业务场景, 比如说查看订单详情, 可能是根据主键又或者是根据订单 SN 来查找的.")]),_._v(" "),v("p",[_._v("那么可以考虑借鉴雪花算法的设计, 将主键生成策略和分库分表键结合在一起, 也就是说在主键内部嵌入分库分表键. 例如, 可以这样设计订单 ID 的生成策略, 在这里假设分库分表用的是买家 ID 的后四位. 第一段依旧是采用时间戳, 但是第二段就换成了这个买家后四位, 第三段采用随机数.")]),_._v(" "),v("p",[_._v("普遍情况下, 都是用买家 ID 来查询对应的订单信息. 在别的场景下, 比如只有一个订单 ID, 这种时候可以取出订单 ID 里嵌入进去的买家 ID 后四位, 来判断数据存储在哪个库, 哪个表. 类似的设计还有答题记录按照答题者 ID 来分库分表, 但是答题记录 ID 本身可以嵌入这个答题者 ID 中用于分库分表的部分.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4eed5dc92311289d92eb8b0b6456a3dc-20250116210757-90kgen9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后要记得升华一下这种设计思想.")]),_._v(" "),v("blockquote",[v("p",[_._v("这一类解决方案, 核心就是不拘泥于雪花算法每一段的含义. 比如说第二段可以使用具备业务含义的 ID, 第三段可以自增, 也可以随机. 只要最终能够保证 ID 生成是全局递增的, 并且是独一无二的就可以.")])]),_._v(" "),v("p",[_._v('为什么要这么升华呢? 因为在这一段话里面, 很明显地埋下了两颗 "雷", 一个是全局递增, 一个是独一无二. 也就是说这个亮点方案保证不了这两点, 而如果面试官的水平足够, 那么他肯定会追问你全局递增和独一无二两个点.')]),_._v(" "),v("h6",{attrs:{id:"全局递增"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#全局递增"}},[_._v("#")]),_._v(" 全局递增")]),_._v(" "),v("p",[_._v("假如说面试官进一步追问: 你这个方案能够保证主键递增吗?")]),_._v(" "),v("blockquote",[v("p",[_._v("这个保证不了, 但是它能够做到大体上是递增的. 可以设想, 同一时刻如果有两个用户来创建订单, 其中用户 ID 为 2345 的先创建, 用户 ID 为 1234 的后创建, 那么很显然用户 ID 1234 会产生一个比用户 ID 2345 更小的订单 ID; 又或者同一时刻一个买家创建了两个订单, 但是第三段是随机数, 第一次 100, 第二次 99, 那么显然第一次产生的 ID 会更大.")]),_._v(" "),v("p",[_._v("但是这并不妨碍我们认为, 随着时间推移, 后一时刻产生的 ID 肯定要比前一时刻产生的 ID 要大. 这样一来, 虽然性能比不上完全严格递增的主键好, 但是比完全随机的主键好.")])]),_._v(" "),v("h6",{attrs:{id:"独一无二"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#独一无二"}},[_._v("#")]),_._v(" 独一无二")]),_._v(" "),v("p",[_._v("如果面试官进一步追问你这个方案能不能保证 ID 唯一, 那么应该回答不能, 但这并不是一个多大的问题.")]),_._v(" "),v("p",[_._v("你可以想到, 不能保证独一无二是因为在第三段里面使用了随机数. 既然是随机数, 那么就可能随机到同样的数字. 但产生冲突 ID 的可能性是很低的. 它要求在同一时刻同一个用户创建了两个订单, 然后订单 ID 的随机数部分随机到了同一个数字.")]),_._v(" "),v("p",[_._v("这时候就可以揭示这个概率以及相应的容错措施.")]),_._v(" "),v("blockquote",[v("p",[_._v("产生一样 ID 的概率不是没有, 而是极低. 它要求同一个用户在同一时刻创建了两个订单, 然后订单 ID 的随机数部分一模一样, 这是一个很低的概率.")])]),_._v(" "),v("p",[_._v("如果有杠精面试官非要问这个概率有多低, 就可以从业务和数学两个角度上解释为什么概率低.")]),_._v(" "),v("blockquote",[v("p",[_._v("在下单场景下, 正常的用户都是一个个订单慢慢下, 在同一时刻同时创建两个订单, 对于用户来说, 是一件不可能的事情. 而如果有攻击者下单, 那就更加无所谓, 反正是攻击者的订单, 失败就失败了. 而即便真的有用户因为共享账号之类的问题同一时刻下两个订单, 那么随机到同一个数的概率也是十万分之一.")])]),_._v(" "),v("p",[_._v("注意, 这里的十万分之一, 是假设随机数产生的范围是在 0 到 十万之间.")]),_._v(" "),v("p",[_._v("最后还是需要提出解决方案, 关键词就是"),v("strong",[_._v("重新产生一个主键.")])]),_._v(" "),v("blockquote",[v("p",[_._v("解决方案其实也很简单, 就是在插入数据的时候, 如果返回了主键冲突错误, 那么重新产生一个, 再次尝试就可以了.")])]),_._v(" "),v("p",[_._v("如果还想要继续刷亮点, 还可以假装很不在意地说:")]),_._v(" "),v("blockquote",[v("p",[_._v("实际上, 还有一种非常偶发性的因素也可能会引起 ID 冲突, 也就是时钟回拨, 不过相比正统雪花算法, 时钟回拨问题在这个方案里面不太严重, 毕竟还有一个随机数的部分.")])]),_._v(" "),v("p",[_._v("这么一说就足以凸显你知识广博, 考虑周全了.")]),_._v(" "),v("h5",{attrs:{id:"优化思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化思路"}},[_._v("#")]),_._v(" 优化思路")]),_._v(" "),v("p",[_._v("如果能够把前面的亮点方案说清楚, 还觉得意犹未尽, 想继续在面试官面前炫技的话, 那么可以尝试聊聊"),v("strong",[_._v("一般的发号器的优化思路")]),_._v(". 注意这个优化思路可以说你只是想过, 但是并没有落地, 省得说不清楚细节.")]),_._v(" "),v("p",[_._v("优化的点就是: "),v("strong",[_._v("批量取, 提前取, singleflight 取, 局部分发")]),_._v(".")]),_._v(" "),v("p",[_._v("注意, 批量取和提前取对应的还有批量生成和提前生成, 思路是一样的. 万一面试官问到了如何设计一个高性能的发号器, 也可以回答这些点.")]),_._v(" "),v("blockquote",[v("p",[_._v("批量取")])]),_._v(" "),v("p",[v("strong",[_._v("批量取是指业务方每次跟发号器打交道, 不是只拿走一个 ID, 而是拿走一批")]),_._v(", 比如说 100 个. 拿到之后业务方自己内部慢慢消耗. 消耗完了再去取下一批.")]),_._v(" "),v("p",[_._v("这种优化思路的优点就是极大地减轻发号器的并发压力. 比如说一批是 100 个, 那么并发数就降低为原本的 1%了. 缺点就是可能破坏递增的趋势. 比如说一个业务方 A 先取走了 100 个 ID, 然后业务方 B 又取走 100 个, 结果业务方 B 先用完了自己取的 ID, 插到了数据库里面; 然后业务方 A 才用完自己的 100 个.")]),_._v(" "),v("blockquote",[v("p",[_._v("提前取")])]),_._v(" "),v("p",[v("strong",[_._v("提前取是指业务方提前取到 ID, 这样就不需要真的等到需要 ID 的时候再临时取")]),_._v(". 提前取可以和批量取结合在一起, 即提前取一批, 然后内部慢慢使用. 在快要用完的时候, 再取一批. 同时也要设计一个兜底措施, 如果要是用完了, 新的一批还没取过来, 要让业务方停下来等待.")]),_._v(" "),v("p",[_._v("这个思路的优点是能够提高业务方的性能, 缺点和前面一样是会破坏 ID 的递增性.")]),_._v(" "),v("blockquote",[v("p",[_._v("singleflight 取")])]),_._v(" "),v("p",[_._v("这个就类似于在缓存中应用 singleflight 模式. 假如说业务方 A 有几十个线程或者协程需要 ID, 那么没有必要让这些线程都去取 ID, 而是派一个代表去取. 这个代表取到之后再分发给需要的线程. 这也能够降低发号器的并发负载.")]),_._v(" "),v("p",[_._v("这个思路还可以进一步优化, 就是每次取的时候多取一点, 那么后续还有别的线程需要, 也不用自己去取了.")]),_._v(" "),v("blockquote",[v("p",[_._v("局部分发")])]),_._v(" "),v("p",[_._v("假如说现在整个实例上有 1000 个 ID, 这些 ID 是批量获取的. 那么一个线程需要 ID 的时候, 它就不再是只拿一个, 而是拿 20 个, 然后存在自己的 "),v("strong",[_._v("TLB")]),_._v("(thread-local-buffer) 里面, 以后这个线程需要 ID 的时候, 就先从自己的 TLB 里面拿, 避开了全局竞争, 减轻了并发压力.")]),_._v(" "),v("h5",{attrs:{id:"面试思路回顾"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路回顾"}},[_._v("#")]),_._v(" 面试思路回顾")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6c783154fb3987d155f28abcff81f71e-20250116210757-8zo7boc.jpg",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("这节主要解决的是分库分表主键生成的问题. 给出了 UUID, 数据库自增和雪花算法这三种常见思路, 并在此基础上设计了一个主键内嵌分库分表键的亮点方案, 还给出了几种优化的思路. 这些回答依旧体现了我一直以来跟你说的, 对于复杂的理论, 不要死记硬背, 而是用一个简单的例子来解释这个理论, 正如同这里用的页分裂的例子. 对于面试官来说, 他很容易听懂, 也容易记住.")]),_._v(" "),v("p",[_._v("同时, 也再次证明了最开始说的那个说法, 对于一些喜欢一杆子打到底的面试官来说, 引导他们是一件非常简单的事情. "),v("strong",[_._v("他们所自豪的一杆子打到底, 实际上每一步都在你的预料之内")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"思考题-14"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-14"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("我在雪花算法里面讲到说, 如果序列号耗尽, 可以缩短时间戳, 把比特位给序列号用, 那么能不能缩减机器 ID 的比特位?")]),_._v(" "),v("li",[_._v("在 singleflight 取那里, 算是一个典型的化全局竞争为局部竞争的并发优化, 那么你还见过类似的优化吗?")])]),_._v(" "),v("h4",{attrs:{id:"_17-分库分表分页查询-为什么你的分页查询又慢又耗费内存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_17-分库分表分页查询-为什么你的分页查询又慢又耗费内存"}},[_._v("#")]),_._v(" 17-分库分表分页查询:为什么你的分页查询又慢又耗费内存?")]),_._v(" "),v("p",[_._v("在实践中, 分页是分库分表之后肯定要解决的问题, 如果解决方案没选好, 那么很容易出现性能问题. 分页的解决方案很多, 不过能够在面试中系统地将所有的方案都说出来的候选人可以说是少之又少.")]),_._v(" "),v("p",[_._v("下面从分库分表的一般做法开始学起.")]),_._v(" "),v("h5",{attrs:{id:"分库分表的一般做法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表的一般做法"}},[_._v("#")]),_._v(" 分库分表的一般做法")]),_._v(" "),v("p",[_._v("分库分表一般会使用三种算法.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("哈希分库分表")]),_._v(": 根据分库分表键算出一个哈希值, 然后根据这个哈希值选择一个数据库. 最常见的就是使用数字类型的字段作为分库分表键, 然后取余. 比如说在订单表里面, 按照买家的 ID 除以 8 的余数进行分表.")]),_._v(" "),v("li",[v("strong",[_._v("范围分库分表")]),_._v(": 将某个数据按照范围大小进行分段. 比如说根据 ID, [0, 1000) 在一张表, [1000, 2000) 在另外一张表上. 最常见的应该是按照日期进行分库分表, 比如说按照月分表, 每个月一张表.")]),_._v(" "),v("li",[v("strong",[_._v("中间表")]),_._v(": 引入一个中间表来记录数据所在的目标表. 一般是记录主键到目标表的映射关系.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5974f6a54d7f15eb0e88e0e576a2a32d-20231223175001-714f3l2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这三者并不是互斥的, 也就是说可以考虑使用哈希分库分表, 同时引入一个中间表. 也可以先进行范围分库分表, 再引入一个中间表.")]),_._v(" "),v("h5",{attrs:{id:"分库分表中间件的形态"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表中间件的形态"}},[_._v("#")]),_._v(" 分库分表中间件的形态")]),_._v(" "),v("p",[_._v("分库分表中间件的形态有三种.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("SDK 形态")]),_._v(": SDK 形态就是大家最熟悉的, 它通过"),v("strong",[_._v("依赖的形式引入到业务代码里面")]),_._v(". 比如 ShardingSphere 的 Java 依赖.")]),_._v(" "),v("li",[v("strong",[_._v("Proxy 形态")]),_._v(": "),v("strong",[_._v("独立部署的分库分表中间件")]),_._v(", 它对于所有的业务方来说, 就像一个普通的数据库, 业务方的查询发送过去之后, 它就会执行分库分表, 发起实际查询, 然后把查询结果返回给业务方. ShardingSphere 也支持这种形态.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3fa01d67f0721d26cb3af82c0ffdb74a-20231223175001-p6xew8e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[v("strong",[_._v("Sidecar 形态")]),_._v(": 简单来说就是一个提供了分库分表的 Sidecar. 这是一个理论上的形态, 现在并没有非常成熟的产品.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/76a04b36eeb86de740033cb7991aeddc-20231223175001-mtqy387.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这三种形态里面, "),v("strong",[_._v("SDK 形态性能最好, 但是和语言强耦合")]),_._v(". 比如说 Java 研发的 ShardingSphere jar 包是没办法给 Go 语言使用的.")]),_._v(" "),v("p",[v("strong",[_._v("Proxy 形态性能最差, 因为所有的数据库查询都发给了它, 很容易成为性能瓶颈")]),_._v(". 尤其是单机部署 Proxy 的话, 还面临着单节点故障的问题. 它的优点就是跟编程语言没有关系, 所以部署一个 Proxy 之后可以给使用不同编程语言的业务使用. 同时, Proxy 将自己伪装成一个普通的数据库之后, 业务方可以轻易地从单库单表切换到分库分表, 整个过程对于业务方来说就是换了一个数据源.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/aa87001029ce37e9fc48733e22b19f2c-20231223175001-ukmta0q.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("Sidecar 目前还没有成熟的产品, 但是从架构上来说它的性能应该介于 SDK 和 Proxy 之间, 并且也没有单体故障, 集群管理等烦恼.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-17"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-17"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在准备分库分表分页查询面试的时候, 还需要弄清楚几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司是"),v("strong",[_._v("如何解决分库分表中的分页问题")]),_._v("的?")]),_._v(" "),v("li",[v("strong",[_._v("有没有因为排序或者分页而引起的性能问题")]),_._v("? 如果有, 最终是怎么解决的?")])]),_._v(" "),v("p",[_._v("还要去看看公司的监控数据, 看看分页查询的响应时间. 并且在业务高峰期或者频繁执行分页的时候, 看看内存和 CPU 的使用率. 这些数据可以作为分页查询比较容易引起性能问题的证据.")]),_._v(" "),v("p",[_._v("从面试策略上来说, 最好是把分页查询优化作为性能优化的一个举措, 可以进一步和前面几节里面讲到的查询优化, 数据库参数优化相结合, 这样方案会更加完善, 对应地你的能力也会更加全面.")]),_._v(" "),v("p",[_._v("如果面试官问到了"),v("strong",[_._v("数据库性能优化和数据库分页查询, 都可以尝试把话题引导到分页查询上")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"基本思路-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-12"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("在面试的时候, 可以尝试介绍一下你是如何优化数据库性能的, 比如 SQL 本身优化, 数据库优化等. 然后罗列出你准备的 SQL 案例, 说明你在 SQL 优化方面做过哪些事情, 比如你说你优化过分库分表的查询, 其中最典型的就是优化分页查询.")]),_._v(" "),v("p",[_._v("我们假设之前是全局查询, 现在我们采用禁用跨页查询的方案来优化.")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始我在公司监控慢查询的时候, 发现有一个分页查询非常慢. 这个分页查询是按照更新时间降序来排序的. 后来我发现那个分页查询用的是全局查询法, 因为这个接口原本是提供给 Web 端用的, 而 Web 端要支持跨页查询, 所以只能使用全局查询法. 当查询的页数靠后的时候, 响应时间就非常长.")]),_._v(" "),v("p",[_._v("后来我们公司搞出 App 之后, 类似的场景直接复用了这个接口. 但是事实上在 App 上是没有跨页需求的. 所以我就直接写了一个新接口, 这个接口要求分页的时候带上上一页的最后一条数据的更新时间. 也就是用这个更新时间构造了一个查询条件, 只查询早于这个时间的数据. 那么分页查询的时候 OFFSET 就永远被控制在 0 了, 查询的时间就非常稳定了.")])]),_._v(" "),v("p",[_._v("最后可以加一个总结.")]),_._v(" "),v("blockquote",[v("p",[_._v("分页查询在分库分表里面是一个很难处理的问题, 要么查询可能有性能问题, 比如说这里使用的全局查询法, 要么就是要求业务折中, 比如说我优化后禁用了跨页, 以及要求数据平均分布的平均分页法, 当然还有各方面都不错, 但是实现比较复杂的二次查询法, 中间表法.")])]),_._v(" "),v("p",[_._v("当面试官追问你其中细节的时候, 就可以这样来引导.")]),_._v(" "),v("h6",{attrs:{id:"全局查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#全局查询"}},[_._v("#")]),_._v(" 全局查询")]),_._v(" "),v("p",[_._v("从理论上来说, "),v("strong",[_._v("分页查询要在全局有序的情况下进行")]),_._v('. 但是在分库分表之后, 要想做到 "全局有序" 就非常难了. 假如数据库 order_tab 是以 buyer_id 除以 2 的余数(%2) 来进行分表的, 如果要执行一个语句.')]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("那么实际执行查询的时候, 就要考虑各种数据的分布情况.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("符合条件的数据全部在某个表里面")]),_._v(". 在这里就是两种情况, order_tab_0 上有全部数据, 或者 order_tab_1 上有全部数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/16a549f16b023c7991c292d71e65524c-20231223175001-0v8d4b8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("偏移量中前面两条全部在一张表, 但是符合条件的数据在另外一张表")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4e9e5b80d67a6e624c098decfc12c288-20231223175001-h41f6wc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("偏移量和数据在两张表都有")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6421d53d83947d347a2bb3b040605a11-20231223175001-43wmzbw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以在分库分表里面, 这样一个 SELECT 语句生成的目标语句是这样的:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("6")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("6")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("注意看 LIMIT 部分, 被修改成了 0, 6. 用更加通用的形式来描述, 就是如果一个分页语句是 "),v("code",[_._v("LIMIT x OFFSET y")]),_._v("​ 的形式, 那么最终生成的目标语句就是 "),v("code",[_._v("LIMIT x + y OFFSET 0")]),_._v("​.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" x "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" y "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" x"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("+")]),_._v("y "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("当分库分表中间件拿到这两个语句的查询结果之后, 就要"),v("strong",[_._v("在内存中进行排序")]),_._v(", 再找出全局的 "),v("code",[_._v("LIMIT 4 OFFSET 2")]),_._v("​.")]),_._v(" "),v("p",[_._v("那么可以先回答这种全局排序的基本思路, 抓住关键词 "),v("strong",[_._v("LIMIT x+y OFFSET 0")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("分库分表中间件一般采用的都是全局排序法")]),_._v(". 假如要查询的是 LIMIT x OFFSET y. 那么分库分表中间件会把查询改写为 LIMIT x+y OFFSET 0, 然后把查询请求发送给所有的目标表. 在拿到所有的返回值之后, 在内存中排序, 并且根据排序结果找出全局符合条件的目标数据.")])]),_._v(" "),v("p",[_._v("接下来可以先从性能问题上刷一个亮点, 抓住受影响的三个方面: "),v("strong",[_._v("网络, 内存, CPU")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这个解决方案最大的问题是性能不太好. 首先是网络传输瓶颈, 比如在 LIMIT 10 OFFSET 1000 这种场景下, 如果没有分库分表, 那么只需要传输 10 条数据. 而在分库分表的情况下, 如果命中了 N 个表, 那么需要传输的就是 (1000 + 10) * N 条数据. 而实际上最终只会用其中的 10 条数据, 存在巨大的浪费.")]),_._v(" "),v("p",[_._v("其次是内存瓶颈. 收到那么多数据之后, 中间件需要维持在内存中排序. CPU 也会成为瓶颈, 因为排序本身是一个 CPU 密集的操作. 所以在 Proxy 形态的分库分表中间件里面, 分页查询一多, 就容易把中间件的内存耗尽, 引发 OOM, 又或者 CPU 100%. 不过可以通过归并排序来缓解这些问题.")])]),_._v(" "),v("p",[_._v("这里还留了一个归并排序的引导点, 但是面试官如果不擅长分库分表的话, 他可能注意不到这个地方, 那也可以直接回答. 关键点就是在拿到数据之后, 使用 "),v("strong",[_._v("归并排序")]),_._v(" 的算法.")]),_._v(" "),v("blockquote",[v("p",[_._v("在分库分表里面, 可以使用归并排序算法来给返回的结果排序. 也就是说在改写为 LIMIT x+y OFFSET 0 之后, 每一个目标表返回的结果都是有序的, 自然可以使用归并排序. 在归并排序的过程中, 可以逐条从返回结果中读取, 这意味着没必要将所有的结果一次性放到内存中再排序. 在分页的场景下, 取够了数据就可以直接返回, 剩下的数据就可以丢弃了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/42273c6cd1d0db2b49b83410bc2bab68-20231223175001-m73gbuq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不过既然前面说了全局查询这个方案的性能很差, 那么有没有其他方案呢? 的确有, 比如"),v("mark",[v("strong",[_._v("平均分页, 禁用跨页查询, 换用其他中间件")])]),_._v("等. 不过任何方案都不是十全十美的, 这些方案也存在一些难点, 有的是需要业务折中, 有的处理过程非常复杂.")]),_._v(" "),v("p",[_._v("先来看第一个需要"),v("strong",[_._v("业务折中")]),_._v("的平均分页方案.")]),_._v(" "),v("h5",{attrs:{id:"平均分页"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#平均分页"}},[_._v("#")]),_._v(" 平均分页")]),_._v(" "),v("p",[_._v("如果你不了解分库分表, 那么看到分页查询的第一个念头应该就是: 能不能在不同的表上平均分页查询数据, 得到的结果合并在一起就是分页的结果.")]),_._v(" "),v("p",[_._v("例如, 查询中的语句是这样的:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("因为本身只有两张表, 那么可以改写成这样:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_0 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_1 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("也就是说, 在每一张表都查询从偏移量 1 开始的 2 条数据, 那么合并在一起就可以认为是从全局的偏移量 2 开始的 4 条数据.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/87540e1959550b2dc72088572965c20d-20231223175001-hwnr9nc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以看一下我给出的平均分页图, 从图里能够看出来, 按照道理全局的 LIMIT 4 OFFSET 2 拿到的应该是 3, 4, 5, 6 四条数据. 但是这里拿到的数据却是 2, 4, 5, 9. 这也就是这个方案的缺陷: 它存在 "),v("strong",[_._v("精度")]),_._v(" 问题. 也就是说, 它返回的"),v("strong",[_._v("数据并不一定是全局最精确的数据")]),_._v(".")]),_._v(" "),v("p",[_._v("那么这个方案是不是就不能用了呢? 并不是的, 在一些对顺序, 精度要求不严格的场景下, 还是可以用的. 例如浏览页面, 只需要返回足够多的数据行, 但是这些数据具体来自哪些表, 用户并不关心.")]),_._v(" "),v("p",[_._v("因此在回答的时候, 抓住关键词: "),v("strong",[_._v("平均分页")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在一些"),v("mark",[_._v("可以接受分页结果不精确的场景")]),_._v("下, 可以考虑平均分页的做法. 举个例子来说, 如果查询的是 LIMIT 4 OFFSET 2, 并且命中了两张目标表, 那么就可以考虑在每个表上都查询 LIMIT 2 OFFSET 1. 这些结果合并在一起就是 LIMIT 4 OFFSET 2 的一个近似答案. 这种做法对于数据分布均匀的分库分表效果很好, 偏差也不大.")])]),_._v(" "),v("p",[_._v("这个方案还有一个进阶版本, 就是根据数据分布来决定如何取数据. 假如预计查询的数据有 70% 在 order_tab_0, 有 30% 在 order_tab_1, 然后你假设逻辑上的查询是:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("10")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("100")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("那么可以根据数据分布, 从 order_tab_0 取 70% 的数据, 然后在 order_tab_1 取 30% 数据, 偏移量也是如此.")]),_._v(" "),v("p",[_._v("因此目标 SQL 就是:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_0 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("7")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("70")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_1 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("30")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("这个进阶版本可以在前面的基本回答之后进一步补充.")]),_._v(" "),v("blockquote",[v("p",[_._v("更加通用的做法是根据数据分布来决定分页在不同的表上各自取多少条数据. 比如说一张表上面有 70% 的数据, 但是另一张表上只有 30% 的数据, 那么在 LIMIT 10 OFFSET 100 的场景下, 可以在 70% 的表里取 LIMIT 7 OFFSET 70, 在 30% 的表里取 LIMIT 3 OFFSET 30. 所以也可以把前面平均分配的方案看作是各取 50% 的特例.")])]),_._v(" "),v("p",[_._v("那么面试官就可能进一步追问, 你怎么知道一张表上有 70% 的数据, 另外一张表上有 30%. 这个倒是很简单, 在开发的时候先用 SQL 在不同的表上执行一下, 看看同样的 WHERE 条件下各自返回了多少数据, 就可以推断出来了.")]),_._v(" "),v("p",[_._v("不过实际上, 能够接受不精确的业务场景还是比较少的. 所以还有一种"),v("strong",[_._v("业务折中")]),_._v("的解决方案, 它精确并且高效, 也就是"),v("strong",[_._v("禁用跨页查询方案")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"禁用跨页查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#禁用跨页查询"}},[_._v("#")]),_._v(" 禁用跨页查询")]),_._v(" "),v("p",[v("strong",[_._v("禁用跨页查询, 意思就是要求用户只能从第 0 页开始, 逐页往后翻, 不允许跨页")]),_._v(". 比如从第 3 页跳到第 10 页, 这种是不允许的. 假如业务上分页查询是 50 条数据一页. 那么发起的查询依次是:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("100")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br")])]),v("p",[_._v("可以看到, 这里不断增长的只有偏移量. 那么有没有办法控制住这个偏移量呢?")]),_._v(" "),v("p",[_._v("答案就是根据 ORDER BY 的部分来增加一个查询条件. 在上面的例子里, ORDER BY id 是按照 id 升序排序的, 那么只需要在 WHERE 部分增加一个大于上次查询的最大 id 的条件就可以了.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" max_id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("max_id 就是上一批次的最大 id.")]),_._v(" "),v("p",[_._v("反过来, 如果 ORDER BY 是降序的, 比如 ORDER BY id DESC, 那么对应的 SQL 就变成这样:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),_._v(" min_id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("0")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("min_id 就是上一批次里最小的 id.")]),_._v(" "),v("p",[_._v("即便 ORDER BY 里面使用了多个列, 规则也是一样的.")]),_._v(" "),v("p",[_._v("总的来看, 回答要分成两部分, 第一部分介绍基本做法, 关键词是"),v("strong",[_._v("拿到上一批次的极值")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("目前比较好的分页做法是禁用跨页查询, 然后在每一次查询条件里面加上上一次查询的极值, 也就是最大值或者最小值. 比如说第一次查询的时候 ORDER BY ID LIMIT 10 OFFSET 0, 那么下一页, 就可以改成 WHERE id > max_id ORDER BY ID LIMIT 10 OFFSET 0. 在现在的手机 App 里这个策略是非常好用的, 因为手机 App 都是下拉刷新, 天然就不存在跨页的问题.")])]),_._v(" "),v("p",[_._v("第一部分提到了极值, 那么面试官就可能问什么时候用最大值, 什么时候用最小值. 可以这样说:")]),_._v(" "),v("blockquote",[v("p",[_._v("至于用最大值还是用最小值, 这个取决于 ​ORDER BY. 总的原则就是升序用最大值, 降序用最小值. 如果 ORDER BY 里面包含了多个列, 那么针对每一个列是升序还是降序, 来确定使用最大值还是使用最小值.")])]),_._v(" "),v("p",[_._v("这种方案在实践中使用得非常广泛. 不过还有一个更加简单粗暴的方案, 既然分库分表难以处理分页的问题, 那么干嘛不"),v("strong",[_._v("直接换用其他中间件")]),_._v("呢?")]),_._v(" "),v("h6",{attrs:{id:"换用其他中间件"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#换用其他中间件"}},[_._v("#")]),_._v(" 换用其他中间件")]),_._v(" "),v("p",[_._v("这个思路可以说是非常直接了, 既然分库分表导致了分页很困难, 那就换一个不需要分库分表的中间件不就好了吗? 也可以, 换中间件也有两种思路.")]),_._v(" "),v("p",[_._v("第一种思路是"),v("strong",[_._v("用 NoSQL 之类的来存储数据")]),_._v(". 比如说使用 Elasticsearch, ClickHouse. 另外一种思路是"),v("strong",[_._v("使用分布式关系型数据库")]),_._v(". 这其实就相当于把分页的难题抛给了这些数据库, 性能如何就取决于最终选择了哪个分布式关系型数据库.")]),_._v(" "),v("p",[_._v("上面这些方案不管是从实际, 还是从理论上, 都有各自的特色. 下面再往前一步, 看看还有哪些比较好用且有亮点的方案.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-10"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-10"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这里提供两个亮点方案. 第一个是"),v("strong",[_._v("二次查询")]),_._v(". 实际上它应该是一个常见的方案, 但因为过于复杂所以能够记住并且把原理讲清楚, 本身就是一件不容易的事情. 第二个是"),v("strong",[_._v("引入中间表")]),_._v(". 这个方案从复杂度上来说是不如二次查询的, 但是它比较罕见, 也就是说面经里面会提到这个方案的比较少.")]),_._v(" "),v("h6",{attrs:{id:"二次查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#二次查询"}},[_._v("#")]),_._v(" 二次查询")]),_._v(" "),v("p",[_._v("二次查询的基本理念是先尝试 "),v("strong",[_._v("获得某个数据的全局偏移量, 然后再根据这个偏移量来计算剩下数据的偏移量")]),_._v(". 这里用一个例子来阐述它的基本原理, 再抽象出一般步骤.")]),_._v(" "),v("p",[_._v("假设查询依旧是:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("数据分布如图所示:")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7aaf207eaea00b7b217f276534a6be9f-20231223175001-o9nboou.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("全局上的 LIMIT 4 OFFSET 4 是 5, 6, 7, 8 四条数据.")]),_._v(" "),v("blockquote",[v("p",[_._v("步骤一: 首次查询")])]),_._v(" "),v("p",[_._v("把 SQL 语句改写成这样:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_0 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_1 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ORDER")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("OFFSET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("注意, 这里只是把 OFFSET 平均分配了, 但是 LIMIT 没变.")]),_._v(" "),v("p",[_._v("那么第一次查询到的数据是怎样的呢? 可以看一下图片.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e6662eb434cce0f4ca813aa7c3b4949b-20231223175001-u6jas2v.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("order_tab_0 拿到了 4, 6, 10, 12, 而 order_tab_1 拿到了 7, 8, 9, 11.")]),_._v(" "),v("blockquote",[v("p",[_._v("步骤二: 确认最小值")])]),_._v(" "),v("p",[_._v("很明显, 上一步返回的查询数据里面, id 最小的是 4, 来自 order_tab_0.")]),_._v(" "),v("blockquote",[v("p",[_._v("步骤三: 二次查询")])]),_._v(" "),v("p",[v("strong",[_._v("这一次查询需要利用上一步找出来的最小值以及各自分库的最大值来构造 BETWEEN 查询")]),_._v(". 改写得到的 SQL 是:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_0 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("BETWEEN")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("12")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" order_tab_1 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("BETWEEN")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("11")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("结果:")]),_._v(" "),v("ul",[v("li",[_._v("order_tab_0 返回 4, 6, 10, 12.")]),_._v(" "),v("li",[_._v("order_tab_1 返回 5, 7, 8, 9, 11, 也就是多了 1 条数据, 记住这一点.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e5c1e34b6147d40af7b908047324yy93-20231223175001-je22h8m.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("取过来的所有数据排序")]),_._v("之后就是 4, 5, 6, 7, 8, 9, 10, 11, 12.")]),_._v(" "),v("blockquote",[v("p",[_._v("步骤四: 计算最小值的全局偏移量")])]),_._v(" "),v("p",[_._v("这是最难理解的一步, 抓住核心: "),v("strong",[_._v("根据 BETWEEN 中多出来的数据量来推断全局偏移量")]),_._v(". 现在知道 4 在 order_tab_0 中的偏移量是 2, 也就是说比 4 小的数据有 2 条. 在 BETWEEN 查询里面, order_tab_1 返回的结果是 5, 7, 8, 9, 11, 7 在第一次查询里面的偏移量是 2, 所以 5 的偏移量是 1. 也就是说, 5 的前面只有一条比 4 小的数据.")]),_._v(" "),v("p",[_._v("那么 4 在 order_tab 中的全局偏移量就是 3(2+1), 换一句话来说, 就是 4 前面有三条数据.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4b69ed053aa4bf27d2b3d25b3978d426-20231223175001-9dxn6an.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么加上 4 本身, 刚好构成了 OFFSET 4, 因此就是从 5 开始取, 往后取 4 条数据.")]),_._v(" "),v("blockquote",[v("p",[_._v("小结")])]),_._v(" "),v("p",[_._v("现在抽象地说一下这个算法. 假设分库分表总共有 N 个表, 查询是 LIMIT X OFFSET Y, 那么:")]),_._v(" "),v("ol",[v("li",[_._v("首先发送查询语句 LIMIT X OFFSET Y/N 到所有的表.")]),_._v(" "),v("li",[_._v("找到所有返回结果中的最小值(升序), 记为 min.")]),_._v(" "),v("li",[_._v("执行第二次查询, 关键是 BETWEEN min AND max. 其中 max 是在第一次查询的数据中每个表各自的最大值.")]),_._v(" "),v("li",[_._v("根据 min, 第一次查询和第二次查询的值来确定 min 的全局偏移量. 总的来说, min 在某个表里面的偏移量这样计算: 如果第二次查询比第一次查询多了 K 条数据, 那么偏移量就是 Y 除以 N 减去 K. 然后把所有表的偏移量加在一起, 得到的就是 min 的全局偏移量.")]),_._v(" "),v("li",[_._v("根据 min 的全局偏移量, 在第二次查询的结果里面向后补足到 Y, 得到第一条数据的位置, 再取 X 条.")])]),_._v(" "),v("p",[_._v("上面的这些步骤太难记忆了, 这里给一个简化版本.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("首次查询, 拿到最小值")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("二次查询, 确认最小值的全局偏移量")]),_._v(".")]),_._v(" "),v("li",[_._v("在二次查询的结果里根据最小值取到符合偏移量的数据.")])]),_._v(" "),v("p",[_._v("这个部分难以理解, 所以在面试回答的时候, 可以尝试回答 "),v("strong",[_._v("最简版本")]),_._v(". 如果面试官继续发问, 就可以通过前面的例子来进一步解释.")]),_._v(" "),v("h6",{attrs:{id:"引入中间表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#引入中间表"}},[_._v("#")]),_._v(" 引入中间表")]),_._v(" "),v("p",[_._v("引入中间表的意思是"),v("strong",[_._v("额外存储一份数据, 只用来排序")]),_._v(". 这个方案里面就是在中间表里"),v("strong",[_._v("加上排序相关的列")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e7dab6da49d87e9ec979a07e7366ba66-20231223175001-hkysj5p.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("排序是一个非常常见的需求, 那么就可以考虑引入一个中间表来辅助排序. 比如在使用更新时间来排序的时候, 在中间表里面加上更新时间. 查询的时候先在中间表里面查到目标数据, 然后再去目标表里面把全部数据都查询出来.")])]),_._v(" "),v("p",[_._v("这个方案也是有缺点的, 可以进一步指出来.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案有两个明显的缺陷, 一个是 WHERE 也只能使用中间表上的列; 另外一个是维护中间表也会引入数据一致性的问题.")])]),_._v(" "),v("p",[_._v("对于第一个缺陷, 面试官应该没什么好问的. 但是第二个缺陷, 也是一个鱼饵, 不出意外面试官就会追问怎么解决这个数据一致性的问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a051a814364db389bff20e5825cacf8c-20231223175001-eg48imu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("比较简单的做法就是业务保持双写, 也就是写入目标表也写入中间表. 不过这里更加建议使用 Canal 之类的框架来监听 binlog, 异步更新中间表. 这样做的好处是业务完全没有感知, 没有什么改造成本. 更新的时候可以考虑引入重试机制, 进一步降低失败的几率.")])]),_._v(" "),v("p",[_._v("这个回答可能会把话题引向前面学过的 binlog, 做好准备就可以.")]),_._v(" "),v("p",[_._v("这里还需要注意, 面试官可能进一步问你, 如果更新中间表经过重试之后也失败了, 怎么办? 这时候并没有更好的办法, 无非就是引入告警, 然后人工介入处理.")]),_._v(" "),v("p",[_._v("最后可以再总结一下这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案是一个依赖最终一致性的方案, 在强调强一致性的场景下并不是很合适.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-16"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-16"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节课内容也有点多, 再来捋一捋. 基础知识的部分需要掌握分库分表的一般做法: 哈希分库分表, 范围分库分表和中间表分库分表. 还有分库分表中间件的形态: "),v("strong",[_._v("SDK, Proxy 和 Sidecar")]),_._v(".")]),_._v(" "),v("p",[_._v("还重点讨论了"),v("strong",[_._v("分页的解决思")]),_._v("路, 分别是:")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("全局查询")]),_._v(": 注意它的性能问题, 以及用归并排序缓解性能问题.")]),_._v(" "),v("li",[v("strong",[_._v("平均分页")]),_._v(": 注意根据数据分布来分页的一般算法.")]),_._v(" "),v("li",[v("strong",[_._v("禁用跨页查询")]),_._v(": 这在实践中非常常用, 基本没什么缺点.")]),_._v(" "),v("li",[v("strong",[_._v("换用其他中间件")]),_._v(": 需要了解对应的中间件.")])]),_._v(" "),v("p",[_._v("最后还给出了两个亮点方案, 一个是二次查询, 这个方案很复杂, 所以需要多花一点精力, 在面试前多模拟练习一下. 另一个是引入中间表: 这个方案并不复杂, 只是因为罕见所以适合拿来面试.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/69fcac6cf43a362d5ba7bc11457b8bb7-20231223175001-1p2bwjn.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-15"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("留两道思考题.")]),_._v(" "),v("ul",[v("li",[_._v("如果查询里面有 GROUP BY, 其实会影响到分页的执行. 你可以说说假如 GROUP BY 刚好是根据分库分表键来进行的, 分页可以怎么执行呢? 不然的话又该怎么执行呢?")]),_._v(" "),v("li",[_._v("我在这里用的例子都是哈希分表的, 那么在使用范围分库分表的情况下, 分页查询执行又有一些不同, 你能说一下范围查询的做法会有怎样的区别吗? 我可以给你一些提示, 要注意 ORDER BY 和分库分表键, 还要注意 GROUP BY.")])]),_._v(" "),v("h4",{attrs:{id:"_18-分布式事务-如何同时保证分库分表-acid和高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_18-分布式事务-如何同时保证分库分表-acid和高性能"}},[_._v("#")]),_._v(" 18-分布式事务:如何同时保证分库分表,ACID和高性能?")]),_._v(" "),v("p",[_._v("在把单库拆分成为分库分表之后, 一个巨大的挑战就是"),v("strong",[_._v("本地事务变成了分布式事务")]),_._v(". 事实上, 即便没有分库分表, 在微服务架构之下也还是会面临分布式事务的问题. 所以, 在学习了微服务架构又学习了分库分表之后, 是时候深入讨论一下分布式事务了.")]),_._v(" "),v("p",[_._v("分布式事务在面试中是一把双刃剑, 用得好, 那么会是一个非常强的加分项. 但如果基础不够扎实, 见闻不够广博, 面分布式事务很容易翻车, 所以熟练掌握分布式事务很重要.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-7"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-7"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("关于分布式事务, 首先需要弄清楚一个东西, 就是"),v("strong",[_._v("分布式事务既可以是纯粹多个数据库实例之间的分布式事务, 也可以是跨越不同中间件的业务层面上的分布式事务")]),_._v(". 前者一般是分库分表中间件提供支持, 后者一般是独立的第三方中间件提供支持, 比如 Seata. 在面试的时候, 要根据上下文确定面试官问的分布式事务是哪一类, 然后有针对性地回答.")]),_._v(" "),v("p",[_._v("要学习分布式事务, 要先学习分布式事务中几个比较常用的协议.")]),_._v(" "),v("h6",{attrs:{id:"两阶段提交"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#两阶段提交"}},[_._v("#")]),_._v(" 两阶段提交")]),_._v(" "),v("p",[_._v("两阶段提交协议(Two Phase Commit)是分布式事务中的一种常用协议, 算法思路可以概括为"),v("strong",[_._v("参与者将操作成败通知协调者, 再由协调者根据所有参与者的反馈情况决定各参与者要提交操作还是中止操作")]),_._v(".")]),_._v(" "),v("p",[_._v("它可以分为两个阶段: "),v("strong",[_._v("准备阶段和提交阶段")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6yyac8bf7452e05cb0d0edaf24363193-20250116210757-z84le97.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",[v("li",[_._v("准备阶段, "),v("strong",[_._v("协调者让参与者执行事务, 但是并不提交, 协调者返回执行情况")]),_._v(". 这个阶段参与者会记录 Redo 和 Undo 信息, 用于后续提交或者回滚.")]),_._v(" "),v("li",[_._v("提交阶段, 协调者根据准备阶段的情况, 要求参与者提交或者回滚, 参与者返回提交或者回滚的结果. 准备阶段任何一个节点执行失败了, 就都会回滚. 全部执行成功就提交.")])]),_._v(" "),v("p",[_._v("两阶段提交协议的缺点很多. 最大缺点是"),v("mark",[v("strong",[_._v("在执行过程中节点都处于阻塞状态")])]),_._v(". 也就是节点之间在等待对方的响应消息时, 什么也做不了. 特别是如果某个节点在已经占有了某项资源的情况下, 为了等待其他节点的响应消息而陷入阻塞状态时, 当第三个节点尝试访问该节点占有的资源时, 这个节点也会连带着陷入阻塞状态.")]),_._v(" "),v("p",[_._v("此外, "),v("strong",[_._v("协调者也是关键, 如果协调者崩溃, 整个分布式事务都无法执行")]),_._v(". 所以, 如果协调者是单节点, 那么就容易"),v("strong",[_._v("出现单节点故障")]),_._v(". 而且协调者采用保守策略, 如果一个节点在第一阶段没有返回响应, 那么协调者会执行回滚. 所以这可能会引起不必要的回滚.")]),_._v(" "),v("p",[_._v("而这里有一个问题, 很少有人会想到. 如果在第二阶段, 协调者发送 Commit 的时候, 参与者没有收到, 会怎样? 那么协调者会不断重试, 直到请求发送成功.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0fdca749e1590ee06ec873e813b505fc-20250116210757-baypf3d.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是如果参与者已经收到了 Commit 请求, 但是在提交之前就宕机了又该怎样呢?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6d2cf55f54b9665b93fdb6f6e7e7d214-20250116210757-7fc5okc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("参与者在恢复过来之后会查看自己本地的日志, 看有没有收到 Commit 指令, 如果已经收到了, 就会使用 Redo 信息来提交事务.")]),_._v(" "),v("p",[_._v("总的来说, 两阶段提交协议是分布式事务中"),v("strong",[_._v("最常用的协议之一")]),_._v(", 它可以有效地保证"),v("strong",[_._v("分布式事务的一致性和可靠性")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"三阶段提交"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#三阶段提交"}},[_._v("#")]),_._v(" 三阶段提交")]),_._v(" "),v("p",[_._v("三阶段提交协议是在两阶段提交协议的基础上进行的改进, 三阶段提交协议引入了一个"),v("strong",[_._v("额外阶段")]),_._v("来确保在执行事务之前有足够的资源, 减少两阶段协议引起的事务失败的可能.")]),_._v(" "),v("p",[_._v("在两阶段协议里面, "),v("strong",[_._v("比较容易出现的一个情况就是参与者在准备阶段辛辛苦苦把 Redo, Undo 写好, 结果另外一个参与者说自己这边执行不了事务, 要回滚")]),_._v(". 那么这个参与者就白费功夫了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f2147aa08d4ffe5ddc150be15e33ffb6-20250116210757-erfzp7f.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此在两阶段提交的基础上, 三阶段提交引入了一个"),v("strong",[_._v("新阶段")]),_._v(", 协调者会先问一下参与者能不能执行这个事务. 所以整个三阶段提交协议的三个阶段是这样的:")]),_._v(" "),v("ol",[v("li",[_._v("第一阶段(CanCommit): "),v("strong",[_._v("协调者问一下各个参与者能不能执行事务")]),_._v(". 参与者这时候一般是检查一下自己有没有足够的资源.")]),_._v(" "),v("li",[_._v("第二阶段(PreCommit): "),v("strong",[_._v("类似于两阶段提交的第一个阶段, 执行事务但是不提交")]),_._v(".")]),_._v(" "),v("li",[_._v("第三阶段(Commit): "),v("strong",[_._v("直接提交或者回滚")]),_._v(".")])]),_._v(" "),v("p",[_._v("目前看来, 三阶段提交协议并没有两阶段提交协议使用得那么广泛, 原因有两个, 一是两阶段提交协议已经足以解决大部分问题了, 二是三阶段提交协议的收益和它的复杂度比起来, 性价比有点低.")]),_._v(" "),v("h6",{attrs:{id:"xa事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#xa事务"}},[_._v("#")]),_._v(" XA事务")]),_._v(" "),v("p",[_._v("XA 事务遵循了两阶段提交协议. 个人认为, 两阶段协议是一种学术理论, "),v("strong",[_._v("而 XA 则是把两阶段提交协议具像化之后的一个标准")]),_._v(". 它定义了协调者和参与者之间的接口. 用专业的术语来说, 就是"),v("strong",[_._v("定义了事务管理器(Transaction Manager)和资源管理器(Resource Manager)之间的接口")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("小结一下")])]),_._v(" "),v("p",[_._v("这里讲一个稍微有点争议的事情, 也就是 XA 是否满足 ACID. 我注意到网上有一部分人认为 XA, 或者说两阶段提交协议, 有数据一致性的问题, 但是也有人认为 XA 是满足 ACID 的.")]),_._v(" "),v("p",[_._v("我在两阶段提交那里说到在提交阶段, 协调者会不断重试直到把 Commit 请求发送给协调者; 协调者如果在提交阶段中途崩溃, 也要确定是否需要提交或者回滚. 那么你就应该可以理解, 在重试成功之前, 或者在协调者恢复过来重新提交或者回滚之前, 数据是 "),v("strong",[_._v("不一致")]),_._v(" 的.")]),_._v(" "),v("p",[_._v("所以我 "),v("strong",[_._v("个人")]),_._v(" 倾向 XA 不满足 ACID. 但是相比其他的方案, 它更加接近 ACID.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-18"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-18"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("关于分布式事务, 你在公司需要弄清楚几个问题:")]),_._v(" "),v("ol",[v("li",[_._v("如果公司使用了分库分表, 那么"),v("strong",[_._v("是否允许跨库事务")]),_._v("?")]),_._v(" "),v("li",[_._v("如果允许跨库事务, 那么是如何解决的?")]),_._v(" "),v("li",[_._v("如果使用了分库分表中间件, 那么它支持哪些类型的事务?")]),_._v(" "),v("li",[v("strong",[_._v("在微服务层面上, 使用的是什么样的分布式事务方案? 是 TCC, SAGA 还是 AT")]),_._v("?")]),_._v(" "),v("li",[_._v("当在使用分布式事务的时候, 中间步骤出错了你怎么办?")])]),_._v(" "),v("p",[_._v("此外, 最好收集一些实际的案例, 在面试的时候作为证据.")]),_._v(" "),v("p",[_._v("正常来说, 在面试微服务架构的时候就有可能面到分布式事务. 面试官可能会问这两个问题.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("在单体应用拆分成微服务架构之后, 你怎么解决分布式事务")]),_._v("?")]),_._v(" "),v("li",[_._v("你们的"),v("strong",[_._v("服务是共享一个数据库吗? 如果不是的话, 怎么解决分布式事务问题")]),_._v("?")])]),_._v(" "),v("p",[_._v("当然, 在分库分表里面也会有类似的问法.")]),_._v(" "),v("ul",[v("li",[_._v("在单库拆分之后, 你怎么解决分布式事务问题?")]),_._v(" "),v("li",[_._v("当开启一个事务的时候, 分库分表中间件做了什么?")]),_._v(" "),v("li",[v("strong",[_._v("怎么在分库分表的事务里面保证 ACID")]),_._v("?")])]),_._v(" "),v("p",[_._v('有些时候面试官不会直接问分布式事务, 而是问数据一致性的问题, 其实基本上也是问的分布式事务. 他可能这样问: "如果你的 DELETE 语句, 经过分库分表之后要删除多张表的数据, 那怎么保证数据一致性?" 所以对于数据一致性的问题, 也要做好准备.')]),_._v(" "),v("p",[_._v("其实面试翻车的一个主要原因就是你不熟悉各种异常情况的处理方案, 所以在接下来介绍的各种方案里面, 容错都是一个比较重要的部分, 也是用来刷亮点的部分.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-13"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-13"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("一句话总结, "),v("mark",[v("strong",[_._v("就是既想要 ACID, 又想要分布式事务, 以目前的条件来说基本不可能. 所以所有解决分布式事务的方案, 立足点都是最终一致性")])]),_._v(". 因此不管从哪里提到了分布式事务, 如果面试官问起来, 都可以先从理论上强调这一点, 关键词是 "),v("strong",[_._v("最终一致性")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("分布式事务或者说跨库事务基本上都只能依赖于最终一致性, ACID 是不太可能的. 比如说常见的 TCC, AT, SAGA, 又或者比较罕见的延迟事务, 其实都是追求最终一致性")]),_._v(".")])]),_._v(" "),v("p",[_._v("这里提到了 TCC, AT 和 SAGA 这些比较具体的方案, 就可以根据后面的内容来进一步解释, 或者等面试官询问.")]),_._v(" "),v("p",[_._v('注意, 如果面试官认为 XA 是支持 ACID 的, 那么他可能会问: "难道没有什么能够保证 ACID 吗?" 通过这种问题你就可以知道面试官的倾向了, 那就可以抛开个人立场, 回答 XA 事务.')]),_._v(" "),v("blockquote",[v("p",[_._v("有, XA 事务可以看作支持 ACID.")])]),_._v(" "),v("p",[_._v("如果面试官直接问 XA, 那么就可以按照自己的真实想法来回答.")]),_._v(" "),v("h6",{attrs:{id:"tcc事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#tcc事务"}},[_._v("#")]),_._v(" TCC事务")]),_._v(" "),v("p",[v("strong",[_._v("TCC 是一个追求最终一致性, 而不是严格一致性的事务解决方案, 它不满足 ACID 要求")]),_._v(". TCC 是 Try-Confirm-Cancel 的缩写, 它"),v("strong",[_._v("勉强也算是两阶段提交协议的一种实现")]),_._v(".")]),_._v(" "),v("ul",[v("li",[_._v("Try: 对应于两阶段提交协议的准备阶段, 执行事务但是不提交.")]),_._v(" "),v("li",[_._v("Confirm: 对应于两阶段提交协议第二阶段的"),v("strong",[_._v("提交步骤")]),_._v(".")]),_._v(" "),v("li",[_._v("Cancel: 对应于两阶段提交协议第二阶段的"),v("strong",[_._v("回滚步骤")]),_._v(".")])]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("之所以给它一个新名字, 完全是因为 TCC 强调的是业务自定义逻辑")])]),_._v(". 也就是说 "),v("strong",[_._v("Try 是执行业务自定义逻辑, Confirm 也是执行业务自定义逻辑, Cancel 同样如此")]),_._v(".")]),_._v(" "),v("p",[_._v("TCC 在微服务架构里面比较常用, "),v("strong",[_._v("Try 对应一个微服务调用, Confirm 对应一个微服务调用, Cancel 也对应一个微服务调用")]),_._v(". 不过一些分库分表中间件也支持 TCC 模式, 但是比较罕见.")]),_._v(" "),v("p",[_._v("接下来可以从两个角度深入讨论.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点一: TCC与本地事务")])]),_._v(" "),v("p",[_._v("其实在微服务架构中 Try-Confirm-Cacel 都对应一个微服务调用, 你就可以猜测到, TCC 的任何一个步骤都可以是"),v("mark",[v("strong",[_._v("本地事务")])]),_._v(", 所以可以这样说:")]),_._v(" "),v("blockquote",[v("p",[_._v("在 TCC 里面, Try 可以是一个完整的本地事务, Confirm 也可以是一个完整的本地事务, Cancel 同样可以是一个完整的本地事务.")])]),_._v(" "),v("p",[_._v("然后可以用这个例子补充说明.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f452e763d48daf1ce86833771af04ca7-20250116210757-f73wh4z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("比如在我的某个业务里面, Try 本身就是插入数据, 但是处于初始化状态, 还不能使用. 后续 Confirm 的时候就是把状态更新为可用, 而 Cancel 则是更新为不可用, 当然直接删除也是可以的.")])]),_._v(" "),v("p",[_._v("不过 TCC 怎样都是会出错的, 比如在 Confirm 阶段出错或者出现超时, 所以是搞不清楚究竟有没有提交的. 这里可以补一句, 引出下面的亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("TCC 用起来还是比较简单的, 但是要想做好容错还是很不容易的.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点二: 容错")])]),_._v(" "),v("p",[_._v("实际上, 正如之前好几次提到的, "),v("strong",[_._v("容错很多时候就是重试, 重试失败之后人工介入或者引入自动故障处理机制, 后续尝试修复数据")]),_._v(".")]),_._v(" "),v("p",[_._v("面试的时候需要一步步分析, 首先要"),v("strong",[_._v("分析出错的场景")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说, TCC 里面 T 阶段出错是没有关系的. 比如说前面的那个例子里, 数据处于初始化状态的时候, 其实后续业务是用不了的, 也就不会有问题. 但是如果在 Confirm 的时候出错了, 问题就比较严重了. 比如说一部分业务已经将数据更新为可用了, 另外一部分业务更新数据为可用失败, 那么就会出现不一致的情况.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/098b5608842f7501ed4a21acdf684746-20250116210757-2e4tg7c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着讲解决方案, 关键词是"),v("mark",[v("strong",[_._v("重试")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("基本上这里就是只能考虑不断重试, 确保在 Confirm 阶段都能提交成功. 毫无疑问, 不管怎么重试, 最终都可能是要失败的, 所以要做好监控和告警的机制.")])]),_._v(" "),v("p",[_._v("这里提到了重试最终都可能失败, 所以紧接着就要进一步补充重试失败了之后怎么办. 给两个方案, 第一个方案是"),v("strong",[_._v("异步比较数据并修复.")])]),_._v(" "),v("blockquote",[v("p",[_._v("我在后面搞了一个离线比对数据并修复的方案, 就是用来查找这种相关联的数据的, 一部分数据还处于初始化状态, 但是一部分数据已经处于可用状态, 然后修复那部分初始化的数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/999a42ef82eff53fa5affa5985bca50f-20250116210757-jgavq1s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("另外一个方案则是在读取数据的时候, 如果发现数据不一致, 那么就"),v("strong",[_._v("丢弃这个数据, 同时触发修复逻辑")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在一些业务场景下, 读请求是能够发现这种数据不一致的. 那么它就会立刻丢弃这个数据, 并且触发修复程序.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f17da3dc9b381aebd3dfc42867ea8239-20250116210757-hrn4o0h.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("到这里 TCC 已经讨论得比较深入了. 接下来可以考虑尝试把话题引到 SAGA.")]),_._v(" "),v("blockquote",[v("p",[_._v("TCC 整体来说是追求最终一致性的, 和它类似的是 SAGA 事务, 也是一个追求最终一致性的事务解决方案, 也不满足 ACID 的要求.")])]),_._v(" "),v("h6",{attrs:{id:"saga事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#saga事务"}},[_._v("#")]),_._v(" SAGA事务")]),_._v(" "),v("p",[_._v("SAGA 的核心思想一句话就可以说明白, "),v("strong",[_._v("就是把业务分成一个个步骤, 当某一个步骤失败的时候, 就")]),_._v("​"),v("mark",[v("strong",[_._v("反向补偿")])]),_._v("​"),v("strong",[_._v("前面的步骤.")])]),_._v(" "),v("p",[_._v("很多人在介绍 SAGA 的时候会用"),v("strong",[_._v("回滚")]),_._v("这个词来取代反向补偿, 但是我认为这会让你误解 SAGA, 所以这里就用"),v("strong",[_._v("反向补偿")]),_._v("这个词.")]),_._v(" "),v("p",[_._v("举一个例子, 某个步骤是插入数据, 如果是回滚的话, 那么是指插入的时候没有提交, 然后在业务失败的时候回滚. "),v("strong",[_._v("如果是反向补偿的话, 那么是指插入的时候已经提交了, 然后在业务失败的时候执行删除")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b54fd51cb4e9e55b24f3a045729316c7-20250116210757-je1mpul.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在聊到 SAGA 的时候, 可以简单介绍一下 SAGA 的基本理念, 关键词是"),v("strong",[_._v("反向补偿")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("SAGA 的核心思想是反向补偿事务中已经成功的步骤. 比如说某个业务, 需要在数据库 1 和数据库 2 中都插入一条数据, 那么在数据库 1 插入之后, 数据库 2 插入失败, 那么就要删除原本数据库 1 的数据. 要注意, 在最开始数据库 1 插入的时候, 事务是已经被提交了的.")])]),_._v(" "),v("p",[_._v("大部分人没有使用过 SAGA. 这里给出我曾经使用过一个实现比较复杂但是理论很简单的 SAGA 调度机制, 可以用来刷亮点, 关键词是"),v("strong",[_._v("并发调度")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我设计过一个比较复杂的 SAGA 机制, 它支持并发调度. 也就是说如果整个分布式事务中有可以并发执行的步骤, 那么就并发执行, 在后续出错的时候, 这些并发执行的步骤也可以并发反向补偿.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4beb57642bb000fe1ae5fcdb658yy1d3-20250116210757-vv4s61s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("SAGA 本身也是"),v("strong",[_._v("需要考虑容错的, 难点就是在")]),_._v("​"),v("mark",[v("strong",[_._v("反向补偿的时候失败了")])]),_._v("​"),v("strong",[_._v("怎么办")]),_._v("? 比如在前面的例子里, 你准备删除数据的时候失败了. 那么还是没有特别好的办法, 无非就是"),v("strong",[_._v("不断重试")]),_._v(", 这一部分可以参考 TCC 中讨论的容错内容.")]),_._v(" "),v("p",[_._v("在讲完容错之后, 紧接着可以尝试把话题引导到 AT.")]),_._v(" "),v("blockquote",[v("p",[_._v("我个人认为最近比较流行的 AT 模式可以看作是 SAGA 的一种特殊形态, 或者说简化形态.")])]),_._v(" "),v("h6",{attrs:{id:"at事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#at事务"}},[_._v("#")]),_._v(" AT事务")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("AT 是指如果操作很多个数据库, 那么分布式事务中间件会帮你生成这些数据库操作的反向操作")])]),_._v(".")]),_._v(" "),v("p",[_._v("这就有点类似于 "),v("strong",[_._v("undo log")]),_._v(". 比如数据库操作是一个 INSERT, 那么对应的反向补偿操作就是 DELETE 了. 在回答的时候就可以结合 undo log 一起回答, 顺便把话题引导到 undo log 上.")]),_._v(" "),v("blockquote",[v("p",[_._v("AT 模式的核心是分布式事务中间件会帮你生成数据库的反向操作, 比如说 INSERT 对应的就是 DELETE, UPDATE 对应的就是 UPDATE, DELETE 对应的就是 INSERT. 这个机制有点类似于 undo log.")])]),_._v(" "),v("p",[_._v("同样地, AT 事务也有容错的问题, 它的容错和 SAGA 一样, 都是"),v("strong",[_._v("在反向补偿的时候出错了该怎么办")]),_._v(". 这里就不赘述了, 可以参考前面的内容.")]),_._v(" "),v("p",[_._v("在回答了这些内容之后, 还可以进一步强调可以考虑"),v("mark",[v("strong",[_._v("禁用跨库事务")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("如果是单纯使用分库分表, 不涉及多个服务的分布式事务, 可以考虑直接禁用跨库事务, 一了百了.")])]),_._v(" "),v("h6",{attrs:{id:"禁用跨库事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#禁用跨库事务"}},[_._v("#")]),_._v(" 禁用跨库事务")]),_._v(" "),v("p",[_._v("在实践中, "),v("strong",[_._v("解决分库分表中的分布式事务问题, 最简单的方式就是直接禁用跨库事务")]),_._v(". 正常来说, 在分库分表之后, 业务就应该操作特定的某个数据库中的某个表. 最多就是操作某个数据库上的某几张表, 跨库本身就是一个不好的实践.")]),_._v(" "),v("p",[_._v("所以可以从公司规范上直接禁用了跨库事务.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司是直接禁止跨库事务. 所以在分库分表之后要做的就是改造业务代码, 确保不会出现跨库事务.")])]),_._v(" "),v("p",[_._v("但是这样又有点太牵强了, 那么接下来就可以补充说明如果真的要使用跨库事务, 可以怎么解决, 也就是把话题引导到"),v("strong",[_._v("延迟事务")]),_._v("这个方案方案上.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-延迟事务"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-延迟事务"}},[_._v("#")]),_._v(" 亮点方案:延迟事务")]),_._v(" "),v("p",[_._v("这算是分库分表中间件经常采用的方案. 从理论上来说这个方案其实并不比 SAGA 复杂, 但是 TCC, SAGA 和 AT 属于烂大街的答案, 你拉不开差距, 而延迟事务可以.")]),_._v(" "),v("p",[_._v("在分库分表中间件眼里, "),v("strong",[_._v("当执行 Begin 的时候, 它是无法预测接下来会在哪些数据库上面开启事务")]),_._v("的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/840fc823ddd3d576651beacdb1761b87-20250116210757-cu5m3zo.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("比如, 在同一个场景下, 某个请求过来, 处理的时候在分库分表中间件上调用了 Begin 方法, 这个请求最终在 user_db_0 和 user_db_1 上开启了事务; 但是另外一个请求过来, 因为参数不同, 它可能最终在 user_db_2 上开启了事务.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c205c41113b148080290632e8b6218c3-20250116210757-d3linq2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以中间件只有两个选择, "),v("strong",[_._v("要么在 Begin 的时候就在全部数据库上开启事务, 要么就是延迟到执行具体 SQL 的时候, 知道要在哪些数据库上执行, 再去开启事务")]),_._v(".")]),_._v(" "),v("p",[_._v("而在 Begin 的时候就直接开启事务过于粗暴, 毕竟后面有些 DB 根本不会有任何查询.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2a970e9bea5a32d3ae4ef482f609a348-20250116210757-yorbp3e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此, 延迟事务应用更加广泛, 它可以避免在用不上的数据库上开启事务的问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b75a73a5498dfba73144786d3c1e497e-20250116210757-y98zz7u.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这时候, 就可以对比 "),v("strong",[_._v("全开事务")]),_._v(" 和 "),v("strong",[_._v("延迟事务")]),_._v(" 这两种思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("默认情况下, 使用的是延迟事务. 在正常的情况下, 当执行 Begin 的时候, 其实并不知道后续事务里面的查询会命中哪些数据库和数据表, 那么只有两个选择, 要么 Begin 的时候在所有的分库上都开启事务. 但是这会浪费一些资源, 毕竟事务不太可能操作所有的库, 因此才有了延迟事务. 也就是在 Begin 的时候, 分库分表中间件并没有真的开启事务, 而是直到执行 SQL 的时候, 才在目标数据库上开启事务.")]),_._v(" "),v("p",[_._v("举例来说, 如果 SQL 命中了数据库 db_0, 这个时候 db_0 还没有开始事务, 那么就会直接开启事务, 然后执行 SQL; 如果又来了一个 SQL, 再次命中了 db_0, 此时 db_0 上已经开启了事务, 因此直接使用已有的事务. 在提交或者回滚的时候, 就提交或者回滚所有开启的事务. 不过提交或者回滚的时候, 部分失败的问题比较难以解决.")])]),_._v(" "),v("p",[_._v("这里故意提到了部分失败的问题, 是为了引导面试官进一步问. 所谓"),v("strong",[_._v("部分失败是指在 COMMIT 的时候, 某些数据库 COMMIT 成功了, 但是另外一些数据库 COMMIT 失败了怎么办")]),_._v("? 当然, 回滚也有类似的问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7dcb91a998c9dc0c67c6f2bdee18d4d5-20250116210757-4ctn3qa.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("其实这里没有完美的解决方案, 只能"),v("mark",[v("strong",[_._v("考虑重试")])]),_._v(", 类似于在讨论 TCC, SAGA 和 AT 的时候那样.")]),_._v(" "),v("blockquote",[v("p",[_._v("部分失败并没有更好的解决办法. 这里就是在 Commit 的时候, 如果发现某个数据库失败了, 那么会立刻发起重试. 如果连续重试失败, 就会触发告警, 人工介入处理.")])]),_._v(" "),v("p",[_._v("这里再给出一个处理重试失败的高级方案. 可以用在高可用微服务架构里面提到的"),v("strong",[_._v("自动故障处理机制")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在重试失败的时候, 最开始我们公司就是告警, 然后人手工介入处理. 后来我改进了这个机制, 引入了自动故障处理机制. 也就是说如果一个事务里面部分数据库提交或者回滚失败, 触发告警, 然后自动故障处理机制就会根据告警的上下文来修复数据.")]),_._v(" "),v("p",[_._v("修复数据本身分成两种, 一种是用已经提交的数据库的数据来修复没有提交成功的数据库的数据; 另外一种则是用没有提交成功的数据库的数据来还原已经提交的数据库的数据. 具体采用哪种, 根据业务来决定.")]),_._v(" "),v("p",[_._v("在我引入这个机制之后, 很多业务都接入了自己的自动修复逻辑, 整体上数据出错之后的持续时间和出错本身的比率都大幅度下降了, 系统可用性提升到了三个九.")])]),_._v(" "),v("p",[_._v("实际上, 这种"),v("strong",[_._v("自动修复的逻辑是跟业务强相关")]),_._v("的, 所以可以提供一些简单的通用处理机制, 但是如果比较复杂的话, 就需要业务方来控制如何修复了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9db2481dc2ec4726e77ccf2344e4ed2f-20250116210757-6fr6oqz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"重试方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#重试方案"}},[_._v("#")]),_._v(" 重试方案")]),_._v(" "),v("p",[_._v("设计一个重试方案要考虑 3 个方面的内容.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("重试次数")]),_._v(": 一般来说设置无限重试是没有多大意义的. 如果一个东西重试很多次都没有成功, 说明大概率永远没办法重试成功了.")]),_._v(" "),v("li",[v("strong",[_._v("重试间隔")]),_._v(": 无非是等间隔重试或者指数退避重试. 指数退避重试是指重试间隔的时间是在增长的, 一般是按照两倍增长. 当然面试的时候可以设计一些更加灵活的重试间隔策略, 比如说最开始按照两倍增长, 再按照 50% 增长, 最后保持最大重试间隔不断重试.")]),_._v(" "),v("li",[v("strong",[_._v("是否允许跨进程重试")]),_._v(": 如果本身在 A 进程里面触发了重试, 但是在重试了一次之后, 是否可以在 B 进程上重试第二次? 在分布式环境下, 这往往意味着"),v("strong",[_._v("是否可以在不同的机器上重试")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fc6011a9757bb4e429d882627a770492-20250116210757-08n2zod.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从理论上来说, "),v("strong",[_._v("重试就是为了避开前一次失败的原因")]),_._v(". 比如说数据库因为偶发的网络抖动失败了, 那么重试就是希望能够避开这次偶发性的网络抖动, 再次查询成功. 有些时候面试官可能会问为什么要设计指数退避的重试策略, 道理也在于此. 通过不断延长重试间隔时间, 有更大的概率避开引发失败的因素.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-17"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-17"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节需要掌握 "),v("strong",[_._v("两阶段提交协议, 三阶段提交协议和 XA 协议的基本步骤这几个重要的知识点")]),_._v(". 到分布式事务的具体解决方案上, 如果是跨服务的分布式事务, 那么可以考虑 "),v("strong",[_._v("TCC, SAGA 和 AT")]),_._v(". 在回答的时候尤其要注意"),v("strong",[_._v("讨论容错部分")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("容错基本上就是重试, 重试失败之后就有三种方案")]),_._v(", 分别是:")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("监控+告警 + 人手工介入处理")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("读请求 + 数据修复")]),_._v(";")]),_._v(" "),v("li",[v("strong",[_._v("监控 + 告警 + 故障自动处理")]),_._v(".")])]),_._v(" "),v("p",[_._v("如果是单纯的分库分表跨库事务, 那么可以考虑延迟事务, 同时它也是亮点方案.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cba3889e193ffe72a714bcf7e0368d47-20250116210757-je1s3qs.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("此外, 这一节又演示了一个面试小技巧, 就是"),v("strong",[_._v("顺着面试官的立场回答")]),_._v(". 在技术领域, 并不是所有答案都有对错之分, 有一些是立场之分, 偏好之分. 如果摸不清面试官的偏向, 就按照自己的本心回答. 如果回答面试官不满意, 也就是你的偏向和他的偏向不一致, 他一路杠到底, 你就直接认怂.")]),_._v(" "),v("p",[_._v("不太建议和面试官杠到底, 毕竟你出去面试, 遇到一个什么样的面试官是未知数, 而人往往喜欢和自己相似的人. 你也不用觉得丢人, 毕竟面试求职生存下来是王道, 挣钱嘛, 不寒碜.")]),_._v(" "),v("h5",{attrs:{id:"思考题-16"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-16"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后思考 2 个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在 XA 事务里面, 我提到了一个有点争议的点, 即 XA 究竟算不算满足了 ACID, 你是怎么看这个问题的? 欢迎你分享自己的观点.")]),_._v(" "),v("li",[_._v("在分布式事务里面, 我提到了三种容错措施, 你还有没有使用过别的容错方案? 可以分享一下.")])]),_._v(" "),v("h4",{attrs:{id:"_19-分库分表无分库分表键查询-你按照买家分库分表-那我卖家怎么查"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_19-分库分表无分库分表键查询-你按照买家分库分表-那我卖家怎么查"}},[_._v("#")]),_._v(" 19-分库分表无分库分表键查询:你按照买家分库分表,那我卖家怎么查?")]),_._v(" "),v("p",[_._v("今天来聊一聊分库分表下的一种特殊的查询-"),v("strong",[_._v("无分库分表键查询")]),_._v(".")]),_._v(" "),v("p",[_._v("在很多业务里面, 分库分表键都是根据主要查询筛选出来的. 那么就会有这样一个问题, 那些不怎么重要的查询怎么解决呢?")]),_._v(" "),v("p",[_._v("比如说"),v("strong",[_._v("大多数电商的订单都是按照买家 ID 来进行分库分表的, 那么商家该怎么查询订单呢? 又或者买家找客服, 客服要找到对应的订单, 又该怎么找")]),_._v("? 在面试分库分表的过程中, 这也算是一个常见的问题.")]),_._v(" "),v("p",[_._v("如果对分库分表不是很熟悉, 可能根本想不到这里面会有什么难点. 那么今天就看看怎么解决这个问题, 以及如何将多个解决方案整合在一起打造一个复杂的亮点方案.")]),_._v(" "),v("h5",{attrs:{id:"分库分表键选择"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表键选择"}},[_._v("#")]),_._v(" 分库分表键选择")]),_._v(" "),v("p",[v("strong",[_._v("分库分表键是指选择进行分库分表的业务字段, 有些时候会有多个字段")]),_._v(". 那怎么选择合适的字段呢?")]),_._v(" "),v("p",[_._v("一句话: "),v("mark",[v("strong",[_._v("根据查询来选择")])]),_._v(". 例如在订单里面, 最常见的是按照买家进行分库分表. 理由很简单, 买家查询自己的订单是最主要的场景. 既然买家查得多, 买家的服务体验也更加重要, 所以选择买家 ID 进行分库分表收益最大.")]),_._v(" "),v("p",[_._v("可以看到这个完全是业务驱动的. 最常用的分库分表键有主键, 外键, 索引列. 如果是范围分库分表, 那么日期类型的列也很常用.")]),_._v(" "),v("p",[_._v("有些人喜欢把分库分表键的选择说得仿佛非常艰难, 实践中根本不是这样的, 因为事实上根本没有多少个候选项. 再结合业务, 很快就能选出合适的分库分表键.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-19"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-19"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要在公司内搞清楚以下情况.")]),_._v(" "),v("ul",[v("li",[_._v("分库分表的主键生成策略, 主要看看他们有没有使用在 "),v("strong",[_._v("主键生成")]),_._v(" 那一节提到的内嵌分库分表键的方案.")]),_._v(" "),v("li",[_._v("如果使用了后续提到的引入中间表, 二次分库分表和使用其他中间件支持查询中的任何一个方案, 就要搞清楚数据同步是怎么做的, 怎么保证数据一致性. 换句话说, 如果数据不一致, 那么多久会发现, 以及最终要多久才能达成一致.")])]),_._v(" "),v("p",[_._v("当在简历里面提到了分库分表的时候, 可以主动提起你是如何解决这个问题的. 又或者在谈分库分表方案设计的时候, 主动提起方案是如何解决这个问题的.")]),_._v(" "),v("p",[_._v("如果面试官问到了下面这些问题, 那么就可以把话题引导到这个主题下面.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("面试官问到了主键生成策略, 那么可以说主键生成会影响分库分表的中间表设计")]),_._v(".")]),_._v(" "),v("li",[_._v("面试官问到了从其他维度怎么查询数据的问题. 例如在订单这里问到了客服怎么查, 运营怎么查等.")]),_._v(" "),v("li",[_._v("面试官问到了"),v("strong",[_._v("数据同步和数据一致性")]),_._v(", 可以用这里面谈到的场景来展示你是如何解决这些问题的.")]),_._v(" "),v("li",[_._v("面试官问到了"),v("strong",[_._v("如何选择合适的分库分表键")]),_._v(", 那么就可以强调非分库分表键的查询更加复杂, 需要额外的支持.")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-14"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-14"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("正常情况下, 面试官都是直接问类似的问题, 比如说介绍了你的分库分表方案, 提到了订单表是按照买家 ID 来进行分库分表的之后, 他就会顺势问你"),v("strong",[_._v("如果卖家要查询 ID 应该怎么办")]),_._v(".")]),_._v(" "),v("p",[_._v("那么可以按照这个模板来介绍不同的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("这一类没有按照分库分表键来筛选数据的查询, 是需要一些额外的手段来支持的. 目前来说主流的就是"),v("mark",[_._v("引入中间表, 二次分库分表或者使用其他中间件")]),_._v(". 当然, 广播作为一个兜底的解决方案, 逼不得已的时候也可以使用. 并且, 如果自己的主键生成策略比较特殊的话, 也能部分支持这一类查询.")])]),_._v(" "),v("p",[_._v("这个回答里面已经提到了足够的关键词, 那么面试官可能就会按照这个关键词一个一个地问.")]),_._v(" "),v("h6",{attrs:{id:"主键生成策略"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主键生成策略"}},[_._v("#")]),_._v(" 主键生成策略")]),_._v(" "),v("p",[_._v("在主键生成那部分介绍过一种策略, 就是"),v("mark",[v("strong",[_._v("在主键里面带上分库分表的列")])]),_._v(", 如果能够拿到主键, 就应该知道去哪个数据库上的哪个数据表里面查找.")]),_._v(" "),v("p",[_._v("比如在订单 ID 里面带上了买家 ID, 那么在根据订单 ID 来查询数据的时候, 就可以通过解析订单 ID 来判断订单的数据在哪个库哪个表上面.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/207de6a6c830aa26681310baee2ba40a-20250116210757-yks49l7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这是一种"),v("strong",[_._v("非常优雅的解决方案, 因为它完全不需要任何第三方工具的帮助, 也不需要额外存储数据")]),_._v(".")]),_._v(" "),v("p",[_._v("但是 ID 这个方案只能解决一部分问题, 而且大多数时候主键都不是采用这种策略来生成的, 那么就只能考虑其他方案了, 比如说引入中间表.")]),_._v(" "),v("h6",{attrs:{id:"引入中间表-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#引入中间表-2"}},[_._v("#")]),_._v(" 引入中间表")]),_._v(" "),v("p",[_._v("引入中间表这个思路在上一节的分页查询里面已经见过了. 那么在这里, 依旧可以继续"),v("strong",[_._v("引入中间表")]),_._v(". 在前面的例子里面, 你想要支持按照卖家来搜索, 那么完全可以引入一个中间表, 这个中间表记录了 ID, 卖家 ID, 买家 ID 三个数据.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e6976b831cdfe4fd72f9b210ab45482c-20250116210757-5suq9vu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然可以考虑将买家 ID 换成目标库和目标表, 这样就不用再根据买家 ID 来定位目标库和目标表了.")]),_._v(" "),v("p",[_._v("所以查询的基本步骤也很清晰.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("先在中间表中根据卖家 ID 找到想要的订单 ID 和买家 ID")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("再根据买家 ID 和订单号找到具体的订单数据")]),_._v(".")])]),_._v(" "),v("p",[_._v("抓住关键词"),v("strong",[_._v("中间表")]),_._v(", 来介绍你的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们用了一个比较简单的方案, 就是引入了中间表来解决卖家查询的问题. 这个中间表主要就是根据卖家找到对应的订单, 并且根据订单表中的买家 ID 来确定目标库, 目标表, 再去对应的数据表里把所有的数据都查询出来.")])]),_._v(" "),v("p",[_._v("在介绍了这个基本方案之后, 可以从两个角度刷一下亮点. "),v("strong",[_._v("第一个角度是结合第一个主键生成策略, 优化中间表的设计")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("如果在设计订单主键的时候, 将买家 ID 编码放到了订单 ID 里面, 那么在这里可以考虑删掉买家 ID 列.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/64a1a55bf8819993f98b8841e6ddc837-20250116210757-sxrqr09.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果前面已经聊到了主键内嵌分库分表键的方案, 那么在这里展示亮点就非常合适. 或者也可以反过来在主键生成面试的时候提到它会间接影响中间表的设计.")]),_._v(" "),v("p",[_._v("第二个角度是讨论中间表的缺陷, 它最大的缺陷是"),v("strong",[_._v("性能瓶颈")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案的一个重大缺陷是"),v("mark",[_._v("中间表就是性能瓶颈")]),_._v(". 如果中间表的数据只插入, 不存在更新的话, 主要就是读瓶颈, 那么多加几个从库就可以了. 但是如果中间表里面有一些列是需要频繁被更新的, 那么中间表本身就扛不住写压力. 但是本身中间表是不能分库分表的, 因为分库分表之后又面临同样的问题: 你怎么知道该查询哪张中间表.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a51fe817691ae671fa28127f59da1663-20250116210757-pt4xnfp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("中间表最让人害怕的是写瓶颈")]),_._v(", 所以可以考虑提供一个解决方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("一般来说, 在设计中间表的时候应该包含尽可能少的列, 而且这些列的值应该尽可能不变, 会频繁更新的列就不要放了. 类似于订单 ID 这种 ID 类的基本不会变, 那就可以随便放, 而状态这种经常变更就还是不要放了.")])]),_._v(" "),v("p",[_._v("中间表还有两个明显的缺陷, 一个是"),v("strong",[_._v("难以适应灵活多变的查询场景")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("中间表的一个缺陷就是表结构很固定, 如果将来需要支持新的查询场景, 那么就必须修改中间表的表结构, 大多数情况下会是增加新的列. 但是另外一方面, 中间表本身往往又是一个大表, 大表修改表结构是一个非常危险的事情. 当然也可以考虑增加新的中间表, 但都是治标不治本. 中间表越多越难维护, 数据一致性越难保证.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1b2abafc2b73923eed46152f9d06d5c1-20250116210757-pi5bsk1.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这个回答里面, 又提到了大表修改表结构这个点, 前面讲过这个内容, 需要做好被问的准备. 另外一个缺陷就是上一段回答里面最后提到的数据一致性问题, 那么可以参考总结部分.")]),_._v(" "),v("p",[_._v("如果进一步思考, "),v("strong",[_._v("中间表要想解决写瓶颈问题, 是不是也可以分库分表")]),_._v("? 这种思路实际上是下一个方案, 二次分库分表.")]),_._v(" "),v("h6",{attrs:{id:"二次分库分表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#二次分库分表"}},[_._v("#")]),_._v(" 二次分库分表")]),_._v(" "),v("p",[_._v("二次分库分表指复制出来一份数据, 然后尝试再进行分库分表. 所以系统里面就会有两份数据, 分别按照不同的分库分表规则存储.")]),_._v(" "),v("p",[_._v("不同的人会有不同的叫法, 比如说也有人把它叫做冗余分库分表, 冗余 sharding, 但是指的都是这个方案. 比如说, 卖家也需要查询订单, 那么就可以"),v("strong",[_._v("再一次按照卖家 ID 来进行分库分表")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b36de7b34e716f04f6bd01f2b3fbfd21-20250116210757-o3q12j1.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("原本订单表是按照买家的 ID 来进行的, 但是这种情况下, 卖家查询订单就很困难. 比如说卖家查询自己当日成交的订单量, 就难以支持. 而且本身卖家查询订单也不能算是一个低频行为, 所以我尝试把数据复制了一份出去, 然后按照卖家 ID 进行分库分表. 这种方案的主要缺陷就是数据一致性问题, 以及数据复制一份需要很多存储空间.")])]),_._v(" "),v("p",[_._v("在这里提到的两个缺点, 自然是为了进一步展示亮点的. 这里重点讲第二个缺点, 第一个缺陷数据一致性可以参考后面的小结部分.")]),_._v(" "),v("p",[_._v("数据复制一份的问题要解决起来也很简单: 其实没必要全部复制一遍, "),v("strong",[_._v("只需要复制关键表以及关键表的关键字段就可以了")]),_._v(". 部分表是不需要复制的, 比如订单详情表完全不需要复制, 可以在拿到订单 ID 之后再次查询订单详情表.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f61668d2c0f8ed9037ae2e706f062108-20250116210757-kimd5dk.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("即便"),v("strong",[_._v("复制表, 也不是所有的字段都需要复制")]),_._v(", 一些 BLOB, TEXT 字段占存储, 还不会出现在查询条件里面, 根本不需要复制. 真需要这些字段的时候, 依旧可以拿着主键和分库分表键来二次查询.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/633df3becce4a073c5de5b171bb7f094-20250116210757-3sacsgu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("于是查询也分成了两个步骤. 但不同的是, 尽量做到大部分查询只需要查询卖家库, 只有少部分查询需要回归到买家库.")]),_._v(" "),v("p",[_._v("所以要抓住 "),v("strong",[_._v("减轻存储压力")]),_._v(" 这个关键词.")]),_._v(" "),v("blockquote",[v("p",[_._v("实际上, 为了减轻数据复制带来的存储压力, 可以考虑只复制一部分表, 或者某个表的一部分字段. 比如在同步的时候, 就不需要同步订单详情表, 而是拿到订单基本信息之后再去原本的买家库里面查询订单详情.")])]),_._v(" "),v("p",[_._v("在这里可以进一步讨论两次查询引入的问题, 以及可行的优化方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("在这种机制之下, 如果有一个查询 QPS 比较高, 但是它又经常需要回原表查询, 那么可以考虑两个优化方案. 首先要考虑的是在查询的 SELECT 部分去除一些用不上的列, 避免回原表. 如果这个措施不行, 那么就考虑将查询所需的列全部复制过去, 避免回原表. 这种优化就类似平时用覆盖索引来优化查询的思路.")])]),_._v(" "),v("h6",{attrs:{id:"使用其他中间件支持查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#使用其他中间件支持查询"}},[_._v("#")]),_._v(" 使用其他中间件支持查询")]),_._v(" "),v("p",[_._v("前面三种策略, 始终存在一些缺陷, 就是它们都难以适应变幻莫测的业务. 比如, 在引入中间表里我已经提到了, 中间表里面就必须包含你的查询条件, 不然你也查不出来. 如果业务变化了, 需要新的查询, 那么你也需要修改表结构. 因此, 为了支持复杂多样的查询, 可以尝试使用别的中间件, 比如说 "),v("strong",[_._v("Elasticsearch")]),_._v(". 在这里引入 Elasticsearch 也可以采用引入中间件方案中的一个优化措施, 即只同步部分跟搜索相关的字段.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了减轻 Elasticsearch 的压力, 我们选择了只同步部分字段. 一些非常庞大的字段, 比如说 TEXT 或者 BLOB 本身我们是不会同步过去的.")])]),_._v(" "),v("p",[_._v("如果选了同步部分数据到 Elasticsearch, 那么最终就会面临一个问题: "),v("strong",[_._v("总有一些业务的查询, 你完全没办法支持")]),_._v(". 那这个时候就只剩下最后一个手段了: "),v("strong",[_._v("广播")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"广播"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#广播"}},[_._v("#")]),_._v(" 广播")]),_._v(" "),v("p",[_._v("所谓的广播就是, 如果不能断定数据可能出现在哪一张表上, 那么就直接在全部表上"),v("strong",[_._v("都查询一遍")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/56ebaf7afe4770e2fd0ee875251eb939-20250116210757-e2lgmke.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在订单这个例子里面, 当卖家想要知道自己究竟卖了多少单的时候, 就可以在所有的表上都问一遍, 汇总之后就是卖家的所有订单.")]),_._v(" "),v("p",[_._v("你基本上一眼就可以看出来这种做法的缺陷: "),v("strong",[_._v("对数据库的压力实在太大")]),_._v(". 这个方案现实中真的"),v("strong",[_._v("很少用")]),_._v(", 只有在上面这些方案都用不了的时候, 才可以考虑使用, 关键词"),v("strong",[_._v("兜底")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("还有一些兜底措施, 也就是如果一个查询确实没办法使用前面那些方案的时候, 那就可以考虑使用广播. 也就是说直接把所有的请求发送到所有的候选节点里面, 然后收集到的数据就是查询的结果. 不过这种方式的缺陷就是对数据库压力很大, 很多数据库上的表根本不可能有数据, 但是都会收到请求, 白白浪费资源. 尤其是如果这些查询还会触发锁, 那么性能就会更差.")])]),_._v(" "),v("p",[_._v("最后你特意强调了锁, 也是为了把话题引到锁那边.")]),_._v(" "),v("h5",{attrs:{id:"引入中间表和二次分库分表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#引入中间表和二次分库分表"}},[_._v("#")]),_._v(" 引入中间表和二次分库分表")]),_._v(" "),v("p",[_._v("实际上, 也可以认为这两种方案之间的差距并不大, 或者说二次分库分表是中间表的升级加强版.")]),_._v(" "),v("ul",[v("li",[_._v("中间表是性能瓶颈, 害怕维护写频繁的字段. 二次分库分表没有这种担忧.")]),_._v(" "),v("li",[_._v("中间表本身的字段会很少, 往往需要回归原表再次查询数据.")]),_._v(" "),v("li",[_._v("二次分库分表成本要更高, 因为它需要复制更多的字段.")])]),_._v(" "),v("p",[_._v("一般来说, "),v("strong",[_._v("优先考虑使用中间表, 其次考虑只复制部分数据的二次分库分表方案")]),_._v(", 逼得不得已再考虑全量复制数据的二次分库分表方案.")]),_._v(" "),v("h5",{attrs:{id:"数据同步问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据同步问题"}},[_._v("#")]),_._v(" 数据同步问题")]),_._v(" "),v("p",[_._v("在引入中间表, 二次分库分表和使用其他中间件三个解决方案里面, 都面临一个同样的问题: "),v("strong",[_._v("怎么进行数据同步")]),_._v("?")]),_._v(" "),v("ul",[v("li",[_._v("在中间表里面是怎么把数据从业务表同步到中间表.")]),_._v(" "),v("li",[_._v("在二次分库分表里面是怎么把数据同步到二次分库分表.")]),_._v(" "),v("li",[_._v("在使用其他中间件里面是怎么把数据同步到选择的中间件.")])]),_._v(" "),v("p",[_._v("数据同步之前介绍过一些方案, 一般来说有两种思路.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("双写, 就是在写入源数据表的时候, 同时写到另外一个地方")]),_._v(". 这个可以通过改造 ORM 或者分库分表中间件来达成. 但是如果分库分表中间件是 Proxy 形态或者 Sidecar 形态的, 那么改起来的难度就比较大.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d05c9c3a949f4648d5d5906061b3fdb5-20250116210757-3f68bv5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[v("strong",[_._v("利用 Canal 之类的框架监听 binlog, 然后异步地把数据库同步到其他地方")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5b0959c3a9ef4c01b80395eb152d8aa9-20250116210757-x411goc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不管是双写, 还是监控 binlog, 都绕不开失败这个话题. "),v("mark",[v("strong",[_._v("那失败的时候怎么办呢? 无非就是各种重试, 在重试都失败之后, 就人手工介入处理")])]),_._v(".")]),_._v(" "),v("p",[_._v("在实践中, 双写方案用得不多. 高端一点的做法就是在重试失败之后, 加上一个异步修复程序进一步尝试修复. 如果修复程序本身也失败了, 那确确实实就只能人手工介入了. 这些内容之前反复提到过.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-11"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-11"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这是一个结合了在基本思路中提到的四种措施的综合方案. 这个方案就凸显你考虑到了不同的情况, 做出了一个比较复杂的架构设计.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9960a5e46766be87f4ca9d37ae142ee6-20250116210757-vvi7uz3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以综合介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("在分库分表之后, 为了充分满足不同情况下的查询需求, 我们公司综合使用了三种方案: 引入中间表, 二次分库分表和 Elasticsearch. 对于卖家查询来说, 我们直接复制了一份数据, 按照卖家 ID 分库分表. 对于一些复杂的查询来说, 就是利用 Elasticsearch. 还有一些查询是通过建立中间表来满足, 比如说商品 ID 和订单 ID 的映射关系.")])]),_._v(" "),v("p",[_._v("因为在回答里面提到了不同的做法, 那么面试官就会进一步问这些方案的细节, 回答在基本思路里面讲到的就可以了, 要注意将每一个方案里面的亮点展示出来.")]),_._v(" "),v("p",[_._v("如果面试官问到了数据同步和数据一致性的问题, 那么就介绍同步方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们的数据同步方案是"),v("mark",[_._v("使用监听 binlog 的方案")]),_._v(". 买家库插入数据之后, 就会同步一份到卖家库和 Elasticsearch 上. 这个过程是有可能失败的, 那么在失败之后会有重试机制, 如果重试都失败了, 那么就只能人手工介入处理了.")])]),_._v(" "),v("p",[_._v("如果面试官足够敏锐的话, 他就会发现这个架构里面的另外一个问题: "),v("strong",[_._v("卖家库的数据需要反向同步到买家库吗")]),_._v("?")]),_._v(" "),v("p",[_._v("第一个回答是如果允许卖家修改卖家库的数据, 那就需要. 架构这个时候就变成了图里展示的这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0d074b0c6ce7ca4e01dbda32ccb1ee6d-20250116210757-gm5ub4q.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("我们是允许卖家直接修改数据的, 所以实际上卖家库的修改也会同步到其他数据源. 因为卖家和买家都可能同时修改各自的库. 这里举一个订单状态修改的例子.")]),_._v(" "),v("p",[_._v("如果买家发起取消订单, 然后卖家那边要把状态修改成已发货. 那么可能出现买家先修改, 然后被卖家覆盖的情况, 结果就是两边都是已发货; 也有可能出现卖家先修改, 然后被买家覆盖的情况, 那么结果就是两边都是已取消.")]),_._v(" "),v("p",[v("mark",[_._v("所以类似的场景最好是采用分布式锁和双写方案")]),_._v(". 比如买家修改状态的时候, 要先拿到分布式锁, 然后同时修改买家库和卖家库. 当然, 要是覆盖数据也没关系, 那么就还是可以继续采用 Canal 的同步方案.")]),_._v(" "),v("p",[_._v("所以综合来看, 允许卖家直接修改卖家库是比较危险的事情, 数据一致性问题更加严重.")])]),_._v(" "),v("p",[_._v("最后一句话提到了数据一致性问题更加严重, 这也是为了引出第二个回答, 就是除了买家库, 其他库都是只读的.")]),_._v(" "),v("blockquote",[v("p",[_._v("也可以考虑"),v("mark",[_._v("只允许从买家库进去修改数据")]),_._v(", 也就是不允许直接修改卖家库的数据. 举个例子, 如果卖家想要修改某个订单的数据, 那么他需要在卖家库查到订单的信息, 但是在修改的时候要拿着订单信息去买家库修改.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73184a142d1ab0c0220544a6201d1281-20250116210757-xkf0tx8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后总结这种做法的好处.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种做法最大的优点就是简单, 没有那么多数据同步和数据一致性方面的问题. 缺点就是性能比较差, 而且写压力始终都在买家库上.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-18"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-18"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下无分库分表键查询的面试要点.")]),_._v(" "),v("ol",[v("li",[_._v("分库分表键的选择要"),v("strong",[_._v("注意根据候选项和业务需求来筛选")]),_._v(", 这在实践中比较容易.")]),_._v(" "),v("li",[_._v("在设计一个重试方案时要"),v("strong",[_._v("考虑重试次数, 重试间隔以及是否允许跨进程重试")]),_._v("这三方面内容.")]),_._v(" "),v("li",[_._v("此外还讨论了引入中间表, 二次分库分表, 使用其他中间件三个基础方案. 并且讨论了主键生成策略对查询的影响, 以及对中间表, 二次分库分表两个方案的影响.")]),_._v(" "),v("li",[_._v("广播则是兜底方案, 也就是说如果什么都不做, 那么解决非分库分表键查询就可以依赖广播, 但是它的性能问题也是非常突出的.")])]),_._v(" "),v("p",[_._v("最后综合了所有方案给出了一个比较复杂的架构设计. 正常来说, 如果面试初中级研发岗位, 你应该只是负责整个架构中的某一环节. 那么能说清楚整个架构就是一个比较不错的加分项. 如果你已经在大厂了, 那么你可以用你所在公司的架构来替换.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/aa893affb4b79c52b4ac342092dac84a-20250116210757-7mob1cs.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-17"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-17"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("要想做到允许跨进程重试, 一般都要借助第三方中间件来完成. 比如说消息队列, 分布式任务调度等. 那么你是如何实现跨进程重试的?")]),_._v(" "),v("li",[_._v("在讲到允许卖家修改卖家库再同步回买家库的时候, 我说到两种覆盖的场景, 那么有没有可能出现买家库是已发货, 但是卖家库反而是已取消的情况?")])]),_._v(" "),v("h4",{attrs:{id:"_20-分库分表容量预估-分库分表的时候怎么计算需要多少个库多少个表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_20-分库分表容量预估-分库分表的时候怎么计算需要多少个库多少个表"}},[_._v("#")]),_._v(" 20-分库分表容量预估:分库分表的时候怎么计算需要多少个库多少个表?")]),_._v(" "),v("p",[_._v("今天来聊一下分库分表中确定容量的问题.")]),_._v(" "),v("p",[_._v("在分库分表的面试中, 基本上面试官都会问你, 你究竟分了几个库分了几个表. 这是因为面试官比较关注数据库的数据量问题, "),v("strong",[_._v("如果容量预估不准确, 那么后续就需要扩容, 而扩容是一个非常麻烦和棘手的事情")]),_._v(".")]),_._v(" "),v("p",[_._v("大部分人在准备面试的时候很少深入思考这个容量是怎么来的, 因此面试官问到的时候就是一脸懵. 那么今天就深入讨论一下怎么计算分库分表的容量, 并教你利用扩容展示自身的能力, 尤其是后面会提到的"),v("strong",[_._v("利用流量复制和重放来做数据校验")]),_._v(", 是一个非常高级的技巧, 足以证明你在系统设计上有丰富的经验了.")]),_._v(" "),v("p",[_._v("先从分区表说起.")]),_._v(" "),v("h5",{attrs:{id:"分区表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区表"}},[_._v("#")]),_._v(" 分区表")]),_._v(" "),v("p",[_._v("大部分数据库都支持分区表. 这里以 MySQL 为例介绍一下分区表的主要特性.")]),_._v(" "),v("p",[_._v("在 MySQL 里, 分区表是表的底层组织方式. 简单来说, 分区表就是把一张表分成几块, 每一块存储在磁盘的一个地方, 一块也叫做一个分区. 比如典型的按月分区, 是指每个月产生的数据在一个独立的区域. 数据库可以单独处理某一块, 也可以多块一起处理.")]),_._v(" "),v("p",[_._v("分区表的优缺点还是非常分明的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/328f7d46c31fd45e9ba55b21f3dc2310-20231223175002-3u51izx.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("虽然分区表的缺点很明显, 但在一些场合, 分区表还是非常好用的, 尤其是一些跟时间有明显关系的业务场景, 按照时间来进行分区要比直接使用分库分表更加简单高效.")]),_._v(" "),v("h5",{attrs:{id:"_2的幂与数据迁移"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2的幂与数据迁移"}},[_._v("#")]),_._v(" 2的幂与数据迁移")]),_._v(" "),v("p",[_._v("如果你平时看过一些大厂发布的分库分表实战, 就可能注意到, 大厂在容量规划的时候都是按照 "),v("strong",[_._v("2 的幂来规划")]),_._v("的, 比如说 4 * 2 * 8, 或者 8 * 4 * 32. 而且在扩容的时候, 也是按照 2 的幂来进行的. 也就是说, 基本上扩容都是选择"),v("strong",[_._v("容量翻倍")]),_._v(". 这其实是因为 2 的特性, 在使用哈希取余来进行分库分表的时候, 可以使用位运算来计算余数, 非常高效.")]),_._v(" "),v("p",[_._v("在扩容的时候, 如果扩容为原来的 2 倍, 那么"),v("strong",[_._v("只需要迁移一半的数据")]),_._v(". 假设原本的表是按照除以 4 的余数(%4)来分库分表的, 分别是 tab_0, tab_1, tab_2, tab_3. 现在扩容成原来的 2 倍, 按照 8 的余数(%8)来分库分表. 那么原本 tab_0 上的数据就需要移走一半.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0c9e4b2ea3257a108960db7acd41c238-20231223175002-rbdgy4s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试准备-20"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-20"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("想要面好分库分表容量预估这个部分, 只了解前面这些知识点还是不够的, 还需要在公司内部弄清楚一些数据.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司"),v("strong",[_._v("分库分表的实际情况")]),_._v(", 也就是分了几个集群, 几个库, 几个表.")]),_._v(" "),v("li",[_._v("你们公司"),v("strong",[_._v("核心业务或者你维护的业务数据库或数据表的数据量, TPS 和 QPS")]),_._v(".")]),_._v(" "),v("li",[_._v("你们公司是否使用过分区表, 分区表是按照什么分区的, 每个分区数据量大概是多少.")])]),_._v(" "),v("p",[_._v("这些数据在面试的时候, 都要趁机讲出来. 现在的人出去面试, 很少有人能够把自己业务的各项数据说清楚, 如果能够说清楚, 本身就是一件有竞争力的事情.")]),_._v(" "),v("p",[_._v("跟容量有关的问题可以称之为夺命连环 call, 面试官会一路问下去.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("为什么要分库分表? 分区表可不可以? 增加从库行不行?")])]),_._v(" "),v("li",[v("strong",[_._v("什么时候需要分库分表")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("分库分表的时候, 是分库还是分表? 还是既分库又分表")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("分多少库? 分多少表? 你是怎么计算出来的")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("万一容量预估得不准, 估少了怎么办")]),_._v("?")])]),_._v(" "),v("p",[_._v("面试过程中, 有些时候问法可能不一样, 但是本质都是一回事, 比如面试官会这样问.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("如果数据库已经到了写瓶颈怎么办? 要么优化写操作, 要么分库")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("如果数据库已经到了读瓶颈怎么办? 要么优化读操作, 要么加从库, 要么分库或分表")]),_._v(".")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-15"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("接下来就顺着面试官的提问思路一个个解答.")]),_._v(" "),v("p",[_._v('面试官问这一类问题的起点差不多都是 "你为什么分库分表?", 比如你的项目经历里有跟数据库有关, 看起来可以用分区表的内容, 那么他就会问 "为什么你要分库分表? 分区表能不能解决问题?"')]),_._v(" "),v("h6",{attrs:{id:"为什么分库分表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么分库分表"}},[_._v("#")]),_._v(" 为什么分库分表?")]),_._v(" "),v("p",[_._v("排除刷 KPI 这种想法, 分库分表只有一个原因, 就是逼不得已了. 在面试的时候分库分表是一个很高端的话题, 但是在实践中, 我一直以来的"),v("strong",[_._v("建议是不到逼不得已不要分库分表")]),_._v(".")]),_._v(" "),v("p",[_._v("那什么情况是逼不得已需要使用分库分表呢? 就是数据库遇到了"),v("strong",[_._v("性能瓶颈")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("一句话总结分库分表, 那就是数据库本身出现了性能问题, 而且这些性能问题已经没办法通过 SQL 优化, 索引优化之类的手段来解决了.")])]),_._v(" "),v("p",[_._v("然后进一步将分库分表和分区表, 读写分离进行对比, 刷一个亮点. 下面"),v("strong",[_._v("从硬件资源, 并发, 数据量")]),_._v("三个引起性能瓶颈的角度去分析.")]),_._v(" "),v("blockquote",[v("p",[_._v("通常在分库分表之前应该优先考虑分区表和读写分离, 因为这两种方案和分库分表比起来都更简单, 好维护.")]),_._v(" "),v("p",[_._v("如果是数据库本身硬件资源不足, 那么不管是分区表还是读写分离都难以解决问题. 比如数据库网络带宽不够了, 这种情况下分区表肯定解决不了; 而如果是写操作引发的网络带宽不够, 那么读写分离增加从库也解决不了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3810aa9d2f26d1c36f137f7f478fd213-20231223175002-wlgrjsv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("如果是并发引起的问题, 那么分区表和读写分离也不太能解决. 比如说表锁, 读写分离是没办法解决的, 就算增加 100 个从库, 表锁都还是在主库上. 分区表虽然因为有分区, 可以减少并发竞争, 但是如果某一个特定分区上已经遇到写瓶颈了, 那么分区表也没用.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/12853cc4eeb1e45de89cb506c72ce523-20231223175002-xhq2jqa.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("如果是单纯因为数据量过大而引起的性能瓶颈, 读写分离也不太能够解决. 举个例子来说, 如果一个表有几千亿条数据, 那么显然无论怎么加从库, 单一一个查询都会很慢. 如果数据量极大, 以至于连索引都无法放入内存, 此时查询性能极差.")])]),_._v(" "),v("p",[_._v("可以记住下面这个简洁版.")]),_._v(" "),v("ul",[v("li",[_._v("对于写瓶颈来说, 分区表可以缓解问题, 而读写分离几乎没有效果, 比如频繁地增删改操作.")]),_._v(" "),v("li",[_._v("对于硬件瓶颈来说, 读写分离, 分区表基本上也解决不了, 比如写操作引发的网络带宽问题.")])]),_._v(" "),v("p",[_._v("最后总结一下, 就是业务已经触及了"),v("strong",[_._v("主库写性能瓶颈")]),_._v(", 走投无路了.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们这个业务数据库逼不得已要分库分表的原因就是主库现在已经不堪重负, 可以认为 TPS 已经触及到硬件天花板了. 虽然理论上还是可以购买更强的服务器来部署数据库实例, 但是实在太贵了, 而且业务增长也还是会触及新机器的性能瓶颈, 那么索性分库分表一步到位. 我们还准备了其他主从集群, 将分库之后的数据库分散在不同的主从集群上, 或者说分了数据源.")])]),_._v(" "),v("p",[_._v("这里还可以进一步指出, "),v("strong",[_._v("分库分表和读写分离, 分区表都不是互斥的, 可以结合在一起使用")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 并不是说分库分表之后就不能使用读写分离. 实际上分库分表的数据库集群一般也是主从集群. 不过分库分表和分区表混合使用的情况比较少, 但理论上也是可行的.")])]),_._v(" "),v("p",[_._v("最后可以拔高一下, 直戳问题的本质, 关键词就是"),v("strong",[_._v("性能瓶颈")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("目前业界有很多公司会出一些最佳实践之类的手册, 告诉你数据量超过多少多少就要分库, 比如行数超过多少行, 或者数据量超过多少 G 就要分表.")]),_._v(" "),v("p",[_._v("但是这些最佳实践其实是一种偷懒的说法, 是我们在日常实践中总结出来的很多表在这么一个量级下就会出现性能瓶颈. 所以归根结底要不要分库分表, 只需要看有没有性能瓶颈.")]),_._v(" "),v("p",[_._v("而且但凡性能瓶颈可以用分区表或者读写分离解决, 就不要着急使用分库分表. 当然, 如果用得起 Oracle 数据库, 那就根本不需要分库分表了.")])]),_._v(" "),v("p",[_._v("到这一步就已经彻底解答了为什么要分库分表的问题. 相信到现在, 你对什么时候分库, 什么时候分表应该心中有数了.")]),_._v(" "),v("h6",{attrs:{id:"分库还是分表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库还是分表"}},[_._v("#")]),_._v(" 分库还是分表?")]),_._v(" "),v("p",[_._v("这里先给出一个适合在面试中回答的"),v("strong",[_._v("三条原则")]),_._v(".")]),_._v(" "),v("ol",[v("li",[_._v("如果是"),v("strong",[_._v("数据库本身的硬件资源引起的性能瓶颈, 那么就要分数据源")]),_._v(". 一句话来说, 就是得有更多的主从集群.")]),_._v(" "),v("li",[_._v("如果是"),v("strong",[_._v("逻辑数据库引起的性能瓶颈")]),_._v(", 那么就只需要在逻辑数据库这个层面进一步分库就可以了.")]),_._v(" "),v("li",[_._v("如果是"),v("strong",[_._v("单表数据量过大, 锁竞争等跟表维度相关的资源引发的性能问题, 那么分表就可以了")]),_._v(".")])]),_._v(" "),v("p",[_._v("确认了要分库, 分表或者同时分库分表之后, 现在就要考虑分几个的问题了.")]),_._v(" "),v("h6",{attrs:{id:"容量估算"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#容量估算"}},[_._v("#")]),_._v(" 容量估算")]),_._v(" "),v("p",[_._v("分库分表容量确定需要依据两点: "),v("strong",[_._v("现在有多少数据, 将来有多少数据")]),_._v(". 所以如果讨论到了容量估算的问题, 就要直接指出核心: "),v("mark",[v("strong",[_._v("现有数据和增长趋势")])]),_._v(". 紧接着就要从这两个点出发解释具体怎么算.")]),_._v(" "),v("blockquote",[v("p",[_._v("存量数据")])]),_._v(" "),v("p",[_._v("存量数据是最好处理的. 基本上只需要简单计算一下就可以得到.")]),_._v(" "),v("p",[_._v("不过并不是所有存量数据都需要进行分库分表, 部分不重要的, 用不上的, 历史悠久的数据, 不如直接归档, 或者放到大数据平台上. 所以真正需要计算的是"),v("strong",[_._v("那些还需要线上继续查询的数据的量")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("增长趋势")])]),_._v(" "),v("p",[_._v("这个就是计算难点, 需要考虑两点, 一个是现有数据增长率, 另一个是数据增长率的变化趋势. 用数学术语来说, 就是"),v("strong",[_._v("数据量的一阶导数和二阶导数")]),_._v(".")]),_._v(" "),v("p",[_._v("那怎么知道数据的增长率, 以及未来数据的增长率呢? 其实这就要"),v("strong",[_._v("看公司的规划了")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("数据的增长趋势只需要根据公司的战略规划来就可以. 比如说今年公司的目标是业务翻倍, 那么就可以认为今年数据的增长率是 100%. 就算公司没有发布这一类的规划, 但是产品经理肯定是背着 KPI 的, 问一下他们也就知道了. 不过正常来说, 一家公司都是有三五年规划的, 照着规划来预估容量就可以了.")])]),_._v(" "),v("p",[_._v("因为扩容非常复杂繁琐, 所以这里可以补充容量预估的原则--宁滥勿缺.")]),_._v(" "),v("blockquote",[v("p",[_._v("大体上, 预估要料敌从宽, 也就是按照业务可能的增长上限来评估. 因为万一容量预估少了, 还需要再扩容, 这就比较麻烦了.")])]),_._v(" "),v("p",[_._v("紧接着, 还有一个可能出现的问题, 就是究竟预估多长时间的数据? 三五年还是十年? 这个问题每个实际操刀分库分表的人答案估计都不一样.")]),_._v(" "),v("p",[_._v("个人认为只需要预估"),v("strong",[_._v("未来三年")]),_._v("就可以. 但是有些公司很有钱同时害怕扩容, 所以一开始可能就留足了余量, 所以可以满足数十年的需要.")]),_._v(" "),v("blockquote",[v("p",[_._v("正常来说, 预估容量需要考虑未来三年的数据增长情况, 只需要确保三年内不会触发扩容就可以. 但是三年也不是一个硬性标准, 比如说有些公司比较害怕扩容, 那么可能直接预估了五年, 十年的容量.")])]),_._v(" "),v("p",[_._v("但这种估计就是一厢情愿, 不管再怎么精打细算最终都有可能估少了. 那么逼不得已就还是要扩容.")]),_._v(" "),v("h5",{attrs:{id:"扩容亮点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#扩容亮点"}},[_._v("#")]),_._v(" 扩容亮点")]),_._v(" "),v("p",[_._v("扩容本质上就是两件事: "),v("strong",[_._v("扩容后的容量评估和数据迁移")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"扩容后的容量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#扩容后的容量"}},[_._v("#")]),_._v(" 扩容后的容量")]),_._v(" "),v("p",[_._v("首先容量评估这个步骤要比初次分库分表简单得多, 基本上都是按照 2 的倍数来进行扩容.")]),_._v(" "),v("blockquote",[v("p",[_._v("就容量评估来说, 因为已经分库分表了, 所以只需要按照已有容量的 2 倍来扩容就可以了. 比如现在是分了 4 个库, 每个库 8 张表, 那么就可以考虑扩容为 8 个库, 每个库 8 张表; 也可以考虑扩容成为 4 个库, 每个库 16 张表. 当然直接扩容到 8 个库, 每个库 16 张表也是可以的.")])]),_._v(" "),v("p",[_._v("这里面留了一个引导点, 就是"),v("strong",[_._v("什么时候扩容库, 什么时候扩容表")]),_._v("? 这个问题可以参考前面 "),v("strong",[_._v("分库还是分表")]),_._v(" 这部分知识来回答, 它们本质上是同一个问题.")]),_._v(" "),v("p",[_._v("有一个问题虽然面试官不太可能会问到, 但还是要有一个心理准备, 就是有没有可能缩容? 比如最开始的时候, 你对业务非常乐观, 认为需要 8 * 16 共 128 张表. 但是后面可能大环境不好, 又或者业务扩张不利, 导致 128 张表的数据量都不多. 自然就会产生这么一种想法, 能不能缩容?")]),_._v(" "),v("p",[_._v("理论上是能缩容的, 但是现在我还没听说哪家公司在分库分表之后又缩容的. 所以如果面试官问到能否缩容, 那么就可以这么回答:")]),_._v(" "),v("blockquote",[v("p",[_._v("理论上是可以的, 而且和扩容差不多, 都是要解决容量问题和数据迁移问题.")])]),_._v(" "),v("h6",{attrs:{id:"数据迁移"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据迁移"}},[_._v("#")]),_._v(" 数据迁移")]),_._v(" "),v("p",[_._v("数据迁移的过程和前面基本一样, 唯一不一样的地方就是"),v("strong",[_._v("不管操作源表还是操作目标表, 都是需要按照分库分表的规则来进行")]),_._v(". 所以基本上可以套用之前的数据迁移方案. 但是这里再额外补充一个更加高级的数据校验方案.")]),_._v(" "),v("p",[_._v("这个校验方案就是"),v("strong",[_._v("流量复制与重放")]),_._v(", 就算你所在的公司没有类似的实践, 也可以跟面试官聊, 因为除了少部分大厂做得还可以, 其他公司基本上都没做过, 或者做得很差.")]),_._v(" "),v("p",[_._v("方案的原理很简单, "),v("strong",[_._v("就是在保持以源表为准的双写阶段, 录制线上的 HTTP 请求, 然后再异步重放")]),_._v(". 拿到原本 HTTP 请求的响应和重放的响应, 做一个比较.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/067bc23a3f511527dea0e7aef662540a-20231223175002-61txbh8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("面试谈到数据校验的时候, 可以介绍一下这个方案, 不过不建议说自己用过这个方案, 因为里面细节比较多, 很容易翻车. 这里用一种设计了这个方案, 但是因为复杂度过高所以没有实施的话术来介绍, 关键词是 "),v("strong",[_._v("流量录制和重放.")])]),_._v(" "),v("blockquote",[v("p",[_._v("在数据校验上, 最开始的时候我设计过一个利用流量录制和重放来做数据校验的方案, 真正从业务逻辑上校验数据的准确性, 完整性和一致性. 整体思路是在 HTTP 入口处引入一个流量复制组件. 当有读请求过来的时候, 就会把请求整体录制下来, 然后异步地重放请求, 再把重放请求的响应和原始响应进行对比, 判断数据迁移有没有出错.")])]),_._v(" "),v("p",[_._v("流量复制和重放一般来说就是使用 tcpcopy 或者 goreplay. 有时间可以去了解一下这两个中间件, 学会如何使用就足够了.")]),_._v(" "),v("p",[_._v("这个数据校验方案有很多可以深挖的地方, 所以可以继续引导.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案还是有比较多的问题, 比如说 HTTPS 的问题, 并发的问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("核心问题1：去除 HTTPS")])]),_._v(" "),v("p",[_._v("第一个问题是要解决流量复制过程中 HTTPS 协议的问题. 那么基本都是在去除了 HTTPS 协议之后才开始录制流量的. 简单来说就是放在了网关后面, 网关会把 HTTPS 协议"),v("strong",[_._v("转成 HTTP 协议")]),_._v(", 这样就可以录制流量了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3f0148033f74d3fc4e679yy304ce42e3-20231223175002-6rh097c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("我这个方案是准备在 Nginx 后面接入流量复制. 用户和 Nginx 之间是 HTTPS 通信, 但是 Nginx 和后面的服务器之间是 HTTP 通信, 所以就可以避开 HTTPS 的问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("核心问题2：并发问题")])]),_._v(" "),v("p",[_._v("这算是一个比较大的亮点, 因为擅长分析并发场景这一点就很有竞争力, 设想这样一个场景.")]),_._v(" "),v("ul",[v("li",[_._v('用户请求 id = 1 的数据, 拿到了响应 name = "小红".')]),_._v(" "),v("li",[_._v('复制请求, 得到数据 id=1, name= "小红".')]),_._v(" "),v("li",[_._v('紧接着, 又来了一个请求, 把 id = 1 的数据 name 更新成了 "小白".')]),_._v(" "),v("li",[_._v('数据同步成功, 扩容后的目标表也更新成 id=1, name= "小白".')]),_._v(" "),v("li",[_._v('重放请求, 最终重放得到的响应是 id=1, name= "小白".')]),_._v(" "),v("li",[_._v("误报数据不一致.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8966167a3ea6db05ecc669a5d5590706-20231223175002-pse8zri.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种就是假阳性问题. 可以看到本身数据是一致的, 但是因为并发问题, 导致校验误报了. 如果还记得前面数据迁移是怎么修复数据的, 那么应该知道这并没有什么影响. 因为修复数据的时候, 永远都是"),v("strong",[_._v("用源表最新的数据去覆盖目标表最新的数据")]),_._v(". 这种假阳性就是白做了修复的工作而已.")]),_._v(" "),v("p",[_._v("你可以进一步打消面试官的疑虑.")]),_._v(" "),v("blockquote",[v("p",[_._v("虽然这里有可能出现假阳性的问题, 不过不足为惧, 因为本身数据是一致的, 而且假阳性很少出现, 因为我们的业务就是一个读多写少的场景. 并且流量也不打算 100% 复制, 只是小比例复制流量就可以了.")])]),_._v(" "),v("p",[_._v("这个流量复制与重放算是一个非常高级也非常难做好的东西, 所以面试的时候大概率面试官是没有接触过类似的技术的, 可以放心说. 面试官没做过就问不出细节, 不太可能把你问倒.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-19"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-19"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节课先学习了 2 的幂在分库分表中的应用和对数据迁移的影响.")]),_._v(" "),v("p",[_._v("后面详细地解释了这几个问题:")]),_._v(" "),v("ol",[v("li",[_._v("为什么分库分表? 这要和分区表, 读写分离对比, 一句话总结就是有一些"),v("strong",[_._v("性能瓶颈只能用分库分表解决")]),_._v(".")]),_._v(" "),v("li",[_._v("分库还是分表? 这就要看"),v("strong",[_._v("性能瓶颈能用分库解决还是能用分表解决. 跟硬件资源相关的分数据源, 跟逻辑数据库相关的分库, 跟数据表相关的就分表")]),_._v(".")]),_._v(" "),v("li",[_._v("容量怎么估算? 这要综合"),v("strong",[_._v("考虑已有数据和数据增长趋势, 然后根据公司的规划来确定容量")]),_._v(".")]),_._v(" "),v("li",[_._v("扩容怎么扩? "),v("strong",[_._v("重新评估容量 + 数据迁移")]),_._v(". 数据迁移里面介绍了一种新的面试思路, 使用流量复制和重放来校验数据.")])]),_._v(" "),v("p",[_._v("这一节最后的流量录制与重放, 在面试的时候是包装成了一个没有实施的方案, 这也算是一个面试技巧. 通过介绍一个高端但是没有实施的方案, 进一步加深面试官对你的印象.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/840ced935905e52937b7yy9535be0728-20231223175002-ie4k7wm.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-18"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-18"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在扩容的时候, 我说 2 的幂翻倍扩容的话, 只需要迁走一半的数据. 如果改成用 3 的幂, 原本你的数据是按照除以 3 的余数分库分表, 现在变成除以 9 的余数分库分表, 那么要迁走多少数据?")]),_._v(" "),v("li",[_._v("网络上有一种说法是超过 2000 万行数据就要分表了, 你知道这个 2000 万是怎么来的吗?")])]),_._v(" "),v("h4",{attrs:{id:"_21-数据库综合应用-怎么保证数据库的高可用和高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_21-数据库综合应用-怎么保证数据库的高可用和高性能"}},[_._v("#")]),_._v(" 21-数据库综合应用:怎么保证数据库的高可用和高性能?")]),_._v(" "),v("p",[_._v("很多人在平时工作中就是设计一下表结构和索引. 好一点的可能还会有一些查询优化的经验, 也有少数人做了很多跟数据库有关的事情, 但是没办法把它们系统组织起来, 给面试官留下深刻印象.")]),_._v(" "),v("p",[_._v("现在有了前面几节的基础之后, 就可以把这些知识串联起来, "),v("strong",[_._v("做成一整个提高数据库性能和可用性的方案")]),_._v(". 在这之前, 为了方便理解后面的方案, 先来学习一下查询缓存相关的知识.")]),_._v(" "),v("h5",{attrs:{id:"查询缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#查询缓存"}},[_._v("#")]),_._v(" 查询缓存")]),_._v(" "),v("p",[_._v("在 MySQL 里面, 允许用户开启查询缓存. 可以理解这个缓存就是用 SQL 作为键, 而对应的查询结果集就是值. 如果下次过来的还是同一个查询, 那么就直接返回缓存起来的查询结果集.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ea82e6887ec2b2fcb9bd352673a98301-20231223175002-mn3rguj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是"),v("strong",[_._v("查询缓存不一定带来查询性能提升")]),_._v(". 如果查询每一次对应的 SQL 都不一样, 那么查询缓存反而会降低查询性能.")]),_._v(" "),v("p",[_._v("在实践中查询缓存的效果的确不怎么好. 按照设计者的想法, 查询缓存的最佳使用场景是一些特别复杂的查询, 它们会扫描很多行, 但是只有一小部分行满足条件. 所以 MySQL 在 8.0 的时候"),v("strong",[_._v("移除")]),_._v("了这个功能.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-21"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-21"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("为了面好数据库这部分内容, 还需要在公司内部搞清楚一些数据和信息.")]),_._v(" "),v("ul",[v("li",[_._v("我后面提到的各种参数是否有改进的空间, "),v("strong",[_._v("记住公司里每一个使用了非默认值的参数")]),_._v(".")]),_._v(" "),v("li",[_._v("如果你所在公司有 DBA, 那么可以请教一下 DBA, 有没有针对公司的业务做过什么优化, 包括数据库自身的优化, 也包括数据库所在的操作系统的优化. 如果你和他们的私人关系够好, 那么可以请教一下他们之前遇到过的各种数据库问题, 然后把这些问题整理成案例, 在面试中使用.")]),_._v(" "),v("li",[_._v("如果你所在公司的文档比较齐全, 那么可以了解一下数据库架构的演进.")])]),_._v(" "),v("p",[_._v("同时, 要为后面的查询优化, 参数调优, 读写分离和分库分表准备一些案例. "),v("strong",[_._v("查询优化部分")]),_._v("要多准备案例, 案例要覆盖不同的优化方向, 比如说有优化索引的案例, 也有优化锁的案例. 在整个数据库面试环节有机会用就抓住机会用上. "),v("strong",[_._v("参数调优部分")]),_._v("在实践中是根据业务特征来选择优化方向, 但是在面试的时候你可以根据准备的回答来找业务特征, 论证自身优化的合理性. "),v("strong",[_._v("读写分离部分")]),_._v("就是看看你所在的公司有没有使用读写分离. 如果有读写分离, 那么主从切换是手动还是自动. 如果是自动的, 那么弄清楚怎么自动切换. 还有"),v("strong",[_._v("分库分表")]),_._v(", 如果有机会亲身参与分库分表那自然是最好的. 要是没有的话, 就看看你所在公司是如何从单库演进到分库分表的. 如果公司本身也没有分库分表, 那么就可以看看别的大厂发布出来的案例, 从各个大厂的技术公众号里就能找到.")]),_._v(" "),v("p",[_._v("面试官问到哪些问题, 可以用这节课的内容来回答呢?")]),_._v(" "),v("ol",[v("li",[_._v("你是"),v("strong",[_._v("如何提升系统可用性或者性能的")]),_._v("?")]),_._v(" "),v("li",[_._v("MVCC 相关的问题, 可以说你调整过 redo log 的刷盘时机, 然后进一步引申到你对数据库调优的其他方案.")]),_._v(" "),v("li",[_._v("读写分离或者分库分表相关问题, 也和这节课的内容强相关.")])]),_._v(" "),v("p",[_._v("最佳的面试策略, "),v("strong",[_._v("是把提高数据库可用性, 性能作为你提高整个系统的可用性, 性能的一环")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"整体方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#整体方案"}},[_._v("#")]),_._v(" 整体方案")]),_._v(" "),v("p",[_._v("为了更好地引导这个话题, 要在三个地方主动提起你在数据库上的深厚积累.")]),_._v(" "),v("p",[_._v("首先是在简历上. 比如说在个人优势里面这样写:")]),_._v(" "),v("blockquote",[v("p",[_._v("我擅长数据库, 包括查询优化, MySQL 和 InnoDB 引擎优化, 熟练掌握 MySQL 高可用和高性能方案.")])]),_._v(" "),v("p",[_._v("然后在自我介绍的时候, 要注意强调一下自己在数据库这方面的竞争优势.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在数据库方面有比较多的积累, 比如说我长期负责公司的查询优化, 提高 MySQL 的可用性和性能. 也在公司推动过读写分离和分库分表, 实践经验丰富.")])]),_._v(" "),v("p",[_._v("在具体的项目里面, 要注意提起自己在数据库上做的事情. 比如说当你在介绍某个项目的时候可以这样说:")]),_._v(" "),v("blockquote",[v("p",[_._v("这个项目是公司的核心业务, 我主要负责性能优化和提高系统可用性. 在数据库上, 我通过查询优化, 参数优化和读写分离, 提高了 20% 的查询性能. 同时参与了一个核心业务数据库的分库分表, 主要负责的是数据迁移和主键生成部分.")])]),_._v(" "),v("p",[_._v("面试官自然就会对你的工作感兴趣, 那么你就可以用这一章的内容来应对面试官的提问.")]),_._v(" "),v("p",[_._v("查询优化已经讲过了, 这里就不赘述了. 这里主要看"),v("strong",[_._v("参数调优, 读写分离和分库分表")]),_._v("这三方面.")]),_._v(" "),v("h6",{attrs:{id:"参数调优"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#参数调优"}},[_._v("#")]),_._v(" 参数调优")]),_._v(" "),v("p",[_._v("之前讲过几个可以调优的参数, 这里复习一下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cfbb238yy09e78e4781ca9301eabaee3-20231223175002-rzfc3jw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里 innodb_flush_log_at_trx_commit 这个参数非常重要, 一定要记住, 此外再介绍一个能够提升数据库性能, 并且适合在面试中使用的参数 "),v("strong",[_._v("innodb_buffer_pool_size")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("重要参数：innodb_buffer_pool_size")])]),_._v(" "),v("p",[_._v("简单说就是 "),v("mark",[v("strong",[_._v("innodb 缓冲池的大小, 用于缓存表和索引, 也包括插入数据缓冲, 增加这个值可以减少磁盘 IO")])]),_._v(".")]),_._v(" "),v("p",[_._v("在实践中应该尽可能"),v("strong",[_._v("调大这个参数")]),_._v(". 如果数据库所在的机器内存比较大, 那么"),v("strong",[_._v("可以调整到整个内存的 70% 或者 75%")]),_._v(" . 但是也要小心这个参数过大, 物理内存不足, 容易触发操作系统 swap.")]),_._v(" "),v("p",[_._v("可以把这个东西包装一下, 变成你解决的一个 Bug.")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始我会想到调整 innodb_buffer_pool_size 是因为我发现数据库上的 swap 非常高. 经过排查我发现是因为 innodb_buffer_pool_size 设置得偏大了. 在内存不足的时候, 操作系统就会触发 swap.")]),_._v(" "),v("p",[_._v("解决思路自然是调小一点, 但这样做要小心对业务的影响. 实际上 innodb_buffer_pool_size 是逐步调整的, 最后调整到原本数值的 70%, swap 就大幅减少了, 而且查询性能也没什么变化.")])]),_._v(" "),v("p",[_._v("这里还可以进一步说明另外一个相关的参数 "),v("strong",[_._v("innodb_buffer_pool_instances")]),_._v(". 从图里可以看到, 要是整个 MySQL InnoDB 引擎内部只有一个缓冲池, 所有查询都访问它, 那么"),v("strong",[_._v("并发竞争会十分厉害")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/62e9754e24d314fb27f4cb78fb2ec712-20231223175002-jom2gf9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这种情况下, 可以"),v("strong",[_._v("考虑启动多个缓冲池实例")]),_._v(", 具体多少个就由 innodb_buffer_pool_instances 这个参数指定. 显然这个数字越大, 并发竞争就越小.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/63609e179957617708e50101659bb27f-20231223175002-8qwswv4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可惜 MySQL 有一些额外的限制, 它要求在 innodb_buffer_pool_instances 大于 1 的情况下, innodb_buffer_pool_size 不能小于 1G. 一般建议在 8G 以内设置成 2 就可以, 如果大于 8G 那么可以设置成 4.")]),_._v(" "),v("p",[v("strong",[_._v("可以把 innodb_buffer_pool_size 和 innodb_buffer_pool_instances 放到一起说")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在解决了 innodb_buffer_pool_size 的 Bug 之后, 我负责的系统数据库的相关设置, 又发现了一个问题. 我们有一个核心数据库, innodb_buffer_pool_size 超过了 8G, 但是 innodb_buffer_pool_instances 居然还保持着 1, 这显然是不合理的. 所以这个我就把它调整成了 4, 减少数据库 buffer pool 的并发竞争.")])]),_._v(" "),v("blockquote",[v("p",[_._v("重要参数：query_cache_min_res_unit")])]),_._v(" "),v("p",[_._v("前面提到了查询缓存相关的知识, 可以从两个相反的角度来使用查询缓存案例. 第一个角度是你认为查询缓存效果不好, 所以你关掉了.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司有一个数据库, 用的是比较古老的 MySQL 版本. 在这个版本上开启了查询缓存. 但是实际上效果不太好, 因为这里存储的数据其实经常变动, 所以缓存命中率一直很低. 我索性就关掉了这个查询缓存, 后来查询性能也基本没有什么损失.")])]),_._v(" "),v("p",[_._v("第二个角度是你赞同使用查询缓存. 这里可以用两个案例来说明, 第一个案例是你开启了查询缓存.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们在业务里面有一个关键查询, 这个查询比较复杂, 执行的时候会非常慢. 但我注意到这个查询对应的数据是很少变动的, 于是我尝试开启了查询缓存. 果然开启缓存之后, 这个查询大部分情况下都命中了缓存, 性能得到了很大的提升.")])]),_._v(" "),v("p",[_._v("第二个案例是你"),v("strong",[_._v("调整了查询缓存的相关参数")]),_._v(", 最为常见的是调整 "),v("strong",[_._v("query_cache_min_res_unit")]),_._v(". 这个参数的默认值是 4KB. 大部分情况下, 4KB 都太大了, 所以会有很多内存浪费. 比如说结果集可能就一行, 总共不到 1KB, 它都给你分配了 4KB.")]),_._v(" "),v("p",[_._v("所以可以这么说:")]),_._v(" "),v("blockquote",[v("p",[_._v("我们有一个数据库是开启了查询缓存的, 但是 query_cache_min_res_unit 一直使用的是默认值 4KB. 后来我仔细评估了一下相关业务的查询结果集大小, 4KB 显然太大了, 浪费了很多内存. 所以我后面把它调整成了 1KB, 还是能够满足大多数查询的需求. 这样就能缓存更多查询的结果集, 查询性能得到了提升.")])]),_._v(" "),v("p",[_._v("在这个角度之下, 要小心面试官问你为什么 MySQL 8.0 移除了这个功能. 答案也很简单, "),v("strong",[_._v("因为缓存功能适合那种耗时并且重复执行的查询, 而实际上这一类的查询并不多")]),_._v(". 另外一个理由是, "),v("strong",[_._v("数据库本身就容易成为性能瓶颈, 那么完全可以让应用自己去做缓存, 减轻数据库的负担")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"读写分离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#读写分离"}},[_._v("#")]),_._v(" 读写分离")]),_._v(" "),v("p",[_._v("如果你在小公司工作的话, 这部分内容会比较适合, 因为正常中大型公司基本上都已经完成了读写分离. 你可以这样介绍你的读写分离方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始我进公司的时候, 就发现他们居然连读写分离都还没做, 包括核心数据库都没有, 而且当我去看观测数据的时候就感觉核心数据库已经快要触及性能瓶颈了. 于是我就在公司里面引入了从库. 虽然只是准备了一个从库, 但是大部分读请求落到从库上, 主库的压力就小多了. 引入读写分离机制, 一方面可以提高了数据库的可用性, 另一方面也提高了查询的性能.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4763600e622c4271ee80f51924d621db-20231223175002-3b2xso8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("有些时候面试官可能会追问具体是怎么做的, 这里给出简要步骤.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("准备一个从库")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("改造业务, 允许业务动态切换读主库还是读从库")]),_._v(".")]),_._v(" "),v("li",[_._v("切换到读从库, 看看是否有问题, 如果有问题就立刻回滚.")])]),_._v(" "),v("p",[_._v("回答的时候就可以介绍这个简单方案, 同时提出一个"),v("mark",[v("strong",[_._v("主从延迟问题")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("单库引入读写分离, 并不是特别复杂. 不过这个过程中要小心主从延迟问题. 比如说原本有一个业务是在更新之后立刻读数据, 那么就会读到更新后的值. 但是如果修改成读从库, 就可能还是会读到更新前的值, 导致业务出错. 在改造业务的过程中要小心这种场景.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d8281a66ca006b987d53f068a758aabd-20231223175002-lnt6iiv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以利用"),v("strong",[_._v("主从自动切换")]),_._v("进一步刷亮点. "),v("strong",[_._v("主从自动切换是指当主库出现问题的时候, 能够自动把某个从库提升成主库")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d7ec66b033fb4146c6828bcb4880ba7e-20231223175002-4map5b8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然如果你们公司本身已经有了读写分离, 那么也可以直接使用这个亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("在实施了读写分离之后, 最开始我们都是手动切换主库或者从库. 但是万一主库在半夜出现了故障, 那就不一定能够及时发现并且切换了. 所以我们用 "),v("mark",[_._v("KeepAlived")]),_._v(" 做了一个简单的自动主从切换机制, 然后在测试环境做过几次演练.")])]),_._v(" "),v("p",[_._v("或者你说:")]),_._v(" "),v("blockquote",[v("p",[_._v("我了解到云服务本身就提供了这种自动切换功能, 所以接入了一下.")])]),_._v(" "),v("p",[_._v("你应该还记得, 在讲微服务高可用的时候就说过, 如果没有自动故障处理机制, 是很难达到非常高的可用性的. 这个亮点可以看作是这种理念在数据库这边的应用.")]),_._v(" "),v("h6",{attrs:{id:"分库分表"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表"}},[_._v("#")]),_._v(" 分库分表")]),_._v(" "),v("p",[_._v("这算是一张王牌, 就个人经验来说, 如果你在公司里面"),v("strong",[_._v("主导过一次单库拆分分库分表")]),_._v(", 那么出去面试, 数据库这一关就不会有任何问题.")]),_._v(" "),v("p",[_._v("在介绍自己的分库分表方案时, 要包含以下几个方面:")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("为什么要分库分表")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("分库分表中间件选型")]),_._v(", 只需要回答公司使用的分库分表中间件的优缺点就可以了. 如果对分库分表中间件没有任何了解, 那么无脑使用 ShardingSphere 也行.")]),_._v(" "),v("li",[v("strong",[_._v("容量规划")]),_._v(", 前面讲过.")]),_._v(" "),v("li",[v("strong",[_._v("数据迁移")]),_._v(", 前面讲过.")]),_._v(" "),v("li",[v("strong",[_._v("分库分表键选择")]),_._v(", 前面讲过.")]),_._v(" "),v("li",[v("strong",[_._v("主键生成策略")]),_._v(", 并且要能解释清楚这种决策的理由.")]),_._v(" "),v("li",[v("strong",[_._v("分库分表之后的事务问题")]),_._v(", 前面也讨论过, 包括在服务层面上解决事务, 例如 TCC, SAGA, 又或者依赖于分库分表中间件提供的策略, 比如说延迟事务.")]),_._v(" "),v("li",[v("strong",[_._v("分库分表中一些特殊查询的处理")]),_._v(", 最主要的就是"),v("strong",[_._v("分页查询")]),_._v(", 前面也学过了.")])]),_._v(" "),v("p",[_._v("面试开始的时候就可以聊聊你实际参与过里面的某个步骤.")]),_._v(" "),v("blockquote",[v("p",[_._v("我进我们公司的时候, 刚好遇上了数据库性能瓶颈, 所以我实际参与了核心数据库的分库分表, 我主要负责的是分库分表中的数据迁移和主键生成部分.")])]),_._v(" "),v("p",[_._v("根据自己实际情况和前面学习的成果来选择. 这里说数据迁移和主键生成, 是因为单纯从技术上来说它们俩更有竞争优势. 不过要注意一点, 要做到对自己负责的部分了如指掌.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-20"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-20"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("在前置知识里面介绍了查询缓存. 其实查询缓存已经差不多过时了, 如果不是因为面试会问的话, 可能我们也不太会地去讲这个部分, 这里有一个基本的了解就可以了.")]),_._v(" "),v("p",[_._v("整个高性能高可用的方案主要落在了四个方面: "),v("strong",[_._v("查询优化, 参数优化, 读写分离还有分库分表")]),_._v(". 如果在大厂工作, 那么相信你们公司可能还有一些更加复杂的高可用方案, 比如说异地多活. 如果有机会能接触到的话, 可以深入了解一下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6ed888392d7e265c6e78bcfe735186f9-20231223175002-pqf98bt.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h3",{attrs:{id:"消息队列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息队列"}},[_._v("#")]),_._v(" 消息队列")]),_._v(" "),v("h4",{attrs:{id:"_22-消息队列-消息队列可以用来解决什么问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_22-消息队列-消息队列可以用来解决什么问题"}},[_._v("#")]),_._v(" 22-消息队列:消息队列可以用来解决什么问题?")]),_._v(" "),v("p",[_._v("从今天开始要学习一个新的主题——消息队列. 一直以来, 消息队列都是业界用于构建高并发, 高可用系统的利器. 即便是简单的业务开发, 也可以通过消息队列的解耦, 异步特性来提高性能和可用性.")]),_._v(" "),v("p",[_._v("消息队列和数据库, 缓存并列为面试中最热门的三个中间件. 消息队列本身的知识也很多, 理论和实践结合紧密, 也是面试中的难题. 所以在消息队列这个主题下, 会学习最热门的面试点, 确保你可以在面试中保持竞争优势. 今天就先来学习第一个面试主题: 消息队列的使用场景.")]),_._v(" "),v("h5",{attrs:{id:"基础知识-8"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础知识-8"}},[_._v("#")]),_._v(" 基础知识")]),_._v(" "),v("p",[_._v("消息队列最鲜明的特性是"),v("mark",[v("strong",[_._v("异步, 削峰, 解耦")])]),_._v(". 也有人说这是消息队列的使用场景, 用途, 并且额外加了几个, 比如日志处理和消息通讯. 但是实际上, 日志处理和消息通讯可以看作是消息队列的具体落地案例. 比如日志处理同时利用了消息队列异步, 解耦和削峰的特性.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f5832b15e1b1fee1356d1fd29976fda4-20231223175002-1vzpi2z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("消息通讯是指即时通讯之类的工具, 比如使用的微信, QQ 都是通讯工具. 通讯工具主要利用的是异步和解耦特性, 不过要是你觉得你的通讯工具会有高并发的收发消息场景, 也可以看作是削峰.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5e5fb2c430e38b2d1342607632de6712-20231223175002-88atczv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("基本上一切消息队列的应用场景, 都是围绕异步, 解耦和削峰三个特性来设计的. 反过来也可以说, 如果有一些需要异步, 解耦和削峰的需求, 那么消息队列就是最合适的工具.")]),_._v(" "),v("p",[_._v("此外消息队列还可以用来实现"),v("strong",[_._v("事件驱动架构")]),_._v(", 这个也是后面要学习的亮点方案.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-22"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-22"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在准备消息队列面试的时候, 需要搞清楚下面几点.")]),_._v(" "),v("ul",[v("li",[_._v("公司有没有使用消息队列? 主要用于解决什么场景的问题?")]),_._v(" "),v("li",[_._v("如果使用了消息队列, 那么在具体的场景下不使用消息队列是否可行? 和使用消息队列的方案比起来, 有什么优缺点?")]),_._v(" "),v("li",[_._v("公司用的是什么消息队列, 它有什么优缺点?")])]),_._v(" "),v("p",[_._v("在前置知识里面我提到了消息队列的三种特性: 异步, 解耦和削峰. 可以在公司内部, 或者自己的过往工作经验里面各找一个案例. 虽然我提到过, 一个案例可能同时体现了异步, 解耦和削峰三个特性, 但还是需要多准备几个案例, 准备得更充分一些.")]),_._v(" "),v("p",[_._v("面试官如果问到了下面这些问题, 都可以引导到这里.")]),_._v(" "),v("ul",[v("li",[_._v("你有没有用过消息队列? 用来解决什么问题?")]),_._v(" "),v("li",[_._v("你是否听过延时队列? 怎么实现延时队列?")]),_._v(" "),v("li",[_._v("如何设计一个秒杀架构? 在回答的时候可以强调一下消息队列的作用.")]),_._v(" "),v("li",[_._v("什么是"),v("strong",[_._v("事件驱动架构")]),_._v("?")])]),_._v(" "),v("p",[_._v("建议有机会的话, 在遇到一些"),v("strong",[_._v("非常复杂棘手的业务时可以考虑使用事件驱动来解决")]),_._v(". 个人认为越复杂的业务系统, 应用事件驱动就越有价值.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-16"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-16"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("首先在简历上就应该写上自己擅长消息队列或者说自己能够用消息队列解决问题. 后续面试官在提问的时候就会考虑面消息队列这方面的内容. 面试官可能会先问你用消息队列解决过什么问题, 那么回答准备的案例就可以.")]),_._v(" "),v("p",[_._v("在介绍了案例之后, 面试官大概率会问一个问题, 就是在具体的场景下, 你为什么非得使用消息队列?")]),_._v(" "),v("p",[_._v("在前置知识里面已经解释了两个场景: 日志处理和消息通讯. 这里再补充几个. 这些场景都是那种引导性非常强的场景, 也就是可以在这些场景下把话题引导到别的主题下.")]),_._v(" "),v("h6",{attrs:{id:"秒杀场景"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#秒杀场景"}},[_._v("#")]),_._v(" 秒杀场景")]),_._v(" "),v("p",[_._v("秒杀也是面试中的一个大热点. "),v("strong",[_._v("一般秒杀的架构设计中都会使用消息队列, 同时利用消息队列三个特性")]),_._v(".")]),_._v(" "),v("p",[_._v("可以看一下一个比较简单的秒杀架构图是怎样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8b1b2602760736c6d40f09c00076954a-20231223175002-o33m1l6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在消息队列之前, 要对用户请求做一些校验, 比如说这个用户是否已经参加过秒杀了. 其次要扣库存, 扣库存成功才算是抢到了. "),v("strong",[_._v("紧接着就是把这个请求丢到消息队列里, 后续异步创建订单, 并且完成支付")]),_._v(".")]),_._v(" "),v("p",[_._v("那么这种设计的精髓就是利用消息队列把"),v("mark",[v("strong",[_._v("整个秒杀过程分成轻重两个部分")])]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("在进入消息队列之前的操作都是轻量级的, 一般也就是内存计算或者访问一些 Redis, 所以可以认为瓶颈基本上取决于 Redis 的性能")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("而进入消息队列之后就是非常重量级的操作了, 比如说要进一步验证交易的合法性, 操作数据库等")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a2e37cf53c064b23637a7edef119c1d3-20231223175002-09nmakt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这样介绍秒杀方案, 关键词是"),v("mark",[v("strong",[_._v("轻重之分")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("消息队列还经常被用在秒杀场景里面. 最基本的架构是秒杀请求进来之后, 会有一个轻量级的服务. 这个服务就是做一些限流, 请求校验和库存扣减的事情. 这些事情差不多都是内存操作, 最多操作 Redis. 当库存扣减成功之后, 就会把秒杀请求丢到一个消息队列.")]),_._v(" "),v("p",[_._v("然后订单服务会从消息队列里面将请求拿出来, 真正创建订单, 并且提示用户支付. 这一部分就是重量级的操作, 无法支撑大规模并发. 所以在这个场景里面可以把消息队列看作是一个轻重操作的分界线.")])]),_._v(" "),v("p",[_._v("这个场景介绍完, 面试官就可能会进一步问和秒杀有关的内容, 比如说扣减了库存之后, 万一用户没有支付怎么办, 于是就可以用下面这个案例了.")]),_._v(" "),v("h6",{attrs:{id:"订单超时取消"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#订单超时取消"}},[_._v("#")]),_._v(" 订单超时取消")]),_._v(" "),v("p",[_._v("在电商里面, 如果用户下单之后一直没有支付, 那么这个订单就会被取消, 从而释放库存.")]),_._v(" "),v("p",[_._v("订单超时取消在行业内有很多种做法, 这里只介绍使用消息队列的解决方案. 要想利用消息队列实现订单超时取消功能, 需要使用"),v("strong",[_._v("延时消息")]),_._v(". 所谓的延时消息, 就是发送者在发送之后, 要过一段时间, 消费者才能消费的消息.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1ed0b3815036a5d7573fff30b1b92af7-20231223175002-fw3v98j.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以这样介绍方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("消息队列也可以用于订单超时取消这种场景. 在这种场景下, 可以准备一个延时队列, 比如超时时间是 30 分钟, 那么延时也是 30 分钟.")]),_._v(" "),v("p",[_._v("但是消费的时候要小心并发问题, 就是在 30 分钟这一个时刻, 一边用户支付, 一边消费者也消费超时消息, 就会有并发问题. 解决思路有很多, 可以使用分布式锁, 乐观锁, 也可以使用 SELECT FOR UPDATE 锁住订单, 防止并发操作.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/00a06b42e6b876b5aa82404d1a9e7d8e-20231223175002-wan61sw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里提到了并发问题, 在解决并发问题的思路中也提到了之前数据库部分学过的 SELECT FOR UPDATE 和乐观锁, 记得复习一下.")]),_._v(" "),v("p",[_._v("这里再额外解释一下乐观锁方案的关键步骤. 乐观锁方案就是在把订单更新为超时状态的时候, 需要"),v("strong",[_._v("确保原始状态还是未支付")]),_._v(".")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("order"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SET")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("status"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"超时未支付"')]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("id"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("123")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token identifier"}},[v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("status"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"未支付"')]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("类似地, 在"),v("strong",[_._v("支付那边也需要确保只有在 status 是未支付的时候才能发起支付")]),_._v(".")]),_._v(" "),v("p",[_._v('这个场景主要是把话题引导到延时消息, 延时消息后面会详细分析. 目前主流的消息队列中 RocketMQ 是支持延时消息的, 它有插件支持. 但是 Kafka 不支持, 不过后续也会教你怎么用 Kafka 支持延时消息. 所以当面试官问 "为什么不用 Kafka" 这种问题, 可以把 Kafka 不支持延时消息作为理由之一.')]),_._v(" "),v("h5",{attrs:{id:"亮点方案-12"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-12"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这节课准备了一个理论上的亮点和一个高级并且复杂的方案. 第一个亮点是回答"),v("strong",[_._v("为什么一定要使用消息队列")]),_._v(". 前面讲过消息队列广泛应用于各种场景, 那你有没有深入思考过, 为什么非得使用消息队列呢?")]),_._v(" "),v("p",[_._v("换一句话来说, 不用消息队列会怎样? 用了又有什么好处呢?")]),_._v(" "),v("h6",{attrs:{id:"为什么一定要使用消息队列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么一定要使用消息队列"}},[_._v("#")]),_._v(" 为什么一定要使用消息队列?")]),_._v(" "),v("p",[_._v("这个问题本身也是反直觉的. 也就是说因为业界一直说消息队列很好很好, 那如果没有思考过这个问题, 面试官突如其来问一下, 就不知道怎么回答了.")]),_._v(" "),v("p",[_._v("先从创建订单的典型场景看起. 在订单创建之后, 要通知很多下游, 正常做法都是发送一个订单创建的消息, 然后关心订单创建的业务方各自去订阅这个消息就可以了.")]),_._v(" "),v("p",[_._v("这里面试官就会问, 为什么订单服务不直接调用各个业务方呢?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1764ae0cffcdddd95e49277e2dc9c626-20231223175002-32g2hu7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6899318310095f93d40b03409e9c7023-20231223175002-f9x78df.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("类似的场景还有, 在"),v("strong",[_._v("消息通讯里面为什么服务端不直接把消息转发给各个接收者呢")]),_._v("?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e833f95f2b5dc437a418af4e6164783f-20231223175002-vqqzjmq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这一类的问题, 本质上都是在问: "),v("strong",[_._v("在这个业务场景下, 不异步, 不解耦或者不削峰会有什么问题")]),_._v("?")]),_._v(" "),v("p",[_._v("那么不用消息队列究竟有什么问题呢? 答案是"),v("strong",[_._v("性能差, 扩展性差, 可用性差")]),_._v(".")]),_._v(" "),v("p",[_._v("这里有一个不太好的回答, 就是耦合严重. 这个回答只能说你答了, 但是回答得不到位. 毕竟你没有解耦自然就是耦合严重, 所以面试官希望你深入解释的是耦合严重会带来什么后果. 其实可以这么说:")]),_._v(" "),v("blockquote",[v("p",[_._v("同步调用方案相比引入消息队列有三个缺陷, 分别是性能差, 可扩展性差和可用性差.")])]),_._v(" "),v("blockquote",[v("p",[_._v("问题1：性能差")])]),_._v(" "),v("p",[_._v("性能差是因为需要停下来等"),v("strong",[_._v("全部调用完成")]),_._v("才可以返回响应.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f679211007f1d5d2d9a5d17de2c2fb12-20231223175002-0078k1y.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("业务方必须停下来等待结果, 如果这里需要通知三个下游, 那么就需要发起三次调用, 并且等它们各自的结果返回之后才能继续往下执行, 或者返回响应, 这样性能太差了.")])]),_._v(" "),v("p",[_._v('紧接着面试官就可能和你抬扛: "如果我并发调用呢? 性能也很好啊!" 他隐含的意思就是可以开启多个线程或者协程, 并发调用所有的下游.')]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3a9c7b1e733371b1d80d36dcf1e9ab4b-20231223175002-ny8twrm.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但即便是 "),v("strong",[_._v("并发调用性能也比使用消息队列差")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("并发调用相比于使用消息队列, 性能也更差. 在并发调用的情况下, 性能取决于最坏的那个同步调用什么时候返回结果. 而正常丢一个消息到消息中间件上是很快的.")])]),_._v(" "),v("p",[_._v("紧接着可以补充一点, 引出扩展性和可用性的话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("并且即便并发调用的性能损耗是可以接受的, 但是扩展性和可用性还是解决不了.")])]),_._v(" "),v("blockquote",[v("p",[_._v("问题2：扩展性")])]),_._v(" "),v("p",[_._v("扩展性归根结底就是一句话: 如果一个新的下游要接入进来有多难? 在使用消息队列的时候, 新的下游要接入, "),v("strong",[_._v("只需要自己去订阅消息就可以, 完全不需要通知任何人")]),_._v(". 在公司里, 可能就是你丢给下游一个文档, 下游自己看看文档, 知道订阅哪个 topic, 消息生产速率有多高, 差不多就能自己独立完成接入了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c5d80d98cde37788d4b8c39a5bfb2fac-20231223175002-o0gzfyu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是如果是同步调用, 事情就麻烦很多. 需要下游提供 RPC 服务地址(定位信息), 根据下游的 API 设计构造请求, 处理响应, 再一起联调, 测试, 上线, 遇到了 Bug 还得推诿扯皮一番.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/859fb2603f6d737bfe9f15f7137033c9-20231223175002-emsbuz3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以这里可以这样回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在使用消息队列的情况下, 消息发送者完全不关心谁会去消费这些消息. 同样地, 如果有一个新的业务方要订阅这个消息, 它可以自主完成. 而同步调用的时候, 上游必须知道下游的接口, 然后要知道如何构造请求, 如何解析响应, 还要联调, 测试, 上线, 整个过程都得和下游密切合作, 因此效率特别低, 可扩展性很差.")])]),_._v(" "),v("p",[_._v("但这里可以刷一个亮点, 就是在类似的场景下, 如果因为一些业务情况确实不能使用消息队列, 那么可以考虑提供一个一致性的抽象来减轻这种接入的负担.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果在某些场景下确实不能用消息队列, 那么这个扩展性问题可以通过一些技术手段来缓解. 比如说上游提供一整套的对接规范, 包括 API 定义, 请求和响应中每个字段的含义. 这样下游就对着这个 API 定义来提供实现, 上游就不需要适配每一个下游了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7306576de9c2e4a38748a0948d203e90-20231223175002-169yd8y.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后进一步总结.")]),_._v(" "),v("blockquote",[v("p",[_._v("这是对接众多下游的基本设计, 可以充分保障高可扩展性和高研发效率.")])]),_._v(" "),v("blockquote",[v("p",[_._v("问题3：可用性")])]),_._v(" "),v("p",[_._v("在使用消息队列的方案中, 只需要确保自己把消息发送到了消息队列上, 就认为操作已经成功了.")]),_._v(" "),v("p",[_._v("但在同步调用方案中, 必须要确保调用所有的下游都成功了才算是成功了. 所以还需要额外考虑部分成功部分失败的问题. 比如说在订单的例子里面, 如果同步调用到推荐成功, 但是到审计和搜索失败了, 那么该怎么办?")]),_._v(" "),v("p",[_._v("所以这样来看, 相比使用消息队列的方案, 同步调用的方案更加容易出错, 并且容错也更难.")]),_._v(" "),v("h6",{attrs:{id:"事件驱动"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#事件驱动"}},[_._v("#")]),_._v(" 事件驱动")]),_._v(" "),v("p",[_._v("事件驱动(Event-Driven)可以说是一种软件开发模式, 也可以看作是一种架构. 它的"),v("strong",[_._v("核心思想是通过把系统看作一系列事件的处理过程, 来实现对系统的优化和重构")]),_._v(".")]),_._v(" "),v("p",[_._v("可以直观地理解成, "),v("strong",[_._v("整个系统不同组件之间的通信是通过事件来完成的")]),_._v(". 也就是组件 1 发送一个事件到消息队列上, 然后组件 2 消费这个消息. 组件 2 消费完成后再发出一个消息到消息队列. 每一个事件就是一个消息.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ac805acb49f7eb8939577f73baef2d56-20231223175002-zir9ap7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("这些消息可能有不同的 Topic, 也可能发送到不同的消息队列集群")]),_._v(". 但是毫无疑问它们要通过"),v("strong",[_._v("密切合作")]),_._v("来解决一个业务问题.")]),_._v(" "),v("p",[_._v("它的优点十分明显.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("低耦合性")]),_._v(": 各个组件只依赖消息队列, 组件之间通过消息的定义间接地耦合在一起. 换句话来说, 组件只需要知道消息的定义, 并不需要知道发送消息的组件是哪个.")]),_._v(" "),v("li",[v("strong",[_._v("可扩展性")]),_._v(": 事件驱动的应用程序具有很强的扩展性, 可以通过添加新的事件处理程序, 组件等来实现系统的扩展和升级.")]),_._v(" "),v("li",[v("strong",[_._v("高可用")]),_._v(": 可以充分利用消息队列的可靠性, 可重复消费等特性, 来保证消息发送, 消费高可用, 从而保证整个系统的高可用.")])]),_._v(" "),v("p",[_._v("事件驱动适合用来解决一些"),v("strong",[_._v("复杂, 步骤繁多, 流程冗长")]),_._v("的业务问题. 在下面的亮点方案里面, 用的就是"),v("mark",[v("strong",[_._v("事件驱动结合 SAGA 分布式事务的方案")])]),_._v(". 这个方案足够高级, 冷僻, 奇异. 它原本用在一个大规模的分布式系统里面, 是一个高性能和高可用的分布式事务解决方案.")]),_._v(" "),v("p",[_._v("可以看一下事件驱动和 SAGA 结合之后的形态.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/77f0e01de943feb6885a690a6d3c856b-20231223175002-ub2zxu8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("也就是说, "),v("strong",[_._v("当某一个步骤完成之后, 就会发出一个或者多个事件, 驱动事务中的后续步骤")]),_._v(". 包括回滚也是这样, 比如"),v("strong",[_._v("发出一个代表某一个步骤执行失败的事件, 对应的消费者就会去执行反向补偿步骤")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/33344e60bcb5782a086f7c5584675629-20231223175002-8qft8kg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("使用事件驱动的优点是低耦合, 高扩展性, 异步, 高可用. 不过在"),v("strong",[_._v("实时性上要比同步调用差一点")]),_._v(". 下面用一个最简单的例子来解释它的运作. 比如有一个分布式事务, 就是要求先更新 DB, 再更新缓存. 那么在缓存更新失败的场景下, 过程看起来就像图里展示的这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/66b2cf98851930010f480dc07fd7d8bb-20231223175002-y8bc0lf.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("其中还原 DB 是指需要用原始数据更新回去, 而不是数据库回滚操作, 之前在 SAGA 分布式事务里面就讲过. 当然这个例子只是帮助理解, 正常来说这么简单的分布式事务是用不着 SAGA 的.")]),_._v(" "),v("p",[_._v("可以考虑这样介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们公司用事件驱动实现了 SAGA 的分布式事务解决方案. 基于事件驱动的 SAGA 模式就是在每一个步骤结束之后发送事件, 不同的步骤会发送一个或者多个事件. 然后消费者消费了消息之后, 就开始执行下一个步骤. 比如说在更新 DB 再更新缓存的场景里就可以这样用. 这种形态和一般的事务比起来, 优势是低耦合, 高扩展, 高可用.")])]),_._v(" "),v("p",[_._v("在这个方案里面, 面试官可能追问的方向有两个, 一个是分布式事务. 另外一个方向是后面会讨论的问题, 就是怎么做到消息的可靠发送和可靠消费.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-21"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-21"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("今天这节的内容还是比较简单的, 主要介绍了消息队列的三个用途: "),v("strong",[_._v("解耦, 异步, 削峰")]),_._v(", 还有几个使用消息队列的场景, 包括 "),v("strong",[_._v("日志处理, 消息通讯, 秒杀场景和订单超时取消")]),_._v(".")]),_._v(" "),v("p",[_._v("最后在面试的亮点部分, 给出了一个"),v("strong",[_._v("基于事件驱动的 SAGA 分布式事务方案")]),_._v(". 事件驱动是一个解决复杂业务问题的神器, 有机会的话尽可能实践一下, 之后有很大可能会用到.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/111199134031684c78a61558d0cca992-20231223175002-j9afuxf.png",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_23-延迟消息-怎么在kafka上支持延迟消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_23-延迟消息-怎么在kafka上支持延迟消息"}},[_._v("#")]),_._v(" 23-延迟消息:怎么在Kafka上支持延迟消息?")]),_._v(" "),v("p",[_._v("今天来讨论一个在消息队列面试中非常热的话题——延迟消息.")]),_._v(" "),v("p",[_._v("延迟消息在 Kafka 面试里面是非常热门的, 其他消息队列多少也会问, 但是不如 Kafka 问得频繁. 因为 Kafka 不支持延迟消息是大家都知道的. 但是偏偏 Kafka 又用得多, 很多业务场景也要求使用延迟消息, 因此面试的时候延迟消息就成了一个重要的考察点.")]),_._v(" "),v("p",[_._v("和之前的面试点不同, 能把延迟消息的方案讲得清楚透彻的人就不多, 更不要说刷亮点了. 那么今天就深入延迟消息, 并且给出一个非常高级的方案. 这个方案会涉及到分库分表, 所以能帮助你把这些知识融会贯通.")]),_._v(" "),v("h5",{attrs:{id:"延迟队列和延迟消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#延迟队列和延迟消息"}},[_._v("#")]),_._v(" 延迟队列和延迟消息")]),_._v(" "),v("p",[v("strong",[_._v("延迟队列")]),_._v("是一种特殊的队列. 它里面的"),v("strong",[_._v("每个元素都有一个过期时间")]),_._v(", 当元素还没到过期时间的时候, 如果试图从队列里面获取一个元素, 会被阻塞. 当有元素过期的时候, 就会拿到这个过期的元素. 可以这样想, 你拿到的永远是最先过期的那个元素.")]),_._v(" "),v("p",[_._v("很多语言本身就提供了延迟队列的实现, 比如说在 Java 里面的 DelayQueue.")]),_._v(" "),v("p",[_._v("这节讨论的就是一种特殊形态的延迟队列, 或者说是基于消息队列的延迟队列, 也叫做"),v("strong",[_._v("延迟消息")]),_._v(". 具体来说, "),v("strong",[_._v("延迟消息是指消息不是立刻被消费的, 而是在经过一段时间之后, 才会被消费")]),_._v(". 在到时间之前, 这个消息一直都被存储在消息队列的服务器上. 上一节就举了订单超时取消的例子, 它就用到了延迟消息.")]),_._v(" "),v("h5",{attrs:{id:"支持延迟消息的其他消息队列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#支持延迟消息的其他消息队列"}},[_._v("#")]),_._v(" 支持延迟消息的其他消息队列")]),_._v(" "),v("p",[_._v("目前, 大部分云厂商版本的消息队列都支持了延迟消息, 不过这里讨论的是原生支持的消息队列. 如果本身使用了今天介绍的这些中间件, 那么可以直接使用这些内容来面试. 如果你使用的是 Kafka, 那么在面试的时候要注意结合着这些消息队列, 对比着面试.")]),_._v(" "),v("p",[_._v("RabbitMQ 有一个延迟消息的插件 rabbitmq_delayed_message_exchange, 只需要启用这个插件就可以使用延迟消息. 这个插件的基本原理也比较简单, 就是实现了一个 exchange. 这个 exchange 控制住了消息什么时候会被真的投递到队列里.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/476cfa5ff52291c158ed891641cd8f56-20231223175002-cjl5oxn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如上图所示, "),v("strong",[_._v("消息会先暂时存储在 exchange 里面")]),_._v(". 它使用的是 Mnesia 来存储, 如果不知道 Mnesia 是什么, 就直观地把它看作一个基于文件的数据库.")]),_._v(" "),v("p",[_._v("当延迟的时间满足条件之后, 这些存储的数据就会被投递到真正的消息队列里面. 紧接着消费者就可以消费到这个消息了. 可以从这里得到一个启发, 就是如果"),v("strong",[_._v("要实现一个延迟队列, 是可以借助数据库")]),_._v("的.")]),_._v(" "),v("p",[_._v("那么这个插件本身也是有很多限制的, 在它的官网主页里面就有说明, 其中有两个最突出的限制.")]),_._v(" "),v("ul",[v("li",[_._v("消息在真的被投递到目标消息队列之前, 是存放在接收到了这个消息的服务端本地的 Mnesia 里面. 也就是说, 如果这个时候还没有刷新磁盘, 那么消息就会丢失; 如果这个节点不可用了, 那么消息也同样会丢失.")]),_._v(" "),v("li",[_._v("不支持高并发, 大数据量. 显然, 现实中很多场景都是要在高并发大数据量场景下使用延迟消息的, 比如前面说的订单超时取消. 因此这个缺点也限制了这个插件被广泛使用.")])]),_._v(" "),v("p",[_._v("除了这个插件, 开发者也可以自己手动实现延迟消息. 这就要利用到 RabbitMQ 的 ttl 功能和所谓的死信队列了.")]),_._v(" "),v("p",[v("strong",[_._v("死信队列是一种逻辑上的概念, 也就是说它本身只是一个普通的队列")]),_._v(". 而死信的意思是指过期的无法被消费的消息, 这些消息会被投送到这个死信队列.")]),_._v(" "),v("p",[_._v("简单来说, 就是开发者准备一个队列 delay_queue, 为这个 delay_queue 设置过期时间, 这个 delay_queue 不需要消费者. 然后把真实的业务 biz_queue 绑定到这个 delay_queue, 作为它的死信队列.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1347e67374197cf37fa0a75a3930b2aa-20231223175002-7l253ky.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("生产者发送消息到 delay_queue, 因为没有消费者, 所以消息会过期. 过期之后的消息被转发到死信队列, 也就是 biz_queue 里面. 这时候消费者就能拿到消息了.")]),_._v(" "),v("p",[_._v("这种方案并没有插件的那两个缺点. 但是 ttl 的设置是在队列级别上, 也就是一个 delay_queue 的延时是固定的, 不能做到随机. 比如一条消息延后三分钟, 另外一条消息延后五分钟, 这是不可能的. 因此, 可能需要创建很多不同 ttl 的 delay_queue 才能满足业务需要.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-23"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-23"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在准备延迟消息面试的时候, 需要先弄清楚公司内部的一些情况.")]),_._v(" "),v("ul",[v("li",[_._v("你所在公司"),v("strong",[_._v("有没有使用延迟消息")]),_._v("的场景?")]),_._v(" "),v("li",[_._v("你所在公司的"),v("strong",[_._v("消息中间件支不支持延迟消息")]),_._v("?")]),_._v(" "),v("li",[_._v("延迟消息的 QPS 有多高, 消息量有多大? 延迟时间有多长?")])]),_._v(" "),v("p",[_._v("然后, 在面试中聊到下面这些话题的时候, 可以尝试把话题引导到这里.")]),_._v(" "),v("ul",[v("li",[_._v("如果你介绍你的业务的时候, 提到了需要延迟消息的场景, 就像订单超时取消的例子, 那么就可以深入讨论延迟消息是怎么实现的.")]),_._v(" "),v("li",[_._v("如果聊到了 Kafka, 在介绍它的优缺点的时候, 可以说一说它的缺点, 就是不支持延迟队列, 那么面试官就会问你如果要 Kafka 支持延迟队列应该怎么做.")]),_._v(" "),v("li",[_._v("如果聊到了你们公司使用的消息队列不是 Kafka, 那么同样可以尝试引导到这里, 比如说强调当初你们 MQ 技术选型的时候, 考虑到 Kafka 不支持延迟消息, 所以最终没有选择 Kafka.")])]),_._v(" "),v("h5",{attrs:{id:"基础思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础思路"}},[_._v("#")]),_._v(" 基础思路")]),_._v(" "),v("p",[_._v("这里给出了很多比较简单的方案, 可以从这些方案里选择一个作为公司的方案, 其他方案你就作为自己了解但是没有实践过的方案.")]),_._v(" "),v("h6",{attrs:{id:"利用定时任务调度"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#利用定时任务调度"}},[_._v("#")]),_._v(" 利用定时任务调度")]),_._v(" "),v("p",[_._v("利用定时任务来实现延迟消息是最好, 最简单的办法. 对于一个延迟消息来说, 一个延迟到 30 分钟后才可以被消费的消息, 也可以认为是 30 分钟后才可以发送. 也就是可以设定一个定时任务, 这个任务会在 30 分钟后把消息发送到消息服务器上.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c70beb212c1773a0d6ae4cdbec908067-20231223175002-yhij0ty.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以这么介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("最简单的做法就是利用定时任务, 最好是解决了持久化的分布式任务平台. 那么业务发送者就相当于注册一个任务, 这个任务就是在 30 分钟之后发送一条消息到 Kafka 上. 之后业务消费者就能够消费了.")])]),_._v(" "),v("p",[_._v("同时还可以阐述一下这个方案的缺点.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案的最大缺点是支撑不住高并发. 这是因为绝大多数定时任务中间件都没办法支撑住高并发, 大数据的定时任务调度, 所以只有应用规模小, 延迟消息也不多的话, 才可以考虑使用这个方案. 如果想要支持高并发, 大数据的延迟方案, 还是要考虑利用消息队列.")])]),_._v(" "),v("p",[_._v("最后一句话是为了把话题重新拉回消息队列这里, 并且阐述下面这个方案.")]),_._v(" "),v("h6",{attrs:{id:"分区设置不同延迟时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区设置不同延迟时间"}},[_._v("#")]),_._v(" 分区设置不同延迟时间")]),_._v(" "),v("p",[_._v("这种方案应该算是很简单, 而且也很好用的方案. 可以看一下它的基本架构图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/966ba2212123df97e89a64cee30c6f27-20231223175002-1ju8vp0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里关键的角色是 "),v("strong",[_._v("delay_topic 和延迟消费组")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("delay_topic 里面的分区被用来接收不同延迟时间的消息")]),_._v(". 比如上图中分成了 p0, p1, p2 三个分区, 分别用于接收延迟时间为 1min, 3min 和 10min 的消息.")]),_._v(" "),v("li",[_._v("延迟消费组会创建出和分区数量一样的消费者, 每一个消费者消费一个分区. 消费者每次读取一个消息, 等延迟足够长的时间之后, 就会转发给 biz_topic.")])]),_._v(" "),v("p",[_._v("因此对于业务发送者来说, 他们需要根据自己的延迟时间来选择正确的分区. 而业务消费者则是对整个过程是无感的, 也就是说他们并不知道中间有延迟消费者在做转发的事情.")]),_._v(" "),v("p",[_._v("所以可以简单介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司用的方案是比较简单的, 也就是创建了一个 delay_topic, 这个 topic 有 N 个分区, 每个分区设定了不同的延迟时间. 然后创建了一个消费组去消费这个 delay_topic, 每个分区有一个独立的消费者. 每个消费者在读取到一条消息之后, 就会根据消息里面的延迟时间来等待一段时间. 等待完之后, 再把消息发送到业务方真正的 topic 上.")])]),_._v(" "),v("p",[_._v("注意, 这个 N 很灵活, 给你两个选择.")]),_._v(" "),v("ul",[v("li",[_._v("5 个分区: 延迟时间分别是 1min, 3min, 5min, 10min, 30min.")]),_._v(" "),v("li",[_._v("10 个分区: 延迟时间分别是 1min, 3min, 5min, 10min, 15min, 30min, 60min, 90min, 120min, 180min.")])]),_._v(" "),v("p",[_._v("总体来说 N 就是一个根据业务来设计的东西.")]),_._v(" "),v("p",[_._v("接下来就是刷亮点的地方了, 第一个就是 rebalance 问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1：rebalance问题")])]),_._v(" "),v("p",[_._v("在这个方案中, 因为消费者睡眠了, 睡眠期间不会消费消息, "),v("strong",[_._v("所以 Kafka 就会判定这个消费者已经崩溃了, 就会触发 rebalance")]),_._v(". 发生 rebalance 之后, 等消费者再恢复过来, 就不知道又会被分配到哪个分区, 那么之前的睡眠就可以认为是白睡了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5edc1d0f01fc70cf287b5eaa3c0be0d3-20231223175002-1qihboy.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了避免这个问题, 就需要确保在睡眠期间不会触发 rebalance. 因此需要利用 Kafka 的暂停(Pause)功能, 在睡眠结束之后, 再恢复(Resume). 注意, Kafka 的暂停功能相当于拉取 0 条数据, 并不是说不拉数据, 也就是说还是会发起 Poll 调用.")]),_._v(" "),v("p",[_._v("所以整体逻辑就是这样的:")]),_._v(" "),v("ol",[v("li",[_._v("拉取一条消息, 假如说 offset = N, 查看剩余的延迟时间 t.")]),_._v(" "),v("li",[_._v("暂停消费, 睡眠一段时间 t.")]),_._v(" "),v("li",[_._v("睡眠结束之后, 恢复消费, 继续从 offset = N 开始消费.")])]),_._v(" "),v("p",[_._v("如果面试官没有做过类似的事情的话, 可能想不到这里还有坑, 所以建议主动补充说明, 关键词是 "),v("strong",[_._v("rebalance")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案里面, 要注意一个 rebalance 的问题. 因为每次拉取到消息之后, 都要根据消息的剩余延迟时间, 睡眠一段时间. 在这段时间之内, Kafka 会认为消费者已经崩溃了, 从而触发 rebalance. 等睡眠结束之后, 重新消费, 就不一定还是消费原本的那个分区了.")]),_._v(" "),v("p",[_._v("所以为了避免这个问题, 在睡眠之前, 要暂停消费, 恢复之后重新消费. 重新消费的时候, 要注意把 offset 重置为之前拉取那个消息的 offset.")])]),_._v(" "),v("p",[_._v("这时还可以进一步刷亮点, 就是暂停的时候还是会发出 Poll 调用, 只不过不会真的把数据从服务端拉到消费者那里.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 的暂停消费, 并不是不再发起 Poll 请求, 而是 Poll 了但是不会真的拉消息. 这样可以让 Kafka 始终认为消费者还活着.")])]),_._v(" "),v("p",[_._v("这个 rebalance 问题还是不太容易想到, 但是一致性问题, 面试官就很容易想到了.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2：一致性问题")])]),_._v(" "),v("p",[_._v("前面说的最后几个步骤是从服务端拉取到消息, 然后转发到 biz_topic 里面. 那应该意识到这里面涉及到了一个关键问题, 是先提交消息, 还是先转发?")]),_._v(" "),v("p",[_._v("如果是先提交, 那么就会出现消息提交了, 但是还来不及转发 biz_topic 就宕机的情况, 这显然不能容忍.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b1dd9f1cf49c9262961b24ccfc93d9be-20231223175002-5a0u3jy.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是如果先转发 biz_topic, 然后提交. 那如果提交之前宕机了, 后面恢复过来, 又会转发一次. 好在多发一次并不是什么问题, 因为可以要求业务消费者确保自己的逻辑是幂等的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/847d5581d890acc4ab0705a3e2fb1a70-20231223175002-6njc5an.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("其实, 即便是非延迟消息, 还是需要消费者保证自己的逻辑是幂等的. 因为本身发送者就存在重复发送的可能, 不然没办法确保消息一定投递到 消息服务器上.")]),_._v(" "),v("p",[_._v("面试官很可能会问这个一致性的问题, 那么就可以抓住关键词 "),v("strong",[_._v("后提交")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("一致性的问题解决起来需要业务方的配合. 我们这个的逻辑是到了延迟时间, 就先转发 biz_topic, 然后再提交. 也就是说, 如果在转发 biz_topic 之后, 提交失败了, 下一次就还可以重试, 那么 biz_topic 就可能收到两条同样的消息. 在这种场景下, 就只能要求消费者做到幂等. 当然, 即便不用延迟消息, 消费者最好也要做到幂等的. 因为发送方为了确保发送成功, 本身就可能重试.")])]),_._v(" "),v("p",[_._v("这个回答可能把话题引申到如何做幂等, 后面会有一个高级方案, 这里就不多说了.")]),_._v(" "),v("blockquote",[v("p",[_._v("优缺点分析")])]),_._v(" "),v("p",[_._v("在回答完前面的两个亮点之后, 要分析一下这个方案的优缺点.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案最大的优点就是足够简单, 对业务方的影响很小, 业务方只需要根据自己的延迟时间选择正确的分区就可以了.")])]),_._v(" "),v("p",[_._v("不过这个方案也有两个突出的缺点, 就是"),v("strong",[_._v("延迟时间必须预先设定好, 分区间负载不均匀")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案的缺点其实还挺严重的. 第一个是延迟时间必须预先设定好, 比如只能允许延迟 1min, 3min 或者 10min 的消息, 不支持随机延迟时间. 在一些业务场景下, 需要根据具体业务数据来计算延迟时间, 那么这个就不适用了.  第二个是分区之间负载不均匀. 比如很多业务可能只需要延迟 3min, 那么 1min 和 10min 分区的数据就很少. 这会进一步导致一个问题,  就是负载高的分区会出现消息积压的问题.")]),_._v(" "),v("p",[_._v("在这里, 很多解决消息积压的手段都无法使用, 所以只能考虑多设置几个延迟时间相近的分区, 比如说在 3min 附近设置 2min30s, 3min30s 这种分区来分摊压力.")])]),_._v(" "),v("p",[_._v("这里会把话题引导到消息积压如何解决的问题上, 这个在后面会讲到. 同时又可以把话题引导到亮点方案里, 就是如何实现随机延迟时间.")]),_._v(" "),v("h5",{attrs:{id:"基于mysql的亮点方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基于mysql的亮点方案"}},[_._v("#")]),_._v(" 基于MySQL的亮点方案")]),_._v(" "),v("p",[_._v("如果在实践中, 我会劝你放弃支持随机延迟时间. 因为绝大多数情况下, 业务是用不着非得随机延迟时间的, 完全可以通过调整业务来适配固定的几个延迟时间. 不过在面试中, 还是需要利用一下支持随机延迟时间来进一步加深面试官对你的印象.")]),_._v(" "),v("p",[_._v("可以看一下基于 MySQL 方案的基本架构图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/39c3c328e69d641ede4496df15921f02-20231223175002-3u10lb6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个方案里面的关键点是"),v("strong",[_._v("创建一个 delay_topic, 业务发送者把消息发送到这个 topic 里面, 消息里面带上了需要延迟的时间")]),_._v(". 里面有一个延迟消费者, 它会消费 delay_topic 里面的消息, 转储到数据库中. 还有一个延迟发送者, 它会轮询数据库里的消息, 把已经可以转发出去的消息转发到真正的 biz_topic 上. 发送完之后, 延迟发送者把数据库的状态更新成已发送. 最后业务消费者消费 biz_topic.")]),_._v(" "),v("p",[_._v("这个方案在落地的时候, 要想支撑住高并发, 还是一个比较麻烦的事情, 所以"),v("strong",[_._v("怎么支撑住高并发就是关注点.")])]),_._v(" "),v("p",[_._v("在前面的基本架构里面, 最明显的性能瓶颈就是 MySQL, 因为这个场景是一个写密集的场景. 所以要想撑住高并发就要想办法提高 MySQL 的性能. 当然最佳的策略还是换一个存储结构, 比如说换 TiDB 或者 Elasticsearch. 不过要是回答换一种存储结构, 那就没办法刷出亮点了. 使用 MySQL 的话, 就可以从分区表, 表交替, 分库分表, 批量操作几个方案里面选择.")]),_._v(" "),v("h6",{attrs:{id:"分区表-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区表-2"}},[_._v("#")]),_._v(" 分区表")]),_._v(" "),v("p",[_._v("最简单的优化方案, 就是在 MySQL 上应用分区. 因为延迟消息是一个时效性很强的数据, 也就是完全可以按照发送时间, 也就是延迟之后具体的发送时间点来分区. 在并发不是很高的时候, 可以按照周来分区. 在并发很高的时候, 可以按照天来分区. 历史分区可以及时清理掉, 因为用不上了.")]),_._v(" "),v("p",[_._v("你这么回答:")]),_._v(" "),v("blockquote",[v("p",[_._v("要想提高 MySQL 的性能, 一个比较简单的做法是使用分区表, 比如说根据并发量选择按月分, 按周分, 按天分. 历史分区就可以直接清理掉.")])]),_._v(" "),v("p",[_._v("与分区表类似的解决方案, 还有表交替方案.")]),_._v(" "),v("h6",{attrs:{id:"表交替"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#表交替"}},[_._v("#")]),_._v(" 表交替")]),_._v(" "),v("p",[_._v("表交替要复杂一点, 但是也很好用. 表交替的意思是准备两个表, 然后交替写, 交替查询. 比如今天用 tab_0, 明天用 tab_1. 当用 tab_1 的时候就可以直接清空(TRUNCATE)tab_0 的数据, 反过来也是这样. 这种按天交替的方案对延迟时间是有限制的, 延迟时间不能超过一天.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/45ff4ff8be3946a632da084fd5785fb5-20231223175002-o0vpfio.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("还可以考虑使用表交替方案, 也就是说准备两个表 tab_0, tab_1. 那么最开始的时候可以读写 tab_0, 然后换成读写 tab_1. 每次交替的时候, 都可以把之前使用的数据 TRUNCATE 掉. TRUNCATE 本身很快, 所以没什么性能问题.")])]),_._v(" "),v("h6",{attrs:{id:"分库分表-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表-2"}},[_._v("#")]),_._v(" 分库分表")]),_._v(" "),v("p",[_._v("前面两个方案实际上就能撑住比较高的并发了, 但是要想进一步提高并发能力, 就只能考虑分库分表了, 毕竟单一的库再怎么分区或者交替都存在写瓶颈.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果并发确实非常高, 那么就只能考虑采用分库分表的方案了. 这里分库分表也很简单, 只需要按照 biz_topic 的名字来分库分表就可以了. 而且每一张表可以叠加前面的分区表和交替表的方案, 进一步提高性能.")])]),_._v(" "),v("p",[_._v("不过这个方案也有一定的隐患, 第一个问题就是不同 topic 的并发度不一样, 比如说 biz_topic_1 的并发只有 100, 而 biz_topic_2 的并发有 10000, 那么按照 biz_topic 来分, 就会出现不同库不同表的压力差异很大的问题.")]),_._v(" "),v("p",[_._v("在这种情况下, 可以回答关键词 "),v("strong",[_._v("轮询插入")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("如果不考虑消息有序性的问题, 那么也可以考虑轮询. 比如说分库分表是 4 * 8 = 32 张表, 那么就可以要求每一个延迟消费者, 轮流往这些表里插入数据. 因为延迟消息有一个很显著的特点, 就是查找的时候只会按照发送时间来找, 所以随机插入都没问题.")])]),_._v(" "),v("p",[_._v("这个可能难以理解, 举个例子, 比如有一个消息发送给 biz_topic_1, 要求是一分钟后发出去. 那么不管这个消息被存在哪个表, 延迟发送者都可以找出来, 然后转发到 biz_topic_1.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6ae7d6fd200bb1eb1f7d9e90cd3c58fe-20231223175002-0dchc6q.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然你的回答也引到了另一个亮点, 就是消息有序性.")]),_._v(" "),v("blockquote",[v("p",[_._v("要想做到延迟消息有序性, 有一个比较简单的方案. 在分库分表的时候, 确保同一个 biz_topic 的消息都落到同一张表里面. 并且最开始发送到 delay_topic 上也是按照 biz_topic 的名字来选择分区的, 那么就可以保证延迟消息转发到 biz_topic 上跟它们被发送到 delay_topic 上是一样的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/53b3c70cd46cab2f17a0f981e50e57e5-20231223175002-c44v4v9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("到这里, 还剩下一个可以同时在延迟消费者和延迟发送者上使用的策略: "),v("strong",[_._v("批量操作")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"批量操作"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批量操作"}},[_._v("#")]),_._v(" 批量操作")]),_._v(" "),v("p",[_._v("这个也非常简单, 而且性能会有大幅提升. 简单来说, 就是"),v("strong",[_._v("批量插入, 批量更新")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("还可以利用批量操作来减轻 MySQL 的压力. 对于延迟消费者来说, 它可以消费了一批数据之后再批量插入到数据库里面, 然后再提交这一批消息. 对于延迟发送者来说, 当发送了一批数据之后, 再批量把这些消息更新为已发送.")])]),_._v(" "),v("p",[_._v("那么你可能注意到, 这个批量操作会使数据一致性问题更加严重.")]),_._v(" "),v("p",[_._v("但是这个方案类似于分区设置不同延时时间方案, 只需要消费者做到幂等就可以了. 本质上, 这里的一致性问题要么是因为延迟消费者重复消费, 要么就是因为延迟发送者重复发送. 但不管是哪个原因, 消费者幂等都可以解决问题.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-22"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-22"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节的内容, 消息队列有两个基本的延迟消息解决方案: "),v("strong",[_._v("利用定时任务调度和分区设置不同延迟时间")]),_._v(". 在为分区设置不同的延迟时间时, 要注意 rebalance 和一致性的问题.")]),_._v(" "),v("p",[_._v("最后给出了一个基于 MySQL 的亮点方案. 要记住里面的四个关键点: "),v("strong",[_._v("分区表, 表交替, 分库分表, 批量操作")]),_._v(". 这里强调一下分库分表, 因为本身它也是一个高级话题, 所以把延迟消息和分库分表结合在一起去面试, 优势显著.")]),_._v(" "),v("p",[_._v("当然, 如果本身不是使用 Kafka 的, 这些方案也是有参考价值的. 比如 RabbitMQ, 但是 RabbitMQ 已有的插件缺陷太多, 你完全可以使用后面描述的 MySQL 方案做一个类似的插件出来.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3ff0d0d408e4520a1e2c0e9a40303562-20231223175002-8ujxbw8.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_24-消息顺序-保证消息有序-一个topic只能有一个partition吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_24-消息顺序-保证消息有序-一个topic只能有一个partition吗"}},[_._v("#")]),_._v(" 24-消息顺序:保证消息有序,一个topic只能有一个partition吗?")]),_._v(" "),v("p",[_._v("今天接着学习消息队列的新主题--"),v("strong",[_._v("有序消息")]),_._v(".")]),_._v(" "),v("p",[_._v("在消息队列的相关的面试里面, "),v("strong",[_._v("有序消息和消息不丢失, 消息重复消费")]),_._v("是三个并列的面试热点, 同时在实践中也很容易遇到要求使用有序消息的场景. 但是大部分人在面试的时候, 无法深入透彻地讨论这个问题. 大多数时候, 只能说出 topic 只能有一个分区这种最简单的方案. 当面试官追问这种方案有什么缺陷的时候就开始答不上来了.")]),_._v(" "),v("p",[_._v("所以今天就深入了解有序消息的方方面面, 深挖解决方案的缺陷以及对应的改进策略.")]),_._v(" "),v("h5",{attrs:{id:"消息在分区上的组织方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息在分区上的组织方式"}},[_._v("#")]),_._v(" 消息在分区上的组织方式")]),_._v(" "),v("p",[_._v("在 Kafka 中, 消息是"),v("strong",[_._v("以分区为单位进行存储")]),_._v("的. 分区是逻辑上的概念, 用于对消息进行水平划分和并行处理. 每个 topic 都可以被划分为一个或多个分区, 每个分区都是一个"),v("strong",[_._v("有序, 不可变")]),_._v("的消息日志.")]),_._v(" "),v("p",[v("strong",[_._v("Kafka 使用 WAL (write-ahead-log)日志来存储消息. 每个分区都有一个对应的日志文件, 新的消息会被追加到文件的末尾, 而已经加入日志里的消息, 就不会再被修改了")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73ef185e2011f444026cff4d140caf70-20231223175002-9okaht2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("每个消息在分区日志里都有一个"),v("strong",[_._v("唯一的偏移量(offset)")]),_._v(" , 用来标识消息在分区里的位置. "),v("mark",[v("strong",[_._v("Kafka 保证同一分区内的消息顺序, 但不保证不同分区之间的顺序")])]),_._v(".")]),_._v(" "),v("p",[_._v("而 Kafka 本身暴露了对应的接口, 也就是可以显式地指定消息要发送到哪个分区, 也可以显式地指定消费哪个分区的数据.")]),_._v(" "),v("h5",{attrs:{id:"什么是有序消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么是有序消息"}},[_._v("#")]),_._v(" 什么是有序消息?")]),_._v(" "),v("p",[_._v("在消息队列里面, "),v("strong",[_._v("有序消息是指消费者消费某个 topic 消息的顺序, 和生产者生产消息的顺序一模一样, 它也叫做顺序消息")]),_._v(".")]),_._v(" "),v("p",[_._v("Kafka 并"),v("strong",[_._v("不能保证不同分区之间的顺序")]),_._v(". 也就是说, 如果业务上有先后顺序的消息被发送到不同的分区上, 那就难以确定哪一个消息会先被消费.")]),_._v(" "),v("p",[_._v("需要注意一点语义上的差别, 这里说生产者生产消息的顺序, 不是指创建出来消息那个实例的先后顺序, 而是"),v("strong",[_._v("指 broker 收到的顺序")]),_._v(". 比如有两个生产者, 一个生产者先生产了 msg1, 另外一个生产者生产了 msg2, 但是 msg2 先发到了 broker 上. 那么实际上认为 msg2 是先于 msg1 的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2682e2f251a64e06e24ae7012337e8f7-20231223175002-62lkia7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果要求的是两个生产者, 一个生产者一定要先于另外一个生产者发送一条消息, 那么这实际上已经超出了消息队列要解决的问题的范畴了, 它属于在分布式环境下如何协调不同节点按照先后顺序执行一定的步骤这个问题范畴. "),v("strong",[_._v("有序消息强调的是某个 topic 内, 而不是跨 topic 的有序消息")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"跨topic的有序消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#跨topic的有序消息"}},[_._v("#")]),_._v(" 跨topic的有序消息")]),_._v(" "),v("p",[_._v("不过有些时候可能因为业务特征或者历史问题, 业务会要求"),v("strong",[_._v("在不同的 topic 之间也保证消息是有序")]),_._v("的. 比如说 msg1 先发送到了 topic_a 上, msg2 被发送到了 topic_b 上. 但是在业务层面上, 要求 msg1 一定要先于 msg2 消费.")]),_._v(" "),v("p",[_._v("这种场景在"),v("strong",[_._v("事件驱动的架构")]),_._v("中更加常见. 在复杂的事件驱动架构下, 可能会倾向于使用不同的 topic 来代表不同的事件, 那么就会遇到要求在不同的 topics 下消息依旧需要保持有序的问题.")]),_._v(" "),v("p",[_._v("这一类的问题是"),v("strong",[_._v("不能依赖于消息队列来解决的")]),_._v(". 要想支持这种跨 topic 的有序消息, 一定要"),v("mark",[v("strong",[_._v("引入一个协调者, 这个协调者负责把消息重组为有序消息")])]),_._v(". 比如如果 msg2 先到了, 但是 msg1 还没出来, 那么这个协调者要有办法让 msg2 的消费者 B 停下来, 暂时不消费 msg2. 而在 msg1 来了之后, 唤醒消费者 A 消费 msg1, 并且在消费完 msg1 之后要再唤醒消费者 B 处理 msg2.")]),_._v(" "),v("p",[_._v("这是一个全新的话题, 面试基本上不会出现这一类问题, 心中有个基本的概念就可以了.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-24"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-24"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在准备面试的时候, 需要了解一下公司内部使用有序消息的情况.")]),_._v(" "),v("ul",[v("li",[_._v("在什么业务场景下, 需要用到有序消息?")]),_._v(" "),v("li",[_._v("你是如何解决有序消息这个问题的? 用的是哪种方案?")]),_._v(" "),v("li",[_._v("如果你用的是"),v("strong",[_._v("单分区")]),_._v("解决方案, 那么有没有消息积压问题? 如果有, 你是怎么解决的?")]),_._v(" "),v("li",[_._v("如果你用的是多分区解决方案, 那么有没有分区负载不均衡的问题? 如果有, 你是怎么解决的?")])]),_._v(" "),v("p",[_._v("可以在简历介绍技能的部分或者项目部分点出你解决过消息有序性的问题. 基本上只要介绍到了, 面试官就肯定会问这方面的问题.")]),_._v(" "),v("p",[_._v("如果自己在实践中真的用了全局有序的单分区解决方案, 但是业务层面上其实并不要求全局有序, 那么可以尝试使用一下多分区解决方案. 这样一来就会对两个方案有非常深入的理解, 也能把握更多细节.")]),_._v(" "),v("p",[_._v("除此之外, 如果面试官问到了这些问题, 也可以把话题引导到"),v("strong",[_._v("有序消息")]),_._v("这个话题上.")]),_._v(" "),v("ol",[v("li",[_._v("增加分区的问题, 后面的多分区方案专门讨论了增加分区可能带来的消息失序的问题.")]),_._v(" "),v("li",[_._v("Redis 的槽和槽分配.")]),_._v(" "),v("li",[_._v("负载均衡, 记得回答一致性哈希, 然后把话题引导到利用一致性哈希来解决多分区数据分布不均匀的问题.")]),_._v(" "),v("li",[_._v("消息积压的问题, 可以把话题引导到单分区方案和多分区方案上.")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-17"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-17"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("前面里面已经说了 Kafka 分区是如何存储数据的. 所以很容易就猜到第一个解决方案, 就是"),v("strong",[_._v("每一个 topic 只使用一个分区, 也就是所谓的单分区解决方案")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d5b8898e6905940312cedee64fa7e523-20231223175002-luerix8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以简单介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("要保证消息有序, 最简单的做法就是让特定的 topic 只有一个分区. 这样所有的消息都发到同一个分区上, 那么自然就是有序的.")])]),_._v(" "),v("p",[_._v("这个方案的优点是简单, 并且是全局有序. 但是这个方案有一个很严重的问题: "),v("strong",[_._v("性能太差")]),_._v(". 因为一个 topic 只有一个分区, 它就没办法支撑高并发.")]),_._v(" "),v("p",[_._v("所以可以在回答中补充这一点, 关键词是"),v("strong",[_._v("性能差")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种只有一个分区的方案性能差, 没办法支撑高并发. 对于生产端来说, 所有的消息都在一个分区上, 也同时意味着所有的消息都发送到了同一个 broker 上, 这个服务器很可能撑不住压力; 对于消费端来说, 只有一个分区, 那么就只能有一个消费者消费, 很容易出现消息积压的问题.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/377e7d99d997ea28f29e7ce17fd232b3-20231223175002-fv2g6cw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("既然说了这个点, 自然就是为了引出改进方案. 不过改进方案都有一个基本的前提, "),v("strong",[_._v("消息需要保持有序, 但不是全局有序, 而是同一个业务内有序")]),_._v(".")]),_._v(" "),v("p",[_._v("如果业务要求的是全局有序, 那就没什么优化手段, 只能是换用更加强大的机器. 但设想一下真实的业务场景, 大部分业务强调的有序是全局有序吗? 并不是, 而是"),v("mark",[v("strong",[_._v("业务内有序")])]),_._v(". 比如在下单的场景下, 会产生创建订单消息和完成支付消息. "),v("mark",[v("strong",[_._v("业务上只会要求同一个订单的创建订单消息应该优先于完成支付消息")])]),_._v(", 但是不会要求订单 A 的创建消息需要先于订单 B 的支付消息.")]),_._v(" "),v("p",[_._v("所以可以先暂时澄清一下同一个业务内有序的概念, 然后引出优化方案.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("如果要求的是全局有序, 那除了换更加强大的机器就没别的办法了. 而事实上, 大部分的业务场景要求的都不是全局有序, 而是业务内有序")]),_._v(". 例如要求同一个订单创建订单的消息应该先于完成支付消息, 但是不会要求不同订单之间的消息是有序的. 在这种场景下, 可以使用多分区方案.")])]),_._v(" "),v("h5",{attrs:{id:"亮点方案-多分区"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-多分区"}},[_._v("#")]),_._v(" 亮点方案:多分区")]),_._v(" "),v("p",[_._v("这个方案在面试的时候也有一些人能回答出来, 但是很少有人能够深入讨论这个方案的潜在问题和对应的解决方案, 所以这也就是你拉开差距的地方.")]),_._v(" "),v("p",[_._v("第二个方案就是原本"),v("strong",[_._v("同一个业务的消息发送到同一个队列, 这里是同一个业务的消息要发送到同一个分区")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("多分区方案就是直接扩展为使用多个分区, 只需要确保同一个业务的消息发送到同一个分区就可以保证同一个业务的消息是有序的")]),_._v(".")])]),_._v(" "),v("p",[_._v("面试官自然就会追问, 怎么保证同一个业务的消息必然发送到同一个分区呢? 做法也很简单, 只需要生产者在发送消息的时候, "),v("strong",[_._v("根据业务特征, 比如说业务 ID 计算出目标分区, 在发送的时候显式地指定分区就可以了")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ed75cffc180df3eccf3dbfe1f0977880-20231223175002-q5xluc6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里抓住关键词 "),v("strong",[_._v("计算分区")]),_._v(" 回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("要想确保同一个业务的消息都发送到同一个分区, 那么只需要发送者自己根据业务特征, 直接计算出来一个目标分区. 比如说最简单的策略就是根据业务 ID 对分区数量取余, 余数就是目标分区.")])]),_._v(" "),v("p",[_._v("所有方案都有优缺点, 这个方案也不例外. 它的优点是足够简单, 业务方需要做的改动很小. 但是缺点有两个, "),v("mark",[v("strong",[_._v("一个是数据不均匀, 另一个是增加分区可能导致消息失序")])]),_._v(".")]),_._v(" "),v("p",[_._v("先来看第一个缺点.")]),_._v(" "),v("h6",{attrs:{id:"数据不均匀"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据不均匀"}},[_._v("#")]),_._v(" 数据不均匀")]),_._v(" "),v("p",[_._v("这个缺点很容易理解, 因为发送方要按照"),v("strong",[_._v("业务特征")]),_._v("来选择分区, 自然就容易"),v("strong",[_._v("导致一些分区有很多数据, 而另外一些分区数据很少")]),_._v(". 而如果某个分区有很多数据的话, 消费者来不及消费也是正常的事情.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1621e78eafde1138214b080ba3974579-20231223175002-m551gm8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("数据不均匀一般是业务造成的. 在我们的方案里面, 分区是根据业务特征来选择的, 那么自然有一些分区有很多数据, 有一些分区数据很少. 比如说万一不小心把热点用户的消息都发到了同一个分区里面, 那么这个分区的 QPS 就会很高, 消费者也不一定来得及消费, 就可能引起消息积压.")])]),_._v(" "),v("p",[_._v("怎么解决这个问题呢?")]),_._v(" "),v("blockquote",[v("p",[_._v("要想解决这个问题, "),v("mark",[_._v("可以通过改进计算目标分区的方式来解决, 比如说采用类似于 Redis 中槽和槽分配的机制, 又或者说一致性哈希算法")]),_._v(", 基本上就能解决这个问题了.")])]),_._v(" "),v("p",[_._v("这两个解决思路, 建议不要等面试官追问, 而是自己直接接着说, 因为到这里讨论的深度大概率已经超出了一般面试官的经验范畴了, 所以他们可能想不到该怎么问你.")]),_._v(" "),v("blockquote",[v("p",[_._v("数据不均匀解决方案1：槽与槽分配")])]),_._v(" "),v("p",[_._v("这种解决方案的基本思路就是借鉴 Redis 的数据分布方案. "),v("mark",[v("strong",[_._v("可以根据业务特征计算一个哈希值, 然后映射到槽上")])]),_._v(". 这里可以参考 Redis, 使用 16384 个槽, 不过如果业务体量不是那种几百万 QPS 的, 用 1024 个槽就可以.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("再通过指定不同的槽把数据分配到不同的分区上, 这个时候就可以根据业务特征合理分配槽, 从而保证分区之间数据分布是均匀的")])]),_._v(".")]),_._v(" "),v("p",[_._v("整个架构如图:")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9c0e58fe55c8b65d4c2b28f836971393-20231223175002-ty95030.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("抓住关键词 "),v("strong",[_._v("槽")]),_._v(" 回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("第一种思路是借鉴 Redis 的槽与槽分配方案. 不过 Redis 使用了 16384 个槽, 一般的业务用不上那么多槽, 所以可以考虑用 1024 个槽. 根据业务的特征来计算一个哈希值, 再除以 1024 取余就可以得到所在的槽. 再根据不同槽的数据多少, 合理地把槽分配到不同的分区. 最好把槽和分区的绑定关系做成"),v("mark",[_._v("动态")]),_._v("的, 也就是说可以随时调整槽到分区的映射关系, 保证所有的分区负载都是均匀的.")])]),_._v(" "),v("p",[_._v("最后提到的动态调整槽与分区的绑定关系, 可以借助于"),v("strong",[_._v("配置中心")]),_._v("来完成. 比如最开始把槽 1 绑定到分区 2 上, 后面在运行的时候发现分区 2 数据太多, 就把槽 1 重新绑定到了分区 3 上.")]),_._v(" "),v("p",[_._v("当然, 因为这个回答的核心是借鉴了 Redis, 那么就有可能把话题引导到 Redis 那里.")]),_._v(" "),v("p",[_._v("但是这个过程还是有问题的, 可能会引起"),v("strong",[_._v("消息失序")]),_._v(", 和增加新的分区指向了同一个问题. 所以可以参考增加分区引起消息失序部分来回答. 接下来再来看看一致性哈希是怎么解决问题的.")]),_._v(" "),v("blockquote",[v("p",[_._v("数据不均匀解决方案2：一致性哈希")])]),_._v(" "),v("p",[_._v("在这里使用哈希一致性算法, 就是"),v("strong",[_._v("把分区分散在哈希环上")]),_._v(". 可以根据"),v("strong",[_._v("业务特征")]),_._v("计算出一个哈希值之后, 根据哈希值在这个环上找到合适的分区, 然后把消息发送过去. 只要通过"),v("mark",[v("strong",[_._v("调整不同分区之间的间隔, 就能控制分区上的数据分布")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8c9fd7c86f8830ec3aaf542192909271-20231223175002-r23ftup.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一种思路是使用一致性哈希算法来筛选分区. 首先要根据数据分布的整体情况, 把分区分布在哈希环上, 确保每一个分区上的数据分布大体上是均匀的. 如果一部分哈希值上数据较多, 就多插入几个分区节点. 然后根据业务特征计算一个哈希值, 从哈希环上找到对应的分区.")])]),_._v(" "),v("p",[_._v("最后可以进一步总结, 升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种槽分配和一致性哈希算法非常适合解决数据或者流量分布不均匀的问题, 因为我们总是可以通过手工调整槽的映射关系或者哈希环上节点的分布来保证数据或者流量在每一个节点上的分布大体是均匀的.")])]),_._v(" "),v("p",[_._v("到这里已经彻底解决了数据不均匀的问题, 接下来就要讨论增加分区引起消息失序的问题了.")]),_._v(" "),v("h6",{attrs:{id:"增加分区引起消息失序"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#增加分区引起消息失序"}},[_._v("#")]),_._v(" 增加分区引起消息失序")]),_._v(" "),v("p",[_._v("可以结合下面这张图来理解.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/125a0070a6d42117e6bbb5e728d58569-20231223175002-5a30ylq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在面试的时候, 可以先介绍这个缺点, 关键词是"),v("strong",[_._v("增加分区会引起消息失序")]),_._v(", 同时补充一个例子.")]),_._v(" "),v("blockquote",[v("p",[_._v("它还有另外一个缺点, 就是如果中间有增加新的分区, 那么就可能引起消息失序. 比如说最开始 id 为 3 的订单消息 msg1 发到分区 0 上, 但是这时候很不幸分区 0 上积攒了很多消息, 所以 msg1 迟迟得不到消费.")]),_._v(" "),v("p",[_._v("紧接着触发扩容, 增加了一个新的分区. 如果这时候来了一个消息 msg2, 那么它会被转发到分区 3 上. 分区 3 上面没有积攒什么数据, 所以消费者 3 直接就消费了这个消息.")]),_._v(" "),v("p",[_._v("这时候会发现, 本来 msg1 应该先于 msg2 被消费. 而增加分区之后 msg2 反而被先消费了. 这就是一个典型的消息失序场景.")])]),_._v(" "),v("p",[_._v("那么针对这个缺点也可以进一步提出解决方案. 这个消息失序的场景解决起来倒也很简单, 就是"),v("strong",[_._v("新增加了分区之后, 这些新分区的消费者先等一段时间, 比如说三分钟, 确保同一个业务在其他分区上的消息已经被消费了")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("要解决这个问题也很容易. 对于新加入的分区, 可以"),v("mark",[_._v("暂停消费")]),_._v("一段时间. 比如说在前面的例子中, 如果估算 msg1 会在一分钟内被消费, 那么新加入的分区的消费者可以在三分钟后再开始消费. 那么大概率 msg1 就会先于 msg2 消费. 不过这种等待的解决方式并不能解决根本问题, 只能说是很大程度上缓解了问题. 但是本身增加分区也是一个很不常见的操作, 再叠加消息失序的概率也很低, 所以也可以通过监控发现这种失序场景, 然后再手工修复一下就可以了.")])]),_._v(" "),v("p",[_._v("到了这一步, 常规的方案和升级的多分区版本已经聊得差不多了. 最后再教一个面试的小技巧.")]),_._v(" "),v("h5",{attrs:{id:"基于优化的面试思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基于优化的面试思路"}},[_._v("#")]),_._v(" 基于优化的面试思路")]),_._v(" "),v("p",[_._v("刚刚从单分区讨论到多分区, 就是一个关于性能优化的非常好的案例, 如何通过这个案例来让我们的能力更加突出呢? 这里可以利用之前学过的一个面试小技巧, 关键词就是"),v("mark",[v("strong",[_._v("优化")])]),_._v(" "),v("mark"),_._v(" "),v("mark",[v("strong",[_._v("+")])]),_._v(" "),v("mark"),_._v(" "),v("mark",[v("strong",[_._v("前后对比")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始我进公司的时候就遇到了一个 Kafka 的线上故障. 我司有一个业务需要用到有序消息, 所以最开始的设计就是对应的 topic 只有一个分区, 从而保证了消息有序.")]),_._v(" "),v("p",[_._v("可是随着业务增长, 一个分区很快就遇到了性能瓶颈. 只有一个分区, 也就意味着只有一个消费者, 所以在业务增长之后, 就开始出现了消息积压. 另外一方面, 这个分区所在的 broker 的负载也明显比其他服务器要大, 偶尔也会有一些性能抖动的问题.")]),_._v(" "),v("p",[_._v("后来我仔细看了我们的业务, 实际上, 我们的业务要求的不是全局有序, 而是业务内有序.")]),_._v(" "),v("p",[_._v("换句话来说, 不一定非得用一个分区, 而是可以考虑使用多个分区. 所以我就给这个 topic 增加了几个分区, 同时也增加了消费者. 优化完之后, 到目前为止, 还没有出现过消息积压的问题.")])]),_._v(" "),v("p",[_._v("这里应该注意到, 从单个分区增加到多个分区, 还是会出现前面说的消息失序的问题. 建议主动提起这个问题, 展开聊聊应对方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 为了避免在单分区增加到多分区的时候, 出现消息失序的问题, 我用了一个很简单的方案, 就是对应的消费者在启动之后, 并没有立刻消费, 而是停顿了三分钟, 从而避免了潜在的消息失序问题.")])]),_._v(" "),v("p",[_._v("注意, 这里的停顿三分钟的前提是要先把积压的消息消费掉. 如果积压的消息还需要三十分钟, 那这里就至少要停顿三十分钟.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-23"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-23"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节了解了有序消息的基本概念, 还有一个看起来有点接近但是完全不同的话题: 跨 topic 的有序消息. 其中有一个关键问题, 就是消息在分区上是如何组织的, 这里记住 "),v("strong",[_._v("WAL 和分区内有序")]),_._v(" 这两个关键词就可以了.")]),_._v(" "),v("p",[_._v("在这个基础上讨论了最常规的方案, 也就是保证 "),v("strong",[_._v("全局有序的单分区方案")]),_._v(", 并且进一步解释了如果在单分区上消息积压了, 可以通过"),v("strong",[_._v("多分区方案")]),_._v("来解决问题.")]),_._v(" "),v("p",[_._v("这里要记住多分区方案的两个缺陷, 还有应对策略.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("数据不均匀. 对应的解决方案是借鉴 Redis 的槽与槽分配的方案和一致性哈希方案")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("增加分区引起的消息失序. 要解决这个问题也很简单, 就是新增加的分区暂时不要消费, 确保在别的分区上的消息已经被消费完了再消费")]),_._v(".")])]),_._v(" "),v("p",[_._v("RabbitMQ 和 RocketMQ 里面消息有序性的解法也是差不多的. 不同的是, 在 RabbitMQ 里面使用的是 queue, 因为 RabbitMQ 没有分区的概念. 而 RocketMQ 里面内置了有序消息的功能, 底层原理也基本相似.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8yy49b0e01ae1e565c7a4d97c5175c5c-20231223175002-x6lav7x.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_25-消息积压-业务突然增长-导致消息消费不过来怎么办"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_25-消息积压-业务突然增长-导致消息消费不过来怎么办"}},[_._v("#")]),_._v(" 25-消息积压:业务突然增长,导致消息消费不过来怎么办?")]),_._v(" "),v("p",[_._v("今天来学习消息队列中"),v("strong",[_._v("消息积压问题")]),_._v("的解决办法.")]),_._v(" "),v("p",[v("strong",[_._v("消息积压是指消息生产速率大于消费速率, 所以消息会在 broker 上存放着")]),_._v(". 消息积压可能会导致消息要等很久才会被消费, 这对于一些业务来说损害很大. 特别是一些对消息消费时效性有要求的业务, 几乎不能容忍任何程度的消息积压.")]),_._v(" "),v("p",[_._v("消息积压在实践中是一个很容易遇到的问题, 尤其是如果你所在的公司处在快速扩张期. 因为在实践中很常见, 所以在面试中消息积压也是一个热点题目. 而大部分人面试的时候, 只会说增加分区, 又或者说异步消费, 但是很难深入讨论.")]),_._v(" "),v("p",[_._v("其实消息积压的解决方案有很多, 下面一个一个看.")]),_._v(" "),v("h5",{attrs:{id:"消费者和分区的关系"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消费者和分区的关系"}},[_._v("#")]),_._v(" 消费者和分区的关系")]),_._v(" "),v("p",[_._v("在 Kafka 里面, "),v("strong",[_._v("一个分区只能有一个消费者, 但是一个消费者可以同时消费多个分区. 也就是如果有 N 个分区, 那么最多只有 N 个消费者, 这个时候再增加消费者已经不能提高消费速率了. 如果不足 N 个消费者, 那么就会有一些消费者同时从多个分区里面拉取数据")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c9172f4079d1f90eb45d2a99dbab9a41-20231223175002-wrc8zfx.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种设计导致"),v("strong",[_._v("不能无限制地增加消费者来解决消息积压问题")]),_._v(". 反过来说, 但凡没这种限制, 也就没有消息积压这回事了.")]),_._v(" "),v("h5",{attrs:{id:"确定分区数量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#确定分区数量"}},[_._v("#")]),_._v(" 确定分区数量")]),_._v(" "),v("p",[v("strong",[_._v("消息积压也可以看作是分区数量不足引发的问题")]),_._v(", 毕竟如果分区数量多, 就意味着消费者多, 消费者足够就肯定不会产生消息积压的问题. 所以为了避免消息积压, 就要求在使用消息队列的时候想清楚需要几个分区.")]),_._v(" "),v("p",[_._v("最正确的做法就是, 直接用 Kafka 的性能测试脚本, 控制消息的平均大小, 吞吐量, 分区数量和消费者线程数, 执行压测, 得出结论. 不过实践中还是很少用的, 因为在测试环境测了也不一定准, 而且也不敢去生产环境测试. 当然, 如果公司的消息队列团队非常专业, 直接告诉他你预期中的生产者速率, 消息大小和消费者速率就可以了, 他们会创建好分区数量合适的 topic.")]),_._v(" "),v("p",[_._v("除此以外, 确定分区数量目前并没有什么权威说法或者统一标准, 这里给出一个我个人的标准, 可以作为参考.")]),_._v(" "),v("p",[_._v("首先, "),v("strong",[_._v("预估生产者的发送速率")]),_._v(", 这里假设 QPS 是 1000. 然后估算单独一个分区能撑住多大的写流量, 假如说这里 QPS 是 100, 那么至少需要 10 个分区.")]),_._v(" "),v("p",[_._v("其次, "),v("strong",[_._v("预估消费者的消费速率")]),_._v(", 这个时候不要考虑异步消费之类的改进措施, 假设消费速率是 50, 那就需要至少 20 个分区.")]),_._v(" "),v("p",[_._v("通过这两条标准得出的这两个值里取比较大的那个, 也就是用 20 个分区, 或者再多加一两个分区作为余量. 当然这是一种简单粗暴, 方便理解的算法, 但是核心是分区数量要"),v("strong",[_._v("确保生产者不会阻塞, 同时确保消费者来得及消费消息")]),_._v(".")]),_._v(" "),v("p",[_._v("那么单一一个分区能撑住多少写流量该怎么确定呢? 可以通过前面的压测来确定, 也可以通过观测消息集群的性能来确定, 当然最简单的办法就是问消息队列运维团队.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-25"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-25"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要在公司内部收集一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司"),v("strong",[_._v("消息队列的监控有哪些? 可以利用哪些监控指标来确定消息是否积压")]),_._v("?")]),_._v(" "),v("li",[_._v("在发现消息积压的时候, 能不能利用监控的消费速率和生产速率, 来推断多久以后积压的消息会被处理完毕?")]),_._v(" "),v("li",[_._v("你们公司"),v("strong",[_._v("消息积压的真实案例")]),_._v(", 包括故障原因, 发现和定位过程, 最终解决方案.")]),_._v(" "),v("li",[_._v("你负责的业务使用的 topic 还有对应的分区数量.")]),_._v(" "),v("li",[_._v("如果有可能, 去问问你们消息队列团队的人是怎么计算分区数量的.")])]),_._v(" "),v("p",[_._v("可以考虑将消息积压纳入你的高性能面试方案中, 也就是说解决消息积压问题也是优化系统性能的一环. 可以在简历中, 项目介绍中提及自己解决过消息积压的问题, 那么面试官就可能会相关的问题.")]),_._v(" "),v("p",[_._v("此外, 还有一些和消息积压有关的问题.")]),_._v(" "),v("ul",[v("li",[_._v("你的业务 topic 里面用了几个分区? 你是怎么确定分区数量的? 如果分区数量不够会发生什么?")]),_._v(" "),v("li",[v("strong",[_._v("什么情况下会发生消息积压")]),_._v("? 怎么解决消息积压的问题?")]),_._v(" "),v("li",[_._v("在异步消费的时候, 如果拉取了一批消息, 还没来得及提交就宕机了会发生什么?")])]),_._v(" "),v("h5",{attrs:{id:"解决方案-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决方案-2"}},[_._v("#")]),_._v(" 解决方案")]),_._v(" "),v("p",[_._v("这里给出了几个可行的解决方案, 每一个方案都有各自的亮点, 在面试的时候根据自己的实际情况挑选其中的两三个来回答就可以了.")]),_._v(" "),v("p",[_._v("解决消息积压的问题, 首先要区"),v("strong",[_._v("分清楚是临时性积压还是永久性积压")]),_._v(".")]),_._v(" "),v("p",[_._v("所谓的临时性积压是指消费能力是够的, 但是因为突如其来的流量, 导致消费者一时半会跟不上速度而引起的积压. 而永久性积压是指消费者处理能力就是跟不上, 所以"),v("strong",[_._v("积压的消息只会越来越多")]),_._v(".")]),_._v(" "),v("p",[_._v("临时性积压基本上都不需要处理, 因为随着时间流逝, 消费者会慢慢把所有消息都消费完. 但是有一种情况例外, 那就是等不及了. 而等不及则有多种可能, 比如业务要求消费延迟不能超过一分钟, 这时候就要时刻关注消息积压的问题; 又或者发现这一次突如其来的流量太多了, 积攒的消息要好几天才能消费完, 这种情况下多半也无法接受.")]),_._v(" "),v("p",[_._v("所以可以先点出这个问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("消息积压首先要看是临时性积压还是永久性积压. 临时性积压是指突如其来的流量, 导致消费者一时半会跟不上. 而永久性积压则是指消费者的消费速率本身就跟不上生产速率.")]),_._v(" "),v("p",[_._v("如果是临时性积压, 并且评估最终消费者处理完积压消息的时间是自己能够接受的, 那么就不需要解决. 比如说偶发性的消息积压, 需要半个小时才能处理完毕, 而我完全等得起半小时, 就不需要处理.")]),_._v(" "),v("p",[_._v("但要是接受不了, 又或者是永久性积压. 就要尝试解决了. 最简单的办法就是增加消费者, 增加到和分区数量一样. 不过我想大部分人在遇到消息积压问题的时候, 消费者数量都已经和分区数量一样了.")])]),_._v(" "),v("p",[_._v("注意这里假设的都是消费者数量已经和分区数量一样了, 也就是即便再增加消费者也已经没办法提高消费速率了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ddcded8c18b54633ac4df38ee63e774f-20231223175002-b4dky6j.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"增加分区"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#增加分区"}},[_._v("#")]),_._v(" 增加分区")]),_._v(" "),v("p",[_._v("最简单的做法就是"),v("strong",[_._v("增加分区")]),_._v(", 可以稍微提一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一种做法就是增加分区, 比如说直接增加好几个分区.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1c5b1ecb43740ab4a3ea422e93f61681-20231223175002-9h3koup.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("有些时候, 公司或者说消息队列的运维是不准加分区的, 那可以考虑下面这个方案: 创建新的 topic.")]),_._v(" "),v("blockquote",[v("p",[_._v("创建新 topic")])]),_._v(" "),v("p",[_._v("采用这个方案意味着需要准备一个新的 topic, 这个 topic 会有更多的分区. 前期消费老的 topic, 同时也消费新的 topic. 等老的 topic 上的数据都消费完毕之后, 就可以完全切换到新的 topic 了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0ddd8449bc80a92d108b071112fe8846-20231223175002-cjo80ql.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种做法还有一个变种, 就是当创建了新 topic 之后, 把老 topic 上已有的消息转发到这个新的 topic 里面. 这样只需要启动消费者消费新 topic 就可以了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cedb185d31defb9bc07f826ee9a65a9e-20231223175002-bn2342z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个变种的优点就是代码比较容易维护, 但是它也会降低消费积压数据的速度. 不过面试的时候还是可以稍微提一下这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果公司不允许增加分区的话, 那么可以考虑直接创建一个新的 topic. 这时候有两种做法, 一种是直接启动足够数量的消费者去消费新老 topic 上的消息, 在老 topic 上的消息消费完毕之后就可以停掉老的 topic 上的消费者了. 另外一种做法是启动几个消费者, 这些消费者会把老的 topic 上的消息转发到新的 topic 里面. 同时启动消费者消费新的 topic.")])]),_._v(" "),v("blockquote",[v("p",[_._v("相比之下, 第一种做法会更加高效, 但是需要多启动几个消费者.")])]),_._v(" "),v("p",[_._v("这里可以顺势引出另外一个话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过这里的难点都是要计算清楚究竟需要几个分区. 比如原本八个分区不够, 要增加新分区, 那么增加几个? 如果是创建新 topic, 需要几个分区? 它本质上是一个分区数量预估的问题.")])]),_._v(" "),v("p",[_._v("你一提这一句, 大概率面试官就会追问怎么计算需要的新分区的数量. 记住要先"),v("strong",[_._v("强调理论上的最佳做法肯定是通过压测来确定的")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"新的分区数量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#新的分区数量"}},[_._v("#")]),_._v(" 新的分区数量")]),_._v(" "),v("p",[_._v("这里和一般的分区预估有点不太一样, 因为消息积压场景下的瓶颈在于消费者, 也就是不需要考虑生产者速率, 也不需要考虑 broker 的速率, "),v("strong",[_._v("只需要考虑消费者")]),_._v(".")]),_._v(" "),v("p",[_._v("所以最简单的做法就是, "),v("strong",[_._v("用平均生产者速率除以单一消费者的消费速率")]),_._v(". 在涉及数学计算的时候, 要记得使用一个简单例子来帮助面试官理解计算方式.")]),_._v(" "),v("blockquote",[v("p",[_._v("要确定新的分区数量的最简单的做法就是用平均生产者速率除以单一消费者的消费速率.")]),_._v(" "),v("p",[_._v("比如说所有的生产者合并在一起, QPS 是 3000. 而一个消费者处理的 QPS 是 200, 那么 3000 / 200 = 15. 也就是 15 个分区. 进一步考虑业务增长或者突发流量, 可以使用 18 个或者 20 个.")])]),_._v(" "),v("p",[_._v("这里面试官可能会进一步追问, 为什么用平均生产者速率而不是峰值速率? 这是因为本身消息队列就承担着削峰的功能, 所以在业务巅峰可能会有少量的消息积压, 但是这是正常现象, 所以可以不考虑. 当然, 如果有钱有资源, 那么就可以按照生产峰值速率来算.")]),_._v(" "),v("h6",{attrs:{id:"优化消费者性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化消费者性能"}},[_._v("#")]),_._v(" 优化消费者性能")]),_._v(" "),v("p",[_._v("在不能增加消费者数量也不能增加分区数量的时候, "),v("strong",[_._v("还可以考虑提高消费者的消费速率, 也就是优化消费者性能")]),_._v(".")]),_._v(" "),v("p",[_._v("优化的思路大体上有两种.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("把消费者部署在更好的实例上")]),_._v(", 这属于花钱买性能.")]),_._v(" "),v("li",[v("strong",[_._v("优化消费者的消费逻辑")]),_._v(", 这跟业务密切相关, 本质上是一个性能优化的问题.")])]),_._v(" "),v("p",[_._v("我们能够回答的就是第二点, 毕竟第一点是钞能力. 可惜的是, 它毕竟是一个和业务密切相关的话题, 所以只能给一个案例来参考. 也可以自己看看公司内部所有的消费者代码, 找找看有没有可以优化的, 作为面试的真实案例.")]),_._v(" "),v("blockquote",[v("p",[_._v("还有一个思路是"),v("mark",[_._v("优化消费者的性能")]),_._v(". 早期我在公司的时候就优化过消费者的性能. 我们的业务逻辑也不是特别复杂, 但是因为考虑同一个业务的消息可能被不同的消费者消费, 所以"),v("mark",[_._v("在消费消息的时候引入了一个分布式锁")]),_._v(".")]),_._v(" "),v("p",[_._v("但实际上可以通过主动选择目标分区使相同的业务总是把消息发到同一个分区上, 确保同一时间只有一个消费者处理一个业务的消息, 这样就可以把分布式锁去掉. 它带来的好处就是, 当没有分布式锁的时候, 也不会有消费者因为等待分布式锁而导致消费速率下降了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/af9dcfab76f8dac7141f335c721157f8-20231223175002-ricapiv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个案例非常精巧, 它充分结合了消息队列, 分布式锁, 还借鉴了解决有序消息的思路. 所以这个案例不光这里可以用, 在聊起性能优化和分布式锁的时候也可以用.")]),_._v(" "),v("h6",{attrs:{id:"消费者降级"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消费者降级"}},[_._v("#")]),_._v(" 消费者降级")]),_._v(" "),v("p",[_._v("这一次你又接触到了降级. 不过这个降级"),v("strong",[_._v("不是为了保护消费者, 而是为了提高消费速率")]),_._v(". 使用这个方案的前提是业务能接受有损消费消息. 这里可以参考微服务降级部分的内容, 比如说如果业务有快慢路径之分, 那么可以"),v("strong",[_._v("考虑在消息积压的情况下只执行快路径")]),_._v(".")]),_._v(" "),v("p",[_._v("这里就不再重复降级有关的内容, 直接给一个案例更能说明问题, 同样的, 也可以在公司内部找找有没有消费者的逻辑是可以用上这种降级策略的.")]),_._v(" "),v("blockquote",[v("p",[_._v("我也尝试过利用微服务中的降级思路来解决消息积压的问题. 但是这个降级本身并不是为了保护系统, 而是为了加快消费速率. 在之前出现消息积压的场景里面, 消费者的处理逻辑总体上可以认为就是调用几个接口, 计算一个值, 然后放到缓存里面, 缓存过期时间就是 15 分钟. 这些提前计算出来的结果就是给查询接口使用的, 查询接口如果都自己算的话, 性能会比较差.")]),_._v(" "),v("p",[_._v("在不触发降级的时候, 也就是没有消息积压的时候, 就正常算. 但是在消息积压的时候, 如果缓存里面有对应的数据, 那就不算, 否则就重新计算一下. 这种降级逻辑是基于这样一个底层逻辑, 就是如果这个数据本身过期时间是十五分钟, 那么即便不更新, 用户拿到的无非就是十五分钟以内的一个不准确的数据. 这在业务上是可以接受的.")]),_._v(" "),v("p",[_._v("而如果缓存不存在了, 那么就确实需要重新计算一遍, 避免查询接口自己实时计算.")]),_._v(" "),v("p",[_._v("在引入了这种降级策略之后, 大概有 1/3 的消息处理逻辑是被降级的.")])]),_._v(" "),v("p",[_._v("这个案例最大的优点就是, "),v("strong",[_._v("降级并不仅仅是局限在了微服务中, 而是被用在了消息消费上, 它能够体现你对服务治理的深刻理解")]),_._v(", 还有灵活敏锐的思维.")]),_._v(" "),v("h6",{attrs:{id:"聚合消息与批量操作"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#聚合消息与批量操作"}},[_._v("#")]),_._v(" 聚合消息与批量操作")]),_._v(" "),v("p",[_._v("假如现在有一个业务, 是要从数据库里筛选出一批数据, 然后针对每一条数据进行处理. 处理之后, 会发送一条消息到消息队列, 消费者再一条条取出来处理.")]),_._v(" "),v("p",[_._v("这里假设消息的关键字段就是带上业务 ID, 例如 "),v("code",[_._v("msg1(biz_id = 1)")]),_._v("​. 但是, 消费者这边也是有批量接口的. 也就是说, 如果发送消息的时候在一条消息里面直接带上批量数据, 消费者这边也可以借助批量接口一次性处理完.")]),_._v(" "),v("p",[_._v("也就是说, 发送者发送的数据是 "),v("code",[_._v("msg2(biz_ids=1,2,3,4)")]),_._v("​, 消费者可以"),v("strong",[_._v("一次性处理完毕")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/22491b5766cfe928576771af9de69d30-20231223175002-gmaeek2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种调整带来了两方面的好处. "),v("strong",[_._v("一方面自然是消费者借助批量接口处理, 速度有数量级的提升; 另外一个则是消息所需的存储空间大大降低, broker 的负载也会降低不少")]),_._v(".")]),_._v(" "),v("p",[_._v("这里直接整理成对应的话术, 供你参考, 如果有类似的场景, 也可以使用自己的案例来替换.")]),_._v(" "),v("blockquote",[v("p",[_._v("还有一种思路是聚合消息和批量操作来优化性能. 之前我有一个业务, 生产者那边是按照用户输入的参数来查找符合条件的数据, 然后一条条处理的. 每条数据处理完毕之后就发送一条消息到消息队列里面. 简单来说, 就是消息里会带上业务 ID. 同时消费者消费消息, 根据业务 ID 进一步处理.")]),_._v(" "),v("p",[_._v("后来随着业务增长就出现了消息积压的问题, 我负责解决这个问题. 在经过排查之后, 我发现其实消费者这边是可以批量处理的. 所以我就先研发了批量接口, 通过性能测试发现批量接口有了一个数量级性能的提升. 然后又开始改造生产者, 让生产者不再是一条数据发一条消息, 而是一批数据发一条消息. 消费者这边也改造成了使用批量接口.")]),_._v(" "),v("p",[_._v("上线之后积压的消息很快就被处理完了, 并且到现在都没再出现消息积压的问题. 而且因为消费速率非常高, 所以反而削减了两个消费者, 节省了一点资源.")]),_._v(" "),v("p",[_._v("这个方案最大的优点就是"),v("mark",[_._v("业务改造的成本不高")]),_._v(". 尤其是在消费者端, 对于历史积压的消息, 还是调用批量接口, 只不过传入的业务 ID 只有一个而已.")])]),_._v(" "),v("p",[_._v("接下来要进一步总结出一般的规律, 刷一个亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种方式一般"),v("mark",[_._v("适用于消费者可以改造成批量接口的场景, 而且可以考虑不改造生产者, 只改造消费者")]),_._v(". 把消费者改造成批量消费, 批量提交偏移量. 比如说消费者一次性拉取 100 条消息, 构造批量处理请求. 在处理成功之后, 再提交偏移量. 这种批量消费, 再批量提交的做法也可以用于异步消费中.")])]),_._v(" "),v("p",[_._v("显然, 最后提到"),v("strong",[_._v("异步消费")]),_._v(", 就是为了引出下一个解决方案, 也是核心解决方案--异步消费.")]),_._v(" "),v("h6",{attrs:{id:"异步消费"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#异步消费"}},[_._v("#")]),_._v(" 异步消费")]),_._v(" "),v("p",[_._v("可以先看一下最简单的异步消费架构图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5d0d5ed1503d23bb128d3a6a81da5301-20231223175002-l78i97l.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("结合图片, 可以简单介绍一下这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("也可以考虑用异步消费来解决消息积压的问题. 所谓的异步消费就是指在消费者这边有一个消费者线程, 负责从消息队列里面拉取消息. "),v("mark",[_._v("同时拉到的消息会立刻转发给一个线程池, 线程池里面会有一些工作线程负责处理消息. 这个方案对生产者毫无影响, 但是消费者这边要小心消息丢失的问题")]),_._v(".")])]),_._v(" "),v("p",[_._v("在这个回答里面, 因为聊到了线程池, 那么面试官也可能问线程池相关的问题. 同时提到了消息丢失的问题, 面试官有极大概率会追问消息丢失该怎么处理.")]),_._v(" "),v("blockquote",[v("p",[_._v("问题1：消息丢失")])]),_._v(" "),v("p",[_._v("所谓的消息丢失是指消费者线程取出消息之后, 要想继续消费下一条就得先提交当前这一条. 这种情况下, 就可能会出现一个问题: 消费者线程提交了, 但是工作者线程还没处理就宕机了. 这个时候, 因为已经提交了, 所以就算重启, 也是从下一条开始消费.")]),_._v(" "),v("p",[_._v("就算不主动提消息丢失的问题, 面试官也会主动问你怎么解决, 那么就可以抓住关键词 "),v("strong",[_._v("批量提交")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("要解决消息丢失, 那么就可以考虑使用批量提交的方法. 也就是消费者线程一次拉取一批消息, 比如说 10 条. 然后并不是说立刻提交这 10 条消息, 而是直接开启十个线程, 并行处理这 10 条消息. 等到 10 条消息都处理完毕, 再批量提交.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/91275e07c2f6cb591cb5dc7be2e77b06-20231223175002-5se80xg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在批量提交这个方案里面, 还是有破绽的, 可以进一步引导.")]),_._v(" "),v("blockquote",[v("p",[_._v("批量提交的效果是很好的, 可以做到数量级性能提升. 但是它的缺陷也很明显, 就是重复消费和部分失败的问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("问题2：重复消费")])]),_._v(" "),v("p",[_._v("批量提交很容易出现"),v("strong",[_._v("重复消费")]),_._v("的问题. 在消费者线程拉取了一批消息之后, 如果过了一段时间还没提交就宕机了, 那么会发生什么?")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("可能所有的消息都还没被处理或者正在处理")]),_._v(".")]),_._v(" "),v("li",[_._v("部分消息被处理了, 可能成功可能失败.")]),_._v(" "),v("li",[_._v("全部消息都被处理了, 可能成功可能失败, 还来不及提交.")])]),_._v(" "),v("p",[_._v("可以预见的是, 因为没有提交, 所以当消费者从宕机中恢复过来的时候, 就会"),v("strong",[_._v("拉取同一批继续消费")]),_._v(". 怎么办?")]),_._v(" "),v("p",[_._v("很简单, 保证处理消息的逻辑是"),v("strong",[_._v("幂等")]),_._v("的就可以. 也就是同一条消息, 反复处理多少次, 最终结果都是一样的. 所以抓住关键词 "),v("strong",[_._v("幂等")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("对于重复消费来说, 解决方案也很简单, 就是让消费逻辑保证是幂等的. 这样即便宕机导致消息被消费了但是来不及提交, 也可以保证在下一次恢复过来的时候, 重复处理不会引起什么业务问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("问题3：部分失败")])]),_._v(" "),v("p",[_._v("在批量提交里面, 还有一个非常棘手的问题就是"),v("strong",[_._v("一批消息里面部分消息处理失败")]),_._v("了怎么办?")]),_._v(" "),v("p",[_._v("实际上, 如果考虑到要继续消费, 肯定可以得出一个结论: "),v("strong",[_._v("要继续提交, 然后继续消费下一批")]),_._v(". 不过, 在提交之前可以做很多事情. 最简单的做法就是, "),v("strong",[_._v("当某个工作线程失败的时候, 直接重试")]),_._v(". 但是要注意, 当工作线程重试的时候, 其他工作线程也在等它, 所以要"),v("strong",[_._v("控制住重试的次数和重试的整体时间")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4a121b11e2dcc617c28a44056287b9ed-20231223175002-ns8dge3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然也可以考虑"),v("strong",[_._v("异步重试")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7f9bd57c3fe4823281f4b4c09cfbabf7-20231223175002-146fuw5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但还有一个更加优雅的动作, "),v("strong",[_._v("就是失败之后, 这个工作线程把这个消息再次丢回消息队列")]),_._v(". 这个丢回去的动作实际上是产生了一个全新的消息, 只不过消息内容一模一样而已.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6ffd9fbc1b838d0c3ae991358ca79e43-20231223175002-lhrqa38.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里要注意, "),v("strong",[_._v("可能需要在消息里面记录一下已经处理过几次了")]),_._v(". 比如限制只能重试三次, 那么三次重试都失败了, 就不要再丢回去了.")]),_._v(" "),v("p",[_._v("可以把这三个方案放在一起回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在部分失败的情况下, 第一种做法是要求工作线程立刻重试, 比如说重试三次, 也可以用一个全新的异步线程来重试. 当然, 也可以考虑把消费失败的消息丢回消息队列里, 后面再轮到它的时候又会被处理, 这就相当于重试了. 这些方案的核心都是确保部分失败不会影响继续向前消费.")])]),_._v(" "),v("p",[_._v("到这里, 整个异步消费方案就非常完整了, 而且讨论得也足够深入了.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-24"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-24"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("今天讨论了消息积压的问题. 为了更好地理解消息积压, 在前置知识里面先介绍了消费者和分区的关系, 还有怎么确定分区数量. 确定分区数量在面试中比较常见, 要记牢.")]),_._v(" "),v("p",[_._v("为了解决消息积压问题, 还准备了五个案例, 分别是 "),v("strong",[_._v("增加分区, 优化消费者性能, 消费者降级, 聚合消息与批量操作, 异步消费")]),_._v(". 可以根据自己的经历来选择方案用于面试, 但是也建议在面试的时候尽量用上异步消费, 并且深入讨论里面的 "),v("mark",[v("strong",[_._v("消息丢失, 重复消费和部分失败")])]),_._v(" 三个问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1f73f07effd8ea0dcb2e8706deb68802-20231223175002-7fvy41m.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_26-消息不丢失-生产者收到写入成功响应后消息一定不会丢失吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_26-消息不丢失-生产者收到写入成功响应后消息一定不会丢失吗"}},[_._v("#")]),_._v(" 26-消息不丢失:生产者收到写入成功响应后消息一定不会丢失吗?")]),_._v(" "),v("p",[_._v("今天来学习消息队列中的新主题-消息丢失.")]),_._v(" "),v("p",[_._v("和消息丢失相对应的概念叫做可靠消息, 这两者基本上指的就是同一件事. 在实践中, 一旦遇到消息丢失的问题, 是很难定位的. 从理论上来说, 要想理解消息丢失, 就需要对生产者到消费者整个环节都有深刻地理解.")]),_._v(" "),v("p",[_._v("今天就看看"),v("strong",[_._v("从生产者发出, 到消费者完成消费, 每一个环节都需要考虑什么才可以确保自己的消息不会丢失")]),_._v(". 到最后, 会再给你一个在 Kafka 的基础上支持消息回查的方案, 帮助你在面试的时候赢得竞争优势. 先从基础知识开始.")]),_._v(" "),v("h5",{attrs:{id:"kafka主从同步与isr"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka主从同步与isr"}},[_._v("#")]),_._v(" Kafka主从同步与ISR")]),_._v(" "),v("p",[_._v("在 Kafka 中, "),v("strong",[_._v("消息被存储在分区中")]),_._v(". 为了避免分区所在的消息服务器宕机, 分区本身也是一个主从结构. 换一句话来说, 不同的分区之间是一个对等的结构, 而"),v("strong",[_._v("每一个分区其实是由一个主分区和若干个从分区组成")]),_._v("的.")]),_._v(" "),v("p",[_._v("不管是主分区还是从分区, 都放在 broker 上. 但是在放某个 topic 分区的时候, 尽量做到一个 broker 上只放一个主分区, 但是可以放别的主分区的从分区.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f8b5a1f5a32849a155283dea50d60yyb-20231223175002-nmevtbx.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种思路也很容易理解, 它有点像是"),v("strong",[_._v("隔离")]),_._v(", 也就是通过将主分区分布在不同的 broker 上, 避免 broker 本身崩溃影响多个主分区.")]),_._v(" "),v("h6",{attrs:{id:"写入语义-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写入语义-2"}},[_._v("#")]),_._v(" 写入语义")]),_._v(" "),v("p",[_._v("结合在 MySQL 部分对写入语义的讨论, 就可以想到, 当说写入消息的时候, "),v("strong",[_._v("既可以是写入主分区, 也可以是写入了主分区之后再写入一部分从分区")]),_._v(".")]),_._v(" "),v("p",[_._v("这方面 Kafka 做得比较灵活, 它"),v("strong",[_._v("让生产者来决定写入语义")]),_._v(". 这个控制参数叫做 "),v("strong",[_._v("acks")]),_._v(", 它的取值有三个.")]),_._v(" "),v("ul",[v("li",[_._v('0: 就是所谓的 "fire and forget", 意思就是'),v("strong",[_._v("发送之后就不管了")]),_._v(", 也就是说 broker 是否收到, 收到之后是否持久化, 是否进行了主从同步, 全都不管.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ac3146bb0e35a512ebbd0c51477d4583-20231223175002-bgs30ih.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[_._v("1: "),v("strong",[_._v("当主分区写入成功的时候, 就认为已经发送成功")]),_._v("了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1353ae8a02b273f87ae59ccae30e7f77-20231223175002-jtzbrvu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("p",[_._v("all: "),v("strong",[_._v("不仅写入了主分区, 还同步给了所有 ISR 成员")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ebbb36b5b50yy462ecba039152359b84-20231223175002-vclj4lb.png",alt:"图片"}}),_._v("​")])])]),_._v(" "),v("p",[_._v("这时候就接触到了 Kafka 中另外一个核心概念 ISR.")]),_._v(" "),v("h6",{attrs:{id:"isr"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#isr"}},[_._v("#")]),_._v(" ISR")]),_._v(" "),v("p",[v("strong",[_._v("ISR(In-Sync Replicas)是指和主分区保持了主从同步的所有从分区")]),_._v(". 比如一个主分区本身有 3 个从分区, 但是因为网络之类的问题, 导致其中一个从分区和主分区失去了联系, 没办法同步数据, 那么对于这个主分区来说, 它的 ISR 就是剩下的 2 个分区.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/12a8a6a8c0db302e2459bab8ca594b3f-20231223175002-b385tyn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("Kafka 对 ISR 里面的分区数量有没有限制呢? 比如有一个主分区, 有 11 个从分区, 那 ISR 可以只有一个从分区吗?")]),_._v(" "),v("p",[_._v("是可以的, 能够通过 "),v("code",[_._v("min.insync.replicas")]),_._v("​ 这个参数来配置. 比如说设置 min.insync.replicas = 2 的时候, 就意味着 ISR 里面至少要有两个从分区. 如果分区数量不足, 那么生产者在配置 acks = all 的时候, 发送消息会失败. 与它对应的一个概念是 OSR, 也就是不在 ISR 里面的分区集合.")]),_._v(" "),v("h5",{attrs:{id:"消息丢失的各种场景"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息丢失的各种场景"}},[_._v("#")]),_._v(" 消息丢失的各种场景")]),_._v(" "),v("p",[_._v("为了让你理解后面提到的各种措施, 现在先分析一下消息从生产者发送到消费者完成消费这个过程中, 究竟哪些环节可能导致消息丢失.")]),_._v(" "),v("h6",{attrs:{id:"生产者发送"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#生产者发送"}},[_._v("#")]),_._v(" 生产者发送")]),_._v(" "),v("p",[_._v("了解了 acks 参数之后, 首先能够想到"),v("strong",[_._v("一个消息丢失的场景就是生产者把 acks 设置成 0, 然后发送消息")]),_._v(". 这个时候虽然生产者能够拿到消息客户端返回的成功响应, 但是事实上 broker "),v("strong",[_._v("可能根本没收到")]),_._v(", 或者收到了但是处理新消息的时候遇到 Bug 了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/byy09273953344093825845yy28e8fe6-20231223175002-cbpgazw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果启用了批量发送功能, 而且批次比较大的话, 那么还可能发生的情况就是, Kafka 客户端连请求都没有发送出去, 服务就整个崩溃了, 这种情况也会引起消息丢失.")]),_._v(" "),v("p",[_._v("那么是不是主分区真的写入了就万无一失了呢? 也不是, 因为还要"),v("strong",[_._v("考虑主从同步的问题")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"主从同步"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主从同步"}},[_._v("#")]),_._v(" 主从同步")]),_._v(" "),v("p",[v("strong",[_._v("在 acks=1 的时候, 只要求写入主分区就可以")]),_._v(". 所以假设在写入主分区之后, 主分区所在 broker 立刻就崩溃了. 这个时候发起新的主分区选举, 不管是哪个从分区被选上, 它都缺了这条消息.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3be0fc0783a37ba7a72a031dd896da30-20231223175002-n0ebpn9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这么看来, 只要使用 acks=all 就肯定不会有问题了, 对不对? 实际上也不是, 因为 Kafka 里面还有一种 unclean 选举. 在允许 unclean 选举的情况下, 如果 ISR 里面没有任何分区, 那么 Kafka 就会选择第一个从分区来作为主分区.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/efa51a426a5243408dbc58faeb786183-20231223175002-zake27s.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种 unclean 选举机制本身主要是为了解决你希望尽可能保证 Kafka 依旧可用, 并且等待从分区重新进入 ISR 的问题. 类似地, unclean 选出来的新的主分区也可能少了部分数据. 那么如果设置 acks=all 并且禁用 unclean 选举, 是不是就万无一失了?")]),_._v(" "),v("p",[_._v("实际上也不是, 因为还有一个问题没有考虑到, 就是"),v("mark",[v("strong",[_._v("刷盘")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"刷盘"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#刷盘"}},[_._v("#")]),_._v(" 刷盘")]),_._v(" "),v("p",[_._v("之前在数据库部分讨论过写入语义, 提到了 redo log 和 binlog 的刷盘问题. 在 Kafka 这里还是会有这个问题.")]),_._v(" "),v("p",[v("strong",[_._v("当 acks=1 的时候, 主分区返回写入成功的消息, 但是这个时候消息可能还在操作系统的 page cache 里面")]),_._v(".")]),_._v(" "),v("p",[_._v("而当 acks=all 的时候, 主分区返回写入成功的消息, 不管是主分区还是 ISR 中的从分区, 这条消息"),v("strong",[_._v("都可能还在 page cache 里面")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d8229a87f6e364e8703yybcfc66e1089-20231223175002-lj6wl51.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而在 Kafka 中, 控制刷盘的参数有三个.")]),_._v(" "),v("ul",[v("li",[_._v("​"),v("code",[_._v("log.flush.interval.messages")]),_._v("​: 控制消息到多少条就要"),v("strong",[_._v("强制刷新磁盘")]),_._v(". Kafka 会在写入 page cache 的时候顺便检测一下.")]),_._v(" "),v("li",[_._v("​"),v("code",[_._v("log.flush.interval.ms")]),_._v("​: 间隔多少毫秒就刷新数据到磁盘上.")]),_._v(" "),v("li",[_._v("​"),v("code",[_._v("log.flush.scheduler.interval.ms")]),_._v("​: 间隔多少毫秒, 就检测数据是否需要刷新到磁盘上.")])]),_._v(" "),v("p",[_._v("后面两个是要配合在一起的. 举个例子, 假如 log.flush.internval.ms 设置为 500, 而 log.flush.schduler.interval.ms 设置为 200. 也就是 Kafka 每隔 200 毫秒检查一下, 如果上次刷新到现在已经过了 500 毫秒, 那么就刷新一次磁盘.")]),_._v(" "),v("p",[_._v("而 log.flush.interval.messages 和 log.flush.interval.ms 都设置了的话, 那么就是它们俩之间任何一个条件满足了, 都会刷新磁盘.")]),_._v(" "),v("p",[_._v("有一个简单的记忆方法: Kafka 要么是 "),v("strong",[_._v("定量刷")]),_._v(", 要么是 "),v("strong",[_._v("定时刷")]),_._v(".")]),_._v(" "),v("p",[_._v("不过, Kafka 的维护者之前是不建议调整这些参数的, 而是"),v("strong",[_._v("强调依赖于副本(从分区)来保证数据不丢失")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"消费者提交"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消费者提交"}},[_._v("#")]),_._v(" 消费者提交")]),_._v(" "),v("p",[_._v("消费者提交是指消费者提交了偏移量, 但是最终却没有消费的情况. 比如线程池形态的异步消费, 消费者线程拿到消息就直接提交, 然后再转交给工作线程. 在转交之前, 或者工作线程正在处理的时候, 消费者都有可能宕机. "),v("strong",[_._v("于是一个消息本来并没有被消费, 但是却被提交了, 这也叫做消息丢失")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"面试准备-26"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-26"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 要在公司内部收集一些和消息丢失相关的素材.")]),_._v(" "),v("ul",[v("li",[_._v("你或者你的同事有没有因为消息丢失而出现线上故障? 如果出现过, 那么是因为什么原因引起的故障? 后来又是怎么解决的? 或者说你用什么措施来防止再次出现这种问题?")]),_._v(" "),v("li",[_._v("核心业务的 topic 的分区数量是多少, 每一个主分区有多少个从分区?")]),_._v(" "),v("li",[_._v("你的"),v("strong",[_._v("业务发送消息的时候是不是异步发送? acks 的设置是多少")]),_._v("?")]),_._v(" "),v("li",[_._v("你使用的 Kafka 里面那三个刷盘参数的值分别是多少? 如果和默认值不一样, 为什么修改?")]),_._v(" "),v("li",[_._v("你有没有遇到一些场景是必须要发送消息成功的? 在这些场景下是如何保证业务方一定把消息发送出来的?")])]),_._v(" "),v("p",[_._v("平时学习类似 Kafka 这种框架的时候, 要注意一下它们的写入语义. 这个在 MySQL 部分已经提过了. 多看几个框架, 就会发现在写入语义上, 不同框架之间的区别很小. 大部分框架的设计理念都是接近的, 你在平时学习的时候注意总结. 这些总结出来的内容能体现你对问题思考的深度和广度, 就可以用在面试中.")]),_._v(" "),v("p",[_._v("如果面试官问到了下面这些问题, 就可以考虑把话题引导到消息丢失这个话题上.")]),_._v(" "),v("ul",[v("li",[_._v("面试官问到了延迟消息, 那么可以在介绍了如何在 Kafka 上支持延迟消息之后, 提及你采用类似的手段支持了消息回查.")]),_._v(" "),v("li",[_._v("面试官问到了有关"),v("strong",[_._v("刷盘")]),_._v("的问题, 比如说 MySQL 里的 redo log, 那么可以提起在 Kafka 里面也有类似的参数.")]),_._v(" "),v("li",[_._v("面试官问到了分区表, 分库分表等问题, 可以说你用这些技术解决过延迟消息和消息回查的问题.")]),_._v(" "),v("li",[_._v("面试官问到了有关主从模式的问题, 那么可以介绍一下在主从模式下的写入语义.")])]),_._v(" "),v("p",[_._v("面试官也可能直接问消息丢失有关的问题. 比如说:")]),_._v(" "),v("ul",[v("li",[_._v("你的业务"),v("strong",[_._v("有没有遇到过消息丢失的问题? 最后是怎么解决的")]),_._v("?")]),_._v(" "),v("li",[_._v("你的"),v("strong",[_._v("业务发送消息的时候, acks 是怎么设置的? 你为什么设置成这个值")]),_._v("?")]),_._v(" "),v("li",[_._v("在使用异步消费的时候, 怎么做避免消息已提交, 但是最终却没有消费的情况?")]),_._v(" "),v("li",[_._v("什么是 ISR? 什么样的场景可能会导致一个分区被挪出 ISR?")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-18"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-18"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("这一次的面试方案强调的是"),v("strong",[_._v("成体系")]),_._v(". 这种面试思路以前已经见过了, 它能够全方面体现你对某一个主题的理解. 首先需要从整体上介绍一下你的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("在我的核心业务里面, 关键点是消息是不能丢失的. 也就是说, 发送者在完成业务之后, 一定要把消息发送出去, 而消费者也一定要消费这个消息. 所以, 我在发送方, 消息队列本身以及消费者三个方面, 都做了很多事情来保证消息绝对不丢失.")])]),_._v(" "),v("h6",{attrs:{id:"发送方一定发了消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#发送方一定发了消息"}},[_._v("#")]),_._v(" 发送方一定发了消息")]),_._v(" "),v("p",[_._v("这实际上和本地事务有点关系. 可以把类似场景都抽象成"),v("mark",[v("strong",[_._v("执行业务操作和发送消息")])]),_._v("这两个步骤.")]),_._v(" "),v("p",[v("strong",[_._v("站在业务的角度, 需要确保这两个步骤要么都不执行, 要么都执行")]),_._v(". 这本身是一个分布式事务的问题, 大体上有两种方案: "),v("mark",[v("strong",[_._v("本地消息表和消息回查")])]),_._v(". 这里先看本地消息表方案, 消息回查方案会作为亮点方案在后面系统分析.")]),_._v(" "),v("p",[_._v("本地消息表这个方案整体来说并不复杂, 在实践中被广泛使用. 可以先讲述这个方案的基本思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("在发送方, 我采用的是本地消息表解决方案. 简单来说, 就是在业务操作的过程中, 在本地消息表里面记录一条待发消息, 做成一个本地数据库事务. 然后尝试立刻发送消息, 如果发送成功, 那么就把本地消息表里对应的数据删除, 或者把状态标记成已发送.")]),_._v(" "),v("p",[_._v("如果这个时候失败了, 就可以立刻尝试重试. 同时还要有一个异步的补发机制, 扫描本地消息表, 找出已经过了一段时间, 比如说三分钟, 但是还没有发送成功的待发消息, 然后补发.")])]),_._v(" "),v("p",[_._v("最后提到的异步补发机制, 可以简单理解成有一个线程定时扫描数据库, 找到需要发送但是又没有发送的消息发送出去. 更直观的来说, 就是这个线程会执行一个类似这样的 SQL.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("# 找出三分钟前还没发送出去的消息, 然后补发. ")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" msg_tab "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" create_time "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("now")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("-")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),_._v("min "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("status")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v("'未发送'")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("整个过程如下图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d8d681ff7bc0469aa703d80bc2481f86-20231223175002-ftwd7cz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("图里标注了三个易出错点, 面试官大概率会追问这三个点, 也就是要刷亮点的地方.")]),_._v(" "),v("blockquote",[v("ol",[v("li",[_._v("如果已经提交事务了, 那么即便服务器立刻宕机了也没关系. 因为异步补发机制会找出这条消息, 进行补发.")]),_._v(" "),v("li",[_._v("如果消息发送成功了, 但是还没把数据库里的消息状态更新成已发送, 也没关系, 异步补发机制还是会找出这条消息, 再发一次. 也就是说, 在这种情况下会发送两次.")]),_._v(" "),v("li",[_._v("如果在重试的过程中, 重发成功了但是还没把消息状态更新成已发送, 和第 2 点一样, 也是依赖于异步补发机制.")])])]),_._v(" "),v("p",[_._v("这三点都依赖于异步补发机制. 但就像前面多次提到的, 重试也要控制住重试间隔和重试次数. 所以在本地消息表里, 还可以用额外的字段来控制重试间隔和重试次数.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在本地消息表里面额外增加了一个新的列, 用来控制重试的间隔和重试的次数. 如果最终补发都失败了就会告警. 这个时候就需要人手工介入了.")])]),_._v(" "),v("p",[_._v("那么这时候本地消息表至少有两个关键列: "),v("strong",[_._v("一个是消息体列, 里面存储了消息的数据; 另一个是重试机制列, 里面可以只存储重试次数, 也可以存储重试间隔, 已重试次数, 最大重试次数")]),_._v(". 剩余的列, 就根据自己的需要随便加, 不关键.")]),_._v(" "),v("p",[_._v("最后注意总结升华一下, 体现出你对分布式事务的深刻理解.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种解决方案其实就是"),v("mark",[_._v("把一个分布式事务转变成本地事务 + 补偿机制")]),_._v(". 在这里案例里面, 分布式事务是要求执行业务操作并且发消息, 那么就转化成一个本地事务, 这个本地事务包含了业务操作, 以及下一步做什么. 然后补偿机制会查看本地事务提交的数据, 找出需要执行但是又没有执行成功的下一步, 执行. 这里的下一步, 就是发送消息.")])]),_._v(" "),v("p",[_._v("在实践中, "),v("strong",[_._v("很多分布式事务都可以转化成本地事务 + 补偿机制")]),_._v(", 可以看看自己公司有没有类似的场景. 这部分面试可能会把话题转向分布式事务, 需要把这两部分知识串联起来记忆.")]),_._v(" "),v("h6",{attrs:{id:"消息队列不丢失"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息队列不丢失"}},[_._v("#")]),_._v(" 消息队列不丢失")]),_._v(" "),v("p",[v("strong",[_._v("发送者一定发了消息就意味着它拿到了消息队列的响应")]),_._v(", 那么根据前面的基础知识, 要想让消息队列一定不会丢失消息, 那么 acks 就需要设置成 all. 而且也不能允许 Kafka 使用 unclean 选举.")]),_._v(" "),v("p",[_._v("进一步考虑刷盘的问题, 那么就需要调整 log.flush.interval.messages, log.flush.interval.ms 和 log.flush.scheduler.interval.ms 的值.")]),_._v(" "),v("p",[_._v("这一点可以结合自己公司的实际取值来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在关键业务上, 我一般都是把 acks 设置成 all 并且禁用 unclean 选举, 来确保消息发送到了消息队列上, 而且不会丢失. 同时 log.flush.interval.messages, log.flush.interval.ms 和 log.flush.scheduler.interval.ms 三个参数会影响刷盘, 这三个值我们公司设置的是 10000, 2000, 3000.")]),_._v(" "),v("p",[_._v("理论上来说, 这种配置确实"),v("mark",[_._v("还是有一点消息丢失的可能, 但是概率已经非常低了")]),_._v(". 只有一种可能, 就是消息队列完成主从同步之后, 主分区和 ISR 的从分区都没来得及刷盘就崩溃了, 才会丢失消息. 这个时候真丢失了消息, 就只能人手工补发了.")])]),_._v(" "),v("p",[_._v("也可以从优化的角度来描述.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我们就遇到过一个消息丢失的案例. 有一个业务在发送消息的时候把 acks 设置成了 0, 后来有一天消息队列真的崩了, 等再恢复过来的时候, 已经找不到消息了. 而这个业务其实是一个很核心的业务, 所以我们把 acks 的设置改成了 all. 之后消息队列再崩溃, 也确实没再出现过丢失的问题.")])]),_._v(" "),v("p",[_._v("当消息队列确保消息不会丢失之后, 需要做的就是确保消费者肯定消费了.")]),_._v(" "),v("h6",{attrs:{id:"消费者肯定消费"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消费者肯定消费"}},[_._v("#")]),_._v(" 消费者肯定消费")]),_._v(" "),v("p",[_._v("消费者肯定消费这个几乎不需要额外做什么, 除非使用了异步消费机制, 这部分可以参考消息积压那一节课提到的异步消费方案.")]),_._v(" "),v("p",[_._v("这里只需要简单介绍一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("要确保消费者肯定消费消息, 大多数时候都不需要额外做什么, 但是如果业务上有使用异步消费机制就要小心一些. 比如我的 A 业务里面就采用了异步消费来提高消费速率, 我利用批量消费, 批量提交来保证异步消费的同时, 也不会出现未消费的问题.")])]),_._v(" "),v("p",[_._v("这里就可以把话题引导到异步消费上, 也就可以顺便提起消息积压的问题.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-在kafka上支持消息回查机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-在kafka上支持消息回查机制"}},[_._v("#")]),_._v(" 亮点方案:在Kafka上支持消息回查机制")]),_._v(" "),v("p",[_._v("所谓的"),v("mark",[v("strong",[_._v("消息回查机制是指消息队列允许在发送消息的时候, 先发一个准备请求, 里面带着你的消息. 这个时候消息队列并不会把消息转交给消费者, 而是当业务完成之后, 需要再发一个确认请求, 这时候消息中间件才会把消息转交给消费者")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8d9d674df16be9850b2a1d67c5dc2cd6-20231223175002-nmwbgow.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("显然, 这就是之前讨论的"),v("mark",[v("strong",[_._v("两阶段提交的一个简单应用, 所以这个也被叫做事务消息")])]),_._v(".")]),_._v(" "),v("p",[_._v("仔细看一下事务消息这张图, 就会发现一个问题: 如果业务成功了, 但是确认请求没发怎么办? 所以这时候就有了"),v("strong",[_._v("消息回查")]),_._v(", 也就是消息在没收到确认请求的时候, 会反过来问一下你, 这个消息要不要交给消费者.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ff789860cf433f3e91517cacd11d9540-20231223175002-9qavfxn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("消息回查机制依赖于消息队列的支持. RocketMQ 是支持的")]),_._v(", 但是不幸的是 Kafka 和 RabbitMQ 都不支持. 所以这里就有一个问题了, 就是怎么在 Kafka 的基础上支持消息回查.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c83e031e7c8895710bfc1f1ddddf77c7-20231223175002-l97e7z6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以结合图片简要回答整个流程.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司用的是 Kafka, 它并不支持消息回查机制, 所以我在公司里面设计过一个系统来支持回查功能.")]),_._v(" "),v("p",[_._v("它的基本步骤是这样的:")]),_._v(" "),v("ol",[v("li",[_._v("应用代码把准备消息发送到 topic=look_back_msg 上. 里面包含业务 topic, 消息体, 业务类型, 业务 ID, 准备状态, 回查接口.")]),_._v(" "),v("li",[_._v("回查中间件消费这个 look_back_msg, 把消息内容存储到数据库里.")]),_._v(" "),v("li",[_._v("应用代码执行完业务操作之后, 再发送一个消息到 look_back_msg 上, 带上业务类型, 业务 ID 和提交状态这些信息. 如果应用代码执行业务出错了, 那么就使用回滚状态.")]),_._v(" "),v("li",[_._v("回查中间件查询消息内容, 转发到业务 topic 上.")])])]),_._v(" "),v("p",[_._v("整个过程到处都是亮点, 一个一个看.")]),_._v(" "),v("h6",{attrs:{id:"亮点一-回查实现"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点一-回查实现"}},[_._v("#")]),_._v(" 亮点一:回查实现")]),_._v(" "),v("p",[_._v("你应该注意到了, 如果在业务操作完成之后, 没有发提交消息, 这时候就需要"),v("strong",[_._v("回查中间件来回查")]),_._v(". 一般来说, "),v("strong",[_._v("回查中间件会异步地扫描长时间未提交的消息, 然后回查业务方")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/90b4f9762f283c80b0a34f5504fe3ac0-20231223175002-qoisnmp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里的关键点就是"),v("strong",[_._v("回查中间件得知道怎么回查业务代码")]),_._v(". 正常来说, 这里应该要设计成可扩展的, 也就是说可以回查 HTTP 接口, 也可以回查 RPC 接口.")]),_._v(" "),v("p",[_._v("所以接着补充.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果业务方最终没有发送提交消息, 那么回查中间件会找出这些长时间没提交的消息, 执行回查. 回查中间件执行回查的关键点是利用准备消息中带着的回查接口配置来发起调用. 我设计了一个通用的机制, 支持 HTTP 调用或者 RPC 调用.")]),_._v(" "),v("p",[_._v("对于 HTTP 调用来说, 业务方需要提供回查 URL. 而对于 RPC 调用来说, 业务方需要实现我提供的回查接口, 然后提供对应的服务名. 我在回查的时候会带上业务类型和业务 ID, 业务方需要告诉我这个消息能不能提交, 也就是要不要发给业务 topic.")])]),_._v(" "),v("p",[_._v("上面的回答你肯定摸不着头脑, 尤其是这个回查接口究竟是怎么一回事. 举个例子. 如果是回查一个订单业务的 HTTP 接口, 那么"),v("strong",[_._v("业务方需要告诉我回查 URL")]),_._v(", 那么回查中间件发出的请求就类似于下面这样.")]),_._v(" "),v("div",{staticClass:"language-json line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-json"}},[v("code",[_._v("method"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" POST\nURL"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" https"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("//abc.com:8080/order/lookback")]),_._v("\nBody"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token property"}},[_._v('"biz_type"')]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"order"')]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token property"}},[_._v('"biz_id"')]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"oid-123"')]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br")])]),v("p",[_._v("业务方返回的"),v("strong",[_._v("响应")]),_._v(":")]),_._v(" "),v("div",{staticClass:"language-json line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-json"}},[v("code",[_._v("Body"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token property"}},[_._v('"biz_type"')]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"order"')]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token property"}},[_._v('"biz_id"')]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"oid-123"')]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token property"}},[_._v('"status"')]),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v('"提交"')]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 如果业务没成功, 那么可以是回滚")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br")])]),v("p",[_._v("而如果是 RPC 接口, 回查中间件就可以定义一个接口, 要求所有的业务方都实现这个接口.")]),_._v(" "),v("div",{staticClass:"language-plain line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-plain"}},[v("code",[_._v("type MsgLookBack interface{\n    LookBack(bizType string, bizID int) Status\n}\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br")])]),v("p",[_._v("然后业务方需要提供服务名字, 比如说 abc.com.order.msg_look_back, 回查中间件会"),v("strong",[_._v("利用 RPC 的泛化调用功能, 发起调用")]),_._v(". 如果不理解泛化调用, 那么可以说暂时只支持了 HTTP 回查接口, 但是将来可以轻易扩展到 RPC 调用上.")]),_._v(" "),v("p",[_._v("这是一个非常能够体现设计能力的一个点, 要是答好了, 就足以证明你具备设计复杂系统来解决业务问题的能力.")]),_._v(" "),v("h6",{attrs:{id:"亮点二-数据存储"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点二-数据存储"}},[_._v("#")]),_._v(" 亮点二:数据存储")]),_._v(" "),v("p",[_._v("这部分和在延迟队列里看到的差不多. 在延迟队列中, 介绍过可以考虑"),v("strong",[_._v("使用分区表, 交替表或者分库分表来存储延迟消息")]),_._v(". 这里同样可以"),v("strong",[_._v("用分区表, 交替表和分库分表来存储回查消息")]),_._v(".")]),_._v(" "),v("p",[_._v("具体细节就不重复了, 可以参考延迟队列的内容. 在回答的时候注意引导就可以, 用分区表作为例子演示一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了保证回查机制的高性能和高可靠, 我使用了分区表. 我按照时间进行分区, 并且历史分区是可以快速归档的, 毕竟这个回查机制使用的数据库只是临时存储一下消息数据而已. 当然, 后续随着业务扩展, 我觉得这个地方是可以考虑使用分库分表的, 比如说按照业务 topic 来分库分表.")])]),_._v(" "),v("h6",{attrs:{id:"亮点三-有序消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点三-有序消息"}},[_._v("#")]),_._v(" 亮点三:有序消息")]),_._v(" "),v("p",[_._v("你有没有想过这样一种可能: 我的"),v("strong",[_._v("中间件回查机制, 有没有可能先收到某个业务的提交消息")]),_._v("?")]),_._v(" "),v("p",[_._v("答案是有可能的. 但是"),v("strong",[_._v("回查机制要求的是一定要先收到准备消息, 再收到提交消息")]),_._v(". 所以可以尝试讲清楚这个点.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案是要求准备消息和提交消息是有序的, 也就是说, 同一个业务的准备消息一定要先于提交消息. 解决方案也很简单, 在发送的时候要求业务方按照业务 ID 计算一个哈希值, 然后除以分区数量的余数, 就是目标分区.")])]),_._v(" "),v("p",[_._v("显然, 也可以在这里趁机把话题引导到有序消息上.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-25"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-25"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节的主要内容. 为了理解消息丢失这个问题, 介绍了 Kafka 主从同步与 ISR 的基本概念, 然后系统地分析了各个环节消息丢失的场景. 在面试的时候, 要沿着生产者, 消息队列, 消费者这条线来"),v("strong",[_._v("说明每一个环节怎么做到消息不丢失")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("在生产者这一边要保证消息一定被发出来, 可以考虑本地消息表和消息回查机制")]),_._v(".")]),_._v(" "),v("li",[_._v("在消息队列上要注意设置 acks 参数, 同时也要注意三个刷盘参数: log.flush.interval.messages, log.flush.interval.ms 和 log.flush.scheduler.interval.ms.")]),_._v(" "),v("li",[v("strong",[_._v("在消费者这边, 只需要小心异步消费的问题就可以了")]),_._v(".")])]),_._v(" "),v("p",[v("strong",[_._v("而 Kafka 本身并不支持消息回查机制, 所以可以考虑利用 MySQL 来支持. 核心就是借鉴两阶段提交协议, 要求业务方先发准备消息, 再发提交消息. 如果没有发送提交消息, 就可以回查业务方. 对应的三个关键点就是回查怎么实现, 数据怎么存储, 准备消息和提交消息怎么保持有序")]),_._v("?")]),_._v(" "),v("p",[_._v("这里再强调一点, 几次提到重试的时候就应该能够想到, 这必然会导致重复消费, 也因此要求消费者必须是幂等的.")]),_._v(" "),v("p",[_._v("同时, 结合延迟消息, 给了两个增强 Kafka 功能的方案. 如果有时间, 可以尝试自己把它们两者融合在一起, 做成一个开源框架. 一方面, 这两个方案都要求支持高并发, 高性能, 大数据, 对你来说很能锻炼自己设计和实现一个系统的能力. 另外一方面, 如果真的能够按照开源标准做出来, 那么只要不是面什么高级架构师之类的岗位, 就都能赢得竞争优势.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a3b33a0dc84166b8ebaa35fea709920d-20231223175002-nbq5f05.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-19"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-19"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后请来思考两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("在支持 Kafka 回查机制中, 要是回查中间件把消息转发到业务 topic 了, 但是标记成已发送失败, 会发生什么?")]),_._v(" "),v("li",[_._v("在支持 Kafka 回查机制中, 你可以考虑把关系型数据库换成 Redis, 这样换的话有什么优缺点?")])]),_._v(" "),v("h4",{attrs:{id:"_27-重复消费-高并发场景下怎么保证消息不会重复消费"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_27-重复消费-高并发场景下怎么保证消息不会重复消费"}},[_._v("#")]),_._v(" 27-重复消费:高并发场景下怎么保证消息不会重复消费?")]),_._v(" "),v("p",[_._v("今天来讨论一个在消息队列里面非常常见的话题——重复消费.")]),_._v(" "),v("p",[_._v("通过前面几节课的学习, 我相信你已经发现了, 很多方案都会引起一个问题: "),v("strong",[_._v("消息重复发送或者重复消费")]),_._v(". 而解决的思路基本上一致, 就是把消费者设计成"),v("strong",[_._v("幂等")]),_._v("的. 也就是说, 同一个消息, 不管消费多少次, 系统状态都是一样的.")]),_._v(" "),v("p",[_._v("另外一个经常和幂等联系在一起的话题就是"),v("strong",[_._v("重试")]),_._v(". 就像在微服务部分接触到的那样, 为了提高可用性, 经常会引入各种重试机制. 而重试的一个前提就是重试的动作必须是幂等的. 所以, 在面试中幂等是一个绕不开的话题. 只不过"),v("strong",[_._v("大部分人在讨论幂等的时候, 只能想到使用唯一索引, 而且即便回答唯一索引, 也很难深入")]),_._v(".")]),_._v(" "),v("p",[_._v("所以今天就从重复消费讨论到幂等, 最后给出一个非常强大的高并发幂等方案.")]),_._v(" "),v("h5",{attrs:{id:"布隆过滤器"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#布隆过滤器"}},[_._v("#")]),_._v(" 布隆过滤器")]),_._v(" "),v("p",[_._v("布隆过滤器(Bloom Filter)是一种数据结构, 它可以用于检索一个元素是否在一个集合里. 它的优点是空间效率和查询时间都远远超过一般的算法, 缺点是存在假阳性的问题, 还有对于删除操作不是很友好.")]),_._v(" "),v("p",[v("strong",[_._v("布隆过滤器的基本思路是当集合加入某个元素的时候, 通过哈希算法把元素映射到比特数组的 N 个点, 把对应的比特位设置成 1")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5fbcbde15331c56b13f6d8b31f808987-20231223175002-s798hsz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在查找的时候, 只需要看对应的比特位是不是 1, 就可以粗略判断集合里有没有这个元素.")]),_._v(" "),v("ul",[v("li",[_._v("如果查询的元素对应的 N 个点都是 1, 那么这个元素"),v("strong",[_._v("可能存在")]),_._v(". 如果布隆过滤器认为一个元素存在, 但是实际上并不存在, 也叫做"),v("strong",[_._v("假阳性")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7d7c6d626f25e363db78bd8cb4900a2b-20231223175002-an4j75u.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[v("mark",[v("strong",[_._v("任何一个点是 0, 那么这个元素必然不存在")])]),_._v(".")])]),_._v(" "),v("p",[_._v("因此布隆过滤器经常和其他手段结合在一起判断某个元素在不在. "),v("strong",[_._v("它在判断某个元素")]),_._v("​"),v("mark",[v("strong",[_._v("必定不存在")])]),_._v("​"),v("strong",[_._v("的场景下, 效果非常好")]),_._v(".")]),_._v(" "),v("p",[_._v("和布隆过滤器类似的还有"),v("mark",[v("strong",[_._v("位图")])]),_._v(" bit array, 也叫做 "),v("strong",[_._v("bit map")]),_._v(". 它也是用一个比特位来代表元素是否存在, 1 代表存在, 0 代表不存在. 它和布隆过滤器的核心区别是它"),v("strong",[_._v("不需要哈希函数")]),_._v(", 因为它的"),v("strong",[_._v("值本身就是一个数字")]),_._v(". 比如用户 ID 是数字, 那就可以把 ID 当成 bit array 的下标, 对应位置的比特位是 1.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a075bf11593815e08c9357b636ff785a-20231223175002-exrhtie.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("并且 bit array 不存在假阳性的说法, 它的判断是精确的.")]),_._v(" "),v("h5",{attrs:{id:"重复消费的可能原因"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#重复消费的可能原因"}},[_._v("#")]),_._v(" 重复消费的可能原因")]),_._v(" "),v("p",[_._v("重复消费的可能原因有 2 种.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("生产者重复发送")]),_._v(". 比如业务在发送消息的时候, 收到了一个超时响应, 这个时候很难确定这个消息是否真的发送出去了, 那么就会考虑重试, 重试就可能导致同一个消息发送了多次.")]),_._v(" "),v("li",[v("strong",[_._v("消费者重复消费")]),_._v(". 比如在处理消息完毕之后, 准备提交了. 这个时候突然宕机了, 没有提交. 等恢复过来, 会再次消费同一个消息.")])]),_._v(" "),v("p",[_._v("在"),v("strong",[_._v("避免重复消费")]),_._v("的实践中就记住一个原则: "),v("mark",[v("strong",[_._v("一定要把消费逻辑设计成幂等的")])]),_._v(". 微服务也要尽可能设计成幂等的, 这样上游就可以利用重试来提高可用性了. 另外要说明一点, 现在大多数消息中间件都声称自己实现了"),v("strong",[_._v("恰好一次(exactly once)语义")]),_._v(", 都是依赖于重试和幂等来达成的.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-27"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-27"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要弄清楚一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你负责的"),v("strong",[_._v("业务里面有没有接口或消费者是要求幂等的? 如果有, 你是如何解决幂等的")]),_._v("?")]),_._v(" "),v("li",[_._v("如果你"),v("strong",[_._v("依赖于唯一索引来解决幂等, 那么这部分的写流量有多大")]),_._v("?")]),_._v(" "),v("li",[_._v("如果你"),v("strong",[_._v("依赖于唯一索引来解决幂等, 那么你是怎么保证业务操作和将数据插入到唯一索引是同时成功, 或者同时失败的")]),_._v("?")]),_._v(" "),v("li",[_._v("你或者你的同事有没有因为没有设计幂等, 或者幂等方案有问题而引起线上事故? 如果有, 你是怎么解决的?")]),_._v(" "),v("li",[_._v("你的业务"),v("strong",[_._v("是否使用过布隆过滤器, 如果有, 当时用来解决什么问题")]),_._v("?")])]),_._v(" "),v("p",[_._v("重复消费, 重试, 幂等是设计系统的时候经常要解决的问题, 所以可以在项目介绍或者自我介绍的时候主动提起你设计过比较复杂的幂等解决方案. 还有在面试过程中, 如果面试官聊到了布隆过滤器, 那么可以主动提起用布隆过滤器实现过幂等方案. 类似地, 聊到了 bit array 也可以提起幂等方案. 当聊到 Redis 的 key 过期时间该怎么确定的时候, 可以用幂等方案里的 Redis key 过期时间的计算方式来作为例子.")]),_._v(" "),v("p",[_._v("下面来看一下关于重复消费的基本面试思路.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-19"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-19"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("在面试的时候, 不管是提到重试还是提到重复消费, 面试官大概率都会问怎么解决幂等的问题, 可以先介绍一个简单的思路, 就是"),v("strong",[_._v("利用唯一索引")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("最简单的幂等方案就是利用唯一索引. 比如说在业务处理的时候, 先根据消息内容往业务表里面插入一条数据, 而这个业务表上有唯一索引. 如果插入成功了就说明这个消息没有被处理过, 可以继续处理. 如果插入的时候出现了唯一索引错误, 那就说明这个消息之前被处理过了.")])]),_._v(" "),v("p",[_._v("如果想要用这个简单的方案刷出亮点, 就需要补充足够多的细节. 第一个亮点就是深入讨论"),v("strong",[_._v("究竟是怎么将数据插入到唯一索引的")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"本地事务将数据插入到唯一索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#本地事务将数据插入到唯一索引"}},[_._v("#")]),_._v(" 本地事务将数据插入到唯一索引")]),_._v(" "),v("p",[_._v("在这个方案里面, 当第一次处理请求的时候, "),v("strong",[_._v("把数据插入到唯一索引成功了, 万一后面处理业务失败了怎么办")]),_._v("?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a0b4cf1256bd63c362fbb7885386f03c-20231223175002-9pcqydc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个时候应该使用"),v("strong",[_._v("事务")]),_._v(". 也就是说, 收到消息之后就"),v("strong",[_._v("开启一个本地事务")]),_._v(". 在这个本地事务里面会"),v("strong",[_._v("同时完成业务操作和将数据插入到唯一索引这两个操作, 然后提交")]),_._v(". 当然, 很多情况下这个插入唯一索引的操作本身就是业务操作的一部分.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5253acb25af6da0a4298ab70c2ab7df4-20231223175002-6h2riey.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这种机制之下, 只会出现一种情况, 就是"),v("strong",[_._v("事务提交了, 但是提交消息失败了")]),_._v(". 显然你会再次消费同一条消息, 但因为事务都已经提交了, 所以下次消费的时候就会遇到唯一索引冲突的错误.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b366df0ba1c34ff505626eca10cd8fd-20231223175002-r9yt9cg.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果没有提交本地事务呢? 那就说明"),v("strong",[_._v("这个消息消费本身就失败了, 应该再次重试")]),_._v(". 所以可以进一步补充这个细节.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("要使用唯一索引, 最好的方式是把唯一索引和业务操作组合在一起, 做成一个事务")]),_._v(". 也就是在收到消息的时候先开启事务, 把数据插入到唯一索引, 然后执行业务操作, 最后提交事务. 提交事务之后, 就认为业务已经成功了, 就算接下来提交消息失败了也没关系, 因为后面重复请求还是会被唯一索引拦下来. 不过万一不能使用本地事务, 比如说在分库分表的条件下, 那么解决方案就会更加麻烦.")])]),_._v(" "),v("p",[_._v("这最后一句可以把话题引向另一个亮点.")]),_._v(" "),v("h6",{attrs:{id:"非本地事务将数据插入到唯一索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#非本地事务将数据插入到唯一索引"}},[_._v("#")]),_._v(" 非本地事务将数据插入到唯一索引")]),_._v(" "),v("p",[_._v("如果没有本地事务, 业务操作和将数据插入到唯一索引的操作就不能看作是一个整体, 无法保证要么都成功, 要么都失败. 这时候, 只能"),v("strong",[_._v("追求最终一致性, 依赖于一个第三方来检测")]),_._v("了.")]),_._v(" "),v("p",[_._v("这种情况下整个方案的执行步骤也不一样, 它分成 3 步.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("把数据插入到唯一索引, 但是这个时候状态被标记为初始状态")]),_._v(". 注意这一步一定要先执行, 这是避免重复处理的关键.")]),_._v(" "),v("li",[v("strong",[_._v("执行业务操作")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("将唯一索引对应的数据标记为完成状态")]),_._v(".")])]),_._v(" "),v("p",[_._v("出问题的地方就是"),v("strong",[_._v("第二步成功了, 但是第三步失败")]),_._v("了. 这时候就需要使用一个异步检测系统, 这个"),v("mark",[v("strong",[_._v("异步检测系统会 定时扫描 唯一索引的表, 然后再去扫描业务表")])]),_._v(". 这个时候会有两种情况.")]),_._v(" "),v("ul",[v("li",[_._v("如果业务表的数据表明业务操作已经处理成功了, 那么这个异步检测系统就会把唯一索引更新为成功状态.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2c9229d32016fede98b4bf7e2a383a58-20231223175002-szb8c44.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ul",[v("li",[_._v("如果业务表的数据表明业务操作没有成功, 那么异步检测系统可以"),v("strong",[_._v("直接触发重试")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b604dcb080624a6240fea5ec82735b57-20231223175002-uym8ilj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以可以抓住关键词 "),v("strong",[_._v("异步检测")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在不能使用本地事务的时候, 实现幂等就更加麻烦了, 因为不能再把业务操作和将数据插入到唯一索引这两步做成原子操作. 所以我们的解决方案是追求最终一致性, 基本步骤是这样的. 首先把数据插入到唯一索引里面, 避免重复消费, 这个时候数据保持在初始化状态. 然后执行业务操作, 执行业务操作之后, 把唯一索引里的数据更新为成功状态.")]),_._v(" "),v("p",[_._v("那么会出问题的地方就是第二步成功了, 但是第三步失败了. 在这种场景下, 需要启动一个异步检测系统定时扫描初始状态的唯一索引数据. 这个异步检测系统会检测唯一索引的数据和业务数据, 判断是否一致. 如果不一致, 那么如果这个时候业务操作已经成功, 那么就把唯一索引的数据标注为成功; 如果这个时候业务失败了, 那么就应该触发重试.")])]),_._v(" "),v("p",[_._v("到这一步, 我觉得就算是单纯用唯一索引这个解决方案来面试, 也可以和其他面试者已经拉开差距了. 不过还有一个更加强大的方案, 能让你的优势更加明显.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-布隆过滤器-redis-唯一索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-布隆过滤器-redis-唯一索引"}},[_._v("#")]),_._v(" 亮点方案:布隆过滤器+Redis+唯一索引")]),_._v(" "),v("p",[_._v("这里给一个非常高级的方案, 这个方案综合运用了大数据处理中常见的布隆过滤器, Redis 和唯一索引. 从思路上来说, 就是四个字"),v("mark",[v("strong",[_._v("层层削流")])]),_._v(". 从目标上来说, 就是"),v("mark",[v("strong",[_._v("确保到达数据库的流量最小化")])]),_._v(".")]),_._v(" "),v("p",[_._v("前面的基本方案里讨论的是使用唯一索引, 并且提及了这种方案的缺陷, 就是"),v("strong",[_._v("性能完全取决于数据库的性能")]),_._v(". 很明显, 数据库是撑不住高并发的, 尤其是高并发写流量. 所以就要想尽一切办法让流量在到达数据库之前就返回了.")]),_._v(" "),v("p",[_._v("这时就需要一个高效的数据结构, 帮助"),v("strong",[_._v("判断某个请求或者消息是否已经被处理过")]),_._v("了. 布隆过滤器就非常适合用来解决这个问题. 但是布隆过滤器本身存在假阳性的问题. 也就是说, 一个消息明明没有被处理过, 但是布隆过滤器可能误报处理过了. 所以"),v("strong",[_._v("可以在布隆过滤器之后再加一个 Redis, 存储近期处理过的业务 key")]),_._v(".")]),_._v(" "),v("p",[_._v("所以整个流程就变成了图片中展示的这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/31de9d54e0d922179e27234d8a02yy27-20231223175002-84j4jos.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在面试的时候可以先介绍下这个方案的基本流程.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在公司设计过一个高并发的幂等方案. 这个幂等方案需要用到布隆过滤器, Redis 和唯一索引. 方案的基本思路是, "),v("mark",[_._v("如果依赖于数据库唯一索引来判断幂等, 那么数据库撑不住高并发")]),_._v(". 所以就想办法在使用唯一索引之前, 尽可能先削减流量. 这个场景就非常适合"),v("mark",[_._v("使用布隆过滤器")]),_._v(". 而为了避免假阳性的问题, 进一步降低发送到数据库的流量, "),v("mark",[_._v("在布隆过滤器和数据库之间再引入一个 Redis")]),_._v(".")]),_._v(" "),v("p",[_._v("基本流程是这样的:")]),_._v(" "),v("p",[_._v("首先, 一个请求过来的时候, 会利用布隆过滤器来判断它有没有被处理过. 如果布隆过滤器说没有处理过, 那么就确实没有被处理过, 可以直接处理. 如果布隆过滤器说处理过(可能是假阳性), 那么就要执行下一步.")]),_._v(" "),v("p",[_._v("第二步就是利用 Redis 存储近期处理过的 key. 如果 Redis 里面有这个 key, 说明它的确被处理过了, 直接返回, 否则进入第三步. 这一步的关键就是 key 的过期时间应该是多长.")]),_._v(" "),v("p",[_._v("第三步则是利用唯一索引, 如果唯一索引冲突了, 那么就代表已经处理过了. 这个唯一索引一般就是业务的唯一索引, 并不需要额外创建一个索引.")])]),_._v(" "),v("p",[_._v("面试官大概率会先问布隆过滤器的基本知识, 然后追问其中的一些细节, 现在一个一个看.")]),_._v(" "),v("h6",{attrs:{id:"更新顺序"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#更新顺序"}},[_._v("#")]),_._v(" 更新顺序")]),_._v(" "),v("p",[_._v("第一个问题: 业务方第一次处理完这个请求, 该怎么更新这个系统? "),v("mark",[v("strong",[_._v("先更新布隆过滤器, 还是先更新 Redis, 或者是先更新数据库的唯一索引")])]),_._v("?")]),_._v(" "),v("p",[_._v("答案是"),v("strong",[_._v("先更新数据库的唯一索引, 因为数据库里的数据是最准确")]),_._v("的.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果业务方是第一次执行这个请求, 它需要把更新数据库的操作放到自己的业务本地事务里面. 等业务方提交的时候, 一起提交. 在数据库事务提交之后, 再去更新布隆过滤器和 Redis. 这时候失败了影响也不大, 因为最终重复请求被处理的时候, 会因为唯一索引冲突而报错, 这时候就知道这个请求是重复请求了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b7c4f76e9bf9da92e61786baf1637ee8-20231223175002-c7sh7h2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("后面无论是先更新布隆过滤器, 还是先更新 Redis, 或者并发更新, 都是可以的")]),_._v(", 这一点不太重要.")]),_._v(" "),v("p",[_._v("可以说这个方案"),v("mark",[v("strong",[_._v("最终都是要依靠唯一索引来兜底的. 也就是说不管什么原因导致布隆过滤器或者 Redis 没生效, 只要跑到了插入唯一索引这一步, 都可以确保最终不会重复处理消息或者请求")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"redis-key的过期时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redis-key的过期时间"}},[_._v("#")]),_._v(" Redis key的过期时间")]),_._v(" "),v("p",[_._v("刚刚提到了一个关键点, 就是 key 的过期时间应该多长这个问题. 简单来说, Redis 的作用就是在布隆过滤器之后进一步削减流量, 而 key 的过期时间就决定了削减流量的效果, 所以只需要确保重复请求过来的时候, 这个 key 还没过期就可以了.")]),_._v(" "),v("p",[_._v("如果面试官问起来, 可以这么回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("Redis 这一步是为了进一步削减流量, 关键就是要确保重复请求过来的时候, key 还没过期. 举个例子, 假如说预计某个特定业务的重试请求会在 10 分钟内到达, 那么可以把过期时间设置成 11 分钟, 多出来的一分钟就是余量.")])]),_._v(" "),v("p",[_._v("这个地方也可以进一步总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("但是如果并发非常高, 以至于 key 非常多, 也要考虑 Redis 能不能放下这么多 key. 另外一个就是有些业务的重试间隔非常长, 比如说一小时, 这就不太适合引入 Redis 了. 可以考虑使用这个方案的简化版本.")])]),_._v(" "),v("h6",{attrs:{id:"简化方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#简化方案"}},[_._v("#")]),_._v(" 简化方案")]),_._v(" "),v("p",[_._v("这个三合一的方案, 也可以简化成二合一方案. 第一种就是"),v("strong",[_._v("布隆过滤器+唯一索引")]),_._v(". 这种方案就比较适合重试间隔非常大的业务.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/552c4cbdcb6693486b589344da509a41-20231223175002-j6wrc92.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("还可以简化成 "),v("strong",[_._v("Redis + 唯一索引")]),_._v(", 如果 Redis 资源足够, 而且数据库性能比较差, 那么这个方案要更好一点.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e23ab1e80b43ac7760a1794d6522192b-20231223175002-oibv2yt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以介绍一下这两个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果说业务并发不是特别高, 或者不想用这么复杂的方案, 那么可以考虑使用简化方案.")]),_._v(" "),v("p",[_._v("第一种简化方案就是只用"),v("mark",[_._v("布隆过滤器和唯一索引")]),_._v(". 如果 Redis 资源不足, 又或者重复请求间隔太长, 导致使用 Redis 的效果不好, 那么就比较适合用这个简化方案. 第二种简化方案就是只用 "),v("mark",[_._v("Redis 和唯一索引")]),_._v(". Redis 资源多, 又或者担心布隆过滤器的假阳性问题, 就可以采用这个方案.")])]),_._v(" "),v("p",[_._v("最后总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("其实最开始的时候我是建议用第一个简化方案的, 后面如果发现假阳性问题非常严重, 那么就可以引入 Redis.")])]),_._v(" "),v("p",[_._v("接下来从"),v("strong",[_._v("优化性能")]),_._v("的角度来看, 第一个可以考虑的就是本地布隆过滤器.")]),_._v(" "),v("h6",{attrs:{id:"本地布隆过滤器"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#本地布隆过滤器"}},[_._v("#")]),_._v(" 本地布隆过滤器")]),_._v(" "),v("p",[_._v("当看到本地两个字的时候, 我不知道你有没有想起前面很多节里面, 都提过类似的解决方案. 这里要再一次使用"),v("strong",[_._v("本地内存来进一步提高性能")]),_._v("了. 整体思路是"),v("mark",[v("strong",[_._v("利用一致性哈希等类型的算法执行负载均衡, 确保同一个 key 的请求落到同一个实例上, 那就可以在这台机器上使用基于本地内存的布隆过滤器了")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bd6afdd990029bd961e3f939c2f36840-20231223175002-c8x2cpc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然, 在消息队列的场景下, 这个问题就变成了在发消息的时候要把同一个业务的消息发到同一个分区. 这样就可以在消费者身上使用基于本地内存的布隆过滤器了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/955c47ae7337bbe8da388cba1bfb86c7-20231223175002-m6k2jab.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而在使用了本地布隆过滤器之后, 也可以考虑把 Redis 替换为本地内存. 不过一般来说本地内存不多的话, 还是使用 Redis 比较好. 因为能够通过布隆过滤器的请求就已经是少数了, 不值得浪费宝贵的本地内存换取一点点性能的提升.")]),_._v(" "),v("p",[_._v("所以可以进一步阐述这个方案, 抓住关键词"),v("strong",[_._v("本地布隆过滤器")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在性能要求非常苛刻的情况下, 可以考虑使用本地布隆过滤器, 但这要和负载均衡结合在一起使用. 比如在消息消费的场景下, 应该要求生产者把同一个 key 的消息都发到同一个分区上, 这样对应的消费者就可以使用本地布隆过滤器了.")])]),_._v(" "),v("p",[_._v("紧接着可以补充一段话, 关键词就是"),v("strong",[_._v("重建本地布隆过滤器")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("本地布隆过滤器在"),v("mark",[_._v("服务器重新启动")]),_._v("之后, 重建起来也很简单, 基本上有两种思路. "),v("mark",[_._v("一种就是不用重建, 直接处理新请求. 在处理新请求的过程中, 逐步重建起布隆过滤器. 这种思路适合时效性很强的请求, 比如今天就不可能收到昨天的重复请求这种场景")]),_._v(".")]),_._v(" "),v("p",[_._v("另外一种思路就是利用过去一段时间的数据, 比如我预计今天收到的重复请求最多来自三天前, 那么就用这三天内处理过的请求来构建布隆过滤器.")]),_._v(" "),v("p",[_._v("布隆过滤器不准确也没关系, 反正有唯一索引兜底, 只需要小心不要让太多流量最终落到唯一索引上就可以.")])]),_._v(" "),v("p",[_._v("使用本地布隆过滤器就已经很快了, 但如果还想进一步提高性能, 那么就可以考虑下使用布隆过滤器的替代品.")]),_._v(" "),v("h5",{attrs:{id:"布隆过滤器的替代品"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#布隆过滤器的替代品"}},[_._v("#")]),_._v(" 布隆过滤器的替代品")]),_._v(" "),v("p",[_._v("在一些场景下, 可以用"),v("strong",[_._v("位图")]),_._v(". 如果 key 本身就是数字, 比如数据库某张表的自增主键, 像这种情况下, 位图性能更好, 并且更能节省内存.")]),_._v(" "),v("p",[_._v("那么面试有两种策略, 一种策略就是直接在前面介绍方案的基本流程的时候, 就把布隆过滤器换成位图. 另外一种策略就是补充说明, 强调这个方案 "),v("strong",[_._v("可以自由切换到位图上")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我这里还在布隆过滤器这边做了一个抽象, 也就是说, 对于一些业务, 其实可以把布隆过滤器换成位图的结构. 比如说某个业务要求判断幂等, 用的就是业务的自增主键, 那么他们就可以使用位图这个实现来判断幂等. 这里也有一个小技巧, 就是假如说自增主键的起点是 N, 那么在位图的第一位就可以表示为 N, 第二位表示为 N + 1, 这样就能进一步节省内存.")])]),_._v(" "),v("p",[_._v("最后的小技巧是平时使用位图的时候使用的. 有些时候为了防止竞争对手猜到自己的业务量, 自增主键不是从 0 开始的, 又或者在使用分布式 ID 的时候, ID 也不是从 0 开始的. 假如说最小的 ID 是 5,000,000. 那么位图里的第一个比特位就可以表示为 5,000,000, 第二个比特位就表示为 5,000,001.")]),_._v(" "),v("p",[_._v("到这一步, 幂等相关的内容就已经刷到极致了.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-26"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-26"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节课的内容. 最开始介绍了布隆过滤器, 这是理解后面方案的关键. 然后分析了一下重复消费的可能原因, 一个是生产者重复发送, 另一个是消费者重复消费.")]),_._v(" "),v("p",[_._v("总的来说, 解决重复消费的思路就一条: "),v("strong",[_._v("让消费者做到幂等")]),_._v(". 所以问题就是怎么做到幂等. 那么最简单的方案就是"),v("strong",[_._v("唯一索引")]),_._v(", 然后深入分析了"),v("strong",[_._v("有本地事务和没有本地事务这两种情况下怎么将数据插入到唯一索引")]),_._v(".")]),_._v(" "),v("p",[_._v("最后给出了一个"),v("mark",[v("strong",[_._v("布隆过滤器")])]),_._v(" "),v("mark",[v("strong",[_._v("+")])]),_._v(" "),v("mark",[v("strong",[_._v("Redis + 唯一索引的方案")])]),_._v(", 这个方案是真正能撑住高并发的幂等方案. 要理解它的基本步骤, 然后在面试过程中深入讨论如何更新系统, Redis 的 key 过期时间, 简化方案, 本地布隆过滤器, 布隆过滤器的替代品这几个点, 赢得面试的竞争优势.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/29819e0d5b0430b7c2ef56b790a7c49a-20231223175002-onzy643.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-20"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-20"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考 2 个问题.")]),_._v(" "),v("ul",[v("li",[_._v("我在基本思路的唯一索引部分画了一张图, 关键点是在 RR 隔离级别下重复请求的插入操作会被阻塞. 那么如果隔离级别不是 RR 的话, 你觉得会发生什么?")]),_._v(" "),v("li",[_._v("如果你的流量中, 几乎不存在重复请求, 比如说重复请求占比不到 1%, 那么你觉得最后一个方案的效果如何?")])]),_._v(" "),v("h4",{attrs:{id:"_28-架构设计-如果让你设计一个消息队列-你会怎么设计它的架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_28-架构设计-如果让你设计一个消息队列-你会怎么设计它的架构"}},[_._v("#")]),_._v(" 28-架构设计:如果让你设计一个消息队列,你会怎么设计它的架构?")]),_._v(" "),v("p",[_._v("今天学习消息队列的架构设计, 也就是如果让你设计一个消息队列, 你会怎么做.")]),_._v(" "),v("p",[_._v("这个话题在面试中属于很难的一类, 它要求你不仅要对 Kafka 本身有很深刻的理解, 也要对分布式系统设计与实现有很深刻的理解. 而且你还要在面试短短几分钟内说清楚, 就更难了. 如果没有准备凭着感觉回答的话, 大概率只能讲出生产者, 消费者这些比较浅显的东西, 不成体系.")]),_._v(" "),v("p",[_._v("所以今天就从理论和落地实践上讲清楚, 如果要设计一个消息队列, 要解决哪些问题. 很多跟消息队列有关的知识已经在前面学过了, 所以直接从面试准备开始.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-28"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-28"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("如果你所在的公司并没有使用任何消息队列之类的中间件, 那么就需要搞清楚公司是如何做到解耦, 异步和削峰的. 当然, 如果所在公司有一些历史比较悠久的系统, 尤其是在 Kafka 等消息队列兴盛起来之前就已经存在的系统, 也可以去找找它们是如何解决类似问题的.")]),_._v(" "),v("p",[_._v("此外还可以进一步去了解下面这些实现.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("基于内存的消息队列, 一般用于进程内的事件驱动")]),_._v(", 又或者用于替代真实的消息队列参与测试.")]),_._v(" "),v("li",[v("strong",[_._v("基于 TCP 的消息队列")]),_._v(". 这种消息队列是指生产者直接和消费者连在一起, 没有 broker. 生产者会直接把消息发给消费者.")]),_._v(" "),v("li",[v("strong",[_._v("基于本地文件的消息队列, 也就是生产者直接把消息写入到本地文件, 消费者直接从本地文件中读取")]),_._v(".")])]),_._v(" "),v("p",[_._v("它们也不一定都叫做消息队列, 但是基本的形态都是发布-订阅模式.")]),_._v(" "),v("p",[_._v("我在面试思路里面讲述的内容也不是只能用于回答如何设计一个消息队列, 下面这些问题也可以用里面的内容来回答.")]),_._v(" "),v("ul",[v("li",[_._v("Kafka 为什么要引入 topic?")]),_._v(" "),v("li",[_._v("Kafka 为什么要引入分区? 只有 topic 行不行?")]),_._v(" "),v("li",[_._v("Kafka 为什么要强调把 topic 的分区分散在不同的 broker 上?")]),_._v(" "),v("li",[_._v("Kafka 为什么要引入消费者组概念? 只有消费者行不行?")])]),_._v(" "),v("h5",{attrs:{id:"面试思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路"}},[_._v("#")]),_._v(" 面试思路")]),_._v(" "),v("p",[_._v("面试官问到这个问题本身只是希望你能"),v("strong",[_._v("站在设计者的角度")]),_._v(", 阐述 Kafka 等消息队列为什么设计成当前的形态. 那么就要围绕生产者, 消费者, broker 和 topic 这 4 个方面来阐述消息队列设计的关键点.")]),_._v(" "),v("blockquote",[v("p",[_._v("目前主流的消息队列已经很强大了, 所以可以考虑参考它们的设计. 现在的消息队列都有几个概念: 生产者, 消费者, Broker 和 topic. 这里以 MySQL 为例, 讲述怎么在 MySQL 的基础上封装一个消息队列.")])]),_._v(" "),v("p",[_._v("那么接下来就可以一个一个介绍你准备怎么设计. 因为单纯讲设计是一个很干巴巴的事情, 这里就用之前接触过的基于数据库封装消息队列的案例来辅助说明.")]),_._v(" "),v("h6",{attrs:{id:"topic设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#topic设计"}},[_._v("#")]),_._v(" topic设计")]),_._v(" "),v("p",[_._v("前面已经知道, 一个 topic 会有若干个分区, 而这些分区是分散在不同的 broker 上的. 那设计肯定是不能脱离这些已有的成熟方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("首先我也会保留 topic 和分区的设计. 现代的消息队列基本上都有类似的结构, 只是名字可能不一样, 有些叫分区 Partition, 有些叫队列 Queue.")])]),_._v(" "),v("p",[_._v("然后要站在设计者的角度补充"),v("strong",[_._v("为什么要这么设计")]),_._v(", 也就是侧面阐述 Kafka 设计的精髓.")]),_._v(" "),v("blockquote",[v("p",[_._v("topic 是必不可少, 因为它代表的是不同的业务. 然后面临的选择就是要不要在 topic 内部进一步划分分区. 假如说不划分分区的话, 有一个很大的缺点, 就是并发竞争, 比如所有的生产者都要竞争同一把锁才能写入到 topic, 消费者要读取数据也必须竞争同一把锁才能读取数据, 这样性能很差. 所以 topic 内部肯定要进一步细分, 因此需要引入分区的设计.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c0750ff9f9c14307f3ecf03d2cf7f0c4-20231223175002-90g8x2l.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后讨论在 MySQL 上怎么把 topic 和表关联起来, 关键词就是"),v("strong",[_._v("一个 topic 一个逻辑表")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("结合 MySQL 的特性, 最基础的设计就是一个 topic 是一个逻辑表, 而对应的分区就是对这个逻辑表执行分库分表之后得到的物理表. 举个例子, 假如说有一个叫做 create_order 的 topic, 那么就代表我有一个逻辑上叫做 create_order 的表. 如果这个 topic 有 3 个分区, 那么就代表我有 create_order_0, create_order_1 和 create_order_2 三张物理表. 这种情况下, 每一张表都可以用自增主键, 这个自增主键就对应于 Kafka 中的偏移量.")])]),_._v(" "),v("p",[_._v("上面这个回答还提到了分库分表, 那么面试官可能将话题引导到分库分表上.")]),_._v(" "),v("p",[_._v("这里你可能会困惑, 包括面试官也可能会问, 为什么要这么设计? 为什么不能所有的 topic 都用一张逻辑表, 里面有一个 topic 的列呢? 这个时候就要抓住 "),v("strong",[_._v("性能和隔离")]),_._v(" 两个点来解释.")]),_._v(" "),v("blockquote",[v("p",[_._v("之所以不采用所有 topic 都共用一张逻辑表, 有两方面的原因. 首先是一张表, 难以应付大数据与高并发的场景, 即便分库分表, 也要分出来几千张表, 实在犯不着; 其次 topic 天然就是业务隔离的, 因此让不同 topic 用不同的表, 那么相互之间就没有影响了.")])]),_._v(" "),v("p",[_._v("接着可以引出 broker 的话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("而且使用不同的表, 能更好地安排不同的数据库实例来存储.")])]),_._v(" "),v("h6",{attrs:{id:"broker与消息存储"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#broker与消息存储"}},[_._v("#")]),_._v(" broker与消息存储")]),_._v(" "),v("p",[_._v("当确定了 topic 和分区两个概念之后, 接着就是怎么存储这些 topic 和分区. Kafka 在存储分区的时候, 是尽量做到分散开来, 所以设计也要遵循这一点.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步保证可用性, 同一个 topic 的不同分区最好分散在不同的 broker 上存储. 这样即便某一个 broker 崩溃了, 这个 topic 也最多只有一个分区受到了影响.")])]),_._v(" "),v("p",[_._v("如果要利用数据库来做到这一点, 那么就是把表分散在不同的数据库上, 换句话说就是, 一个 topic 的不同分区, "),v("strong",[_._v("不仅要分表, 还要分库")]),_._v(". 这里的分库更加准确地说是"),v("strong",[_._v("分数据源")]),_._v(". 也就是说, 不同分区最好是存放在不同的主从集群上.")]),_._v(" "),v("blockquote",[v("p",[_._v("要想提高可用性, 最好的策略就是把分区分散在不同的主从集群上. 比如说有四个分区, 那么可以四个分区分别在四个不同的主从集群上. 优点是尽量分散了流量, 并且不同的主从集群之间互不影响.")])]),_._v(" "),v("p",[_._v("然后进一步指出, 主从集群本身就达成类似 Kafka 的副本效果, 只不过你没有 ISR 的概念.")]),_._v(" "),v("blockquote",[v("p",[_._v("主从集群就意味着每一个分区在从库都有对应的一份数据. 举个例子来说, 如果是一主两从, 那么就意味着每一个分区都有一个主分区和两个从分区. 使用 MySQL 的主从机制也意味着不需要管理主从选举的问题, 这样能够很大程度上减轻落地的难度.")])]),_._v(" "),v("h6",{attrs:{id:"发送消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#发送消息"}},[_._v("#")]),_._v(" 发送消息")]),_._v(" "),v("p",[_._v("在解决了 topic 和 broker 的问题之后, 接下来就要讨论发送者怎么发送了. 第一个要确定就是发送者发送应该是"),v("strong",[_._v("推模型还是拉模型")]),_._v(". 也就是发送者主动发给 broker 还是 broker 主动去拉取. 显然在发送者这个场景下, 应该是"),v("strong",[_._v("发送者来推送")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("就生产者来说, 它应该主动推送消息到 broker 上, 因为消息产生速率完全跟 broker 没有关系, 让 broker 来主动拉取的话, broker 不好控制拉的频率和拉的数量.")])]),_._v(" "),v("p",[_._v("紧接着可以深入进去, 讨论一下发送者发送性能的问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("批量发送")])]),_._v(" "),v("p",[_._v("同样可以借鉴 Kafka 优化发送者性能的措施, 就是批量发送.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了优化发送性能, 可以支持批量发送功能. 也就是生产者可以考虑凑够一个批次之后再发送. 这个批次大小可以让生产者来控制. 当然生产者也要考虑兜底措施, 也就是说如果在一段时间之内, 没有凑够一批数据也要发送, 防止消息长时间停留在生产者内存里面, 出现消息丢失的问题. Kafka 有类似的机制, 比如生产者可以通过 "),v("code",[_._v("linger.ms")]),_._v("​ 来控制生产者最终等待多长时间.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/306b1b3c5e5c698916695215a18be784-20231223175002-8x4j6ic.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个批量发送能够有效提高生产者的性能, 下一节会展开讨论. 除了这个批量发送, 还有另外一个做法, 就是"),v("strong",[_._v("生产者直接插入数据到消息表")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("直接插入消息")])]),_._v(" "),v("p",[_._v("在 MySQL 的实现里面, 消息最终是存储在数据库里面, 既可以通过 broker 来访问这个数据库, 也可以"),v("strong",[_._v("让生产者直接访问这个数据库")]),_._v(". 后者也可以认为生产者和 broker 就是一体的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/051b5ab3172142b4bbcb55ec10b217b1-20231223175002-sw67m28.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("如果要追求极致的性能, 那么可以考虑让生产者直接把消息插入到数据库里. 生产者需要引入一个本地依赖, 本地依赖会根据消息的 topic, 分区找到对应的数据库配置, 初始化连接池. 而发送消息就是调用本地依赖的本地方法, 这个方法会执行一个 INSERT 语句, 插入消息. 这样做的好处就是省略了一次网络中间通信. 同样地, 也可以使用批量插入来进一步提高性能. 在消费者端也可以采用这样的措施.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5484360d557656d2a6999c471fdc0771-20231223175002-kagqrxt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"消费消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消费消息"}},[_._v("#")]),_._v(" 消费消息")]),_._v(" "),v("p",[_._v("显然, 可能会有不同的业务方消费同一个 topic 的消息, 所以需要引入消费者组和消费者的概念.")]),_._v(" "),v("blockquote",[v("p",[_._v("在消费消息的时候, 同样需要引入消费者组和消费者的概念. 一个业务方就是一个消费者组, 一个消费者组里面可以有多个消费者. 在 Kafka 里面, 每一个分区有一个消费者, 但是一个消费者可以消费多个分区. 那么我这里也保留了这种设计, 每一个分区是一张表, 这张表对于一个消费者组来说, 只能有一个消费者读取消息.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c731a33b81325c52302b3ffd0aa645af-20231223175002-3wrzils.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("接着要指出"),v("strong",[_._v("消费者这边使用拉模型会更好")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("因为消费者才知道自己的消费速率, 所以消费者这边用拉模型, 例如每 1s 从消息队列中拉取 50 条消息.")])]),_._v(" "),v("p",[_._v("这时候就会有另外一个问题, 就是"),v("strong",[_._v("怎么记录一个消费者已经消费了哪些消息")]),_._v("?")]),_._v(" "),v("blockquote",[v("p",[_._v("记录偏移量")])]),_._v(" "),v("p",[_._v("既然用的是 MySQL, 那么自然就是用另外一张表来记录了, 而且同样保持每个 topic 都有一张表, 例如 create_order 有一个对应的表叫做 create_order_consumers, 里面记录了消费 create_order 这张表的消费者组和消费者数量.")]),_._v(" "),v("p",[_._v("这张表的设计也很简单, 主要包含三列: "),v("strong",[_._v("消费者组的名字, 分区, 已消费偏移量")]),_._v(". 假如说 create_order 这个 topic 有搜索和推荐两个业务方消费消息, 那么 create_order_consumers 这张表的数据就类似于下面这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/336590202310cf188a614a895f5122c1-20231223175002-i6jy6gk.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("为了存储每一个消费者消费的偏移量, 需要一张新的表. 比如说在 create_order 这个例子里面, 有一张表叫做 create_order_consumers. 这张表有三个关键列: 消费者组名字, 分区和偏移量. 而每次消费者提交消息, 对于 borker 来说就是更新这张表的偏移量.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a1b1935b0e3e7841d3a025d5301a3bd4-20231223175002-q44kmaa.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着就要介绍一下消息队列惯常支持的"),v("strong",[_._v("指定偏移量消费")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("对于消费者来说, 它也可以消费指定偏移量的消息, 比如最开始消费到了偏移量 1000 的消息, 现在因为业务出了问题, 要从偏移量 100 的消息重新消费. 这种时候, 只需要更新 commited_offset 为 100 就可以了.")])]),_._v(" "),v("p",[_._v("可以理解为 broker 就是执行一下这种语句.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("UPDATE")]),_._v(" create_order_consumers "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SET")]),_._v(" committed_offset"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("100")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("partition")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("2")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("and")]),_._v(" consumer_group "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token string"}},[_._v("'test'")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br")])]),v("p",[_._v("而消费者拉取消息, 实际上就是执行一个 SELECT 查询, 比如在前面的例子里, 重置偏移量到 100 之后, 再次拉取一批消息, 假如说一批是 50 条消息, 那么就执行这样的 SELECT 语句.")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" create_order_2 "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" id "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("100")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("LIMIT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("50")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br")])]),v("p",[_._v("然后要分析一下这样做的好处.")]),_._v(" "),v("blockquote",[v("p",[_._v("可以预见每一个 topic 都不会有很多消费者, 所以记录消费偏移量的表不会有很多数据. 而且在执行更新的时候, 也只会使用到行锁, 所以性能会很好.")])]),_._v(" "),v("p",[_._v("还可以考虑一些改进, 也就是不用 MySQL 来记录这个消费偏移量.")]),_._v(" "),v("blockquote",[v("p",[_._v("也可以参考 Kafka 之类的设计, 使用别的中间件来记录消费偏移量, 比如说 ZooKeeper.")])]),_._v(" "),v("p",[_._v("然后可以用一个 "),v("strong",[_._v("Redis 结合异步刷新")]),_._v("的方案来进一步刷亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("此外, 更新偏移量的操作并发非常高, 那么可以考虑使用 Redis 来记录消费偏移量, 然后异步刷新到数据库中.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2f5bb57794c5fb71db06abe9bde04d86-20231223175002-xynn4dn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但凡涉及到异步, 就应该想到数据丢失的问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("但这个方案存在的风险就是 Redis 可能突然宕机, 导致最新的偏移量没有更新到 MySQL 中. 比如数据库记录的消费偏移量是 950, 而消费者已经消费到了偏移量 1000, 但是因为 Redis 突然宕机, 以至于数据库里的偏移量还没更新为 1000. 当 Redis 再次恢复之后, 消费者就只能从 950 的位置重新消费. 这种情况下, 消费者做到幂等就可以.")])]),_._v(" "),v("p",[_._v("如果要提高性能, 也可以考虑让消费者直接连上数据库, 自己拉取消息.")]),_._v(" "),v("blockquote",[v("p",[_._v("直接拉取消息")])]),_._v(" "),v("p",[_._v("类似于生产者直连数据库, 消费者也可以考虑直连数据库.")]),_._v(" "),v("blockquote",[v("p",[_._v("还有一个优化消费者性能的地方, 就是提供一个本地依赖, 让消费者通过这个本地依赖直连数据库, 直接从数据库中读取消息. 同样地, 消费者也通过这个本地依赖来提交消息.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/65b1a55e7218cc25b6c9bf488fe67433-20231223175002-i7ttg13.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"延迟消息"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#延迟消息"}},[_._v("#")]),_._v(" 延迟消息")]),_._v(" "),v("p",[_._v("这个方案有一个很大的好处, 就是它很容易"),v("strong",[_._v("实现延迟消息")]),_._v(". 关键操作就是在消息表里面加上一个预期发送时间. 而消费者拉取消息的时候, 执行的语句类似于下面这样:")]),_._v(" "),v("div",{staticClass:"language-sql line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-sql"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("SELECT")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("FROM")]),_._v(" some_topic\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("WHERE")]),_._v(" send_time "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("<=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("now")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("AND")]),_._v(" send_time "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(">")]),_._v(" $last_batch_send_max_time\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br")])]),v("p",[_._v("上面 SQL 中的参数 "),v("code",[_._v("$last_batch_send_time")]),_._v("​ 就是消费者拉取出来的一批消息中最大的那个发送时间. 你应该注意到了, 在这种形态下, 需要记录的就不是消费偏移量, 而是时间戳了. 比如说对于某个消费者, 应该记录它已经消费到了哪个时间点的延迟消息.")]),_._v(" "),v("p",[_._v("所以可以先简单介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我这个方案很容易支持延迟消息, 只需要在消息表里面加上一个 send_time 的列记录预期发送时间的毫秒数就可以. 比如说消费者拉取消息的时候就是执行类似这样一个语句, "),v("code",[_._v("SELECT * FROM some_topic WHERE send_time <= now() AND send_time > last_batch_send_max_time")]),_._v("​. last_batch_send_max_time 就是消费者拉取出来的一批消息里最大的那个发送时间. 不过这里并不能用 LIMIT 来解决批次大小的问题, 因为这里要考虑同时发送的问题.")])]),_._v(" "),v("p",[_._v("最后一句话, 就是为了引出来同时发送的问题. 不需要立刻回答, 而是等着面试官来问. 问到了就先解释什么叫做同时发送.")]),_._v(" "),v("blockquote",[v("p",[_._v("举个例子来说, 数据库里面有 40 条消息是在 00:00.001 时刻发送, 50 条是在 00:00.002 时刻发送. 如果在 SELECT 语句里面加上 LIMIT 50, 那就会拿到 40 条 00:00.001 发送的消息, 10 条 00:00.002 发送的消息. 下一次执行的时候, WHERE send_time > 00:00.002 就会把剩下的 40 条 00:00.002 发送的消息全部跳过.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a53f088438c0b6646b4b2e597a14012d-20231223175002-mzjcr02.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("如果条件改成 WHERE send_time >= 00:00.002, 那么这一次拉出来的 10 条 00:00.002 消息会再次拉出来.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5e217c3f35a7yy06b23a6f4b2882bf46-20231223175002-00b2w0c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着就要说一下这个问题的解决方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("要解决这个问题就要在查询的时候, 不依赖于数据库计算 LIMIT, 而是自己算. 也就是说, 当拿到这个查询返回的结果集的时候, 首先读够50条. 然后检查第50条之后的数据, 如果 send_time 和第50条是一样, 那么就加入到当前批次来. 所以按照这个算法, 当前批次应该是把 00:00.001 和 00:00.002 两个时刻的数据都读到, 也就是有 90 条. 这个算法有一个基本假设, 也就是某一个时刻, 要发送的消息不会太多. 比如说特定某毫秒的消息, 连几十条可能都没有.")])]),_._v(" "),v("p",[_._v("如果面试官问这个方案的难点在哪里, 也可以用这个同时发送的问题来回答. 在其他类似的跟时间有关的场景下, 也需要考虑同样的问题, 所以解决思路还是比较有参考价值的.")]),_._v(" "),v("h6",{attrs:{id:"方案总结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案总结"}},[_._v("#")]),_._v(" 方案总结")]),_._v(" "),v("p",[_._v("这个方案还有一些点需要解释一下, 防止面试官突然问到相关的问题.")]),_._v(" "),v("p",[_._v("首先这个方案利用了数据库来作为存储, 而不是自己操作文件, 也就是避开了消息队列中对性能影响很大的 IO 方面的内容, 自然也就用不上零拷贝之类的技术.")]),_._v(" "),v("p",[_._v("这个方案是基于 MySQL 实现的, 也可以把 MySQL 换成 PostgreSQL 或者 Oracle. 在换成 Oracle 之后, 连分库分表都不需要, 因为 Oracle 完全撑得住高并发. 也可以考虑换成 TiDB 等分布式数据库.")]),_._v(" "),v("p",[_._v("你可能会觉得有点奇怪, 就是"),v("strong",[_._v("什么情况下会考虑用 MySQL 来实现一个消息队列? 答案是在一些 ToB 的场景下")]),_._v(". 比如 A 公司研发了一个软件, B 公司购买之后要求本地部署. A 公司研发的软件需要使用到消息队列, 但是 B 公司是一个小公司, 并不打算部署消息队列, 因为他们缺乏技术力量来维护这个消息队列. 那么 A 公司就可以考虑利用 MySQL 来封装一个消息队列, 比较典型的例子就是私有化部署的即时通讯工具.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-27"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-27"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这节深入讨论了设计一个消息队列应该要考虑的问题, 并且给出了基于 MySQL 实现的一个方案, 里面有一些要点需要记住.")]),_._v(" "),v("ul",[v("li",[_._v("一个 topic 一个逻辑表, 一个分区一个物理表.")]),_._v(" "),v("li",[_._v("同一个 topic 的不同分区对应的表, 应该尽可能分散在不同的数据库, 主从集群上.")]),_._v(" "),v("li",[_._v("生产者使用推模型, 主动推送消息.")]),_._v(" "),v("li",[_._v("生产者可以考虑使用批量发送, 直连数据库的方式提高性能.")]),_._v(" "),v("li",[_._v("一个 topic 一个消费偏移量表, 用来记录各个消费者组的消费进度.")]),_._v(" "),v("li",[_._v("消费者使用拉模型, 按照自己的消费能力按需拉取.")]),_._v(" "),v("li",[_._v("可以通过增加 send_time 这个列来支持延时队列.")])]),_._v(" "),v("p",[_._v("此外, 在面试中还有可能遇到类似的问题, 比如让你设计一个 Redis, 一个数据库, 或者 ZooKeeper. 如果"),v("strong",[_._v("没有提前准备这一类问题, 就可以回答相应中间件的核心原理")]),_._v(". 比如消息队列, 除了用 MySQL 来封装一个消息队列的核心设计, 其他的基本上都是在介绍 Kafka 的核心原理.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fa99f508e787e2a244b403b37198af08-20231223175002-4tootkf.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_29-高性能-kafka为什么性能那么好"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_29-高性能-kafka为什么性能那么好"}},[_._v("#")]),_._v(" 29-高性能:Kafka为什么性能那么好?")]),_._v(" "),v("p",[_._v("今天来讨论一个问题, Kafka 的性能为什么那么好?")]),_._v(" "),v("p",[_._v("Kafka 的高性能话题也算是热点了, 如果你面试的公司在并发量或者数据量上已经到了一定地步, 那么面试的时候大概率逃不过这个问题.")]),_._v(" "),v("p",[_._v("大部分人面不好这个部分的原因只有一个: Kafka 为了实现高性能采用的手段太多了, 以至于根本记不住. 这一节就先聚焦在 "),v("strong",[_._v("Kafka 本身为了高性能做了哪些事情")]),_._v(", 下一节再从实践出发, 告诉你怎么优化 Kafka 的性能.")]),_._v(" "),v("p",[_._v("先从 Kafka 的一些基本知识开始说起.")]),_._v(" "),v("h5",{attrs:{id:"kafka分段与索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka分段与索引"}},[_._v("#")]),_._v(" Kafka分段与索引")]),_._v(" "),v("p",[_._v("即便在同一个分区内部, Kafka 也进一步利用了"),v("strong",[_._v("分段日志和索引来加速消息查找")]),_._v(". 在 Kafka 内部, 一个"),v("strong",[_._v("分区的日志是由很多个段(segment)组成的, 每个段可以理解成一个文件")]),_._v(". 同一个 topic 的文件就存放在以 topic 命名的目录下.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5b02d02b705bfd1b6afd1000b462bbaf-20231223175002-g56vm2o.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了快速找到对应的段文件, 段日志文件使用了偏移量来命名. 假如说一个文件的名字是 N.log, 那么就表示这个段文件里第一条消息的偏移量是 N + 1.")]),_._v(" "),v("p",[_._v("这里就能猜到, Kafka 完全"),v("strong",[_._v("可以根据文件名来进行二分查找, 从而快速定位到段文件")]),_._v(".")]),_._v(" "),v("p",[_._v("为了加快段文件内的查找, "),v("strong",[_._v("每一个段文件都有两个索引文件")]),_._v(".")]),_._v(" "),v("ul",[v("li",[_._v("一个是偏移量索引文件, 存储着部分消息偏移量到存储位置的映射, 类似于 "),v("code",[_._v("<offset, position>")]),_._v("​ 这种二元组. 这个 offset 不是全局 offset, 是相对于这个文件第一条消息的偏移量. 也就是说假如第一条消息的全局偏移量是 1000, 那么偏移量为 1002 的消息的索引项是 "),v("code",[_._v("<2, pos1>")]),_._v("​.")]),_._v(" "),v("li",[_._v("一个是时间索引文件, 存储着时间戳到存储位置的映射, 类似于 "),v("code",[_._v("<timestamp, position>")]),_._v("​ 二元组.")])]),_._v(" "),v("p",[_._v("所以整个日志文件目录看上去是这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/880b85b2c0f64bdb72665b78615335e8-20231223175002-oz0av56.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("以这张图片为例, 假如说要查找 topic 为 test_topic, 分区为 1, 偏移量为 20000 的消息, 那么整个过程是这样的.")]),_._v(" "),v("ol",[v("li",[_._v("在日志目录下找到名字为 test_topic_1 的子目录, 里面就放着这个分区的消息日志文件.")]),_._v(" "),v("li",[_._v("在 test_topic_1 子目录下, 根据文件名进行二分查找, 可以确定 20000 这条消息应该放在010031.log 这个文件里面.")]),_._v(" "),v("li",[_._v("利用 010031.index 的内容进行二分查找, 查找索引项. 如果 20000 恰好有一个索引项 "),v("code",[_._v("<20000, pos0>")]),_._v("​, 那么就读取 pos0 这个位置的数据.")]),_._v(" "),v("li",[_._v("如果 20000 没有对应的索引项, 就找到比 20000 小的最接近 20000 的索引项, 假如有 "),v("code",[_._v("<19990, pos1>")]),_._v("​, 那么就从 pos1 往后遍历, 找到 20000 对应的数据.")])]),_._v(" "),v("p",[_._v("对应的根据时间查找也差不多. 这里要注意的是, "),v("strong",[_._v("索引文件放的只是部分消息对应的位置")]),_._v(", 因为 Kafka 希望索引文件能够装入内存. 这种思想之前提到过, 在讨论 MySQL 索引的时候也是默认索引都在内存里面.")]),_._v(" "),v("p",[_._v("为了帮助记忆, 这里整理成了三句话: "),v("strong",[_._v("topic 加分区定目录, 偏移量定文件, 索引定位置")]),_._v(". 记住这三句话就可以了.")]),_._v(" "),v("h5",{attrs:{id:"零拷贝"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#零拷贝"}},[_._v("#")]),_._v(" 零拷贝")]),_._v(" "),v("p",[_._v("零拷贝(zero copy)是中间件广泛使用的一个技术, 它能极大地提高中间件的性能. 所谓的"),v("mark",[v("strong",[_._v("零拷贝, 就是指没有 CPU 参与的拷贝")])]),_._v(". 要理解零拷贝, 要先从一般的读写操作开始讲起. 假如现在要从磁盘读取内容, 然后发送到网络上, 那么基本流程如图所示.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4ac629727b0538e96aeb2ed0c281ab15-20231223175002-unvqa53.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("DMA (Direct Memory Access)是一个独立于 CPU 的硬件, 所以不太在意 DMA 拷贝. NIC(Network Interface Card)就是指网卡.")]),_._v(" "),v("p",[_._v("这里面总共有四个步骤.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("应用进入内核态, 从磁盘里读取数据到内核缓存, 也就是读缓存. 这一步应用就是发了一个指令, 然后是 DMA 来完成的")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("应用把读缓存里的数据拷贝到应用缓存里, 这个时候切换回用户态")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("应用进入内核态, 把应用缓存里的数据拷贝到内核缓存里, 也就是写缓存")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("应用把数据从写缓存拷贝到 NIC 缓存里, 这一步应用也就是发了一个指令, DMA 负责执行")]),_._v(".")])]),_._v(" "),v("p",[_._v("而这里面总共有四次内核态与用户态的切换.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ee5003fd2cde138f4808e02bf887dd6f-20231223175002-mo405h0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为什么要那么复杂, 能不能不经过应用缓存, 直接让磁盘读到内核缓存, 然后内核缓存直接写到 NIC 缓存? 这样不是非常完美吗?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ee3ae14795834184909a34279dc2d704-20231223175002-k245u39.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("也可以, 而这就是零拷贝, "),v("strong",[_._v("对应的内核态-用户态切换, 也只剩下了两次")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/22af5f6b822a629a3847bb6da8e313c5-20231223175002-wftf6bw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么和最原始的操作比起来, 零拷贝少了两次内核态与用户态的切换, 还少了两次 CPU 拷贝. 但是"),v("strong",[_._v("零拷贝本身还是要用到 DMA 拷贝")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"批量操作的优势"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批量操作的优势"}},[_._v("#")]),_._v(" 批量操作的优势")]),_._v(" "),v("p",[_._v("批量操作在高性能中间件里面也很常见. 那么批量操作的优势究竟在哪里呢? 主要体现在两个方面: "),v("strong",[_._v("一个是更少的系统调用和内核态与用户态的切换, 还有一个是高效利用网络带宽")]),_._v(".")]),_._v(" "),v("p",[_._v("举个例子, 客户端每次都只发一个请求到服务端上, 如今要发 100 个请求. 现在客户端用了零拷贝技术, 那么客户端发送 100 个请求, 需要 100 次系统调用, 200 次内核态与用户态的切换. 而如果客户端一次性发送 100 个请求, 那么它只需要 1 次系统调用, 2 次内核态与用户态的切换.")]),_._v(" "),v("p",[_._v("在网络传输的时候, 每一次发送都有一个固定开销, 比如说协议头的部分, 这个开销大小和具体的协议设计有关. 假如每个请求大小是 1KB, 在网络传输的时候, 分 100 次传输 1KB 和 1 次传输 100KB, 后者也是明显快很多的. 前者需要传输 100 次协议头, 而后者只需要传输 1 次协议头.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/45b059b3a720a29a830c5e3edd43bfae-20231223175002-kb522uj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然这是指应用层协议, 如果是底层协议, 比如 TCP, 这方面也能节省一些, 但是效果不如应用层协议好.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-29"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-29"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("准备 Kafka 高性能的面试, 还可以在公司内部了解一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("公司有没有因为分区或者 topic 太多导致 Kafka 性能衰退的案例? 如果有, 当时是怎么解决的?")]),_._v(" "),v("li",[_._v("公司内部的 Kafka 用的是机械硬盘还是固态硬盘?")]),_._v(" "),v("li",[_._v("公司内部的 Kafka 能撑住的并发量是多大? 你的业务并发量是多大?")]),_._v(" "),v("li",[_._v("公司内部还有没有别的中间件也使用了类似的优化技术?")]),_._v(" "),v("li",[_._v("你在业务中有没有使用批量处理的技术来优化系统性能? 如果有, 具体是怎么做的?")])]),_._v(" "),v("p",[_._v("在面试中, 比较好的策略是根据自己对不同中间件的了解进行横向对比. 比如说聊到 WAL 的时候, 把它和 MySQL, Redis 进行对比. 这样能够凸显你对系统设计原则有深刻的理解.")]),_._v(" "),v("p",[_._v("当和面试官聊到了下面这些话题的时候, 都可以尝试引导到这节课的话题下.")]),_._v(" "),v("ul",[v("li",[_._v("你们聊到了 "),v("strong",[_._v("WAL 和 AOF")]),_._v(", 可以提及 Kafka 利用了类似的技术.")]),_._v(" "),v("li",[_._v("你们聊到"),v("strong",[_._v("操作系统的基本原理, 系统调用, 文件 IO 等, 就可以提及零拷贝, 批量处理技术在 Kafka 中的应用")]),_._v(".")]),_._v(" "),v("li",[_._v("你们聊到了"),v("strong",[_._v("并发优化的内容")]),_._v(", 那么可以用分区作为例子解释缩小并发粒度的好处.")]),_._v(" "),v("li",[_._v("你们聊到其他中间件采用了后面列举的技术, 那么就可以和 Kafka 对比, 深入阐述相关原理.")]),_._v(" "),v("li",[_._v("你们聊到了 K"),v("strong",[_._v("afka 消息怎么存储")]),_._v(", 那么就可以从性能的角度解释 Kafka 的分段和索引的优点.")])]),_._v(" "),v("p",[_._v("当然面试官不一定直接问你为什么 Kafka 性能那么高, 他也可能有多种问法.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司的 Kafka "),v("strong",[_._v("性能怎样")]),_._v("? 怎么做到的?")]),_._v(" "),v("li",[_._v("Kafka "),v("strong",[_._v("为什么要用零拷贝")]),_._v("?")]),_._v(" "),v("li",[_._v("分区太多为什么会导致 Kafka 性能衰退?")]),_._v(" "),v("li",[_._v("Kafka 为什么要用"),v("strong",[_._v("压缩技术")]),_._v("?")]),_._v(" "),v("li",[_._v("Kafka 是怎么查找到特定偏移量的消息的?")])]),_._v(" "),v("p",[_._v("这一类问题都可以用后面的内容来回答.")]),_._v(" "),v("h5",{attrs:{id:"面试思路-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路-2"}},[_._v("#")]),_._v(" 面试思路")]),_._v(" "),v("p",[_._v("Kafka 本身使用了很多手段来保证高性能, 包括"),v("strong",[_._v("零拷贝, page cache(页缓存), 顺序读写, 分区分段与索引, 批量处理, 压缩")]),_._v(". 其中"),v("mark",[v("strong",[_._v("零拷贝和顺序读写")])]),_._v("最重要, 是一定要能回答出来的.")]),_._v(" "),v("h6",{attrs:{id:"零拷贝-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#零拷贝-2"}},[_._v("#")]),_._v(" 零拷贝")]),_._v(" "),v("p",[_._v("前面已经了解了什么是零拷贝, 那在回答的时候就可以介绍零拷贝是如何运作的, 然后再总结零拷贝的优势.")]),_._v(" "),v("blockquote",[v("p",[_._v("零拷贝是中间件设计的通用技术, 是指完全没有 CPU 参与的读写操作. 以从磁盘读数据, 然后写到网卡上为例介绍一下. 首先, 应用程序发起系统调用, 这个系统调用会读取磁盘的数据, 读到内核缓存里面. 同时, 磁盘到内核缓存是 DMA 拷贝. 然后再从内核缓存拷贝到 NIC 缓存中, 这个过程也是 DMA 拷贝. 这样就完成了整个读写操作. 和普通的读取磁盘再发送到网卡比起来, 零拷贝少了两次 CPU 拷贝, 和两次内核态与用户态的切换.")])]),_._v(" "),v("p",[_._v("正常来说, 在回答里面不需要介绍普通的读取磁盘再发送的流程, 不过如果面试官问了, 就可以按照前置知识里面的内容来回答. 这里还有可能引申到操作系统相关的基本知识, 面试前也不要忘了复习.")]),_._v(" "),v("p",[_._v("然后再补充一句, 引出 page cache 的内容.")]),_._v(" "),v("blockquote",[v("p",[_._v("这里说的内核缓存, 在 linux 系统上其实就是 "),v("mark",[_._v("page cache")]),_._v(".")])]),_._v(" "),v("h6",{attrs:{id:"page-cache"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#page-cache"}},[_._v("#")]),_._v(" page cache")]),_._v(" "),v("p",[v("strong",[_._v("Kafka 把数据写入到 page cache 而不是直接刷新到磁盘上, 有效减少了真实的 IO 操作次数")]),_._v(".")]),_._v(" "),v("p",[_._v("另外一方面, Kafka 是基于 JVM 的, 所以直接操作 page cache 能够避开 JVM 的垃圾回收. 同时也能充分利用操作系统对 page cache 的优化.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 充分利用了 page cache. Kafka 写入的时候只是写入到了 page cache, 这几乎等价于一个内存写入操作, 然后依靠异步刷新把数据刷新到磁盘上. 而 page cache 是可以存放很多数据的, 也就是说 Kafka 本身调用了很多次写入操作之后, 才会真的触发 IO 操作, 提高了性能. 而且, Kafka 是基于 JVM 的, 那么利用 page cache 也能缓解垃圾回收的压力. 大多数跟 IO 操作打交道的中间件都有类似的机制, 比如说 MySQL, Redis.")])]),_._v(" "),v("p",[_._v("这里可以适当引导一下, 把话题引导到"),v("strong",[_._v("消息丢失")]),_._v("上.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过使用 page cache 的缺陷就是如果消息还没刷新到磁盘上, 服务器就宕机了, 那么整个消息就丢失了.")])]),_._v(" "),v("h6",{attrs:{id:"顺序写"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#顺序写"}},[_._v("#")]),_._v(" 顺序写")]),_._v(" "),v("p",[_._v("在写操作里面, 一般默认写是很慢的. 但是实际上, 写操作分成顺序写和随机写, 大家认为写操作很慢, 那都是随机写, 而"),v("strong",[_._v("顺序写本身并不慢, 所以要先指出顺序写的性能")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在计算机里面, 普遍认为写很慢, 但是实际上是随机写很慢, 但是顺序写并不慢. 即便是机械硬盘的顺序写也并不一定会比固态硬盘的顺序写慢.")])]),_._v(" "),v("p",[_._v("然后补充 Kafka 充分利用了顺序写.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 在写入数据的时候就充分利用了顺序写的特性. "),v("mark",[_._v("它针对每一个分区, 有一个日志文件 WAL(write-ahead log), 这个日志文件是只追加的, 也就是顺序写的, 因此发消息的性能会很好")]),_._v(". MySQL, Redis 和其他消息中间件也采用了类似的技术.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ff0cbe809be426d82f115a0c30996127-20231223175002-4dfzvzc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着再补充一点业界早期的讨论.")]),_._v(" "),v("blockquote",[v("p",[_._v("所以早期的时候业界就有人做过实验, 一台 Kafka 服务器, 把磁盘从机械硬盘切换到固态硬盘, 性能虽然有提升, 但是并不明显. 在固态硬盘很贵的情况下, 并不划算.")])]),_._v(" "),v("p",[_._v("接下来可以从两个角度刷亮点: "),v("strong",[_._v("分区多影响写入性能和如何解决分区多问题")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"分区多影响写入性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区多影响写入性能"}},[_._v("#")]),_._v(" 分区多影响写入性能")]),_._v(" "),v("p",[_._v("你应该注意到, Kafka 是每一个分区都有一个日志文件, 万一有很多分区呢? 也就是说, 如果分区特别多, 就可能导致 Kafka 的写性能衰退.")]),_._v(" "),v("blockquote",[v("p",[_._v("但是 Kafka 的顺序写要求的是分区内部顺序写, 不同的分区之间就不是顺序写的. 所以如果一个 topic 下的分区数量不合理, 偏多的话, 写入性能是比较差的.")]),_._v(" "),v("p",[_._v("举个例子, 假如要写入 100M 的数据, 如果只有一个分区, 那就是直接顺序写入 100M. 但是如果有 100 个分区, 每个分区写入 1M, 它的性能是要差很多的. 因为一个 topic 至少有一个分区, topic 多也会影响 Kafka 的性能. 最好是在创建 topic 的时候就规划好分区, 但是如果没规划好, 还是得考虑解决.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/59a137d035215d702c6db1d56c201236-20231223175002-kgujruy.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个回答里提到了一个点, 就是分区设置不合理, 所以面试官就会追问如何估计分区数量. 前面已经学过了, 记得复习一下.")]),_._v(" "),v("p",[_._v("最后一句话, 也是引导面试官追问怎么解决分区或者 topic 过多的问题.")]),_._v(" "),v("h6",{attrs:{id:"分区过多如何解决"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区过多如何解决"}},[_._v("#")]),_._v(" 分区过多如何解决?")]),_._v(" "),v("p",[_._v("可以从"),v("strong",[_._v("分区过多和 topic 过多")]),_._v("的角度分别去讨论.")]),_._v(" "),v("p",[_._v("如果是分区过多的话很好办, 只需要"),v("strong",[_._v("不使用其中的一些分区")]),_._v("就可以了.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果某个 topic 分区太多了用不上, 就可以考虑不用其中的一些分区. 假设现在有 32 个分区, 但是事实上业务本身用不上那么多分区, 那么就可以考虑要求发送者只将消息发送到特定的 16 个分区上. 当然能够直接创建新 topic 是最好的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c37146b35ef503b3dc83dbbd2ac3025c-20231223175002-g3v87y0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("topic 过多的问题, 要稍微棘手一点, 可以考虑 "),v("strong",[_._v("合并")]),_._v(" topic.")]),_._v(" "),v("blockquote",[v("p",[_._v("topic 过多的话, 可以考虑合并一些 topic, 但这也是看业务的. 比如说最开始的设计是某个主业务下的子业务都有一个 topic, 那么可以考虑这些子业务合并使用一个 topic, 然后在里面用 type 等字段来标记是归属于哪个子业务的.")])]),_._v(" "),v("p",[_._v("有时候面试官可能会问, 究竟多少个分区才算多, 或者多少个分区才会导致性能下降呢? 这里给一个阿里云中间件团队测试的结论.")]),_._v(" "),v("blockquote",[v("p",[_._v("多少分区才算多, 以及多少分区才会引起性能下降, 这和 topic 本身有关, 也和业务有关.")]),_._v(" "),v("p",[_._v("不过之前阿里云中间件团队测试过, 在一个 topic 八个分区的情况下, 超过 64 个 topic 之后, Kafka 性能就开始下降了.")])]),_._v(" "),v("p",[_._v("如果有兴趣, 也可以在你们公司的 Kafka 上执行一下测试.")]),_._v(" "),v("h6",{attrs:{id:"分区"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分区"}},[_._v("#")]),_._v(" 分区")]),_._v(" "),v("p",[_._v("分区本身就能带来性能的提升, 分区的好处就是 Kafka 可以按分区来处理, "),v("strong",[_._v("减少并发竞争")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 的分区机制也能提高性能. 假如现在 Kafka 没有分区机制, 只有 topic, 那么可以预计的是不管是读还是写, 并发竞争都是 topic 维度的. 而在引入了分区机制之后, 并发竞争的维度就变成分区了. 如果是操作不同的分区, 那么完全不需要搞并发控制.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1cbd466eac09bba24ce608cd2cf26785-20231223175002-4qctzn8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果在面试过程中和面试官讲到了并发优化的点, 那可以用分区这个例子来解释可以通过缩小并发粒度来提高性能.")]),_._v(" "),v("h6",{attrs:{id:"分段与索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分段与索引"}},[_._v("#")]),_._v(" 分段与索引")]),_._v(" "),v("p",[_._v("分段与索引的基本概念已经学过了, 所以只需要根据总结的三句话简单介绍分段与索引就可以. 同时讲清楚如何查找到特定消息, 因为查找过程本身就是一个亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("在 Kafka 中, 每一个分区都对应多个段文件, 放在同一个目录下. Kafka 根据 topic 和分区就可以确定消息存储在哪个目录内. 每个段文件的文件名就是偏移量, 假设为 N, 那么这个文件第一条消息的偏移量就是 N+1. 所以 Kafka 根据偏移量和文件名进行二分查找, 就能确定消息在哪个文件里.")]),_._v(" "),v("p",[_._v("然后每一个段文件都有一个对应的偏移量索引文件和时间索引文件. Kafka 根据这个索引文件进行二分查找, 就很容易在文件里面找到对应的消息. 如果目标消息刚好有这个索引项, 那么直接读取对应位置的数据. 如果没有, 就找到比目标消息偏移量小的, 最接近目标消息的位置, 顺序找过去. 整个过程非常像跳表.")])]),_._v(" "),v("h6",{attrs:{id:"批量处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批量处理"}},[_._v("#")]),_._v(" 批量处理")]),_._v(" "),v("p",[v("strong",[_._v("批量处理是高并发和大数据的常见解决方案")]),_._v(". Kafka 为了提高性能, 引入端到端的批量发送机制. 在发送端, Kafka 的客户端并不是一次只发送一条消息, 而是发送"),v("strong",[_._v("一批消息")]),_._v("(record batch). 简单来说, 就是好几条消息合并在一起发送.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a5acbbc1d81bdbf7365993666a2099e3-20231223175002-k2xfpjz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而在 broker 端, Kafka 在存储的时候也是按照批来处理的. 在回答的时候要先解释 Kafka "),v("strong",[_._v("批量处理")]),_._v(" 的基本机制.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 还采用了批量处理来提高性能. Kafka 的客户端在发送的时候, 并不是说每来一条消息就发送到 broker 上, 而是说聚合够一批再发送. 而在 broker 这一端, Kafka 也是同样按照批次来处理的, 显然即便同样是顺序写, 一次性写入数据都要比分多次快很多. 除了 Kafka, 很多高并发, 大数据的中间件也采用类似的技术, 比如日志采集与上报就采用批量处理来提升性能.")])]),_._v(" "),v("p",[_._v("然后可以从批量处理的高性能原因和兜底技术两个角度刷亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("批量处理高性能原因")])]),_._v(" "),v("p",[_._v("首先要深入分析批量处理高性能的原因.")]),_._v(" "),v("blockquote",[v("p",[_._v("批量处理能够提升性能的原因是非常直观的, 有两方面. 一方面是"),v("mark",[_._v("减少系统调用和内核态与用户态切换的次数")]),_._v(". 比方说 100 个请求发送出去, 即便采用零拷贝技术, 也要 100 次系统调用 200 次内核态与用户态切换. 而如果是一次性发送的话, 那么就只需要 1 次系统调用和 2 次内核态与用户态切换.")]),_._v(" "),v("p",[_._v("另外一方面, "),v("mark",[_._v("批量处理也有利于网络传输")]),_._v(". 在网络传输中, 一个难以避免的问题就是网络协议自身的开销. 比如说协议头开销. 那么如果发送 100 次请求, 就需要传输 100 次协议头. 如果 100 个请求合并为一批, 那就只需要一个协议头.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0390fc774852fe34893f50c86927bace-20231223175002-djbzcxk.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("批量处理的兜底技术")])]),_._v(" "),v("p",[_._v("那么多大批次比较合适呢? 关键词就是"),v("strong",[_._v("要兜底")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("不过批次也要设计合理. 正常来说批次总是越大越好, 但是批次太大会导致一个后果, 就是客户端难以凑够一个批次. 比如说 100 条消息一批和 1000 条消息一批, 后者肯定很难凑够一个批次. 一般来说"),v("mark",[_._v("批量处理都是要兜底的, 就是在固定时间内如果都没有凑够某个批次, 那么就直接发送")]),_._v(". 比如说 Kafka 里面生产者就可以通过 "),v("code",[_._v("linger.ms")]),_._v("​ 参数来控制生产者最终等多长时间. 时间到了, 即便只有一条消息, 生产者也会把消息发送到 broker 上.")])]),_._v(" "),v("h6",{attrs:{id:"压缩"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#压缩"}},[_._v("#")]),_._v(" 压缩")]),_._v(" "),v("p",[_._v("为了进一步降低数据传输和存储的压力, Kafka 还启用了"),v("strong",[_._v("压缩功能")]),_._v(". Kafka 的压缩机制很特别. 正常我们会认为如果 Kafka 支持压缩, 那么应该是生产者压缩, 发送到 broker 之后, broker 解压缩. 然后 broker 压缩, 发送到消费者之后, 消费者解压缩.")]),_._v(" "),v("p",[_._v("Kafka 是彻底地端到端, 就是"),v("strong",[_._v("生产者压缩之后发送到 broker, broker 直接存储. 当 broker 推送到消费者的时候, 消费者解压缩")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2c94c7054eb25955d1fbee719e47101b-20231223175002-w1z28hi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 为了进一步降低网络传输和存储的压力, 还对消息进行了压缩. 这种压缩是端到端的压缩, 也就是生产者压缩, broker 直接存储压缩后的数据, 只有消费者才会解压缩. 它带来的好处就是, 网络传输的时候传输的数据会更少, 存储的时候需要的磁盘空间也更少. 当然缺点就是压缩还是会消耗 CPU. 如果生产者和消费者都是 CPU 密集型的应用, 那么这种压缩机制反而加重了它们的负担.")])]),_._v(" "),v("p",[_._v("最后点出 "),v("strong",[_._v("CPU 密集型应用")]),_._v("在使用 Kafka 的时候还面临着压缩数据竞争 CPU 资源的问题. 不过在业界, CPU 密集型的应用非常少, 会使用到 Kafka 的 CPU 密集型应用就更少了.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-28"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-28"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节的要点. 通过 "),v("strong",[_._v("Kafka 的分段与索引技术")]),_._v(", 了解到一个消息是怎么被存储的, 还有消息是怎么查找的. 这里还引入了"),v("strong",[_._v("零拷贝技术")]),_._v(", 需要记住相比传统 IO 它独特的优势.")]),_._v(" "),v("p",[_._v("在回答 Kafka 为什么性能这么好这个问题的时候, 要从"),v("mark",[v("strong",[_._v("零拷贝, page cache, 顺序写, 分区, 分段与索引, 批量处理, 压缩")])]),_._v("这几个角度回答. 如果记不住这么多内容, 那么记住零拷贝, 顺序写这两个也可以.")]),_._v(" "),v("p",[_._v("也建议从横向角度去分类, 比如"),v("strong",[_._v("写下零拷贝再写下使用了零拷贝的相应的中间件")]),_._v(". 这样能够加深理解, 在面试的时候也可以用这个知识来刷亮点.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5f9f06fdae07580aab5124a704943040-20231223175002-pfo0ja4.png",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_30-kafka综合运用-怎么在实践中保证kafka高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_30-kafka综合运用-怎么在实践中保证kafka高性能"}},[_._v("#")]),_._v(" 30-Kafka综合运用:怎么在实践中保证Kafka高性能?")]),_._v(" "),v("p",[_._v("今天来聊 Kafka 的最后一个话题——"),v("strong",[_._v("怎么在实践中保证 Kafka 高性能")]),_._v("? 也可以说, "),v("strong",[_._v("怎么在业务里面优化使用 Kafka 的性能")]),_._v(".")]),_._v(" "),v("p",[_._v("在前面微服务部分, 就说高并发可遇不可求, 而高可用和高性能是可求的. 在追求高性能的时候, Kafka 自然也是一个绕不开的环节. 那么今天这节就深入讨论"),v("strong",[_._v("怎么优化发送者和 broker, 结合消息积压中优化消费者性能的知识")]),_._v(", 你就掌握了一条消息从生产出来到消费完成整个环节上优化性能的方法.")]),_._v(" "),v("h5",{attrs:{id:"如何选择压缩算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何选择压缩算法"}},[_._v("#")]),_._v(" 如何选择压缩算法?")]),_._v(" "),v("p",[_._v("不管是 Kafka 还是别的中间件, 在选择压缩算法的时候, 首先要考虑的就是"),v("strong",[_._v("压缩比和压缩速率")]),_._v(". 压缩比主要是为了节省网络带宽和磁盘存储空间, 而压缩速率主要影响吞吐量.")]),_._v(" "),v("p",[_._v("一般来说, 压缩比越高, 压缩速率越低; 压缩比越低, 压缩速率越高.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/408fc97ddb65b6059b83213f0402897f-20231223175002-b4741ap.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以选择压缩算法就是"),v("strong",[_._v("看自己的业务场景究竟是偏向压缩比还是偏向压缩速率")]),_._v(". 不过在真实环境下, 一切都要"),v("mark",[v("strong",[_._v("以性能测试为准")])]),_._v(", 而不能仅仅依赖于原理分析.")]),_._v(" "),v("h5",{attrs:{id:"操作系统交换区"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#操作系统交换区"}},[_._v("#")]),_._v(" 操作系统交换区")]),_._v(" "),v("p",[_._v("在现代操作系统中, 基本都支持交换区, 也叫做 swap 分区. 当操作系统发现可用的物理内存不足的时候, 就会把物理内存里的一部分页淘汰出来, 放到磁盘上, 也就是放到 swap 分区.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/71475610yye35c73c46222147911b3e8-20231223175002-lnjtk25.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v('也可以把 swap 分区看作是 "虚拟内存". 那么可以想到, 如果触发了这种交换, 性能就会显著下降. 交换越频繁, 下降越快.')]),_._v(" "),v("p",[_._v("在 Linux 中有一个参数, 叫做 "),v("code",[_._v("vm.swappniess")]),_._v("​, 它控制住了使用交换区的"),v("strong",[_._v("积极性")]),_._v(". 比如 vm.swappniess 在大多数 linux 发行版上默认值都是 60, 也就是比较积极地使用交换区. "),v("strong",[_._v("而追求性能的中间件, 如消息队列, 数据库等都会尽量避免触发交换, 也就是把 vm.swappniess 调小")]),_._v(".")]),_._v(" "),v("p",[_._v("有一种说法是当内存使用率超过 40% 的时候就开始使用 swap 分区, 但是这种说法其实不够准确, 因为是否交换在 Linux 2.6 以后的版本后还参考了别的因素, 如果有兴趣的话可以自己去深挖一下, 面试的时候记住"),v("strong",[_._v("追求性能调小")]),_._v("就可以.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-30"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-30"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前需要提前了解清楚一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你维护的业务在使用消息队列的时候, 后面"),v("strong",[_._v("优化措施中提到的参数取值")]),_._v("都是多少?")]),_._v(" "),v("li",[_._v("你们公司"),v("strong",[_._v("消息队列的各个参数有没有被调过? 为什么调")]),_._v("?")]),_._v(" "),v("li",[_._v("你是否遇到过和消息队列有关的 Bug? 如果有, 那么怎么解决的?")]),_._v(" "),v("li",[_._v("你维护的"),v("strong",[_._v("业务使用消息队列时的 QPS 是多少")]),_._v("?")])]),_._v(" "),v("p",[_._v("类似于在 MySQL 中提到的, 可以找运维问一下消息队列的相关配置, 然后弄清楚其中每一个配置的含义. 同样后面会提到一些操作系统优化和 JVM 相关的优化, 这一类优化同样可以在别的中间件里面找到, 你以提前了解一部分, 然后在面试过程中交叉对比.")]),_._v(" "),v("p",[_._v("面试官很少会直接问怎么优化 Kafka, 但聊到下面这些话题的时候都可以引导到这里.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("性能优化")]),_._v(", 消息队列相关的优化是其中一个重要的点.")]),_._v(" "),v("li",[v("strong",[_._v("TCP 协议")]),_._v(", Linux 上的几个 TCP 参数以及如何调整这些参数来优化中间件性能, 这里可以举 Kafka 的例子.")]),_._v(" "),v("li",[v("strong",[_._v("swap")]),_._v(", 追求性能的中间件都会尝试优化 vm.swappiness 参数, 可以以 Kafka 为例.")]),_._v(" "),v("li",[_._v("从主从同步引申到 Kafka 主从分区同步, 还有批量拉数据模型.")]),_._v(" "),v("li",[v("strong",[_._v("压缩")]),_._v(", Kafka 的压缩功能, 以及你实际使用的压缩算法.")]),_._v(" "),v("li",[_._v("JVM 或者垃圾回收, 可以用优化 Kafka 垃圾回收来证明自己的技术实力.")])]),_._v(" "),v("p",[_._v("在做好这些准备之后, 就可以开始面试了.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-20"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-20"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("最佳的面试策略依旧是把消息队列优化作为你优化整个系统的可用性和性能的一个环节. 可以参考这个话术.")]),_._v(" "),v("blockquote",[v("p",[_._v("我这个系统有一个关键点, 就是一个高并发的消息队列使用场景. 也就是说, 它要求做到高效发送, 高效消费, 不然就会有问题, 比如说出现消息积压或生产者阻塞的问题. 那么优化的整体思路就是从消息队列的生产者, broker 和消费者这三方出发.")])]),_._v(" "),v("p",[_._v("这里提到了两个问题: "),v("strong",[_._v("消息积压和生产者阻塞")]),_._v(". 这两个问题都是跟性能有关的热门问题, 所以大概率面试官会问, 比如怎么优化生产者或者 broker. 这个时候就可以用下面的优化措施来回答了.")]),_._v(" "),v("h5",{attrs:{id:"优化措施"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化措施"}},[_._v("#")]),_._v(" 优化措施")]),_._v(" "),v("p",[_._v("这里给出很多优化方案, 可以根据自己平时使用的消息队列的情况来选择. 除了这里提到的方案, 前面也提过优化 Kafka 的刷盘时机, 同样可以用来面试.")]),_._v(" "),v("h6",{attrs:{id:"优化生产者"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化生产者"}},[_._v("#")]),_._v(" 优化生产者")]),_._v(" "),v("blockquote",[v("p",[_._v("优化1：优化acks")])]),_._v(" "),v("p",[_._v("前面已经学过 acks 了. 在尝试优化 acks 的时候, "),v("strong",[_._v("如果追求性能, 那么就应该把 acks 设置为 0")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们有一个系统在一个高并发场景下会发送消息到 Kafka. 后来就发现这个接口在业务高峰的时候响应时间很长, 客户端经常遇到超时的问题. 后来排查才知道, 写这段代码的人直接复制了已有的发送消息代码, 而原本人家的业务追求的是消息不丢, 所以 acks 设置成了 all. 实际上这个业务并没有那么严格的消息不丢的要求, 完全可以把 acks 设置为 0. 这么一调整, 整个接口的响应时间就显著下降了, 客户端那边也很少再出现超时的问题.")])]),_._v(" "),v("p",[_._v("当然这里设置为 1 也可以, 就是性能要比 0 差一点.")]),_._v(" "),v("p",[_._v("如果"),v("strong",[_._v("追求消息不丢失, 那么就应该把 acks 设置为 all")]),_._v(", 这部分已经在消息丢失部分学过了. 可以总结一下, 尝试把话题引导到消息丢失和下一个优化批次的措施上.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过追求消息不丢失的业务场景就不能把 acks 设置为 0 或者 1, 这时候就只能考虑别的优化手段, 比如说优化批次.")])]),_._v(" "),v("blockquote",[v("p",[_._v("优化2：优化批次")])]),_._v(" "),v("p",[_._v("优化批次有两个好处, 对于生产者本身来说, 它"),v("strong",[_._v("发送消息的速率更快")]),_._v("; 对于 Kafka 来说, 同样数量的消息, 批次越大, 性能越好.")]),_._v(" "),v("p",[_._v("所以当发送者遇到瓶颈之后, 就可以"),v("strong",[_._v("尝试调大批次的参数来进一步提高发送性能")]),_._v(". 和批次有关的有两个参数: linger.ms 和 batch.size. 前者是凑够一个批次的最大等待时间, 后者是一个批次最大能有多少字节. 可以先简单介绍优化手段, 关键词是"),v("strong",[_._v("调大批次")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我之前遇到过一个生产者发送消息的性能问题. 后来经过排查之后, 发现是因为发送性能太差, 导致发送缓冲池已经满了, 阻塞了发送者. 这个时候我们注意到其实发送速率还没有达到 broker 的阈值, 也就是说, broker 其实是处理得过来的. 在这种情况下, 最直接的做法就是加快发送速率, 也就是调大 batch.size 参数, 从原本的 100 调到了 500, 就没有再出现过阻塞发送者的情况了.")])]),_._v(" "),v("p",[_._v("注意, "),v("strong",[_._v("调大批次究竟能有多大的优化效果和调整前后批次大小, 消息平均大小, borker 负载有关")]),_._v(". 好的时候 TPS 可以翻倍, 差的时候可能也就是提升 10% 不到. 所以最好亲自动手试一试业务调整这个参数性能究竟能提升多少.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/474edb861151efb25cacabyy352d1887-20231223175002-wv1n7g3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("同时也要指出, "),v("strong",[_._v("批次也不是越大越好")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 批次也不是说越大越好. 因为批次大了的话, 生产者这边丢失数据的可能性就比较大. 而且批次大小到了一个地步之后, 性能瓶颈就变成了 broker 处理不过来了, 再调大批次大小是没有用的.")])]),_._v(" "),v("p",[_._v('也别忘了占领 "高地".')]),_._v(" "),v("blockquote",[v("p",[_._v("最好的策略, 还是"),v("mark",[_._v("通过压测来确定合适的批次大小")]),_._v(".")])]),_._v(" "),v("p",[_._v("然后可以进一步介绍另外一种优化思路, 刷个亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("发送者被阻塞也可能是因为缓冲池太小, 那么只需要"),v("mark",[_._v("调大缓冲池")]),_._v("就可以. 比如说是因为 topic, 分区太多, 每一个分区都有一块缓冲池装着批量消息, 导致缓冲池空闲缓冲区不足, 这一类不是因为发送速率的问题导致的阻塞, 就可以通过调大缓冲池来解决.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e262918eba238e0349482e6603303194-20231223175002-doc4y35.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后再总结一下, 体现你对这个问题的深入思考.")]),_._v(" "),v("blockquote",[v("p",[_._v("所以发送者阻塞要仔细分析, 如果是发送速率的问题, 那么调大发送缓冲区是治标不治本的. 如果发送速率没什么问题, 确实就是因为缓冲池太小引起的, 就可以调大缓冲池. 如果现实中, 也比较难区别这两种情况, 就可以考虑先调大批次试试, 再调整缓冲池.")])]),_._v(" "),v("p",[_._v("当然, 提高发送速率还有一个更加简单的手段, 也就是"),v("strong",[_._v("启用压缩")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("优化3：启用压缩")])]),_._v(" "),v("p",[_._v("Kafka 默认是不启用压缩的, 所以如果希望进一步提高吞吐量就可以考虑启用压缩. 但是这个优化措施很简单, 所以只需要随便提一下就可以.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高 Kafka 的吞吐量, 我也开启了 Kafka 的压缩功能, 使用了 LZ4 压缩算法.")])]),_._v(" "),v("p",[_._v("假设你最开始选择的算法是 Snappy, 那么这么回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高 Kafka 的吞吐量, 我将压缩算法从 Snappy 换到了 LZ4.")])]),_._v(" "),v("p",[_._v("经过验证, 我和几个同样做过性能测试的朋友都认为 LZ4 吞吐量最好. 在面试的时候还可以介绍一下自己做性能测试的结果. 同时也要注意, 这样有可能会把话题引导到压缩算法和 Kafka 的压缩机制上.")]),_._v(" "),v("h6",{attrs:{id:"优化broker"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化broker"}},[_._v("#")]),_._v(" 优化broker")]),_._v(" "),v("p",[_._v("下面的方案中, 前三个是比较有亮点的优化手段. 倒不是说这三个优化手段有多难, 而是大部分候选者并不会从操作系统层面上优化.")]),_._v(" "),v("blockquote",[v("p",[_._v("优化1：优化swap")])]),_._v(" "),v("p",[_._v("Kafka 是一个非常依赖内存的应用, 所以可以"),v("strong",[_._v("调小 vm.swappniess 参数来优化内存")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("为了优化 Kafka 的性能, 可以调小 vm.swappiness. 比如说调整到 10, 这样就可以充分利用内存; 也可以调整到 1, 这个值在一些 linux 版本上是指进行最少的交换, 但是不禁用交换. 目前我们公司用的就是 10.")])]),_._v(" "),v("p",[_._v("面试官可能会问, 为什么不直接禁用 swap 呢? 就要回答"),v("strong",[_._v("以防万一")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("物理内存总是有限的, 所以直接禁用的话容易遇到内存不足的问题. 因此只是要尽可能优化内存, 如果物理内存真的不够, 那么使用交换区也比系统不可用好.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0196d35ec475ace20c90df80ba56be76-20231223175002-mwpbqwe.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("优化2：优化网络读写缓冲区")])]),_._v(" "),v("p",[_._v("Kafka 也是一个网络 IO 频繁的应用, 所以"),v("strong",[_._v("调整网络有关的读写缓冲区, 效果也会更好")]),_._v(". 对应的参数有6个.")]),_._v(" "),v("ul",[v("li",[_._v("net.core.rmem_default 和 net.core.wmem_default: Socket 默认读写缓冲区大小.")]),_._v(" "),v("li",[_._v("net.core.rmem_max 和 net.core.wmem_max: Socket 最大读写缓冲区.")]),_._v(" "),v("li",[_._v("net.ipv4.tcp_wmem 和 net.ipv4.tcp_rmem: TCP 读写缓冲区. 它们的值由空格分隔的最小值, 默认值, 最大值组成. 可以考虑调整为 4KB, 64KB 和 2MB.")])]),_._v(" "),v("p",[_._v("这些参数记不住没有关系, 记住一个点"),v("mark",[v("strong",[_._v("调大读写缓冲区")])]),_._v("就可以. 这里列举的值只是为了举例子, 可以用公司实际的值来替代.")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一个优化方向是调大读写缓冲区. Scoket 默认读写缓冲区可以考虑调整到 128KB; Socket 最大读写缓冲区可以考虑调整到 2MB, TCP 的读写缓冲区最小值, 默认值和最大值可以设置为 4KB, 64KB 和 2MB. 不过这些值究竟多大, 还是要根据 broker 的硬件资源来确定.")])]),_._v(" "),v("blockquote",[v("p",[_._v("优化3：优化磁盘IO")])]),_._v(" "),v("p",[v("strong",[_._v("Kafka 显然也是一个磁盘 IO 密集的应用")]),_._v(". 优化磁盘 IO 的两个方向就是"),v("strong",[_._v("调整文件系统")]),_._v(", 使用 XFS, 并且禁用 atime. atime 是指文件最后的访问时间, 而本身 Kafka 用不上.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 也是一个磁盘 IO 密集的应用, 所以可以从两个方向优化磁盘 IO. 一个是使用 XFS 作为文件系统, 它要比 EXT4 更加适合 Kafka. 另外一个是禁用 Kafka 用不上的 atime 功能.")])]),_._v(" "),v("p",[_._v("这里提到了 XFS 更加适合, 但是没有解释. 因此面试官就可能继续追问为什么要选择 XFS. 这个时候就可以回答 "),v("strong",[_._v("XFS 性能更好.")])]),_._v(" "),v("blockquote",[v("p",[_._v("相比于 EXT4, XFS 性能更好. 在同等情况下, 使用 XFS 的 Kafka 要比 EXT4 性能高 5% 左右.")])]),_._v(" "),v("p",[_._v("虽然 XFS 还有别的优点, 比如说扩展性更好, 支持更多, 更大的文件, 但是这些都不是关键, 关键就是 "),v("strong",[_._v("XFS 读写性能要好一点")]),_._v(".")]),_._v(" "),v("p",[_._v("如果面试的是比较基础的岗位, 那么大概率面试官会把话题引导到操作系统中文件子系统的部分. 上面这三个都可以看作是优化操作系统参数, 而 Kafka 本身也是可以调整的.")]),_._v(" "),v("blockquote",[v("p",[_._v("优化4：优化主从同步")])]),_._v(" "),v("p",[_._v("从分区和主分区数据同步的过程受到了几个参数的影响.")]),_._v(" "),v("ul",[v("li",[_._v("num.replica.fetchers: "),v("strong",[_._v("从分区拉取数据的线程数量")]),_._v(", 默认是 1. 可以考虑设置成 3.")]),_._v(" "),v("li",[_._v("replica.fetch.min.bytes: 可以通过调大这个参数来避免小批量同步数据.")]),_._v(" "),v("li",[_._v("replica.fetch.max.bytes: 这个可以调大, 比如说调整到 5m, 但是不要小于 message.max.byte, 也就是不要小于消息的最大长度.")]),_._v(" "),v("li",[_._v("replica.fetch.wait.max.ms: 如果主分区没有数据或者数据不够从分区的最大等待时间, 可以考虑同步调大这个值和 replica.fetch.max.bytes.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/03acaaf86507404b88300e3c0374287e-20231223175002-4t72k4e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这些参数都是跟机器有关的, 所以"),v("strong",[_._v("在实践中需要通过不断测试来确认这些参数的最佳值")]),_._v(". 如果记不住细节, 那就记住"),v("strong",[_._v("都调大")]),_._v(". 尤其是后三个, 调大它们的效果, 就是为了让从分区一批次同步尽可能多的数据.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 的主从分区同步也可以优化. 首先调整从分区的同步数据线程数量, 比如说调整到 3, 这样可以加快同步速率, 但是也会给主分区和网络带宽带来压力. 其次是调整同步批次的最小和最大字节数量, 越大则吞吐量越高, 所以都尽量调大. 最后也可以调整从分区的等待时间, 在一批次中同步尽可能多的数据.")])]),_._v(" "),v("p",[_._v("类似于批次大小, 也不能一直调大.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过调大到一定地步之后, 瓶颈就变成了从分区来不及处理. 或者调大到超过了消息的并发量, 那么也没意义了.")])]),_._v(" "),v("p",[_._v("可以进一步总结, 类似的批量拉数据场景都可以考虑这一类的优化, 包括业务层面上的批量拉数据.")]),_._v(" "),v("blockquote",[v("p",[_._v("Kafka 这种机制可以看作是典型的批量拉数据模型. 在这个模型里面, 要着重考虑的就是多久拉一次, 没有怎么办, 一次拉多少? 在实现这种模型的时候, 让用户根据自己的需要来设定参数是一个比较好的实践.")])]),_._v(" "),v("blockquote",[v("p",[_._v("优化5：优化JVM")])]),_._v(" "),v("p",[_._v("Kafka 是运行在 JVM 上的, 所以理论上来说任何优化 Java 性能的措施, 对 Kafka 也一样有效果. 如果面试 Java 岗位, 那么这个点会非常适合你, 因为可以同时展示你对 JVM 的理解.")]),_._v(" "),v("p",[v("strong",[_._v("优化 JVM 首先就是考虑优化 GC, 即优化垃圾回收")]),_._v(". 而优化 GC 最重要的就是"),v("strong",[_._v("避免 full GC")]),_._v(". full GC 是指整个应用都停下来等待 GC 完成. 它会带来两方面影响. "),v("strong",[_._v("一方面是发送者如果设置 acks 为 1 或者 all, 都会被阻塞, Kafka 吞吐量下降")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/4dcc2931cddb53c7634d354cee9abd92-20231223175002-hkufocd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("另一方面是"),v("strong",[_._v("如果 full GC 时间太长, 那么主分区可能会被认为已经崩溃了, Kafka 会重新选择主分区")]),_._v("; 而如果是从分区, 那么它会被挪出 ISR, 进一步影响 acks 设置为 all 的发送者.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0de232063233f907b4613d64392b545d-20231223175002-3v9eki8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("基本的思路就是"),v("strong",[_._v("调大 JVM 的堆, 并且在堆很大的情况下, 启用 G1 垃圾回收器")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们的 Kafka 集群还出过 GC 引发的性能问题. 有一个 Kafka 的堆内存很大, 有 8G, 但是垃圾回收器还是用的 CMS. 触发了 full GC 之后, 停顿时间就会很长, 导致 Kafka 吞吐量显著下降, 并且有时候还会导致 Kafka 认为主分区已经崩溃, 触发主从选举.")]),_._v(" "),v("p",[_._v("在这种情况下, 有两个优化思路, 一个是考虑优化 CMS 本身, 比如说增大老年代, 但是这个治标不治本, 可以缓解问题, 但是不能根治问题. 所以综合之下我选了另外一个方向, 直接切换到 G1 回收器. G1 回收器果然表现得非常好, 垃圾回收频率和停顿时间都下降了.")])]),_._v(" "),v("h5",{attrs:{id:"面试方案总结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试方案总结"}},[_._v("#")]),_._v(" 面试方案总结")]),_._v(" "),v("p",[_._v("最后来总结一下这一节的内容.")]),_._v(" "),v("ol",[v("li",[_._v("当"),v("strong",[_._v("选择压缩算法")]),_._v(" 的时候, 需要权衡压缩比和压缩速率, 根据需求做选择.")]),_._v(" "),v("li",[v("strong",[_._v("操作系统交换区")]),_._v(' 可以看作 "虚拟内存". 如果触发交换, 性能就会显著下降.')]),_._v(" "),v("li",[_._v("优化生产者有三个措施: "),v("strong",[_._v("优化 acks, 优化批次和启用压缩")]),_._v(".")]),_._v(" "),v("li",[_._v("优化 broker 有五个措施: "),v("strong",[_._v("优化 swap, 优化网络读写缓冲区, 优化磁盘 IO, 优化主从同步, 优化 JVM")]),_._v(".")])]),_._v(" "),v("p",[_._v("这一节描述的这些优化都是很容易用于实践中的, 所以有机会的话尽可能用一下, 加深理解. 包括各种参数设置成什么值最好, 都是跟业务, broker 的硬件资源有关的, 自己实践得出的值更有说服力.")]),_._v(" "),v("p",[_._v("同时也总结一下在面试"),v("strong",[_._v("中间件优化的一般思路")]),_._v(". 这种套路适用于绝大多数的中间件.")]),_._v(" "),v("ul",[v("li",[v("mark",[v("strong",[_._v("在操作系统层面上, 你优化了什么")])]),_._v("? 目前来说大多数中间件, 都可以调整操作系统上和 swap, TCP, IO 有关的参数.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("中间件本体")])]),_._v(". 比如说调整 Kafka 的刷盘参数, 调整主从同步等. 并且有很多中间件是基于 JVM 的, 因此可以调整 JVM 相关的内容. 而调整 JVM, 最重要的就是调整垃圾回收相关的参数.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("客户端参数")])]),_._v(". 在这里是指引入的依赖, 比如说引入了 Kafka 的客户端依赖, 创建生产者的时候用了什么参数.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/62456d32ca7bd095e7d86dc701da6e28-20231223175002-p2i8765.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h3",{attrs:{id:"缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存"}},[_._v("#")]),_._v(" 缓存")]),_._v(" "),v("h4",{attrs:{id:"_31-缓存过期-为什么redis不立刻删除已经过期的数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_31-缓存过期-为什么redis不立刻删除已经过期的数据"}},[_._v("#")]),_._v(" 31-缓存过期:为什么Redis不立刻删除已经过期的数据?")]),_._v(" "),v("p",[_._v("今天来讨论一个全新的话题--缓存.")]),_._v(" "),v("p",[_._v("缓存在实践中, 面试中的重要性不言而喻. 应该说, 缓存用好了就能解决大部分的性能问题. 反过来, 如果缓存没有用好, 那么系统性能是不可能好的.")]),_._v(" "),v("p",[_._v("缓存在面试中也分成两个方向: "),v("strong",[_._v("一个是理论上缓存的设计, 包括 Redis 的原理; 一个是在实践中使用缓存的案例, 聚焦在怎么使用缓存, 怎么解决一致性问题")]),_._v(".")]),_._v(" "),v("p",[_._v("今天先从第一个话题缓存的过期时间开始.")]),_._v(" "),v("h5",{attrs:{id:"缓存命中率"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存命中率"}},[_._v("#")]),_._v(" 缓存命中率")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("缓存命中率是用来衡量缓存效果的关键指标. 它的计算方式是缓存命中次数除以查询总次数")])]),_._v(".")]),_._v(" "),v("p",[_._v("在实践中, 要努力把缓存命中率提高到 90% 以上. 不过, 缓存命中率也受到业务模式的影响, 有一些业务是没有办法做到 90% 以上的.")]),_._v(" "),v("p",[_._v("比如有一些场景是缓存计算时间很长的结果, 但是大部分请求都是小请求, 也就是都不会命中缓存, 这种时候缓存命中率可能连一半都没有. 但是因为这些小请求计算很快, 所以走实时计算响应时间也能接受, 而且实时计算的数据更加准确.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8yy71b8106121d5d9f992542c65a6e73-20231223175002-rb3os7e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"实现过期机制的一般思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#实现过期机制的一般思路"}},[_._v("#")]),_._v(" 实现过期机制的一般思路")]),_._v(" "),v("p",[_._v("从系统设计的角度来说, "),v("strong",[_._v("过期之类的机制")]),_._v("可以考虑使用四种思路来实现.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("定时删除")]),_._v(": 是指针对每一个需要被删除的对象启动一个计时器, 到期之后直接删除.")]),_._v(" "),v("li",[v("strong",[_._v("延迟队列")]),_._v(": 也就是把对象放到一个延迟队列里面. 当从队列里取出这个对象的时候, 就说明它已经过期了, 这时候就可以删除.")]),_._v(" "),v("li",[v("strong",[_._v("懒惰删除")]),_._v(": 是指每次要"),v("strong",[_._v("使用对象的时候, 检查一下这个对象是不是已经过期了. 如果已经过期了, 那么直接删除")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("定期删除")]),_._v(": 是指每隔一段时间就遍历对象, 找到已经过期的对象删除掉.")])]),_._v(" "),v("p",[_._v("针对这四种思路的优缺点, 可以参考下面的表格.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5e46e9e857e289ace47d67aa50640fae-20231223175002-3kpk5uj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("大部分的缓存框架, 比如 Redis, 它们都使用了"),v("mark",[v("strong",[_._v("懒惰删除和定期删除结合的策略")])]),_._v(". 定时删除和延迟队列对于缓存这种场景来说, 性能太差.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-31"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-31"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 需要弄清楚一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你的"),v("strong",[_._v("业务是如何使用缓存的, 命中率有多少")]),_._v("? 业务高峰的时候消耗了多少内存?")]),_._v(" "),v("li",[_._v("你的"),v("strong",[_._v("业务使用缓存的时候过期时间是多少")]),_._v("? 当时为什么设置成这个过期时间?")]),_._v(" "),v("li",[_._v("有没有一些不一般的业务场景, 你确定过期时间的时候是费了比较多精力的?")]),_._v(" "),v("li",[_._v("你有"),v("strong",[_._v("没有调整过缓存的过期时间, 怎么调整的")]),_._v("? 为什么这么调整? 最好就是调大过期时间和调小过期时间的案例各准备一个.")])]),_._v(" "),v("p",[_._v("在面试过程中, 面试官可能会直接问缓存中间件的原理. 比如简历上提到了 Redis, 那么面试官就可能直接问 Redis, 进一步就可能问到 Redis 的过期 key 的删除策略.")]),_._v(" "),v("p",[_._v("另外一种可能是在和面试官聊项目的时候, 讲到项目中使用了缓存, 于是面试官就可能会问具体细节, 也就包括缓存的过期时间等内容.")]),_._v(" "),v("p",[_._v("如果面试官问到了这些问题, 也可以用本节的内容来回答.")]),_._v(" "),v("ol",[v("li",[_._v("你是"),v("strong",[_._v("如何确定缓存的过期时间")]),_._v("的?")]),_._v(" "),v("li",[v("strong",[_._v("过期时间过长或者过短有什么问题")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("怎么优化缓存的命中率")]),_._v("?")]),_._v(" "),v("li",[_._v("Redis 是如何处理过期 key 的? 是立刻删除吗?")]),_._v(" "),v("li",[_._v("当读 Redis 从库的时候, 有可能读到过期 key 吗?")]),_._v(" "),v("li",[_._v("Redis 的 RDB 或者 AOF 是如何处理过期 key 的?")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-21"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-21"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("优化过期时间有两个方向. 第一个是"),v("strong",[_._v("调大过期时间")]),_._v(", 提高缓存命中率, 并提高性能.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我优化过一个缓存的过期时间, 从十分钟延长到了二十分钟, 缓存命中率从 80% 提升到了 90%. 当然, 代价就是 Redis 中缓存了更多的 key, 占用了更多内存.")])]),_._v(" "),v("p",[_._v("又或者是"),v("strong",[_._v("减少过期时间")]),_._v(", 从而减少 Redis 的消耗.")]),_._v(" "),v("blockquote",[v("p",[_._v("我刚进公司的时候, 发现公司的过期时间基本上都是统一的半小时, 而没有考虑具体的业务特征. 后来我排查之后, 发现很多业务根本用不了半小时. 比如说我把一个业务的过期时间降低到 10 分钟, 缓存命中率基本上没有变化. 经过这样的排查之后, Redis 的开销降了 30%.")])]),_._v(" "),v("p",[_._v("在提到了缓存过期时间之后, 面试官就很可能问, 你使用的缓存是如何删除过期对象的? 这时要根据自己使用的缓存来回答, 但是基本上不会超出前置知识里面讲到的四种思路. 这里以 Redis 为例来说明.")]),_._v(" "),v("blockquote",[v("p",[_._v("我使用的是 Redis, Redis 的过期删除机制简单来说就是懒惰删除和定期删除. 懒惰删除是指 Redis 会在查询 key 的时候检测这个 key 是否已经过期, 如果已经过期, 那么 Redis 就会顺手删除这个 key.")]),_._v(" "),v("p",[_._v("单纯使用懒惰删除肯定是不行的, 因为一个 key 过期之后, 可能一直没有被使用过. 所以 Redis 结合了定期删除策略. Redis 每运行一段时间, 就会随机挑选出一部分 key, 查看是否过期, 如果已经过期了, 就把 key 删除掉. Redis 的定期删除要比这里讲的复杂很多, 毕竟 Redis 是一个追求高性能的中间件, 所以肯定要有复杂的机制控制住定期删除的开销.")])]),_._v(" "),v("p",[_._v("最后一句也就是为了引出后面的亮点. 当回答完这一句之后, 就可以等着面试官追问了. 面试官追问的问题会有很多, 一个个看.")]),_._v(" "),v("h6",{attrs:{id:"为什么不立刻删除"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么不立刻删除"}},[_._v("#")]),_._v(" 为什么不立刻删除?")]),_._v(" "),v("p",[_._v("一个经典问题就是, "),v("mark",[v("strong",[_._v("为什么不立刻删除过期的 key? 答案就是做不到, 或者即便能做到, 代价也太高")])]),_._v(".")]),_._v(" "),v("p",[_._v("最简单的做法就是前面提到的, 每一个 key 启动一个定时器, 到时间了就删掉. 但是这里会有 2 个问题.")]),_._v(" "),v("ol",[v("li",[_._v("key 太多了, 一个 key 一个计时器, Redis 承受不住那么大的计时器开销.")]),_._v(" "),v("li",[_._v("修改过期时间的时候, 要重置计时器的时间, 这会进一步带来额外的开销.")])]),_._v(" "),v("p",[_._v("所以这个思路肯定不行.")]),_._v(" "),v("p",[_._v("那么还有一种思路就是把所有的 key 额外再按照过期时间组一个延迟队列, 排在最前面的就是最近要过期的. 不过这个思路也有 3 个问题.")]),_._v(" "),v("ol",[v("li",[_._v("延迟队列的本身开销很大, 尤其是在 key 很多的情况下.")]),_._v(" "),v("li",[_._v("修改过期时间需要调整延迟队列中各个 key 的顺序.")]),_._v(" "),v("li",[_._v("延迟队列一般需要一个线程配合使用, 如果引入这个线程, 那么 Redis 就需要做更多并发控制, 性能会下降.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f13d9ea81e9587yyfef7421cf84d6084-20231223175002-rha40of.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("总的来说, 在回答的时候可以抓住关键点 "),v("strong",[_._v("性能")]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("理论上来说, 并不是做不到, 只不过代价比较高昂不值得而已.")]),_._v(" "),v("p",[_._v("最简单的做法就是使用定时器, 但是定时器本身开销太大, 还得考虑在更新过期时间的时候重置定时器. 另外一种思路就是使用延迟队列, 但是延迟队列本身开销也很大, 修改过期时间也要调整延迟队列, 还要引入大量的并发控制.")]),_._v(" "),v("p",[_._v("综合来看, 并不值得. "),v("mark",[_._v("而定期删除和懒惰删除的策略虽然看上去可能浪费内存, 但是这个浪费很少, 并且对响应时间也没那么大的影响")]),_._v(".")])]),_._v(" "),v("p",[_._v("既然没办法立刻删除, 只能定期删除, 那怎么控制这个开销呢?")]),_._v(" "),v("h6",{attrs:{id:"redis是怎么控制定期删除开销的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redis是怎么控制定期删除开销的"}},[_._v("#")]),_._v(" Redis是怎么控制定期删除开销的?")]),_._v(" "),v("p",[_._v("假如现在 Redis 有 100 万 key, 那显然 Redis 在定期删除过期 key 的时候, 是不可能遍历完这 100 万个 key 的. 而 Redis 也确实没有遍历全部的 key, 简单来说 Redis 会在每一个循环中遍历 DB. 如果当次定期删除循环没有遍历完全部 DB, 那么下一个循环就会从当次最后遍历的 DB 的下一个继续遍历下去.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/517fc00a423affbe5cb88989659a3a68-20231223175002-e8tac7f.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("针对每一个 DB, 都会有这样一个步骤.")]),_._v(" "),v("ol",[v("li",[_._v("如果 DB 里存放的 key 都没有设置过期时间, 那么遍历下一个 DB.")]),_._v(" "),v("li",[_._v("从设置了过期时间的 key 中"),v("strong",[_._v("抽一批")]),_._v(", 默认一批是 25 个.")]),_._v(" "),v("li",[_._v("逐个检查这些 key. "),v("strong",[_._v("如果这个 key 已经过期了, 那么执行删除操作")]),_._v(".")]),_._v(" "),v("li",[_._v("每遍历 16 个 key, 就检测执行时间. 如果"),v("strong",[_._v("执行时间已经超过了阈值, 那么就中断这一次定期删除循环")]),_._v(".")]),_._v(" "),v("li",[_._v("如果这一批过期的 key 比例超过一个阈值, 那么就抽取下一批 key 来检查, 这个阈值也是可以通过参数来控制的.")])]),_._v(" "),v("p",[_._v("上面这个步骤记不住也没关系, 因为在面试中很少会考察 Redis 的源码, 而且 Redis 这部分的代码修改过很多次, 也无从面起.")]),_._v(" "),v("p",[_._v("只需要按照最后总结出来的来回答就可以了.")]),_._v(" "),v("blockquote",[v("p",[_._v("在每一个定期删除循环中, Redis 会遍历 DB. 如果这个 DB 完全没有设置了过期时间的 key, 那就直接跳过. 否则就针对这个 DB 抽一批 key, 如果 key 已经过期, 就直接删除.")]),_._v(" "),v("p",[_._v("如果在这一批 key 里面, 过期的比例太低, 那么就会中断循环, 遍历下一个 DB. 如果执行时间超过了阈值, 也会中断. 不过这个中断是整个中断, 下一次定期删除的时候会从当前 DB 的下一个继续遍历.")]),_._v(" "),v("p",[_._v("总的来说, Redis 是"),v("mark",[_._v("通过控制执行定期删除循环时间来控制开销")]),_._v(", 这样可以在服务正常请求和清理过期 key 之间取得平衡.")])]),_._v(" "),v("p",[_._v("这个时候, 有些面试官会问为什么要随机抽样, 同一个 DB 内按照顺序遍历下去不就可以吗? 你就要回答"),v("strong",[_._v("确保每个 key 都能遍历到")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("随机只是为了保证每个 key 都有一定概率被抽查到. 假设在每个 DB 内部都是从头遍历的话, 那么如果每次遍历到中间, 就没时间了, 那么 DB 后面的 key 可能永远也遍历不到.")])]),_._v(" "),v("p",[_._v("可以进一步总结大部分缓存控制开销的套路, 也就是"),v("strong",[_._v("控制时间或者控制个数")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("在一些本地缓存的实现里面, 也基本上会控制住这个开销. 但是做法会比较简单. 一种做法是循环的每个迭代都检测执行时间, 超过某个阈值了就中断循环. 另外一种做法是遍历够了就结束, 比如固定遍历 10000 个. 当然也可以考虑两种策略混合使用.")])]),_._v(" "),v("h6",{attrs:{id:"如何控制定期删除的频率"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何控制定期删除的频率"}},[_._v("#")]),_._v(" 如何控制定期删除的频率?")]),_._v(" "),v("p",[_._v("在 Redis 里面, 定期删除的频率可以通过 hz 参数来控制. 不过 hz 控制的是所有的后台任务, 并不是单独控制这一个定期删除循环.")]),_._v(" "),v("p",[_._v("假如说 hz 的值是 N, 那么就意味着"),v("strong",[_._v("每 1/N 秒就会执行一次后台任务")]),_._v(". 举例来说, 如果 hz=10, 那么就意味着每 100ms 执行一次后台任务.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/210422533009e84bb629a06677221c76-20231223175002-zx0doj5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("正常来说, Redis 这个值不要超过 100. "),v("strong",[_._v("越大就意味着后台任务执行的频率越高, CPU 使用率越高")]),_._v(".")]),_._v(" "),v("p",[_._v("与之对应的是一个 dynamic-hz 选项. 在开启了这个选项之后, hz 的值会被认为是一个基数, 而实际的值是 Redis 自己动态计算的.")]),_._v(" "),v("p",[_._v("所以如果面试官问到了"),v("strong",[_._v("如何控制这个频率")]),_._v(", 就可以回答 hz 和 dynamic-hz.")]),_._v(" "),v("blockquote",[v("p",[_._v("在 Redis 里面有一个参数叫做 hz, 它代表的是 Redis 后台任务运行的频率. 正常来说, 这个值不需要调, 即便调整也不要超过 100. 与之相关的是 dynamic-hz 参数. 这个参数开启之后, Redis 就会在 hz 的基础上动态计算一个值, 用来控制后台任务的执行频率.")])]),_._v(" "),v("p",[_._v("在这之后有一个问题, 就是 Redis "),v("strong",[_._v("在使用了主从集群的时候, 如果查询从库, 有没有可能查询到过期的数据")]),_._v("?")]),_._v(" "),v("h6",{attrs:{id:"从库处理过期key"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#从库处理过期key"}},[_._v("#")]),_._v(" 从库处理过期key")]),_._v(" "),v("p",[_._v("在 Redis 3.2 之前有一个非常著名的 Bug, 就是在从库查询一个 key 的时候, 即便这个 key 已经过期, 但还是能够拿到数据. 后来这个 Bug 在 3.2 修复了. 当下如果在从库上查询 key, 而这个 key 已经过期了, 那么 Redis 从库会返回 NULL.")]),_._v(" "),v("p",[_._v("注意, "),v("mark",[v("strong",[_._v("从库和主库的区别是, 主库发现 key 过期后会执行删除操作. 但是从库不会, 从库会等待主库的删除命令")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/43187e3a40c4ddae59e7c81d453df0be-20231223175002-vyrpsbb.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("有时候面试官可能会问, 如果一个 key 过期了, 那么还能不能拿到这个 key 的值? 这时候就应该知道, 面试官问的是这个 Bug, 区分回答 3.2 之前的行为和 3.2 之后的行为就可以.")]),_._v(" "),v("blockquote",[v("p",[_._v("在 Redis 的 3.2 版本之前, 如果读从库的话, 是有可能读取到已经过期的 key. 后来在 3.2 版本之后这个 Bug 就被修复了. 不过从库上的懒惰删除特性和主库不一样. 主库上的懒惰删除是在发现 key 已经过期之后, 就直接删除了. 但是在从库上, 即便 key 已经过期了, 它也不会删除, 只是会给你返回一个 NULL 值.")])]),_._v(" "),v("p",[_._v("因为讨论到了从库之类的问题, 那么可能会把话题引导到"),v("strong",[_._v("主从同步")]),_._v(", 以及 Redis Sentinel 和 Redis Cluster 等问题上, 课程后面也会讨论这些.")]),_._v(" "),v("p",[_._v("Redis 本身也有持久化机制, 那么问题来了, "),v("strong",[_._v("Redis 在持久化的时候怎么处理这些过期的 key")]),_._v("?")]),_._v(" "),v("h6",{attrs:{id:"持久化处理过期key"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#持久化处理过期key"}},[_._v("#")]),_._v(" 持久化处理过期key")]),_._v(" "),v("p",[_._v("Redis 里面有两种持久化文件, RDB 和 AOF.")]),_._v(" "),v("p",[_._v("RDB 简单来说就是"),v("strong",[_._v("快照文件")]),_._v(", 也就是当 Redis 执行 SAVE 或者 BGSAVE 命令的时候, 就会把内存里的所有数据都写入 RDB 文件里. 后续主库可以载入这个文件来恢复数据, "),v("strong",[_._v("从库也可以利用这个文件来完成数据同步")]),_._v(". 对于 RDB 来说, 一句话总结就是"),v("strong",[_._v("主库不读不写, 从库原封不动.")])]),_._v(" "),v("p",[_._v("也就是说, 在生成 RDB 的时候, 主库会忽略已经过期的 key. 在主库加载 RDB 的时候, 也会忽略 RDB 中已经过期的 key. 而从库则是整个 RDB 都加载进来, 因为从库在加载完 RDB 之后, 很快就能从主库里面收到删除的指令, 从而删除这个过期的 key.")]),_._v(" "),v("p",[_._v("AOF 就是 Append Only File. Redis "),v("strong",[_._v("用这个文件来逐条记录执行的修改数据的命令")]),_._v(". 不管 Redis 是定期删除, 还是懒惰删除过期 key, "),v("strong",[_._v("Redis 都会记录一条 DEL 命令")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2e6975c57615715b55e0cd7a7f22c57d-20231223175002-bwn08vr.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因为每一条修改命令都要记录, 所以 "),v("strong",[_._v("AOF 就会很大")]),_._v(". 这时候 Redis 就会考虑"),v("strong",[_._v("重写整个 AOF")]),_._v(", 也就是直接把整个内存中的数据写下来, 写完就可以把之前的 AOF 文件都删了. 在重写过程中, Redis 会忽略已经过期的 key.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-13"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-13"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("这一次的亮点方案准备了理论和实践两方面的内容. 理论上是讨论该如何确定一个合理的过期时间, 而实践方面给了三个有特色的过期时间案例.")]),_._v(" "),v("h6",{attrs:{id:"如何确定过期时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何确定过期时间"}},[_._v("#")]),_._v(" 如何确定过期时间?")]),_._v(" "),v("p",[_._v("确定"),v("strong",[_._v("过期时间")]),_._v("是那种看起来很简单, 但如果之前没有认真思考过就会栽跟头的问题. 在回答这个问题之前, 可以想到, 如果缓存容量足够大, 那么缓存就可以设置成永不过期, 所有的请求都会百分百命中. 但是问题是没有足够的资源.")]),_._v(" "),v("p",[_._v("所以在实践中就是根据希望的缓存命中率来确定缓存过期时间. "),v("strong",[_._v("缓存命中率越高, 就需要越多的缓存容量, 越长的过期时间")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d57232565685c07e10ffec2ba0e70ebb-20231223175002-th7wbkp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以要"),v("strong",[_._v("先揭示这三者之间的关系")]),_._v(", 然后通过一个简单的例子说明是如何确定具体的过期时间的.")]),_._v(" "),v("blockquote",[v("p",[_._v("一般是根据缓存容量和缓存命中率确定过期时间的. 正常来说, 越高缓存命中率, 需要越多的缓存容量, 越长的过期时间. 所以最佳的做法还是通过"),v("mark",[_._v("模拟线上流量来做测试")]),_._v(", 不断延长过期时间, 直到满足命中率的要求. 当然, 也可以从业务场景出发. 比如当某个数据被查询出来以后, 用户大概率在接下来的三十分钟内再次使用这个对象, 那么就可以把过期时间设置成 30 分钟.")])]),_._v(" "),v("p",[_._v("这个回答是非常正统的, 但是有些时候如果公司资源不足, 比如原本需要 3G 内存才能满足 90% 的命中率, 结果公司只能 1G, 这个时候就只能缩短过期时间了, 这个时候命中率也会跟着下降. 可以进一步补充这个点.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果公司的缓存资源不足, 那么就只能缩短过期时间, 当然代价就是缓存命中率降低.")])]),_._v(" "),v("p",[_._v("在这个回答里面, 反复提到了命中率, 那么面试官很可能会问如何确定缓存命中率. 可以说"),v("strong",[_._v("根据用户体验来确定")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("缓存命中率要根据用户体验来确定. 比如要求 90% 的用户都能直接命中缓存, 以保证响应时间在 100ms 以内, 那么命中率就不能低于 90%. 又或者公司规定了接口的 99 线或者平均响应时间, 那么根据自己接口命中缓存和不命中缓存的响应时间, 就可以推断出来命中率应该多高.")]),_._v(" "),v("p",[_._v("举个例子, 如果公司要求平均响应时间是 300ms, 命中缓存响应时间是 100ms, 没命中缓存的响应时间是 1000ms, 假设命中率是 p, 那么 p 要满足 100 * p + 1000 * (1 - p) = 300.")])]),_._v(" "),v("p",[_._v("在这个回答里面, p 计算出来大概是 0.78. 但在面试的时候只需要回答这个等式就可以了, 并不需要真的计算出来 p.")]),_._v(" "),v("h6",{attrs:{id:"确定过期时间的案例"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#确定过期时间的案例"}},[_._v("#")]),_._v(" 确定过期时间的案例")]),_._v(" "),v("p",[_._v("接下来在面试的时候可以考虑用一些案例来证明你对计算缓存的过期时间很有经验. 可以先引出这个话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("理论上是要根据用户体验来确定过期时间, 更加直观的做法是"),v("mark",[_._v("根据重试的时间, 数据的热度来确定过期时间")]),_._v(".")])]),_._v(" "),v("blockquote",[v("p",[_._v("案例1：高并发幂等方案中 Redis 的过期时间")])]),_._v(" "),v("p",[_._v("第一个是之前说过的布隆过滤器-Redis-唯一索引的高并发幂等方案中, 确定 Redis 的过期时间的方法.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我设计过一个支持高并发的幂等方案, 里面用到了 Redis. 这个 Redis 会缓存近期已经处理过的业务 key, 那么为了避免穿透这个缓存, 缓存的过期时间就很关键了. 如果过短, 缓存命中率太低, 请求都落到数据库上, 撑不住高并发; 如果过长, 那么会浪费内存.")]),_._v(" "),v("p",[_._v("所以这个过期时间是和重复请求相关的, 例如在我的某个业务里面, 重试是很快的, 基本上在 10 分钟内就能重试完毕, 那么我就把这个 Redis 的 key 的过期时间设置为 10 分钟.")]),_._v(" "),v("p",[_._v("类似的思路也可以用于重试机制. 比如说如果流程很漫长, 那么可以考虑缓存中间结果, 比如说中间某个步骤计算的结果. 当触发重试请求的时候, 就直接利用中间结果来继续执行. 而这些中间结果的过期时间, 就会触发重试的时间.")])]),_._v(" "),v("p",[_._v("实际中很多过期时间都是根据重试机制来确定的, 不过也有一些过期时间是根据数据是不是热点来确定的.")]),_._v(" "),v("blockquote",[v("p",[_._v("案例2：热点数据过期时间")])]),_._v(" "),v("p",[_._v("简单来说, 就是"),v("strong",[_._v("越热的数据, 过期时间越长")]),_._v(". 也就是说, 如果能够确定什么样的数据是热点数据, 那么这一部分数据就可以设置更长的过期时间. 反过来, 一个数据越冷就可以将过期时间设置得越短.")]),_._v(" "),v("blockquote",[v("p",[_._v("也可以考虑根据数据是否是热点来确定过期时间. 热点数据就会设置很长的过期时间, 但是非热点数据, 过期时间就可以设置得短一些. 比如业务每个小时都会计算一些榜单数据, 那么这些榜单对应的缓存过期时间就是一个小时.")]),_._v(" "),v("p",[_._v("又比如说当某个大 V 发布了一个新作品之后, 这个新作品的缓存时间可以保持在数小时. 因为可以预期大 V 的粉丝会在这几小时内看完这个新作品. 而一个已经发布很久的作品, 即便要缓存, 缓存时间也要设置得比较短, 因为这个时候并没有什么人来看.")])]),_._v(" "),v("p",[_._v("此外还有一个比较奇诡的方案, 就是缓存预加载与超短过期时间.")]),_._v(" "),v("blockquote",[v("p",[_._v("案例3：预加载与超短过期时间")])]),_._v(" "),v("p",[_._v("在一些业务场景里面, "),v("strong",[_._v("用户的行为是可以预料的")]),_._v(". 比如列表页和详情页, 用户在看到列表页之后, 下一个动作比较大的可能就是点击列表页里的某项, 查看详情. 例如在搜索的时候, 用户有意识地搜索了某个关键字, 那么看到结果列表页之后, 他大概率就会点击列表页中的头几项进一步查看详情.")]),_._v(" "),v("p",[_._v("抽象地来说, 就是用户访问 A 数据的时候, 大概率会访问 B 数据. 所以在返回 A 数据时, 顺便把 B 数据准备好, 丢到缓存里面. 那么进一步考虑, 这个用户不管有没有访问 B 数据, 别人都是用不上的. 而且用户也不会一直访问 B 数据, 可能就是一分钟或者更短的时间内访问一次两次. 所以这个时候可以把缓存时间设置得很短, 来控制住缓存的内存使用率.")]),_._v(" "),v("p",[_._v("所以, 也可以认为这个方案就是用"),v("strong",[_._v("内存换响应时间")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我们有一个业务场景, 就是用户会搜索出一个列表页, 然后用户大概率就会点击列表页前面的某些数据. 因此我做了一个简单的性能优化, 就是预加载缓存. 当用户访问列表页的时候, 会异步地把列表页的第一页的数据加载出来放到缓存里面. 因为可以预计的是, 接下来用户会直接使用查看列表页中内容的详情信息. 那么就会直接命中缓存, 而不必再次查询.")]),_._v(" "),v("p",[_._v("当然, 因为用户也不一定就会访问, 而且就算访问了也就是只访问一两次, 因此过期时间可以设置得很短, 比如一分钟.")])]),_._v(" "),v("p",[_._v("这个方案应该说, 在实践中的局限性很大, 只有在提到的这种关联性很强的业务场景中才能使用. 但是拿出去面试, 就很有用, 因为它能体现你对缓存过期时间以及对具体业务场景的深刻理解.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-29"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-29"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("来总结一下这节课的主要内容.")]),_._v(" "),v("p",[_._v("首先在前置知识里面介绍缓存命中率和实现过期机制的一般思路, 可以结合自己使用的各种缓存来理解. 在实践中, 我也非常建议你关注一下自己使用的缓存命中率, 并且尝试优化一下.")]),_._v(" "),v("p",[_._v("这节课还重点解决了 Redis 中和过期时间有关的问题, 分别是:")]),_._v(" "),v("ul",[v("li",[_._v("Redis 具体是怎么处理过期 key 的? 懒惰删除加定期删除.")]),_._v(" "),v("li",[_._v("Redis 为什么不立刻删除? 实现立刻删除的代价太高.")]),_._v(" "),v("li",[_._v("Redis 是怎么控制定期删除的开销的? 总的来说是控制执行时间.")]),_._v(" "),v("li",[_._v("怎么控制 Redis 的定期删除频率? 通过 hz 参数和 dynamic-hz 参数控制.")]),_._v(" "),v("li",[_._v("从库是怎么处理过期 key 的? 查询返回 NULL, 删除等主库命令.")]),_._v(" "),v("li",[_._v("Redis 持久化怎么处理过期 key? 对于 RDB 来说, 主库不读不写, 从库原封不动. 对于 AOF 来说, 正常追加 DEL 命令, 重写则是不管.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1b3ac9cffdaa5b02bd4cyy0058cfc11e-20231223175002-3j1qnny.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-21"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-21"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考 2 个问题.")]),_._v(" "),v("ol",[v("li",[_._v("你有没有用过本地缓存? 你知道它是如何删除过期 key 的吗?")]),_._v(" "),v("li",[_._v("有没有遇到过动态确定过期时间的场景? 比如说根据请求特征, 计算时间, 重要性, 优先级等, 为同一个业务场景的不同请求设置不同的过期时间.")])]),_._v(" "),v("h4",{attrs:{id:"_32-缓存淘汰策略-怎么淘汰缓存命中率才不会下降"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_32-缓存淘汰策略-怎么淘汰缓存命中率才不会下降"}},[_._v("#")]),_._v(" 32-缓存淘汰策略:怎么淘汰缓存命中率才不会下降?")]),_._v(" "),v("p",[_._v("今天来聊一个使用缓存的时候绕不开的话题--"),v("strong",[_._v("如何淘汰键值对")]),_._v('? 先从 "为什么要淘汰" 这个问题开始学习.')]),_._v(" "),v("h5",{attrs:{id:"为什么要淘汰"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么要淘汰"}},[_._v("#")]),_._v(" 为什么要淘汰?")]),_._v(" "),v("p",[_._v("日常在使用缓存的时候, 都会尝试控制整个缓存的开销, 尤其是本地缓存的内存开销. 比如说线上偶尔会遇到本地缓存了太多数据, 导致应用内存不足的问题. 如果是 Java 这种垃圾回收的语言, 那么就会遇到频繁地垃圾回收甚至 full GC 之类的问题.")]),_._v(" "),v("p",[_._v("所以用"),v("strong",[_._v("缓存肯定要控制住缓存的内存使用量")]),_._v(". 而这就会引出一个问题, 万一达到了内存使用上限, 但是又需要加入新的键值对, 怎么办? 最保守的做法就是直接报错, 那就没有办法缓存新的数据了. 后续如果缓存中已有的数据过期了, 就能缓存新的数据了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ed91bc802b8fd16ea0f91c3385ce168d-20231223175002-7i1d72h.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是大多数的业务是不能接受这种方案的, 因为这一类的业务认为已经在缓存中的数据可能用不上了, 虽然还没有过期, 但是还是"),v("strong",[_._v("可以考虑淘汰掉, 腾出空间来存放新的数据")]),_._v(". 这些新的数据比老的数据有更大的可能性被使用.")]),_._v(" "),v("h5",{attrs:{id:"淘汰算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#淘汰算法"}},[_._v("#")]),_._v(" 淘汰算法")]),_._v(" "),v("p",[_._v("最有名的淘汰算法是 LRU 和 LFU. 除了这两种, 还有最佳置换算法(OPT)和先进先出置换算法(FIFO)等, 但是用得都不如 LRU 和 LFU 多, 所以这里主要聊 LRU 和 LFU 这两种.")]),_._v(" "),v("h6",{attrs:{id:"lru"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#lru"}},[_._v("#")]),_._v(" LRU")]),_._v(" "),v("p",[v("strong",[_._v("LRU(Least Recently Used)是指最近最少使用算法")]),_._v(". 也就是缓存容量不足的时候, 就"),v("mark",[v("strong",[_._v("从所有的 key 里面挑出一个最近一段时间最长时间未使用的 key")])]),_._v(".")]),_._v(" "),v("p",[_._v("这个算法从实现上来说很简单, "),v("strong",[_._v("只需要把 key 用额外的链表连起来, 然后每次被访问到的 key 都挪到队尾, 那么队首就是最近最长时间未访问过的 key")]),_._v(". 也可以反过来, 每次访问过的挪到队首, 那么队尾就是最近最久未访问过的 key. 比如可以借助 Java 的 LinkedHashMap 轻易实现 LRU 算法.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/26ayyd38e37ec287b4c3da2029df670f-20231223175002-gy409km.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里访问是一个含糊的说法, 可以认为"),v("strong",[_._v("读写都是访问")]),_._v(", 也可以认为只有写是访问. 所以有个 LRU 的变种是只有在写的时候, 才会挪动这个 key, 读并不会, 也就是"),v("strong",[_._v("它倾向于保留写频繁的数据")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"lfu"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#lfu"}},[_._v("#")]),_._v(" LFU")]),_._v(" "),v("p",[v("strong",[_._v("LFU(Least Frequently Used)是最不经常使用算法, 它是根据对象的使用次数来确定淘汰对象的, 每次都是将使用次数最低的淘汰掉")]),_._v(". 所以基本的思路就是"),v("strong",[_._v("按照访问频率来给所有的对象排序. 每次要淘汰的时候, 就从使用次数最少的对象里面找出一个淘汰掉")]),_._v(".")]),_._v(" "),v("p",[_._v("如果有好几个对象的访问频次恰好相等, 而且又是最低的, 那么可以自由决策如何淘汰. 标准做法是淘汰最先插入的, 不过也有一些实现就是随机删一个, 又或者删掉排序位置最小的那个. 实现的基本思路就是每次读写的时候, 对象上面的次数都加 1, 然后调整位置.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/26ff10849e7f7ce99b389cb050f395a1-20231223175002-woljd6y.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个算法也有一些变种. 最主要的变种是统计一段时间内的访问次数而不是整个生命周期的次数. 比如每个对象都只统计近一个小时内的访问次数. 但是这种变种的实现复杂度就要高很多.")]),_._v(" "),v("h6",{attrs:{id:"小结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[_._v("#")]),_._v(" 小结")]),_._v(" "),v("p",[_._v("在实践中, 一般是优先考虑 LRU. 这主要是因为 LRU 对时间局部性突出的应用非常友好, 而大多数的应用场景都满足时间局部性的要求.")]),_._v(" "),v("p",[_._v("但是 LRU 在一些特殊的场景下, 表现也不好. 最典型的场景就是"),v("strong",[_._v("访问历史记录")]),_._v(", 因为越是历史悠久的, 越有可能已经被淘汰了. 另外一个场景是"),v("strong",[_._v("遍历")]),_._v(", 遍历的时候, 当次被遍历到对象总是不会被淘汰掉, 而实际上, 已经被遍历的对象反而应该被淘汰掉, 腾出空间给尚未遍历的对象.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/314549c93d87f66c91cea32b7d784ef0-20231223175002-s3ixos9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("例如, 图中遍历到 key5 的时候会触发淘汰, 把 key4 淘汰了. 紧接着遍历 key4, 会把 key3 淘汰了. 以此类推, 最终结果就是缓存完全没命中.")]),_._v(" "),v("h5",{attrs:{id:"redis支持的淘汰算法"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redis支持的淘汰算法"}},[_._v("#")]),_._v(" Redis支持的淘汰算法")]),_._v(" "),v("p",[_._v("Redis 支持很多种淘汰算法, 可以通过 "),v("strong",[_._v("maxmemory 选项")]),_._v("来控制 Redis 的整个内存使用量, 还可以通过"),v("strong",[_._v("指定 maxmemory_policy 来设置淘汰算法")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/67f5f45ab8d835375632d3c477411700-20231223175002-gkbefbe.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("另外, 没有办法控制某些 key 的最大内存使用量, 比如说某个业务最多缓存 100M 的数据, "),v("strong",[_._v("只能控制整个 Redis 实例的内存使用量")]),_._v(".")]),_._v(" "),v("p",[_._v("但可以通过控制某个业务允许的键值对数量和单一键值对最大内存来间接控制业务在 Redis 上的内存使用量. 比如某个业务只允许有 10000 个键值对, 每个键值对不能超过 1KB, 那么它的整个内存使用量就不会超过 10MB.")]),_._v(" "),v("p",[_._v("可以考虑在 Redis 中"),v("strong",[_._v("额外记录一个键值对数量, 同时监听键值对的删除命令")]),_._v(". 当新加入某个键值对的时候, 键值对数量加一. 当某个键值对被删除的时候, 键值对减一, 那么就算键值对自然过期被淘汰, 还是能够得到通知.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/44f53618a5d487ea600172b2d297cb60-20231223175002-uqoc09j.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("注意, 要区分一下这个键值对是一个全新的键值对, 还是已有这个键但是值被修改了. 在后一种情况下, 并不需要更新键值对的数量.")]),_._v(" "),v("p",[_._v("这种机制很复杂, 如果你想把后面提到的那些算法用在 Redis 上, 就得编写一些比较复杂的 lua 脚本.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-32"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-32"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试缓存淘汰之前, 需要了解清楚公司内的一些情况.")]),_._v(" "),v("ul",[v("li",[_._v("公司的 "),v("strong",[_._v("Redis 淘汰策略")]),_._v("是什么? 中间有没有调整过? 如果有, 那么为什么调整?")]),_._v(" "),v("li",[_._v("有没有用过本地缓存? 如果用过本地缓存, 那么这个本地缓存是如何控制内存使用量的? 它支持什么样的缓存淘汰策略?")]),_._v(" "),v("li",[_._v("有没有出现过因为缓存占用内存太大而引起的线上故障? 后来是怎么解决的?")]),_._v(" "),v("li",[_._v("有没有使用 Redis 不当引起的线上故障? 后来是怎么解决的?")])]),_._v(" "),v("p",[_._v("非常建议有空的时候写一个本地缓存. 对于大多数语言来说, 实现一个本地缓存所需的数据结构大多数都已经有了, 所以实际上难度并不大. 在这个过程中, 就可以尝试设计不同的淘汰策略, 这样就会有更加深刻的理解.")]),_._v(" "),v("p",[_._v("除此以外, 当面试官问到以下问题, 也可以用这节的内容来回答.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("在使用缓存的时候有什么注意事项")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("为什么要控制缓存的内存使用量")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("你使用缓存遇到过什么问题")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("你优化过缓存吗? 怎么提高缓存的命中率")]),_._v("?")]),_._v(" "),v("li",[_._v("R"),v("strong",[_._v("edis 支持哪些淘汰策略? 你们公司用的是什么")]),_._v("?")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-22"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-22"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("最好的面试思路还是把"),v("strong",[_._v("优化缓存淘汰策略作为保证系统高性能的一环")]),_._v(". 这里就可以用对比说明策略, 就是在优化之前缓存命中率或者响应时间有多差, 而在优化之后, 缓存命中率提高了多少或者响应时间下降了多少.")]),_._v(" "),v("p",[_._v("这里用优先淘汰代价低的案例来展示如何回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高系统的性能, 我还尝试过优化缓存. 早期有一个业务, 用到了一个本地缓存. 这个本地缓存使用的淘汰算法是 LRU, 最开始都觉得这个算法没什么问题. 后来业务反馈, 说有几个大客户一直抱怨自己的查询时快时慢. 一听到时快时慢, 我就可以确定应该是缓存出了问题.")]),_._v(" "),v("p",[_._v("经过排查发现原来这个缓存执行 LRU 的时候有时会把大客户的数据淘汰掉. 而偏偏大客户的数据实时计算很慢, 所以一旦没有命中缓存, 响应时间就会暴增.")]),_._v(" "),v("p",[_._v("后来进一步梳理业务, 一方面考虑进一步增大缓存的可用内存. 另外一方面, 设计了灵活的淘汰策略, 在淘汰的时候优先淘汰小客户的数据.")]),_._v(" "),v("p",[_._v("这样做的好处就是优先保证了大客户的用户体验, 平均响应时间下降了40%. 而小客户因为本身计算就很快, 所以影响也不是很大.")])]),_._v(" "),v("p",[_._v("当然, 从实践角度来说, 针对不同业务调整淘汰策略取得的收益是比较小的. 但是站在面试的角度, 这也算是一个比较新奇的优化点, 倒是可以用用.")]),_._v(" "),v("p",[_._v('除了主动提起, 面试官也可能主动询问, 比如从怎么安全使用缓存这个点切入. "安全" 强调的就是用缓存不能影响到别人, 那么控制缓存的内存使用量就是一个关键的环节. 所以这种时候应该这样回答:')]),_._v(" "),v("blockquote",[v("p",[_._v("使用缓存一定要注意控制缓存的内存使用量, 不能因为某一个业务而直接把所有的内存都耗尽.")])]),_._v(" "),v("p",[_._v("要控制住内存使用量, 就需要在内存用完的时候淘汰一些键值对.")]),_._v(" "),v("p",[_._v("实际上, 解决缓存淘汰的最佳思路, 就是给缓存足够的内存, 不触发淘汰. 但这也可以说是正确但是无用的废话, 因为现实中不可能你需要多少内存就有多少内存, 所以最终还是要考虑怎么淘汰键值对.")]),_._v(" "),v("blockquote",[v("p",[_._v("解决缓存淘汰的问题, "),v("mark",[_._v("应该优先考虑增加内存, 降低缓存淘汰的几率")]),_._v(". 不过毕竟内存也不是无限的, 最终都还是要选择合适的淘汰策略. 比如说我们公司的 Redis 使用了 volatile-lru 淘汰策略.")])]),_._v(" "),v("p",[_._v("这里可以将 volatile-lru 淘汰策略换成实际的策略. 有些时候面试官也可能会直接问 Redis 支持哪些淘汰策略, 这时候按照前置知识里面罗列出来的内容回答就可以了, 同时不要忘记补充你的 Redis 使用的是什么策略.")]),_._v(" "),v("p",[_._v("最后记得补充一句话, 用来引导话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("这些 LRU 或者 LFU 之类的算法都是普适性很强的算法, 但是我也用过一些更加"),v("mark",[_._v("针对业务的淘汰算法")]),_._v(". 比如说按照优先级淘汰, 大对象优先淘汰, 小对象优先淘汰, 代价低优先淘汰. 大多数时候, 不论是 Redis 还是本地缓存, 这种业务针对性特别强的算法, 都得自己实现.")])]),_._v(" "),v("p",[_._v("相信面试官会对针对业务特性来设计淘汰策略感兴趣, 因为它能够体现你对业务的理解, 以及灵活设计方案的能力.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-14"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-14"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("在实践中, 同一个公司内部业务的重要性都是有区别的. 就算是同一个业务内部, 不同用户的重要性也是有区别的. 所以"),v("mark",[v("strong",[_._v("针对业务设计淘汰策略的一个核心思路就是根据业务的重要性来设计")])]),_._v(".")]),_._v(" "),v("p",[_._v("比如某个服务同时服务于 VIP 用户和普通用户, 那么完全可以在缓存触发淘汰的时候, 先把普通用户的数据淘汰了. 所以可以考虑"),v("mark",[v("strong",[_._v("为每一个键值对绑定一个优先级, 每次缓存要执行淘汰的时候, 就从先淘汰优先级最低的数据")])]),_._v(".")]),_._v(" "),v("p",[_._v("这个方案在 Redis 落地基本上就是在前面提到的控制键值对数量的基础上, 引入一个"),v("strong",[_._v("按照优先级进行排序的有序集合, 那么有序集合里元素个数就是键值对个数")]),_._v(". 在每次触发淘汰的时候, 从有序集合里面取出来一个 key, 再把对应的键值对删除.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/92be1066d2dcdfcf4c3cd1a48baa4338-20231223175002-4uk2n8k.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以先简单介绍一下这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我在业务里面使用过一个按照优先级来淘汰的策略. 我们的业务有一个特点, 就是数据有很鲜明的"),v("mark",[_._v("重要性之分")]),_._v(". 所以可以尽可能保证优先级高的数据都在缓存中. 所以在触发了淘汰的时候, 我们希望先淘汰优先级比较低的缓存. 所以我在 Redis 上利用有序集合设计了一个控制键值对数量, 并且按照优先级来淘汰键值对的机制. 这个有序集合是使用数据的优先级来排序的, 也就是用优先级作为 score.")])]),_._v(" "),v("p",[_._v("这里要仔细解释每一个部分. 首先是"),v("strong",[_._v("增加键值对的时候是如何操作")]),_._v("的.")]),_._v(" "),v("blockquote",[v("p",[_._v("增加一个键值对就要执行一个 lua 脚本. 在这个脚本里面, 它会先检测有序集合里面的元素个数有没有超过允许的键值对数量上限, 如果没有超过, 就写入键值对, 再把 key 加入有序集合. "),v("mark",[_._v("如果超过了上限, 那么就从有序集合里面拿出第一个 key, 删除这个 key 对应的键值对")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dbde5623e1cf22c700dbc5eac15e3474-20231223175002-o3vunje.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后补充"),v("strong",[_._v("怎么在键值对过期的时候, 维护有序集合")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("同时监听 Redis 上的删除事件, 每次收到删除事件, 就把有序集合中对应的 key 删除.")])]),_._v(" "),v("p",[_._v("那么在这个基础上, 根据计算优先级的不同方式, 可以将这个机制用于不同的场景. 所以需要总结拔高一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("在这个基础上, 可以根据不同的业务特征来计算优先级, 从而实现大对象先淘汰, 小对象先淘汰, 热度低先淘汰等算法.")])]),_._v(" "),v("p",[_._v("这里稍微解释一下这个总结里面提到的几种淘汰策略, 在面试官问到的时候可以补充说明.")]),_._v(" "),v("h6",{attrs:{id:"先淘汰大对象"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#先淘汰大对象"}},[_._v("#")]),_._v(" 先淘汰大对象")]),_._v(" "),v("p",[_._v("在一些场景下, 如果缓存有大有小, 那么在淘汰的时候你会希望"),v("strong",[_._v("尽可能先把大的对象淘汰")]),_._v("了, 因为这样可以一次性腾出比较多的内存. 这种策略在本地缓存实现上经常使用. 与之对应的另一些场景下, 可以考虑小对象优先淘汰.")]),_._v(" "),v("h6",{attrs:{id:"先淘汰小对象"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#先淘汰小对象"}},[_._v("#")]),_._v(" 先淘汰小对象")]),_._v(" "),v("p",[_._v("比如大对象都是经过复杂计算之后得出来的, 而小对象的计算逻辑就非常简单. 那么显然淘汰大对象是不合适的, 因为一旦缓存未命中, 那么响应时间就会大幅度提高. 而淘汰小对象, 即便下一次触发了重复计算, 响应时间也没多少波动. 进一步抽象就可以说成是代价低的优先淘汰.")]),_._v(" "),v("p",[_._v("所谓的"),v("strong",[_._v("代价高低")]),_._v('是一种逻辑上的概念, 可以把任何你认为会对业务产生关键性影响的资源认为是 "代价", 而消耗很多这个资源的, 就是代价高昂. 不怎么消耗这个资源的, 就可以认为是代价低廉.')]),_._v(" "),v("p",[_._v("那么小对象先淘汰也是基于这样一个假设, 小对象对应的计算步骤都是很快的, 代价是比较低的, 所以可以先淘汰. 但是淘汰小对象也有一个缺陷, 就是如果新加入的键值对数据比较大, 那么需要淘汰好几个小对象才能腾出足够的空间.")]),_._v(" "),v("h6",{attrs:{id:"低热度优先"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#低热度优先"}},[_._v("#")]),_._v(" 低热度优先")]),_._v(" "),v("p",[_._v("这种是根据数据冷热来淘汰, 比如存在博主粉丝关系的内容平台上, 在淘汰数据的时候完全可以先把小博主的数据淘汰了, 留下大博主的数据. 因为大博主粉丝更多, 所以他们的数据留下来有更大的概率会被访问到. 这个和上节提到的热点数据缓存时间会更长的思路是一样的.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-30"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-30"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("最后来总结一下这节的内容.")]),_._v(" "),v("p",[_._v("需要先了解为什么会有淘汰这种说法, 原因就是希望控制住内存使用量. 常见的淘汰算法 LRU, LFU, 以及 Redis 支持的各种淘汰算法比较重要, 在准备面试的过程中, 记得提前了解你们公司 Redis 使用的算法.")]),_._v(" "),v("p",[_._v("最后提出了一个"),v("strong",[_._v("针对业务特性来设计的按照优先级淘汰的算法, 根据怎么计算优先级又可以进一步细分成大对象先淘汰, 小对象先淘汰, 根据热度来淘汰")]),_._v(". 这些方案在 Redis 上落地的时候, 都需要借助 Redis 的有序集合, 而且为了避免并发问题, "),v("strong",[_._v("操作 Redis 的时候都是要通过 lua 脚本封装一系列操作的")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a073ea7c658277777246dd068f61b9dd-20231223175002-jvc72s0.png",alt:""}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"思考题-22"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#思考题-22"}},[_._v("#")]),_._v(" 思考题")]),_._v(" "),v("p",[_._v("最后来思考两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("我在这一节里面只说了, 可以在 Redis 上控制键值对数量来间接控制内存使用量. 实际上要直接控制某个业务的内存使用量也不是不行, 就是非常麻烦, 你觉得可以怎么做?")]),_._v(" "),v("li",[_._v("在 Redis 控制内存使用量的方案中, 一直说要使用 lua 脚本, 因为有并发问题. 那么你能想到有什么样的并发问题吗?")])]),_._v(" "),v("h4",{attrs:{id:"_33-缓存模式-缓存模式能不能解决缓存一致性问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_33-缓存模式-缓存模式能不能解决缓存一致性问题"}},[_._v("#")]),_._v(" 33-缓存模式:缓存模式能不能解决缓存一致性问题?")]),_._v(" "),v("p",[_._v("今天来学习缓存的另外一个热点——"),v("strong",[_._v("缓存模式")]),_._v(".")]),_._v(" "),v("p",[_._v("缓存模式在面试中属于高频问题, 但是大部分人的回答都会有两个缺陷: 一个是不够完整, 也就是只知道一部分缓存模式; 另外一个是不够深入, 也就是只能泛泛而谈. 尤其是有些面试官会故意问怎么用缓存模式来解决一致性问题, 你就有可能上当.")]),_._v(" "),v("p",[_._v("那么这节就深入分析每一个缓存模式, 并且讨论它的优缺点以及在数据一致性方面的表现.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-33"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-33"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("缓存模式首先要确保自己能够记住这些模式, 其次要在公司内部收集一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你们"),v("strong",[_._v("公司有没有使用缓存模式, 使用了哪些, 有没有遇到过缓存一致性的问题, 最终是如何解决的")]),_._v("?")]),_._v(" "),v("li",[_._v("你的"),v("strong",[_._v("业务中使用了缓存之后, 你是如何更新缓存和数据库中的数据的? 有没有一致性问题")]),_._v("?")])]),_._v(" "),v("p",[v("strong",[_._v("缓存模式用得好可以有效缓解数据一致性的问题, 也可以用于解决缓存穿透, 击穿和雪崩的问题")]),_._v(". 这两个话题后面会进一步讨论, 要结合在一起理解.")]),_._v(" "),v("p",[_._v("为了便于理解, 下面用一个简化模型来解释缓存模式, 也就是系统里面有缓存和数据库, 读写数据都要操作这两者.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-23"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-23"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("在最开始面试的时候, 可以在自我介绍的时候提起缓存模式的话题.")]),_._v(" "),v("blockquote",[v("p",[_._v("我对缓存模式有比较深刻的理解, 平时会用缓存模式来解决很多问题, 比如说缓存穿透, 雪崩和击穿.")])]),_._v(" "),v("p",[_._v("在这段话里面, 还提到了缓存穿透, 雪崩和击穿, 这一部分后面会学习. 在后续面试过程中, 面试官就会直接问, 你"),v("strong",[_._v("了解哪些缓存模式或者用过哪些缓存模式")]),_._v(". 就可以这么回答:")]),_._v(" "),v("blockquote",[v("p",[_._v("缓存模式有 Cache Aside, Read Through, Write Through, Write Back, Singleflight. 除此之外, 我还用过删除缓存和延迟双删.")])]),_._v(" "),v("p",[_._v("严格意义上来说, 删除缓存, 延迟双删不能算是缓存模式, 但是在面试中还是很常见的, 所以可以顺便提一下.")]),_._v(" "),v("h6",{attrs:{id:"cache-aside"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#cache-aside"}},[_._v("#")]),_._v(" Cache Aside")]),_._v(" "),v("p",[_._v("Cache Aside 我个人认为都很难说是一种缓存模式, 毕竟什么也不做的时候, 就是 Cache Aside. 这个模式, "),v("strong",[_._v("就是把缓存看作一个独立的数据源. 当写入的时候, 业务方来控制写入顺序")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/21b770802b9a125200ff212ef23ebb8c-20231223175002-way289o.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("当"),v("strong",[_._v("读取的时候, 也是由业务方来控制")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c5ffd743dafdd7e0338ca85957d25061-20231223175002-qy2q7t2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("先简单介绍读写的基本操作.")]),_._v(" "),v("blockquote",[v("p",[_._v("Cache Aside 是最基本的缓存模式, 在这个模式下, 业务代码就是把缓存看成是和数据库一样的独立的数据源, 然后业务代码控制怎么写入缓存, 怎么写入数据库. 一般来说, 都是优先写入数据库的.")])]),_._v(" "),v("p",[_._v("最后一句提到了优先写入数据库, 那么面试官就会追问为什么要先写入数据库.")]),_._v(" "),v("blockquote",[v("p",[_._v("先写数据库是因为大多数业务场景下数据都是以数据库为准的, 也就是说如果写入数据库成功了, 就可以认为这个操作成功了. 即便写入缓存失败, 但是缓存本身会有过期时间, 那么它过期之后重新加载, 数据就会恢复一致.")])]),_._v(" "),v("p",[_._v("最后要加一句总结.")]),_._v(" "),v("blockquote",[v("p",[_._v("不管是先写数据库还是先写缓存, "),v("mark",[_._v("Cache Aside 都不能解决数据一致性问题")]),_._v(".")])]),_._v(" "),v("p",[_._v("这一句总结很重要, 可以看下面的图, 如果面试官追问为什么都不能解决, 或者有什么不一致的场景, 按照图里面的内容来回答就可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5yy88978b6eae00aa3eee64eacdda546-20231223175002-w9zr8iu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("教你一个简单的记忆方法, 就是注意观察图里的线程 2, 它一定是"),v("strong",[_._v("后面才开始执行, 但是最先结束的")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"read-through"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#read-through"}},[_._v("#")]),_._v(" Read Through")]),_._v(" "),v("p",[_._v("这个缓存模式也叫做"),v("strong",[_._v("读穿透")]),_._v(". 它的核心是"),v("mark",[v("strong",[_._v("当缓存里面没有数据的时候, 缓存会代替你去数据库里面把数据加载出来, 并且缓存起来")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/53519ca2ee9f7fd41c71a7489847ea65-20231223175002-i1eakuj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而写入的时候, 就和 Cache Aside 一样.")]),_._v(" "),v("blockquote",[v("p",[_._v("Read Through 也是一个很常用的缓存模式. Read Through 是指在读缓存的时候, 如果缓存未命中, 那么缓存会代替业务代码去数据库中加载数据.")]),_._v(" "),v("p",[_._v("这种模式有两个异步变种, 一种是异步写回缓存, 一种是完全异步加载数据, 然后写回缓存. 当然, 不管是什么变种, "),v("mark",[_._v("Read Through 都不能解决缓存一致性的问题")]),_._v(".")])]),_._v(" "),v("p",[_._v("可以注意到, "),v("strong",[_._v("Read Through 只管了读的部分, 而写的部分是完全没有管的, 所以它的写过程和 Cache Aside 是一样的")]),_._v(". 因此, 它一样有缓存一致性的问题. 要是面试官追问, 就用 Cache Aside 中的分析来回答.")]),_._v(" "),v("p",[_._v("最后提到异步加载数据, 也就是为了引出亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点: 异步方案")])]),_._v(" "),v("p",[_._v("Read Through 模式在发现缓存里面没有数据的时候, 加载数据, 缓存起来这两个步骤是可以考虑异步执行的. 所以可以先回答第一个变种.")]),_._v(" "),v("blockquote",[v("p",[_._v("缓存可以在从数据库加载了数据之后, 立刻把数据返回给业务代码, 然后开启一个线程异步更新缓存.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/111b230fd2fb2266d2720688895ca23f-20231223175002-6r79s96.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("既然缓存数据这个步骤可以异步, 那么"),v("strong",[_._v("从数据库中加载数据也完全可以异步")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("第二个变种是直接让整个加载和回写缓存的过程都异步执行. 也就是说, 如果缓存未命中, 那么就直接返回一个错误或者默认值, 然后缓存异步地去数据库中加载, 并且回写缓存. 和第一个变种比起来, 这种变种的缺陷是业务方在当次调用中只能拿到错误或者默认值.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3072d2d4916551a9fe58a9f747086985-20231223175002-6sw3pe3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后可以总结一下什么场景可以使用这两个变种.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果业务方对响应时间的要求非常苛刻, 那么就可以考虑使用变种二. 代价就是业务方会收到错误响应或者默认值. 而变种一其实收益很小, 只有在缓存操作很慢的时候才会考虑. 比如说缓存大对象, 又或者要把一个大对象序列化之后再存储到缓存里面.")])]),_._v(" "),v("p",[_._v("如果在实践中用过这些变种, 那就可以用自己的实际业务来举例子.")]),_._v(" "),v("h6",{attrs:{id:"write-through"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#write-through"}},[_._v("#")]),_._v(" Write Through")]),_._v(" "),v("p",[_._v("这个也叫做"),v("mark",[v("strong",[_._v("写穿透, 是指当业务方写入数据的时候, 只需要写入缓存. 缓存会代替业务方去更新数据库")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/811e6fd221d070654b4bdbe93e68d5b6-20231223175002-puhht5b.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("Write Through 读数据的步骤就跟 Cache Aside 是一样的")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("Write Through 就是在写入数据的时候, 只写入缓存, 然后缓存会代替我们的去更新数据库. 但是, Write Through 没有要求先写数据库还是先写缓存, 不过一般也是先写数据库.")]),_._v(" "),v("p",[_._v("其次, Write Through 也没有讨论如果缓存中原本没有数据, 那么写入数据的时候, 要不要更新缓存. 一般来说, 如果预计写入的数据很快就会读到, 那么就要刷新缓存中的数据.")]),_._v(" "),v("p",[_._v("Write Through 也有对应的异步变种方案. 当然, 这些变种也都"),v("mark",[_._v("没有解决缓存一致性的问题")]),_._v(".")])]),_._v(" "),v("p",[_._v("在刚刚的回答中, 提到了写入顺序的问题, 那么面试官就可能追问写入一致性的问题. 显然, Write Through 也没有解决一致性的问题, 同样可以参考 Cache Aside 中的分析.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点: 异步方案")])]),_._v(" "),v("p",[_._v("类似地, Write Through 也是可以考虑异步的. 也就是在"),v("strong",[_._v("写入缓存之后, 缓存立刻返回结果")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5aa8d273fa2b86033a4932400ecd9090-20231223175002-u7h9cb3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但这种模式是有"),v("strong",[_._v("可能丢数据")]),_._v("的, 也就是当业务代码收到成功响应之后, 缓存崩溃了, 那么数据其实并没有写入到数据库中.")]),_._v(" "),v("p",[_._v("另外一个比较可行的变种是同步写入到数据库中, 但是会"),v("strong",[_._v("异步刷新缓存")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b13c2f58dd835e540b2d62bbe01db27f-20231223175002-r6eo2i9.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("在缓存收到写请求之后, 可以直接返回成功响应, 然后异步写入数据库和刷新缓存. 但是这种方案比较危险, 存在数据丢失的风险.")]),_._v(" "),v("p",[_._v("缓存也可以考虑只写入数据库, 然后返回成功响应, 后面可以异步刷新缓存. 基本上前者很少用, 要用也是用一个和它很像的 Write Back 方案. 变种二则适合用于缓存写入操作且代价高昂的场景. 比如说前面提到的, 写入大对象或者需要序列化大对象再写入缓存.")])]),_._v(" "),v("h6",{attrs:{id:"write-back"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#write-back"}},[_._v("#")]),_._v(" Write Back")]),_._v(" "),v("p",[_._v("Write Back 这个模式的特色非常鲜明. 在这个模式下, "),v("strong",[_._v("当写入数据的时候, 只是写到了缓存. 当缓存过期的时候, 才会被刷新到数据库")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/08e535458fab38d17d8a99f3c1bee033-20231223175002-x7kpejn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("Write Back 模式是指在更新数据的时候, 只把数据更新到缓存中就返回. 后续会有一个组件监听缓存中过期的 key, 在过期的时候将数据刷新到数据库中. 显然, 只是监听过期 key 的话还是会有问题, 比如说关闭缓存的时候还是需要把缓存中的数据全部刷新到数据库里.")])]),_._v(" "),v("p",[_._v("但如果数据还在缓存中的时候, 缓存突然崩溃了, 那数据就直接丢了.")]),_._v(" "),v("blockquote",[v("p",[_._v("Write Back 有一个硬伤, 就是如果缓存突然宕机, 那么还没有刷新到数据库的数据就彻底丢失了. 这也限制了 Write Back 模式在现实中的应用. 不过要是缓存能够做到高可用, 也就不容易崩溃, 也可以考虑使用.")])]),_._v(" "),v("p",[_._v("到这里还可以进一步刷亮点, 深入讨论 Write Back 和数据一致性的问题. 所以可以稍微总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("Write Back 最大的优点是排除数据丢失这一点, 它能解决数据一致性的问题.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点: 能否解决数据一致性问题")])]),_._v(" "),v("p",[_._v("这里要分成两种情况来讨论, 使用"),v("strong",[_._v("本地缓存还是使用 Redis 这种缓存")]),_._v(". 可以肯定的是, 如果使用的是本地缓存, 那么 Write Back 也会有不一致的问题, 毕竟数据缓存在多个节点上. 但如果用的是 Redis, 那么在不考虑缓存丢失的情况下, 就可以做到数据一致性了.")]),_._v(" "),v("p",[_._v("这个稍微有点绕, 为了让面试官理解, 要一步步引导.")]),_._v(" "),v("blockquote",[v("p",[_._v("首先, 在使用 Redis 更新数据的时候业务代码"),v("mark",[_._v("只更新缓存, 所以对于业务方来说必然是一致的")]),_._v(". 也就是说, 虽然数据库的数据和缓存的数据不一致, 但是对于业务方来说, 它只能读写到缓存的数据, 对业务方来说, 数据是一致的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/21cf7ae8a34b49aeba7dbea44d9d891e-20231223175002-o0zimc0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这是第一个前提, 也就是写操作不会带来不一致的问题. 紧接着要解释读操作.")]),_._v(" "),v("blockquote",[v("p",[_._v("当业务方读数据的时候, 如果缓存没有数据, 就要去数据库里面加载. 这个时候, 就有可能产生不一致的问题. 比如数据库中 a=3, 读出来之后还没写到缓存里面. 这个时候来了一个写请求, 在缓存中写入了 a = 4. "),v("mark",[_._v("如果这时候读请求回写缓存, 就会用数据库里的老数据覆盖缓存中的新数据")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c92102d20b64a2a1fcfc44de9e79cda2-20231223175002-aw3mcej.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着补充解决方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("解决这个问题的思路也很简单, "),v("mark",[_._v("当读请求回写的时候, 使用 SETNX 命令")]),_._v(". 也就是说, 只有当缓存中没有数据的时候, 才会回写数据. 而如果回写失败了, 那么读请求会再从缓存中读取到数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7268e0e75e5b75cfe1082f4b9aed9cdc-20231223175002-6nwvdfq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后一锤定音, 总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("因此 Write Back 除了有数据丢失的问题, 在缓存一致性的表现上, 比其他模式要好.")])]),_._v(" "),v("p",[_._v("这句话其实有一点强词夺理, 所以要酌情使用. 如果你觉得说 Write Back 解决了一致性问题有点夸张, 可以说 Write Back 极大地"),v("strong",[_._v("缓解了数据不一致的问题")]),_._v(".")]),_._v(" "),v("p",[_._v("激进的观点会让你留下深刻的印象, 但是如果面试官不认同就可能否定你. 保守的观点没有风险, 但是也没有对应的收益.")]),_._v(" "),v("h6",{attrs:{id:"refresh-ahead"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#refresh-ahead"}},[_._v("#")]),_._v(" Refresh Ahead")]),_._v(" "),v("p",[_._v("Refresh Ahead 是指利用 CDC(Capture Data Change)接口异步刷新缓存的模式. 这种模式在实践中也很常见, 比如说"),v("strong",[_._v("利用 Canal 来监听数据库的 binlog, 然后 Canal 刷新 Redis")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b9d1638e9ab6822907ef020d211ce1b-20231223175002-c8e5iqi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种模式也"),v("strong",[_._v("有缓存一致性的问题, 也是出在缓存未命中的读请求和写请求上")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a81a425b4628222a3c8db446734409d3-20231223175002-wn7ddjo.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("实际上, 这个缓存一致性问题是可以解决的, 也就是参考 Write Back 里面的策略.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果读请求在回写缓存的时候, 使用了 SETNX 命令, 那么就没有什么大的不一致问题了. 唯一的不一致就是数据写入到了数据库, 但是还没刷新到缓存的那段时间.")])]),_._v(" "),v("h6",{attrs:{id:"singleflight"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#singleflight"}},[_._v("#")]),_._v(" Singleflight")]),_._v(" "),v("p",[_._v("Singleflight 主要是为了控制住加载数据的并发量.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6b66435e6ef218d636db7825fb620cfb-20231223175002-8nc9se5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("先简单介绍 Singleflight 的原理, 再补充它的优缺点.")]),_._v(" "),v("blockquote",[v("p",[_._v("Singleflight 模式是指当缓存未命中的时候, 访问同一个 key 的线程或者协程中只有一个会去真的加载数据, 其他都在原地等待.")]),_._v(" "),v("p",[_._v("这个模式最大的优点就是可以减轻访问数据库的并发量. 比如如果同一时刻有 100 个线程要访问 key1, 那么最终也只会有 1 个线程去数据库中加载数据. 这个模式的缺点是如果并发量不高, 那么基本没有效果. 所以热点之类的数据就很适合用这个模式.")])]),_._v(" "),v("h6",{attrs:{id:"删除缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#删除缓存"}},[_._v("#")]),_._v(" 删除缓存")]),_._v(" "),v("p",[_._v("这算是在业务中比较常见的用法, 也就是"),v("mark",[v("strong",[_._v("在更新数据的时候先更新数据库, 然后将缓存删除")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fd58f546688edb5daf82c3be0b24e2yy-20231223175002-mow19sb.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("删除缓存本身没有规定必须是业务代码来删除缓存, 所以实际上也可以结合 Write Through 模式, 让缓存去更新数据库, 然后缓存自己删除自己的数据")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/806bde52b8242874ab713e708ce69823-20231223175002-8px5ajt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个模式"),v("strong",[_._v("依旧没有解决数据一致性的问题")]),_._v(", 但是它的一致性问题"),v("strong",[_._v("不是源自两个线程同时更新数据, 而是源自一个线程更新数据, 一个线程缓存未命中回查数据库")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cfa81ee750af2f83e5a4890ebf96f83e-20231223175002-ctlmjx8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在回答的时候要注意答出这一点.")]),_._v(" "),v("blockquote",[v("p",[_._v("删除是最常用的更新缓存的模式, 它是指在更新数据库之后, 直接删除缓存. 这种做法可以是业务代码来控制删除操作, 也可以结合 Write Through 使用. 而且删除缓存之后会使缓存命中率下降, 也算是一个隐患. 如果偶尔出现写频繁的场景, 导致缓存一直被删除, 那么就会使性能显著下降. 缓存未命中回查数据库叠加写操作, 数据库压力会很大.")]),_._v(" "),v("p",[_._v("删除缓存和别的模式一样, "),v("mark",[_._v("也有一致性问题")]),_._v(". 但是它的一致性问题是出在读线程缓存未命中和写线程冲突的情况下.")])]),_._v(" "),v("p",[_._v("然后补充一句总结.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了避免这种缓存不一致的问题, 又有了"),v("mark",[_._v("延迟双删模式")]),_._v(".")])]),_._v(" "),v("h6",{attrs:{id:"延迟双删"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#延迟双删"}},[_._v("#")]),_._v(" 延迟双删")]),_._v(" "),v("p",[_._v("从名字上大概就能知道"),v("mark",[v("strong",[_._v("延迟双删是有两次删除操作")])]),_._v("的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6304cf03bf54b4031fbf56df45c9e32f-20231223175002-mherwm5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("延迟双删类似于删除缓存的做法, 它在第一次删除操作之后设定一个定时器, 在一段时间之后再次执行删除.")])]),_._v(" "),v("p",[_._v("紧接着解释一下第二次删除的动机.")]),_._v(" "),v("blockquote",[v("p",[_._v("第二次删除就是为了"),v("mark",[_._v("避开删除缓存中的读写导致数据不一致的场景")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3a09a23b76a1830e2e4f3065fefc58a7-20231223175002-93xpcxe.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么是不是就不会有数据不一致的问题了? 从理论上来说是可能的. 第一个不一致出现在上图写入 a = 3 到第二次删缓存之间, 还有一种不一致的可能如下图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1425611e8af4fe88a15065505c648848-20231223175002-x8h73fs.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是这种可能性"),v("strong",[_._v("只是存在理论中")]),_._v(", 因为两次删除的时间间隔很长, 不至于出现图片里的这种情况. 所以补充说明一下就可以了.")]),_._v(" "),v("blockquote",[v("p",[_._v("在这种形态之下, 只需要考虑在回写缓存和第二次删除之间, 数据可能不一致的问题.")])]),_._v(" "),v("p",[_._v("紧接着再次说明这种模式的缺点.")]),_._v(" "),v("blockquote",[v("p",[_._v("延迟双删因为存在两次删除, 所以实际上"),v("mark",[_._v("缓存命中率下降的问题更加严重")]),_._v(".")])]),_._v(" "),v("h6",{attrs:{id:"选用什么模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#选用什么模式"}},[_._v("#")]),_._v(" 选用什么模式?")]),_._v(" "),v("p",[_._v("我觉得到这一步你已经非常困惑了, 万一面试官问应该使用哪个模式要怎么回答呢? 坦白说, "),v("strong",[_._v("任何一种缓存模式都有各自的缺陷, 所以你实际上选哪个都有好处, 也都有问题")]),_._v(". 面试的时候就可以根据自己的偏好来选择, 只要分析清楚优劣, 并解释清楚数据一致性问题就可以了.")]),_._v(" "),v("p",[_._v("如果确实需要一个标准答案, 那就回答延迟双删.")]),_._v(" "),v("blockquote",[v("p",[_._v("这么多模式里面, 我比较喜欢延迟双删, 因为它的一致性问题不是很严重. 虽然会降低缓存的命中率, 但是业务并发也没有特别高, 写请求是很少的. 命中率降低一点点是完全可以接受的.")])]),_._v(" "),v("h5",{attrs:{id:"亮点方案-用装饰器模式实现缓存模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-用装饰器模式实现缓存模式"}},[_._v("#")]),_._v(" 亮点方案:用装饰器模式实现缓存模式")]),_._v(" "),v("p",[_._v("这个亮点可以考虑是否要使用, 建议先在实践中落地之后再拿去面试. 但不需要把所有的模式都实现一遍, 实现一下项目中用到的就可以.")]),_._v(" "),v("p",[_._v("前面的缓存模式中, 除了 Refresh Ahead 和 Cache Aside, 其他的模式都可以使用"),v("strong",[_._v("装饰器模式")]),_._v("来实现. 举一个使用缓存模式中 Read Through 模式的例子. 伪代码如下.")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("type")]),_._v(" Cache "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("interface")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Get")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("string")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" any\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Set")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("string")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" val any"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("type")]),_._v(" ReadThroughCache "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("struct")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  c Cache\n  fn "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("func")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("string")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" any\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("func")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("r "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("*")]),_._v("ReadThroughCache"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Get")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key "),v("span",{pre:!0,attrs:{class:"token builtin"}},[_._v("string")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" any "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    val "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v(":=")]),_._v(" r"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("c"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Get")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" val "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("==")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token boolean"}},[_._v("nil")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n      val "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" r"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("fn")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n      r"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),_._v("c"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(".")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("Set")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("key"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" val"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("return")]),_._v(" val\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br"),v("span",{staticClass:"line-number"},[_._v("12")]),v("br"),v("span",{staticClass:"line-number"},[_._v("13")]),v("br"),v("span",{staticClass:"line-number"},[_._v("14")]),v("br"),v("span",{staticClass:"line-number"},[_._v("15")]),v("br"),v("span",{staticClass:"line-number"},[_._v("16")]),v("br"),v("span",{staticClass:"line-number"},[_._v("17")]),v("br"),v("span",{staticClass:"line-number"},[_._v("18")]),v("br")])]),v("p",[_._v("抓住关键词装饰器模式来描述这个解决方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在我们公司利用装饰器模式, 无侵入式地实现了其中的大部分模式. 以 Read Through 为例, 装饰器模式只需要在已有的缓存实现的基础上, 为 Get 方法添加一个缓存中没有找到就去加载数据的额外逻辑就可以.")])]),_._v(" "),v("p",[_._v("而且, 如果平时在公司的项目经历比较平淡, 那么完全可以在公司内部"),v("strong",[_._v("定义一个统一的 Cache 接口, 提供基于 Redis 和本地内存的实现, 同时提供这些缓存模式的实现")]),_._v(", 那么也算是一个比较有特色的项目了.")]),_._v(" "),v("p",[_._v("就可以这样介绍你的项目.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在公司里面因为经常用到缓存, 也经常使用缓存模式, 所以我抽象了一个缓存接口, 提供了基于 Redis 和本地内存的实现. 在这个基础上, 我还用装饰器模式实现了大部分缓存模式. 对于开发者来说, 他们只要会初始化装饰器就可以应用这个缓存模式.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-31"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-31"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节学习了缓存模式, 包括 Cache Aside, Read Through, Write Through, Write Back, Refresh Ahead 和 Singleflight 几种. 此外还有删除缓存和延迟双删, 这两个虽然不叫缓存模式, 但是面试中可以提一提.")]),_._v(" "),v("p",[_._v("缓存模式数量众多, 但"),v("strong",[_._v("都需要记住")]),_._v(", 尤其是每一种缓存模式下, 什么情况下会出现数据不一致的问题. 此外, 建议实践一下这些缓存模式, 比如可以用装饰器模式来实现它们.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/13622c46d28b80d8d8c7722633e0a49e-20231223175002-10l1ib1.png",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_34-缓存一致性问题-高并发服务如何保证缓存一致性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_34-缓存一致性问题-高并发服务如何保证缓存一致性"}},[_._v("#")]),_._v(" 34-缓存一致性问题:高并发服务如何保证缓存一致性?")]),_._v(" "),v("p",[_._v("今天来聊一个面试缓存必然会涉及的一个问题: "),v("strong",[_._v("怎么保证数据一致性")]),_._v("?")]),_._v(" "),v("p",[_._v("上一节详细分析了各个缓存模式, 会发现这些缓存模式要么存在数据丢失的可能, 要么在某一段时间内总是会不一致. 那么"),v("strong",[_._v("有没有能够彻底解决缓存一致性的方案呢")]),_._v("?")]),_._v(" "),v("p",[_._v("这节就分析各种可行的解决方案, 并且告诉你这些方案在保障数据一致性上, 究竟能够做到什么地步. 为了方便理解后面的内容, 先来看 double-check 模式.")]),_._v(" "),v("h5",{attrs:{id:"double-check模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#double-check模式"}},[_._v("#")]),_._v(" double-check模式")]),_._v(" "),v("p",[_._v("double-check 是并发里为了兼顾并发安全和性能经常采用的一种代码模式. 它的基本思路可以总结为"),v("strong",[_._v("检查, 加锁, 检查")]),_._v(", 所以也叫做 double-check. double-check 经常用在使用读写锁的场景. 这里用伪代码来描述它的基本思路.")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("func")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("doubleCheck")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("rlock")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 加读锁")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("!")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("checkSomething")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 执行一些动作")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("return")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("runlock")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 释放读锁")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("lock")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("!")]),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("checkSomething")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 执行一些动作")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("return")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 执行另外一些动作")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("lock")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br"),v("span",{staticClass:"line-number"},[_._v("10")]),v("br"),v("span",{staticClass:"line-number"},[_._v("11")]),v("br"),v("span",{staticClass:"line-number"},[_._v("12")]),v("br"),v("span",{staticClass:"line-number"},[_._v("13")]),v("br"),v("span",{staticClass:"line-number"},[_._v("14")]),v("br"),v("span",{staticClass:"line-number"},[_._v("15")]),v("br")])]),v("p",[_._v("比如, "),v("strong",[_._v("先加读锁检测数据是否存在, 如果存在就直接返回, 否则就释放读锁, 加写锁, 再次检查数据是否存在, 存在就直接返回, 不存在就根据业务计算数据并返回")]),_._v(".")]),_._v(" "),v("p",[_._v("double-check 还有一些变种. 第一个变种是在第一次检查的时候, 什么锁都不加, 这个变种一般用在分布式锁下, 因为分布式锁没有读锁. 另外一个变种是用原子操作来取代读锁, 但是前提是用原子操作就可以完成检查.")]),_._v(" "),v("p",[_._v("一般来说, 可以把 double-check 作为自己优化并发代码的一个措施, 纳入到整个性能优化方案里面.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-34"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-34"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("这里先来问几个问题.")]),_._v(" "),v("ul",[v("li",[_._v("每一个你"),v("strong",[_._v("使用了缓存的地方, 你是如何解决一致性问题的")]),_._v("?")]),_._v(" "),v("li",[_._v("如果没有解决, 你能容忍多久不一致?")]),_._v(" "),v("li",[_._v("当数据不一致的时候, 多久能发现, 多久能修复, 有没有自动发现和修复机制?")])]),_._v(" "),v("p",[_._v("当在简历或者项目里面有任何一个地方提到了缓存, 面试官都有可能询问数据一致性相关的内容. 实际上很多时候面试官也知道"),v("strong",[_._v("越追求严格的数据一致性, 代价也就越大")]),_._v(". 所以在回答数据一致性的问题的时候, 要强调的是知道数据一致性的问题, 而且你不仅知道, 还知道能有多不一致, 能在多长时间内达成一致.")]),_._v(" "),v("p",[_._v("并且数据一致性是一个"),v("strong",[_._v("非常考验分析并发场景")]),_._v("的地方, 因此在面试之前, 可以试着自己分析一下你使用的缓存方案里面有哪些场景会引起数据不一致.")]),_._v(" "),v("h5",{attrs:{id:"基本思路-24"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-24"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("h6",{attrs:{id:"不一致的根源"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#不一致的根源"}},[_._v("#")]),_._v(" 不一致的根源")]),_._v(" "),v("p",[_._v("在讲到任何数据不一致的时候, 都可以先揭示两个不一致的来源.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("源自操作部分失败")])]),_._v(" "),v("li",[v("strong",[_._v("源自并发操作")])])]),_._v(" "),v("p",[_._v("你能讨论到这两个来源, 就算是一个亮点, 因为很少有人能仔细分析这些问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("要想彻底解决数据一致性问题, 就首先要搞清楚数据不一致的两个来源. 第一个是操作部分失败, 第二个是并发更新.")])]),_._v(" "),v("blockquote",[v("p",[_._v("不一致的根源1：源自操作部分失败")])]),_._v(" "),v("p",[_._v("这个是最难解决的. 也就是"),v("strong",[_._v("在分布式环境下, 很难保证多个操作要么都成功, 要么都失败")]),_._v(". 而在更新数据的时候, 即便是最简单的模型, 也是要求更新数据库和更新缓存要么都成功, 要么都失败.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7d7e7c7777c1207c9d4d1yye46236f03-20231223175002-c3d92mw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("显然, 这是一个"),v("strong",[_._v("分布式事务问题")]),_._v(". 那么通过前面的学习, 应该知道已有的分布式事务里面, "),v("strong",[_._v("追求的都是最终一致性")]),_._v(". 即便你认为 XA 事务能够解决一致性问题, 但是缓存基本上没有支持 XA 事务的.")]),_._v(" "),v("p",[_._v("好在缓存有点特殊. 所以在这节的后面给出了一个结合本地事务和分布式锁的无限接近强一致性的方案. 所以这里的结论就是, "),v("mark",[v("strong",[_._v("源自部分失败造成的数据不一致是不可避免的")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("举一个例子来说明操作部分失败, 在最简单的模型里面, 就是更新数据库和更新缓存两个步骤. 理论上来说"),v("mark",[_._v("要保证数据一致性, 就必须要保证这两个更新要么都成功, 要么都失败, 不能有中间状态")]),_._v(". 也就是说, "),v("mark",[_._v("这是一个分布式事务问题. 而现在缓存中间件包括 Redis, 都不支持分布式事务. 因此这个问题就决定了数据不一致是不可避免的")]),_._v(".")])]),_._v(" "),v("p",[_._v("可以进一步总结拔高.")]),_._v(" "),v("blockquote",[v("p",[_._v("在能够彻底解决操作部分失败的问题之前, 都只能说尽可能避免不一致, 并且尽快达成一致, 这也就包括"),v("mark",[_._v("重试失败操作, 数据自动校验并修复")]),_._v("等措施.")])]),_._v(" "),v("blockquote",[v("p",[_._v("不一致的根源2：源自并发操作")])]),_._v(" "),v("p",[_._v("上一节分析各种缓存模式遇到的数据不一致的问题, 都是从这个角度出发的. "),v("strong",[_._v("源自并发操作的数据不一致, 在某种程度上来说是可以解决的")]),_._v(". 比如说在缓存模式中提到的 Write Back 模式.")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("解决这一类的数据不一致, 核心是确保同一个时刻只有一个线程在更新数据库和缓存")])]),_._v(". 在分布式环境下, 这也就意味着即便有几百个实例, 依旧只能有一个实例上的一个线程在更新数据.")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一个导致数据不一致的原因是并发操作, 比如说多个线程同时更新数据库和缓存, 在这种情况下有可能先更新数据库的线程后更新缓存, 导致数据不一致.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/695e31fdc36d9c9c1358a96a8b8f925b-20231223175002-rlwf44r.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后可以解释这个是可以解决的.")]),_._v(" "),v("blockquote",[v("p",[_._v("并发操作的数据不一致问题, 是可以解决的. 比如说在缓存模式里面, Write Back 就可以, 虽然它会丢数据. 又或者使用分布式锁, 也可以控制并发更新.")])]),_._v(" "),v("p",[_._v("在这个回答里面, 提到了"),v("strong",[_._v("缓存模式")]),_._v(", 自然就可以把话题引到上一节的内容上, 记得跟面试官深入剖析每一个缓存模式可能存在的数据不一致的场景.")]),_._v(" "),v("p",[_._v("在这个回答里面还提出了一个解决方案: "),v("strong",[_._v("分布式锁")]),_._v(", 那么自然也会把话题引导到分布式锁上.")]),_._v(" "),v("h6",{attrs:{id:"解决方案-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决方案-3"}},[_._v("#")]),_._v(" 解决方案")]),_._v(" "),v("p",[_._v("针对上面两个根源的分析, 我想你已经看出来了, 要想解决部分失败的问题, 只能"),v("strong",[_._v("考虑分布式事务")]),_._v(", 而且如果追求的是强一致性, 那么就需要用强一致性的分布式事务. 显然, 之前就学过, 排除 XA 这个存在争议的方案, "),v("strong",[_._v("目前并没有解决方案")]),_._v(".")]),_._v(" "),v("p",[_._v("所以"),v("mark",[v("strong",[_._v("只能考虑解决并发操作带来的不一致问题")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("要想"),v("mark",[_._v("解决并发操作带来的问题, 可以使用缓存模式, 分布式锁, 消息队列或者版本号")]),_._v(".")])]),_._v(" "),v("p",[_._v("分布式锁中有很多细节可以作为亮点方案, 所以最后再聊, 这里先来看消息队列和版本号的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("解决方案1：消息队列")])]),_._v(" "),v("p",[_._v("既然使用分布式锁是为了保证同一时刻只有一个线程在更新数据, 那么为什么不"),v("strong",[_._v("让更新请求都跑到消息队列上排个队")]),_._v("呢?")]),_._v(" "),v("p",[_._v("思路也很简单, 就是结合之前在有序消息里面讲到的方案, 让针对同一个业务的更新请求保持有序. "),v("strong",[_._v("消费者挨个将消息取出来, 然后更新数据库和缓存")]),_._v(". 这种做法一样能够保证在同一时刻对同一个数据只有一个线程在更新.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7efc4b73ac1f53fe9f417d6bfd3d4f3f-20231223175002-83w32fp.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("针对一些可以异步更新数据的场景, 可以考虑将更新请求都发送到消息队列上. 但是要注意的是, 同一个业务的消息必须是有序的, 不然更新数据会出错. 消费者在取出消息之后, 执行更新. 而且消费者在更新失败之后, 可以多次重试, 对业务也没有什么影响. 这个方案也是追求"),v("mark",[_._v("最终一致性")]),_._v("的, 强一致性还是用不了.")])]),_._v(" "),v("p",[_._v("这里有一个变种, "),v("strong",[_._v("就是先更新数据库, 再发送消息到消息队列, 让消费者去更新缓存")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/08256646fff5ca822f214e03b1955fd2-20231223175002-p67lel7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但是如果消费者依赖消息中的数据来更新缓存, 那么就会有并发问题, 因为先更新数据库的不一定先发消息.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e6e03bf4c3e6e6b95ac98048227715ca-20231223175002-l4pcb66.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以最多就是把消息当成一个触发器, 收到消息就去更新缓存, 但是是查询数据库中的数据来执行更新. 但是我个人认为, 既然要先更新数据库, 为什么不用缓存模式中的 Refresh Ahead, 引入 Canal 之类的来更新缓存呢, 这样效果更好.")]),_._v(" "),v("blockquote",[v("p",[_._v("解决方案2：版本号")])]),_._v(" "),v("p",[v("strong",[_._v("版本号也能解决并发更新的问题")]),_._v(". 它的基本思路就是"),v("strong",[_._v("每一次更新版本号都要加一, 然后低版本数据不能覆盖高版本的数据")]),_._v(".")]),_._v(" "),v("p",[_._v("在这种思路之下, 前面在缓存模式里面出现过的很多数据不一致的场景, 都能得到解决. 比如在 Cache Aside 里面, 加上版本号之后, 就不会出现不一致的问题了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d04a05caff1a016014e0c35c84e5b12e-20231223175002-y28g5vw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一个思路是使用版本号来控制并发更新, 每个数据都有一个对应的版本号, 在更新的时候版本号都要加一. 每一次在更新的时候都要比较版本号, 版本号低的数据不能覆盖版本号高的数据.")])]),_._v(" "),v("p",[_._v("那么这个方案有没有缺点呢? 有, 版本号本身是一个比较难维护的东西.")]),_._v(" "),v("blockquote",[v("p",[_._v("这个方案的缺点是需要维护版本号, 最好是在数据库里面增加一个版本字段. 那么后面在更新缓存的时候, 比如说更新 Redis, 就得使用 lua 脚本, 先检测缓存的版本号, 再执行更新了. 不过也可以考虑用更新时间来替代版本号, 一样可以.")])]),_._v(" "),v("p",[_._v("事实上, 在正常的面试中, 你能分析清楚数据不一致的两个根源, 然后回答出消息队列和版本号两个方案, 已经算是答得比较好的了. 不过有一个问题, 还是要进一步介绍一下, 防止在面试的时候被问住, 那就是"),v("strong",[_._v("在多级缓存里面怎么更新的问题")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"多级缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#多级缓存"}},[_._v("#")]),_._v(" 多级缓存")]),_._v(" "),v("p",[_._v("多级缓存是指在业务中使用了"),v("strong",[_._v("多个缓存, 比如说本地缓存 + Redis + 数据库的架构")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/68c5e318a4fe14cf9e3161ed772bace5-20231223175002-jcctq8z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这种架构下, 更新数据的时候, 需要考虑更新本地缓存, Redis 和数据库的顺序.")]),_._v(" "),v("p",[_._v("首先可以明确的一点是, "),v("mark",[v("strong",[_._v("数据库是最准确的数据源, 所以肯定是优先更新数据库的")])]),_._v(". 剩下的无非就是先更新本地缓存还是先更新 Redis 的事情了.")]),_._v(" "),v("p",[_._v("坦白说, 如果"),v("strong",[_._v("只是考虑数据一致性的问题, 随便更新哪个都会不一致")]),_._v(". 硬要矮个子里面挑高个的, 我认为更新本地缓存应该先于 Redis.")]),_._v(" "),v("blockquote",[v("p",[_._v("在使用本地缓存和 Redis 缓存的时候, 我的更新顺序是, 先更新数据库, 再更新本地缓存, 最后更新 Redis. 先更新数据库是因为数据库应该是最准确的数据源.")]),_._v(" "),v("p",[_._v("其次更新本地缓存, 理由有三个: 一是更新本地缓存几乎不会失败; 二是查询的时候是先查询本地缓存的, 先更新本地缓存可以确保用户能够拿到最新的数据; 三是即便后续 Redis 更新失败, 因为本地缓存中数据是存在的, 所以也不会查询到 Redis 中不一致的数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/39bafa4dcf17f387a33d431ee26d772c-20231223175002-wl9k7es.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从上面这个图也可以看出来, "),v("strong",[_._v("引入了本地缓存和 Redis 缓存之后, 数据不一致性的概率就更加大了")]),_._v(", 可以按照前面几节分析各种不一致场景的思路去分析, 就不重复了.")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-15"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("h6",{attrs:{id:"一致性哈希和缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一致性哈希和缓存"}},[_._v("#")]),_._v(" 一致性哈希和缓存")]),_._v(" "),v("p",[_._v("这个亮点方案在微服务部分已经见过了, 这一次是进一步深入讨论. 先回顾一下一致性哈希负载均衡算法和本地缓存的方案.")]),_._v(" "),v("p",[_._v("这个方案主要解决的是"),v("strong",[_._v("并发更新")]),_._v("的问题, 因为它通过哈希负载均衡算法做到某一个 key 只有一个服务端节点在处理. 因此将本地缓存换成 Redis 也一样可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0c20410c8404feff2526a51e1f01f269-20231223175002-i5rfq4f.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在面试缓存一致性的时候也不要忘记提起这个方案. 但是没有细说一个点, 就是怎么更新数据? 因为即便是同一个 key 的请求都落在同一个节点上, 依旧存在并发更新的问题. 这个时候就需要使用到缓存模式中的 singleflight 模式了. 在介绍完基本方案之后, 要注意提一下这个.")]),_._v(" "),v("blockquote",[v("p",[_._v("在使用了这种负载均衡算法之后, 更新缓存的时候要使用 singleflight 模式, 那么就可以做到同一个 key 一定落在同一个节点上, 并且这个节点上最多只有一个线程在更新数据. 如果有多个更新请求, 那么它们会轮流更新数据库和缓存.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8d9bebc62006bd1a76ebce701a172e44-20231223175002-8mk1nef.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("此外, 当时也提到一个问题, 在节点上线或者下线的时候, 就会引起不一致的问题, 那么怎么解决呢?")]),_._v(" "),v("p",[_._v("先来看节点下线. 节点下线其实是最好处理的, 因为下线之后, 新的请求都会被打到另外一个节点上, 也就是只有一个节点在处理某个 key 的请求. 但是如果节点上线, 也就是扩容的话, 就会引起不一致的问题.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9000a7f4db4d9b8a7664059e994de7f5-20231223175002-gj8pd0z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("解决的思路其实也很简单, 既然问题出在新节点加入之后的短时间内, 有两个节点在处理写请求, 那么停掉一个就可以了. 所以在介绍完基本想法以及可能存在数据不一致的问题之后, 补充这个说明.")]),_._v(" "),v("blockquote",[v("p",[_._v("解决这种数据不一致的思路也很简单, 就是在新节点上线的一小段时间内, 不要读写缓存, 等待老节点上的请求自然返回. 可以预想一下, 如果你们公司的响应时间是要求在 1s 以内, 那么新节点上来的头 2s, 就可以不用读写缓存. 虽然这两秒的请求响应时间会很差, 但是也能避开数据不一致的问题.")])]),_._v(" "),v("p",[_._v("这个方案的好处就是结合了负载均衡, 数据一致性, 并发场景分析, 包括解决方案都很出其不意, 非常适合面试的时候展示.")]),_._v(" "),v("p",[_._v("除了这些以外, 还有一个分布式锁的亮点方案, 也可以进一步聊一聊.")]),_._v(" "),v("h6",{attrs:{id:"分布式锁方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分布式锁方案"}},[_._v("#")]),_._v(" 分布式锁方案")]),_._v(" "),v("p",[_._v("分布式锁方案很多人用, 但是很少有人解释清楚里面的弯弯绕绕. 这里先解释安全, 性能不错, 但是一致性比较差的思路, 再介绍无限接近强一致性, 但是隐患比较多的思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("思路一:先本地事务,后分布式锁")])]),_._v(" "),v("p",[_._v("这个思路是"),v("strong",[_._v("先执行本地事务, 然后加分布式锁, 删除缓存, 释放分布式锁")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/03d7d9e4a877e28408d3eddc16c984de-20231223175002-8iybe8e.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("显然, 如果单纯这样做, 肯定会有不一致的问题, 可以看一下示意图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2c5dyy2a8c7ef21cfe4243ebd2846164-20231223175002-mkqgjbl.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了避免这个并发更新的问题, 需要"),v("strong",[_._v("在缓存未命中回查数据库的时候, 加上分布式锁")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/022b7062d35d2d19ee90968fb76d3336-20231223175002-y98wd2w.png",alt:""}}),_._v("​")]),_._v(" "),v("p",[_._v("所以抓住先本地事务, 后分布式锁的顺序来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("我之前用过分布式锁来尝试解决并发更新的问题, 基本思路是先执行本地事务, 在事务提交之后加分布式锁, 然后删除缓存. 而在读请求来了的时候, 先读缓存. 如果缓存未命中, 再加分布式锁, 然后从数据中加载数据回写缓存, 再释放分布式锁.")])]),_._v(" "),v("p",[_._v("注意这里的关键点是读请求第一次读缓存的时候, 没有加分布式锁, 这是保证高性能的关键. 这里还有一个优化思路是应用 double-check 机制.")]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 这里也可以进一步优化, 在读请求缓存未命中加上了分布式锁之后, 再次读一下缓存, 看看有没有别的线程已经加载好了数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/10c60f39cd700af1a1787ab42058bd3a-20231223175002-nm1gcdw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("显然, 这个只解决了并发更新的问题. 你可能想到了, 既然有一个本地事务, 那能不能在本地事务还没提交的时候, 就把缓存删除? 这也就是第二个思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("思路二:先删除缓存,再提交事务")])]),_._v(" "),v("p",[_._v("这一个思路的核心是"),v("strong",[_._v("把删除缓存的操作放在数据库事务里")]),_._v(", 可以看一下基本思路图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/73371860fc7353d155f1bc919639a6a7-20231223175002-9lwoyax.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在面试的时候先简要介绍思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("另外一个思路是尝试在数据库提交事务之前就删除缓存. 它的思路是先开启本地事务, 执行事务操作. 然后获取分布式锁, 删除缓存. 紧接着提交事务, 释放分布式锁. 当然, 在缓存未命中回查的时候, 还是要先加分布式锁, 避免并发更新的问题.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/0047d61a5743cb9f85e18d9669e6ce55-20231223175002-i1y1bwb.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("回答到这里, 如果面试官反应灵敏, 他就可能会追问删除缓存和提交事务两个动作的失败问题, 那就回答这两种情况.")]),_._v(" "),v("blockquote",[v("p",[_._v("有两种主要失败场景. 一是删除失败了, 那么事务不会提交, 数据是一致的. 二是删除成功了, 事务提交失败了, 数据依旧是一致的, 也就是多删了一次缓存而已.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/547d665101d9199yy54befeb9b8c9233-20231223175002-yispsuc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么这个做法是不是强一致性的呢? 答案是"),v("strong",[_._v("无限接近强一致性")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种解决思路已经非常非常接近强一致性了. 不过这里有两个条件, 如果满足了就可以认为是达成了强一致性的效果.")]),_._v(" "),v("p",[_._v("第一, 分布式锁本身必须是可靠的, 也就是一个线程拿了分布式锁, 其他线程绝对不可能拿到同一个分布式锁.")]),_._v(" "),v("p",[_._v("第二, 在删除缓存超时的时候会继续重试直到确认删除成功.")])]),_._v(" "),v("p",[_._v("那么这个方案有没有缺点呢? 有, 而且很大.")]),_._v(" "),v("blockquote",[v("p",[_._v("这一个方案最大的缺点就是本地事务比较容易超时. 比如分布式锁被人抢占了, 那么在等待分布式锁的时候, 就可能超时. 当然, 如果本身网络不稳定导致一直无法删除缓存, 也会引起本地事务超时.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8c961c73fbc8e18fc3efbf85c6d84296-20231223175002-petzzbu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("超时问题其实有方案来缓解.")]),_._v(" "),v("blockquote",[v("p",[_._v("可以考虑先加分布式锁, 再开启本地事务, 然后删除缓存, 提交事务, 最后释放分布式锁. 代价就是分布式锁的持有时间变长了. 并且删除缓存本身依旧在本地事务里面, 还是可能导致本地事务超时.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d5a2d1a03916079e2ebb86baf4382aa6-20231223175002-6rem1wd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("整个方案里面, 几乎都是在围绕分布式锁来做文章, 所以面试话题十有八九会被引导到分布式锁上, 课程后面会有详细分析, 要结合在一起学习.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-32"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-32"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节介绍了 double-check, 然后在面试思路里面分析了"),v("strong",[_._v("引起不一致的两个根源: 操作部分失败和并发操作")]),_._v(". 总的来说, 并发操作容易解决, 比如使用缓存模式就很容易解决并发更新的问题, 除此之外使用消息队列或者版本号也同样可以解决问题.")]),_._v(" "),v("p",[_._v("然后进一步讨论了负载均衡那一节课里引入的一致性哈希负载均衡算法和缓存结合使用的方案, 重点讨论了使用分布式锁来解决一致性问题的两个思路. 第一个思路比较中规中矩, 先提交本地事务, 再加分布式删除缓存. 第二个思路能达成一种无限接近强一致性的效果, 核心是先删除缓存, 再提交事务, 但是它严重依赖分布式锁的可靠性.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3e1db94cbba9828byya3bba4287e86e4-20231223175002-okrlnfe.png",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_35-缓存问题-怎么解决缓存穿透-击穿和雪崩问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_35-缓存问题-怎么解决缓存穿透-击穿和雪崩问题"}},[_._v("#")]),_._v(" 35-缓存问题:怎么解决缓存穿透,击穿和雪崩问题?")]),_._v(" "),v("p",[_._v("今天再来聊一个缓存中的热门面试话题: "),v("strong",[_._v("怎么解决缓存穿透, 击穿和雪崩问题")]),_._v(".")]),_._v(" "),v("p",[_._v("这个问题之所以常见, 是因为在使用缓存的过程中一不小心就会遇到它们. 比如如果"),v("strong",[_._v("缓存崩溃")]),_._v(", 那么大量请求就会落到数据库上, 直接把数据库压垮. 然而很多新手在刚接触缓存的时候完全意识不到这个问题, 只有在出了线上故障之后才会考虑缓存崩溃的事情. 因此, 面试官就倾向于在面试的时候确认你是否会解决这一类的问题.")]),_._v(" "),v("p",[_._v("这一节会综合分析这三种情况, 以及其他可能出现的缓存问题. 不得不说的是, 缓存穿透, 击穿和雪崩是三个很容易搞混的概念, 尤其是缓存穿透和击穿.")]),_._v(" "),v("h5",{attrs:{id:"缓存穿透"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存穿透"}},[_._v("#")]),_._v(" 缓存穿透")]),_._v(" "),v("p",[v("mark",[v("strong",[_._v("缓存穿透是指数据既不在缓存中, 也不在数据库中")])]),_._v(".")]),_._v(" "),v("p",[_._v("最常见的场景就是有"),v("strong",[_._v("攻击者伪造了大量的请求")]),_._v(", 请求某个不存在的数据. 这会造成两个后果.")]),_._v(" "),v("ul",[v("li",[_._v("缓存里面没有对应的数据, 所以查询会落到数据库上.")]),_._v(" "),v("li",[_._v("数据库也没有数据, 所以没有办法回写缓存, 下一次请求同样的数据, 请求还是会落到数据库上.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b5d8c1a8a95c32dc5eabb8d8b7207196-20231223175002-ouz5sl0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果没有在服务层面上采用熔断, 限流之类的措施, 那么数据库就可能崩溃.")]),_._v(" "),v("h5",{attrs:{id:"缓存击穿"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存击穿"}},[_._v("#")]),_._v(" 缓存击穿")]),_._v(" "),v("p",[v("strong",[_._v("缓存击穿是指")]),_._v("​"),v("mark",[v("strong",[_._v("数据不在缓存中")])]),_._v("​ "),v("strong",[_._v(", 导致请求落到了数据库上")]),_._v(". 注意数据这个时候"),v("strong",[_._v("在数据库中是存在")]),_._v("的, 所以可以预计, 查询到数据库中的数据之后就会回写缓存.")]),_._v(" "),v("p",[_._v("这看起来并没有问题. 但如果"),v("strong",[_._v("请求的是热点数据")]),_._v("呢? 比如同一时刻有几百个人请求某个大博主的数据, 这些请求都没有命中缓存, 那么几百个查询请求都会落到数据库上.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/482554f7864698f1c1f5c6a7196dac68-20231223175002-lxroo5h.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此, 如果请求的数据并不是什么热点数据, 那么击穿也没有什么问题, 它就是普通的缓存未命中而已.")]),_._v(" "),v("h5",{attrs:{id:"缓存雪崩"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存雪崩"}},[_._v("#")]),_._v(" 缓存雪崩")]),_._v(" "),v("p",[v("strong",[_._v("缓存雪崩是指缓存里大量数据在同一时刻过期, 导致请求都落到了数据库上")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ef84c080bf293823dba7548743c1c58e-20231223175002-m68w10m.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("缓存雪崩基本上都是"),v("strong",[_._v("因为一次性加载了很多数据到缓存中, 并且都设置为同一个过期时间")]),_._v(". 比如在应用启动的时候, 提前从数据库里查询数据, 然后放到缓存里面, 这样这一批数据就会在同一时刻过期. 又比如榜单数据计算好了之后加载到缓存里, 都是同一个过期时间, 导致这一批榜单数据同一时间过期.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-35"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-35"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前需要在公司里面收集一些信息.")]),_._v(" "),v("p",[_._v("比如:")]),_._v(" "),v("ul",[v("li",[_._v("你用的 "),v("strong",[_._v("Redis 是如何部署的? 用的是 Redis Cluster 还是 Redis Sentinel")]),_._v("?")]),_._v(" "),v("li",[_._v("你们公司"),v("strong",[_._v("有没有出现过 Redis 崩溃的问题")]),_._v("? 如果有, 是什么原因引发的?")]),_._v(" "),v("li",[_._v("公司"),v("strong",[_._v("有没有出现过 Redis 连不上的问题")]),_._v("? 如果有, 后面有没有使用什么方案来容错?")]),_._v(" "),v("li",[_._v("你有"),v("strong",[_._v("没有遇到过缓存穿透, 击穿或者雪崩等问题")]),_._v("? 如果有, 你当时是怎么解决的, 有没有可以改进的点?")]),_._v(" "),v("li",[_._v("公司有没有保护数据库的措施? 比如说防止缓存失效, 导致数据库不堪重负直接崩溃.")])]),_._v(" "),v("p",[_._v("可以在简历中或者自我介绍的时候强调自己解决过很多缓存问题, 包括缓存穿透, 击穿, 雪崩等问题. 面试官多半会对这些点感兴趣, 那就可以趁机把前面准备的各种案例说出来. 同时也可以考虑把各种缓存问题融合到自己的高可用方案里面, 作为其中的一个环节.")]),_._v(" "),v("h5",{attrs:{id:"解决缓存穿透"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决缓存穿透"}},[_._v("#")]),_._v(" 解决缓存穿透")]),_._v(" "),v("p",[_._v("缓存穿透是因为数据本身不存在而引起的, 所以就要想办法"),v("strong",[_._v("在确认数据不存在之后, 避免下一次查询再次落到数据库上")]),_._v(". 这有两种解决思路.")]),_._v(" "),v("h6",{attrs:{id:"回写特殊值"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#回写特殊值"}},[_._v("#")]),_._v(" 回写特殊值")]),_._v(" "),v("p",[v("strong",[_._v("第一种思路是在缓存未命中, 而且数据库里也没有的情况下, 往缓存里写入一个特殊的值")]),_._v(". 这个值就是标记数据不存在, 那么下一次查询请求过来的时候, 看到这个特殊值, 就知道没有必要再去数据库里查询了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c569532ec6a39f9af6d8fff5321346bd-20231223175002-10fg1v3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以直接介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("第一种思路是回写特殊值. 也就是在第一次查询发现数据库里都没有数据的时候, 直接写入一个特殊值. 那么下一次查询过来的时候, 看到缓存里的特殊值, 就知道没有数据, 这时候直接返回就可以了. 在这种设计之下, 数据库只需要支撑住第一次请求就可以.")])]),_._v(" "),v("p",[_._v("但是这个方案也是有缺点的.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果攻击者每次都用不同的且都不存在的 key 来请求数据, 那么这种措施毫无效果. 并且, 因为要回写特殊值, 那么"),v("mark",[_._v("这些不存在的 key 都会有特殊值, 浪费了 Redis 的内存")]),_._v(". 这可能会进一步引起另外一个问题, 就是 Redis 在内存不足, 执行淘汰的时候, 把其他有用的数据淘汰掉.")]),_._v(" "),v("p",[_._v("这时候就可以引出下一个点了, 考虑使用布隆过滤器.")])]),_._v(" "),v("h6",{attrs:{id:"布隆过滤器-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#布隆过滤器-2"}},[_._v("#")]),_._v(" 布隆过滤器")]),_._v(" "),v("p",[_._v("既然缓存穿透是因为数据不存在, 那么"),v("strong",[_._v("提前用布隆过滤器判断一下")]),_._v("不就可以了嘛?")]),_._v(" "),v("p",[_._v("正常请求一个 key 的流程如下:")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/92f79dce0dd0ac567f72d39df9235338-20231223175002-t23c3zj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("如果请求一个 key 不存在, 那么布隆过滤器会直接说数据不存在, 那么就没必要继续往下查询了")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2c10663b7b825ef5d3dd0694405d4da9-20231223175002-bq443an.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("先简要介绍这个流程.")]),_._v(" "),v("blockquote",[v("p",[_._v("使用布隆过滤器的流程是业务代码收到请求之后, 要先问一下布隆过滤器有没有这个 key. 如果说没有, 那就不用继续往后执行了. "),v("mark",[_._v("如果布隆过滤器说有, 那么就继续往后执行, 去查询缓存和数据库, 并且在查询到了数据的时候, 回写到缓存里面")]),_._v(".")])]),_._v(" "),v("p",[_._v("然后要记得介绍假阳性的问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("但是布隆过滤器本身存在假阳性的问题, 所以当攻击者请求一个不存在的 key 的时候, 布隆过滤器可能会返回数据存在的假阳性响应. 在这种情况下, 业务代码依旧会去查询缓存和数据库. 不过这个不需要担心, 因为假阳性的概率是很低的. 假如说假阳性概率是万分之一, 那么就算攻击的并发有百万, 也只有 100 个查询请求会落到数据库上, 这一点查询请求就是毛毛雨了.")])]),_._v(" "),v("p",[_._v("这时候, 可以补充一个变种, 也就是"),v("strong",[_._v("先查询缓存, 缓存中没有数据的时候, 再去问布隆过滤器")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("也可以考虑先查询缓存, 当缓存没有数据的时候, 再去查询布隆过滤器. 如果布隆过滤器说有数据, 再去查询数据库.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/47172ae3e995de7a641737f7c39c321d-20231223175002-lwaefti.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后对比两者.")]),_._v(" "),v("blockquote",[v("p",[_._v("这两种模式没有太大的差别. 先查询布隆过滤器, 保护效果会更好, 也就是提前挡住了非法请求. 而先查询缓存, 对正常请求更加友好, 因为正常请求大概率命中缓存, 直接返回数据, 也就不用查询布隆过滤器了.")])]),_._v(" "),v("p",[_._v("不过如果布隆过滤器也是在 Redis 的基础上实现的, 两者就基本上没什么区别了.")]),_._v(" "),v("h5",{attrs:{id:"解决缓存击穿"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决缓存击穿"}},[_._v("#")]),_._v(" 解决缓存击穿")]),_._v(" "),v("p",[_._v("解决缓存击穿是很容易的, 只需要用到在缓存模式里面提到的 singleflight 模式. 也就是说, 就算是一个热点数据, 当几百个请求缓存未命中的时候, "),v("strong",[_._v("在 singleflight 模式之下, 也只有一个请求会真的去查询数据, 剩下的都在等着这个请求查询回来的结果")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c86c8d10c44a0090fbc21769ff52eff2-20231223175002-33moeqt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"解决缓存雪崩"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#解决缓存雪崩"}},[_._v("#")]),_._v(" 解决缓存雪崩")]),_._v(" "),v("p",[_._v("缓存雪崩也很容易解决. 前面提到过之所以有雪崩, 就是因为一次性加载了一大批数据放到了缓存里面, 并且设置了同样的过期时间.")]),_._v(" "),v("p",[_._v("那么解决思路自然就有两个, 一个是不允许一次性加载一大批数据到缓存, 而这显然不现实, 因为批量加载属于业务要求; 另外一个思路就是"),v("strong",[_._v("设置不同的过期时间")]),_._v(".")]),_._v(" "),v("p",[_._v("最简单的思路, 就是"),v("strong",[_._v("在过期时间的基础上加一个随机偏移量")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("要解决缓存雪崩, 就是在数据批量加载到缓存的场景中在过期时间的基础上加上一个随机量. 比如说预计这一批数据的过期时间是 15 分钟. 那就在设置每一条数据的过期时间的时候, 在 15 分钟的基础上加上一个 0～180 秒的偏移量. 那么这一批数据就不会在同一时刻过期, 也就不存在缓存雪崩的问题了.")])]),_._v(" "),v("p",[_._v("这时候, 面试官可能会问你这个偏移量的范围怎么确定. 比如你说的是 0～180 秒的偏移量, 那么 0～10 秒的偏移量行不行? 这时候你要抓住核心, "),v("strong",[_._v("偏移量要跟过期时间成正比, 不能过低或者过高.")])]),_._v(" "),v("blockquote",[v("p",[_._v("这个随机偏移量应该和过期时间成正比. 比如如果过期时间是 15 分钟, 那么随机偏移量在 0～180 秒都可以. 如果数据量不多, 那么 0～60 秒也可以. 而如果过期时间很长, 比如说 4 个小时, 也可以把偏移量控制在 0～10 分钟. 如果过期时间很短, 比如只有 10s, 这个时候偏移量就只能在 0～3 秒内了.")])]),_._v(" "),v("h5",{attrs:{id:"限流"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#限流"}},[_._v("#")]),_._v(" 限流")]),_._v(" "),v("p",[_._v("此外还要注意一点, 就是引发缓存穿透, 击穿和雪崩等问题的一个关键是"),v("strong",[_._v("有很多请求落到了数据库上")]),_._v(". 所以一个"),v("strong",[_._v("最简单的办法就是限制住这些请求, 不让它们落到数据库上")]),_._v(". 所以限流就可以用在这些场景中.")]),_._v(" "),v("p",[_._v("可以回答限流的基本思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("缓存穿透和击穿只有在高并发下才会成为一个问题, 所以一个很自然的想法就是使用限流. 限流可以考虑在两个地方使用: "),v("mark",[_._v("服务层面和数据库层面")]),_._v(".")])]),_._v(" "),v("p",[_._v("而在服务层面上限流, 是有一个隐含假设的, 可以强调一下这个假设, 就是"),v("strong",[_._v("数据库撑得住.")])]),_._v(" "),v("blockquote",[v("p",[_._v("在服务层面上限流的时候, 要保证只要 QPS 没有超过这个数值, 就算所有的请求都没有命中缓存, 直接落到了数据库上, 数据库也能撑住这个流量, 但是有些时候也难以保证. 或者说大多数人在考虑限流阈值, 包括使用压测来确定限流阈值的时候, 都已经把命中缓存这种情况考虑进去了. 所以需要进一步考虑数据库层面上的限流了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/52eaa16c6b0c5cddff0c7b60a63f6117-20231223175002-6jfeapz.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("降级那节提到, 为了防止数据库崩溃, 最好在数据库访问上加一些限流措施. 显然, 就算数据库没有崩溃, 这个限流还是可以保护数据库免遭大流量的冲击.")]),_._v(" "),v("blockquote",[v("p",[_._v("数据库层面上的限流总的来说是必不可少的. 不管是缓存崩溃, 还是穿透或者击穿, 限流都能保护住数据库. 如果使用了数据库代理, 并且这些代理支持限流, 那么就可以直接在代理上做限流. 如果没有使用代理或者代理不支持, 那么就可以考虑在 ORM 上做.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1066b0575e039e88622df47c4yy3e3e1-20231223175002-z8ysyyj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"亮点方案-16"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点方案-16"}},[_._v("#")]),_._v(" 亮点方案")]),_._v(" "),v("p",[_._v("到这里, 已经知道不管是缓存穿透, 击穿还是雪崩, "),v("mark",[v("strong",[_._v("归根结底就是请求都落到了数据库上")])]),_._v(". 除了这三个异常, Redis 本身也有可能崩溃, 又或者因为网络问题连不上这个集群. 那么今天准备的亮点方案--"),v("strong",[_._v("集群互为备份")]),_._v(", 就可以很好地解决这个问题.")]),_._v(" "),v("p",[_._v("很多大厂会用一些异地多活的方案, 就是使用两个 Redis 集群, 然后两个集群之间要保持数据同步. 那么"),v("strong",[_._v("其中一个 Redis 集群崩溃的时候, 就可以用另外一个 Redis 集群")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bedc1c4f87879a348029755040d89d7b-20231223175002-z5e5yct.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("但这个方案太高端了, 不在大厂的话很难接触到. 所以这里准备一个比较低端但是更加容易落地的方案.")]),_._v(" "),v("p",[_._v("这个方案的思路还是"),v("strong",[_._v("用两个或者多个 Redis 集群, 但不会让这些集群之间保持数据同步")]),_._v(". 比如可以在两个云服务厂商上购买两个不同的 Redis 服务, 然后尽可能让核心业务访问不同的集群.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/80153252bbef3yy1dd39f0dbd04a52a8-20231223175002-z418t31.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么可以这样介绍这个思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("假设我有两个业务, 那么我准备两个 Redis 集群, 业务 1 主要用集群 1, 集群 2 作为备份. 业务 2 主要使用集群 2, 集群 1 作为备份.")]),_._v(" "),v("p",[_._v("具体思路是这样的:")]),_._v(" "),v("p",[_._v("第一, 业务 1 会和集群 1 保持心跳. 当发现连不上 Redis 之后, 就可以执行容错方案, 这个时候业务 1 会保持和集群 1 的心跳.")]),_._v(" "),v("p",[_._v("第二, 触发容错之后, 业务 1 根据流量价值分成两部分. 对于非核心业务来说, 直接触发熔断, 不会查询集群 2, 也不会查询数据库, 这是舍小保大. 对于核心业务来说, 按照预先设置的流量比例, 查询集群 2, 并回查数据库, 其余请求一样熔断. 如果当前流量比例查询集群 2 没有引起任何的问题, 数据库也没有问题, 那么就增大流量比例.")]),_._v(" "),v("p",[_._v("第三, 当集群 1 重新恢复心跳之后, 业务 1 还是逐步把集群 2 上的流量转发到集群 1 上.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d4a0676a96322d7fee96aaed7cd11yyf-20231223175002-77bdia8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以进一步总结这个思路的要点, 就是"),v("strong",[_._v("渐进式.")])]),_._v(" "),v("blockquote",[v("p",[_._v("在触发容错之后, 没有立刻把全部流量转发到集群 2 上, 是因为担心集群 2 会撑不住, 所以要逐步转发流量, 每次转发之后发现没问题就可以调大比例. 转发回集群 1 也是这样, 因为和集群 1 刚恢复通信的时候, 集群 1 上面什么数据都没有, 而这个时候集群 2 还能用, 所以不着急立刻转发回来, 先小规模流量重建集群 1 上的数据.")])]),_._v(" "),v("p",[_._v("那为什么互为备份可行呢? 因为正常 Redis 集群都有很大的余量, 在遇到问题的时候互为备份顶一下就可以. 当技术人员发现问题之后, 会紧急采购新的 Redis 服务, 或者部署新的集群接替集群 1. 所以集群 2 大概率会在高负载状态下运行一段时间.")]),_._v(" "),v("p",[_._v("如果面试的是比较小型的公司, 对成本比较敏感, 就可以补充一个变种, 关键词是凑合用便宜货.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果觉得两个 Redis 集群服务太贵, 那么也有一个低成本方案, 公司可以自己部署一个小规模的 Redis 集群, 甚至单机 Redis 作为所有业务的备份. 这个 Redis 集群不要求高可用, 对它的唯一要求就是撑住我线上集群的核心流量一段时间就可以. 毕竟, 不管这个备份集群有多差, 都比完全没有要好.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/411d042856a57666e8e8721a46c5b9d3-20231223175002-wf8gjzj.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这里还有一些细节问题. 第一个是最开始按多少比例转发到集群 2 上比较合适, 答案是这个初始流量的大小就是你业务数据库能撑住的流量大小. 因为一开始转发到集群 2 上的流量, 肯定都是缓存未命中的, 也就是要回查数据库, 所以数据库决定了这个初始流量.")]),_._v(" "),v("p",[_._v("第二个问题是后续流量要怎么放开. 答案是可以自由选择, 按照比例增长, 线性增长都可以. 但是原则是要保守, 因为万一把集群 2 弄崩溃了, 业务损失就更大了.")]),_._v(" "),v("p",[_._v("第三个问题就是怎么判定 Redis 已经崩溃了, 或者恢复过来了? 这个问题在微服务部分已经多次遇到了, 思路都是一样的, 这里就不重复了.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-33"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-33"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("今天这节介绍了缓存穿透, 击穿和雪崩三个基本概念, 要注意它们之间的区别, 尤其是含义非常接近的穿透和击穿两个概念, "),v("strong",[_._v("穿透是完全没有数据, 而击穿是缓存里没有数据")]),_._v(".")]),_._v(" "),v("p",[_._v("后面也提出了具体的解决方案.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("解决缓存穿透: 回写特殊值和布隆过滤器两个方案")])]),_._v(" "),v("li",[v("strong",[_._v("解决缓存击穿: singleflight 模式")])]),_._v(" "),v("li",[v("strong",[_._v("解决缓存雪崩: 过期时间增加随机偏移量")])])]),_._v(" "),v("p",[_._v("还有一个"),v("strong",[_._v("限流, 能够彻底保护住数据库, 对于穿透, 击穿和雪崩等问题都有效果")]),_._v(".")]),_._v(" "),v("p",[_._v("最后给出了一个互为备份的集群容错方案, 并且提供了一个经济适用版的变种. 这一次的亮点方案稍微有点不同, 是一个低端一点的方案. 但是它更加符合大多数人的实际情况, 在实践中落地也不是很难, 只需要改造一下缓存客户端代码, 加上探活和流量调度的逻辑就可以了.")]),_._v(" "),v("p",[_._v("如果你在大厂工作过, 那么可以考虑深入了解你们公司异地多活方案的细节. 就算没有实际部署实施过, 但是面试的时候还是可以拿出来聊一下, 凸显一下你的知识面.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/66a4bfb42b5214f9466c7211440ee6cb-20231223175002-9e0fov9.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_36-redis单线程-为什么redis用单线程而memcached用多线程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_36-redis单线程-为什么redis用单线程而memcached用多线程"}},[_._v("#")]),_._v(" 36-Redis单线程:为什么Redis用单线程而Memcached用多线程?")]),_._v(" "),v("p",[_._v("今天来探讨一下 "),v("strong",[_._v("Redis 高性能的原因")]),_._v(".")]),_._v(" "),v("p",[_._v("这个问题在面试中还是很常见的, 原因也很简单, 除了 Redis 基本上没有听过其他采用单线程模型的中间件, 所以这就凸显了 Redis 的与众不同.")]),_._v(" "),v("p",[_._v("而且这个问题也很有现实意义. 大部分时候对 Redis 的一些高级应用, 比如前面提到的利用 Redis "),v("strong",[_._v("实现一个分布式锁, 其中有一个很重要的假设就是 Redis 是线程安全的, 没有并发问题. 而 Redis 是单线程的这一点就保证了线程安全的特性")]),_._v(".")]),_._v(" "),v("p",[_._v("那么今天来看一下, Redis 的高性能究竟是怎样做到的.")]),_._v(" "),v("h5",{attrs:{id:"redis是单线程的含义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redis是单线程的含义"}},[_._v("#")]),_._v(" Redis是单线程的含义")]),_._v(" "),v("p",[_._v("在学习 Redis 的时候, 肯定听过一句话, Redis 是单线程的. 而实际上, Redis 并不是单线程的. "),v("mark",[v("strong",[_._v("业界说 Redis 是单线程的, 是指它在处理命令的时候, 是单线程的")])]),_._v(". 在 Redis 6.0 之前, Redis 的 IO 也是单线程的, 但是在 6.0 之后也改成了多线程.")]),_._v(" "),v("p",[v("strong",[_._v("但是其他部分, 比如持久化, 数据同步之类的功能, 都是由别的线程来完成的. 因此严格来说, Redis 其实是多线程的")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"面试准备-36"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-36"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("这一部分的面试内容基本上都是纯理论的, 所以需要做几件事情.")]),_._v(" "),v("ul",[v("li",[_._v("了解你使用的其他中间件, 在 IO 上是否使用了 epoll, 以及是否使用了 Reactor 模式.")]),_._v(" "),v("li",[_._v("了解你们公司有没有使用 Redis 的多线程, 如果用了, 那么弄清楚最开始的决策理由以及相比单线程性能究竟提升了多少.")]),_._v(" "),v("li",[_._v("了解清楚你使用的 Redis 的性能瓶颈.")])]),_._v(" "),v("p",[_._v("如果用的 Redis 真的启用了多线程模式, 就可以将这一点纳入到你的性能优化方案中. 有关 Redis 的线程模型面试是纯理论面试, 所以需要记忆的东西很多. 有时间的话可以把 Redis 的源码下载下来, 看看和网络 IO 处理有关的部分, 加深印象.")]),_._v(" "),v("p",[_._v("当和面试官聊到了这些话题的时候, 就可以用这节课的知识来回答.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("网络 IO 问题")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("其他也用 epoll 的中间件")]),_._v(".")]),_._v(" "),v("li",[_._v("多线程的 Memcache, Memcache 用了多线程, 但是 Redis 用了单线程.")]),_._v(" "),v("li",[v("strong",[_._v("Redis 的性能问题")]),_._v(".")])]),_._v(" "),v("h5",{attrs:{id:"面试思路-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路-3"}},[_._v("#")]),_._v(" 面试思路")]),_._v(" "),v("p",[_._v('一般来说, 面试官都会问 "为什么 Redis 是单线程的, 但是又能做到高性能?" 很多人会下意识地回答: "因为 Redis 是完全内存操作的." 这个理由很关键, 但是这并不是面试官想要的答案, 他希望你回答的是 Redis 的 '),v("strong",[_._v("IO 模型")]),_._v(".")]),_._v(" "),v("p",[_._v("所以要回答这个问题, 首先要澄清 Redis 单线程的含义.")]),_._v(" "),v("blockquote",[v("p",[_._v("通常说的 Redis 单线程, 其实是"),v("strong",[_._v("指处理命令的时候 Redis 是单线程的")]),_._v(". 但是 Redis 的其他部分, 比如说持久化其实是另外的线程在处理. 因此本质上, Redis 是多线程的. 特别是 Redis 在 6.0 之后, 连 IO 模型都改成了多线程的模型, 进一步发挥了多核 CPU 的优势.")])]),_._v(" "),v("p",[_._v("然后先点明两个关键点: 内存操作和高效 IO 模型.")]),_._v(" "),v("blockquote",[v("p",[_._v("Redis 的高性能源自两方面, "),v("mark",[_._v("一方面是 Redis 处理命令的时候, 都是纯内存操作. 另外一方面, 在 Linux 系统上 Redis 采用了 epoll 和 Reactor 结合的 IO 模型, 非常高效")]),_._v(".")])]),_._v(" "),v("p",[_._v("这个时候他肯定就会问什么是 epoll, 什么是 Reactor 模式.")]),_._v(" "),v("h6",{attrs:{id:"epoll模型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#epoll模型"}},[_._v("#")]),_._v(" epoll模型")]),_._v(" "),v("p",[v("strong",[_._v("简单来说就是 epoll 会帮你管着一大堆的套接字. 每次需要做啥的时候, 就问问哪些套接字可用")]),_._v(". 读数据, 就是"),v("strong",[_._v("找出那些已经收到了数据的套接字; 写数据, 就是找出那些可以写入数据的套接字")]),_._v(".")]),_._v(" "),v("p",[_._v("而在 Linux 系统里面, "),v("strong",[_._v("套接字就是一个普通的文件描述符, 因此 epoll 本质上是管着一堆文件描述符")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/538e2c314e88be9f07b0970694cc94a9-20231223175002-3gqvbf2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("只需要记住: "),v("strong",[_._v("==epoll = CRUD 文件描述符==")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("Redis 使用的是 epoll 来处理 IO. 在 Linux 里面, 万物都是文件, 和网络 IO 有关的套接字也是文件. 所以 epoll 要做的事情, 就是管理这些文件描述符. 或者用一句话来描述: "),v("mark",[_._v("epoll 就是增删改查文件描述符")]),_._v(".")])]),_._v(" "),v("p",[_._v("然后再介绍一下 epoll 的基本结构和系统调用.")]),_._v(" "),v("blockquote",[v("p",[_._v("epoll 里面有两个关键结构. "),v("mark",[_._v("一个是红黑树, 每一个节点都代表了一个文件描述符. 另外一个是双向链表, 也叫做就绪列表")]),_._v(".")]),_._v(" "),v("p",[_._v("为了维护 epoll 的结构, 有三个关键的系统调用.")]),_._v(" "),v("ol",[v("li",[_._v("epoll_create: 也就是创建一个 epoll 结构")]),_._v(" "),v("li",[_._v("epoll_ctl: 管理 epoll 里面的那些文件描述符, 简单说就是增删改 epoll 里面的文件描述符.")]),_._v(" "),v("li",[_._v("epoll_wait: 根据你的要求, 返回符合条件的文件描述符, 也就是查.")])])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b4678e40fe7591f84366334626400a74-20231223175002-03m53tm.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么显然可以猜到, 如果写一个从网络中读取数据的程序, 看起来应该是这样的.")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[_._v("epoll "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("epoll_create")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// fd 是一个套接字对应的文件描述符, 并且告诉它, 你关心读事件")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 可以加很多个")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("epoll_ctl")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("epoll"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" ADD"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" fd"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" READ"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\nwhile "),v("span",{pre:!0,attrs:{class:"token boolean"}},[_._v("true")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 需要可读数据的套接字, 等待时间是 1000 毫秒")]),_._v("\n  fds "),v("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("epoll_wait")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("epoll"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" READ"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("1000")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 一步步处理")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br"),v("span",{staticClass:"line-number"},[_._v("9")]),v("br")])]),v("p",[_._v("可以进一步"),v("strong",[_._v("补充 epoll 是怎么把文件描述符挪到就绪列表的")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("需要注意的是, epoll 并不是在发起 epoll 调用的时候才把文件描述符挪到就绪列表的. 而是在 epoll 创建之后, 不管有没有发起 epoll_wait 调用, 只要文件描述符满足条件了, 就会被挪到就绪列表.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/75eda1514e3a2fcfce0a186c91dab6d5-20231223175002-au56zvs.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"发起epoll调用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#发起epoll调用"}},[_._v("#")]),_._v(" 发起epoll调用")]),_._v(" "),v("p",[_._v("因此, 当发起 epoll_wait 的时候, 有两种情况. "),v("strong",[_._v("第一种情况是就绪列表里面有符合条件的套接字, 直接给你")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/28717b3031f7095a542833d2d5d8b9ee-20231223175002-o5ze4jo.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("第二种情况就是就绪列表里面没有符合条件的套接字, 这时候传入不同的超时时间, 会有不同的响应")]),_._v(". 记住关键词, -1 永远阻塞, 0 立刻返回, 正数等待直到超时.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果在发起超时调用的时候, 传入的超时时间是 -1, 那么调用者会被阻塞, 直到有满足条件的文件描述符. 如果传入的超时时间是 0, 那么会立刻返回, 不管有没有满足条件的文件描述符. 如果传入的是正数 N, 那么就会等待最多 N 毫秒, 直到有数据或者超时.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bbfabdf280e94a698d017144b2ee9fa7-20231223175002-egktox0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"亮点-epoll与中断"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#亮点-epoll与中断"}},[_._v("#")]),_._v(" 亮点:epoll与中断")]),_._v(" "),v("p",[_._v("紧接着可以刷一个亮点, 就是 "),v("strong",[_._v("epoll 怎么知道数据来了? 又或者 epoll 怎么知道超时了")]),_._v("? 答案是"),v("mark",[v("strong",[_._v("中断")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("每一个和 IO 有关的文件描述符都有一个对应的驱动, 这个驱动会告诉 epoll 发生了什么. 比如说, 当有数据发送到网卡的时候, 会触发一个中断. "),v("mark",[_._v("借助这个中断, 网卡的驱动会告诉 epoll, 这里有数据了. 而超时也是利用了中断, 不过是时钟中断. 时钟中断之后, 内核会去检查发起 epoll_wait 的线程有没有超时, 如果超时了就会唤醒这个线程. 调用者就会得到超时响应")]),_._v(".")])]),_._v(" "),v("p",[_._v("这部分内容建议主动提起, 因为很少有面试官会在面试中追问到这里. 而且可以将比较上层的应用原理和底层的中断机制关联在一起, 能体现你计算机基础很扎实.")]),_._v(" "),v("h6",{attrs:{id:"epoll-poll和select"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#epoll-poll和select"}},[_._v("#")]),_._v(" epoll,poll和select")]),_._v(" "),v("p",[_._v("在面试中, epoll, poll 和 select 有时候会一起问. 也就是让你分析这三种模型, 并且解释三者的优劣.")]),_._v(" "),v("p",[_._v("前面已经掌握了最难的 epoll 了, 而 poll 和 select 比 epoll 简单多了.")]),_._v(" "),v("p",[_._v("先来看 select. "),v("strong",[_._v("发起 select 调用的时候会传给 select 一堆代表连接的文件描述符, 内核会帮你检查这些文件描述符")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/12f8325f3d73f1a20805b16dfe1576bb-20231223175002-7mzkf3d.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("它和 epoll 的区别是, "),v("strong",[_._v("必须要发起 select 调用, 内核才会一个个帮你问")]),_._v(". 也就是说, select 调用缺乏 epoll 那种即便不调用 epoll_wait, epoll 也会把准备好的文件描述符放到就绪列表的机制. 一句话来说, 就是 "),v("mark",[v("strong",[_._v("epoll 会提前帮你准备好符合条件的文件描述符, 但是 select 不会")])]),_._v(".")]),_._v(" "),v("p",[_._v("select 用起来的伪代码就像这样:")]),_._v(" "),v("div",{staticClass:"language-plain line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-plain"}},[v("code",[_._v("readfds = [] // 一堆文件描述符, 作为候选\nwritefds = [] // 也是一堆文件描述符, 作为候选\nexecpfds = [] // 还是一堆文件描述符, 作为候选\nselect(readfds, writefds, excepfds) // 从这些描述符里面挑出符合条件的\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br")])]),v("p",[_._v("在 select 方法内部, 内核会遍历传入的这些候选文件描述符, 找出你要的. "),v("strong",[_._v("poll 和 select 的基本原理一样")]),_._v(".")]),_._v(" "),v("p",[_._v("三者的区别下面列了一个表格, 在面试的时候可以强调一下和性能有关的几个点.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ceb8dbe7356b809897fa1f343f75de10-20231223175002-nro9svs.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在面试中主要面 epoll 的细节, poll 和 select 大概提一下就可以. 一般情况下能解释清楚 epoll 就行了.")]),_._v(" "),v("h6",{attrs:{id:"reactor模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#reactor模式"}},[_._v("#")]),_._v(" Reactor模式")]),_._v(" "),v("p",[_._v("在搞清楚了 Redis 使用的系统调用之后, 还有一个面试的点, 就是 "),v("mark",[v("strong",[_._v("Redis 使用的 Reactor 模式")])]),_._v(".")]),_._v(" "),v("p",[_._v("Reactor 模式也是广泛使用的 IO 模式, 它的性能很好, Redis 也用了 Reactor 模式.")]),_._v(" "),v("p",[_._v("用一句话来说明 "),v("mark",[v("strong",[_._v("Reactor 模式: 一个分发器 + 一堆处理器")])]),_._v(".")]),_._v(" "),v("p",[_._v("一般来说, 客户端和服务端的 IO 交互主要有两类事件: "),v("strong",[_._v("连接事件和读写事件")]),_._v(". 那么 Reactor 里面的"),v("strong",[_._v("分发器就是把连接事件交给 Acceptor, 把读写事件交给对应的 Handler")]),_._v(". 这些 Handler 最终会调用到真正需要读写数据的业务代码.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b8a2993394fcdc987689e276ff4c4b22-20231223175002-etr6j4c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("结合前面讲的 epoll, 基本上就能猜到, "),v("mark",[v("strong",[_._v("Redis 的 Reactor 就是调用了 epoll, 拿到创建连接的套接字, 或者可读写的套接字, 转发给后面的 Acceptor 或者 Handler")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a995172ff330b92d25yy295a6yy559d2-20231223175002-pzloe1z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在搞清楚这一点之后, 接下来就能够理解各种 Reactor 的变种了. 变种基本上可以分成三类.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("把 Accetor 做成多线程")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("把 Handler 做成多线程")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("把 Reactor 做成多线程")]),_._v(". Reactor 的主线程只监听连接创建的事件, 监听到了就交给其他线程处理. 其他线程则是监听读写事件, 然后调用对应的 Handler 处理.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6353266286333db7e09f312c7e9ed1da-20231223175002-uodx6bd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("Redis 的特殊之处在于, Redis 是单线程的. 也就是说, "),v("strong",[_._v("Reactor, Handler, Acceptor 都只是一个逻辑上的区分, 实际上都是同一个线程")]),_._v(".")]),_._v(" "),v("p",[_._v("所以当面试官问到的时候, 就把这两者结合在一起回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了保证性能最好, Redis 使用的是基于 epoll 的 Reactor 模式.")]),_._v(" "),v("p",[_._v("Reactor 模式可以看成是一个分发器 + 一堆处理器. Reactor 模式会发起 epoll 之类的系统调用, 如果是读写事件, 那么就交给 Handler 处理; 如果是连接事件, 就交给 Acceptor 处理.")])]),_._v(" "),v("p",[_._v("然后强调一下单线程的 Redis 是怎么使用这个 Reactor 模式的.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("Redis 是单线程模型, 所以 Reactor, Handler 和 Acceptor 其实都是这个线程")]),_._v(".")]),_._v(" "),v("p",[_._v("整个过程是这样的:")]),_._v(" "),v("ol",[v("li",[_._v("Redis 中的 Reactor 调用 epoll, 拿到符合条件的文件描述符.")]),_._v(" "),v("li",[_._v("假如 Redis 拿到了可读写的描述符, 就会执行对应的读写操作.")]),_._v(" "),v("li",[_._v("如果 Redis 拿到了创建连接的文件描述符, 就会完成连接的初始化, 然后准备监听这个连接上的读写事件.")])]),_._v(" "),v("p",[_._v("后面在 6.0 的时候, Redis 改成了多线程模型, 但是基本原理还是 Reactor + epoll.")])]),_._v(" "),v("p",[_._v("最后提到了 Redis 的 6.0 新模型, 那么面试官就可能会问两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("同样是基于内存的缓存中间件, 为什么 Memcache 用的是多线程模型, 而 Redis 用的是单线程模型?")]),_._v(" "),v("li",[_._v("Redis 为什么最终又引入了多线程模型? 和原本的单线程模型比起来, 区别在哪里?")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点一: 为什么 Memcache 使用多线程?")])]),_._v(" "),v("p",[_._v("坦白来说, 个人认为这就是一个设计者的偏好问题, 因为两者的优缺点都是很明显的.")]),_._v(" "),v("p",[_._v("在回答的时候, 也就是回答两者的优缺点, 再随便补充一点个人理解就可以了. 可以先回答 Redis 使用单线程模式的原因.")]),_._v(" "),v("blockquote",[v("p",[_._v("Redis 使用单线程模式的理由有很多. 首先有两个显著的优点: "),v("mark",[_._v("不会引入上下文切换的开销, 也没有多线程访问资源的竞争问题")]),_._v(". 其次 Redis 是一个内存数据库, 操作很快, 所以它的性能瓶颈只可能出现在网络 IO 和内存大小上, 是不是多线程影响不大. 最后, 单线程模式比较好理解, 调试起来也容易.")])]),_._v(" "),v("p",[_._v("紧接着回答 Memcache 的设计.")]),_._v(" "),v("blockquote",[v("p",[_._v("Memcache 采用了多线程设计, 那么带来的后果就是会有线程上下文切换的开支, 并且多线程模式下需要引入锁来保护共享资源. 优点则是 Memcache 会比 Redis 更充分地利用多核 CPU 的性能.")])]),_._v(" "),v("p",[_._v("毕竟我们都不是 Redis 的设计者, 也难以说清楚究竟是什么因素促使设计者下定决心使用单线程模型. 下面的这一段话是个人理解, 可以替换成你自己的思考.")]),_._v(" "),v("blockquote",[v("p",[_._v("我之前注意到有些人在网上发布了 Redis 和 Memcache 的性能对比. 基本上就是有些时候 Redis 好一点, 有些时候 Memcache 好一点.")]),_._v(" "),v("p",[_._v("我觉得既然 Redis 用单线程模型都能取得这种不相上下的性能表现, 就说明 Redis 的选择还是很正确的. 即便如此, 后面 Redis 在 6.0 的时候, 还是引入了多线程模型, 期望进一步利用多核 CPU 的优势.")])]),_._v(" "),v("blockquote",[v("p",[_._v("亮点二: Redis 为什么引入多线程?")])]),_._v(" "),v("p",[_._v("引入多线程的原因只有一个, 那就是"),v("strong",[_._v("性能")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("Redis 在 6.0 引入多线程的原因只有一个, "),v("mark",[_._v("在高并发场景下可以利用多个线程并发处理 IO 任务, 命令解析和数据回写")]),_._v(". 这些线程也被叫做 IO 线程. 默认情况下, 多线程模式是被禁用了的, 需要显式地开启.")])]),_._v(" "),v("p",[_._v("当然要想答好这个问题, 就不能只解释为什么引入多线程, 还要结合 Reactor 和 epoll 来解释在启用了多线程模型之后, Redis 是如何运作的.")]),_._v(" "),v("p",[_._v("如果刨除 Redis 主线程和 IO 线程之间的交互细节, 那么"),v("strong",[_._v("多线程模式下的 Redis 的 Reactor 和 epoll 结合在一起的形式")]),_._v("就是像图片里展示的这样.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/3ef2dec04c2a9b3e9cb0b1de1f72a940-20231223175002-ytrbp06.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以这样介绍整个设计.")]),_._v(" "),v("blockquote",[v("p",[v("mark",[_._v("当 Redis 启用了多线程之后, 里面的主线程就要负责接收事件, 创建连接, 执行命令. Redis 的 IO 线程就负责读写数据")]),_._v(".")]),_._v(" "),v("p",[_._v("用一个请求的处理过程来解释一下整个设计. 当客户端发出请求的时候, 主线程会收到一个可读的事件, 于是它把对应的客户端丢到可读的客户端列表. 一个 IO 线程会被安排读写这个客户端发过来的命令, 并且解析好. 紧接着主线程会执行 IO 线程解析好的命令, 并且把响应放回到可写客户端列表里面. IO 线程负责写回响应. 整个过程就结束了.")]),_._v(" "),v("p",[_._v("所以"),v("mark",[_._v("整个 Redis 在多线程模式下, 可以看作是单线程 Reactor, 单线程 Acceptor 和多线程 Handler 的 Reactor 模式")]),_._v(". 只不过 Redis 的主线程同时扮演了 Reactor 中分发事件的角色, 也扮演了接收请求的角色. 同时多线程 Handler 在 Redis 里面仅仅是读写数据, 命令的执行还是依赖于主线程来进行的.")])]),_._v(" "),v("p",[_._v("紧接着要补充一个业界比较多人认同的观点, 就是"),v("mark",[v("strong",[_._v("不到逼不得已不要启用 Redis 多线程模型")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("虽然说现在 Redis 的 IO 改成多线程之后能够有效利用多核性能, 但是大部分情况下都是不推荐使用多线程模式的. 道理很简单, Redis 在单线程模式下的性能就足以满足绝大多数使用场景了, 那么用不用多线程已经无所谓了.")])]),_._v(" "),v("p",[_._v("接下来根据你们公司的实际情况来选择一个回答.")]),_._v(" "),v("p",[_._v("第一个回答是介绍你们公司使用了多线程模型.")]),_._v(" "),v("blockquote",[v("p",[_._v("我司的 Redis 早期的时候就触及了单线程的性能瓶颈, 后来在开启了多线程之后, 能支撑的 QPS 大概提升了 50%, 效果还是很不错的.")])]),_._v(" "),v("p",[_._v("你最好在自己公司里面测试一下性能提升的幅度. 有些时候面试官可能会问用了几个线程, 你回答公司的实际情况就行.")]),_._v(" "),v("p",[_._v("另外一个回答是你们公司没有用多线程模型.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我们公司虽然遇到过 Redis 的性能瓶颈, 但还是没有启用多线程模型, 而是改成了使用 Redis Cluster(或者扩大了 Redis Cluster 规模). 个人认为 Redis Cluster 一样能够解决性能瓶颈问题, 而且相比多线程模式, Redis Cluster 的可用性更好, 解决性能问题的效果也更好.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-34"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-34"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v('这一节首先澄清了一个观点 "Redis 是单线程的", 实际上'),v("strong",[_._v("强调的是命令的执行过程是单线程")]),_._v("的.")]),_._v(" "),v("p",[_._v("在面试过程中, Redis 的高性能主要分成两个部分: "),v("mark",[v("strong",[_._v("epoll 和 Reactor 模式")])]),_._v(". 要注意在回答的时候解释清楚 Redis 究竟是怎么把这两者结合在一起的. "),v("strong",[_._v("简单来说就是 Reactor 通过 epoll 这个调用知道发生了什么, 然后分发给后面的 Acceptor 和 Handler")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("记住, 在单线程里面, Reactor 模式里面各个组件实际上都是同一个线程")]),_._v(". 那么相应的 epoll 结构, 基本原理以及和中断的关系也需要记住.")]),_._v(" "),v("p",[_._v("最后讨论了两个问题.")]),_._v(" "),v("ul",[v("li",[_._v("为什么 Memcache 使用多线程? 在回答的时候可以分析单线程多线程的优劣, 最后讲一下自己的体会.")]),_._v(" "),v("li",[_._v("Redis 为什么引入多线程? 核心还是为了充分利用多核性能. 要想在这个问题里面赢得优势, 需要说清楚在多线程模式下, Redis 中的 Reactor 模式是如何运作的.")])]),_._v(" "),v("p",[_._v("要强调的一点就是, 今天这部分内容用于面试应该是够了, 毕竟在面试的时候很少有面试官会要求答出 Redis 的源码究竟是怎么实现的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dc0b8a3e2549f6f17d92c838f141ba0f-20231223175002-mjs9ht4.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_37-分布式锁-如何保证redis分布式锁的高可用和高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_37-分布式锁-如何保证redis分布式锁的高可用和高性能"}},[_._v("#")]),_._v(" 37-分布式锁:如何保证Redis分布式锁的高可用和高性能?")]),_._v(" "),v("p",[_._v("今天来学习一个面试中热度极高的话题--"),v("strong",[_._v("分布式锁")]),_._v(".")]),_._v(" "),v("p",[_._v("分布式锁和分布式事务, 可以说是分布式系统里面两个又热又难的话题. 从理论上来说, 分布式锁和分布式事务都涉及到了很多分布式系统里面的基本概念, 所以我们不愁找不到切入点. 从实践上来说, 分布式锁和分布式事务都是属于一不小心就会出错的技术手段.")]),_._v(" "),v("p",[_._v("在面试分布式锁的过程中, 大部分人只知道很基础的几个点, 比如只能回答出使用 SETNX 命令, 又或者能答出要设置超时时间. 当进一步追问的时候, 就不知道了.")]),_._v(" "),v("h5",{attrs:{id:"能用于实现分布式锁的中间件"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#能用于实现分布式锁的中间件"}},[_._v("#")]),_._v(" 能用于实现分布式锁的中间件")]),_._v(" "),v("p",[_._v("这一节的主题是用 Redis 来实现一个分布式锁, 但是"),v("strong",[_._v("并不意味着分布式锁只能使用 Redis 来实现")]),_._v(".")]),_._v(" "),v("p",[_._v("简单来说, "),v("strong",[_._v("支持排他性操作")]),_._v("的中间件都可以作为实现分布式锁的中间件, 例如 ZooKeeper, Nacos 等, 甚至关系型数据库也可以, 比如利用 MySQL 的 SELECT FOR UPDATE 语法是可以实现分布式锁的.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-37"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-37"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在公司里面要收集一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司"),v("strong",[_._v("有没有使用分布式锁的场景")]),_._v("? 不用分布式锁行不行?")]),_._v(" "),v("li",[_._v("你们"),v("strong",[_._v("使用的分布式锁是怎么实现的? 性能怎么样")]),_._v("?")]),_._v(" "),v("li",[_._v("你使用的分布式锁有没有做什么性能优化?")]),_._v(" "),v("li",[_._v("你使用的"),v("strong",[_._v("分布式锁是如何加锁, 释放锁的? 有没有续约机制")]),_._v("?")]),_._v(" "),v("li",[_._v("在使用分布式锁的时候, 各个环节收到超时响应, 你会怎么办?")])]),_._v(" "),v("p",[_._v("分布式锁是一个通用的业务解决方案. 也就是说完全可以研发一个独立的分布式锁, 提供给各个业务线使用. 所以在简历中或者自我介绍的时候就可以强调自己开发了一个独立的分布式锁框架, 不仅实现了基本功能, 还做了一定的性能优化.")]),_._v(" "),v("p",[_._v("当然, 讨论到下面这些话题的时候, 也可以尝试把话题引导到分布式锁上.")]),_._v(" "),v("ul",[v("li",[_._v("聊到了 ZooKeeper 等适合用来实现分布式锁的中间件的时候, 可以提起你利用 Redis 实现了一个分布式锁.")]),_._v(" "),v("li",[_._v("和面试官聊到了 singltflight 模式, 可以提起用 Singleflight 来优化过分布式锁的性能.")]),_._v(" "),v("li",[_._v("和面试官聊到了过期时间, 可以提起在分布式锁里也要设置一个合适的过期时间.")]),_._v(" "),v("li",[_._v("和面试官聊到了租约之类的机制, 可以提起分布式锁也要实现类似的机制, 防止锁持有者崩溃, 无法释放锁.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路-4"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路-4"}},[_._v("#")]),_._v(" 面试思路")]),_._v(" "),v("p",[_._v("整个面试思路就是层层深入, 将分布式锁的各个点都讨论清楚.")]),_._v(" "),v("h6",{attrs:{id:"加锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#加锁"}},[_._v("#")]),_._v(" 加锁")]),_._v(" "),v("p",[_._v("要使用 Redis 实现分布式锁, 首先要明确一个分布式锁在 Redis 上究竟意味着什么. 答案也很简单, "),v("mark",[v("strong",[_._v("所谓的分布式锁在 Redis 上就是一个普通的键值对")])]),_._v(".")]),_._v(" "),v("p",[_._v("那么为什么一个普通的键值对也可以看成 Redis 的分布式锁呢? 奥妙就在于"),v("mark",[v("strong",[_._v("分布式锁的本质---排他性")])]),_._v(", 就是只要能够借助 Redis 达成排他的效果就可以了.")]),_._v(" "),v("p",[_._v("而在 Redis 上怎么能够达到这种排他的效果? "),v("strong",[_._v("用 SETNX 命令就可以做到")]),_._v(". 也就是说, 如果一个线程能够用 SETNX 成功地在 Redis 上设置好一个键值对, 那么在它删除这个键值对之前, 别的线程都没办法再设置同样的键值对.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7ec76768f7dfccea4cb5ec4ec36562fa-20231223175002-60hxt9p.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以, "),v("mark",[v("strong",[_._v("加锁就是调用 SETNX 命令, 而释放锁就是执行 DEL 命令")])]),_._v(". 面试的过程中要先简明扼要地说清楚锁的实质, 还有加锁和释放锁是什么.")]),_._v(" "),v("blockquote",[v("p",[_._v("利用 Redis 来实现分布式锁的时候, 所谓的锁就是一个普通的键值对. 而加锁就是使用 SETNX 命令, 排他地设置一个键值对. 如果 SETNX 命令设置键值对成功了, 那么说明加锁成功. 如果没有设置成功, 说明这个时候有人持有了锁, 需要等待别人释放锁. 而相应地, 释放锁就是删除这个键值对.")])]),_._v(" "),v("p",[_._v("接下来可以等面试官主动询问这个过程中的细节.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1: 等待时间")])]),_._v(" "),v("p",[_._v("在前面回答中, 你提到加锁失败了, 就要等一段时间, 等别人释放锁. 那么面试官可能问, 究竟该等多长时间? 理论上来说, 是尽可能在等待的这段时间内拿到锁. "),v("strong",[_._v("因此等待的时间就是一个锁会被持有的时间")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("当加锁失败的时候, 这个"),v("mark",[_._v("等待时间是要根据锁的持有时间来设置的")]),_._v(". 比如如果预计 99% 的锁持续时间是一秒钟, 那就可以把这个等待时间设置成一秒钟.")])]),_._v(" "),v("p",[_._v("在说完了如何确定等待时间之后, 接下来就可以讨论怎么实现这种等待机制.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2: 如何实现等待机制")])]),_._v(" "),v("p",[_._v("面试官大概率会进一步追问, 你说的等待究竟是怎么实现的? 这也有两种方案, "),v("strong",[_._v("轮询和监听删除事件")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("等待也有两种实现方式. 第一种方式就是轮询, 比如在加锁失败之后, 每睡眠 100 毫秒就尝试加锁一次, 直到成功或者整个等待时间超过一秒钟. 第二种方式是监听删除事件, 也就是在加锁失败之后立刻订阅这个键值对. 当键值对被删除的时候就说明锁被释放了, 这个时候再次尝试加锁. 监听删除事件总的来说, 实时性比较好, 但是实现起来比较麻烦.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7d8b22d27dbdcb089a26cebb6484bdaf-20231223175002-1a03r0i.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个示意图只是为了方便理解, 而在实际的实现中, 发现锁被人设置了和订阅是要做成一个整体的, 不然就会有并发问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点3: 加锁重试")])]),_._v(" "),v("p",[_._v("就算是正常的加锁也有可能遇到超时的问题, 怎么办? 这个问题棘手之处在于不知道出现超时的时候, 究竟有没有加锁成功.")]),_._v(" "),v("p",[_._v("按照之前遇到超时的一般思路, 就是"),v("strong",[_._v("直接重试")]),_._v(". 但是重试的逻辑比较复杂, 分成几种情况.")]),_._v(" "),v("ol",[v("li",[_._v("第一次调用的时候, 并没有成功.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d06564265bc222b94711079ae06603d9-20231223175002-z1zq31h.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[_._v("第一次调用的时候, "),v("strong",[_._v("加锁成功")]),_._v("了.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c99042e750a4ac9a31702975a71548b6-20231223175002-7emk2ux.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[_._v("第一次调用的时候, "),v("strong",[_._v("加锁失败了, 并且现在别的线程持有锁")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/c3f303212f17ae108eed92a81bf6fbe2-20231223175002-9xmz4dd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这三张图里重试的"),v("strong",[_._v("一个核心是要知道自己究竟有没有加锁成功")]),_._v(". 所以在加锁的时候, "),v("mark",[v("strong",[_._v("键值对里的值应该可以标识锁是谁加的")])]),_._v(". 比如使用 UUID. 也就是重试的时候还带着上次的 UUID, 如果 Redis 里键值对存在, 并且值正好是自己的 UUID, 那就说明是自己加的锁.")]),_._v(" "),v("p",[_._v("所以可以这么介绍你的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("分布式锁也可以考虑提供重试功能. 比如加锁的时候收到了超时响应, 就可以发起重试. 假如要给 key1 加分布式锁, 随机生成了一个 UUID value1 作为值, 那么重试的基本逻辑是这样的:")]),_._v(" "),v("ol",[v("li",[_._v("检查一下 Redis 里是否存在 key1. 如果 key1 不存在, 那么说明上一次调用没有加锁成功.")]),_._v(" "),v("li",[_._v("如果 key1 存在, 检查值是不是 value1. 如果是 value1, 那么说明自己上一次加锁成功了. 考虑到距离重试的时候已经过去了一段时间, 所以需要"),v("mark",[_._v("重置一下过期时间")]),_._v(".")]),_._v(" "),v("li",[_._v("值并不是 value1, 这个时候说明已经有别人拿着锁了, 也就说明加锁失败了.")])])]),_._v(" "),v("p",[_._v("在实践中, 因为 Redis 本身性能很好, 所以最多重试一两次. 但如果从理论上分析, 就有重试一直都超时的可能. 这时候会发生什么?")]),_._v(" "),v("blockquote",[v("p",[_._v("如果重试一直都超时, 这个时候也不需要额外处理. 因为如果之前加锁已经成功了, 那么无非就是过期时间到了, 锁自然失效. 如果之前没有加锁成功, 就更没事了, 别的线程需要的时候就可以拿到锁.")])]),_._v(" "),v("p",[_._v("在这个回答里面提到了一个概念: "),v("strong",[_._v("过期时间")]),_._v(". 为什么分布式锁需要一个过期时间呢?")]),_._v(" "),v("h6",{attrs:{id:"锁过期时间"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#锁过期时间"}},[_._v("#")]),_._v(" 锁过期时间")]),_._v(" "),v("p",[_._v("如果机器永远不会出问题, 网络也永远不会出问题, 那么分布式锁用 Redis 的 SETNX 和 DEL 命令就足够了. 然而现实中这个假设显然是不成立的, 所以就要考虑这么一个问题, "),v("mark",[v("strong",[_._v("万一加锁的那个线程崩溃了呢")])]),_._v("? 比如它所在的机器整个崩溃了, 应该怎么办?")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/64ef504b343e4d1e4bedfba53256d04d-20231223175002-obodjfn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以抓住关键词 "),v("mark",[v("strong",[_._v("没人释放")])]),_._v(" 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("在使用分布式锁的时候, 分布式锁的持有者有可能宕机, 这会导致整个锁既没有人能够获得, 也没有人能够释放. 在这种情况下, 就可以"),v("mark",[_._v("考虑给分布式锁加一个过期时间")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/e2d12160ef5cd3fc262f523291cee7d7-20231223175002-xotg655.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1: 过期时间应该多长")])]),_._v(" "),v("p",[_._v("只要涉及这种过期时间的问题, 面试官肯定会问, 这个"),v("strong",[_._v("过期时间应该设置成多长")]),_._v("?")]),_._v(" "),v("blockquote",[v("p",[_._v("这个过期时间应该根据业务来设置. 比如如果在拿到锁之后, 99% 的业务都可以在 1 秒内完成, 那么就可以把过期时间设置得比 1 秒长一些, 比如设置成 2 秒. 保险起见, 设置成 10 秒甚至一分钟也没多大关系.")]),_._v(" "),v("p",[_._v("过期时间主要是为了防止系统宕机而引入的, 而大部分情况下, 锁都能被正常释放掉, 所以把过期时间设置得长一些也没什么问题.")])]),_._v(" "),v("p",[_._v("我注意到, 很多公司的分布式锁也就是实现到了这一步. 所以可以考虑进一步刷亮点.")]),_._v(" "),v("blockquote",[v("p",[_._v("总的来说, "),v("mark",[_._v("不管过期时间设置成多长, 都可能遇到业务没能在持有分布式锁期间完成的情况")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5d816c2fd1366e6208a862b9d07c7124-20231223175002-03w7gps.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这也是为了引导面试官发问. "),v("mark",[v("strong",[_._v("这种情况究竟该怎么解决呢? 答案是续约")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2: 续约机制")])]),_._v(" "),v("p",[_._v("所谓"),v("mark",[v("strong",[_._v("续约是指设置了过期时间之后, 在快要过期的时候, 再次延长这个过期时间")])]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/6c9cd6bda834593306471c060ff3ee0b-20231223175002-nijfgpb.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("为了防止出现总有业务不能在锁过期时间内结束的问题, 可以考虑引入续约机制. 也就是"),v("mark",[_._v("在分布式锁快要过期的时候就重置一下过期时间")]),_._v(". 比如一开始过期时间设置的是 1 分钟, 那么可以在 50 秒之后再次把过期时间重置为 1 分钟. 理论上来说, 只需要确保在剩余过期时间内能够续约成功, 就可以了. 比如说这里预留了 10 秒, 那么就算第一次续约失败, 也有足够的时间进行重试.")])]),_._v(" "),v("p",[_._v("这时候又会出现新的问题, "),v("strong",[_._v("如果重试之后, 续约都失败了怎么办")]),_._v("? 这就要看业务特性了.")]),_._v(" "),v("blockquote",[v("p",[_._v("如果不断重试之后, 续约都失败了, 那么这个时候就要根据业务来决定采取保守策略还是激进策略了. 如果你对排他性要求得非常严格, 那么这个时候只能考虑中断业务. 因为可能续约失败了, 那么接下来就会有人拿到分布式锁. 所以业务不能继续执行, 这也就是保守策略.")]),_._v(" "),v("p",[_._v("如果你觉得这种非常偶然的续约失败是可以接受的, 那么还是可以继续执行业务, 当然这可能引起数据不一致的问题, 这也就是激进方案.")])]),_._v(" "),v("p",[_._v("这里提到了中断业务, 这也就是你接下来要刷的另外一个亮点, "),v("strong",[_._v("如何中断业务")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点3: 中断业务")])]),_._v(" "),v("p",[_._v("之前已经在超时控制里面接触过中断业务了, 分布式锁其实也面临着一样的困境.")]),_._v(" "),v("blockquote",[v("p",[_._v("在分布式锁出了问题的时候, 中断业务也是一个很困难的事情. 分布式锁并不能直接帮你中断业务, 它只能"),v("mark",[_._v("给你发一个信号")]),_._v(", 告诉你发生了什么糟糕的事情. 比如分布式锁在续约失败的时候, 给你发了一个信号. 这个时候是否中断业务完全是看业务代码是如何实现的. 举个例子, 如果业务是一个大循环, 那么可以在每个循环开始的时候, 检测一下有没有收到什么信号. 如果收到了需要中断的信号, 那么就退出循环.")])]),_._v(" "),v("p",[_._v("伪代码:")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("for")]),_._v(" condition "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 中断业务执行")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" interrupted "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n    "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("break")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token comment"}},[_._v("// 你的业务逻辑")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("DoSomething")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br")])]),v("blockquote",[v("p",[_._v("如果业务没有循环, 那么可以在每一个关键步骤之后都检测一下有没有收到信号, 然后考虑要不要中断业务.")])]),_._v(" "),v("p",[_._v("伪代码:")]),_._v(" "),v("div",{staticClass:"language-go line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-go"}},[v("code",[v("span",{pre:!0,attrs:{class:"token function"}},[_._v("step1")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" interrupted "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("return")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token function"}},[_._v("step2")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("if")]),_._v(" interrupted "),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("{")]),_._v("\n  "),v("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("return")]),_._v("\n"),v("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("}")]),_._v("\n")])]),_._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[_._v("1")]),v("br"),v("span",{staticClass:"line-number"},[_._v("2")]),v("br"),v("span",{staticClass:"line-number"},[_._v("3")]),v("br"),v("span",{staticClass:"line-number"},[_._v("4")]),v("br"),v("span",{staticClass:"line-number"},[_._v("5")]),v("br"),v("span",{staticClass:"line-number"},[_._v("6")]),v("br"),v("span",{staticClass:"line-number"},[_._v("7")]),v("br"),v("span",{staticClass:"line-number"},[_._v("8")]),v("br")])]),v("p",[_._v("最后要总结拔高一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种中断业务的问题, 在微服务超时控制里面也会遇到, 不过也是无解的问题, 因为微服务框架也做不到帮你自动中断业务.")])]),_._v(" "),v("h6",{attrs:{id:"释放锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#释放锁"}},[_._v("#")]),_._v(" 释放锁")]),_._v(" "),v("p",[_._v("正常来说, 释放锁都不会有什么问题. "),v("strong",[_._v("但是在一些特殊场景下, 释放锁也可能会有问题")]),_._v(". 比如说线程 1 加了锁, 结果 Redis 崩溃了又恢复过来, 这时候线程 2 也加了同一把锁.")]),_._v(" "),v("p",[_._v("当线程 1 执行完毕之后, 去释放锁就会把线程 2 的锁也释放掉.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/890253f814bc56d4afe1a430819bcb0a-20231223175002-ailnzyi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("所以"),v("mark",[v("strong",[_._v("在释放锁的时候, 都要确认这个锁是不是自己")])]),_._v("的.")]),_._v(" "),v("blockquote",[v("p",[_._v("在释放锁的时候, 要先确认锁是不是自己加的, 防止因为系统故障或者有人手动操作了 Redis 导致锁被别人持有了. 确认锁的方法也很简单, 就是"),v("mark",[_._v("比较一下键值对里的值是不是自己设置的")]),_._v(". 这也要求在加锁设置键值对的时候使用唯一的值, 比如说用 UUID.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ceb68e8b25e60b1c6cb3cb8266a8f3fb-20231223175002-si57j4t.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h6",{attrs:{id:"其他亮点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#其他亮点"}},[_._v("#")]),_._v(" 其他亮点")]),_._v(" "),v("p",[_._v("这里再补充三个亮点, 一个是非常热门的话题 Redlock, 另外两个是性能优化的方案. 可以尝试把性能优化的亮点纳入到你优化整个系统性能的方案中.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点1：Redlock")])]),_._v(" "),v("p",[_._v("在实现分布式锁的时候, 有一个问题必须要考虑: "),v("strong",[_._v("如果 Redis 崩溃了怎么办?")]),_._v("  在释放锁那里, 已经看到, 如果 Redis 崩溃了再恢复过来的时候, 锁就有可能被别人拿走. 怎么解决这种问题呢?")]),_._v(" "),v("p",[_._v("首先, Redis 的主从切换机制是解决不了这个问题的, 因为 Redis 的主从同步是异步的. 也就是说当拿到一个分布式锁的时候, "),v("strong",[_._v("这个锁还没有同步到从节点, 主节点就可能崩溃了")]),_._v(". 这个时候从节点被提升成主节点, "),v("strong",[_._v("里面并没有你的分布式锁, 所以别人就可以拿到分布式锁")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f6f9d0f84477275f7233a0f284809d99-20231223175002-srtkiq0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了解决这个问题, 就有了 Redlock 算法. 只需要掌握 Redlock 的基本概念就可以, 不需要深入去研究. 原因也很简单, 就是"),v("mark",[v("strong",[_._v("目前绝大部分公司使用的分布式锁, 都没有按照 Redlock 算法来实现, 因为 Redlock 成本高, 性能也比较差")])]),_._v(".")]),_._v(" "),v("p",[_._v("Redlock 的思想说起来也很简单, 用一句话概括就是"),v("strong",[_._v("多数原则")]),_._v(". 也就是说, "),v("strong",[_._v("加锁的时候要在多个独立的 Redis 节点上同时加锁. 当大多数节点都告诉你加锁成功的时候, 就说明加锁成功了")]),_._v(". 举例来说, 如果同时在 5 个节点上加锁, 那么大多数就意味着至少 3 个节点成功才算加锁成功.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/81c757c7f725601cf27ba8162d66fb7f-20231223175002-5l757z6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这个过程中, 假设锁过期时间是 10 秒, 加锁花了 1 秒钟, 那么就只剩下 9 秒钟. 如果加锁失败, 还要在所有的节点上释放锁. 比如 4 个节点成功了, 1 个节点超时了, 这种时候需要在 5 个节点上一起释放锁.")]),_._v(" "),v("p",[_._v("这个问题一般会在分布式锁面试的最后出现, 面试官可能会随口问一下, 看看你知不知道 Redlock 这回事.")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点2：性能优化")])]),_._v(" "),v("p",[_._v("其实分布式锁能够做的优化不多. 一个思路是优化 Redis 本身的性能, 另外一个思路是"),v("strong",[_._v("减少分布式锁的竞争")]),_._v(". 在高并发的环境下, 可以考虑使用 "),v("strong",[_._v("Singleflight 模式")]),_._v(" 来优化分布式锁.")]),_._v(" "),v("p",[_._v("Singleflight 模式前面已经接触过了. 在缓存模式里, Singleflight 模式可以"),v("strong",[_._v("确保同一个 key 在一个实例上, 只有一个线程去回查数据库")]),_._v(". 类似地, 在分布式锁中应用 Singleflight 模式则是为了确保针对同一个锁一个实例只有一个线程去获取分布式锁.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a348cd0ff31bb1ab3816663909b77f9c-20231223175002-ycj5oy0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("要想优化分布式锁的性能, 一方面是考虑优化 Redis 本身的性能, 比如启用单独的 Redis 集群, 这可以有效防止别的业务操作 Redis, 影响加锁和释放锁的性能. 另外一方面则是可以考虑减少分布式锁的竞争, 比如说使用 Singleflight 模式. 也就是针对同一把锁, 每个实例内部先选出一个线程去获得锁.")]),_._v(" "),v("p",[_._v("假设有 2 个实例, 每个实例上各有 10 个线程要去获得 key1 上的分布式锁. 在不使用 Singleflight 模式的情况下, 总共有 20 个线程会去竞争分布式锁. 但是在使用 Singleflight 模式之后, 最终只有 2 个线程去竞争分布式锁. 竞争越激烈, 这种方案的效果越好. 如果没什么并发的话, 那么就基本没什么效果.")])]),_._v(" "),v("p",[_._v("这里还有一种更加激进的优化方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("在实例拿到了分布式锁之后, 释放锁之前先看看本地有没有别的线程也需要同一把分布式锁. 如果有, 就直接转交给本地的线程, 进一步减少加锁和释放锁的开销. 这种优化手段同样是在竞争越激烈的场景, 效果越好.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cab4aa44f2a80c81b2e6e50a3af35b8f-20231223175002-wleoprv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("最后不要忘了补充一下, 也就是分布式锁不到逼不得已, 就不要使用.")]),_._v(" "),v("blockquote",[v("p",[_._v("分布式锁不管怎么优化, 都有性能损耗. 所以原则上来说, 能不用分布式锁就不用分布式锁.")])]),_._v(" "),v("p",[_._v("这句话也是为了引出下一个亮点, "),v("mark",[v("strong",[_._v("去分布式锁")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("亮点3：去分布式锁")])]),_._v(" "),v("p",[_._v("在一些场景下是可以考虑去掉分布式锁的. 严格来说, 应该是原本这些场景就不该用分布式锁, 现在是回归本源了.")]),_._v(" "),v("p",[_._v("那究竟怎么去分布式锁呢? 第一种思路: "),v("mark",[v("strong",[_._v("用数据库乐观锁来取代分布式锁")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("第一种思路就是可以尝试用数据库乐观锁来取代分布式锁. 比如一些场景是加了分布式锁之后执行一些计算, 最后更新数据库. 在这种场景下, 完全可以抛弃分布式锁, 直接计算, 最后计算完成之后, 利用乐观锁来更新数据库. 缺点就是没有分布式锁的话, 可能会有多个线程在计算. 但是问题不大, 因为只要最终更新数据库控制住了并发, 就没关系.")])]),_._v(" "),v("p",[_._v("还有另外一种思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("第二种思路是"),v("mark",[_._v("利用一致性哈希负载均衡算法")]),_._v(". 在使用这种算法的时候, 同一个业务的请求肯定发到同一个节点上. 这时候就没必要使用分布式锁了, "),v("mark",[_._v("本地直接加锁")]),_._v(", 或者用 Singleflight 模式就可以.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f9e3ae47f06e3c5361ebfdd9ef245787-20231223175002-ng59o4c.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-35"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-35"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节聊到了实现一个分布式锁要考虑的各种细节. 一个分布式锁在 Redis 上就是一个普通的键值对. 加锁的时候使用 SETNX 命令, 并且要考虑如果加锁没成功要等多久, 是轮询等待还是监听锁释放, 加锁超时怎么重试等问题.")]),_._v(" "),v("p",[_._v("为了防止锁持有者崩溃导致没有人释放锁, 都会给锁设置一个"),v("strong",[_._v("过期时间")]),_._v(", 这里要考虑怎么确定合理的过期时间. 不过就算是充分考虑到了"),v("strong",[_._v("各种异常情况")]),_._v(", 业务都还是有可能在过期时间到了的时候都还没执行完, 所以需要"),v("strong",[_._v("考虑续约")]),_._v(". 而续约本身也有可能失败, 那就要"),v("strong",[_._v("根据业务要求来决定是继续执行还是中断")]),_._v(". 中断业务一直是一个老大难的问题, 目前也只能是靠人在代码里面主动检测.")]),_._v(" "),v("p",[_._v("在"),v("strong",[_._v("释放锁的时候, 要考虑到中间 Redis 崩溃又恢复导致分布式锁被别人拿到了的情况, 所以在释放锁之前, 也要先检测是不是自己的锁")]),_._v(".")]),_._v(" "),v("p",[_._v("最后还给出了三个亮点内容, 第一个是 Redlock, 这个只需要有一个基本概念就可以了. 另外两个都是尝试优化性能, 优化分布式锁的性能主要是用 Singleflight 来减少竞争. 而优化系统本身的性能, 也就是尝试把分布式锁去掉, 可以考虑使用数据库乐观锁或者一致性哈希负载均衡来取代分布式锁.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/552d3b227dbecaf49261940d939f254f-20231223175002-x8r5mvz.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_38-缓存综合应用-怎么用缓存来提高整个应用的性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_38-缓存综合应用-怎么用缓存来提高整个应用的性能"}},[_._v("#")]),_._v(" 38-缓存综合应用:怎么用缓存来提高整个应用的性能?")]),_._v(" "),v("p",[_._v("今天来讨论一个话题--"),v("strong",[_._v("怎么优雅地使用缓存来提高整个应用的性能")]),_._v(".")]),_._v(" "),v("p",[_._v("面试中比较好用的就是高可用方案和高性能方案. 那么"),v("strong",[_._v("在高性能方案里面, 缓存就是一个绕不过的坎")]),_._v(".")]),_._v(" "),v("p",[_._v("但是大部分人在面试的时候, 缓存方案都比较朴素, 没有什么突出之处. 比如也就是用用 Redis, 使用 Redis 的确能够提高性能, 但毕竟使用 Redis 是一个入行三个月就能溜得飞起的技能, 并不能凸显你的能力. 所以今天就准备了一些比较有特色的缓存方案.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-38"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-38"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("ul",[v("li",[_._v("看看你所维护的业务有没有可以"),v("strong",[_._v("使用请求级别缓存或者会话级别缓存的场景")]),_._v(". 如果有可以在公司尝试优化一下, 并且注意比较优化前后的性能.")]),_._v(" "),v("li",[v("strong",[_._v("有没有使用过什么与众不同的缓存方案")]),_._v("? 如果没有的话, 可以尝试根据公司的业务特征来设计一些有特色的缓存方案.")]),_._v(" "),v("li",[v("strong",[_._v("业务里面有没有可能引入本地缓存的, 并且可以进一步引入一致性哈希负载均衡策略来提高缓存命中率和性能")]),_._v(".")])]),_._v(" "),v("p",[_._v("记住在面试缓存的时候, 除了要掌握前面的那些知识点以外, 还要有非常具体的缓存方案.")]),_._v(" "),v("p",[_._v("很多时候, 你出去面试缓存的时候显得干巴巴的, 就是因为在面试的时候缺乏具体的案例支撑或者细节不够. 就算是缓存里非常基础的知识, 都要有"),v("strong",[_._v("案例")]),_._v("来支撑.")]),_._v(" "),v("p",[_._v("最佳面试策略就是将缓存方案作为提高整个系统性能中的关键一环. 然后要围绕这个缓存方案讲清楚几点.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("为什么这么设计")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("缓存命中率多少")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("一致性问题你是怎么解决的")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("缓存命中的性能和未命中的性能差异是多少")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("实施这个缓存方案前的性能数据和实施这个方案之后的性能数据是多少")]),_._v("?")]),_._v(" "),v("li",[v("strong",[_._v("和业界的一般方案比起来, 这个方案有没有什么独特之处")]),_._v("?")])]),_._v(" "),v("p",[_._v("最后一点也就是缓存面试中的难点, 因为常规方案面试官已经见得太多了, 所以要想加深印象, 就得出奇制胜. 所以尽可能根据自己公司的业务特征, 在缓存上搞点不一样的东西出来.")]),_._v(" "),v("h5",{attrs:{id:"缓存方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存方案"}},[_._v("#")]),_._v(" 缓存方案")]),_._v(" "),v("h6",{attrs:{id:"一致性哈希-本地缓存-redis缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一致性哈希-本地缓存-redis缓存"}},[_._v("#")]),_._v(" 一致性哈希+本地缓存+Redis缓存")]),_._v(" "),v("p",[_._v("经过前面的学习, 你已经看到了一致性哈希和本地缓存结合的巨大威力, 相信你至少听过本地缓存和 Redis 缓存结合使用的案例. 所以这个一致性哈希 + 本地缓存 + Redis 缓存的方案就显得比较平庸了, 不过在面试时还是可以提一下的, 毕竟竞争对手的方案可能就是简单的本地缓存 + Redis 缓存的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我有一个接口, 性能要求十分苛刻. 最开始的时候, 只用了 Redis 缓存, 性能其实也还说得过去. 但是后面想要进一步提升性能的时候, 就只能考虑引入本地缓存. 而为了避免本地缓存命中率不高还有内存浪费的问题, 就进一步"),v("mark",[_._v("在客户端利用一致性哈希负载均衡算法, 确保同一个业务的请求总是落到同一个节点上")]),_._v(". 经过改进之后, 性能果然提高了 40%. 而且因为使用一致性哈希负载均衡, 所以本地缓存的命中率也很高.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bd40a37e50e05cc8ff88e28fc8ac25af-20231223175002-d37oxg8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个方案的好处就是"),v("strong",[_._v("适用性广泛")]),_._v(", 基本上"),v("mark",[v("strong",[_._v("只要使用了本地缓存和 Redis, 就可以在前面加一个一致性哈希负载均衡")])]),_._v(".")]),_._v(" "),v("p",[_._v("在使用这个方案的时候, 要记得深入讨论一下数据一致性的问题, 尤其是"),v("strong",[_._v("上线新节点会发生什么")]),_._v(". 这个问题在前面的内容里面已经讨论过了, 就不再重复了.")]),_._v(" "),v("h6",{attrs:{id:"redis缓存降级成本地缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#redis缓存降级成本地缓存"}},[_._v("#")]),_._v(" Redis缓存降级成本地缓存")]),_._v(" "),v("p",[_._v("前面提到过一个案例, 是使用一个廉价的 Redis 来作为备份. 一旦生产用的 Redis 崩溃了就直接替换到备份上. 实际上, 直接用本地缓存也可以. 但是这个本地缓存并不是为了性能, 而是在 Redis 崩溃之后作为"),v("strong",[_._v("容错")]),_._v(". 也就是在正常的情况下, 如果 Redis 运作良好, 那么查询的都是 Redis, 如果 Redis 里没有数据, 那就查询数据库.")]),_._v(" "),v("p",[_._v("但是"),v("strong",[_._v("如果 Redis 崩溃了, 或者说因为网络问题长时间连不上去, 就会启用本地缓存")]),_._v(". 这时候, 查询会先查询本地缓存, 本地缓存中没有数据, 就会查询数据库.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a69dcbc1a92a688c32b8f20c7279379c-20231223175002-yxuenot.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("正常用法都是先查询本地缓存, 再查询 Redis, 而这个方案反其道而行之, 能够达到出其不意的效果.")]),_._v(" "),v("p",[_._v("所以可以这样来介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我之前维护了一个强调高可用和高性能的服务. 这个服务最开始使用的缓存方案是比较典型的, 就是访问 Redis, 然后访问数据库. 后来有一次网络出了问题, 连不上 Redis, 导致压力瞬间都到了数据库上, 数据库崩溃.")]),_._v(" "),v("p",[_._v("我后面做了两个事情, 防止再一次出现类似的问题. 第一个事情就是在数据库查询上加上了限流. 另外一个事情就是引入了本地缓存. 但是本地缓存一开始是没有启用的. 我会实时监控 Redis 的状态, 一旦发现 Redis 已经崩溃, 就会启用本地缓存. 启用本地缓存之后, 好处是保住了数据库, 并且响应时间还是很好. 缺点就是本地缓存会面临更加严重的数据一致性问题.")])]),_._v(" "),v("p",[_._v("这时候就会发现, 这个方案好像又可以和哈希一致性负载均衡联系在一起.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了缓解这种数据不一致性的问题, 我进一步引入了一致性哈希负载均衡算法, 确保同一个业务的请求肯定落到同一个服务端节点上, 这样就可以提高本地缓存的命中率, 并且降低本地缓存的消耗.")])]),_._v(" "),v("p",[_._v("而怎么发现 Redis 崩溃了的问题, 同样可以借鉴在微服务部分判断节点健康与否的内容, 比如收到了大量的 Redis 超时响应, 就可以认为 Redis 已经崩溃. 当然在启用了本地缓存之后, 也要考虑实时监控 Redis 的情况, 一旦 Redis 恢复过来, 就要逐步放弃本地缓存.")]),_._v(" "),v("blockquote",[v("p",[_._v("在启用了本地缓存之后, 还要监控 Redis 的状态. 当 Redis 恢复过来, 就可以逐步将本地缓存上的流量转发到 Redis 上. 之所以不是立刻全部转发过去, 是因为刚恢复的时候 Redis 上面可能什么数据都没有, 导致缓存未命中, 回查数据库. 这可能会引起数据库的问题.")])]),_._v(" "),v("p",[_._v("这两个方案说到底就是 Redis 和本地缓存的灵活运用而已. 接下来看两个奇诡的方法: 请求级别缓存和会话级别缓存.")]),_._v(" "),v("h6",{attrs:{id:"请求级别缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#请求级别缓存"}},[_._v("#")]),_._v(" 请求级别缓存")]),_._v(" "),v("p",[_._v("所谓的请求级别缓存是指当请求返回响应的时候, 缓存也就失效了.")]),_._v(" "),v("p",[_._v("解释一下这种缓存的基本原理. 使用这种缓存方案的前提是, "),v("strong",[_._v("在一个请求里面会反复查询同一个数据多次")]),_._v(". 比如因为模块划分之后要恪守边界, 所以每个模块都会自己去调用接口来获得同一份数据.")]),_._v(" "),v("p",[_._v("那就可以考虑将数据和请求关联在一起, 做成"),v("strong",[_._v("一个在请求生命周期内有效的缓存")]),_._v(".")]),_._v(" "),v("p",[_._v("举例来说, 有两个模块, 一个是订单模块, 一个是支付模块. 这两个模块因为封装得都非常好, 所以它们都只需要传入一个 user_id, 这两个模块拿着 user_id 去查询对应的用户信息, 完成对应的业务.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/cb5261db69133325d77f5d5543041d5b-20231223175002-qzgoe86.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当没有使用请求级别缓存的时候, 它们一共发出两次数据库查询. 当用了请求级别缓存的时候, 订单模块查询到之后, 支付模块只需要直接用就可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/55134400ba72fb9711b096c0d06e9f9a-20231223175002-1s0kc2w.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个东西一般是需要特殊的中间件来支持的. 比如在 Java 里面可以直接借助 Request-Scope 的 Bean 来缓存数据. 而在 Go 里面可以借助 context.Context 来完成.")]),_._v(" "),v("p",[_._v("这时候你可能会问, "),v("strong",[_._v("为什么不直接使用缓存呢")]),_._v("? 比如本地缓存. 因为和本地缓存之类的方案比起来, "),v("strong",[_._v("请求级别的缓存不需要考虑一致性的问题")]),_._v(". 因为缓存数据在请求返回响应之后就无效了, 撑死了就是有人在处理这个请求的过程中修改了数据, 但是你并不知道. 而大多数的时候, 可能并不在意这么一点不一致.")]),_._v(" "),v("p",[_._v("不过总的来说, 这个方案的应用面还是比较狭窄的. 可以考虑在自己的业务里面找到了真实场景之后再来使用这个方案面试.")]),_._v(" "),v("p",[_._v("另一个方法是在请求级别上扩大了缓存的作用范围, 就是"),v("strong",[_._v("会话级别缓存")]),_._v(". 相比之下, 这个级别要更加实用一些.")]),_._v(" "),v("h6",{attrs:{id:"会话级别缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#会话级别缓存"}},[_._v("#")]),_._v(" 会话级别缓存")]),_._v(" "),v("p",[_._v("类似于请求级别缓存, 这个级别的缓存是在"),v("strong",[_._v("用户和系统的会话结束之后, 就失效")]),_._v("了.")]),_._v(" "),v("p",[_._v("简单来说, 就是"),v("strong",[_._v("把缓存做成类似于登录态里 Session 那种东西")]),_._v(", Session 结束了, 那么缓存的数据也失效了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/96c0e697bba8afae507149603254d794-20231223175002-o0zzg2o.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个在 Java 里面也很好落地, 因为 Java 的 Spring 支持 Session-Scope 的 Bean. 只需要把数据放到这种 Bean 里面就可以.")]),_._v(" "),v("p",[_._v("它的好处同样是数据一致性问题没那么严重. 它相当于在用户和系统保持会话的期间, 使用的数据始终是同一份. 比如说用户权限信息, 它对一致性的要求很高, 但是使用又非常频繁.")]),_._v(" "),v("p",[_._v("可以参考这段话, 然后根据自己的业务实际情况替换就可以.")]),_._v(" "),v("blockquote",[v("p",[_._v("我在做系统性能优化的时候, 发现系统有一个共同点, 就是经常需要查询权限信息, 来做鉴权. 但是经过分析, 我发现"),v("mark",[_._v("权限之类的信息在一个会话期间基本不可能修改")]),_._v(".")]),_._v(" "),v("p",[_._v("于是我就引入了一个会话级别的缓存, 系统先查询会话中缓存的权限信息, 找不到就去查询权限模块.")]),_._v(" "),v("p",[_._v("同时, 监听对用户权限信息的修改, 在发生修改之后, 直接清空会话中缓存的权限数据.")])]),_._v(" "),v("h6",{attrs:{id:"客户端缓存"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#客户端缓存"}},[_._v("#")]),_._v(" 客户端缓存")]),_._v(" "),v("p",[_._v("在微服务架构里面, 有些时候性能要求非常苛刻, 又或者对一致性要求不是特别高, 于是就会想在调用别人的微服务的时候把结果缓存下来. 等到下一次有类似的请求过来, 就可以直接用自己缓存的数据了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/467d1293a998e794fdffc07828b1c873-20231223175002-vlzjjii.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以沿用优化性能的思路.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我还优化过一个服务的接口. 这个服务有很多接口, 但是大部分接口都需要用到用户的信息, 所以就做了一个客户端缓存. 思路是这样的, 每次发起调用查询了用户的信息之后, 就会把它缓存起来, 设置一个比较短的过期时间, 比如一分钟. 后续如果需要这个数据的时候, 就先从缓存里拿数据, 如果缓存里没有数据, 再调用用户服务的接口. 这种做法最大好处的是省了一次微服务调用的开销.")])]),_._v(" "),v("p",[_._v("这里用的是用户信息作为例子, 可以换成自己的实际业务.")]),_._v(" "),v("p",[_._v("紧接着可以说一个面试官绝对想不到的亮点: "),v("strong",[_._v("自己缓存的话, 淘汰策略对自己的业务更加友好")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("和服务端缓存比起来, 这个方案还有一个意想不到的优点, 就是服务端的淘汰策略不会影响到我.")]),_._v(" "),v("p",[_._v("举个例子, 虽然服务端也缓存了数据, 但是因为服务端是给很多业务提供服务的. 那么就可能出现这种问题: 某个业务的查询相对业务的查询来说, 非常高频, 或者优先级更高, 导致服务端在淘汰键值对的时候, 总是优先淘汰我用的键值对.")]),_._v(" "),v("p",[_._v("那么就会出现, 服务端整体上缓存命中率很高, 但是我这个特定的业务方, 缓存命中率很低的问题. 而自己缓存的话, 淘汰的肯定就是这个业务不怎么需要的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/abde5d01cf44ea2b12d11f96b9223765-20231223175002-pltgexi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("总的来说, "),v("strong",[_._v("客户端缓存是一种反范式的用法, 因为它会加剧数据不一致的问题")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("这种用法也是一种反范式的用法. 因为按照正统的微服务理论来说, 应该是服务端缓存数据, 而不是在客户端缓存数据. 否则的话, 如果服务端接收到了请求, 修改了数据, 客户端这边是没有感知的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/916fa324a60c7c99bb2f90b9a4a9ac79-20231223175002-vhbxz17.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("为了解决这个问题, 我们又引入了一个变种, 也是在客户端这边缓存, 但这个缓存是服务端提供的依赖来管理的. 比如在 Java 这边, 引入服务端的 Jar 包, 服务端的 Jar 包会自己先查询缓存, 当缓存没有数据的时候, 才会真的发出请求到服务端.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/b154e53568e8d740d916954cf797e625-20231223175002-0tlzixc.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("正常来说, 除非同时是服务端的研发, 不然很难要求别的组或者别的部门来提供这样一个依赖.")]),_._v(" "),v("p",[v("strong",[_._v("客户端缓存还可以利用业务相关性")]),_._v("来进一步提升缓存的命中率和接口的性能.")]),_._v(" "),v("h6",{attrs:{id:"业务相关缓存预加载"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#业务相关缓存预加载"}},[_._v("#")]),_._v(" 业务相关缓存预加载")]),_._v(" "),v("p",[_._v("所谓的业务相关缓存预加载是指如果从业务上来看, 用户调用了 A 接口之后会很快调用 B 接口, 那就可以在 A 接口调用的时候把 B 接口用得上的数据缓存起来, 又或者在调用 A 接口的时候, 提前加载 B 接口的缓存.")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我还利用业务的关联性来优化过系统的性能. 在我的系统里面, 用户调用 A 接口之后, 大概率会调用 B 接口. 所以我就做了两件事, A 接口和 B 接口都需要的数据, 可以直接缓存起来. 如果 B 接口还需要一些额外的数据, 那么可以提前发起微服务调用, 拿到数据之后一起缓存起来.")]),_._v(" "),v("p",[_._v("后续用户真的调用了 B 接口, 就直接从缓存里拿数据, 性能很好. 就算没有调用 B 接口, 在缓存的时候, 设置的过期时间也很短, 也不会有什么问题.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fefe52af6d74d96979c4ee40fbba3841-20231223175002-vm6hua8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以进一步谈谈个人理解.")]),_._v(" "),v("blockquote",[v("p",[_._v("个人认为, 利用业务之间的关联性来缓存, 或者提前加载缓存数据, 是很好的优化性能的手段.")])]),_._v(" "),v("p",[_._v("这里提到了"),v("strong",[_._v("缓存预加载")]),_._v(", 那么面试官就可以继续追问下去.")]),_._v(" "),v("h6",{attrs:{id:"缓存预热和预加载"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存预热和预加载"}},[_._v("#")]),_._v(" 缓存预热和预加载")]),_._v(" "),v("p",[v("strong",[_._v("缓存预热或者预加载")]),_._v("有两种思路.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("在启动的时候, 就直接把缓存加载到缓存中")]),_._v(". 可以全量加载, 也可以只加载热点数据. 在使用这种策略的时候, 就要"),v("strong",[_._v("小心缓存雪崩")]),_._v("的问题.")]),_._v(" "),v("li",[_._v("启动之后, 不是立刻就打过来 100% 的流量, 而是先小比例地把流量打过来, 在处理这些请求的过程中, 缓存中的数据会慢慢加载好.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dfcf9c0d26abb8c1b4cdefbcd2657c80-20231223175002-9at30r4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以这么介绍这个方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我使用的本地缓存来优化性能的时候, 为了防止在节点刚启动的时候本地缓存中还没有数据, 导致性能抖动, 我引入了缓存预热的机制.")]),_._v(" "),v("p",[_._v("在节点刚启动的时候, 它的权重会很低. 这个时候基于权重的负载均衡就只会把少量流量转发过来. 而后在运行了一段时间之后, 这个节点的权重就会提高到正常数值. 这个时候负载均衡就会把正常水平的流量打过来.")])]),_._v(" "),v("p",[_._v("这个方案用于面试中的优点是它结合了基于权重的负载均衡策略, 所以就可以把话题引导到负载均衡那边.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-36"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-36"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("在讨论系统性的缓存方案的时候, 可以按照"),v("strong",[_._v("从前端到后端, 从微服务到数据库")]),_._v(", 每一个环节在缓存上做了些什么的思路来面试.")]),_._v(" "),v("ul",[v("li",[_._v("在前端部分, 用了什么和缓存有关的技术来提高性能? 比如缓存静态资源, 或者设置更长的缓存过期时间.")]),_._v(" "),v("li",[_._v("在 BFF 层, 也就是接入层, 可以利用 Session 这种东西来维持一个会话级别的缓存, 提高性能.")]),_._v(" "),v("li",[_._v("在发起微服务调用的时候, 可以考虑应用客户端缓存.")]),_._v(" "),v("li",[_._v("具体到某个服务上, 可以使用"),v("strong",[_._v("一致性哈希负载均衡策略 + 本地缓存 + Redis 缓存")]),_._v(". 但是在面试的时候要注意准备数据一致性的解决方案.")]),_._v(" "),v("li",[_._v("在任何第三方中间件上, 都可以通过调整它们的缓存设置来提高性能. 比如说在 MySQL 已经学到了通过调整 InnoDB 引擎里 buffer pool 的配置来提升性能了.")])]),_._v(" "),v("p",[_._v("在面试之前, 把整个方案好好整理出来. 这样面试就能做到有备无患, 回答也能做到井井有条.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1b45cb6aedc1df45bc024329e625762d-20231223175002-ktqyilo.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h3",{attrs:{id:"nosql"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#nosql"}},[_._v("#")]),_._v(" NoSQL")]),_._v(" "),v("h4",{attrs:{id:"_39-elasticsearch高可用-怎么保证elasticsearch的高可用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_39-elasticsearch高可用-怎么保证elasticsearch的高可用"}},[_._v("#")]),_._v(" 39-Elasticsearch高可用:怎么保证Elasticsearch的高可用?")]),_._v(" "),v("p",[_._v("今天开始要学习一个新的主题——NoSQL. 在这个主题里面, 先从 Elasticsearch 开始学起.")]),_._v(" "),v("p",[_._v("Elasticsearch 从面试的热度上来说, 肯定是比不过数据库, 缓存和消息队列. 但是 Elasticsearch 在中大型公司里面又非常常用, 这意味着如果你希望跳槽到一些比较大型的公司, 那么 Elasticsearch 还是有比较大的概率考到的.")]),_._v(" "),v("p",[_._v("就像之前说的, 目前互联网行业面试中间件的话, 就是"),v("strong",[_._v("高可用和高性能")]),_._v(". 而具体到每一个点, 又可以拆成两个方向.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("中间件是如何做到高可用/高性能的")]),_._v("?")]),_._v(" "),v("li",[_._v("你"),v("strong",[_._v("在实践中怎么做到高可用/高性能")]),_._v("?")])]),_._v(" "),v("p",[_._v("那么这一节就先来看"),v("strong",[_._v("高可用")]),_._v("这一个点, 并给出几个有亮点的提高可用性的方案, 让你在面试的时候赢得竞争优势. 在这里就不严格区分 Elasticsearch 还是 Lucene, 统一使用 Elasticsearch. 先来看看 Elasticsearch 中的节点角色.")]),_._v(" "),v("h5",{attrs:{id:"elasticsearch节点角色"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch节点角色"}},[_._v("#")]),_._v(" Elasticsearch节点角色")]),_._v(" "),v("p",[_._v("Elasticsearch 的节点可以分成很多种角色, "),v("strong",[_._v("并且一个节点可以扮演多种角色")]),_._v(". 这里列举几种主要的.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("候选主节点")]),_._v("(Master-eligible Node): 可以被选举为主节点的节点. 主节点主要负责集群本身的管理, 比如创建索引. 类似的还有仅投票节点(Voting-only Node), 这类节点只参与主从选举, 但是自身并不会被选举为主节点.")]),_._v(" "),v("li",[v("strong",[_._v("协调节点")]),_._v("(Coordinating Node): 协调节点负责协调请求的处理过程. 一个查询请求会被发送到协调节点上, 协调节点确定数据节点, 然后让数据节点执行查询, 最后协调节点合并数据节点返回的结果集. 大多数节点都会兼任这个角色.")]),_._v(" "),v("li",[v("strong",[_._v("数据节点")]),_._v("(Data Node): 存储数据的节点. 当协调节点发来查询请求的时候, 也会执行查询并且把结果返回给协调节点. 类似的还有热数据节点(Hot Data Node), 暖数据节点(Warm Data Node), 冷数据节点(Cold Data Node), 从名字就可以看出来, 它们只是用于存储不同热度的数据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/437f24e7d41ce3b5637275814338a101-20231223175002-zbbmbc3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("给节点设置不同的角色的原则就一条: "),v("strong",[_._v("有钱就专款专用, 没钱就兼任")]),_._v(". 兼任就是指一个节点扮演了多个角色. 意思是如果有钱有足够的资源, 那就不要让节点兼任. 如果没钱, 那就可以考虑兼任. 但是不管怎样, 兼任都有可能引起性能问题.")]),_._v(" "),v("p",[_._v("因此, 如果真的"),v("strong",[_._v("追求高性能高可用, 就还是让节点只扮演一个角色比较好")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"写入数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写入数据"}},[_._v("#")]),_._v(" 写入数据")]),_._v(" "),v("p",[_._v("在 Elasticsearch 中, 写入数据整体上是这样的:")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8157b61216e79876f316cff1894de0ea-20231223175002-ebea785.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("简单描述一下这个过程.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("文档首先被写入到 Buffer 里面, 这个是 Elasticsearch 自己的 Buffer")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("定时刷新到 Page Cache 里面. 这个过程叫做 refresh, 默认是 1 秒钟执行一次")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("刷新到磁盘中还会同步记录一个 Commit Point")]),_._v(".")])]),_._v(" "),v("p",[_._v("在图里面还可以注意到, 在"),v("mark",[v("strong",[_._v("写入到 Page Cache 之后会产生很多段(Segment), 一个段里面包含了多个文档. 文档只有写到了这里之后才可以被搜索到, 因此从支持搜索的角度来说, Elasticsearch 是近实时的")])]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("不断写入会不断产生段, 而每一个段都要消耗 CPU, 内存和文件句柄, 所以需要考虑合并")]),_._v(". 可以注意到, 这些段本身还在支持搜索, 因此在合并段的时候, 不能对已有的查询产生影响.")]),_._v(" "),v("p",[_._v("看到这里你应该觉得很熟悉, 因为在"),v("strong",[_._v("数据迁移里面也面临着同样的困难")]),_._v(". 所以, 即便不看源码都能猜到基本的过程.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("已有的段不动")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("创建一个新的段, 把已有段的数据写过去, 标记为删除的文档就不会写到段里面")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("告知查询使用新的段")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("等使用老的段的查询都结束了, 直接删掉老的段")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/bf7b55112853f732c1446cc26d0348b0-20231223175002-jyndwn7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么查询怎么知道应该使用"),v("strong",[_._v("合并段")]),_._v("了呢? 这都依赖于一个"),v("mark",[v("strong",[_._v("统一的机制, 就是 Commit Point. 可以理解成它里面记录了哪些段是可用的. 所以当合并段之后, 产生一个新的 Commit Point, 里面有合并后的段, 但是没有被合并的段, 就相当于告知了查询使用新的段")])]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"translog"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#translog"}},[_._v("#")]),_._v(" Translog")]),_._v(" "),v("p",[_._v("实际上, Elasticsearch 在写入的时候, 还要写入一个东西, 也就是 "),v("strong",[_._v("Translog")]),_._v(". 可以把这个看成是 MySQL 里和 redo log 差不多的东西. 也就是如果宕机了, "),v("strong",[_._v("Elasticsearch 可以用 Translog 来恢复数据")]),_._v(".")]),_._v(" "),v("p",[_._v("可以对比一下 MySQL 的写入过程和 Elasticsearch 的写入过程.")]),_._v(" "),v("ul",[v("li",[_._v("MySQL 写入的时候, 其实只是修改了内存里的值, 然后记录了日志, 也就是 binlog, redo log 和 undo log.")]),_._v(" "),v("li",[v("strong",[_._v("Elasticsearch 写入的时候, 也是写到了 Buffer 里, 然后记录了 Translog")]),_._v(".")])]),_._v(" "),v("p",[_._v("不同的是, Translog 是固定间隔刷新到磁盘上的, 默认情况下是 5 秒.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/669a23fdfd9ab728730c3c6eb6bb3da1-20231223175002-ecg1e7r.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("类似于在 MySQL 里讨论的, "),v("strong",[_._v("Translog 是只追加的, 也就是顺序写的, 所以效率非常高. 它只有在刷新到磁盘上的时候, 才会非常慢")]),_._v(".")]),_._v(" "),v("p",[_._v("这时候就会注意到, 就算有 Translog, "),v("strong",[_._v("还是有数据丢失的可能. 最差的情况下, 会丢失 5s 的数据")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"elasticsearch索引与分片"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch索引与分片"}},[_._v("#")]),_._v(" Elasticsearch索引与分片")]),_._v(" "),v("p",[_._v("在一般的语境下, 一个 Elasticsearch 的索引并"),v("strong",[_._v("不仅仅指倒排索引, 还包括了对应的文档")]),_._v(". 这个和关系型数据库下的语义是不同的.")]),_._v(" "),v("p",[v("strong",[_._v("Elasticsearch 的一个索引有多个分片, 每个分片又有主从结构")]),_._v(". 这种结构类似于分库分表. 作为类比, 可以这样理解.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("一个索引就是一个逻辑表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("分片就是分库分表")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("每个分片都有主从结构, 在分库分表里面, 一般也是用主从集群来存储数")]),_._v("据.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ab49d4b34d8f67128283ce58426da83d-20231223175002-pcc09u6.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[v("strong",[_._v("Elasticsearch 会尽量把分片分散在不同的节点上")]),_._v(", 这一点和 Kafka 尽量把分区分散在不同的 broker 上是一样的, 都是为了保证在节点崩溃的时候将影响最小化.")]),_._v(" "),v("p",[_._v("那么主分片崩溃之后, 是怎么选出新的主分片呢? 答案是"),v("strong",[_._v("主节点选择一个分片作为主分片")]),_._v(". 这有点类似于 Redis Sentinel 里面的机制, 如果主节点宕机了, 那么 Sentinel 会从从节点里面挑出来一个作为主节点.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-39"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-39"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("在面试前, 应该在公司内部收集好这些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司"),v("strong",[_._v("有没有使用 Elasitcsearch")]),_._v("? 用来解决什么问题?")]),_._v(" "),v("li",[_._v("你用的 Elasticsearch 的性能怎么样? 读写流量多大? 存储的数据量又有多大?")]),_._v(" "),v("li",[_._v("你"),v("strong",[_._v("创建的索引有多大? 多少个分片? 你是怎么确定分片数量的")]),_._v("?")]),_._v(" "),v("li",[_._v("你们公司有没有使用一些措施来保证 Elasticsearch 的可用性? 有没有用过 Elasticsearch 的网关?")]),_._v(" "),v("li",[_._v("你们公司的 Elasticsearch 有没有出过问题? 出了什么问题? 最终又是怎么解决的?")])]),_._v(" "),v("p",[_._v("如果你在一个小公司, 并且公司没有使用 Elasticsearch, 那可以通过各种途径收集一些使用 Elasticsearch 的基本案例, 这样在面试讲到一些理论的时候, 可以用这些案例来佐证.")]),_._v(" "),v("p",[_._v("因为这节具体讨论的是"),v("strong",[_._v("提高 Elasticsearch 的可用性")]),_._v(", 所以可以考虑把它纳入到你提高整个系统可用性方案中, 做成其中的一环. 可以在项目介绍的时候强调一下你的项目可用性的一个关键点就是 Elasticsearch, 从而打开话题.")]),_._v(" "),v("p",[_._v("和 Elasticsearch 相关的面试题目有很多, 比如:")]),_._v(" "),v("ul",[v("li",[_._v("你有没有用过 Elasticsearch? 用来解决什么问题?")]),_._v(" "),v("li",[_._v("你"),v("strong",[_._v("用 Elasticseach 的过程中, 有没有遇到什么问题")]),_._v("? 最终是如何解决的?")]),_._v(" "),v("li",[v("strong",[_._v("为什么说 Elasticsearch 是近实时的")]),_._v("?")]),_._v(" "),v("li",[_._v("Elasticsearch 的 flush 是指什么? refresh 又是指什么?")]),_._v(" "),v("li",[v("strong",[_._v("Elasticsearch 的写入过程是怎样的")]),_._v("?")])]),_._v(" "),v("h5",{attrs:{id:"基本思路-25"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基本思路-25"}},[_._v("#")]),_._v(" 基本思路")]),_._v(" "),v("p",[_._v("如果你是业务开发, 而且面试的不是什么架构师之类的岗位, 那么 Elasticsearch 的面试会简单很多, 基本上就是问一下 Elasticsearch 的基础知识. 比较关键的一部分已经在前置知识里面写了, 还有一部分和倒排索引有关的内容, 下节会仔细讲一讲.")]),_._v(" "),v("p",[v("strong",[_._v("Elasticsearch 最基本的可用性保障就是分片, 而且是主从分片")]),_._v(". 所以在遇到 Elasticsearch 是如何做到高可用这个问题的时候, 要先提到这一点.")]),_._v(" "),v("blockquote",[v("p",[_._v("Elasticsearch 高可用的核心是分片, 并且每个分片都有主从之分. 也就是说, 万一主分片崩溃了, 还可以使用从分片, 从而保证了最基本的可用性.")])]),_._v(" "),v("p",[_._v("然后要接着补充第二个 Translog 的作用.")]),_._v(" "),v("blockquote",[v("p",[_._v("而且 Elasticsearch 在写入数据的过程中, 为了保证高性能, 都是写到自己的 Buffer 里面, 后面再刷新到磁盘上. 所以为了降低数据丢失的风险, Elasticsearch 还额外写了一个 Translog, 它就类似于 MySQL 里的 redo log. 后面 Elasticsearch 崩溃之后, 可以利用 Translog 来恢复数据.")])]),_._v(" "),v("p",[_._v("紧接着可以尝试把话题引导到你准备的高可用方案中.")]),_._v(" "),v("blockquote",[v("p",[_._v("我维护的业务对可用性的要求比较高, 所以在 Elasticsearch 的基础上, 我还做了一些额外的优化, 来保证 Elasticsearch 的高可用.")])]),_._v(" "),v("h5",{attrs:{id:"elasticsearch高可用方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch高可用方案"}},[_._v("#")]),_._v(" Elasticsearch高可用方案")]),_._v(" "),v("p",[_._v("这里给出几个可行的实践方案, 可以进一步刷出亮点.")]),_._v(" "),v("h6",{attrs:{id:"限流保护节点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#限流保护节点"}},[_._v("#")]),_._v(" 限流保护节点")]),_._v(" "),v("p",[_._v("限流算是一个治标的策略, 但是它能够"),v("strong",[_._v("保证 Elasticsearch 不会因为突发大流量而直接崩溃")]),_._v(".")]),_._v(" "),v("p",[_._v("可以通过 Elasticsearch 的"),v("strong",[_._v("插件机制来实现自定义的限流策略")]),_._v(". 注意 Elasticsearch 集群本身提供了限流的功能, 并且也可以通过控制线程池大小和队列大小来间接实现限流的功能.")]),_._v(" "),v("p",[_._v("因此如果利用插件来提供限流功能的时候, 就一定要有特殊之处. 比如可以"),v("strong",[_._v("考虑结合 Elasticsearch 的内存使用率和 CPU 使用率设计一个限流策略")]),_._v(". 这个限流策略在微服务部分也提到过了.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我用 Elasticsearch 的插件机制设计过一个限流插件. 这个限流插件的功能就是根据 Elasticsearch 当前的内存使用率和 CPU 使用率来判断是否需要执行限流. 不管是内存使用率还是 CPU 使用率, 只要超过阈值一段时间, 就触发限流.")])]),_._v(" "),v("p",[_._v("这里面试官也会考察你怎么确定限流的阈值, 超过阈值多久才会触发限流, 限流之后怎么恢复等问题.")]),_._v(" "),v("p",[_._v("当然, 如果你会研发限流插件, 也可以用插件来实现熔断, 降级. 熔断比较好处理, 就是直接拒绝新的查询请求, "),v("strong",[_._v("但是降级这个就要考虑怎么降级了")]),_._v(". 如果能够知道不同查询的业务价值, 那就可以考虑触发降级的时候优先保障核心业务的请求, 但是把非核心的请求拒绝了.")]),_._v(" "),v("p",[_._v("总而言之, 之前在微服务学习到的熔断, 限流, 降级的思想, 在这里一样适用.")]),_._v(" "),v("p",[_._v("如果从来没有研发过 Elasticsearch 插件, 那么也可以考虑其他两种策略, 一种是在 "),v("strong",[_._v("Elasticsearch 之前加一个网关, 查询经过网关的时候会被限流, 熔断或者降级")]),_._v(". 当然引入代理也可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/eab9aae9887570c74b3b5b2b9d81eeb5-20231223175002-ima3yfe.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("目前市面上的这方面的产品不多, 比较成熟的就是极限网关. 所以建议用一种自己了解但是没有实践过的话术来说.")]),_._v(" "),v("blockquote",[v("p",[_._v("我还了解过 Elasticsearch 网关或代理, 希望能够借助这些产品来做 Elasticsearch 的治理. 比如说借助网关来做熔断, 限流, 降级这种, 但是市面上相关的产品比较少, 也担心引入网关之后的性能损耗, 所以最终并没有实施这个方案.")])]),_._v(" "),v("p",[_._v("另外一种是在客户端这边限流. 也就是"),v("strong",[_._v("各个业务方需要限制住自己的查询频率")]),_._v(", 防止把整个 Elasticsearch 打崩. 相比之下, 这种方式是最好落地的.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们这边为了保护 Elasticsearch, 在客户端这边都是做了限流的. 比如某个业务的查询都比较慢, 对 Elasticsearch 的压力很大, 那么限流的阈值就比较小.")])]),_._v(" "),v("p",[_._v("不过 Elasticsearch 设计之初就是为了支持高并发大数据的, 所以"),v("strong",[_._v("最佳方式还是要考虑扩容")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("不管如何, 限流都只能算是治标. 如果经常触发限流, 或发现 Elasticsearch 有性能问题, 那么还是要及时扩容的.")])]),_._v(" "),v("h6",{attrs:{id:"利用消息队列削峰"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#利用消息队列削峰"}},[_._v("#")]),_._v(" 利用消息队列削峰")]),_._v(" "),v("p",[v("strong",[_._v("在一些对数据实时性要求不高的场景下, 完全可以考虑在业务方和 Elasticsearch 中间加入一个消息队列")]),_._v(".")]),_._v(" "),v("p",[_._v("可以抓住关键字"),v("strong",[_._v("削峰和限流")]),_._v("来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我优化过我们业务的架构, 就是在数据同步到 Elasticsearch 之前, 加入一个消息队列来削峰. 在早期的时候都是双写, 一方面写数据库, 一方面写 Elasticsearch. 那么在业务高峰期, Elasticsearch 就会有性能瓶颈.")]),_._v(" "),v("p",[_._v("而实际上, 我们业务对实时性的要求不高. 在这种情况下, 我引入了消息队列. 业务方只是写入数据库就返回. 然后监听 binlog, 并且生成消息丢到 Kafka 上. 在这种情况下, Elasticsearch 空闲的话, 消费速率就高; 如果 Elasticsearch 性能比较差, 那么消费就比较慢. 这样就起到了削峰和限流的效果.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/13140ccfea580067c7610a677c8cb828-20231223175002-k6r1ic2.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("在这个架构的基础上, 还可以考虑"),v("strong",[_._v("引入降级")]),_._v(", 也就是在 Elasticsearch 真的有性能问题的时候, 关闭一部分消费者.")]),_._v(" "),v("blockquote",[v("p",[_._v("而在这个架构的基础上, 还做了一个简单的降级. 也就是我有两类消费者写入数据到 Elasticsearch. 一类是核心数据消费者, 一类是非核心数据消费者.")]),_._v(" "),v("p",[_._v("如果监控到 Elasticsearch 性能已经比较差了, 比如写入的时候会遇到超时问题, 那就把非核心数据消费者停下来. 等 Elasticsearch 恢复过来再启动.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1295e281d220cb19858bc9ba890ba337-20231223175002-flmefxq.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("甚至更加极端一点, 如果是在大促或者秒杀这种活动中, 可以"),v("strong",[_._v("把整个数据同步都停掉")]),_._v(", 让 Elasticsearch 只支持查询操作. 如果业务是电商类的, 那可以考虑使用这个策略.")]),_._v(" "),v("h6",{attrs:{id:"保护协调节点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#保护协调节点"}},[_._v("#")]),_._v(" 保护协调节点")]),_._v(" "),v("p",[_._v("在 Elasticsearch 里, 比较容易出现问题的还有"),v("strong",[_._v("协调节点")]),_._v(". "),v("strong",[_._v("协调节点就类似于分库分表代理, 它负责分发请求, 然后处理结果集")]),_._v(".")]),_._v(" "),v("p",[_._v("那可以预计到, 如果一个查询需要消耗非常多的资源, 就有可能把协调节点搞崩溃. 举个例子, 假如有一个查询命中了十个分片, 并且每个分片都返回了几万条数据, 那么协调节点本身的资源使用量一下就会上去, 甚至出现 CPU 100% 或者 OOM 等问题.")]),_._v(" "),v("p",[v("strong",[_._v("因此要保证 Elasticsearch 高可用就要考虑防止突发大请求打崩协调节点的问题")]),_._v(".")]),_._v(" "),v("p",[_._v("整个面试思路是层层递进的. 首先可以指出如果公司内部资源比较多, 那么可以考虑"),v("strong",[_._v("部署纯粹的协调节点")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("要想提高 Elasticsearch 的可用性, 就要想办法防止协调节点在遇到大请求的时候崩溃. 最简单的做法就是使用纯粹的协调节点. 比如专门部署一批节点, 只扮演协调节点的角色.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/081b69187ea820f3159f05d4c37a5b9d-20231223175002-s04znf8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个思路总体上属于钞能力的范畴, 所以可以接着补充怎么用好这些协调节点, 关键词就是"),v("strong",[_._v("隔离")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("如果整个 Elasticsearch 除了这种纯粹的协调节点, 还有一些兼任多个角色的协调节点, 那就还可以考虑使用隔离策略. 也就是如果客户端能够判定自己是大请求, 就将请求发送到纯粹的协调节点上, 否则发送到其他兼任的协调节点上.")]),_._v(" "),v("p",[_._v("这种做法的好处就是, 大请求即便把协调节点打崩了, 也只会影响到其他大请求. 但是占据绝大多数的普通请求, 并不会受到影响.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a2ea4929e52ee113c6ea8e6ddb97ec24-20231223175002-lb98vj5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种做法的好处是和隔离结合在了一起, 因此可以尝试把话题引导到"),v("strong",[_._v("隔离策略")]),_._v("上.")]),_._v(" "),v("p",[_._v("在一些技术实力很强的大厂, 它们还会"),v("strong",[_._v("对 Elasticsearch 进行二次开发")]),_._v(". 可以修改协调节点的逻辑, 让协调节点在资源快不足的时候, 直接拒绝这种大请求. 如果你在大厂, 可以了解一下自己公司有没有在这方面做优化.")]),_._v(" "),v("p",[_._v("可以在这个基础上进一步总结, 就是"),v("strong",[_._v("只使用单一角色的节点")]),_._v("以提高可用性.")]),_._v(" "),v("blockquote",[v("p",[_._v("在资源足够的情况下, 建议所有的节点都只扮演单一角色. 这样做不仅仅能够带来可用性的提升, 也能带来性能的提升.")])]),_._v(" "),v("h6",{attrs:{id:"双集群"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#双集群"}},[_._v("#")]),_._v(" 双集群")]),_._v(" "),v("p",[_._v("双集群算是一个很高级, 投入也很大的高可用方案.")]),_._v(" "),v("p",[_._v("最简单的方案就是直接使用付费的 CCR 跨集群复制, 这个基本上就不需要你操心. 不过这个也属于钞能力, 面试的时候简单提一下就可以.")]),_._v(" "),v("blockquote",[v("p",[_._v("提高 Elasticsearch 可用性还有一个方法, 就是使用双集群. 比如直接使用付费的 CCR 功能, 不过我司比较穷, 肯定是不愿意买的.")])]),_._v(" "),v("p",[_._v("在不使用这种付费功能的情况下, 就只能考虑自己做了. 这里有一个比较简单的方案, 假如有 A 和 B 两个集群, 那么基本思路就是这样的:")]),_._v(" "),v("ul",[v("li",[_._v("使用消息队列来保持双写.")]),_._v(" "),v("li",[_._v("在查询的时候, 优先使用 A 集群, 当确认 A 集群出了问题的时候, 切换到 B 集群.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9ffb423f52d70d987265e755d28b8555-20231223175002-q2wt72x.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("抓住关键词 "),v("strong",[_._v("消息队列双写")]),_._v(" 回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们采用的是一个比较简单的双集群方案. 就是写入的时候并不是直接写入到 Elasticsearch, 而是写入到消息队列, 而后启动两个消费者, 分别消费消息, 然后写到两个集群 AB 里面. 关键在于查询的时候, 要判断集群 A 有没有出问题, 出了问题就切换到集群 B.")])]),_._v(" "),v("p",[_._v("而怎么判断集群 A 是否已经出问题, 一样可以参考微服务中判断节点是否健康的部分, 思路都是类似的, 这里就不重复了.")]),_._v(" "),v("p",[_._v("具体怎么切换, 有两种思路. "),v("strong",[_._v("一种是使用的客户端切换, 一种是利用 DNS 机制切换")]),_._v(". 也就是正常情况下, 使用的 Elasticsearch 的连接信息, DNS 解析的时候返回的是集群 A 的 IP. 但是当触发了容灾切换的时候, DNS 解析得到的是集群 B 的地址.")]),_._v(" "),v("p",[_._v("在回答的时候可以选择其中任意一种, 这里以客户端为例来说一说.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了实现自动切换的效果, 我们对 Elasticsearch 的客户端进行了二次封装. 在封装之后, 正常情况下, 会访问集群 A. 同时客户端监控集群 A 的响应时间. 如果响应时间超出预期, 又或者返回了比较多超时响应, 客户端就会自动切换到集群 B 上.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fc1c782fafc07197e37c0287151yy77d-20231223175002-9g2hysn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-37"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-37"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节讨论的是 Elasticsearch 的高可用问题. 首先介绍了 Elasticsearch 中的节点角色, Elasticsearch 的写入过程, 以及 Elasticsearch 索引与分片的关系.")]),_._v(" "),v("p",[_._v("然后讲了四个提高 Elasticsearch 可用性的方案.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("限流保护节点")]),_._v(": 可以考虑使用 Elasticsearch 的插件机制, 网关或者在客户端限流. 也不仅仅是限流, 也可以用来熔断或者降级.")]),_._v(" "),v("li",[v("strong",[_._v("利用消息队列削峰")]),_._v(": 这个案例也可以用在消息队列的面试中.")]),_._v(" "),v("li",[v("strong",[_._v("保护协调节点")]),_._v(": 因为查询总是先到协调节点, 而后协调节点再分发个数据节点执行. 并且协调节点自己还要处理结果集, 所以它也是可用性的瓶颈. 最佳策略就是让部分节点只充当协调节点. 在这个基础上可以考虑根据请求大小, 业务价值来对协调节点进行分组与隔离")]),_._v(" "),v("li",[v("strong",[_._v("双集群")]),_._v(": 大部分时候, 只有不差钱的公司才会考虑为了一点点的可用性提升而引入双集群, 这里介绍了钞能力 CCR 方案和使用消息队列完成双写的双集群方案.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a070ed9cc66395bcc22a3057bc7945ec-20231223175002-hl3szby.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_40-elasticsearch查询-怎么优化elasticsearch的查询性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_40-elasticsearch查询-怎么优化elasticsearch的查询性能"}},[_._v("#")]),_._v(" 40-Elasticsearch查询:怎么优化Elasticsearch的查询性能?")]),_._v(" "),v("p",[_._v("今天学习 Elasticsearch 的另外一个关键主题--"),v("strong",[_._v("高性能")]),_._v(".")]),_._v(" "),v("p",[_._v("如果你经常和 Elasticsearch 打交道, 你十有八九遇到过 "),v("strong",[_._v("Elasticsearch 的性能问题")]),_._v(". 这也就是为什么在面试中"),v("strong",[_._v("经常会遇到 Elasticsearch 性能优化相关的问题")]),_._v(". 今天就看看怎么优化 Elasticsearch 的性能, 在面试中赢得竞争优势.")]),_._v(" "),v("p",[_._v("先来看 Elasticsearch 的索引机制, 它是理解 Elasticsearch 原理的关键.")]),_._v(" "),v("h5",{attrs:{id:"elasticsearch的索引机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch的索引机制"}},[_._v("#")]),_._v(" Elasticsearch的索引机制")]),_._v(" "),v("p",[_._v("Elasticsearch 的索引与数据库索引比起来, 还是有很大不同的, 它使用的是"),v("mark",[v("strong",[_._v("倒排索引")])]),_._v('. 所谓的倒排索引是相对于 "正排" 索引而言的. '),v("strong",[_._v("在一般的文件系统中, 索引是文档映射到关键字, 而倒排索引正相反, 是从关键字映射到了文档")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/db5821d3c177ba83963442c6c8fd56cd-20231223175002-2flk8dv.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v('所以可以想到, 假如没有倒排索引, 想要找到包含关键字 "Elasticsearch" 的文档, 那么需要遍历所有的文档, 然后筛选出包含了 "Elasticsearch" 关键字的文档. 而有了倒排索引, 就可以直接从关键字出发, 找到 "Elasticsearch" 关键字对应的文档.')]),_._v(" "),v("p",[v("strong",[_._v("Elasticsearch 依赖于 Lucene 来维护索引")]),_._v(", 它的基本原理也很简单.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("每当写入一个新的文档的时候, 根据文档的每一个字段, Elasticsearch 会使用分词器, 把每个字段的值切割成一个个关键词, 每一个关键词也叫做 Term")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("切割之后, Elasticsearch 会统计每一个关键词出现的频率, 构建一个关键词到文档 ID, 出现频率, 位置的映射, 这个也叫做 posting list")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/783b9379ce3343539e47538931f74da1-20231223175002-gaiw13z.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("从图片里可以看出来几个关键点.")]),_._v(" "),v("ul",[v("li",[_._v("每个字段其实是"),v("strong",[_._v("分散统计")]),_._v("的.")]),_._v(" "),v("li",[v("strong",[_._v("Elasticsearch 记录了两个位置信息, 一个位置是指它是第几个词, 另外一个偏移量是指整个关键词的起始位置")]),_._v(".")])]),_._v(" "),v("p",[_._v("可以想到, 存在 Elasticsearch 里的文档数不胜数, 那就意味着"),v("strong",[_._v("一个字段会有非常多的关键词")]),_._v(". 比如图片里的 desc 字段, 如果系统有一亿用户, 每个人写的内容都不一样, 关键词就会非常多.")]),_._v(" "),v("p",[_._v("假如要查询的是 desc 里包含 Hello 这个关键字的文档, 首先就要在关键词表格里面找到 Hello 这一条. 如果关键词都是随机的, 那么肯定很难找. 如果让你来设计, 你肯定会让 Elasticsearch 把这些"),v("strong",[_._v("关键词排序")]),_._v(", 比如说按照字母来排序.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8fdf66553bd000487331a9af23f25417-20231223175002-3r8emc5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("当然, Elasticsearch 的设计者明显要高明很多. 这种类似于查找单词的东西, 在业界早就有成熟的方案, 那就是"),v("mark",[v("strong",[_._v("前缀树(Trie Tree)")])]),_._v(' , 也叫做字典树, 而这个 "关键词表格" 在 Elasticsearch 里面叫做 '),v("strong",[_._v("Term Dictionary")]),_._v(". 它们的目标是"),v("strong",[_._v("尽可能地把全部关键词组成的索引整个装进内存里")]),_._v(". 之所以是尽可能, 而不是一定, 是因为部分字段的关键词会非常多, 确实装不进去. 所以连前缀树都觉得这样的空间开销受不了.")]),_._v(" "),v("p",[_._v("而 Elastiscearch 更进一步, 用了一个优化, 就是所谓的 "),v("strong",[_._v("FST")]),_._v("(Finite State Transducers). "),v("strong",[_._v("这个 FST 的核心思想是连公共前缀, 后缀也一并压缩了")]),_._v(". 真正的 FST 原理还是相当复杂的, 下面给一个非常直观的例子, 就能懂其基本的概念了.")]),_._v(" "),v("p",[_._v("假如现在有两个关键词 cat 和 ct, 两种数据结构看起来是这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dd4539e68e797fb64908b8874a56c63c-20231223175002-2tyw6d3.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这个图更加接近真实数据结构的定义, 所以有点难以理解. 可以认为当找到 3 的时候, 如果是经过 0-1-3, 那么知道前缀是 ct, 并且能够得到 ct 在 Term Dictionary 的位置.")]),_._v(" "),v("p",[_._v("这个位置, 就是这个 ct 所在的 "),v("strong",[_._v("Block")]),_._v(". 但是也可以想到, 可能还有别的关键词 cta, ctb 等, 都是使用这个前缀的. "),v("strong",[_._v("如果几千个关键词都共享某个前缀, 在一个 Block 内部怎么找")]),_._v("?")]),_._v(" "),v("p",[_._v("其实 Elasticsearch 会在 Block 内部有很多的关键词的时候, 进一步切割成所谓的 "),v("strong",[_._v("Floor Block")]),_._v(". 每个 Floor Block 使用第一个关键词的首字母来加快查找.")]),_._v(" "),v("p",[_._v("而在 Block 或者 Floor Block 内部, 都是"),v("strong",[_._v("通过遍历来查找对应的关键词的")]),_._v(". 因此整个结构看起来是下面这样的.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/1aea13d83dbe83f5798ff822bfcdcd25-20231223175002-jfwfgd7.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("因此可以把这个查找关键词的过程理解成两步.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("根据 FST 找到 Block")]),_._v(".")]),_._v(" "),v("li",[v("strong",[_._v("在 Block 里面遍历找到关键词")]),_._v(". 如果 Block 进一步细分为 Floor Block, 就先根据前缀找到 Floor Block, 然后再去遍历 Floor Block.")])]),_._v(" "),v("p",[_._v("找到了关键词, 也就找到了这个关键词对应的 posting list, 那就可以根据文档 ID 来找到具体的文档了.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-40"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-40"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("除了刚刚说的这些基础知识, 还要了解清楚公司内部一些和 Elasticsearch 有关的数据.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司 Elasticsearch 是如何部署的, 有几个节点, 每个节点上面的内存有多大, 这些内存是怎么分配的?")]),_._v(" "),v("li",[_._v("你们公司 Elasticsearch 上 JVM 的配置是什么, 垃圾回收用的是哪个, 垃圾回收停顿的时间有多长?")]),_._v(" "),v("li",[_._v("你们"),v("strong",[_._v("公司 Elasticsearch 的哪些配置和默认值不一样")]),_._v(", 为什么修改?")]),_._v(" "),v("li",[_._v("你们公司 Elasticsearch 的性能怎么样, 能撑住多大的读写流量?")])]),_._v(" "),v("p",[_._v("如果你本身对 Elasticsearch 性能优化不是很了解的话, 不是特别建议在简历或自我介绍的时候提起 Elasticsearch 性能优化. 但是如果你很擅长, 那就可以特意强调一下.")]),_._v(" "),v("p",[_._v("应该说, 能用好数据库, Redis 和消息队列的人很多, 但能用好 Elasticsearch 的人就很少. 如果非常了解怎么优化 Elasticsearch, 平时也做过一些优化, 在面试的时候就一定要提起这一点, 这是非常大的竞争优势.")]),_._v(" "),v("h5",{attrs:{id:"优化方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化方案"}},[_._v("#")]),_._v(" 优化方案")]),_._v(" "),v("p",[_._v("面试的时候并不需要记住全部的优化方案, 而是可以尝试记住里面几个典型的, 或者根据这里写出来的思路, 结合自己的业务设计几个面试方案.")]),_._v(" "),v("p",[_._v("实际上, Elasticsearch 里可以优化的点非常多, 这里筛选出了比较适合面试的方案. 有一些优化的点就是简单调整一下参数, 又不能引导到别的话题, 这里就没有罗列出来.")]),_._v(" "),v("h6",{attrs:{id:"优化分页查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化分页查询"}},[_._v("#")]),_._v(" 优化分页查询")]),_._v(" "),v("p",[v("strong",[_._v("这个优化思路是很好的面试点, 因为它可以和分库分表结合在一起")]),_._v(". 在分库分表的那一节深入讨论了分页查询为什么性能那么差, 而在 Elasticsearch 里面也一样有这个问题. 在 Elasticsearch 里面, 当执行分页查询的时候, 是使用 "),v("code",[_._v("FROM X SIZE Y")]),_._v("​ 的语法, 基本等同于 SQL 里的 "),v("code",[_._v("OFFSET X LIMIT Y")]),_._v("​. 也就是说, 如果查询命中了 Elasticsearch 的 N 个分片, 那么最终查询的数据量是 "),v("code",[_._v("N * (X + Y)")]),_._v("​.")]),_._v(" "),v("p",[_._v("在 Elasticsearch 里面, 也有两种可行的优化手段.")]),_._v(" "),v("ol",[v("li",[v("strong",[_._v("Scroll 和 Scroll Scan")]),_._v(": 这种方式适合一次性查询大量的数据, 比如导出数据之类的场景. 这种用法更加接近在别的语言或者中间件里面接触到的游标的概念.")]),_._v(" "),v("li",[v("strong",[_._v("Search After")]),_._v(": 也就是翻页, 在查询的时候需"),v("strong",[_._v("要在当次查询里面带上上一次查询中返回的 search_after 字段")]),_._v(".")])]),_._v(" "),v("p",[_._v("在面试的时候, 建议使用 Search After 来回答, 因为 Search After 适用的场景更加广泛.")]),_._v(" "),v("blockquote",[v("p",[_._v("我还优化过 Elasticsearch 的分页查询, 也就是用 Search After 来优化的. Search After 就有点类似于分库分表中使用的禁用跳页查询的方案, 也就是不支持随机翻页. "),v("mark",[_._v("每次查询都带上上一次查询的 search_after 字段")]),_._v(".")]),_._v(" "),v("p",[_._v("它的优点就是查询的数据量不再和偏移量有关, 只和每一页的大小, 以及命中的分片数量有关. 之前我在分库分表里面也优化过类似的分页查询, 不过分库分表本身没有 search_after 之类的字段, 只能是我自己在业务层面上搞出来一个类似的 search_after.")])]),_._v(" "),v("p",[_._v("注意, 这里的 search_after 就类似于分库分表中禁用跳页查询里面加入的 "),v("code",[_._v("WHERE id > $max_id")]),_._v("​ 这种极值过滤条件.")]),_._v(" "),v("h6",{attrs:{id:"增大刷新间隔"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#增大刷新间隔"}},[_._v("#")]),_._v(" 增大刷新间隔")]),_._v(" "),v("p",[_._v("上一节已经学到了"),v("strong",[_._v("数据最开始是写入到 Buffer 中, 然后经过 refresh 才被写入到 Page Cache")]),_._v(". 那么基本上可以预计, 如果频繁地把数据刷新到 Page Cache 里, 性能会有损耗. 因此一个比较简单的优化方案就是"),v("strong",[_._v("调大这个刷新间隔")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我优化 Elasticsearch 的时候, 把 index.refresh_interval 调大到了 30. 调整之后, 性能大概提升了 20%.")])]),_._v(" "),v("p",[_._v("可以尝试在自己的业务里面调整这个参数, 看看性能提升的幅度.")]),_._v(" "),v("h6",{attrs:{id:"批量提交"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批量提交"}},[_._v("#")]),_._v(" 批量提交")]),_._v(" "),v("p",[_._v("这也是在前面的内容里面见过的优化手段, 记得复习一下之前对批量提交为什么能提高性能的分析, 在面试 Elasticsearch 的时候一样用得到.")]),_._v(" "),v("p",[_._v("批量提交也有两种策略. 第一种策略是"),v("strong",[_._v("化单个为批量")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("早期我有一个业务, 就是把数据库里的数据同步到 Elasticsearch. 最开始的时候是每次用户更新了数据, 就直接更新 Elasticsearch. 但这样效果很不好, 因为用户基本上都是一条条数据更新.")]),_._v(" "),v("p",[_._v("后来我考虑到这个业务对数据一致性的要求不是很高, 我就把实时同步修改成了异步同步, 也就是定时扫描数据库中发生变化的数据, 然后批量提交变更数据到 Elasticsearch. 这个异步任务是每秒钟同步一次, 和原来每一次写请求都要操作 Elasticsearch 比起来, 压力小多了. 同时业务方的响应时间也下降了 50%.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d577326d07bef64d0d4fd9e987ef4a1a-20231223175002-ksv2nad.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种单个转批次的方案还可以用在 Kafka 和 Elasticsearch 结合使用的方案中. 也就是"),v("strong",[_._v("有些公司的架构把数据写入到 Elasticsearch 的时候, 并不是直接写入的, 而是统一写入到 Kafka, 然后再由一些消费者把 Kafka 里的数据写入到 Elasticsearch")]),_._v(".")]),_._v(" "),v("p",[_._v("这里就可以给出一个"),v("strong",[_._v("利用批量提交来解决消息积压问题")]),_._v("的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司的很多业务都不是直接同步数据到 Elasticsearch, 而是要经过一个 Kafka, 然后由 Kafka 的消费者把数据写入到 ElasticSearch. 但随着业务的增长, 越来越多的数据要写入到 Elasticsearch, 尤其是在业务高峰期, 很容易产生消息积压的问题.")]),_._v(" "),v("p",[_._v("为了解决这个问题, 我做了一个优化, 就是批量消费, 批量提交到 Elasticsearch. 也就是说, 早期 Kafka 的消费者是每次消费一条消息, 就写一条数据到 Elasticsearch. 而现在改成了一次拉取 100 条消息(这个应该是可配置的), 做成一个批次, 提交给 Elasticsearch, 就解决了消息积压的问题.")])]),_._v(" "),v("p",[_._v("这个方案的好处就是能够把消息积压和 Elasticsearch 的知识点联系在一起, 能够从这个案例里看出你的思维很灵活. 当然这也会将话题引导到 Kafka 或者消息积压上, 要记得复习.")]),_._v(" "),v("p",[_._v("另外一个是 "),v("strong",[_._v("调整批次")]),_._v(". 这一类手段非常适合用在日志同步中, 这里给出一个"),v("strong",[_._v("调整批次和降级的方案")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司的日志都是要利用 Logstash 直接同步到 Elasticsearch 的. 那么在业务繁忙的时候, 日志就有可能同步得很慢, 或者 Elasticsearch 压力很大. 在这种情况下, 我把日志同步到 Elasticsearch 的批次调大了一些, 显著降低了 Elasticsearch 的负载.")]),_._v(" "),v("p",[_._v("而且, 我还引入了一个降级机制. 正常公司的日志是全量同步的, 但如果发现 Elasticsearch 有问题, 就会触发降级, 触发降级的时候就会先丢弃 INFO 级别的日志. 运行一段时间之后, 如果 Elasticsearch 还是没能恢复正常, 就把 WARN 级别的也丢弃.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f1b6e3daa4c0dda7a4f8935db2dd591a-20231223175002-43xpofm.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这一个方案亮点在于"),v("strong",[_._v("把调整批次和降级结合在一起")]),_._v(", 能体现综合运用各种手段解决实际问题的能力.")]),_._v(" "),v("h6",{attrs:{id:"优化不必要字段"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化不必要字段"}},[_._v("#")]),_._v(" 优化不必要字段")]),_._v(" "),v("p",[_._v("有些时候, 最开始设计索引的人可能没有注意, 就把一些根本不会搜索到的字段也存储到了 Elasticsearch. 更加可怕的是还使用了动态的 mapping, 这可能无意间索引了很多新字段.")]),_._v(" "),v("p",[_._v("在"),v("mark",[v("strong",[_._v("实践中最常见的错误, 就是把数据库里存储的数据全量同步到 Elasticsearch 上. 但是其实根本没有必要")])]),_._v(". 所以这种"),v("mark",[v("strong",[_._v("优化手段就是只把要被查询的字段同步到 Elasticsearch 上, 而把数据的主体部分留在原本的数据库里")])]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我接手的一个历史系统需要把数据同步到 Elasticsearch 上支持搜索. 但最开始的时候数据量并不是很大, 所以直接把全量数据同步到了 Elasticsearch 上的. 后面业务起来之后, 就发现这个业务的数据占据了大量的内存和磁盘空间.")]),_._v(" "),v("p",[_._v("我在梳理了业务之后发现其实不用全部同步过去的, 因为要被搜索的字段只是其中的一小部分, 而另外一些字段同步过去只是白白加重了 Elasticsearch 的负担. 所以后面就修改了同步的过程, 那一部分数据就直接传入 null 了. 查询过程就相当于在 Elasticsearch 上根据各种输入查到业务的主键, "),v("mark",[_._v("如果还需要 Elasticsearch 中没有的字段, 就回数据库再次查询")]),_._v(".")]),_._v(" "),v("p",[_._v("当然, 这样做的代价就是有一些查询需要再次查询数据库. 但是评估后发现受影响的请求不足 10%, 所以这个结果还是可以接受的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a74b74de9162b9896ab98efb7022ce6b-20231223175002-qtlrhi4.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("少同步一些数据, 就意味着索引所需的内存, 磁盘更少, 所以查询速度也会更快. 紧接着补充一个 reindex 的改进计划.")]),_._v(" "),v("blockquote",[v("p",[_._v("不过后续我也在考虑重新创建一个索引, 现在这种有字段但是不同步数据的方式不太优雅.")])]),_._v(" "),v("p",[_._v("这种同步部分数据的手段, 在日志检索中也很常见. 毕竟日志一般都非常长, 而搜索一般都是根据业务 ID 之类的来查询.")]),_._v(" "),v("p",[_._v("还可以尝试在这个地方把话题引导到分库分表中间表上.")]),_._v(" "),v("blockquote",[v("p",[_._v("这种二次查询类似于分库分表中利用中间表来支持一些无分库分表键查询的解决方案, 都是要先在一个地方用查询条件拿到主键或者分库分表键, 然后再到具体的数据库上查询到完整的数据.")])]),_._v(" "),v("h6",{attrs:{id:"冷热分离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#冷热分离"}},[_._v("#")]),_._v(" 冷热分离")]),_._v(" "),v("p",[_._v("冷热分离应该算是一个业界非常常用的方案了. 它的基本思路是"),v("strong",[_._v("同一个业务里面数据也有冷热之分")]),_._v(". 对于"),v("strong",[_._v("冷数据来说, 可以考虑使用运行在廉价服务器上的 Elasticsearch 来存储; 而对于热数据来说, 就可以使用运行在昂贵的高性能服务器上的 Elasticsearch")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我在公司的时候做过一个 Elastisearch 优化, 就是冷热数据分离存储. 数据最开始都是存在统一规格的 Elasticsearch 上, 然后这两年经济不太好, 就想着降本增效, 于是就决定试试业界用得比较多的冷热分离方案.")]),_._v(" "),v("p",[_._v("基本的思路是整个 Elasticsearch 的节点分成冷热两类, 数据最开始都是写入到热节点上. 等过一段时间之后, 数据已经不热了, 就迁移到冷节点上.")]),_._v(" "),v("p",[_._v("这部分是借助了新出来的索引生命周期特性来实现的. 比如"),v("mark",[_._v("日志就是三天内的数据都在热节点上, 三天之后就是迁移到了冷节点上. 这个过程都是自动的, 不需要人工介入")]),_._v(".")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/54593b79e7134bcf8a12bd3d58191599-20231223175002-zz2j7pi.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("利用生命周期管理功能实现冷热数据分离操作起来还是很简单的, 可以考虑通过 Kibana 来直接在界面傻瓜式操作. 而且一些云服务厂商也提供了这种功能, 使用起来都很便捷.")]),_._v(" "),v("p",[_._v("建议在实践中操作一下再出去面试, 最好是根据自己的业务来定制. 比如前面的回答里用的是日志的例子, 那么可以把它替换成自己的业务数据.")]),_._v(" "),v("p",[_._v("这种冷热分离的思路不仅仅可以在 Elasticsearch 中使用, 在微服务治理, 缓存中也多次提到过类似的思路, 所以如果有机会, 可以尝试引导话题.")]),_._v(" "),v("h5",{attrs:{id:"其他常规优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#其他常规优化"}},[_._v("#")]),_._v(" 其他常规优化")]),_._v(" "),v("p",[_._v("这部分之所以叫做常规优化, 是因为正常生产环境上的 Elasticsearch 都优化过了, 因此可以简要说明一下.")]),_._v(" "),v("h6",{attrs:{id:"优化垃圾回收"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化垃圾回收"}},[_._v("#")]),_._v(" 优化垃圾回收")]),_._v(" "),v("p",[_._v("如果你本身是 Java 开发, 那么非常建议使用这个优化. 就像在 Kafka 里面提到的, 面试 Java 岗位很重要的一点就是展示你在 JVM 上的深厚功力.")]),_._v(" "),v("p",[_._v("一般 Elasticsearch 优化垃圾回收的第一个思路就是"),v("strong",[_._v("调整垃圾回收算法")]),_._v(". Elasticsearch "),v("strong",[_._v("需要一个很大的堆")]),_._v(", 那么 CMS 是肯定撑不住的, 停顿时间会非常长.")]),_._v(" "),v("p",[_._v("所以可以考虑把垃圾回收算法换成 G1, 或者更加激进的 ZGC. 现在用 G1 比较多, 所以可以尝试用 G1 来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("长期以来我们使用 Elasticsearch 有一个很大的问题, 就是触发垃圾回收的时候, 停顿时间比较长, 会有一百多毫秒. 这主要是因为 Elasicsearch 用的都还是非常古老的 CMS, 而 CMS 在超过 8G 的堆上面, 表现就比较差.")]),_._v(" "),v("p",[_._v("所以后面就尝试将 Elasticsearch 换成了 G1, 换了之后效果是非常不错, 现在停顿时间都可以控制在 15ms 以内. 不过我也在调研 ZGC, ZGC 在特大堆上的表现比 G1 还要好. 不过目前这方面业界的实践不多, 所以也没有进一步优化.")])]),_._v(" "),v("p",[_._v("使用这个方案的核心就是把话题引导到垃圾回收这个主题上.")]),_._v(" "),v("h6",{attrs:{id:"优化swap"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化swap"}},[_._v("#")]),_._v(" 优化swap")]),_._v(" "),v("p",[_._v("之前在讨论 Kafka 的时候就提到过优化 swap 这个措施.")]),_._v(" "),v("p",[_._v("Elasticsearch 也是一个"),v("strong",[_._v("内存依赖非常严重的中间件")]),_._v(", 在触发了 swap 的时候, 性能下降得很快. 有两种做法, 第一种做法是在操作系统层面上直接禁用了 swap, 或者把 vm.swappness 设置成一个非常小的值. 第二种做法是在 Elasticsearch 里把 bootstrap.memory_lock 设置成 true.")]),_._v(" "),v("p",[_._v("在面试的时候要注意把 Elasticsearch 和其他中间件联系在一起, 这里以 Kafka 为例来说一说.")]),_._v(" "),v("blockquote",[v("p",[_._v("使用 Elasticsearch 的时候要把 swap 禁用, 或者把 vm.swappness 设置得很小, 也可以把 bootstrap.memory_lock 设置成 true. 所有类似于 Elasticsearch 的中间件都可以采用这种优化手段, 比如说 Kafka.")])]),_._v(" "),v("h6",{attrs:{id:"文件描述符"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#文件描述符"}},[_._v("#")]),_._v(" 文件描述符")]),_._v(" "),v("p",[v("strong",[_._v("Elasticsearch 需要非常多的文件描述符, 所以正常来说都需要把文件描述符的数量调大, 比如说调到 65536")]),_._v(", 甚至更多.")]),_._v(" "),v("p",[_._v("可以用解决 Bug 的思路来面试, 比如面试官问到遇到过 Elasticsearch 什么 Bug 的时候, 就可以用这个来回答.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我们在使用 Elasticsearch 的时候, 还遇到过文件描述符耗尽的问题. 这是因为我们用的是一个非常大的 Elasticsearch, 很多业务共用, 导致 Elasticsearch 打开的文件描述符非常多.")]),_._v(" "),v("p",[_._v("那一次的故障之后, 一方面是调大了最大文件描述符的数量, 另外一方面也是考虑把业务逐步迁移到不同的 Elasticsearch 上. 毕竟这一次故障, 直接导致了好几个核心业务都出问题了, 足以说明还是要考虑隔离的.")])]),_._v(" "),v("p",[_._v("这个回答还可以把话题引导到微服务的隔离上去.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-38"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-38"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("经过前面 MySQL 优化, Redis 优化, Kafka 优化, 再加上这节的 Elasticsearch 优化, 其实可以总结出"),v("mark",[v("strong",[_._v("一般性的性能优化方案")])]),_._v(".")]),_._v(" "),v("p",[_._v("实际上任何查询, 不管是关系型数据库还是非关系型数据的查询, 优化起来就是这几个方向.")]),_._v(" "),v("ul",[v("li",[v("mark",[v("strong",[_._v("优化查询本身")])]),_._v(": 这可能涉及到改写 SQL, 优化索引等.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("优化中间件本身")])]),_._v(": 通常也就是调整一下中间件的各种参数, 只有一些大厂在具备足够强的实力的情况下, 会考虑二次开发. 如果中间件本身是基于 JVM 的, 那么也可以优化 JVM.")]),_._v(" "),v("li",[v("mark",[v("strong",[_._v("优化操作系统")])]),_._v(": 目前接触到的大多数中间件应该都是对内存, 网络 IO 和磁盘 IO 有很强依赖, 那么优化也就是调整跟这三个方面有关的参数.")])]),_._v(" "),v("p",[_._v("如果工作经历里面出现了这个课程里没有讨论过的中间件, 也可以按照类似的思路去准备面试用的性能优化方案. 当然, 要是你所在公司的运维团队非常强, 就直接问他们是如何优化性能的就可以.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/a78d02695d35a674daf4a75874d2de78-20231223175002-5me2evv.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_41-mongodb-mongodb是怎么做到高可用的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_41-mongodb-mongodb是怎么做到高可用的"}},[_._v("#")]),_._v(" 41-MongoDB:MongoDB是怎么做到高可用的?")]),_._v(" "),v("p",[_._v("今天看另外一个 NoSQL 数据库, 也就是大名鼎鼎的 MongoDB.")]),_._v(" "),v("p",[_._v("MongoDB 是出现得比较早的"),v("strong",[_._v("文档型数据库")]),_._v(", 应该说早期谈到 NoSQL 的时候, 第一个想到的就是 MongoDB. 现在很多公司内部都使用了 MongoDB 来保存一些偏向文档类型的数据.")]),_._v(" "),v("p",[_._v("今天先来学习一下 MongoDB 的基本原理, 并看看 MongoDB 是如何保证高可用的.")]),_._v(" "),v("h5",{attrs:{id:"为什么用-mongodb"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么用-mongodb"}},[_._v("#")]),_._v(" 为什么用 MongoDB?")]),_._v(" "),v("p",[_._v("在讨论之前, 要知道为什么要用 MongoDB? 因为在很多情况下用 MongoDB 能够解决的问题, MySQL 同样也可以解决.")]),_._v(" "),v("p",[_._v("就个人来说, "),v("strong",[_._v("使用 MongoDB 的决策理由第一个就是灵活性, 其次是它的横向扩展能力")]),_._v(".")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("MongoDB 是灵活的文档模型")]),_._v(". 也就是说, 如果我预计业务数据可以被一个稳定的模型来描述, 那么我会倾向于使用 MySQL 等关系型数据库. 而一旦"),v("strong",[_._v("数据模型会经常变动, 比如很难预料到用户会输入什么数据")]),_._v(", 这种情况下我就更加倾向于使用 MongoDB.")]),_._v(" "),v("li",[v("strong",[_._v("MongoDB 更容易进行横向扩展")]),_._v(". 虽然关系型数据库也可以通过分库分表来达成横向扩展的目标, 但比 MongoDB 要困难很多, 后期运维也要复杂很多. 而这一切在 MongoDB 里面都是自动的, 基本不需要操心.")])]),_._v(" "),v("p",[_._v("当然, 对于一般的中小型公司来说, MongoDB 都不是必须使用的存储中间件, 大部分时候使用关系型数据库也能应付一般的文档存储需求.")]),_._v(" "),v("h5",{attrs:{id:"mongodb的分片机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mongodb的分片机制"}},[_._v("#")]),_._v(" MongoDB的分片机制")]),_._v(" "),v("p",[_._v("当下, 跟数据存储和检索有关的中间件基本上都会支持分片. 或者说步入了分布式时代之后诞生的中间件, 基本上都会考虑分片机制. MongoDB 也不例外.")]),_._v(" "),v("p",[_._v("在 MongoDB 里, 可以使用所谓的"),v("strong",[_._v("分片集合")]),_._v("(collection). "),v("strong",[_._v("每一个分片集合都被分成若干个分片, 如果按照关系型数据库分库分表的说法, 那么集合就是逻辑表, 而分片就是物理表")]),_._v(".")]),_._v(" "),v("p",[v("strong",[_._v("每个分片又由多个块(chunk)组成")]),_._v(". 在最新版本的默认情况下, 一个块的大小是 128 MB.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/03069bf2c07b54e8365ce5641491bd39-20231223175002-ghmaxey.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("如果一个块满足了下面这两个条件里的任何一个, 就会被拆分成两个块.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("整个块的数据量过多了")]),_._v(". 比如默认一个块是 128MB, 但是这个块上放的数据超过了 128 MB, 那么就会拆分.")]),_._v(" "),v("li",[v("strong",[_._v("块上面放了太多文档, 这个阈值是平均每个块包含的文档数量的 1.3 倍")]),_._v(". 也就是如果平均每个块可以放 1000 个文档, 如果当前块上面放了超过 1300 个文档, 那么这个块也会被切分.")])]),_._v(" "),v("p",[_._v("这两个条件简单记忆就是"),v("strong",[_._v("数据太多和文档太多.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/8db3edd4e61a7fbc89cc65961cc301f8-20231223175002-5b5ees5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("接下来就是讨论 MongoDB 的神奇的地方了. 在"),v("strong",[_._v("分库分表")]),_._v("里面, 经常会遇到的一个问题是, "),v("strong",[_._v("不同的表之间数据并不均衡, 有的多有的少")]),_._v(". 所以这就要求在设计分库分表方案的时候, 要尽可能准确预估每一个物理表的数据, 确保均衡.")]),_._v(" "),v("p",[_._v("而在 MongoDB 里面, 它会"),v("strong",[_._v("自动平衡不同分片的数据, 尽量做到每个分片都有差不多的数据量")]),_._v(", 整个机制也叫做"),v("strong",[_._v("负载均衡")]),_._v(". 只不过"),v("mark",[v("strong",[_._v("一般意义上的负载均衡强调的是流量负载均衡, 而这里强调的数据量负载均衡")])]),_._v(".")]),_._v(" "),v("p",[_._v("而发现数据不均匀之后, 迁移数据的过程也叫做"),v("strong",[_._v("再平衡")]),_._v("(rebalance). 再平衡过程本质上就是"),v("strong",[_._v("挪动块")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d293ddbf914c37622847b22fa001d786-20231223175002-dsfl7tt.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("那么什么时候才会触发再平衡过程呢? MongoDB 设定了一些"),v("strong",[_._v("阈值")]),_._v(", 超过了这个阈值就会触发再平衡的过程. 可以看一下具体的阈值表.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/40126b23c62aa33034a7a047a4927942-20231223175002-s0o7avv.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("举个例子, 如果一个集合里面最大的分片有 9 个块, 而最少的集合有 7 个块, 那么就会触发再平衡过程.")]),_._v(" "),v("p",[_._v("那块迁移究竟是怎么进行的呢? 这里假设要迁移块 A, 这个过程就包含七个步骤.")]),_._v(" "),v("ol",[v("li",[_._v("平衡器发送 moveChunk 命令到源分片上.")]),_._v(" "),v("li",[_._v("源分片执行 moveChunk 命令, 这个时候读写块 A 的操作都是源分片来负责的.")]),_._v(" "),v("li",[_._v("目标分片创建对应的索引.")]),_._v(" "),v("li",[_._v("目标分片开始同步块 A 的数据.")]),_._v(" "),v("li",[_._v("当块 A 最后一个文档都同步给目标分片之后, 目标分片会启动一个同步过程, 把迁移过程中的数据变更也同步过来.")]),_._v(" "),v("li",[_._v("整个数据同步完成之后, 源分片更新元数据, 告知块 A 已经迁移到了目标分片.")]),_._v(" "),v("li",[_._v("当源分片上的游标都关闭之后, 它就可以删除块 A 了.")])]),_._v(" "),v("p",[_._v("应该说, 这个过程和别的中间件的数据迁移过程都差不多.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/66999320087e2f38fbe9b76378987d7d-20231223175002-bp0w2dl.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"mongodb的配置服务器"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mongodb的配置服务器"}},[_._v("#")]),_._v(" MongoDB的配置服务器")]),_._v(" "),v("p",[_._v("当引入了分片机制之后, MongoDB 启用了"),v("strong",[_._v("配置服务器(config server)来存储元数据")]),_._v(". 这些元数据包括"),v("strong",[_._v("分片信息, 权限控制信息, 用来控制分布式锁")]),_._v(". 其中分片信息还会被负责执行查询 mongos 使用.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/da05912dcc08212e1414985b5010aaa5-20231223175002-o7n5vsn.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("MongoDB 的配置服务器有一个很大的优点, 就是就算主节点崩溃了, 但它还是可以继续提供读服务. 这和别的中间件不一样, 大多数中间件的主从结构都是在主节点崩溃之后完全不可用, 直到选举出了一个新的主节点.")]),_._v(" "),v("p",[_._v("但不管怎么说, 配置服务器在 MongoDB 里面是一个非常关键的组件. 甚至可以说, 一旦配置服务器有问题, 就算只是轻微地性能抖动一下, 对整个 MongoDB 集群的影响都是很大的.")]),_._v(" "),v("h5",{attrs:{id:"mongodb的复制机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mongodb的复制机制"}},[_._v("#")]),_._v(" MongoDB的复制机制")]),_._v(" "),v("p",[v("strong",[_._v("也可以把 MongoDB 的复制机制理解成 MongoDB 的主从机制")]),_._v(". 简单来说, MongoDB 的副本也是 MongoDB 实例, 它们和主实例持有一样的数据. 在 MongoDB 里面, "),v("strong",[_._v("用 Primary 来代表主实例, 而用 Secondary 来代表副本实例. 主从实例合并在一起, 也叫做一个复制集(Replica Set)")]),_._v(" .")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/634620780e112cfcc641227d03c22311-20231223175002-npblm4x.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("类似于数据库的读写分离机制, 也可以在 MongoDB 上进行"),v("strong",[_._v("读写分离")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/dbb74faeffdf39f8ed8e2eb66a2bcf7a-20231223175002-adyykz0.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("既然有主从, 那么肯定也有"),v("strong",[_._v("主从集群和数据同步")]),_._v(". 在 MongoDB 里面, "),v("strong",[_._v("主从之间的数据同步是通过所谓的 oplog 来实现的, 从这一点来看, 这个 oplog 很像 MySQL 的 binlog")]),_._v(".")]),_._v(" "),v("p",[_._v("不过在 MongoDB 里面, oplog 是有一些缺陷的. 第一个缺陷就是在一些特定的操作里, oplog 可能会超乎想象地大. 这主要是因为 oplog 是"),v("strong",[_._v("幂等")]),_._v("的, 所以任何操作都必须转化成幂等操作.")]),_._v(" "),v("p",[_._v("可以简单一点来理解, "),v("strong",[_._v("任何对 MongoDB 里数据的操作, 最后都会被转化成一个 set 操作. 所以可以预计的是, 就算只是更新了数据的一小部分, 但是生成的 oplog 还是 set 整个数据")]),_._v(".")]),_._v(" "),v("p",[_._v("第二个缺陷是 oplog 是有期限的. 或者说 MongoDB 限制了 oplog 的大小. 当 oplog 占据了太多的磁盘之后, 就会被删除. 就算某个从节点来不及同步, oplog 也是会被删除的. 这个时候, 这个从节点就只能重新发起一次全量的数据同步了.")]),_._v(" "),v("h5",{attrs:{id:"写入语义-3"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写入语义-3"}},[_._v("#")]),_._v(" 写入语义")]),_._v(" "),v("p",[_._v("MongoDB 的写入语义和 Kafka 的写入语义非常像. 也就是说可以通过参数来控制写入数据究竟写到哪里. 而写入语义对性能, 可用性和数据可靠性有显著的影响.")]),_._v(" "),v("p",[_._v("在 MongoDB 里面, 写入语义也叫做 "),v("code",[_._v("Write Concern")]),_._v("​, 它由 w, j 和 wtimeout 三个参数控制.")]),_._v(" "),v("p",[_._v("对于 w 来说, 它的取值是这样的:")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("majority")]),_._v(": 要求写操作已经同步给大部分节点, 也是 MongoDB 的默认取值. 这个选项的可用性很强, 但是写入的性能比较差.")]),_._v(" "),v("li",[v("strong",[_._v("数字 N")]),_._v(": 如果 N 等于 1, 那么要求必须写入主节点; 如果 N 大于 1, 那么就必须写入主节点, 并且写入从节点, 这些节点数量加在一起等于 N; 如果 N 等于 0, 就不用等任何节点写入. 这种模式下性能很好, 但可以想象到, 在这个模式下虽然客户端可能收到了成功的响应, 但是数据也会丢失.")]),_._v(" "),v("li",[v("strong",[_._v("自定义写入节点策略")]),_._v(": 具体来说就是可以给一些节点打上标签, 然后要求写入的时候一定要写入带有这些标签的节点. 这个在实践中用得比较少, 但是如果你们公司采用了的话, 非常适合用来面试.")])]),_._v(" "),v("p",[_._v("j 选项控制数据有没有被写到磁盘上. 对于 j 来说它的取值就是 true 或者 false.")]),_._v(" "),v("p",[_._v("最后一个参数 wtimeout, 就是指写入的超时时间, 它只会在 w 大于 1 的时候生效. 需要注意的是, 在超时之后 MongoDB 就直接返回一个错误, 但是在这种情况下, MongoDB 还是可能写入数据成功了.")]),_._v(" "),v("h5",{attrs:{id:"面试准备-41"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-41"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("除了上面这些基础知识, 还要在公司内部弄清楚和 MongoDB 有关的信息.")]),_._v(" "),v("ul",[v("li",[_._v("你负责的业务或者你们公司有没有使用 MongoDB? 主要是用来做什么?")]),_._v(" "),v("li",[_._v("为什么你要用 MongoDB? 用 MySQL 行不行?")]),_._v(" "),v("li",[_._v("你用 MongoDB 的时候, 你的文档支持分片吗? 如果支持分片, 那么是按照什么来分片的?")]),_._v(" "),v("li",[_._v("你用 MongoDB 的业务有多少数据量, MongoDB 上的并发有多高?")]),_._v(" "),v("li",[_._v("你们公司的 MongoDB 是怎么部署的, 主从节点有多少? 有没有多数据中心的部署方案?")]),_._v(" "),v("li",[_._v("你使用 MongoDB 的写入语义是什么? 也就是说 w 和 j 这两个参数的取值是什么?")])]),_._v(" "),v("p",[_._v("站在个人成长的角度, 建议在某个问题可以用 MySQL 来解决, 但是看起来用 MongoDB 更好的时候, 尽量选用 MongoDB.")]),_._v(" "),v("p",[_._v("当面试官聊到了这些话题的时候, 也可以引导到这节的内容上.")]),_._v(" "),v("ul",[v("li",[_._v("Kafka 的 acks 机制, 那么可以引申到 MongoDB 的写入语义上.")]),_._v(" "),v("li",[_._v("其他中间件的对等结构, 或者主从结构, 可以引导到 MongoDB 的分片和主从机制上.")]),_._v(" "),v("li",[_._v("Kafka 的元数据, 可以结合 MongoDB 的元数据来一起回答.")])]),_._v(" "),v("p",[_._v("另外, 如果面试官问到了 MongoDB 数据不丢失的问题, 记得结合前置知识里面的写入语义, 参考在 Kafka 里分析的思路来回答. 在整个 MongoDB 的面试过程中, 要注意和不同的中间件进行对比, 凸显你在这方面的积累.")]),_._v(" "),v("h5",{attrs:{id:"主从结构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主从结构"}},[_._v("#")]),_._v(" 主从结构")]),_._v(" "),v("p",[_._v("MongoDB 的高可用其实和别的中间件的高可用方案不能说一模一样, 但是可以说是一脉相承. 比如在 MySQL 里面就接触过了分库分表和主从同步. 在 Redis 里面, 也看到了 Redis 的主从结构; 在 Kafka 里分区也是有主从结构的.")]),_._v(" "),v("p",[_._v("所以要先介绍你启用了主从同步.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们这个系统有一个关键组件, 就是 MongoDB. 但在最开始的时候, MongoDB 都还没有启用主从, 也就是一个单节点的. 因此每年总会有那么一两次, MongoDB 崩溃不可用. 所以我做了一件很简单的事情, 就是把 MongoDB 改成了主从同步, 最开始的时候业务量不多, 为了节省成本, 我们就用了推荐的配置一主两从. 这种改变的好处就是当主节点崩溃之后, 从节点可以选举出一个新的主节点.")])]),_._v(" "),v("p",[_._v("当然在这个回答里面, 可以直接说你所在的公司, 用了几个主从节点. 要是面试官问到了主从同步, 就回答 oplog 的内容就可以了.")]),_._v(" "),v("h6",{attrs:{id:"引入仲裁节点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#引入仲裁节点"}},[_._v("#")]),_._v(" 引入仲裁节点")]),_._v(" "),v("p",[_._v("另外一种面试思路是说你在公司引入了"),v("strong",[_._v("仲裁节点")]),_._v("(Aribiter). "),v("strong",[_._v("所谓的仲裁节点是指这个节点参与主从集群的主节点选举, 但是只参与投票, 就类似于 Elasticsearch 里的仅投票节点")]),_._v(".")]),_._v(" "),v("p",[_._v("这种机制在别的中间件里面也见过了. 这一类节点的好处就在于它们只参与投票, 也就是只关心主从选举, 所以只需要很少的资源就可以运行起来.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/ec78c1cdd8ec8ccdc3c29e3799223e5a-20231223175002-1twb6r5.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始的时候, 我们公司只是部署了一主两从, 两个从节点都会同步数据. 后面为了进一步提高可用性, 我引入了仲裁节点. 这些仲裁节点被部署在轻量级的服务器上, 成本非常低. 在引入了这些仲裁节点之后, 就算有一个从节点崩溃了, 整个集群也基本没什么影响, 因为这个时候还是有足够的节点可以投票.")])]),_._v(" "),v("h6",{attrs:{id:"启用主从模式的配置服务器"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#启用主从模式的配置服务器"}},[_._v("#")]),_._v(" 启用主从模式的配置服务器")]),_._v(" "),v("p",[_._v("在前置知识里面也知道了配置服务器是 MongoDB 中的关键组件, 一旦出现问题, 对整个集群的可用性都有很大的影响. 那么"),v("strong",[_._v("配置服务器能使用主从结构")]),_._v("吗? 答案是"),v("strong",[_._v("可以")]),_._v("的.")]),_._v(" "),v("p",[_._v("实际上, MongoDB 本身也是推荐使用主从结构的配置服务器.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们 MongoDB 最开始部署的时候, 配置服务器并没有启用主从模式, 毕竟当时是想着节省资源. 但是后面发现, 配置服务器这个对集群的影响太大了, 一旦不可用, 整个集群就基本不可用了. 在这种情况下, 就只好引入了主从结构的配置服务器. 目前我们公司的配置服务器本身就有一主两从.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2fde43b07b5cec7e426def798f1485d2-20231223175002-8rn5x97.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("紧接着可以补充这个做法的好处.")]),_._v(" "),v("blockquote",[v("p",[_._v("虽然主节点还是存在崩溃的可能, 但在主节点崩溃之后会有主从选举. 更加重要的是, 在主节点崩溃之后, 整个配置服务集群还是可读的. 而且在一个 MongoDB 集群里面, 元数据也是读多写少的. 两者一结合, 整个 MongoDB 集群的可用性就提高了.")])]),_._v(" "),v("h6",{attrs:{id:"多数据中心的主从结构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#多数据中心的主从结构"}},[_._v("#")]),_._v(" 多数据中心的主从结构")]),_._v(" "),v("p",[_._v("在主从结构这里, 再深入一些的话, 就需要聊聊"),v("strong",[_._v("多数据中心的主从结构")]),_._v(". MongoDB 里面有一个推荐的架构, 可以看一下示意图.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/d864094640ee2b74ac4db152bfb6c24d-20231223175002-mae471l.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("不过正常来说, 大部分公司没那么多资源部署, 那么一个简化版本就是用两个数据中心, 部署一主三从或者一主两从.")]),_._v(" "),v("blockquote",[v("p",[_._v("我们公司本身业务规模比较大, 对 MongoDB 的依赖也很严重, 所以还部署了多数据中心的主从结构. 我们有两个数据中心(可以同城, 可以异地), 其中一个数据中心, 部署了一主一从, 另外一个数据中心部署了两个从节点. 那么万一一个数据中心崩溃了, 另外一个数据中心也还是可用的.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/7c64b8f60d6215a7f6cc49a6f3c88677-20231223175002-a4jhu42.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("然后在主从选举的时候, 我们也会倾向于选择和主节点在同一个数据中心的从节点, 也就是图里面深黄色的从节点. 因为正常来说同一个数据中心内部的从节点, 数据会比较新.")]),_._v(" "),v("blockquote",[v("p",[_._v("同时为了保证在主从选举的时候优先选择同一个数据中心的节点, 我们还调整了从节点的优先级. 也就是先把同一个机房的节点都设置成比较高的优先级, 那么主节点大概率就会从这个机房选出来.")])]),_._v(" "),v("p",[_._v("当然, 如果你们公司本身就使用了这种多数据中心的主从结构, 那就可以用公司的多数据中心主从结构来回答.")]),_._v(" "),v("p",[_._v("在整个主从结构都面完了之后, 进一步总结一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("基本上目前主流的这种大型中间件, "),v("mark",[_._v("在提高可用性上用的方法无外乎就是分片和主从结构")]),_._v(". 除了 MongoDB, 类似的还有 Redis, Elasticsearch, Kafka.")])]),_._v(" "),v("h5",{attrs:{id:"引入分片"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#引入分片"}},[_._v("#")]),_._v(" 引入分片")]),_._v(" "),v("p",[_._v("那么第二个可以提高可用性的点, 就是"),v("strong",[_._v("引入分片")]),_._v(". 从理论上来说, 分片既可以提高性能, 又可以提高可用性.")]),_._v(" "),v("p",[_._v("在 MongoDB 里面, 引入分片要比关系型数据库简单多了. 可以直接说你在开发新业务的时候就启用了分片功能.")]),_._v(" "),v("blockquote",[v("p",[_._v("随着我们业务的增长, 后面使用 MongoDB 的时候, 都要求开启分片功能, 来进一步提高可用性和性能.")])]),_._v(" "),v("p",[_._v("另外一种面试思路就是"),v("strong",[_._v("为已有的数据添加分片功能")]),_._v(". 这个面试思路要谨慎使用, 因为这个部分比较容易遇到问题. 如果没实际操刀过, 面试官问细节就可能答不上来.")]),_._v(" "),v("blockquote",[v("p",[_._v("为了进一步提高可用性和性能, 我还在我的业务上引入了分片. 不过因为现在已经有数据了, 所以这算是一个比较危险的操作. 因此我在业务低峰期的时候, 在运维的协助下, 把集合改成了分片集合.")])]),_._v(" "),v("p",[_._v("最后也要进一步总结升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v('目前来说, 支持大数据高并发的中间件基本上也有类似的分片功能. 或者说这一类的中间件明面上都是对等结构, 而对等结构里面的每一个 "节点" 又是一个主从集群. 就算是关系型数据库的分库分表, 也可以看作是这种对等结构+主从结构的模式.')])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/511b3c368275572537008e84745a0348-20231223175002-o2np52v.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h5",{attrs:{id:"调整写入语义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#调整写入语义"}},[_._v("#")]),_._v(" 调整写入语义")]),_._v(" "),v("p",[_._v("就像之前在 MySQL 和 Kafka 里见到的, 像这种写入语义一般都有两种调整思路, 一个是朝着"),v("strong",[_._v("可用性")]),_._v("的角度调整, 另一个是朝着"),v("strong",[_._v("性能")]),_._v("的角度调整.")]),_._v(" "),v("p",[_._v("这里以可用性为例.")]),_._v(" "),v("blockquote",[v("p",[_._v("最开始的时候, 我们遇到过一个 Bug, 就是数据写入到 MongoDB 之后, 偶尔会出现数据丢失的问题. 因为之前在 Kafka 上也遇到过类似的问题, 所以我就怀疑是不是写入语义没做好. 然后我就去排查, 果然有发现在这个数据丢失的场景下, Write Concern 的 w 取值不是默认的 majority, 而是 1, 也就是说只需要主节点写入就可以.")]),_._v(" "),v("p",[_._v("很明显, 在这种情况下, 万一写入之后主节点崩溃了, 那么从节点就算被提升成主节点, 也没有这一条数据. 所以后面就把这个改回了 majority. 同时我还去排查了一个 j 参数, 确认设置成了 true. 这样一来, 数据就不太可能丢失了.")])]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-39"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-39"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("在前置知识部分了解了用 MongoDB 的原因, 主要是为了灵活的文档模型和易于横向扩展. 其次了解了 MongoDB 在可用性上最基本的机制: "),v("strong",[_._v("分片和复制")]),_._v(", 还有支撑分片和复制机制的配置服务器. 这部分内容很容易引申到数据可靠性的问题上, 所以为了以防万一, 详细讲解了写入语义的问题. 最后通过引入主从机制, 引入分片和调整写入语义三个主要措施构建了一个高可用方案.")]),_._v(" "),v("p",[_._v("在 MongoDB 的面试里面, 始终要记住一点, "),v("strong",[_._v("就是把 MongoDB 和别的中间件进行横向对比, 最好的方式是自己总结出一张思维导图或者表格")]),_._v(", 更加一目了然.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2a1b3f82d35c565e20400768697df1fe-20231223175002-v3ja9qo.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"_42-mongodb高性能-怎么优化mongodb的查询性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_42-mongodb高性能-怎么优化mongodb的查询性能"}},[_._v("#")]),_._v(" 42-MongoDB高性能:怎么优化MongoDB的查询性能?")]),_._v(" "),v("p",[_._v("今天来学习 MongoDB 的另外一个热点面试主题--优化 MongoDB 的查询性能.")]),_._v(" "),v("p",[_._v("就像之前多次提到的, 任何中间件的面试说到底就是以"),v("strong",[_._v("高可用, 高性能和高并发")]),_._v("为主. 高性能和高并发可以说是孪生兄弟, 做到了高性能, 基本上就做到了高并发.")]),_._v(" "),v("p",[_._v("在面试中, 性能优化一直被看作是一个高级面试点, 因为只有对原理了解得很透彻的人, 在实践中才能找准性能问题的关键点, 从而通过各种优化手段解决性能问题.")]),_._v(" "),v("p",[_._v("在这之前先来看看 MongoDB 的查询过程, 这样方便理解后面的优化手段.")]),_._v(" "),v("h5",{attrs:{id:"mongodb的查询过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mongodb的查询过程"}},[_._v("#")]),_._v(" MongoDB的查询过程")]),_._v(" "),v("p",[_._v("MongoDB 在分片之后肯定会有一些机制来"),v("strong",[_._v("保证查询能够准确找到数据")]),_._v(". 说到这里, 你肯定想到了分库分表的查询过程. 在分库分表中, 查询的执行过程中最重要的一步, 就是计算数据可能在哪个目标表上. 如果实在计算不出来, 那么只能考虑使用广播.")]),_._v(" "),v("p",[_._v("而 MongoDB 也需要考虑类似的问题. "),v("strong",[_._v("在 MongoDB 里面, 有一类实例叫做 mongos, 这些实例就是负责路由查询到目标表上, 还有合并结果集")]),_._v(".")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/717ef05ee34e5c413b5a27c479626062-20231223175002-4q8f5aw.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("而在分库分表中, 计算目标表是分库分表中间件或者分库分表代理完成的.")]),_._v(" "),v("h5",{attrs:{id:"mongodb的esr规则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mongodb的esr规则"}},[_._v("#")]),_._v(" MongoDB的ESR规则")]),_._v(" "),v("p",[_._v("在 MongoDB 里面设计索引的时候就要考虑所谓的 "),v("strong",[_._v("ESR 规则")]),_._v(". "),v("strong",[_._v("ESR 代表的是 E(Equality), S(Sort)和 R(Range), 也就是相等, 排序和范围")]),_._v(". 在设计索引的时候, 按照 ESR 规则来排列你的索引列.")]),_._v(" "),v("p",[_._v("比如用 A 进行等值查找, 用 B 进行排序, 用 C 进行范围查询, 那么就应该是 ABC. 如果是 BAC, 那么就违背了 ESR 规则.")]),_._v(" "),v("p",[_._v("而且 ESR 的三个元素是可以重复的, 只要相对顺序不变就可以.")]),_._v(" "),v("ul",[v("li",[v("strong",[_._v("EESR")]),_._v(": 两个等值列是可以的.")]),_._v(" "),v("li",[v("strong",[_._v("ESSR")]),_._v(": 两个排序列也是可以的.")]),_._v(" "),v("li",[v("strong",[_._v("ER")]),_._v(": 没有排序列也是可以的.")]),_._v(" "),v("li",[v("strong",[_._v("ERR")]),_._v(": 两个范围列也是可以的.")])]),_._v(" "),v("p",[_._v("因此在设计索引, 优化索引的时候就是要"),v("strong",[_._v("让索引尽可能符合 ESR 规则")]),_._v(".")]),_._v(" "),v("h5",{attrs:{id:"面试准备-42"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试准备-42"}},[_._v("#")]),_._v(" 面试准备")]),_._v(" "),v("p",[_._v("除了上面的这些基础知识, 在面试前还需要在公司内部收集一些信息.")]),_._v(" "),v("ul",[v("li",[_._v("你们公司有没有遇到过 MongoDB 慢查询的问题? 如果有, 那么引发慢查询的原因是什么? 最终又是怎么解决的?")]),_._v(" "),v("li",[_._v("有没有优化过 MongoDB 的索引? 如果有, 是怎么优化的?")]),_._v(" "),v("li",[_._v("你们公司 MongoDB 的参数有没有调整过? 如果调整过, 调过哪些? 为什么调整?")]),_._v(" "),v("li",[_._v("你们公司 MongoDB 的平均查询时间多长? 99 线以及 999 线是多少?")])]),_._v(" "),v("p",[_._v("可以把 MongoDB 的性能优化, MySQL 查询性能优化, Elasticsearch 性能优化三个合并在一起. 也就是说整个面试思路就是讨论它们三个的性能优化手段.")]),_._v(" "),v("p",[_._v("比如:")]),_._v(" "),v("ul",[v("li",[_._v("在讨论到 MySQL 索引优化的时候, 提起优化 MongoDB 的索引.")]),_._v(" "),v("li",[_._v("在讨论到分库分表分页查询的时候, 提起 MongoDB 里的 mongos.")]),_._v(" "),v("li",[_._v("在讨论 Elasticsearch 分片的时候, 也可以提起 MongoDB 的分片.")])]),_._v(" "),v("p",[_._v("可以通过这样的横向对比, 树立起一个掌握了各种中间件性能优化方法论的形象, 从而加深面试官对你的印象, 赢得竞争优势.")]),_._v(" "),v("h5",{attrs:{id:"优化mongodb查询"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化mongodb查询"}},[_._v("#")]),_._v(" 优化MongoDB查询")]),_._v(" "),v("h6",{attrs:{id:"方案1-使用覆盖索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案1-使用覆盖索引"}},[_._v("#")]),_._v(" 方案1:使用覆盖索引")]),_._v(" "),v("p",[_._v("这里是借鉴了 MySQL 里的说法. 你应该知道, 在 MySQL 上使用覆盖索引的最大好处就是不需要回表, 从索引里就可以直接拿到需要的数据.")]),_._v(" "),v("p",[_._v("在 MongoDB 里也可以用这样的手段. 也就是说, "),v("strong",[_._v("如果有一个索引上有要查询的全部数据, 那么 MongoDB 就不用把整个文档加载出来")]),_._v(". 最直观的做法就是在查询中使用 projection 方法指定字段, 而且这些字段都是索引字段.")]),_._v(" "),v("p",[_._v("这算是最基本的优化手段, 在真实的工作场景里也很常见. 因为最开始开发者为了省事, 通常都是直接把所有的字段都查询出来, 后续随着数据量增长才会遇到性能问题.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我做过一个很简单的优化. 我们早期有一个业务查询, 就是把整个文档都加载起来. 后面我发现, 这个查询的调用者大部分其实不需要整个文档, 只需要里面的几个字段. 所以就额外提供了一个新的查询接口, 这个查询接口只会返回部分字段. 这样优化之后, 大部分查询都是改用新接口, MongoDB 也不需要把整个文档都加载出来, 性能提升了至少 30%.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/46ae44ff3a5b86372f1f266e380ed9ec-20231223175002-20rzmdu.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以进一步总结升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("也不仅仅是查询, 就算是在更新的时候, 也要尽可能做到只更新必要的字段. 比如在一些业务场景下, 出于快速研发的角度, 可能会考虑前端把整个文档传过来, 后端就直接更新整个文档. 但如果能够做到只传来修改过的字段, 那么就可以只更新必要的字段了. 这样性能也更好.")])]),_._v(" "),v("h6",{attrs:{id:"方案2-优化排序"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案2-优化排序"}},[_._v("#")]),_._v(" 方案2:优化排序")]),_._v(" "),v("p",[_._v("这又是一个在 MySQL 里见过的优化手段. 在 MongoDB 里面, "),v("strong",[_._v("如果能够利用索引来排序的话, 那么直接按照索引顺序加载数据就可以了")]),_._v(". 而如果不能利用索引来排序的话, 就必须在加载了数据之后, 再次进行排序, 也就是进行内存排序.")]),_._v(" "),v("p",[_._v("可想而知, 如果内存排序, 再叠加分页查询的话, 性能就会更差. 比如要查询 "),v("code",[_._v("skip(100000).limit(100)")]),_._v("​, 那么最坏的情况下, MongoDB 要把所有的文件都加载到内存里进行排序, 然后找到从 100000 开始的 100 条数据.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/f599936ed3ff59056f40b0a5cf703f23-20231223175002-y89zhw8.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("优化的思路也类似于之前在 MySQL 里面讲的. "),v("strong",[_._v("第一种是把查询优化成利用索引来排序, 可以考虑修改查询, 也可以考虑修改索引")]),_._v(". 比如可以新建索引.")]),_._v(" "),v("blockquote",[v("p",[_._v("我还优化过一个分页查询. 早期的时候, 有一个查询是需要排序加分页的, 但是最开始数据量不多, 所以随便写了也没问题. 但是后面数据量上来之后, 这个地方查询就越来越慢. 看到这个排序加分页的查询, 我的第一个想法就是这个查询肯定是内存排序, 不然不会那么慢. 我一排查, 还真是这样. 后来就创建了一个新的索引, 确保排序的时候可以直接利用索引来排序.")])]),_._v(" "),v("p",[_._v("另外一种优化思路是借鉴在分库分表里面提到的"),v("strong",[_._v("禁止跨页查询")]),_._v(", 也就是说每次查询带上上一次查询的极值作为查询条件.")]),_._v(" "),v("blockquote",[v("p",[_._v("MongoDB 的分页查询还有一种优化方式, 但这种优化方式需要业务折中. 也就是原本分页向后翻页是通过偏移量来进行的, 那现在可以通过修改查询条件, 在查询语句里带上前一页的排序字段的极值. 比如查询是根据创建时间 create_time 倒序排序, 那就可以优化成查询条件里上一批最小的 create_time, 接近于 "),v("code",[_._v("WHERE create_time <= $last_min_create_time 的语义")]),_._v("​.")])]),_._v(" "),v("p",[_._v("注意, 这里的极值是最大值还是最小值, 跟排序有关.")]),_._v(" "),v("p",[_._v("另外可以进一步把这个话题引导到 MySQL 和分库分表上.")]),_._v(" "),v("blockquote",[v("p",[_._v("总体来说, MongoDB 的分页查询面临的问题和关系型数据库分页查询面临的问题差不多, 而在分片集合上进行分页查询面临的问题, 也和分库分表的问题差不多. 总之, 分页查询如果不小心的话, 是比较容易出现性能问题的.")])]),_._v(" "),v("p",[_._v("既然 MongoDB 会有这种分页的问题, 那么分片情况下处理分页的 mongos 岂不是就容易成为瓶颈吗?")]),_._v(" "),v("p",[_._v("是的, 所以就可以考虑"),v("strong",[_._v("增加 mongos 的数量")]),_._v(".")]),_._v(" "),v("h6",{attrs:{id:"方案3-增加mongos数量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案3-增加mongos数量"}},[_._v("#")]),_._v(" 方案3:增加mongos数量")]),_._v(" "),v("p",[_._v("在前置知识里面已经知道了, "),v("strong",[_._v("如果是分片集合的话, 查询都要靠 mongos 来执行路由, 并且合并结果集")]),_._v(".")]),_._v(" "),v("p",[_._v("换一句话来说, mongos 就是查询的"),v("strong",[_._v("性能瓶颈")]),_._v(", 它可能是 CPU 瓶颈, 可能是内存瓶颈, 也可能是网络带宽瓶颈. 举个例子, 比如有分页查询, 那么 mongos 就必须要求各个分片查询到结果之后, 自己再排序, 选出全局分页里对应的数据.")]),_._v(" "),v("p",[_._v("因此, 在实践中要密切关注查询性能, 并且在发现查询很慢的时候, 就要去看看是不是 mongos 引起的.")]),_._v(" "),v("blockquote",[v("p",[_._v("之前我还优化过 mongos. 不过 mongos 实例能优化的不多, 主要就是增加 mongos 实例. 而且最好是独立部署 mongos, 独享系统的 CPU 和内存资源.")])]),_._v(" "),v("p",[_._v("另外一种面试的思路是"),v("strong",[_._v("隔离")]),_._v(". 也就是考虑到 mongos 本身容易成为性能瓶颈, 并且也不能无限增加 mongos 实例, 所以如果公司资源足够, 应该让核心业务使用独立的 mongos 实例或者独立的 MongoDB 集群.")]),_._v(" "),v("h6",{attrs:{id:"方案4-拆分大文档"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案4-拆分大文档"}},[_._v("#")]),_._v(" 方案4:拆分大文档")]),_._v(" "),v("p",[_._v("这算是很常见的一种优化手段了. 在一些特定的业务场景中会有一些很大的文档, 这些文档有很多字段, 并且有一些特定的字段还特别大.")]),_._v(" "),v("p",[_._v("那么就可以"),v("strong",[_._v("考虑拆分这些文档")]),_._v(".")]),_._v(" "),v("blockquote",[v("p",[_._v("大文档对 MongoDB 的性能影响还是很大的. 就个人经验来说, 可以考虑从两个角度出发去拆分大文档.")]),_._v(" "),v("ol",[v("li",[_._v("按照字段的访问频率拆分. 也就是访问频繁的放一个文档, 访问不频繁的拆出去, 作为另外一个文档.")]),_._v(" "),v("li",[_._v("按照字段的大小来拆分. 也就是小字段放在一个文档, 大字段拆出去, 作为另外一个文档.")])]),_._v(" "),v("p",[_._v("之前我就拆分过一个文档, 非常庞大. 而且在业务中, 有一些庞大的字段根本用不上. 在这种情况下, 我一次拆出了三个文档.")]),_._v(" "),v("ol",[v("li",[v("p",[_._v("访问频繁的小字段放在一起, 作为一个文档.")])]),_._v(" "),v("li",[v("p",[_._v("把访问不频繁的大字段拆出去, 作为一个文档. 这个地方我觉得可以进一步优化为特定的巨大的字段可以直接拿出去, 作为一个单独的文档.")])]),_._v(" "),v("li",[v("p",[_._v("剩余的合并在一起, 作为一个文档.")]),_._v(" "),v("p",[_._v("这样做的优点很明显, 比较多的业务查询其实只需要第一种文档, 极少数会需要第二种文档. 但是缺点也同样明显, 如果调用者需要整个文档, 也就意味着我需要查询三次, 再合并组成一个业务上完整的文档.")])])])]),_._v(" "),v("p",[_._v("还可以升华一下.")]),_._v(" "),v("blockquote",[v("p",[_._v("当然, 拆分终究是下策, 最好还是在一开始使用 MongoDB 的时候就约束住文档的大小.")])]),_._v(" "),v("p",[_._v("不过还有一个和这种策略完全相反的优化手段: 嵌入文档.")]),_._v(" "),v("h6",{attrs:{id:"方案5-嵌入文档"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案5-嵌入文档"}},[_._v("#")]),_._v(" 方案5:嵌入文档")]),_._v(" "),v("p",[_._v("所谓的嵌入文档是指如果 A 文档和 B 文档有关联关系, 那么就"),v("strong",[_._v("在 A 文档里面嵌入 B 文档, 做成一个大文档")]),_._v(".")]),_._v(" "),v("p",[_._v("相当于原本 A 文档和 B 文档都是单独存储的, 可能在 A 文档里面有一个 B 文档的 ID 字段, 又或者在 B 文档里有 A 的文档 ID. 那么可以考虑合并这两个文档.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/2b7791226945c7d33c3724c43ec42524-20231223175002-2h34dbd.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("可以这么介绍你的方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("早前我们有一个过度设计的场景, 就是有两个文档 A 和 B. 其中 A 里面有一个 B 的文档 ID, 建立了一对一的映射关系. 但是实际上, 业务查询的时候, 基本上都是分成两次查询, 先把 A 查询出来, 再根据 A 里面的文档 ID 把 B 也查出来.")]),_._v(" "),v("p",[_._v("后面这个地方慢慢成为了性能瓶颈, 我就尝试了优化这个地方. 我的想法是既然 A 和 B 在业务上联系那么紧密, 那可以直接把它们整合成一个文档. 整合之后, 一次查询就能拿到所有需要的数据了, 直接节约了一个 MongoDB 查询, 业务响应时间提高了, 而且 MongoDB 的压力也变小了.")])]),_._v(" "),v("p",[_._v("那么如果面试官问怎么直接整合成一个文档呢? 就可以考虑说采用的是懒惰的, 渐进式的整合方案.")]),_._v(" "),v("blockquote",[v("p",[_._v("我采用的是懒惰策略来整合文档. 也就是如果先查询 A 文档之后发现 A 文档还没有嵌入 B 文档, 那么就查询 B 文档, 嵌入进 A 文档之后, 直接更新 A 文档. 在更新 A 文档的时候, 要采用乐观锁策略, 也就是在更新的条件里面, 加上 A 文档不包含 B 文档这个条件.")]),_._v(" "),v("p",[_._v("这个业务有一个好处, 就是没有直接更新 B 文档的场景, 都是通过 A 来操作 B 文档, 所以并不需要考虑其他的并发问题.")])]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5a1239149a71162cb47da2d3705d3fd3-20231223175002-2r5xpoe.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("这种懒惰更新策略里的最后一步更新动作, 实际上就是一个乐观锁. 所以可以尝试把话题引导到乐观锁上.")]),_._v(" "),v("p",[_._v("不过, 嵌入整个文档是很罕见的优化手段. 更加常用的是嵌入部分字段, 也叫做冗余字段. 这种优化手段在关系型数据库里也很常见. 比如 A 经常使用 B 的某几个字段, 那么就可以在 A 里面冗余一份. 不过这种"),v("strong",[_._v("冗余的方案会有比较严重的数据一致性问题")]),_._v(". 只有在能够容忍这种数据不一致的时候, 才可以应用这个方案.")]),_._v(" "),v("p",[_._v("在现实中最常见的场景就是在别的模块的文档里面冗余用户的昵称, 头像, 这样可以避免再次去用户文档里查询昵称或者头像. 毕竟昵称和头像在很多时候, 都不是什么关键字段.")]),_._v(" "),v("h6",{attrs:{id:"方案6-操作系统优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#方案6-操作系统优化"}},[_._v("#")]),_._v(" 方案6:操作系统优化")]),_._v(" "),v("p",[_._v("前面提到的都是查询本身的优化, 那么根据之前在 Kafka, Elasticsearch 里准备面试的思路, 也需要为 MongoDB 准备一些操作系统优化的点.")]),_._v(" "),v("p",[_._v("首先就是"),v("strong",[_._v("内存优化")]),_._v(".")]),_._v(" "),v("p",[_._v("在 MongoDB 里, 索引对性能的影响很大, 所以应该尽可能保证"),v("strong",[_._v("有足够的物理内存")]),_._v("来存放所有的索引. 这个类似于前面 MySQL 里讨论索引的时候说到的, 预估查询的耗时有一个基本的假设, 就是索引都是放在内存里的. 所以优化内存差不多就是使用钞能力, 加大内存.")]),_._v(" "),v("p",[_._v("进一步也能够想到, swap 对 MongoDB 的影响也很大. 同样需要避免触发交换, 也就是可以调小 vm.swappiness 这个参数.")]),_._v(" "),v("h5",{attrs:{id:"面试思路总结-40"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面试思路总结-40"}},[_._v("#")]),_._v(" 面试思路总结")]),_._v(" "),v("p",[_._v("这一节先分析了 MongoDB 的查询过程, 目的是让你知道 mongos 在其中的关键作用. 在设计索引的过程中要注意遵循 ESR 规则.")]),_._v(" "),v("p",[_._v("后面列举了"),v("strong",[_._v("覆盖索引, 优化排序, 增加 mongos 数量, 拆分大文档, 嵌入文档和操作系统优化几个性能优化方案")]),_._v(". 不过业界肯定还有很多其他精妙绝伦的方案, 有兴趣可以进一步去搜集.")]),_._v(" "),v("p",[_._v("再强调一次, 不管是 SQL 查询优化, Elasticsearch 查询优化, 还是这里的 MongoDB 查询优化, 都有非常多的手段可以考虑, 没办法全部列举出来, 课程中没有提到的方案, 就需要靠你自己去探索了.")]),_._v(" "),v("p",[_._v("最后还是想要再叮嘱一下, 在面试的时候要提前准备好优化方案, 在面试过程中注意引导. 不然如果面试官自由发挥, 手写一个查询让你优化, 撞上你不知道的手段或者没有见过的案例, 就回答不出来了.")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/fcd0a6d07e3f565d8d0a27e4f6588847-20231223175002-br3s31k.jpg",alt:""}}),_._v("​")]),_._v(" "),v("h3",{attrs:{id:"模拟面试与结束语"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试与结束语"}},[_._v("#")]),_._v(" 模拟面试与结束语")]),_._v(" "),v("h4",{attrs:{id:"模拟面试-微服务架构面试思路一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试-微服务架构面试思路一图懂"}},[_._v("#")]),_._v(" 模拟面试-微服务架构面试思路一图懂")]),_._v(" "),v("p",[_._v("恭喜你学完第一章的内容, 终于到了要验收成果的时刻了. 微服务这一章的内容很多, 而且知识点之间盘根错节, 记忆起来并不容易, 所以为了帮助更好地掌握这部分内容, 我们在这里设置了面试题.")]),_._v(" "),v("p",[_._v("你在回答的时候, 最好是能够写成一个文档, 至少也要口头上说一遍. 千万不要只在脑海里面回忆一遍. 因为在真正面试的时候, 脑海中的记忆到嘴里说出的话, 还需要一个转换.")]),_._v(" "),v("p",[_._v("此外, 在回答的时候可以从以下几个角度来评估自己的回答:")]),_._v(" "),v("ul",[v("li",[_._v("在面试前有没有想好自己要打造什么人设? 你的回答有没有围绕这个人设进行?")]),_._v(" "),v("li",[_._v("当你看到一个问题的时候, 你能不能瞬间想到可以怎么刷亮点? 怎么引导面试官?")]),_._v(" "),v("li",[_._v("有没有在回答中留下足够的引导话术?")]),_._v(" "),v("li",[_._v("有没有在我准备的回答基础上, 糅合自己的项目经历, 打造独一无二的回答?")])]),_._v(" "),v("h5",{attrs:{id:"整体性问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#整体性问题"}},[_._v("#")]),_._v(" 整体性问题")]),_._v(" "),v("p",[_._v("✨ 什么是微服务架构?")]),_._v(" "),v("p",[_._v("✨ 怎么保证微服务架构的高可用?")]),_._v(" "),v("p",[_._v("还有下面这些问题, 横跨了多个主题, 可以从不同的角度回答.")]),_._v(" "),v("p",[_._v("✨ 怎么判定服务是否已经健康?")]),_._v(" "),v("p",[_._v("✨ 如果服务不健康该怎么办?")]),_._v(" "),v("p",[_._v("✨ 怎么判定服务已经从不健康状态恢复过来了?")]),_._v(" "),v("p",[_._v("✨ 听你说你用到了 Redis 作为缓存, 如果你的 Redis 崩溃了会怎么样?")]),_._v(" "),v("p",[_._v("✨ 听你说你用到了 Kafka 作为消息队列, 如果你的 Kafka 崩溃了怎么办?")]),_._v(" "),v("p",[_._v("✨ 现在需要设计一个开放平台, 即提供接口给合作伙伴用, 你觉得需要考虑一些什么问题?")]),_._v(" "),v("h5",{attrs:{id:"_01-服务注册与发现-注册中心应该选ap还是cp"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_01-服务注册与发现-注册中心应该选ap还是cp"}},[_._v("#")]),_._v(" 01-服务注册与发现:注册中心应该选AP还是CP?")]),_._v(" "),v("p",[_._v("🔍 什么是注册中心?")]),_._v(" "),v("p",[_._v("🔍 服务注册与发现机制的基本模型是怎样的?")]),_._v(" "),v("p",[_._v("🔍 服务上线与服务下线的步骤是什么?")]),_._v(" "),v("p",[_._v("🔍 注册中心选型需要考虑哪些因素?")]),_._v(" "),v("p",[_._v("🔍 你为什么使用 Zookeeper/Nacos/etcd 作为你的注册中心?")]),_._v(" "),v("p",[_._v("🔍 什么是 CAP?")]),_._v(" "),v("p",[_._v("🔍 在服务注册与发现里面你觉得应该用 AP 还是 CP?")]),_._v(" "),v("p",[_._v("🔍 如何保证服务注册与发现的高可用?")]),_._v(" "),v("p",[_._v("🔍 服务器崩溃, 如何检测?")]),_._v(" "),v("p",[_._v("🔍 客户端容错的措施有哪些?")]),_._v(" "),v("p",[_._v("🔍 注册中心崩溃了怎么办?")]),_._v(" "),v("p",[_._v("🔍 注册中心怎么判断服务端已经崩溃了?")]),_._v(" "),v("h5",{attrs:{id:"_02-负载均衡-调用结果-缓存机制怎么影响负载均衡的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_02-负载均衡-调用结果-缓存机制怎么影响负载均衡的"}},[_._v("#")]),_._v(" 02-负载均衡:调用结果,缓存机制怎么影响负载均衡的?")]),_._v(" "),v("p",[_._v("⚖️ 你了解负载均衡算法吗?")]),_._v(" "),v("p",[_._v("⚖️ 静态负载均衡算法和动态负载均衡算法的核心区别是什么?")]),_._v(" "),v("p",[_._v("⚖️ 轮询与随机负载均衡算法有什么区别?")]),_._v(" "),v("p",[_._v("⚖️ 你了解平滑的加权轮询算法吗?")]),_._v(" "),v("p",[_._v("⚖️ 如何根据调用结果来调整负载均衡效果?")]),_._v(" "),v("p",[_._v("⚖️ 为什么有些算法要动态调整节点的权重? 权重究竟代表了什么?")]),_._v(" "),v("p",[_._v("⚖️ 你们公司的算法有没有调整过权重? 为什么?")]),_._v(" "),v("p",[_._v("⚖️ 最快响应时间负载均衡算法有什么缺点?")]),_._v(" "),v("p",[_._v("⚖️ 如果我现在有一个应用, 对内存和 CPU 都非常敏感, 你可以针对这个特性设计一个负载均衡算法吗?")]),_._v(" "),v("p",[_._v("⚖️ 为什么使用轮询, 加权轮询, 随机之类的负载均衡算法, 系统始终会出现偶发性的流量不均衡, 以至于某台服务器出故障的情况? 怎么解决这一类问题?")]),_._v(" "),v("h5",{attrs:{id:"_03-熔断-熔断-恢复-熔断-恢复-抖来抖去怎么办-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_03-熔断-熔断-恢复-熔断-恢复-抖来抖去怎么办-2"}},[_._v("#")]),_._v(" 03-熔断:熔断-恢复-熔断-恢复,抖来抖去怎么办?")]),_._v(" "),v("p",[_._v("🔥 为什么说熔断可以提高系统的可用性?")]),_._v(" "),v("p",[_._v("🔥 如何判断节点的健康状态, 需要看哪些指标?")]),_._v(" "),v("p",[_._v("🔥 触发熔断之后, 该熔断多久?")]),_._v(" "),v("p",[_._v("🔥 响应时间超过多少应该触发熔断?")]),_._v(" "),v("p",[_._v("🔥 响应时间超过阈值就一定要触发熔断吗?")]),_._v(" "),v("p",[_._v("🔥 怎么避免偶发性超过阈值的情况?")]),_._v(" "),v("p",[_._v("🔥 服务熔断后如何恢复?")]),_._v(" "),v("p",[_._v("🔥 产生抖动的原因, 以及如何解决抖动问题?")]),_._v(" "),v("h5",{attrs:{id:"_04-降级-为什么每次大促的时候总是要把退款之类的服务停掉-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_04-降级-为什么每次大促的时候总是要把退款之类的服务停掉-2"}},[_._v("#")]),_._v(" 04-降级:为什么每次大促的时候总是要把退款之类的服务停掉?")]),_._v(" "),v("p",[_._v("🤚 什么时候会用到降级, 请举例说明?")]),_._v(" "),v("p",[_._v("🤚 降级有什么好处?")]),_._v(" "),v("p",[_._v("🤚 跨服务降级常见的做法是什么?")]),_._v(" "),v("p",[_._v("🤚 你怎么评估业务服务的重要性? 或者说, 你怎么知道 A 服务比 B 服务更加重要?")]),_._v(" "),v("p",[_._v("🤚 请说一说服务内部常见的降级思路.")]),_._v(" "),v("p",[_._v("🤚 怎么判断哪些服务需要降级?")]),_._v(" "),v("p",[_._v("🤚 触发降级之后, 应该保持在降级状态多久?")]),_._v(" "),v("p",[_._v("🤚 服务降级之后如何恢复, 如何保证恢复过程中不发生抖动?")]),_._v(" "),v("p",[_._v("🤚 你们公司的产品首页是如何保证高可用的?")]),_._v(" "),v("h5",{attrs:{id:"_05-限流-别说算法了-就问你阈值怎么算-限流的目的是什么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_05-限流-别说算法了-就问你阈值怎么算-限流的目的是什么"}},[_._v("#")]),_._v(" 05-限流:别说算法了,就问你阈值怎么算?限流的目的是什么?")]),_._v(" "),v("p",[_._v("🏁 限流算法都包括哪些?")]),_._v(" "),v("p",[_._v("🏁 不同的限流算法怎么选?")]),_._v(" "),v("p",[_._v("🏁 限流的对象应该如何选择?")]),_._v(" "),v("p",[_._v("🏁 怎么确定流量的阈值?")]),_._v(" "),v("p",[_._v("🏁 如何应对突发流量?")]),_._v(" "),v("p",[_._v("🏁 被限流的请求会被怎么处理?")]),_._v(" "),v("p",[_._v("🏁 为什么使用了限流, 系统还是有可能崩溃?")]),_._v(" "),v("p",[_._v("🏁 我们有一个功能, 对于普通用户来说, 一些接口需要限制在每分钟不超过 10 次, 整天不能超过 1000 次; VIP 用户不限制. 你怎么解决这个问题?")]),_._v(" "),v("h5",{attrs:{id:"_06-隔离-怎么保证尊贵的vip用户体验不受损-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_06-隔离-怎么保证尊贵的vip用户体验不受损-2"}},[_._v("#")]),_._v(" 06-隔离:怎么保证尊贵的VIP用户体验不受损?")]),_._v(" "),v("p",[_._v("🤝 什么是隔离, 你用来解决什么问题?")]),_._v(" "),v("p",[_._v("🤝 你了解哪些隔离策略? 你用过哪些?")]),_._v(" "),v("p",[_._v("🤝 当某个服务崩溃的时候, 你有什么办法保证其它服务不受影响?")]),_._v(" "),v("p",[_._v("🤝 在使用线程池, 连接池和协程池的时候, 怎么避免业务之间相互影响?")]),_._v(" "),v("h5",{attrs:{id:"_07-超时控制-怎么保证用户一定能在1s内拿到响应-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_07-超时控制-怎么保证用户一定能在1s内拿到响应-2"}},[_._v("#")]),_._v(" 07-超时控制:怎么保证用户一定能在1s内拿到响应?")]),_._v(" "),v("p",[_._v("🕙 为什么要做超时控制?")]),_._v(" "),v("p",[_._v("🕙 为什么缺乏超时控制有可能引起连接泄露, 线程泄露?")]),_._v(" "),v("p",[_._v("🕙 什么是链路超时控制?")]),_._v(" "),v("p",[_._v("🕙 如何确定超时时间?")]),_._v(" "),v("p",[_._v("🕙 怎么在链路中传递超时时间?")]),_._v(" "),v("p",[_._v("🕙 超时时间传递的是什么?")]),_._v(" "),v("p",[_._v("🕙 如何计算网络传输时间?")]),_._v(" "),v("p",[_._v("🕙 什么是时钟同步问题?")]),_._v(" "),v("p",[_._v("🕙 客户端和服务端谁来监听超时?")]),_._v(" "),v("p",[_._v("🕙 超时之后能不能中断业务? 怎么中断?")]),_._v(" "),v("h5",{attrs:{id:"_08-调用第三方-下游的接口不稳定性能又差怎么办-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_08-调用第三方-下游的接口不稳定性能又差怎么办-2"}},[_._v("#")]),_._v(" 08-调用第三方:下游的接口不稳定性能又差怎么办?")]),_._v(" "),v("p",[_._v("🌊 如何保证调用第三方接口的可用性?")]),_._v(" "),v("p",[_._v("🌊 如果在出错的时候你会切换不同的第三方, 但是如果全部第三方换一遍之后都崩溃了, 怎么办?")]),_._v(" "),v("p",[_._v("🌊 调用第三方接口出错的时候, 你是怎么重试的? 重试次数和重试间隔你是怎么确定的?")]),_._v(" "),v("p",[_._v("🌊 你怎么判定第三方服务已经非常不可用, 以至于要切换一个新的第三方服务了?")]),_._v(" "),v("p",[_._v("🌊 对时效性要求不高的接口, 你可以怎么优化架构?")]),_._v(" "),v("p",[_._v("🌊 在压力测试一个接口的时候, 如果这个接口依赖了一个第三方接口, 你怎么解决?")]),_._v(" "),v("p",[_._v("🌊 公司业务依赖一个非常关键的第三方依赖, 我要怎么保证我在调用第三方的时候不出错?")]),_._v(" "),v("h5",{attrs:{id:"一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一图懂"}},[_._v("#")]),_._v(" 一图懂")]),_._v(" "),v("p",[_._v("最后将这节课的内容整理成了一张图片, 图片能够更好地展现知识点之间的联系!")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/21dd6b903c7421505be505yy14a7a549-20231223175002-toy0ptp.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"模拟面试-数据库面试思路一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试-数据库面试思路一图懂"}},[_._v("#")]),_._v(" 模拟面试-数据库面试思路一图懂")]),_._v(" "),v("h5",{attrs:{id:"_10-数据库索引-为什么mysql用b-树而不用b树"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_10-数据库索引-为什么mysql用b-树而不用b树"}},[_._v("#")]),_._v(" 10-数据库索引:为什么MySQL用B+树而不用B树?")]),_._v(" "),v("ol",[v("li",[_._v("什么是覆盖索引?")]),_._v(" "),v("li",[_._v("什么是聚簇索引/非聚簇索引?")]),_._v(" "),v("li",[_._v("什么是哈希索引? MySQL InnoDB 引擎怎么创建一个哈希索引?")]),_._v(" "),v("li",[_._v("什么回表? 如何避免回表?")]),_._v(" "),v("li",[_._v("树的高度和查询性能是什么关系?")]),_._v(" "),v("li",[_._v("什么是索引最左匹配原则?")]),_._v(" "),v("li",[_._v("范围查询, Like 之类的查询怎么影响数据库使用索引?")]),_._v(" "),v("li",[_._v("索引是不是越多越好?")]),_._v(" "),v("li",[_._v("使用索引有什么代价?")]),_._v(" "),v("li",[_._v("如何选择合适的索引列? 组合索引里面怎么确定列的顺序? 状态类的列是否适合作为索引的列?")]),_._v(" "),v("li",[_._v("为什么 MySQL 使用 B+ 树作为索引的数据结构? 为什么不用 B 树? 为什么不用红黑树? 为什么不用二叉平衡树? 为什么不用跳表?")]),_._v(" "),v("li",[_._v("NULL 对索引有什么影响?")]),_._v(" "),v("li",[_._v("唯一索引是否允许多个 NULL 值?")])]),_._v(" "),v("h5",{attrs:{id:"_11-sql优化-如何发现sql中的问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_11-sql优化-如何发现sql中的问题"}},[_._v("#")]),_._v(" 11-SQL优化:如何发现SQL中的问题?")]),_._v(" "),v("ol",[v("li",[_._v("请你解释一下 EXPALIN 命令.")]),_._v(" "),v("li",[_._v("你有优化过 SQL 吗? 具体是怎么优化的?")]),_._v(" "),v("li",[_._v("你有没有优化过索引? 怎么优化的?")]),_._v(" "),v("li",[_._v("怎么优化 COUNT 查询?")]),_._v(" "),v("li",[_._v("怎么优化 ORDER BY?")]),_._v(" "),v("li",[_._v("怎么优化 LIMIT OFFSET 查询?")]),_._v(" "),v("li",[_._v("为什么要尽量把条件写到 WHERE 而不是写到 HAVING 里面?")]),_._v(" "),v("li",[_._v("怎么给一张表添加新的索引/修改表结构? 如果我的数据量很大呢?")]),_._v(" "),v("li",[_._v("USE INDEX/FORCE INDEX/IGNORE INDEX 有什么效果?")])]),_._v(" "),v("h5",{attrs:{id:"_12-数据库锁-明明有行锁-怎么突然就加了表锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_12-数据库锁-明明有行锁-怎么突然就加了表锁"}},[_._v("#")]),_._v(" 12-数据库锁:明明有行锁,怎么突然就加了表锁?")]),_._v(" "),v("ol",[v("li",[_._v("什么是行锁, 表锁? 什么时候加表锁? 怎么避免?")]),_._v(" "),v("li",[_._v("什么是乐观锁? 怎么在 MySQL 里面实现一个乐观锁?")]),_._v(" "),v("li",[_._v("什么是意向锁? 可以举一个例子吗?")]),_._v(" "),v("li",[_._v("什么是共享锁和排它锁? 它们有什么特性?")]),_._v(" "),v("li",[_._v("什么是两阶段加锁?")]),_._v(" "),v("li",[_._v("什么是记录锁, 间隙锁和临键锁?")]),_._v(" "),v("li",[_._v("RC 级别有间隙锁和临键锁吗?")]),_._v(" "),v("li",[_._v("MySQL 是怎么在 RR 级别下解决幻读的?")]),_._v(" "),v("li",[_._v("什么情况下会加临键锁? 什么情况下会加间隙锁? 什么时候加记录锁?")]),_._v(" "),v("li",[_._v("唯一索引和普通索引会怎么影响锁?")]),_._v(" "),v("li",[_._v("你遇到过什么死锁问题吗? 怎么排查的? 最终又是怎么解决的?")]),_._v(" "),v("li",[_._v("你有没有优化过锁? 怎么优化的?")])]),_._v(" "),v("h5",{attrs:{id:"_13-mvcc协议-mysql修改数据时-还能不能读到这条数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_13-mvcc协议-mysql修改数据时-还能不能读到这条数据"}},[_._v("#")]),_._v(" 13-MVCC协议:MySQL修改数据时,还能不能读到这条数据?")]),_._v(" "),v("ol",[v("li",[_._v("什么是 MVCC? 为什么需要 MVCC?")]),_._v(" "),v("li",[_._v("什么是隔离级别? 隔离级别有哪几种?")]),_._v(" "),v("li",[_._v("什么是脏读, 不可重复读, 幻读? 它们与隔离级别的关系是怎样的?")]),_._v(" "),v("li",[_._v("隔离级别是不是越高越好?")]),_._v(" "),v("li",[_._v("你们公司用的是什么隔离级别? 为什么使用这个隔离级别? 能不能使用别的隔离级别?")]),_._v(" "),v("li",[_._v("你有没有改过隔离级别? 为什么改?")])]),_._v(" "),v("h5",{attrs:{id:"_14-数据库事务-事务提交了-你的数据就一定不会丢吗-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_14-数据库事务-事务提交了-你的数据就一定不会丢吗-2"}},[_._v("#")]),_._v(" 14-数据库事务:事务提交了,你的数据就一定不会丢吗?")]),_._v(" "),v("ol",[v("li",[_._v("什么是 undo log? 为什么需要 undo log?")]),_._v(" "),v("li",[_._v("什么是 redo log? 为什么需要 redo log?")]),_._v(" "),v("li",[_._v("什么是 binlog? 它有几种模式? 用来做什么?")]),_._v(" "),v("li",[_._v("事务是如何执行的?")]),_._v(" "),v("li",[_._v("什么是 ACID? 隔离性和隔离级别是什么关系? 你觉得哪个隔离级别满足这里的隔离性要求?")]),_._v(" "),v("li",[_._v("redo log 的刷盘时机有哪些? 该如何选择? 你们公司用的是哪个配置? 为什么用这个配置?")]),_._v(" "),v("li",[_._v("binlog 的刷盘时机有哪些? 该如何选择? 你们公司用的是哪个配置? 为什么用这个配置?")]),_._v(" "),v("li",[_._v("我的事务提交了, 就一定不会丢吗? 怎么确保一定不会丢?")]),_._v(" "),v("li",[_._v("什么是 page cache? 为什么不直接写到磁盘?")]),_._v(" "),v("li",[_._v("在分布式环境下, 当服务器告诉我写入成功的时候, 一定写入成功了吗? 如果服务器宕机了了可能发生什么?")])]),_._v(" "),v("h5",{attrs:{id:"_15-数据迁移-如何在不停机的情况下保证迁移数据的一致性-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_15-数据迁移-如何在不停机的情况下保证迁移数据的一致性-2"}},[_._v("#")]),_._v(" 15-数据迁移:如何在不停机的情况下保证迁移数据的一致性?")]),_._v(" "),v("ol",[v("li",[_._v("你们单库拆分的时候是如何做数据迁移的/你们修改大表结构的时候是怎么做数据迁移的? 怎么在保持应用不停机的情况下做数据迁移?")]),_._v(" "),v("li",[_._v("什么是双写? 为什么要引入双写?")]),_._v(" "),v("li",[_._v("如果双写的过程中, 有一边写失败了, 怎么办?")]),_._v(" "),v("li",[_._v("你可以用本地事务来保证双写要么都成功, 要么都失败吗? 分布式事务呢?")]),_._v(" "),v("li",[_._v("为什么有一个阶段是双写, 但是以目标表为准? 干嘛不直接切换到单写目标表?")]),_._v(" "),v("li",[_._v("你们有什么容错方案? 比如说如果在迁移过程中出错了, 你们的应用会怎么办?")]),_._v(" "),v("li",[_._v("你们是怎么校验数据的?")]),_._v(" "),v("li",[_._v("增量数据校验你们是怎么做的?")]),_._v(" "),v("li",[_._v("数据迁移你能够做到数据绝对不出错吗?")]),_._v(" "),v("li",[_._v("如果数据出错了你们怎么修复? 怎么避免并发问题?")]),_._v(" "),v("li",[_._v("让你迁移一个 2000 万行的表, 你的方案大概要多久?")]),_._v(" "),v("li",[_._v("你用过 mysqldump/XtraBackup 吗? 它有什么缺点?")])]),_._v(" "),v("h5",{attrs:{id:"_16-分库分表主键生成-如何设计一个主键生成算法-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_16-分库分表主键生成-如何设计一个主键生成算法-2"}},[_._v("#")]),_._v(" 16-分库分表主键生成:如何设计一个主键生成算法?")]),_._v(" "),v("ol",[v("li",[_._v("你们分库分表怎么生成主键的?")]),_._v(" "),v("li",[_._v("使用 UUID/数据库自增/雪花算法有什么优缺点?")]),_._v(" "),v("li",[_._v("雪花算法是如何实现的?")]),_._v(" "),v("li",[_._v("雪花算法是怎么做到全局唯一的?")]),_._v(" "),v("li",[_._v("怎么解决雪花算法的序列号耗尽问题?")]),_._v(" "),v("li",[_._v("怎么解决雪花算法的数据堆积问题?")]),_._v(" "),v("li",[_._v("你有没有优化过主键生成的性能? 怎么优化的? 效果如何?")]),_._v(" "),v("li",[_._v("你的主键生成的 ID 是严格递增的吗? 不是递增有什么问题?")]),_._v(" "),v("li",[_._v("为什么我们一般使用自增主键?")]),_._v(" "),v("li",[_._v("什么是页分裂? 有什么缺点?")])]),_._v(" "),v("h5",{attrs:{id:"_17-分库分表分页查询-为什么你的分页查询又慢又耗费内存-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_17-分库分表分页查询-为什么你的分页查询又慢又耗费内存-2"}},[_._v("#")]),_._v(" 17-分库分表分页查询:为什么你的分页查询又慢又耗费内存?")]),_._v(" "),v("ol",[v("li",[_._v("你们公司是怎么解决分页查询的? 平均查询性能如何?")]),_._v(" "),v("li",[_._v("为什么分页查询那么慢?")]),_._v(" "),v("li",[_._v("全局查询有什么优缺点? 对于一个查询 LIMIT X OFFSET Y 来说, 如果我命中了三张表, 会取来多少数据?")]),_._v(" "),v("li",[_._v("怎么提高分页查询的速度?")]),_._v(" "),v("li",[_._v("什么是二次查询? 它的步骤是什么样的?")]),_._v(" "),v("li",[_._v("怎么在二次查询里面计算全局的偏移量?")]),_._v(" "),v("li",[_._v("二次查询有什么优缺点?")]),_._v(" "),v("li",[_._v("代理形态的分库分表中间件有什么优缺点? 怎么解决或者改进它的缺点?")]),_._v(" "),v("li",[_._v("使用中间表来进行分库分表, 有什么优缺点? 怎么设计中间表?")]),_._v(" "),v("li",[_._v("在使用中间表的时候, 你怎么保证数据一致性? 你能保证强一致吗? 如果不能, 不一致的时间最差是多久?")]),_._v(" "),v("li",[_._v("你们公司有没有考虑使用别的中间件来解决分页查询? 你选择哪一个? 为什么?")])]),_._v(" "),v("h5",{attrs:{id:"_18-分库分表事务-如何同时保证分库分表-acid及高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_18-分库分表事务-如何同时保证分库分表-acid及高性能"}},[_._v("#")]),_._v(" 18-分库分表事务:如何同时保证分库分表,ACID及高性能?")]),_._v(" "),v("ol",[v("li",[_._v("你们公司在分库分表之后, 如何解决事务问题?")]),_._v(" "),v("li",[_._v("什么是两阶段提交协议? 有什么缺点?")]),_._v(" "),v("li",[_._v("什么是三阶段提交协议? 相比两阶段, 改进点在哪里?")]),_._v(" "),v("li",[_._v("什么是 XA 事务?")]),_._v(" "),v("li",[_._v("你觉得 XA 事务是否满足 ACID? 为什么?")]),_._v(" "),v("li",[_._v("什么是 TCC?")]),_._v(" "),v("li",[_._v("什么是 SAGA?")]),_._v(" "),v("li",[_._v("什么是 AT 事务?")]),_._v(" "),v("li",[_._v("什么是延迟事务? 延迟事务失败了怎么办? 为什么分库分表中间件喜欢用延迟事务?")]),_._v(" "),v("li",[_._v("你们公司是否允许跨库事务? 为什么? 有什么场景是必须要使用跨库事务的?")])]),_._v(" "),v("h5",{attrs:{id:"_19-分库分表无分库分表键查询-按买家分库分表-卖家怎么查"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_19-分库分表无分库分表键查询-按买家分库分表-卖家怎么查"}},[_._v("#")]),_._v(" 19-分库分表无分库分表键查询:按买家分库分表,卖家怎么查?")]),_._v(" "),v("ol",[v("li",[_._v("你们公司的分库分表是怎么分的? 一般情况下怎么选择分库分表键?")]),_._v(" "),v("li",[_._v("假设说现在我的订单表是按照买家 ID 来分库分表的, 现在我卖家要查询, 怎么办?")]),_._v(" "),v("li",[_._v("利用中间表来支持无分库分表键查询的时候, 怎么设计中间表?")]),_._v(" "),v("li",[_._v("为什么在买家分库分表的时候, 按照 4 "),v("em",[_._v("8")]),_._v(" 32, 但是同样的数据, 按照卖家分库分表的时候, 就只需要按照 2 "),v("em",[_._v("8")]),_._v(" 16?")]),_._v(" "),v("li",[_._v("广播有什么缺点?")]),_._v(" "),v("li",[_._v("可以使用什么中间件来支持复杂查询? 你们公司用了什么?")])]),_._v(" "),v("h5",{attrs:{id:"_20-分库分表容量预估-分库分表时怎么计算所需库-表的数量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_20-分库分表容量预估-分库分表时怎么计算所需库-表的数量"}},[_._v("#")]),_._v(" 20-分库分表容量预估:分库分表时怎么计算所需库,表的数量?")]),_._v(" "),v("ol",[v("li",[_._v("你是怎么估计容量的? 考虑了什么因素?")]),_._v(" "),v("li",[_._v("你怎么知道数据未来增长会有多快?")]),_._v(" "),v("li",[_._v("你这容量是预估了几年的数据量? 为什么?")]),_._v(" "),v("li",[_._v("你是怎么利用流量录制和重放来验证数据的?")]),_._v(" "),v("li",[_._v("在流量录制之后, 重放之前, 如果数据修改了, 你的数据校验还能正常运行吗?")]),_._v(" "),v("li",[_._v("你公司用的是 HTTPS 协议吗? 使用 HTTPS 协议你怎么录制流量?")]),_._v(" "),v("li",[_._v("为什么大家都喜欢用 2 的幂来作为容量?")]),_._v(" "),v("li",[_._v("怎么扩容? 有哪些步骤?")]),_._v(" "),v("li",[_._v("如果你发现之前分库分表分太多了, 能不能缩容? 假如要你缩容, 你怎么办?")])]),_._v(" "),v("h5",{attrs:{id:"_21-数据库综合应用-怎么保证数据库高可用-高性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_21-数据库综合应用-怎么保证数据库高可用-高性能"}},[_._v("#")]),_._v(" 21-数据库综合应用:怎么保证数据库高可用,高性能?")]),_._v(" "),v("ol",[v("li",[_._v("你们有没有做过数据库优化? 有没有做过 InnoDB 引擎优化?")]),_._v(" "),v("li",[_._v("你调过什么数据库相关的参数? 为什么要调?")]),_._v(" "),v("li",[_._v("InnoDB 引擎的 buffer pool 是拿来做什么的? 怎么优化它的性能?")]),_._v(" "),v("li",[_._v("buffer pool 是不是越大越好? 过大或者过小都有什么问题? 怎么确定合适的大小?")]),_._v(" "),v("li",[_._v("数据库里面有很多刷盘相关的参数, 你都了解吗? 调过吗? 根据什么来调?")]),_._v(" "),v("li",[_._v("你有没有做过主从分离? 主从延迟是什么? 怎么解决主从延迟?")]),_._v(" "),v("li",[_._v("你们公司的数据库主节点宕机了会发生什么?")]),_._v(" "),v("li",[_._v("什么是查询缓存? 你们公司有没有用查询缓存?")])]),_._v(" "),v("h5",{attrs:{id:"数据库面试一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库面试一图懂"}},[_._v("#")]),_._v(" 数据库面试一图懂")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/yyb7d8934c45239ed7441a3f3d6e96a2-20231223175002-8rxokbs.png",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"模拟面试-消息队列面试思路一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试-消息队列面试思路一图懂"}},[_._v("#")]),_._v(" 模拟面试-消息队列面试思路一图懂")]),_._v(" "),v("h5",{attrs:{id:"_22-消息队列-消息队列可以用来解决什么问题-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_22-消息队列-消息队列可以用来解决什么问题-2"}},[_._v("#")]),_._v(" 22-消息队列:消息队列可以用来解决什么问题?")]),_._v(" "),v("ol",[v("li",[_._v("你用过消息队列吗? 主要用来解决什么问题? 异步, 削峰和解耦你能各举一个例子吗?")]),_._v(" "),v("li",[_._v("你用的是哪个消息队列? 为什么使用它而不用别的消息队列?")]),_._v(" "),v("li",[_._v("为什么你一定要用消息队列? 不用行不行? 不用有什么缺点?")]),_._v(" "),v("li",[_._v("在对接多个下游的时候, 直接用 RPC 调用行不行? 为什么?")]),_._v(" "),v("li",[_._v("为什么说使用消息队列可以提高性能?")]),_._v(" "),v("li",[_._v("为什么说使用消息队列可以提高扩展性?")]),_._v(" "),v("li",[_._v("为什么说使用消息队列可以提高可用性?")]),_._v(" "),v("li",[_._v("为什么秒杀场景中经常用消息队列? 怎么用的?")]),_._v(" "),v("li",[_._v("订单超时取消可以怎么实现?")]),_._v(" "),v("li",[_._v("你了解事件驱动吗?")]),_._v(" "),v("li",[_._v("什么是 SAGA 事务? 怎么利用事件驱动来设计一个 SAGA 事务框架?")])]),_._v(" "),v("h5",{attrs:{id:"_23-延迟消息-怎么在kafka上支持延迟消息-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_23-延迟消息-怎么在kafka上支持延迟消息-2"}},[_._v("#")]),_._v(" 23-延迟消息:怎么在Kafka上支持延迟消息?")]),_._v(" "),v("ol",[v("li",[_._v("什么是延迟消息? 你有没有用过? 可以用来解决什么问题?")]),_._v(" "),v("li",[_._v("Kafka 支不支持延迟消息? 为什么 Kafka 不支持?")]),_._v(" "),v("li",[_._v("RabbitMQ 支不支持延迟消息? 怎么支持的?")]),_._v(" "),v("li",[_._v("RabbitMQ 的延迟消息解决方案有什么缺点? 让你来改进, 你会怎么办?")]),_._v(" "),v("li",[_._v("什么是死信队列? 什么是消息 ttl?")]),_._v(" "),v("li",[_._v("如果要让 Kafka 支持延迟消息你会怎么做? 你有几种方案? 各有什么优缺点?")]),_._v(" "),v("li",[_._v("在你的延迟消息队列方案里面, 时间有多精确? 比如说我希望在 10:00:00 发出来, 你能保证这个一定恰好在这个时刻发出来吗? 误差有多大? 你能进一步提高时间精确性吗?")]),_._v(" "),v("li",[_._v("在分区设置不同延迟时间的方案里, 能不能支持随机延迟时间?")]),_._v(" "),v("li",[_._v("在分区设置不同延迟时间的方案里, 如果要是发生了 rebalance, 会有什么后果?")]),_._v(" "),v("li",[_._v("当你从准备转发消息到业务 topic(biz_topic)的时候失败了, 有什么后果? 怎么办?")]),_._v(" "),v("li",[_._v("在你使用 MySQL 支持延迟消息的方案里, 你怎么解决性能问题?")]),_._v(" "),v("li",[_._v("如果要分库分表来解决 MYSQL 的性能问题, 你会怎么分库分表? 是分库还是分表?")]),_._v(" "),v("li",[_._v("如果要是不同业务 topic 的并发量有区别, 你分库分表怎么解决这种负载不均匀的问题?")]),_._v(" "),v("li",[_._v("如果延迟消息还要求有序性, 该怎么办?")]),_._v(" "),v("li",[_._v("如果你已经将消息转发到了 biz_topic 上, 但是更新数据库状态失败了怎么办?")]),_._v(" "),v("li",[_._v("除了用 MySQL, 可以考虑用别的中间件来实现延迟消息吗?")])]),_._v(" "),v("h5",{attrs:{id:"_24-消息积压-业务突然增长-导致消息消费不过来怎么办"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_24-消息积压-业务突然增长-导致消息消费不过来怎么办"}},[_._v("#")]),_._v(" 24-消息积压:业务突然增长,导致消息消费不过来怎么办?")]),_._v(" "),v("ol",[v("li",[_._v("一个分区可以有多个消费者吗? 一个消费者可以消费多个分区吗?")]),_._v(" "),v("li",[_._v("你业务里面的消息有多少个分区? 你怎么计算出来的? 它能撑住多大的读写压力?")]),_._v(" "),v("li",[_._v("你遇到过消息积压吗? 怎么发现的? 为什么会积压? 最后怎么解决的?")]),_._v(" "),v("li",[_._v("为什么会出现消息积压? 只要我容量规划好, 肯定不会有消息积压, 对不对?")]),_._v(" "),v("li",[_._v("消息积压可以考虑怎么解决?")]),_._v(" "),v("li",[_._v("增加消费者数量能不能解决消息积压问题?")]),_._v(" "),v("li",[_._v("能不能通过限制发送者, 让他们少发一点来解决消息积压问题?")]),_._v(" "),v("li",[_._v("现在我发现分区数量不够了, 但是运维又不准我增加新的分区, 该怎么办?")]),_._v(" "),v("li",[_._v("异步消费有什么缺陷?")]),_._v(" "),v("li",[_._v("你怎么解决异步消费的消息丢失问题? 你的方案会引起重复消费吗?")]),_._v(" "),v("li",[_._v("在异步消费一批消息的时候, 要是有部分消费失败了, 怎么办? 要不要提交?")])]),_._v(" "),v("h5",{attrs:{id:"_25-消息顺序-保证消息有序-一个topic只能有一个partition吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_25-消息顺序-保证消息有序-一个topic只能有一个partition吗"}},[_._v("#")]),_._v(" 25-消息顺序:保证消息有序,一个topic只能有一个partition吗?")]),_._v(" "),v("ol",[v("li",[_._v("消息在 Kafka 分区上是怎么存储的?")]),_._v(" "),v("li",[_._v("什么是有序消息? 用于解决什么问题?")]),_._v(" "),v("li",[_._v("Kafka 上的消息是有序的吗? 为什么?")]),_._v(" "),v("li",[_._v("要想在 Kafka 上保证消息有序, 应该怎么做?")]),_._v(" "),v("li",[_._v("什么是全局有序? 要保证全局有序, 在 Kafka 上可以怎么做?")]),_._v(" "),v("li",[_._v("要保证消息有序, 一个 topic 只能有一个 partition 吗?")]),_._v(" "),v("li",[_._v("异步消费的时候怎么保证消息有序?")]),_._v(" "),v("li",[_._v("在你使用的多分区方案中, 有没有可能出现分区间负载不均衡的问题? 怎么解决?")]),_._v(" "),v("li",[_._v("增加分区有可能让你的消息失序吗? 怎么解决?")]),_._v(" "),v("li",[_._v("你还知道哪些消息队列是支持有序消息的?")]),_._v(" "),v("li",[_._v("要做到跨 topic 的消息也有序, 难点在哪里?")])]),_._v(" "),v("h5",{attrs:{id:"_26-消息不丢失-生产者收到写入成功响应后消息一定不会丢失吗-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_26-消息不丢失-生产者收到写入成功响应后消息一定不会丢失吗-2"}},[_._v("#")]),_._v(" 26-消息不丢失:生产者收到写入成功响应后消息一定不会丢失吗?")]),_._v(" "),v("ol",[v("li",[_._v("什么是 ISR? 什么是 OSR?")]),_._v(" "),v("li",[_._v("一个分区什么情况下会被挪进去 ISR, 什么时候又会被挪出 ISR?")]),_._v(" "),v("li",[_._v("生产者的 acks 参数有什么含义? 你用的是多少?")]),_._v(" "),v("li",[_._v("怎么感觉业务选择合适的 acks 参数?")]),_._v(" "),v("li",[_._v("消息丢失的场景有哪些?")]),_._v(" "),v("li",[_._v("你遇到过消息丢失的问题吗? 是什么原因引起的? 你怎么排查的? 最终怎么解决的?")]),_._v(" "),v("li",[_._v("当生产者收到发送成功的响应之后, 消息就肯定不会丢失吗?")]),_._v(" "),v("li",[_._v("acks 设置为 all, 消息就一定不会丢失吗?")]),_._v(" "),v("li",[_._v("什么是事务消息? Kafka 支持事务消息吗?")]),_._v(" "),v("li",[_._v("怎么在 Kafka 上支持事务消息?")]),_._v(" "),v("li",[_._v("什么是本地消息表? 拿来做什么的?")]),_._v(" "),v("li",[_._v("你是怎么保证你在执行了业务操作之后, 消息一定发出去了?")]),_._v(" "),v("li",[_._v("怎么保证生产者收到发送成功的响应之后, 消息一定不会丢失? 需要调整哪些参数?")]),_._v(" "),v("li",[_._v("什么是 unclean 选举? 有什么问题? 你用的 Kafka 允许 unclean 选举吗?")]),_._v(" "),v("li",[_._v("在你设计的回查方案里面, 你怎么知道应该回查哪个接口? 你这个能同时支持 HTTP 和 RPC 吗? 能方便扩展到别的协议吗?")]),_._v(" "),v("li",[_._v("你的回查机制有没有可能先收到提交消息? 再收到准备消息? 怎么保证两者的顺序?")]),_._v(" "),v("li",[_._v("如果你已经把消息发到了业务 topic 上, 但是你标记已发送失败了, 怎么办?")])]),_._v(" "),v("h5",{attrs:{id:"_27-重复消费-高并发场景下怎么保证消息不会重复消费-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_27-重复消费-高并发场景下怎么保证消息不会重复消费-2"}},[_._v("#")]),_._v(" 27-重复消费:高并发场景下怎么保证消息不会重复消费?")]),_._v(" "),v("ol",[v("li",[_._v("什么是布隆过滤器?")]),_._v(" "),v("li",[_._v("什么是 bit array?")]),_._v(" "),v("li",[_._v("为什么说尽量把消费者设计成幂等的?")]),_._v(" "),v("li",[_._v("什么场景会造成重复消费?")]),_._v(" "),v("li",[_._v("什么是恰好一次语义, Kafka 支持恰好一次语义吗?")]),_._v(" "),v("li",[_._v("利用唯一索引来实现幂等的方案里, 你是先插入数据到唯一索引, 还是先执行业务? 为什么")]),_._v(" "),v("li",[_._v("如果先插入唯一索引成功了, 但是业务执行失败了, 怎么办?")]),_._v(" "),v("li",[_._v("如果不能使用本地事务, 你怎么利用唯一索引来实现幂等? 中间可能会有什么问题? 你怎么解决?")]),_._v(" "),v("li",[_._v("利用唯一索引来解决幂等问题, 有什么缺陷?")]),_._v(" "),v("li",[_._v("高并发场景下, 怎么解决幂等问题?")]),_._v(" "),v("li",[_._v("在你的高并发幂等方案里面, 为什么要引入 Redis?")]),_._v(" "),v("li",[_._v("Redis 里面的 Key 过期时间该怎么确定?")]),_._v(" "),v("li",[_._v("布隆过滤器 + Redis + 唯一索引里面, 去掉布隆过滤器行不行? 去掉 Redis 呢? 去掉唯一索引呢?")]),_._v(" "),v("li",[_._v("布隆过滤器 + Redis + 唯一索引方案中能不能使用本地布隆过滤器? 怎么用?")]),_._v(" "),v("li",[_._v("布隆过滤器 + Redis + 唯一索引有什么缺陷?")])]),_._v(" "),v("h5",{attrs:{id:"_28-架构设计-如果让你设计一个消息队列-你会怎么设计架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_28-架构设计-如果让你设计一个消息队列-你会怎么设计架构"}},[_._v("#")]),_._v(" 28-架构设计:如果让你设计一个消息队列,你会怎么设计架构")]),_._v(" "),v("ol",[v("li",[_._v("Kafka 为什么要引入分区? 只有 topic 行不行?")]),_._v(" "),v("li",[_._v("Kafka 为什么要强调把 topic 的分区分散在不同的 broker 上?")]),_._v(" "),v("li",[_._v("Kafka 为什么要引入消费者组概念? 只有消费者行不行?")]),_._v(" "),v("li",[_._v("Kafka 为什么要引入 topic?")]),_._v(" "),v("li",[_._v("如果让你来设计一个消息队列, 你会怎么设计架构?")]),_._v(" "),v("li",[_._v("在你的设计里面, 你能支持延迟消息吗?")]),_._v(" "),v("li",[_._v("在你的设计里面, 怎么保证消息有序?")]),_._v(" "),v("li",[_._v("在你的设计里面, 会出现消息丢失的问题吗?")]),_._v(" "),v("li",[_._v("在你的设计里面, 什么场景会引起重复消息?")]),_._v(" "),v("li",[_._v("在你的设计里面, 你觉得性能瓶颈可能出现在哪里?")]),_._v(" "),v("li",[_._v("在你的设计里面, 你还可以考虑怎么提高性能?")])]),_._v(" "),v("h5",{attrs:{id:"_29-高性能-kafka为什么性能那么好-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_29-高性能-kafka为什么性能那么好-2"}},[_._v("#")]),_._v(" 29-高性能:Kafka为什么性能那么好")]),_._v(" "),v("ol",[v("li",[_._v("为什么 Kafka 性能那么好?")]),_._v(" "),v("li",[_._v("为什么零拷贝性能那么好?")]),_._v(" "),v("li",[_._v("写磁盘一定很慢吗? 顺序写为什么很快?")]),_._v(" "),v("li",[_._v("批量操作为什么快? 节省了什么资源?")]),_._v(" "),v("li",[_._v("什么是上下文切换? 为什么上下文切换慢?")]),_._v(" "),v("li",[_._v("分区过多有什么问题? topic 过多有什么问题?")]),_._v(" "),v("li",[_._v("分区有什么好处?")]),_._v(" "),v("li",[_._v("实际中使用批量发送之类的技术, 可能出现什么问题? 怎么解决?")]),_._v(" "),v("li",[_._v("什么是 page cache ? 为什么要引入 page cache?")])]),_._v(" "),v("h5",{attrs:{id:"_30-kafka综合运用-怎么在实践中保证kafka高性能-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_30-kafka综合运用-怎么在实践中保证kafka高性能-2"}},[_._v("#")]),_._v(" 30-Kafka综合运用:怎么在实践中保证Kafka高性能?")]),_._v(" "),v("ol",[v("li",[_._v("什么是交换区?")]),_._v(" "),v("li",[_._v("如果来不及发送, 那么性能瓶颈可能在哪里?")]),_._v(" "),v("li",[_._v("怎么优化发送者的发送性能?")]),_._v(" "),v("li",[_._v("批次发送的时候, 多大的批次才是最合适的?")]),_._v(" "),v("li",[_._v("使用压缩有什么优缺点? 怎么选择合适的压缩算法?")]),_._v(" "),v("li",[_._v("怎么优化 broker?")]),_._v(" "),v("li",[_._v("怎么优化 broker 所在的操作系统?")]),_._v(" "),v("li",[_._v("什么是 TCP 读写缓冲区? 怎么调优?")]),_._v(" "),v("li",[_._v("哪些参数可以影响 Kafka 的主从同步? 你优化过吗?")]),_._v(" "),v("li",[_._v("你有优化过 Kafka 的 JVM 吗? 怎么优化的?")])]),_._v(" "),v("h5",{attrs:{id:"消息队列面试一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息队列面试一图懂"}},[_._v("#")]),_._v(" 消息队列面试一图懂")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/9c75c2faf5905eaa5e92d0e4e2792eaf-20231223175003-t6sb1mf.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"模拟面试-缓存面试思路一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试-缓存面试思路一图懂"}},[_._v("#")]),_._v(" 模拟面试-缓存面试思路一图懂")]),_._v(" "),v("h5",{attrs:{id:"_31-为什么redis不立刻删除已经过期的数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_31-为什么redis不立刻删除已经过期的数据"}},[_._v("#")]),_._v(" 31-为什么Redis不立刻删除已经过期的数据?")]),_._v(" "),v("ol",[v("li",[_._v("Redis 是怎么删除过期 key 的?")]),_._v(" "),v("li",[_._v("Redis 为什么不立刻删除已经过期的 key?")]),_._v(" "),v("li",[_._v("Redis 为什么不每个 key 都启动一个定时器, 监控过期时间?")]),_._v(" "),v("li",[_._v("Redis 是如何执行定期删除的?")]),_._v(" "),v("li",[_._v("为什么 Redis 在定期删除的时候不一次性把所有的过期 key 都删除掉?")]),_._v(" "),v("li",[_._v("当你从 Redis 上查询数据的时候, 有可能查询到过期的数据吗?")]),_._v(" "),v("li",[_._v("当 Redis 生成 RDB 文件的时候, 会怎么处理过期的 key?")]),_._v(" "),v("li",[_._v("当 Redis 重写 AOF 文件的时候, 会怎么处理过期的 key?")]),_._v(" "),v("li",[_._v("Redis 定期删除的循环是不是执行得越频繁就越好?")]),_._v(" "),v("li",[_._v("如果设计一个本地缓存, 你会怎么实现删除过期 key 的功能?")]),_._v(" "),v("li",[_._v("你是怎么确定过期时间的? 过期时间太长会怎样, 太短又会怎样?")])]),_._v(" "),v("h5",{attrs:{id:"_32-缓存淘汰策略-怎么淘汰缓存命中率才不会下降-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_32-缓存淘汰策略-怎么淘汰缓存命中率才不会下降-2"}},[_._v("#")]),_._v(" 32-缓存淘汰策略:怎么淘汰缓存命中率才不会下降?")]),_._v(" "),v("ol",[v("li",[_._v("你知道什么是 LFU, 什么是 LRU 吗? 可不可以手写一个?")]),_._v(" "),v("li",[_._v("什么情况下使用 LFU, 什么情况下使用 LRU?")]),_._v(" "),v("li",[_._v("Redis 支持哪些淘汰策略? 你们公司的 Redis 上的淘汰策略使用了哪个? 为什么用这个?")]),_._v(" "),v("li",[_._v("你使用的本地缓存是如何控制内存使用量的?")]),_._v(" "),v("li",[_._v("你业务里面的缓存命中率有多高? 还能不能进一步提高? 怎么进一步提高?")]),_._v(" "),v("li",[_._v("假如说 A 和 B 两个业务共用一个 Redis, 那么有办法控制 A 业务的 Redis 内存使用量吗? 怎么控制?")]),_._v(" "),v("li",[_._v("现在我的业务里面有普通用户和 VIP 用户. 现在我希望在缓存内存不足的时候, 优先淘汰普通用户的数据, 该怎么做?")])]),_._v(" "),v("h5",{attrs:{id:"_33-缓存模式-缓存模式能不能解决缓存一致性问题-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_33-缓存模式-缓存模式能不能解决缓存一致性问题-2"}},[_._v("#")]),_._v(" 33-缓存模式:缓存模式能不能解决缓存一致性问题?")]),_._v(" "),v("ol",[v("li",[_._v("什么是 Cache Aside, 它能不能解决数据一致性问题?")]),_._v(" "),v("li",[_._v("什么是 Read Through, 它能不能解决数据一致性问题?")]),_._v(" "),v("li",[_._v("什么是 Write Through, 它能不能解决数据一致性问题?")]),_._v(" "),v("li",[_._v("什么是 Write Back, 它有什么缺点, 能不能解决一致性问题?")]),_._v(" "),v("li",[_._v("什么是 Refresh Ahead, 它能不能解决一致性问题?")]),_._v(" "),v("li",[_._v("什么是 Singleflight 模式? 你用它解决过什么问题?")]),_._v(" "),v("li",[_._v("在具体的工作场景中, 你是怎么更新数据的? 会不会有数据不一致的问题? 怎么解决?")]),_._v(" "),v("li",[_._v("什么是延迟双删, 使用延迟双删能不能解决数据一致性问题?")]),_._v(" "),v("li",[_._v("你知道哪些缓存模式, 用过哪些模式?")])]),_._v(" "),v("h5",{attrs:{id:"_34-缓存一致性问题-高并发服务如何保证缓存一致性-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_34-缓存一致性问题-高并发服务如何保证缓存一致性-2"}},[_._v("#")]),_._v(" 34-缓存一致性问题:高并发服务如何保证缓存一致性?")]),_._v(" "),v("ol",[v("li",[_._v("为什么会有数据不一致的问题?")]),_._v(" "),v("li",[_._v("你在使用缓存的时候怎么解决数据不一致的问题?")]),_._v(" "),v("li",[_._v("当你的数据不一致的时候, 你多久能够发现?")]),_._v(" "),v("li",[_._v("如果你使用了本地缓存和 Redis, 那么更新数据的时候你怎么更新?")]),_._v(" "),v("li",[_._v("使用分布式锁能不能解决数据一致性问题, 有什么缺点?")]),_._v(" "),v("li",[_._v("你能保证更新数据库和更新缓存同时成功吗? 如果不能, 你怎么解决?")]),_._v(" "),v("li",[_._v("你有什么方法可以解决并发更新导致的数据不一致性问题?")])]),_._v(" "),v("h5",{attrs:{id:"_35-缓存问题-怎么解决缓存穿透-击穿和雪崩问题-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_35-缓存问题-怎么解决缓存穿透-击穿和雪崩问题-2"}},[_._v("#")]),_._v(" 35-缓存问题:怎么解决缓存穿透,击穿和雪崩问题?")]),_._v(" "),v("ol",[v("li",[_._v("什么是缓存穿透, 击穿和雪崩?")]),_._v(" "),v("li",[_._v("你平时遇到过缓存穿透, 击穿和雪崩吗? 什么原因引起的? 最终是怎么解决的?")]),_._v(" "),v("li",[_._v("你还遇到过什么跟缓存有关的事故? 最终都是怎么解决的?")]),_._v(" "),v("li",[_._v("在你的系统里面, 如果 Redis 崩溃了会发生什么?")]),_._v(" "),v("li",[_._v("怎么在 Redis 崩溃之后保护好数据库?")])]),_._v(" "),v("h5",{attrs:{id:"_36-redis单线程-为什么redis用单线程而memcached用多线程-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_36-redis单线程-为什么redis用单线程而memcached用多线程-2"}},[_._v("#")]),_._v(" 36-Redis单线程:为什么Redis用单线程而Memcached用多线程?")]),_._v(" "),v("ol",[v("li",[_._v("操作系统中的上下文切换有什么开销?")]),_._v(" "),v("li",[_._v("Redis 真的是单线程的吗?")]),_._v(" "),v("li",[_._v("Redis 为什么后面又引入了多线程?")]),_._v(" "),v("li",[_._v("Redis 后面的引入的多线程模型是怎么运作的? 相比原本的单线程模型有什么改进?")]),_._v(" "),v("li",[_._v("同样是缓存, 为什么 Memcached 使用了多线程?")]),_._v(" "),v("li",[_._v("什么是 epoll? 和 poll, select 比起来, 有什么优势?")]),_._v(" "),v("li",[_._v("什么是 Reactor 模式?")]),_._v(" "),v("li",[_._v("为什么 Redis 的性能那么好?")]),_._v(" "),v("li",[_._v("你可以说说 Redis 的 IO 模型吗?")]),_._v(" "),v("li",[_._v("为什么 Redis 可以用单线程, 但是 Kafka 之类的中间件确不能使用单线程呢?")])]),_._v(" "),v("h5",{attrs:{id:"_37-分布式锁-如何保证redis分布式锁的高可用和高性能-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_37-分布式锁-如何保证redis分布式锁的高可用和高性能-2"}},[_._v("#")]),_._v(" 37-分布式锁:如何保证Redis分布式锁的高可用和高性能?")]),_._v(" "),v("ol",[v("li",[_._v("什么是分布式锁? 你用过分布式锁吗?")]),_._v(" "),v("li",[_._v("你使用的分布式锁性能如何, 可以优化吗?")]),_._v(" "),v("li",[_._v("怎么用 Redis 来实现一个分布式锁?")]),_._v(" "),v("li",[_._v("怎么确定分布式锁的过期时间?")]),_._v(" "),v("li",[_._v("如果分布式锁过期了, 但是业务还没有执行完毕, 怎么办?")]),_._v(" "),v("li",[_._v("加锁的时候得到了超时响应, 怎么办?")]),_._v(" "),v("li",[_._v("加锁的时候如果锁被人持有了, 这时候怎么办?")]),_._v(" "),v("li",[_._v("分布式锁为什么要续约? 续约失败了怎么办? 如果重试一直都失败, 怎么办?")]),_._v(" "),v("li",[_._v("怎么减少分布式锁竞争?")]),_._v(" "),v("li",[_._v("你知道 redlock 是什么吗?")])]),_._v(" "),v("h5",{attrs:{id:"_38-缓存综合应用-怎么用缓存来提高整个应用的性能-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_38-缓存综合应用-怎么用缓存来提高整个应用的性能-2"}},[_._v("#")]),_._v(" 38-缓存综合应用:怎么用缓存来提高整个应用的性能?")]),_._v(" "),v("ol",[v("li",[_._v("你是如何利用缓存来提高系统性能的?")]),_._v(" "),v("li",[_._v("当你的缓存崩溃了的时候, 你的系统会怎么样?")]),_._v(" "),v("li",[_._v("你们公司的 Redis 是如何部署的, 性能怎么样?")]),_._v(" "),v("li",[_._v("假如说有一个服务 A 要调用服务 B, 那么能不能让 A 把 B 的结果缓存下来, 这样下次就不用调用了? 这种做法有什么优缺点?")]),_._v(" "),v("li",[_._v("为什么要做缓存预加载, 怎么做预加载?")])]),_._v(" "),v("h5",{attrs:{id:"缓存面试一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存面试一图懂"}},[_._v("#")]),_._v(" 缓存面试一图懂")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/23e884c0da65e31fa76175dc41e68a83-20231223175003-iexvt84.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"模拟面试-nosql面试思路一图懂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#模拟面试-nosql面试思路一图懂"}},[_._v("#")]),_._v(" 模拟面试-NoSQL面试思路一图懂")]),_._v(" "),v("h5",{attrs:{id:"_39-elasticsearch-高可用-怎么保证elasticsearch的高可用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_39-elasticsearch-高可用-怎么保证elasticsearch的高可用"}},[_._v("#")]),_._v(" 39-Elasticsearch 高可用:怎么保证Elasticsearch的高可用?")]),_._v(" "),v("ol",[v("li",[_._v("Elasticsearch 的节点有什么角色? 一个节点可以扮演多个角色吗?")]),_._v(" "),v("li",[_._v("在实践中, 怎么合理安排不同节点扮演的角色?")]),_._v(" "),v("li",[_._v("什么是候选主节点和投票节点? 投票节点可以被选为主节点吗? 为什么要引入投票节点?")]),_._v(" "),v("li",[_._v("可以说一下你们公司的 Elasticsearch 是如何部署的吗? 性能如何?")]),_._v(" "),v("li",[_._v("你用 Elasticsearch 解决过什么问题? 为什么用 Elasticsearch? 可以用别的框架吗?")]),_._v(" "),v("li",[_._v("Elasticsearch 为什么引入分片? 为了解决什么问题?")]),_._v(" "),v("li",[_._v("当一个写入请求发送到 Elasticsearch 之后, 发生了什么?")]),_._v(" "),v("li",[_._v("Elasticsearch 是实时的吗?")]),_._v(" "),v("li",[_._v("Elasticsearch 的 Translog 是拿来干什么的? 它可以保证数据一定不丢失吗?")]),_._v(" "),v("li",[_._v("什么是 Commit Point? 用来干什么?")]),_._v(" "),v("li",[_._v("Elasticsearch 在合并段的时候, 会影响到已有的查询吗? 一个查询怎么知道应该用合并前的段, 还是应该用合并后的段?")]),_._v(" "),v("li",[_._v("如果我的写入数据流量很大, 怎么保证我的 Elasticsearch 不会崩溃?")]),_._v(" "),v("li",[_._v("你知道什么是协调节点吗? 它的作用是什么? 怎么保证协调节点高可用?")])]),_._v(" "),v("h5",{attrs:{id:"_40-elasticsearch查询-怎么优化elasticsearch的查询性能-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_40-elasticsearch查询-怎么优化elasticsearch的查询性能-2"}},[_._v("#")]),_._v(" 40-Elasticsearch查询:怎么优化Elasticsearch的查询性能?")]),_._v(" "),v("ol",[v("li",[_._v("你的业务写入和查询的性能如何? Elasticsearch 的性能瓶颈是多少?")]),_._v(" "),v("li",[_._v("如何设计 Ealsticsearch 的索引?")]),_._v(" "),v("li",[_._v("你有没有优化过 Elasticsearch 的查询性能? 怎么优化? 为什么可以这么优化?")]),_._v(" "),v("li",[_._v("为什么 Elasticsearch 的分页查询也那么慢? 可以怎么优化?")]),_._v(" "),v("li",[_._v("你有没有优化过 Elasticsearch 的 JVM? 怎么优化的?")]),_._v(" "),v("li",[_._v("如果 Elasticsearch 经常出现 Full GC, 怎么排查和优化?")]),_._v(" "),v("li",[_._v("怎么为 Elasticsearch 选择适合垃圾回收算法?")]),_._v(" "),v("li",[_._v("swap 对 Elasticsearch 有什么影响? 应该怎么调整?")]),_._v(" "),v("li",[_._v("为什么 Elasticsearch 容易出现文件描述符耗尽的问题? 可以怎么优化?")])]),_._v(" "),v("h5",{attrs:{id:"_41-mongodb-mongodb是怎么做到高可用的-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_41-mongodb-mongodb是怎么做到高可用的-2"}},[_._v("#")]),_._v(" 41-MongoDB:MongoDB是怎么做到高可用的?")]),_._v(" "),v("ol",[v("li",[_._v("你们公司的 MongoDB 是如何部署的? 可用性有多高?")]),_._v(" "),v("li",[_._v("你用 MongoDB 解决过什么问题? 你为什么要用 MongoDB? 用 MySQL 行不行?")]),_._v(" "),v("li",[_._v("和关系型数据库比起来, MongoDB 有哪些优势?")]),_._v(" "),v("li",[_._v("MongoDB 是如何分片的?")]),_._v(" "),v("li",[_._v("MongoDB 的块是什么?")]),_._v(" "),v("li",[_._v("什么情况下会触发块迁移? 怎么迁移?")]),_._v(" "),v("li",[_._v("MongoDB 的负载均衡(再平衡)是指什么?")]),_._v(" "),v("li",[_._v("MongoDB 的配置服务器有什么作用?")]),_._v(" "),v("li",[_._v("MongoDB 的复制机制是怎样的?")]),_._v(" "),v("li",[_._v("为什么 MongoDB 的 oplog 总是很多?")]),_._v(" "),v("li",[_._v("怎么控制 MongoDB 的写入语义? 你用的是什么语义? 为什么用这个语义?")]),_._v(" "),v("li",[_._v("有没有遇到过配置服务器崩溃的问题? 怎么提高配置服务器的可用性?")]),_._v(" "),v("li",[_._v("当 MongoDB 的主节点崩溃之后, 如何选出一个新的主节点?")]),_._v(" "),v("li",[_._v("怎么样可以让 MongoDB 在主从选举的时候优先选择同机房的从节点?")])]),_._v(" "),v("h5",{attrs:{id:"_42-mongodb高性能-怎么优化mongodb的查询性能-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_42-mongodb高性能-怎么优化mongodb的查询性能-2"}},[_._v("#")]),_._v(" 42-MongoDB高性能:怎么优化MongoDB的查询性能?")]),_._v(" "),v("ol",[v("li",[_._v("你的业务里面使用 MongoDB 的性能如何? 能撑住多大的读写流量?")]),_._v(" "),v("li",[_._v("你有没有遇到过 MongoDB 的性能问题? 后面是如何解决的?")]),_._v(" "),v("li",[_._v("当我一个查询请求落到了 MongoDB 之上后, MongoDB 是怎么执行这个查询的?")]),_._v(" "),v("li",[_._v("mongos 是什么? 拿来干什么? 怎么优化它的性能?")]),_._v(" "),v("li",[_._v("怎么设计 MongoDB 的索引? 怎么判定一个索引是否合适?")]),_._v(" "),v("li",[_._v("什么是 ESR 规则? 为何要遵守 ESR 规则? 不遵守行不行?")]),_._v(" "),v("li",[_._v("大文档有什么问题? 可以怎么解决大文档引发的问题?")]),_._v(" "),v("li",[_._v("什么时候要嵌入文档? 有什么优势?")]),_._v(" "),v("li",[_._v("怎么优化 MongoDB 的排序(分页)查询?")]),_._v(" "),v("li",[_._v("为什么要尽可能只查询必要的字段?")]),_._v(" "),v("li",[_._v("怎么优化 MongoDB 所在的操作系统? 这些优化为什么会有效果?")])]),_._v(" "),v("h5",{attrs:{id:"一图懂-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一图懂-2"}},[_._v("#")]),_._v(" 一图懂")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/95d66dd42aa434c03fa1970031ef224b-20231223175002-pycuz1q.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("p",[_._v("​"),v("img",{attrs:{src:"/img/5c58317ae49c0d81630c4eda9b50c42c-20231223175002-2z0aqyi.jpg",alt:"图片"}}),_._v("​")]),_._v(" "),v("h4",{attrs:{id:"结束语-未来掌握在自己手中"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#结束语-未来掌握在自己手中"}},[_._v("#")]),_._v(" 结束语-未来掌握在自己手中")]),_._v(" "),v("blockquote",[v("p",[_._v("夯实基础:万丈高楼平地起")])]),_._v(" "),v("p",[_._v("第一步也是非常重要的一步就是打好基础, "),v("strong",[_._v("基础是构筑高楼大厦的基石")]),_._v(". 这意味着要理解和掌握编程语言的基础知识, 如语法, 数据类型, 控制结构等. 没有这些基础, 就很难理解框架为什么这么设计, 方案为什么要这么设计.")]),_._v(" "),v("p",[_._v("此外, "),v("strong",[_._v("基础决定了你的上限")]),_._v('. 在这个行业, 一个大家普遍认同的观点就是, 那些在编程领域取得突出成就的人, 往往都是那些能够深入理解基础概念, 并能够灵活运用这些知识解决实际问题的人. 所以无论选择学习哪种编程语言或技术, 都需要有一定的编程基础和算法基础. 这些基础知识和技能是你的 "学习工具箱", 无论走到哪里, 都能帮助你快速理解和掌握新的知识和技术.')]),_._v(" "),v("p",[_._v("基础知识的重要性在课程里面也体现得淋漓尽致. 比如每次讲到性能优化的时候, 都会提及的操作系统优化, 实际上就是操作系统原理的简单应用而已.")]),_._v(" "),v("p",[_._v('因此, 如果你寻求 "骚操作", 首先应该做的是夯实基础. 只有当你的基础足够扎实, 才能更好地理解和掌握新技术, 才能在编程的道路上走得更高, 更远.')]),_._v(" "),v("blockquote",[v("p",[_._v("博闻广识:眼界决定边界")])]),_._v(" "),v("p",[_._v("在当今技术日新月异的时代, 必须不断拓展自己的知识领域, 以适应不断变化的市场需求.")]),_._v(" "),v("p",[_._v("了解多个领域的知识有助于开拓思维. 通过学习其他领域的知识, 可以从中汲取新的思路和想法, 并将其应用到自己的工作中. 这不仅可以提高你的创新能力, 还可以帮助你从更广阔的视角看待问题, 从而更好地解决问题. 正如同课程里面看到的各种方案, 其实都借鉴了已有开源框架的思想, 解决思路.")]),_._v(" "),v("p",[_._v("此外, 拓宽知识面还有助于提高解决问题的能力, 可以让你深刻理解这些方案背后一脉相承的思想. 并且这些技术, 解决方案各有优缺点, 通过总结这些优缺点, 你更加能够理解在什么场景下应该使用什么样的方案, 并反哺到自己的工作中.")]),_._v(" "),v("p",[_._v("总而言之, 你只有看得多了, 想得多了, 才能拉开和别人的差距, 才能实现创新, 给未来的自己争取更多选择的权利.")]),_._v(" "),v("blockquote",[v("p",[_._v("创新:立于不败之地")])]),_._v(" "),v("p",[_._v("如果你想要在未来的工作生涯中, 跨过 35 岁职业危机, 保持竞争力甚至更进一步, 那么创新精神是必不可少的.")]),_._v(" "),v("p",[_._v("创新可以帮助你满足不断变化的市场需求. 在技术快速发展的今天, 市场需求也在不断变化. 你需要具备创新精神, 不断探索新技术, 新方法和新思路, 提供更加高效, 灵活, 安全的解决方案, 为公司赢得竞争优势.")]),_._v(" "),v("p",[_._v("此外, 创新还可以帮助你提高个人竞争力. 在竞争激烈的职场中, 具备创新精神和创新能力是你脱颖而出的关键. 只有具备创新精神, 你才能在职场中不断推出新的想法和解决方案, 获得更好的职业发展和薪资待遇. 同时你也更容易获得领导和同事的认可和信任, 从而在职场中获得更多的机会和资源.")]),_._v(" "),v("p",[_._v("‍")]),_._v(" "),v("p",[_._v("‍")])])}),[],!1,null,null,null);v.default=s.exports}}]);