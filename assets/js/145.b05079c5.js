(window.webpackJsonp=window.webpackJsonp||[]).push([[145],{461:function(v,_,t){"use strict";t.r(_);var a=t(7),s=Object(a.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"_500-分布式技术原理与算法解析-极客时间-🌸"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_500-分布式技术原理与算法解析-极客时间-🌸"}},[v._v("#")]),v._v(" 500.分布式技术原理与算法解析(极客时间)🌸")]),v._v(" "),_("h3",{attrs:{id:"开篇词"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#开篇词"}},[v._v("#")]),v._v(" 开篇词")]),v._v(" "),_("h4",{attrs:{id:"开篇词-四纵四横-带你透彻理解分布式技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#开篇词-四纵四横-带你透彻理解分布式技术"}},[v._v("#")]),v._v(" 开篇词-四纵四横,带你透彻理解分布式技术")]),v._v(" "),_("p",[v._v("在众多计算机技术当中, 分布式技术无疑是最璀璨的明珠之一. 毫不夸张地说, 没有分布式技术就没有互联网, 也就没有现在的阿里巴巴, 腾讯, 亚马逊, Facebook, 谷歌等科技巨头, 更不会有以信息技术为核心的, 对人类历史产生巨大变革的第三次工业革命. 万维网, Email, DNS 等, 都是分布式系统的典型代表.")]),v._v(" "),_("p",[v._v("2007 年, 我在西安电子科技大学攻读博士期间, 就开始研究并行与分布式计算; 毕业后, 在 IBM 做过 HPC 大规模负载管理系统 LSF 相关的设计和研发工作, 在华为负责过分布式 IoT 相关项目的架构设计, 以及电信级业务微服务框架, 函数服务框架的设计工作, 也从事过区块链相关的研究工作. 现在, 我在智载云帆负责技术体系的构建, 专注于无服务器 Serverless 的架构实践.")]),v._v(" "),_("p",[v._v("从我深入研究分布式技术这十多年的经验来看, 分布式技术概念繁多, 知识庞杂, 新兴技术层出不穷, 令许多新手望而却步, 而许多有一定年限工作经验的老手, 虽然也能对一些概念滔滔不绝, 但追问到实质性问题就变得磕磕巴巴, 顾左右而言它. 比如:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("各种分布式概念")]),v._v(", 名词学了一大堆, 但经常张冠李戴, 傻傻分不清楚;")]),v._v(" "),_("li",[v._v("做了多年技术, 也参与了很多分布式技术实践, 却无法回答工作中各种分布式技术, 组件, 框架选型背后的根源;")]),v._v(" "),_("li",[v._v("在一个分布式技术配套的典型场景往往能驾轻就熟, 但一旦稍微变更考察业务场景, 业务目标后, 就变得毫无头绪.")])]),v._v(" "),_("p",[v._v("究其原因, 主要是"),_("mark",[_("strong",[v._v("知识碎片化, 不成体系, 见树不见林")])]),v._v('​ **. ** 如果再追究更深层次的原因, 那无外乎就是: **信息碎片化与信息孤立. ** 在信息泛滥的信息时代, 各种经典教材, 最新文章自然是唾手可得. 但教材固然经典但严谨有余浅出不够, 最重要的是没有与时下最新的场景相结合, 一方面是因为教材"年久失修", 另一方面确实是因为分布式领域新技术推出的速度令人叹为观止; 而网上的各种技术文章虽然多, 却鲜有体系化的说明, 一个个概念如同一座座信息孤岛. **如果不能体系化地理解这些概念, 何谈掌握, 更谈不上真正地去综合运用这些知识了. **')]),v._v(" "),_("p",[v._v('其实, 在工作, 面试, 演讲等多种场合, 也经常会有人问我: "聂博士, 分布式领域的新概念繁多, 各种框架五花八门, 各种组件层出不穷, 应该如何应对啊? "我回答说: "其实你已经有答案了. "')]),v._v(" "),_("p",[v._v('看着他们满脸疑惑, 我笑着问: "RISC 芯片, 程序设计中的封装, 继承, 还有现在提倡的中台战略, 它们都在做一件什么事情呢? "他们答道: "莫非是重用? "')]),v._v(" "),_("p",[v._v('我说: "是的, '),_("strong",[v._v('既然指令可以重用, 代码可以重用, 技术, 业务, 数据等都可以重用, 为什么知识体系不可以呢? 学好分布式通识课, 掌握了分布式的核心技术, 体系, 就会发现很多新技术, 新框架, 新组件只不过是新瓶装旧酒, 将分布式核心技术进行了再包装, 再组合, 至多也就是做了一点延伸而已."')])]),v._v(" "),_("p",[v._v("那么, 分布式通识课究竟该如何学呢?")]),v._v(" "),_("p",[v._v("第一, 分布式技术错综复杂, 各种技术相互耦合, 确实无法简单地像网络等技术一样划分层次, 所以我会结合自己多年的积累和思考, 首先为你梳理出一个脉络清晰, "),_("strong",[v._v("四纵四横")]),v._v("的分布式核心技术知识体系, 然后从这个纵横的技术体系中抽取最核心, 最普适的技术思想以及概念, 结合各种适用场景一一解析. 这样的设计, 旨在帮助你找到核心知识点, 并将这些知识点联系起来, 快速形成分布式核心技术的知识网络, 从而形成自己的技术判断力, 进而规划出自己的技术路线.")]),v._v(" "),_("p",[v._v("第二, 从一个熟知的事物出发, 进行浅出的讲解, 帮助你从已有知识体系扩展到新的知识体系, 从而迅速, 牢固地掌握分布式技术的核心知识点.")]),v._v(" "),_("p",[v._v("第三, 透过表象深入讲解技术本质, 而不是 case by case 地讲解, 帮助你知其然并知其所以然, 真正做到理解与运用时的举一反三.")]),v._v(" "),_("p",[v._v('第四, 针对同一分布式问题的不同方法, 从多维度, 多角度进行对比, 分析, 方便你在工作中灵活选型, 避免重复"造轮子". 你甚至可以综合权衡各种方法的优缺点, 提炼发明出新的方法, 最终做到活学活用.')]),v._v(" "),_("p",[v._v('讲到这里, 你是不是也有点摩拳擦掌, 跃跃欲试了呢? "分布式世界这么大, 我要去看看! "别慌, 请先看完这份技术地图.')]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/3650b5dc5f47b7e5e4b29f464acc448a-20230731163147-bwme583.png",alt:""}})]),v._v(" "),_("p",[v._v("首先, 按照业务的架构层次栈, 自底向上按照"),_("strong",[v._v("资源, 通信, 数据与计算")]),v._v('的维度, 梳理出了 4 个技术层次: 分布式资源池化, 分布式通信, 分布式数据存储与管理, 分布式计算. 这样的划分符合业务架构设计的一般规律, 即  **"**​'),_("mark",[_("strong",[v._v("在一定资源上, 进行一定通信, 通过一定计算, 完成一定数据的加工和处理, 从而对外提供特定的服务")])]),v._v("​ "),_("strong",[v._v('".')]),v._v("  另一方面, 这样的划分也整合了零散的知识点, 具有完备性.")]),v._v(" "),_("p",[v._v("既然横向的 4 个层次都已经完备了, 那为什么又多出了 4 个纵向的技术呢? 如果把横向的 4 个层次比作派生类的话, 那么纵向的 4 条技术线应该是它们的"),_("strong",[v._v("基类")]),v._v(". 因为, 在分布式环境下, 无论是资源, 通信, 数据还是计算, 都需要去解决协同, 调度, 追踪高可用, 还有部署的问题. 因此, 我从横向的技术层次中, 提炼出"),_("strong",[v._v("分布式协同, 分布式调度, 分布式追踪与高可用, 分布式部署")]),v._v(" 4 个纵向技术线. 由于分布式追踪, 分布式部署虽属于支撑技术, 但并不会影响业务的构成, 因此不会在本专栏中进行讲解.")]),v._v(" "),_("p",[v._v("最后, 如果说现在分布式领域里各种包装出来的, 五花八门的新技术, 像是令人高不可攀的女神, 男神的话, 那么这个分布式通识课程中所提炼出来的体系和核心知识点无疑就是女神, 男神素颜的样子. 我想说, 等你**看尽素颜, 无论是女神, 男神也好, 还是各种高大上的技术也好, 也就不会觉得那么高不可攀了. **")]),v._v(" "),_("h4",{attrs:{id:"_01-分布式缘何而起-从单兵-到游击队-到集团军"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_01-分布式缘何而起-从单兵-到游击队-到集团军"}},[v._v("#")]),v._v(" 01-分布式缘何而起:从单兵,到游击队,到集团军")]),v._v(" "),_("p",[v._v("本节先来聊聊什么是分布式. 与其直接用些抽象, 晦涩的技术名词去给分布式下一个定义, 还不如从理解分布式的发展驱动因素开始, 一起去探寻它的本质, 自然而然地也就清楚它的定义了.")]),v._v(" "),_("h5",{attrs:{id:"分布式起源"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式起源"}},[v._v("#")]),v._v(" 分布式起源")]),v._v(" "),_("h6",{attrs:{id:"_1-单兵模式-单机模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-单兵模式-单机模式"}},[v._v("#")]),v._v(" (1)单兵模式:单机模式")]),v._v(" "),_("p",[v._v("所谓"),_("strong",[v._v("单机模式")]),v._v("是指, 所有应用程序和数据均部署在一台电脑或服务器上, 由一台计算机完成所有的处理.")]),v._v(" "),_("p",[v._v("以铁路售票系统为例, 铁路售票系统包括用户管理, 火车票管理和订单管理等模块, 数据包括用户数据, 火车票数据和订单数据等, 如果使用单机模式, 那么所有的模块和数据均会部署在同一台计算机上, 也就是说数据存储, 请求处理均由该计算机完成. 这种模式的好处是功能, 代码和数据集中, 便于维护, 管理和执行.")]),v._v(" "),_("p",[v._v("单机模式的示意图, 如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c47f921ae55f64b902b03db7869b8f35-20230731163147-8lakykx.png",alt:""}})]),v._v(" "),_("p",[v._v("这里需要注意的是, **本文的所有示意图中, 紫色虚线表示在一台计算机内. **")]),v._v(" "),_("p",[v._v("事物均有两面性, 再来看看单机模式的缺点. 单个计算机的处理能力取决于 CPU 和内存等, 但硬件的发展速度和性能是有限的, 而且升级硬件的性价比也是要考虑的, 由此决定了 "),_("strong",[v._v("CPU 和内存等硬件的性能将成为单机模式的瓶颈")]),v._v(".")]),v._v(" "),_("p",[v._v("单机模式和单兵作战模式非常相似, 单台计算机能力再强, 就好比特种兵以一敌百, 但终归能力有限. 此外, 将所有任务都交给一台计算机, 也会存在将所有鸡蛋放到一个篮子里的风险, 也就是"),_("strong",[v._v("单点失效问题")]),v._v(".")]),v._v(" "),_("p",[v._v("归纳一下, 单机模式的主要问题是: "),_("mark",[_("strong",[v._v("性能受限, 存在单点失效问题")])]),v._v("​ **. **")]),v._v(" "),_("h6",{attrs:{id:"_2-游击队模式-数据并行或数据分布式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-游击队模式-数据并行或数据分布式"}},[v._v("#")]),v._v(" (2)游击队模式:数据并行或数据分布式")]),v._v(" "),_("p",[v._v("既然单机模式存在性能和可用性的问题. 那么, 有没有什么更好的计算模式呢? 答案是肯定的.")]),v._v(" "),_("p",[v._v("为解决单机模式的问题, 并行计算得到了发展, 进而出现了数据并行(也叫作数据分布式)模式. "),_("strong",[v._v("并行计算")]),v._v("采用消息共享模式使用多台计算机并行运行或执行多项任务, "),_("strong",[v._v("核心原理是每台计算机上执行相同的程序, 将数据进行拆分放到不同的计算机上进行计算")]),v._v(".")]),v._v(" "),_("p",[v._v("请注意, 并行计算强调的是"),_("strong",[v._v("对数据进行拆分")]),v._v(", 任务程序在每台机器上运行. 要达到这个目的, 必须首先把单机模式中的应用和数据分离, 才可能实现对数据的拆分. 这里的应用就是执行任务的程序, 任务就是提交的请求. 以铁路售票系统为例, 运行在服务器上的用户管理, 火车票管理和订单管理等程序就是应用, 用户提交的查询火车票, 购买火车票的请求就是任务.")]),v._v(" "),_("p",[v._v("在单机模式中, 应用和数据均在一台计算机或服务器上, 要实现数据的并行, 首先必须将应用和数据分离以便将应用部署到不同的计算机或服务器上; 然后, 对同类型的数据进行拆分, 比方说, 不同计算机或服务器上的应用可以到不同的数据库上获取数据执行任务.")]),v._v(" "),_("p",[v._v("以铁路售票系统的数据并行为例, 主要包括两个步骤, 如下所示:")]),v._v(" "),_("p",[_("strong",[v._v("第一步")]),v._v(", 将应用与数据分离, 分别部署到不同的服务器上:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/98ed3725da1903f97dce8e4737de33d3-20230731163147-aeda0ob.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("第二步")]),v._v(", 对数据进行拆分, 比如把同一类型的数据拆分到两个甚至更多的数据库中, 这样应用服务器上的任务就可以针对不同数据并行执行了.")]),v._v(" "),_("p",[v._v("对于铁路售票系统来说, 根据线路将用户, 火车票和订单数据拆分到不同的数据库中, 部署到不同的服务器上, 比如京藏线的数据放在数据库服务器 1 上的数据库中, 沪深线的数据放在数据库服务器 2 上的数据库中.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4c77424ca9c3c78474c1ce0f94e824ec-20230731163147-ehyamwn.png",alt:""}})]),v._v(" "),_("p",[v._v("需要注意的是, 为了更好地帮助你理解这个数据拆分的过程, 在这里选择拆分数据库的方式进行讲解. 由于数据库服务器本身的并发特性, 因此也可以根据你的业务情况进行选择, 比方说所有业务服务器共用一个数据库服务器, 而不一定真的需要去进行数据库拆分.")]),v._v(" "),_("p",[v._v("可以看出, 在数据并行或数据分布式模式中, "),_("strong",[v._v("每台计算机都是全量地从头到尾一条龙地执行一个程序")]),v._v(", 就像一个全能的铁道游击队战士. 所以, 也可以将这种模式形象地理解成游击队模式.")]),v._v(" "),_("p",[v._v("这种模式的好处是, 可以利用多台计算机并行处理多个请求, 使得可以在相同的时间内完成更多的请求处理, 解决了单机模式的计算效率瓶颈问题. 但这种模式仍然存在如下几个问题, 在实际应用中, 需要对其进行相应的优化:")]),v._v(" "),_("ul",[_("li",[v._v('相同的应用部署到不同的服务器上, 当大量用户请求过来时, 如何能比较均衡地转发到不同的应用服务器上呢? 解决这个问题的方法是设计一个负载均衡器, 会在"分布式高可靠"模块讲述负载均衡的相关原理.')]),v._v(" "),_("li",[v._v("当请求量较大时, 对数据库的频繁读写操作, 使得数据库的 IO 访问成为瓶颈. 解决这个问题的方式是读写分离, 读数据库只接收读请求, 写数据库只接收写请求, 当然读写数据库之间要进行数据同步, 以保证数据一致性.")]),v._v(" "),_("li",[v._v("当有些数据成为热点数据时, 会导致数据库访问频繁, 压力增大. 解决这个问题的方法是引入缓存机制, 将热点数据加载到缓存中, 一方面可以减轻数据库的压力, 另一方面也可以提升查询效率.")])]),v._v(" "),_("p",[v._v("从上面介绍可以看出, 数据并行模式实现了多请求并行处理, 但如果单个请求特别复杂, 比方说需要几天甚至一周时间的时候, 数据并行模式的整体计算效率还是不够高.")]),v._v(" "),_("p",[v._v("由此可见, 数据并行模式的主要问题是: **对提升单个任务的执行性能及降低时延无效. **")]),v._v(" "),_("h6",{attrs:{id:"_3-集团军模式-任务并行或任务分布式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-集团军模式-任务并行或任务分布式"}},[v._v("#")]),v._v(" (3)集团军模式:任务并行或任务分布式")]),v._v(" "),_("p",[v._v("那么, 有没有办法可以提高单个任务的执行性能, 或者缩短单个任务的执行时间呢? 答案是肯定的. 任务并行(也叫作任务分布式)就是为解决这个问题而生的. 那什么是任务并行呢?")]),v._v(" "),_("p",[_("strong",[v._v("任务并行指的是, 将单个复杂的任务拆分为多个子任务, 从而使得多个子任务可以在不同的计算机上并行执行.")])]),v._v(" "),_("p",[v._v("仍以铁路售票系统为例, 任务并行首先是对应用进行拆分, 比如按照领域模型将用户管理, 火车票管理, 订单管理拆分成多个子系统分别运行在不同的计算机或服务器上. 换句话说, 原本包括用户管理, 火车票管理和订单管理的一个复杂任务, 被拆分成了多个子任务在不同计算机或服务器上执行, 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/9e45d1f72c8183dcc6546efe702c7f4e-20230731163147-fjbmcno.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, 任务并行模式完成一项复杂任务主要有两个核心步骤: "),_("strong",[v._v("首先将单任务拆分成多个子任务, 然后让多个子任务并行执行")]),v._v(". 这种模式和集团军模式很像, 任务拆分者对应领导者, 不同子系统对应不同兵种, 不同子程序执行不同任务就像不同的兵种执行不同的命令一样, 并且运行相同子系统或子任务的计算机又可以组成一个兵团.")]),v._v(" "),_("p",[v._v("在集团军模式中, 由于多个子任务可以在多台计算机上运行, 因此通过将同一任务待处理的数据分散到多个计算机上, 在这些计算机上同时进行处理, 就可以加快任务执行的速度. 因为只要一个复杂任务拆分出的任意子任务执行时间变短了, 那么这个任务的整体执行时间就变短了.")]),v._v(" "),_("p",[v._v("当然, nothing is perfect. "),_("strong",[v._v("集团军模式在提供了更好的性能, 扩展性, 可维护性的同时, 也带来了设计上的复杂性问题")]),v._v(", 毕竟对一个大型业务的拆分也是一个难题. 不过对于大型业务来讲, 从长远收益来看, 这个短期的设计阵痛是值得的. 这也是许多大型互联网公司, 高性能计算机构等竞相对业务进行拆分以及重构的一个重要原因.")]),v._v(" "),_("h5",{attrs:{id:"分布式是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式是什么"}},[v._v("#")]),v._v(" 分布式是什么?")]),v._v(" "),_("p",[v._v("讲了半天, 那到底什么是分布式呢?")]),v._v(" "),_("p",[v._v("**总结一下, 分布式其实就是将相同或相关的程序运行在多台计算机上, 从而实现特定目标的一种计算方式. **")]),v._v(" "),_("p",[v._v("从这个定义来看, 数据并行, 任务并行其实都可以算作是分布式的一种"),_("strong",[v._v("形态")]),v._v(". 从这些计算方式的演变中不难看出, **产生分布式的最主要驱动力量, 是我们对于性能, 可用性及可扩展性的不懈追求. **")]),v._v(" "),_("h5",{attrs:{id:"总结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享了分布式的起源, 即从单机模式到数据并行(也叫作数据分布式)模式, 再到任务并行(也叫作任务分布式)模式.")]),v._v(" "),_("p",[v._v("单机模式指的是, 所有业务和数据均部署到同一台机器上. 这种模式的好处是功能, 代码和数据集中, 便于维护, 管理和执行, 但计算效率是瓶颈. 也就是说单机模式性能受限, 也存在单点失效的问题.")]),v._v(" "),_("p",[v._v("数据并行(也叫作数据分布式)模式指的是, 对数据进行拆分, 利用多台计算机并行执行多个相同任务, 通过在相同的时间内完成多个相同任务, 从而缩短所有任务的总体执行时间, 但对提升单个任务的执行性能及降低时延无效.")]),v._v(" "),_("p",[v._v("任务并行(也叫作任务分布式)模式指的是, 单任务拆分成多个子任务, 多个子任务并行执行, 只要一个复杂任务中的任意子任务的执行时间变短了, 那么这个业务的整体执行时间也就变短了. 该模式在提高性能, 扩展性, 可维护性等的同时, 也带来了设计上的复杂性问题, 比如复杂任务的拆分.")]),v._v(" "),_("p",[v._v("在数据并行和任务并行这两个模式的使用上, 用户通常会比较疑惑, 到底是采用数据并行还是任务并行呢? 一个简单的原则就是: "),_("strong",[v._v("任务执行时间短, 数据规模大, 类型相同且无依赖, 则可采用数据并行; 如果任务复杂, 执行时间长, 且任务可拆分为多个子任务, 则考虑任务并行")]),v._v(". 在实际业务中, 通常是这两种模式并用.")]),v._v(" "),_("h4",{attrs:{id:"_02-分布式系统的指标-啥是分布式的三围"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_02-分布式系统的指标-啥是分布式的三围"}},[v._v("#")]),v._v(" 02-分布式系统的指标:啥是分布式的三围")]),v._v(" "),_("p",[v._v("本节来看看可以用哪些指标去具体地衡量一个分布式系统.")]),v._v(" "),_("h5",{attrs:{id:"分布式系统的指标"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统的指标"}},[v._v("#")]),v._v(" 分布式系统的指标")]),v._v(" "),_("p",[v._v("从分布式技术的起源可以看出, 分布式系统的出现就是为了用廉价的, 普通的机器解决单个计算机处理复杂, 大规模数据和任务时存在的性能问题, 资源瓶颈问题, 以及可用性和可扩展性问题. 换句话说, 分布式的目的是**用更多的机器, 处理更多的数据和更复杂的任务. **")]),v._v(" "),_("p",[v._v("由此可以看出, "),_("strong",[v._v("性能, 资源, 可用性和可扩展性")]),v._v('是分布式系统的重要指标. 没错, 它们就是分布式系统的"三围". 接下来一起来看看这几个指标.')]),v._v(" "),_("h6",{attrs:{id:"_1-性能-performance"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-性能-performance"}},[v._v("#")]),v._v(" (1)性能(Performance)")]),v._v(" "),_("p",[v._v("性能指标, 主要用于衡量一个系统处理各种任务的能力. 无论是分布式系统还是单机系统, 都会对性能有所要求.")]),v._v(" "),_("p",[v._v("不同的系统, 服务要达成的目的不同, 关注的性能自然也不尽相同, 甚至是相互矛盾. 常见的性能指标, 包括吞吐量(Throughput), 响应时间(Response Time)和完成时间(Turnaround Time).")]),v._v(" "),_("p",[_("strong",[v._v("吞吐量")]),v._v("指的是, 系统在一定时间内可以处理的任务数. 这个指标可以非常直接地体现一个系统的性能, 就好比在客户非常多的情况下, 要评判一个银行柜台职员的办事效率, 你可以统计一下他在 1 个小时内接待了多少客户. 常见的吞吐量指标有 QPS(Queries Per Second), TPS(Transactions Per Second)和 BPS(Bits Per Second).")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("QPS")]),v._v(", 即查询数每秒, 用于衡量一个系统每秒处理的查询数. 这个指标通常用于读操作, 越高说明对读操作的支持越好. 所以, 我们在设计一个分布式系统的时候, 如果应用主要是读操作, 那么需要重点考虑如何提高 QPS, 来支持高频的读操作.")]),v._v(" "),_("li",[_("strong",[v._v("TPS")]),v._v(", 即事务数每秒, 用于衡量一个系统每秒处理的事务数. 这个指标通常对应于写操作, 越高说明对写操作的支持越好. 我们在设计一个分布式系统的时候, 如果应用主要是写操作, 那么需要重点考虑如何提高 TPS, 来支持高频写操作.")]),v._v(" "),_("li",[_("strong",[v._v("BPS")]),v._v(", 即比特数每秒, 用于衡量一个系统每秒处理的数据量. 对于一些网络系统, 数据管理系统, 我们不能简单地按照请求数或事务数来衡量其性能. 因为请求与请求, 事务与事务之间也存在着很大的差异, 比方说, 有的事务大需要写入更多的数据. 那么在这种情况下, BPS 更能客观地反应系统的吞吐量.")])]),v._v(" "),_("p",[_("strong",[v._v("响应时间")]),v._v("指的是, 系统响应一个请求或输入需要花费的时间. 响应时间直接影响到用户体验, 对于时延敏感的业务非常重要. 比如用户搜索导航, 特别是用户边开车边搜索的时候, 如果响应时间很长, 就会直接导致用户走错路.")]),v._v(" "),_("p",[_("strong",[v._v("完成时间")]),v._v("指的是, 系统真正完成一个请求或处理需要花费的时间. 任务并行(也叫作任务分布式)模式出现的其中一个目的, 就是缩短整个任务的完成时间. 特别是需要计算海量数据或处理大规模任务时, 用户对完成时间的感受非常明显.")]),v._v(" "),_("h6",{attrs:{id:"_2-资源占用-resource-usage"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-资源占用-resource-usage"}},[v._v("#")]),v._v(" (2)资源占用(Resource Usage)")]),v._v(" "),_("p",[v._v("资源占用指的是, 一个系统提供正常能力需要占用的硬件资源, 比如 CPU, 内存, 硬盘等.")]),v._v(" "),_("p",[v._v("一个系统在没有任何负载时的资源占用, 叫做"),_("strong",[v._v("空载资源占用")]),v._v(", 体现了这个系统自身的资源占用情况. 比如, 你在手机上安装一个 App, 安装的时候通常会提示你有多少 KB, 这就是该 App 的空载硬盘资源占用. 对于同样的功能, 空载资源占用越少, 说明系统设计越优秀, 越容易被用户接受.")]),v._v(" "),_("p",[v._v("一个系统满额负载时的资源占用, 叫做"),_("strong",[v._v("满载资源占用")]),v._v(", 体现了这个系统全力运行时占用资源的情况, 也体现了系统的处理能力. 同样的硬件配置上, 运行的业务越多, 资源占用越少, 说明这个系统设计得越好.")]),v._v(" "),_("h6",{attrs:{id:"_3-可用性-availability"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-可用性-availability"}},[v._v("#")]),v._v(" (3)可用性(Availability)")]),v._v(" "),_("p",[v._v("可用性, 通常指的是系统在面对各种异常时可以正确提供服务的能力. 可用性是分布式系统的一项重要指标, 衡量了系统的鲁棒性, 是系统容错能力的体现.")]),v._v(" "),_("p",[v._v("系统的可用性可以用**系统停止服务的时间与总的时间之比衡量. **假设一个网站总的运行时间是 24 小时, 在 24 小时内, 如果网站故障导致不可用的时间是 4 个小时, 那么系统的可用性就是 4/24=0.167, 也就是 0.167 的比例不可用, 或者说 0.833 的比例可用.")]),v._v(" "),_("p",[v._v("除此之外, 系统的可用性还可以用"),_("strong",[v._v("某功能的失败次数与总的请求次数之比来衡量")]),v._v(", 比如对网站请求 1000 次, 其中有 10 次请求失败, 那么可用性就是 99%.")]),v._v(" "),_("p",[v._v("你可能经常在一个系统的宣传语中见到或听到 3 个 9(或 3N, 3 Nines), 5 个 9(或 9N, 9 Nines). 这些宣传语中所说的 3 个 9, 5 个 9, 实际上就是系统厂商对可用性的一种标榜, 表明该系统可以在 99.9% 或 99.999% 的时间里能对外无故障地提供服务.")]),v._v(" "),_("p",[v._v("讲到了可用性, 你可能还会想到一个非常近似的术语: 可靠性(Reliability). 那**可靠性和可用性有什么区别呢? **")]),v._v(" "),_("p",[_("strong",[v._v("可靠性")]),v._v("通常用来表示一个系统完全不出故障的概率, 更多地用在硬件领域. 而"),_("strong",[v._v("可用性")]),v._v("则更多的是指在允许部分组件失效的情况下, 一个系统对外仍能正常提供服务的概率.")]),v._v(" "),_("p",[v._v("杰夫 · 迪恩(Jeff Dean)曾在 Google I/O 大会上透露: 谷歌一个基于 1000 台通用计算机的集群, 一年之内就有 1000+ 硬盘会出现故障. 由于现在比较常见的分布式系统基本上都是基于通用计算机的, 这就意味着在这些系统中无法实现真正的可靠, 所以我们也会在一些场合见到可靠性和可用性交换使用的情况.")]),v._v(" "),_("h6",{attrs:{id:"_4-可扩展性-scalability"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_4-可扩展性-scalability"}},[v._v("#")]),v._v(" (4)可扩展性(Scalability)")]),v._v(" "),_("p",[v._v("可扩展性, 指的是分布式系统通过扩展集群机器规模提高系统性能 (吞吐, 响应时间,  完成时间), 存储容量, 计算能力的特性, 是分布式系统的特有性质.")]),v._v(" "),_("p",[v._v("分布式系统的设计初衷, 就是利用集群多机的能力处理单机无法解决的问题. 然而, 完成某一具体任务所需要的机器数目, 即集群规模, 取决于单个机器的性能和任务的要求.")]),v._v(" "),_("p",[v._v("**当任务的需求随着具体业务不断提高时, 除了升级系统的性能做垂直 / 纵向扩展外, 另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模. **")]),v._v(" "),_("p",[v._v('这里垂直 / 纵向扩展指的是, 增加单机的硬件能力, 比如 CPU 增强, 内存增大等; 水平 / 横向扩展指的就是, 增加计算机数量. 好的分布式系统总在追求"线性扩展性", 也就是说系统的某一指标可以随着集群中的机器数量呈线性增长.')]),v._v(" "),_("p",[v._v("衡量系统可扩展性的常见指标是加速比(Speedup), 也就是一个系统进行扩展后相对扩展前的性能提升.")]),v._v(" "),_("ul",[_("li",[v._v("如果你的扩展目标是为了提高系统吞吐量, 则可以用扩展后和扩展前的系统吞吐量之比进行衡量.")]),v._v(" "),_("li",[v._v("如果你的目标是为了缩短完成时间, 则可以用扩展前和扩展后的完成时间之比进行衡量.")])]),v._v(" "),_("h5",{attrs:{id:"不同场景下分布式系统的指标"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#不同场景下分布式系统的指标"}},[v._v("#")]),v._v(" 不同场景下分布式系统的指标")]),v._v(" "),_("p",[v._v("我们都希望自己的分布式系统是高性能, 高可用, 高扩展和低资源占用的. 但出于硬件成本, 开发效率等因素的约束, 我们无法在性能, 可用性, 可靠性和资源占用做到面面俱到. 因此, 在不同的业务场景中, 设计者们需要有所取舍.")]),v._v(" "),_("p",[v._v("接下来, 我带你一起看一下典型的电商, IoT, 电信, HPC(高性能计算), 大数据, 云计算, 区块链等业务或系统对不同指标的诉求.")]),v._v(" "),_("ul",[_("li",[v._v("**电商系统. **对于一个电商系统而言, 系统设计者最看重的是吞吐量, 为了处理更多的用户访问或订单业务, 甚至不惜牺牲一些硬件成本.")]),v._v(" "),_("li",[v._v("**IoT. **对于一个 IoT 系统而言, 设计者最看重的是资源占用指标, 因为在一些功能极简的 IoT 设备上 RAM, ROM 的可用资源通常都是 KB 级的.")]),v._v(" "),_("li",[v._v("**电信业务. **对于电信业务而言, 最重要的无疑是响应时间, 完成时间, 以及可用性. 因为, 你在打电话时不希望你的声音半天才被对方听到, 也不希望半天才听到对方的回应, 更不希望你的电话无法拨出.")]),v._v(" "),_("li",[v._v("**HPC. **HPC 系统最显著的特点是任务执行时间极长, 一个天体物理任务的分析和计算通常耗时数周甚至数月. 因此, 通过水平扩展来提高系统的加速比, 是 HPC 系统设计者需要关注的.")]),v._v(" "),_("li",[v._v("**大数据. **大数据任务的处理时间可能相对 HPC 系统来讲比较短, 但常见的完成时间也达到了小时级, 所以扩展性也是大数据系统首先要考虑的.")]),v._v(" "),_("li",[v._v("**云计算. **对于一个云计算系统而言, 常见任务是虚拟主机或容器的创建, 资源调整, 销毁等操作, 如何减少这些操作的完成时间, 从而提升用户体验是设计者们要重点关注的. 另外, 云计算系统本质上卖的是资源, 那么降低系统本身的资源开销, 也是系统设计的重中之重.")]),v._v(" "),_("li",[v._v("**区块链. **区块链的吞吐量比较低, 比特币的 TPS 只有 7 次每秒, 单平均一次交易的确认就需要 10 分钟左右, 因此吞吐量和完成时间通常是区块链系统设计者的首要目标.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a4a7aca9b38641cd893f2110acc882d1-20230731163147-2ojmfrm.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"总结与思考"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结与思考"}},[v._v("#")]),v._v(" 总结与思考")]),v._v(" "),_("p",[v._v("按照不同维度, 分布式系统的指标可以分为"),_("strong",[v._v("性能, 资源占用, 可用性, 可扩展性")]),v._v("这四大类. 我们自然希望自己的系统, 是高性能, 高可用, 高扩展和低资源占用的, 但考虑到硬件成本, 开发效率等因素, 必须要在设计不同的系统, 业务时有所取舍.")]),v._v(" "),_("p",[v._v("所以, 这里分析了典型的电商, IoT, 电信, HPC(高性能计算), 大数据, 云计算, 区块链等业务或系统的不同诉求, 进而得出了系统设计者需要关注哪些指标. 在设计其他类型的系统时, 可以按照这个思路进行取舍.")]),v._v(" "),_("h3",{attrs:{id:"分布式协调与同步"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式协调与同步"}},[v._v("#")]),v._v(" 分布式协调与同步")]),v._v(" "),_("h4",{attrs:{id:"_03-分布式互斥-有你没我-有我没你"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_03-分布式互斥-有你没我-有我没你"}},[v._v("#")]),v._v(" 03-分布式互斥:有你没我,有我没你")]),v._v(" "),_("p",[v._v("本节正式踏上第一站: "),_("strong",[v._v("分布式协调与同步")]),v._v(". 本节将关注"),_("strong",[v._v("如何让程序通过协作共同去达成一个业务目标")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"什么是分布式互斥"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分布式互斥"}},[v._v("#")]),v._v(" 什么是分布式互斥?")]),v._v(" "),_("p",[v._v("什么是分布式互斥呢?")]),v._v(" "),_("p",[v._v('想象一下, 你正在一家餐厅使用自助咖啡机泡制咖啡, 突然有个人过来挪走了你的杯子, 开始泡制他自己的咖啡. 你耐着性子等他操作完, 继续泡制自己的咖啡. 结果你开始没多久, 他又回来中断了你泡制咖啡的过程. 相信要不了几个回合, 你和他就会上演一场"有你没我, 有我没你"的格斗了.')]),v._v(" "),_("p",[v._v("这样现实的问题也同样存在于分布式世界. 就像使用自助咖啡机时不希望被打扰一样, 对于同一共享资源, 一个程序正在使用的时候也不希望被其他程序打扰. 这就要求"),_("strong",[v._v("同一时刻只能有一个程序能够访问这种资源")]),v._v(".")]),v._v(" "),_("p",[v._v("在分布式系统里, 这种排他性的资源访问方式, 叫作**分布式互斥(Distributed Mutual Exclusion), "),_("strong",[v._v("​"),_("strong",[_("strong",[v._v("而这种被互斥访问的共享资源就叫作")])]),v._v("​")]),v._v("临界资源(Critical Resource). **")]),v._v(" "),_("p",[v._v("下面一起看看如何才能让分布式系统里的程序互斥地访问临界资源.")]),v._v(" "),_("h5",{attrs:{id:"霸道总裁-集中式算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#霸道总裁-集中式算法"}},[v._v("#")]),v._v(" 霸道总裁:集中式算法")]),v._v(" "),_("p",[v._v('对于前面提到的咖啡机问题, 首先想到的就是, 增加一个 "协调者" 来约束大家使用自助咖啡机, 解决强行插入打断别人的问题.')]),v._v(" "),_("p",[_("strong",[v._v('类似地, 可以引入一个协调者程序, 得到一个分布式互斥算法. 每个程序在需要访问临界资源时, 先给协调者发送一个请求. 如果当前没有程序使用这个资源, 协调者直接授权请求程序访问; 否则, 按照先来后到的顺序为请求程序 "排一个号". 如果有程序使用完资源, 则通知协调者, 协调者从 "排号" 的队列里取出排在最前面的请求, 并给它发送授权消息. 拿到授权消息的程序, 可以直接去访问临界资源')]),v._v(".")]),v._v(" "),_("p",[v._v("这个互斥算法, 就是"),_("strong",[v._v("集中式算法")]),v._v(", 也可以叫做中央服务器算法. 之所以这么称呼, 是因为"),_("strong",[v._v("协调者代表着集中程序或中央服务器")]),v._v(".")]),v._v(" "),_("p",[v._v("集中式算法的示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/754f941bcc772f8c70487caed98d495c-20230731163147-jeiu13e.png",alt:""}})]),v._v(" "),_("p",[v._v("如图所示, 程序 1, 2, 3, 4 为普通运行程序, 另一个程序为协调者. 当程序 2 和程序 4 需要使用临界资源时, 它们会向协调者发起申请, 请求协调者授权.")]),v._v(" "),_("p",[v._v("不巧的是, 程序 3 正在使用临界资源. 这时, 协调者根据程序 2 和 4 的申请时间顺序, 依次将它们放入等待队列. 在这个案例里, 程序 4 的申请时间早于程序 2, 因此排在程序 2 的前面.")]),v._v(" "),_("p",[v._v("程序 3 使用完临界资源后, 通知协调者释放授权. 此时协调者从等待队列中取出程序 4, 并给它发放授权. 这时, 程序 4 就可以使用临界资源了.")]),v._v(" "),_("p",[v._v("从上述流程可以看出, "),_("strong",[v._v("一个程序完成一次临界资源访问, 需要如下几个流程和消息交互")]),v._v(":")]),v._v(" "),_("ol",[_("li",[v._v("向协调者发送请求授权信息, 1 次消息交互;")]),v._v(" "),_("li",[v._v("协调者向程序发放授权信息, 1 次消息交互;")]),v._v(" "),_("li",[v._v("程序使用完临界资源后, 向协调者发送释放授权, 1 次消息交互.")])]),v._v(" "),_("p",[v._v("因此, "),_("strong",[v._v("每个程序完成一次临界资源访问, 需要进行 3 次消息交互")]),v._v(".")]),v._v(" "),_("p",[v._v("不难看出, 集中式算法的优点在于直观, 简单, 信息交互量少, 易于实现, 并且所有程序只需和协调者通信, 程序之间无需通信. 但这个算法的问题也出在了协调者身上.")]),v._v(" "),_("ul",[_("li",[v._v("一方面, "),_("strong",[v._v("协调者会成为系统的性能瓶颈")]),v._v(". 想象一下, 如果有 100 个程序要访问临界资源, 那么协调者要处理 100 * 3 = 300 条消息. 也就是说, 协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加.")]),v._v(" "),_("li",[v._v("另一方面, "),_("strong",[v._v("容易引发单点故障问题")]),v._v(". 协调者故障, 会导致所有的程序均无法访问临界资源, 导致整个系统不可用.")])]),v._v(" "),_("p",[v._v("因此, 在使用集中式算法的时候, 一定要选择性能好, 可靠性高的服务器来运行协调者.")]),v._v(" "),_("p",[_("strong",[v._v("小结一下:")]),v._v("  集中式算法具有简单, 易于实现的特点, 但可用性, 性能易受协调者影响. "),_("strong",[v._v("在可靠性和性能有一定保障的情况下, 比如中央服务器计算能力强, 性能高, 故障率低, 或者中央服务器进行了主备备份, 主故障后备可以立马升为主, 且数据可恢复的情况下, 集中式算法可以适用于比较广泛的应用场景")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"民主协商-分布式算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#民主协商-分布式算法"}},[v._v("#")]),v._v(" 民主协商:分布式算法")]),v._v(" "),_("p",[v._v("既然引入协调者会带来一些问题, 这时你可能就会想, 不用协调者是否可以实现对临界资源的互斥访问呢? 想象一下, 当需要使用自助咖啡机的时候, 是不是可以先去征求其他人的意见, 在确认其他人都没在使用也暂时不会使用咖啡机时, 就可以放心大胆地去泡制自己的咖啡了呢?")]),v._v(" "),_("p",[v._v("同理, 可以把这套算法用于分布式系统. "),_("strong",[v._v("当一个程序要访问临界资源时, 先向系统中的其他程序发送一条请求消息, 在接收到所有程序返回的同意消息后, 才可以访问临界资源")]),v._v(". 其中, 请求消息需要包含所请求的资源, 请求者的 ID, 以及发起请求的时间.")]),v._v(" "),_("p",[v._v("这就是民主协商法. "),_("strong",[v._v("在分布式领域中, 称为分布式算法, 或者使用组播和逻辑时钟的算法.")])]),v._v(" "),_("p",[v._v("如图所示, 程序 1, 2, 3 需要访问共享资源 A. 在时间戳为 8 的时刻, 程序 1 想要使用资源 A, 于是向程序 2 和 3 发起使用资源 A 的申请, 希望得到它们的同意. 在时间戳为 12 的时刻, 程序 3 想要使用资源 A, 于是向程序 1 和 2 发起访问资源 A 的请求.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/506dd4fc4943fc04f043703a5a5e3195-20230731163147-l4k5ldj.png",alt:""}})]),v._v(" "),_("p",[v._v("如图所示, 此时程序 2 暂时不访问资源 A, 因此同意了程序 1 和 3 的资源访问请求. 对于程序 3 来说, 由于程序 1 提出请求的时间更早, 因此同意程序 1 先使用资源, 并等待程序 1 返回同意消息.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/59a2b3b63cbd5c5dc79eae6f95ceed8f-20230731163147-6ldpqgn.png",alt:""}})]),v._v(" "),_("p",[v._v("如图所示, 程序 1 接收到其他所有程序的同意消息之后, 开始使用资源 A. 当程序 1 使用完资源 A 后, 释放使用权限, 向请求队列中需要使用资源 A 的程序 3 发送同意使用资源的消息, 并将程序 3 从请求队列中删除. 此时, 程序 3 收到了其他所有程序的同意消息, 获得了使用资源 A 的权限, 开始使用临界资源 A 的旅程.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/d7dde6a9e220e58a51fe355edd115721-20230731163147-mu5o2c0.png",alt:""}})]),v._v(" "),_("p",[v._v("从上述流程可以看出, 一个程序完成一次临界资源的访问, 需要进行如下的信息交互:")]),v._v(" "),_("ol",[_("li",[v._v("向其他 n-1 个程序发送访问临界资源的请求, 总共需要 n-1 次消息交互;")]),v._v(" "),_("li",[v._v("需要接收到其他 n-1 个程序回复的同意消息, 方可访问资源, 总共需要 n-1 次消息交互.")])]),v._v(" "),_("p",[v._v("可以看出, 一个程序要成功访问临界资源, 至少需要 "),_("code",[v._v("2 * (n - 1)")]),v._v("​ 次消息交互. 假设, 现在系统中的 n 个程序都要访问临界资源, 则会同时产生 "),_("code",[v._v("2n(n - 1)")]),v._v("​ 条消息. 总结来说, "),_("strong",[v._v('在大型系统中使用分布式算法, 消息数量会随着需要访问临界资源的程序数量呈指数级增加, 容易导致高昂的 "沟通成本".')])]),v._v(" "),_("p",[v._v("从上述分析不难看出, "),_("strong",[v._v('分布式算法根据 "先到先得" 以及 "投票全票通过" 的机制, 让每个程序按时间顺序公平地访问资源, 简单粗暴, 易于实现')]),v._v(". 但这个算法可用性很低, 主要包括两个方面的原因:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v('当系统内需要访问临界资源的程序增多时, 容易产生 "信令风暴"')]),v._v(" , 也就是程序收到的请求完全超过了自己的处理能力, 而导致自己正常的业务无法开展.")]),v._v(" "),_("li",[_("strong",[v._v("一旦某一程序发生故障, 无法发送同意消息, 那么其他程序均处在等待回复的状态中")]),v._v(", 使得整个系统处于停滞状态, 导致整个系统不可用. 所以, 相对于集中式算法的协调者故障, 分布式算法的可用性更低.")])]),v._v(" "),_("p",[_("strong",[v._v("针对可用性低的一种改进办法是")]),v._v(", 如果检测到一个程序故障, 则直接忽略这个程序, 无需再等待它的同意消息. 这就好比在自助餐厅, 一个人离开餐厅了, 那在使用咖啡机前, 也无需征得他的同意. 但这样的话, 每个程序都需要对其他程序进行故障检测, 这无疑带来了更大的复杂性.")]),v._v(" "),_("p",[v._v("因此, "),_("strong",[v._v("分布式算法适合节点数目少且变动不频繁的系统, 且由于每个程序均需通信交互, 因此适合 P2P 结构的系统")]),v._v(". 比如, 运行在局域网中的分布式文件系统, 具有 P2P 结构的系统等.")]),v._v(" "),_("p",[v._v("那"),_("strong",[v._v("什么样的场景适合采用分布式算法呢?")])]),v._v(" "),_("p",[v._v("Hadoop 是一个分布式系统, 其中的分布式文件系统 HDFS 的文件修改就是一个典型的应用分布式算法的场景.")]),v._v(" "),_("p",[v._v("如下图所示, 处于同一个局域网内的计算机 1, 2, 3 中都有同一份文件的备份信息, 且它们可以相互通信. 这个共享文件, 就是"),_("strong",[v._v("临界资源")]),v._v(". 当计算机 1 想要修改共享的文件时, 需要进行如下操作:")]),v._v(" "),_("ol",[_("li",[v._v("计算机 1 向计算机 2, 3 发送文件修改请求;")]),v._v(" "),_("li",[v._v("计算机 2, 3 发现自己不需要使用资源, 因此同意计算机 1 的请求;")]),v._v(" "),_("li",[v._v("计算机 1 收到其他所有计算机的同意消息后, 开始修改该文件;")]),v._v(" "),_("li",[v._v("计算机 1 修改完成后, 向计算机 2, 3 发送文件修改完成的消息, 并发送修改后的文件数据;")]),v._v(" "),_("li",[v._v("计算机 2 和 3 收到计算机 1 的新文件数据后, 更新本地的备份文件.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/fa36f6a71364536da5272f408e455b31-20230731163147-cgb576h.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("归纳一下:")]),v._v('  分布式算法是一个 "先到先得" 和 "投票全票通过" 的公平访问机制, 但通信成本较高, 可用性也比集中式算法低, 适用于临界资源使用频度较低, 且系统规模较小的场景.')]),v._v(" "),_("h5",{attrs:{id:"轮值ceo-令牌环算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#轮值ceo-令牌环算法"}},[v._v("#")]),v._v(" 轮值CEO:令牌环算法")]),v._v(" "),_("p",[v._v("那么除了集中式算法, 分布式算法以外, 还有什么方法可以实现分布式互斥吗? 答案是肯定的. 毕竟, 方法总比问题多. 华为独创的轮值 CEO 其实就是一个很好的启示. 在华为的轮值 CEO 体系里, "),_("strong",[v._v("CEO 就是临界资源, 同时只能有一个人担任, 由多名高管轮流出任 CEO")]),v._v(".")]),v._v(" "),_("p",[v._v("类似地, 程序访问临界资源问题也可按照轮值 CEO 的思路实现.  如下图所示, "),_("strong",[v._v("所有程序构成一个环结构, 令牌按照顺时针(或逆时针)方向在程序之间传递, 收到令牌的程序有权访问临界资源, 访问完成后将令牌传送到下一个程序; 若该程序不需要访问临界资源, 则直接把令牌传送给下一个程序")]),v._v(".")]),v._v(" "),_("p",[v._v("在分布式领域, 这个算法叫作令牌环算法, 也可以叫作基于环的算法. 为了便于理解与记忆, 完全可以把这个方法形象地理解为轮值 CEO 法.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bc0493648377237dc033dbaf5f2e7069-20230731163147-h5083xr.png",alt:""}})]),v._v(" "),_("p",[v._v("因为在使用临界资源前, 不需要像分布式算法那样挨个征求其他程序的意见了, 所以相对而言, 在令牌环算法里单个程序具有更高的通信效率. 同时在一个周期内, 每个程序都能访问到临界资源, 因此令牌环算法的公平性很好.")]),v._v(" "),_("p",[v._v("但不管环中的程序是否想要访问资源, 都需要接收并传递令牌, 所以也会带来一些无效通信. 假设系统中有 100 个程序, 那么程序 1 访问完资源后, 即使其它 99 个程序不需要访问, 也必须要等令牌在其他 99 个程序传递完后, 才能重新访问资源, 这就降低了系统的实时性.")]),v._v(" "),_("p",[v._v("综上, "),_("strong",[v._v("令牌环算法非常适合通信模式为令牌环方式的分布式系统")]),v._v(", 例如移动自组织网络系统. 一个典型的应用场景就是无人机通信. 无人机在通信时, 工作原理类似于对讲机, 同一时刻只能发送信息或接收信息. 因此通信中的上行链路(即向外发送信息的通信渠道)是临界资源.")]),v._v(" "),_("p",[v._v("如下图所示, 所有的无人机组成一个环, 按照顺时针方向通信. 每个无人机只知道其前一个发送信息的无人机, 和后一个将要接收信息的无人机. 拥有令牌的无人机可以向外发送信息, 其他无人机只能接收数据. 拥有令牌的无人机通信完成后, 会将令牌传送给后一个无人机. 所有的无人机轮流通信并传输数据, 从而消除了多个无人机对通信资源的争夺, 使得每个无人机都能接收到其他无人机的信息, 降低了通信碰撞导致的丢包率, 保证了网络通信的稳定性, 提高了多个无人机之间的协作效率.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/cc6a057028e7b126879965e785f9ca46-20230731163147-s8se37t.png",alt:""}})]),v._v(" "),_("p",[v._v("令牌环算法是一种更加公平的算法, 通常会与通信令牌结合, 从而取得很好的效果. 特别是当系统支持广播或组播通信模式时, 该算法更加高效, 可行.")]),v._v(" "),_("p",[v._v("对于集中式和分布式算法都存在的单点故障问题, 在令牌环中, 若某一个程序(例如上图的无人机 2)出现故障, 则直接将令牌传递给故障程序的下一个程序(例如, 上图中无人机 1 直接将令牌传送给无人机 3), 从而很好地解决单点故障问题, 提高系统的健壮性, 带来更好的可用性. 但这就要求每个程序都要记住环中的参与者信息, 这样才能知道在跳过一个参与者后令牌应该传递给谁.")]),v._v(" "),_("p",[v._v("**小结一下: **令牌环算法的公平性高, 在改进单点故障后, 稳定性也很高, 适用于系统规模较小, 并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景.")]),v._v(" "),_("h5",{attrs:{id:"知识扩展-有适合大规模系统中的分布式互斥算法吗"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-有适合大规模系统中的分布式互斥算法吗"}},[v._v("#")]),v._v(" 知识扩展:有适合大规模系统中的分布式互斥算法吗?")]),v._v(" "),_("p",[v._v("可以看到, 上面提到的集中式, 分布式和令牌环 3 个互斥算法, 都不适用于规模过大, 节点数量过多的系统. 那么, 什么样的互斥算法适用于大规模系统呢?")]),v._v(" "),_("p",[v._v("由于大规模系统的复杂性, 很自然地想到要用一个相对复杂的互斥算法. 时下有一个很流行的互斥算法, "),_("strong",[v._v("两层结构的分布式令牌环算法,")]),v._v("  把整个广域网系统中的节点组织成两层结构, 可以用于节点数量较多的系统, 或者是广域网系统.")]),v._v(" "),_("p",[v._v("广域网由多个局域网组成, 因此在该算法中, 局域网是较低的层次, 广域网是较高的层次. 每个局域网中包含若干个局部进程和一个协调进程. 局部进程在逻辑上组成一个环形结构, 在每个环形结构上有一个局部令牌 T 在局部进程间传递. 局域网与局域网之间通过各自的协调进程进行通信, 这些协调进程同样组成一个环结构, 这个环就是广域网中的全局环. 在这个全局环上, 有一个全局令牌在多个协调进程间传递.")]),v._v(" "),_("h5",{attrs:{id:"总结-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-2"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("接下来把今天的内容通过下面的一张思维导图再全面总结下.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/13799c39636e92ff8611056ccb68c955-20230731163147-6xggcbt.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_04-分布式选举-国不可一日无君"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_04-分布式选举-国不可一日无君"}},[v._v("#")]),v._v(" 04-分布式选举:国不可一日无君")]),v._v(" "),_("p",[v._v("对于一个集群来说, 多个节点到底是怎么协同, 怎么管理的呢. 比如, 数据库集群, 如何保证写入的数据在每个节点上都一致呢?")]),v._v(" "),_("p",[v._v('也许你会说, 这还不简单, 选一个"领导"来负责调度和管理其他节点就可以了啊. 这个想法一点儿也没错. 这个 "领导", 在分布式中叫做主节点, '),_("strong",[v._v('而选 "领导" 的过程在分布式领域中叫作分布式选举')]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"为什么要有分布式选举"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么要有分布式选举"}},[v._v("#")]),v._v(" 为什么要有分布式选举?")]),v._v(" "),_("p",[v._v("主节点, 在一个分布式集群中负责对其他节点的协调和管理, 也就是说, 其他节点都必须听从主节点的安排.")]),v._v(" "),_("p",[_("strong",[v._v("主节点的存在, 就可以保证其他节点的有序运行, 以及数据库集群中的写入数据在每个节点上的一致性. 这里的一致性是指, 数据在每个集群节点中都是一样的, 不存在不同的情况.")])]),v._v(" "),_("p",[v._v("当然, 如果主故障了, 集群就会天下大乱, 就好比一个国家的皇帝驾崩了, 国家大乱一样. 比如数据库集群中主节点故障后, 可能导致每个节点上的数据会不一致.")]),v._v(" "),_("p",[_("strong",[v._v('这就应了那句话 "国不可一日无君", 对应到分布式系统中就是 "集群不可一刻无主"')]),v._v(" . 总结来说, "),_("strong",[v._v("选举的作用就是选出一个主节点, 由它来协调和管理其他节点, 以保证集群有序运行和节点间数据的一致性")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"分布式选举的算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式选举的算法"}},[v._v("#")]),v._v(" 分布式选举的算法")]),v._v(" "),_("p",[v._v("那么, 如何在集群中选出一个合适的主呢? 目前常见的选主方法有基于序号选举的算法( 比如 Bully 算法), 多数派算法(比如 Raft 算法, ZAB 算法)等.")]),v._v(" "),_("h6",{attrs:{id:"长者为大-bully算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#长者为大-bully算法"}},[v._v("#")]),v._v(" 长者为大:Bully算法")]),v._v(" "),_("p",[v._v('Bully 算法是一种霸道的集群选主算法, 为什么说是霸道呢? 因为它的选举原则是 "长者" 为大, 即'),_("strong",[v._v("在所有活着的节点中, 选取 ID 最大的节点作为主节点")]),v._v(".")]),v._v(" "),_("p",[v._v("在 Bully 算法中, 节点的角色有两种: 普通节点和主节点. 初始化时, 所有节点都是平等的, 都是普通节点, 并且都有成为主的权利. 但当选主成功后, 有且仅有一个节点成为主节点, 其他所有节点都是普通节点. 当且仅当主节点故障或与其他节点失去联系后, 才会重新选主.")]),v._v(" "),_("p",[v._v("Bully 算法在选举过程中, 需要用到以下 3 种消息:")]),v._v(" "),_("ul",[_("li",[v._v("Election 消息, 用于发起选举;")]),v._v(" "),_("li",[v._v("Alive 消息, 对 Election 消息的应答;")]),v._v(" "),_("li",[v._v("Victory 消息, 竞选成功的主节点向其他节点发送的宣誓主权的消息.")])]),v._v(" "),_("p",[v._v('Bully 算法选举的原则是 "长者为大", 意味着它的'),_("strong",[v._v("假设条件是, 集群中每个节点均知道其他节点的 ID.")]),v._v("  在此前提下, 其具体的选举过程是:")]),v._v(" "),_("ol",[_("li",[v._v("集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的, 如果是则直接向其他节点发送 Victory 消息, 宣誓自己的主权;")]),v._v(" "),_("li",[v._v("如果自己不是当前活着的节点中 ID 最大的, 则向比自己 ID 大的所有节点发送 Election 消息, 并等待其他节点的回复;")]),v._v(" "),_("li",[v._v("若在给定的时间范围内, 本节点没有收到其他节点回复的 Alive 消息, 则认为自己成为主节点, 并向其他节点发送 Victory 消息, 宣誓自己成为主节点; 若接收到来自比自己 ID 大的节点的 Alive 消息, 则等待其他节点发送 Victory 消息;")]),v._v(" "),_("li",[v._v("若本节点收到比自己 ID 小的节点发送的 Election 消息, 则回复一个 Alive 消息, 告知其他节点, 我比你大, 重新选举.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a055b07361a40e83e9b13d0f7467acba-20230731163147-g08zwg4.png",alt:""}})]),v._v(" "),_("p",[v._v("目前已经有很多开源软件采用了 Bully 算法进行选主, 比如 "),_("strong",[v._v("MongoDB 的副本集故障转移功能")]),v._v(". MongoDB 的分布式选举中, 采用节点的最后操作时间戳来表示 ID, 时间戳最新的节点其 ID 最大, 也就是说时间戳最新的, 活着的节点是主节点.")]),v._v(" "),_("p",[_("strong",[v._v("小结一下")]),v._v(". Bully 算法的选择特别霸道和简单, "),_("strong",[v._v("谁活着且谁的 ID 最大谁就是主节点, 其他节点必须无条件服从. 这种算法的优点是, 选举速度快, 算法复杂度低, 简单易实现")]),v._v(".")]),v._v(" "),_("p",[v._v("但这种算法的缺点在于, 需要每个节点有全局的节点信息, 因此额外信息存储较多; 其次, 任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候, 都可能会触发重新选举, 成为新的主节点, 如果该节点频繁退出, 加入集群, 就会导致频繁切主.")]),v._v(" "),_("h6",{attrs:{id:"民主投票-raft算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#民主投票-raft算法"}},[v._v("#")]),v._v(" 民主投票:Raft算法")]),v._v(" "),_("p",[v._v('Raft 算法是典型的多数派投票选举算法, 其选举机制与日常生活中的民主投票机制类似, 核心思想是 "'),_("mark",[_("strong",[v._v("少数服从多数")])]),v._v('". 也就是说, Raft 算法中, '),_("strong",[v._v("获得投票最多的节点成为主")]),v._v(".")]),v._v(" "),_("p",[v._v("采用 Raft 算法选举, 集群节点的角色有 3 种:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("Leader")]),v._v(", 即主节点, 同一时刻只有一个 Leader, 负责协调和管理其他节点;")]),v._v(" "),_("li",[_("strong",[v._v("Candidate")]),v._v(", 即候选者, 每一个节点都可以成为 Candidate, 节点在该角色下才可以被选为新的 Leader;")]),v._v(" "),_("li",[_("strong",[v._v("Follower")]),v._v(", Leader 的跟随者, 不可以发起选举.")])]),v._v(" "),_("p",[v._v("Raft 选举的流程, 可以分为以下几步:")]),v._v(" "),_("ol",[_("li",[v._v("初始化时, 所有节点均为 Follower 状态.")]),v._v(" "),_("li",[v._v("开始选主时, "),_("strong",[v._v("所有节点的状态由 Follower 转化为 Candidate")]),v._v(", 并向其他节点发送选举请求.")]),v._v(" "),_("li",[v._v("其他节点根据接收到的选举请求的先后顺序, 回复是否同意成为主. 这里需要注意的是, "),_("strong",[v._v("在每一轮选举中, 一个节点只能投出一张票")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("若发起选举请求的节点获得超过一半的投票, 则成为主节点, 其状态转化为 Leader, 其他节点的状态则由 Candidate 降为 Follower. Leader 节点与 Follower 节点之间会定期发送心跳包, 以检测主节点是否活着.")])]),v._v(" "),_("li",[v._v("当 Leader 节点的任期到了, 即发现其他服务器开始下一轮选主周期时, Leader 节点的状态由 Leader 降级为 Follower, 进入新一轮选主.")])]),v._v(" "),_("p",[v._v("节点的状态迁移如下所示(图中的 term 指的是选举周期):")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a939691d7511b6931b541620953b5dc4-20230731163147-lykcclh.png",alt:""}})]),v._v(" "),_("p",[v._v("请注意, "),_("strong",[v._v("每一轮选举, 每个节点只能投一次票.")]),v._v("  这种选举就类似人大代表选举, 正常情况下每个人大代表都有一定的任期, 任期到后会触发重新选举, 且投票者只能将自己手里唯一的票投给其中一个候选者. 对应到 Raft 算法中, 选主是周期进行的, 包括选主和任值两个时间段, 选主阶段对应投票阶段, 任职阶段对应节点成为主之后的任期. 但也有例外的时候, 如果主节点故障, 会立马发起选举, 重新选出一个主节点.")]),v._v(" "),_("p",[v._v("Google 开源的 Kubernetes, 擅长容器管理与调度, 为了保证可靠性, 通常会部署 3 个节点用于数据备份. 这 3 个节点中, 有一个会被选为主, 其他节点作为备. "),_("strong",[v._v("Kubernetes 的选主采用的是开源的 etcd 组件. 而, etcd 的集群管理器 etcds, 是一个高可用, 强一致性的服务发现存储仓库, 就是采用了 Raft 算法来实现选主和一致性的")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("小结一下.")]),v._v("  Raft 算法具有选举速度快, 算法复杂度低, 易于实现的优点; 缺点是, 它要求系统内每个节点都可以相互通信, 且需要获得过半的投票数才能选主成功, 因此通信量大. 该算法选举稳定性比 Bully 算法好, 这是因为当有新节点加入或节点故障恢复后, 会触发选主, 但不一定会真正切主, 除非新节点或故障后恢复的节点获得投票数过半, 才会导致切主.")]),v._v(" "),_("h6",{attrs:{id:"具有优先级的民主投票-zab算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#具有优先级的民主投票-zab算法"}},[v._v("#")]),v._v(" 具有优先级的民主投票:ZAB算法")]),v._v(" "),_("p",[_("strong",[v._v("ZAB(ZooKeeper Atomic Broadcast)选举算法是为 ZooKeeper 实现分布式协调功能而设计的")]),v._v(". 相较于 Raft 算法的投票机制, ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主, 节点 ID 和数据 ID 越大, 表示数据越新, 优先成为主. 相比较于 Raft 算法, "),_("strong",[v._v("ZAB 算法尽可能保证数据的最新性")]),v._v(". 所以, ZAB 算法可以说是对 Raft 算法的改进.")]),v._v(" "),_("p",[v._v("使用 ZAB 算法选举时, 集群中每个节点拥有 3 种角色:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("Leader")]),v._v(", 主节点;")]),v._v(" "),_("li",[_("strong",[v._v("Follower")]),v._v(", 跟随者节点;")]),v._v(" "),_("li",[_("strong",[v._v("Observer")]),v._v(", 观察者, 无投票权.")])]),v._v(" "),_("p",[v._v("选举过程中, 集群中的节点拥有 4 个状态:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("Looking 状态")]),v._v(", 即选举状态. 当节点处于该状态时, 它会认为当前集群中没有 Leader, 因此自己进入选举状态.")]),v._v(" "),_("li",[_("strong",[v._v("Leading 状态")]),v._v(", 即领导者状态, 表示已经选出主, 且当前节点为 Leader.")]),v._v(" "),_("li",[_("strong",[v._v("Following 状态")]),v._v(", 即跟随者状态, 集群中已经选出主后, 其他非主节点状态更新为 Following, 表示对 Leader 的追随.")]),v._v(" "),_("li",[_("strong",[v._v("Observing 状态")]),v._v(", 即观察者状态, 表示当前节点为 Observer, 持观望态度, 没有投票权和选举权.")])]),v._v(" "),_("p",[_("strong",[v._v("投票过程中, 每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch), 其中 server_id 表示本节点的唯一 ID; server_zxID 表示本节点存放的数据 ID, 数据 ID 越大表示数据越新, 选举权重越大; epoch 表示当前选取轮数, 一般用逻辑时钟表示")]),v._v(".")]),v._v(" "),_("p",[v._v('ZAB 选举算法的核心是 "少数服从多数, ID 大的节点优先成为主", 因此选举过程中通过 (vote_id, vote_zxID) 来表明投票给哪个节点, 其中 vote_id 表示被投票节点的 ID, vote_zxID 表示被投票节点的服务器 zxID. '),_("strong",[v._v("ZAB 算法选主的原则是:")]),v._v(" "),_("mark",[_("strong",[v._v("server_zxID 最大者成为 Leader; 若 server_zxID 相同, 则 server_id 最大者成为 Leader")])]),v._v("​ "),_("strong",[v._v(".")])]),v._v(" "),_("p",[v._v("接下来以 3 个 Server 的集群为例, 此处每个 Server 代表一个节点, 来介绍 ZAB 选主的过程.")]),v._v(" "),_("p",[v._v("第一步: 当系统刚启动时, 3 个服务器当前投票均为第一轮投票, 即 epoch=1, 且 zxID 均为 0. 此时每个服务器都推选自己, 并将选票信息 "),_("code",[v._v("<epoch, vote_id, vote_zxID>")]),v._v("​ 广播出去.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/d3069f9e63dfb6e99de3176cc2fdf3aa-20230731163147-igw4lme.png",alt:""}})]),v._v(" "),_("p",[v._v("第二步: 根据判断规则, 由于 3 个 Server 的 epoch, zxID 都相同, "),_("strong",[v._v("因此比较 server_id, 较大者即为推选对象, 因此 Server 1 和 Server 2 将 vote_id 改为 3, 更新自己的投票箱并重新广播自己的投票")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6b9ff2c8c27f248e51630122dfcb574a-20230731163147-x17ww6y.png",alt:""}})]),v._v(" "),_("p",[v._v("第三步: 此时系统内所有服务器都推选了 Server 3, "),_("strong",[v._v("因此 Server 3 当选 Leader, 处于 Leading 状态, 向其他服务器发送心跳包并维护连接; Server1 和 Server2 处于 Following 状态")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/179bd40d9c4a592f379efcea868348e2-20230731163147-xknlv55.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("小结一下")]),v._v(". ZAB 算法性能高, 对系统无特殊要求, 采用广播方式发送信息, 若节点中有 n 个节点, 每个节点同时广播, 则集群中信息量为 "),_("code",[v._v("n * (n - 1)")]),v._v("​ 个消息, 容易出现"),_("strong",[v._v("广播风暴")]),v._v("; 且除了投票, 还增加了对比节点 ID 和数据 ID, 这就意味着还需要知道所有节点的 ID 和数据 ID, 所以选举时间相对较长. 但该算法选举稳定性比较好, 当有新节点加入或节点故障恢复后, 会触发选主, 但不一定会真正切主, 除非新节点或故障后恢复的节点数据 ID 和节点 ID 最大, 且获得投票数过半, 才会导致切主.")]),v._v(" "),_("h6",{attrs:{id:"三种选举算法的对比分析"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三种选举算法的对比分析"}},[v._v("#")]),v._v(" 三种选举算法的对比分析")]),v._v(" "),_("p",[v._v("下面从"),_("strong",[v._v("消息传递内容, 选举机制和选举过程")]),v._v("的维度, 对这 3 种算法进行一个对比分析, 以帮助你理解记忆.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/00b7442452b9c0d218d38ecf15869d2f-20230731163147-sh0hdo0.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"为什么-多数派-选主算法通常采用奇数节点-而不是偶数节点呢"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么-多数派-选主算法通常采用奇数节点-而不是偶数节点呢"}},[v._v("#")]),v._v(' 为什么"多数派"选主算法通常采用奇数节点,而不是偶数节点呢?')]),v._v(" "),_("p",[v._v("多数派选主算法的核心是少数服从多数, 获得投票多的节点胜出. 想象一下, 如果现在采用偶数节点集群, 当两个节点均获得一半投票时, 到底应该选谁为主呢?")]),v._v(" "),_("p",[v._v("答案是, 在这种情况下, 无法选出主, 必须重新投票选举. 但即使重新投票选举, 两个节点拥有相同投票数的概率也会很大. 因此, "),_("strong",[v._v("多数派选主算法通常采用奇数节点")]),v._v(".")]),v._v(" "),_("p",[v._v("这也是 ZooKeeper, etcd, Kubernetes 等开源软件选主均采用奇数节点的一个关键原因.")]),v._v(" "),_("h5",{attrs:{id:"总结-3"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-3"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节述了什么是分布式选举, 以及为什么需要分布式选举. 然后介绍了实现分布式选举的 3 种方法, 即: Bully 算法, Raft 算法, 以及 ZooKeeper 中的 ZAB 算法, 并通过实例展示了各类方法的选举流程.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/26cb2ca4403ebd0df6bd988f9bb71a63-20230731163147-ycropm9.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_05-分布式共识-存异求同"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_05-分布式共识-存异求同"}},[v._v("#")]),v._v(" 05-分布式共识:存异求同")]),v._v(" "),_("p",[_("strong",[v._v("分布式选举问题, 是从多个节点中选出一个主节点, 相关的选举方法几乎都有一个共同特点: 每个节点都有选举权和被选举权")]),v._v(". 大部分选举方法采用多数策略, 也就是说一个节点只有得到了大部分节点的同意或认可才能成为主节点, 然后主节点向其他节点宣告主权.")]),v._v(" "),_("p",[v._v("其实, 这个"),_("strong",[v._v("选主过程就是一个分布式共识问题")]),v._v(', 因为每个节点在选出主节点之前都可以认为自己会成为主节点, 也就是说集群节点 "存异"; 而通过选举的过程选出主节点, 让所有的节点都认可该主节点, 这叫 "求同". 由此可见, '),_("strong",[v._v('分布式共识的本质就是 "存异求同".')])]),v._v(" "),_("p",[v._v("所以, "),_("strong",[v._v("从本质上看, 分布式选举问题, 其实就是传统的分布式共识方法, 主要是基于多数投票策略实现的.")]),v._v("  基于多数投票策略的分布式选举方法, 如果用于分布式在线记账一致性问题中, 那么记账权通常会完全掌握到主节点的手里, 这使得主节点非常容易造假, 且存在性能瓶颈. 因此, "),_("strong",[v._v("分布式选举不适用于分布式在线记账的一致性问题")]),v._v(". 本节就了解另外一种用于解决分布式在线记账一致性问题的分布式共识技术.")]),v._v(" "),_("p",[v._v("这里所说的分布式在线记账, 是指在没有集中的发行方, 也就是没有银行参与的情况下, 任意一台接入互联网的电脑都能参与买卖, 所有看到该交易的服务器都可以记录这笔交易, 并且记录信息最终都是一致的, 以保证交易的准确性. 而如何保证交易的一致性, 就是该场景下的分布式共识问题.")]),v._v(" "),_("h5",{attrs:{id:"什么是分布式共识"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分布式共识"}},[v._v("#")]),v._v(" 什么是分布式共识?")]),v._v(" "),_("p",[v._v("假设, 现在有 5 台服务器, 分散在美国华盛顿, 英国伦敦, 法国巴黎, 中国北京, 中国上海, 分别对应着用户"),_("code",[v._v("{A,B,C,D,E}")]),v._v("​. 现在, 用户 A 给用户 B 转了 100 元.")]),v._v(" "),_("p",[v._v("在传统方法中, 通过银行进行转账并记录该笔交易. 但分布式在线记账方法中, 没有银行这样的一个集中方, 而是由上述 5 台服务器来记录该笔交易. 但这 5 台服务器均是有各自想法的个体, 都可以自主操作或记录, 那么如何保证记录的交易是一致的呢? 这就是分布式共识技术要解决的问题.")]),v._v(" "),_("p",[_("strong",[v._v("可以看出, 分布式共识就是在多个节点均可独自操作或记录的情况下, 使得所有节点针对某个状态达成一致的过程. 通过共识机制, 可以使得分布式系统中的多个节点的数据达成一致.")])]),v._v(" "),_("p",[v._v("其实这里说的分布式在线记账, 就是近几年比较火的区块链技术解决的问题. 而分布式共识技术, 就是区块链技术共识机制的核心.")]),v._v(" "),_("p",[v._v("接下来看看分布式共识是如何实现的, 有哪些方法吧.")]),v._v(" "),_("h5",{attrs:{id:"分布式共识方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式共识方法"}},[v._v("#")]),v._v(" 分布式共识方法")]),v._v(" "),_("p",[v._v("为了不影响你理解分布式共识的核心技术, 先介绍区块链中的一个核心概念: 挖矿.")]),v._v(" "),_("p",[v._v('在传统的交易方式中, 用户 A 给用户 B 转账, 需要银行来实行具体的转账操作并记录交易, 银行会从中收取相应的手续费. 而采用分布式在线记账的话, 参与记录这笔交易的服务器, 也可以从中获得一些奖励(这些奖励, 在区块链技术中可以换成钱). 所有服务器帮助记录交易并达成一致的过程, 就是区块链中的 "挖矿".')]),v._v(" "),_("p",[v._v("区块链是由包含交易信息的区块从后向前有序链接起来的数据结构, 其中区块是指很多交易数据的集合, 每个区块包括区块头和区块体, 区块头包括前一区块的哈希值, 本区块的哈希值和时间戳; 区块体用来存储交易数据.")]),v._v(" "),_("p",[v._v("接下来将介绍 3 种主流的解决分布式在线记账一致性问题的共识技术, 即: "),_("strong",[v._v("PoW")]),v._v("(Proof-of-Work, 工作量证明), "),_("strong",[v._v("PoS")]),v._v("(Proof-of-Stake, 权益证明)和 "),_("strong",[v._v("DPoS")]),v._v("(Delegated Proof of Stake, 委托权益证明).")]),v._v(" "),_("h6",{attrs:{id:"pow"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#pow"}},[v._v("#")]),v._v(" PoW")]),v._v(" "),_("p",[v._v("从分布式选举问题可以看出, 同一轮选举中有且仅有一个节点成为主节点. 同理, 在分布式在线记账问题中, 针对同一笔交易, 有且仅有一个节点或服务器可以获得记账权, 然后其他节点或服务器同意该节点或服务器的记账结果, 达成一致.")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("分布式共识包括两个关键点, 获得记账权和所有节点或服务器达成一致")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("PoW 算法")]),v._v(', 是以每个节点或服务器的计算能力(即 "算力")来竞争记账权的机制, 因此是一种'),_("strong",[v._v("使用工作量证明机制的共识算法")]),v._v(". 也就是说, "),_("strong",[v._v("谁的计算力强, 工作能力强, 谁获得记账权的可能性就越大")]),v._v(".")]),v._v(" "),_("p",[v._v('那如何体现节点的"算力"呢? 答案就是, 每个节点都去解一道题, 谁能先解决谁的能力就强.')]),v._v(" "),_("p",[v._v("假设每个节点会划分多个区块用于记录用户交易, PoW 算法获取记账权的原理是: 利用区块的 index, 前一个区块的哈希值, 交易的时间戳, 区块数据和 nonce 值, 通过 SHA256 哈希算法计算出一个哈希值, 并判断前 k 个值是否都为 0. 如果不是, 则递增 nonce 值, 重新按照上述方法计算; 如果是, 则本次计算的哈希值为要解决的题目的正确答案. 谁最先计算出正确答案, 谁就获得这个区块的记账权.")]),v._v(" "),_("p",[_("strong",[v._v("请注意")]),v._v(": nonce 值是用来找到一个满足哈希值的数字; k 为哈希值前导零的个数, 标记了计算的难度, 0 越多计算难度越大.")]),v._v(" "),_("p",[_("strong",[v._v("达成共识的过程, 就是获得记账权的节点将该区块信息广播给其他节点, 其他节点判断该节点找到的区块中的所有交易都是有效且之前未存在过的, 则认为该区块有效, 并接受该区块, 达成一致.")])]),v._v(" "),_("p",[v._v("接下来"),_("strong",[v._v("以上文提到的分散在世界各地的 5 台服务器为例, 说明基于 PoW 的共识记账过程.")])]),v._v(" "),_("p",[v._v("假设客户端 A 产生一个新的交易, 基于 PoW 的共识记账过程为:")]),v._v(" "),_("ul",[_("li",[v._v("客户端 A 产生新的交易, 向全网进行广播, 要求对交易进行记账.")]),v._v(" "),_("li",[v._v("每个记账节点接收到这个请求后, 将收到的交易信息放入一个区块中.")]),v._v(" "),_("li",[v._v("每个节点通过 PoW 算法, 计算本节点的区块的哈希值, 尝试找到一个具有足够工作量难度的工作量证明.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bcee93d3479da75e55c55446ebf8c2b7-20230731163147-rpvagr3.png",alt:""}})]),v._v(" "),_("ul",[_("li",[v._v("若节点 D 找到了一个工作量证明向全网广播. 当然, 当且仅当包含在该区块中的交易都是有效且之前未存在过的, 其他节点才会认同该区块的有效性.")]),v._v(" "),_("li",[v._v("其他节点接收到广播信息后, 若该区块有效, 接受该区块, 并跟随在该区块的末尾, 制造新区块延长该链条, 将被接受的区块的随机哈希值视为新区块的随机哈希值.")])]),v._v(" "),_("p",[v._v("可以看出, PoW 算法中, 谁的计算能力强, 获得记账权的可能性就越大. 但必须保证其记账的区块是有效的, 并在之前未存在过, 才能获得其他节点的认可.")]),v._v(" "),_("p",[v._v("目前, 比特币采用了 PoW 算法, 属于区块链 1.0 阶段, 其重心在于货币, 比特币大约 10min 才会产生一个区块, 区块的大小也只有 1MB, 仅能够包含 3000～4000 笔交易, 平均每秒只能够处理 5~7(个位数)笔交易.")]),v._v(" "),_("p",[v._v('PoW 通过 "挖矿" 的方式发行新币, 把比特币分散给个人, 实现了相对的公平. PoW 的容错机制, 允许全网 50% 的节点出错, 因此如果要破坏系统, 则需要投入极大成本(若你有全球 51% 的算力, 则可尝试攻击比特币).')]),v._v(" "),_("p",[v._v("但 PoW 机制每次达成共识需要全网共同参与运算, 增加了每个节点的计算量, 并且如果题目过难, 会导致计算时间长, 资源消耗多; 而如果题目过于简单, 会导致大量节点同时获得记账权, 冲突多. 这些问题, 都会增加达成共识的时间.")]),v._v(" "),_("p",[v._v("所以, PoW 机制的缺点也很明显, 共识达成的周期长, 效率低, 资源消耗大.")]),v._v(" "),_("h6",{attrs:{id:"pos"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#pos"}},[v._v("#")]),v._v(" PoS")]),v._v(" "),_("p",[v._v('为了解决 PoW 算法的问题, 引入了 PoS 算法. 它的核心原理是, 由系统权益代替算力来决定区块记账权, 拥有的权益越大获得记账权的概率就越大. 这里所谓的权益, 就是每个节点占有货币的数量和时间, 而货币就是节点所获得的奖励. PoW 算法充分利用了分布式在线记账中的奖励, 鼓励"利滚利".')]),v._v(" "),_("p",[v._v("在股权证明 PoS 模式下, 根据你持有货币的数量和时间, 给你发利息. 每个币每天产生 1 币龄, 比如你持有 100 个币, 总共持有了 50 天, 那么币龄就为 5000. 这个时候, 如果你发现了一个 PoS 区块, 你的币龄就会被减少 365. 每被减少 365 币龄, 就可以从区块中获得 0.05 个币的利息 (可理解为年利率 5%).")]),v._v(" "),_("p",[v._v("在这个案例中, 利息 = (5000 * 5%) / 365 = 0.68 个币. 这下就有意思了, 持币有利息.")]),v._v(" "),_("p",[_("strong",[v._v("基于 PoS 算法获得区块记账权的方法与基于 PoW 的方法类似, 不同之处在于")]),v._v(": 节点计算获取记账权的方法不一样, PoW 是利用区块的 index, 前一个区块的哈希值, 交易的时间戳, 区块数据和 nonce 值, 通过 SHA256 哈希算法计算出一个哈希值, 并判断前 k 个值是否都为 0, "),_("strong",[v._v("而 PoS 是根据节点拥有的股权或权益进行计算的")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来看一个具体的案例. 假设一个公链网络中, 共有 3 个节点, A , B 和 C. 其中 A 节点拥有 10000 个币, 总共持有 30 天, 而 B 和 C 节点分别有 1000 和 2000 个币, 分别持有 15 和 20 天.")]),v._v(" "),_("p",[v._v("通过 PoS 算法决定区块记账权的流程和 PoW 算法类似, 唯一不同的就是, "),_("strong",[v._v("每个节点在计算自己记账权的时候, 通过计算自己的股权或权益来评估, 如果发现自己权益最大, 则将自己的区块广播给其他节点, 当然必须保证该区块的有效性")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/8e609ad5650caa99406b749dfb120d1d-20230731163147-jguszoi.png",alt:""}})]),v._v(" "),_("p",[v._v("以太坊平台属于区块链 2.0 阶段, 在区块链 1.0 的基础上进一步强调了合约, 采用了 PoS 算法. 12 年发布的点点币(PPC), 综合了 PoW 工作量证明及 PoS 权益证明方式, 从而在安全和节能方面实现了创新.")]),v._v(" "),_("p",[v._v("可以看出, "),_("strong",[v._v("PoS 将算力竞争转变成权益竞争")]),v._v(". 与 PoW 相比, PoS 不需要消耗大量的电力就能够保证区块链网络的安全性, 同时也不需要在每个区块中创建新的货币来激励记账者参与当前网络的运行, 这也就在一定程度上缩短了达成共识所需要的时间. 所以基于 PoS 算法的以太坊每秒大概能处理 30 笔左右的交易.")]),v._v(" "),_("p",[v._v("但 PoS 算法中持币越多或持币越久, 币龄就会越高, 持币人就越容易挖到区块并得到激励, 而持币少的人基本没有机会, 这样整个系统的安全性实际上会被持币数量较大的一部分人掌握, 容易出现垄断现象.")]),v._v(" "),_("h6",{attrs:{id:"dpos"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#dpos"}},[v._v("#")]),v._v(" DPoS")]),v._v(" "),_("p",[v._v("为了解决 PoS 算法的垄断问题, 2014 年比特股(BitShares)的首席开发者丹尼尔*拉里默(Dan Larimer)提出了"),_("strong",[v._v("委托权益证明法, 也就是 DPoS 算法")]),v._v(".")]),v._v(" "),_("p",[v._v("DPoS 算法的原理, 类似股份制公司的董事会制度, 普通股民虽然拥有股权, 但进不了董事会, 他们可以投票选举代表(受托人)代他们做决策. "),_("strong",[v._v("DPoS 是由被社区选举的可信帐户(受托人, 比如得票数排行前 101 位)来拥有记账权")]),v._v(".")]),v._v(" "),_("p",[v._v("为了成为正式受托人, 用户要去社区拉票, 获得足够多的信任. 用户根据自己持有的货币数量占总量的百分比来投票, 好比公司股票机制, 假设总的发行股票为 1000, 现在股东 A 持股 10, 那么股东 A 投票权为 10/1000=1/100. 如下图所示, 根据自己拥有的权益, 投票选出可代表自己的受托节点, 受托节点之间竞争记账权.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/cf903ec58b2578fa2e03aa200dcfbb4d-20230731163147-clqgjol.png",alt:""}})]),v._v(" "),_("p",[v._v("在 DPos 算法中, "),_("strong",[v._v("通常会选出 k(比如 101) 个受托节点, 它们的权利是完全相等的")]),v._v(". 受托节点之间争取记账权也是根据算力进行竞争的. 只要受托节点提供的算力不稳定, 计算机宕机或者利用手中的权力作恶, 随时可以被握着货币的普通节点投票踢出整个系统, 而后备的受托节点可以随时顶上去.")]),v._v(" "),_("p",[v._v("DPoS 在比特股和 Steem 上已运行多年, 整个网络中选举出的多个节点能够在 1s 之内对 99.9% 的交易进行确认. 此外, DPoS 在 EOS(Enterprise Operation System, 为商用分布式应用设计的一款区块链操作系统)中也有广泛应用, 被称为区块链 3.0 阶段.")]),v._v(" "),_("p",[v._v("DPoS 是在 PoW 和 PoS 的基础上进行改进的, 相比于 PoS 算法, DPoS 引入了受托人, 优点主要表现在:")]),v._v(" "),_("ul",[_("li",[v._v("由投票选举出的若干信誉度更高的受托人记账, 解决了所有节点均参与竞争导致消息量大, 达成一致的周期长的问题. 也就是说, DPoS 能耗更低, 具有更快的交易速度.")]),v._v(" "),_("li",[v._v("每隔一定周期会调整受托人, 避免受托人造假和独权.")])]),v._v(" "),_("p",[v._v("但在 DPoS 中, 由于大多数持币人通过受托人参与投票, 投票的积极性并不高; 且一旦出现故障节点, DPoS 无法及时做出应对, 导致安全隐患.")]),v._v(" "),_("h6",{attrs:{id:"三种分布式共识算法对比分析"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三种分布式共识算法对比分析"}},[v._v("#")]),v._v(" 三种分布式共识算法对比分析")]),v._v(" "),_("p",[v._v("现在已经理解了 PoW, PoS 和 DPoS 这 3 种分布式共识算法. 下面把这三种算法放在一起做下对比, 如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c5066643e208b70d5376f8526281c7e9-20230731163147-zglb56g.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"扩展-一致性与共识的区别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#扩展-一致性与共识的区别是什么"}},[v._v("#")]),v._v(" 扩展:一致性与共识的区别是什么?")]),v._v(" "),_("p",[v._v("在平常使用中, 通常会混淆一致性和共识这两个概念, 接下来就分析下这两个概念吧.")]),v._v(" "),_("p",[_("strong",[v._v("一致性")]),v._v("是指, 分布式系统中的多个节点之间, 给定一系列的操作, 在约定协议的保障下, 对外界呈现的数据或状态是一致的.")]),v._v(" "),_("p",[_("strong",[v._v("共识")]),v._v("是指, 分布式系统中多个节点之间, 彼此对某个状态达成一致结果的过程.")]),v._v(" "),_("p",[v._v("也就是说, "),_("mark",[_("strong",[v._v("一致性强调的是结果, 共识强调的是达成一致的过程")])]),v._v(", 共识算法是保障系统满足不同程度一致性的核心技术.")]),v._v(" "),_("h5",{attrs:{id:"总结-4"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-4"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节介绍了分布式在线记账问题中的 3 种常见共识算法, 即: PoW, PoS 和 DPoS.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/77877d0a863c08cc8ec98e3cd675bae3-20230731163147-xu9c0ni.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_06-分布式事务-all-or-nothing"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_06-分布式事务-all-or-nothing"}},[v._v("#")]),v._v(" 06-分布式事务:All or nothing")]),v._v(" "),_("p",[v._v("对于网上购物的每一笔订单来说, 电商平台一般都会有两个核心步骤: "),_("strong",[v._v("一是订单业务采取下订单操作, 二是库存业务采取减库存操作")]),v._v(".")]),v._v(" "),_("p",[v._v("通常, 这两个业务会运行在不同的机器上, 甚至是运行在不同区域的机器上. 针对同一笔订单, 当且仅当订单操作和减库存操作一致时, 才能保证交易的正确性. 也就是说一笔订单, 只有这"),_("strong",[v._v("两个操作都完成, 才能算做处理成功")]),v._v(', 否则处理失败, 充分体现了 "All or nothing" 的思想.')]),v._v(" "),_("p",[v._v("在分布式领域中, 这个问题就是分布式事务问题.")]),v._v(" "),_("h5",{attrs:{id:"什么是分布式事务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分布式事务"}},[v._v("#")]),v._v(" 什么是分布式事务?")]),v._v(" "),_("p",[v._v("事务, 其实是包含一系列操作的, 一个有边界的工作序列, 有明确的开始和结束标志, 且要么被完全执行, 要么完全失败, 即 all or nothing. 通常情况下所说的事务指的都是本地事务, 也就是在单机上的事务.")]),v._v(" "),_("p",[v._v("而"),_("mark",[_("strong",[v._v("分布式事务, 就是在分布式系统中运行的事务, 由多个本地事务组合而成")])]),v._v("​ "),_("strong",[v._v(".")]),v._v("  在分布式场景下, 对事务的处理操作可能来自不同的机器, 甚至是来自不同的操作系统. 文章开头提到的电商处理订单问题, 就是典型的分布式事务.")]),v._v(" "),_("p",[v._v("要深入理解分布式事务, 首先需要了解它的特征. 分布式事务是多个事务的组合, 那么事务的特征 ACID, 也是分布式事务的基本特征, 其中 ACID 具体含义如下:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("原子性(Atomicity")]),v._v("), 即事务最终的状态只有两种, 全部执行成功和全部不执行. 若处理事务的任何一项操作不成功, 就会导致整个事务失败. 一旦操作失败, 所有操作都会被取消(即回滚), 使得事务仿佛没有被执行过一样.")]),v._v(" "),_("li",[_("strong",[v._v("一致性(Consistency)")]),v._v(" , 是指事务操作前和操作后, 数据的完整性保持一致或满足完整性约束. 比如用户 A 和用户 B 在银行分别有 800 元和 600 元, 总共 1400 元, 用户 A 给用户 B 转账 200 元, 分为两个步骤, 从 A 的账户扣除 200 元和对 B 的账户增加 200 元; 一致性就是要求上述步骤操作后, 最后的结果是用户 A 还有 600 元, 用户 B 有 800 元, 总共 1400 元, 而不会出现用户 A 扣除了 200 元, 但用户 B 未增加的情况.")]),v._v(" "),_("li",[_("strong",[v._v("隔离性(Isolation)")]),v._v(" , 是指当系统内有多个事务并发执行时, 多个事务不会相互干扰, 即一个事务内部的操作及使用的数据, 对其他并发事务是隔离的.")]),v._v(" "),_("li",[_("strong",[v._v("持久性(Durability)")]),v._v(" , 也被称为永久性, 是指一个事务完成了, 那么它对数据库所做的更新就被永久保存下来了. 即使发生系统崩溃或宕机等故障, 只要数据库能够重新被访问, 那么一定能够将其恢复到事务完成时的状态.")])]),v._v(" "),_("p",[v._v("分布式事务基本能够满足 ACID, 其中的 C 是强一致性, 也就是所有操作均执行成功, 才提交最终结果, 以保证数据一致性或完整性. 但随着分布式系统规模不断扩大, 复杂度急剧上升, 达成强一致性所需时间周期较长, 限定了复杂业务的处理. 为了适应复杂业务, "),_("strong",[v._v("出现了 BASE 理论, 该理论的一个关键点就是采用最终一致性代替强一致性")]),v._v('. 后面会在 "知识扩展" 模块详细展开 BASE 理论这部分内容.')]),v._v(" "),_("p",[v._v('介绍完什么是分布式事务, 以及事务的基本特征后, 就进入"怎么做"的阶段. 所以接下来就看看如何实现分布式事务.')]),v._v(" "),_("h5",{attrs:{id:"如何实现分布式事务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何实现分布式事务"}},[v._v("#")]),v._v(" 如何实现分布式事务?")]),v._v(" "),_("p",[v._v("实际上, 分布式事务主要是解决在分布式环境下, 组合事务的一致性问题. 实现分布式事务有以下 3 种基本方法:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("基于 XA 协议的二阶段提交协议方法;")])])]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("三阶段提交协议方法;")])]),v._v(" "),_("li",[_("strong",[v._v("基于消息的最终一致性方法.")])])]),v._v(" "),_("p",[v._v("其中, "),_("mark",[_("strong",[v._v("基于 XA 协议的二阶段提交协议方法和三阶段提交协议方法, 采用了强一致性, 遵从 ACID, 基于消息的最终一致性方法, 采用了最终一致性, 遵从 BASE 理论")])]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"基于xa协议的二阶段提交方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于xa协议的二阶段提交方法"}},[v._v("#")]),v._v(" 基于XA协议的二阶段提交方法")]),v._v(" "),_("p",[v._v("XA 是一个分布式事务协议, 规定了事务管理器和资源管理器接口. 因此 XA 协议可以分为两部分, 即"),_("strong",[v._v("事务管理器和本地资源管理器")]),v._v(".")]),v._v(" "),_("p",[v._v("XA 实现分布式事务的原理, 就类似于之前介绍的集中式算法: "),_("mark",[_("strong",[v._v("事务管理器作为协调者, 负责各个本地资源的提交和回滚; 而资源管理器就是分布式事务的参与者, 通常由数据库实现, 比如 Oracle, DB2 等商业数据库都实现了 XA 接口")])]),v._v(".")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("基于 XA 协议的二阶段提交方法中, 二阶段提交协议(The two-phase commit protocol, 2PC), 用于保证分布式系统中事务提交时的数据一致性, 是 XA 在全局事务中用于协调多个资源的机制.")])])]),v._v(" "),_("p",[v._v("那么, "),_("strong",[v._v("两阶段提交协议如何保证分布在不同节点上的分布式事务的一致性呢")]),v._v("? 为了保证它们的一致性, 需要引入一个协调者来管理所有的节点, 并确保这些节点正确提交操作结果, 若提交失败则放弃事务. 接下来看看两阶段提交协议的具体过程.")]),v._v(" "),_("p",[v._v("两阶段提交协议的执行过程, 分为"),_("mark",[_("strong",[v._v("投票(voting)和提交(commit)")])]),v._v(" 两个阶段.")]),v._v(" "),_("p",[_("strong",[v._v("投票为第一阶段, 协调者(Coordinator, 即事务管理器)会向事务的参与者(Cohort, 即本地资源管理器)发起执行操作的 CanCommit 请求, 并等待参与者的响应")]),v._v('. 参与者接收到请求后, 会执行请求中的事务操作, 记录日志信息但不提交, 待参与者执行成功, 则向协调者发送 "Yes" 消息, 表示同意操作; 若不成功, 则发送 "No" 消息, 表示终止操作.')]),v._v(" "),_("p",[v._v("当所有的参与者都返回了操作结果(Yes 或 No 消息)后, "),_("strong",[v._v("系统进入了提交阶段")]),v._v(". 在提交阶段, "),_("strong",[v._v("协调者会根据所有参与者返回的信息向参与者发送 DoCommit 或 DoAbort 指令")]),v._v(":")]),v._v(" "),_("ul",[_("li",[v._v('若协调者收到的都是 "Yes" 消息, 则向参与者发送 "DoCommit" 消息, 参与者会完成剩余的操作并释放资源, 然后向协调者返回 "HaveCommitted" 消息;')]),v._v(" "),_("li",[v._v("如果协调者收到的消息中"),_("strong",[v._v("包含")]),v._v(' "No" 消息, 则向所有参与者发送 "DoAbort" 消息, 此时发送 "Yes" 的参与者则会根据之前执行操作时的'),_("strong",[v._v("回滚日志对操作进行回滚")]),v._v(', 然后所有参与者会向协调者发送 "HaveCommitted" 消息;')]),v._v(" "),_("li",[v._v('协调者接收到 "HaveCommitted" 消息, 就意味着整个事务结束了.')])]),v._v(" "),_("p",[v._v("接下来"),_("strong",[v._v("以用户 A 要在网上下单购买 100 件 T 恤为例, 重点介绍下单操作和减库存操作这两个操作")]),v._v(", 以加深对二阶段提交协议的理解.")]),v._v(" "),_("p",[v._v('第一阶段: 订单系统中将与用户 A 有关的订单数据库锁住, 准备好增加一条关于用户 A 购买 100 件 T 恤的信息, 并将同意消息 "Yes" 回复给协调者. 而库存系统由于 T 恤库存不足, 出货失败, 因此向协调者回复了一个终止消息 "No".')]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a4a71c9eeb96e93a1ea941683747ccba-20230731163147-3etfl4e.png",alt:""}})]),v._v(" "),_("p",[v._v('第二阶段: 由于库存系统操作不成功, 因此协调者就会向订单系统和库存系统发送 "DoAbort" 消息. 订单系统接收到 "DoAbort" 消息后, 将系统内的数据退回到没有用户 A 购买 100 件 T 恤的版本, 并释放锁住的数据库资源. 订单系统和库存系统完成操作后, 向协调者发送 "HaveCommitted" 消息, 表示完成了事务的撤销操作.')]),v._v(" "),_("p",[v._v("至此, 用户 A 购买 100 件 T 恤这一事务已经结束, 用户 A 购买失败.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bdda0ffd69d008f9f5af9222ce0773ec-20230731163147-gq25flg.png",alt:""}})]),v._v(" "),_("p",[v._v("由上述流程可以看出, 二阶段提交的算法思路可以概括为: "),_("mark",[_("strong",[v._v("协调者下发请求事务操作, 参与者将操作结果通知协调者, 协调者根据所有参与者的反馈结果决定各参与者是要提交操作还是撤销操作")])]),v._v(".")]),v._v(" "),_("p",[v._v("虽然基于 XA 的二阶段提交算法基本满足了事务的 ACID 特性, 但依然有些不足.")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("同步阻塞问题")]),v._v(": 二阶段提交算法在执行过程中, 所有参与节点都是"),_("strong",[v._v("事务阻塞型")]),v._v("的. 也就是说, 当本地资源管理器占有临界资源时, 其他资源管理器如果要访问同一临界资源, 会处于阻塞状态.")]),v._v(" "),_("li",[_("strong",[v._v("单点故障问题:")]),v._v("  基于 XA 的二阶段提交算法类似于集中式算法, "),_("strong",[v._v("一旦事务管理器发生故障, 整个系统都处于停滞状态")]),v._v(". 尤其是在提交阶段, 一旦事务管理器发生故障, 资源管理器会由于等待管理器的消息, 而一直锁定事务资源, 导致整个系统被阻塞.")]),v._v(" "),_("li",[_("strong",[v._v("数据不一致问题:")]),v._v("  在提交阶段, 当协调者向参与者发送 DoCommit 请求之后, 如果发生了局部网络异常, 或者在发送提交请求的过程中协调者发生了故障, 就会导致只有一部分参与者接收到了提交请求并执行提交操作, 但其他未接到提交请求的那部分参与者则无法执行事务提交. 于是整个分布式系统便出现了"),_("strong",[v._v("数据不一致")]),v._v("的问题.")])]),v._v(" "),_("h6",{attrs:{id:"三阶段提交方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三阶段提交方法"}},[v._v("#")]),v._v(" 三阶段提交方法")]),v._v(" "),_("p",[v._v("三阶段提交协议(Three-phase commit protocol, 3PC), 是对二阶段提交(2PC)的改进. "),_("strong",[v._v("为了解决两阶段提交的同步阻塞问题, 三阶段提交引入了超时机制和准备阶段")]),v._v(".")]),v._v(" "),_("ul",[_("li",[v._v("同时在协调者和参与者中引入超时机制. "),_("strong",[v._v("如果协调者或参与者在规定的时间内没有接收到来自其他节点的响应, 就会根据当前的状态选择提交或者终止整个事务")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("在第一阶段和第二阶段中间引入了一个准备阶段, 也就是在提交阶段之前, 加入了一个预提交阶段")]),v._v(". 在预提交阶段排除一些不一致的情况, 保证在最后提交之前各参与节点的状态是一致的.")])]),v._v(" "),_("p",[v._v("也就是说, 除了引入超时机制之外, "),_("strong",[v._v("3PC 把 2PC 的提交阶段一分为二, 这样三阶段提交协议就有 CanCommit, PreCommit, DoCommit 三个阶段")]),v._v(".")]),v._v(" "),_("p",[v._v("**第一, CanCommit 阶段. **")]),v._v(" "),_("p",[v._v("CanCommit 阶段与 2PC 的投票阶段类似: "),_("strong",[v._v("协调者向参与者发送请求操作(CanCommit 请求), 询问参与者是否可以执行事务提交操作, 然后等待参与者的响应; 参与者收到 CanCommit 请求之后, 回复 Yes, 表示可以顺利执行事务; 否则回复 No")]),v._v(".")]),v._v(" "),_("p",[v._v("CanCommit 阶段不同节点之间的事务请求成功和失败的流程, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1fe99b2ace06081e71351115f5b42517-20230731163147-feo3rpx.png",alt:""}})]),v._v(" "),_("p",[v._v("**第二, PreCommit 阶段. **")]),v._v(" "),_("p",[v._v("协调者根据参与者的回复情况, 来决定是否可以进行 PreCommit 操作.")]),v._v(" "),_("ul",[_("li",[_("p",[v._v('如果所有参与者回复的都是 "Yes", 那么协调者就会执行事务的'),_("strong",[v._v("预执行")]),v._v(":")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("发送预提交请求.")]),v._v("  协调者向参与者发送 PreCommit 请求, 进入"),_("strong",[v._v("预提交阶段")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("事务预提交")]),v._v(". 参与者接收到 PreCommit 请求后执行事务操作, 并将 Undo 和 Redo 信息记录到事务日志中.")]),v._v(" "),_("li",[_("strong",[v._v("响应反馈")]),v._v(". 如果参与者成功执行了事务操作, 则返回 ACK 响应, 同时开始等待最终指令.")])])]),v._v(" "),_("li",[_("p",[v._v('假如任何一个参与者向协调者发送了 "No" 消息, 或者等待超时之后, 协调者都没有收到参与者的响应, 就执行中断事务的操作:')]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("发送中断请求")]),v._v('. 协调者向所有参与者发送 "Abort" 消息.')]),v._v(" "),_("li",[_("strong",[v._v("终断事务")]),v._v('. 参与者收到 "Abort" 消息之后, 或超时后仍未收到协调者的消息, 执行事务的终断操作.')])])])]),v._v(" "),_("p",[v._v("预执行阶段, 不同节点上事务执行成功和失败的流程, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7086f193d194cb594898759214df2592-20230731163147-go1511j.png",alt:""}})]),v._v(" "),_("p",[v._v("**第三, DoCommit 阶段. **")]),v._v(" "),_("p",[_("strong",[v._v("DoCmmit 阶段进行真正的事务提交")]),v._v(", 根据 PreCommit 阶段协调者发送的消息, 进入执行提交阶段或事务中断阶段.")]),v._v(" "),_("ul",[_("li",[_("p",[v._v("**执行提交阶段: **")]),v._v(" "),_("ul",[_("li",[v._v("发送提交请求. 协调者接收到所有参与者发送的 Ack 响应, 从预提交状态进入到提交状态, 并向所有参与者发送 DoCommit 消息.")]),v._v(" "),_("li",[v._v("事务提交. "),_("strong",[v._v("参与者接收到 DoCommit 消息之后, 正式提交事务. 完成事务提交之后, 释放所有锁住的资源")]),v._v(".")]),v._v(" "),_("li",[v._v("响应反馈. 参与者提交完事务之后, 向协调者发送 Ack 响应.")]),v._v(" "),_("li",[v._v("完成事务. 协调者接收到所有参与者的 Ack 响应之后, 完成事务.")])])]),v._v(" "),_("li",[_("p",[v._v("**事务中断阶段: **")]),v._v(" "),_("ul",[_("li",[v._v("发送中断请求. 协调者向所有参与者发送 Abort 请求.")]),v._v(" "),_("li",[_("strong",[v._v("事务回滚")]),v._v(". 参与者接收到 Abort 消息之后, 利用其在 PreCommit 阶段记录的 Undo 信息执行事务的回滚操作, 并释放所有锁住的资源.")]),v._v(" "),_("li",[v._v("反馈结果. 参与者完成事务回滚之后, 向协调者发送 Ack 消息.")]),v._v(" "),_("li",[v._v("终断事务. 协调者接收到参与者反馈的 Ack 消息之后, 执行事务的终断, 并结束事务.")])])])]),v._v(" "),_("p",[v._v("执行阶段不同节点上事务执行成功和失败 (事务终断) 的流程, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5a2400f8147bef4930cf32ea6a89efb7-20230731163147-r6gke51.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("在 DoCommit 阶段, 当参与者向协调者发送 Ack 消息后, 如果长时间没有得到协调者的响应, 在默认情况下, 参与者会自动将超时的事务进行提交, 不会像两阶段提交那样被阻塞住")]),v._v(".")]),v._v(" "),_("p",[v._v("3PC 中引入了预提交阶段, 相对于 2PC 来讲是增加了一个预判断, 如果在预判断阶段协调者出现故障, 那就不会执行事务. 这样可以在一定程度上减少故障导致的数据不一致问题, 尽可能保证在最后提交阶段之前, 各参与节点的状态是一致的. 所以说, "),_("strong",[v._v("3PC 是针对 2PC 中存在的问题做的一个改进, 虽然没能完全解决这些问题, 但也起到了一定的效果")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"基于分布式消息的最终一致性方案"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于分布式消息的最终一致性方案"}},[v._v("#")]),v._v(" 基于分布式消息的最终一致性方案")]),v._v(" "),_("p",[v._v("2PC 和 3PC 这两种方法, 有两个共同的缺点, 一是都需要锁定资源, 降低系统性能; 二是, 没有解决数据不一致的问题. 因此便有了通过分布式消息来确保事务最终一致性的方案.")]),v._v(" "),_("p",[v._v("在 eBay 的分布式系统架构中, 架构师解决一致性问题的核心思想就是: "),_("mark",[_("strong",[v._v("将需要分布式处理的事务通过消息或者日志的方式异步执行, 消息或日志可以存到本地文件, 数据库或消息队列中, 再通过业务规则进行失败重试")])]),v._v(". 这个案例, 就是使用"),_("strong",[v._v("基于分布式消息的最终一致性方案")]),v._v("解决了分布式事务的问题.")]),v._v(" "),_("p",[v._v("基于分布式消息的最终一致性方案的事务处理, 引入了一个"),_("strong",[v._v("消息中间件(Message Queue, MQ)")]),v._v(" , 用于在多个应用之间进行消息传递. 基于消息中间件协商多个节点分布式事务执行操作的示意图, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7795d3bea3c2ed46837dff49aa63ae36-20230731163147-odx76ey.png",alt:""}})]),v._v(" "),_("p",[v._v("仍然以网上购物为例. 假设用户 A 在某电商平台下了一个订单, 需要支付 50 元, 发现自己的账户余额共 150 元, 就使用余额支付, 支付成功之后, 订单状态修改为支付成功, 然后通知仓库发货.")]),v._v(" "),_("p",[v._v("在该事件中, 涉及到了"),_("strong",[v._v("订单系统, 支付系统, 仓库系统")]),v._v(", 这三个系统是相互独立的应用, 通过远程服务进行调用.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/abf8de938db92df5415e288714b642d6-20230731163147-d45dthc.png",alt:""}})]),v._v(" "),_("p",[v._v("根据基于分布式消息的最终一致性方案, 用户 A 通过终端手机首先在订单系统上操作, 然后整个购物的流程如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/900ad7f6de017468379c7ac759ec96de-20230731163147-c8kwb8x.png",alt:""}})]),v._v(" "),_("ol",[_("li",[_("strong",[v._v('订单系统把订单消息发给消息中间件, 消息状态标记为 "待确认".')])]),v._v(" "),_("li",[_("strong",[v._v('消息中间件收到消息后, 进行消息持久化操作, 即在消息存储系统中新增一条状态为 "待发送" 的消息.')])]),v._v(" "),_("li",[v._v("消息中间件返回消息持久化结果(成功/失败), 订单系统根据返回结果判断如何进行业务操作. 失败, 放弃订单, 结束(必要时向上层返回失败结果); 成功, 则创建订单.")]),v._v(" "),_("li",[v._v("订单操作完成后, 把操作结果(成功/失败)发送给消息中间件.")]),v._v(" "),_("li",[_("strong",[v._v('消息中间件收到业务操作结果后, 根据结果进行处理: 失败, 删除消息存储中的消息, 结束; 成功, 则更新消息存储中的消息状态为 "待发送(可发送)", 并执行消息投递.')])]),v._v(" "),_("li",[v._v('如果消息状态为 "可发送", '),_("strong",[v._v("则 MQ 会将消息发送给支付系统, 表示已经创建好订单, 需要对订单进行支付")]),v._v(". 支付系统也按照上述方式进行订单支付操作.")]),v._v(" "),_("li",[v._v("订单系统支付完成后, 会将支付消息返回给消息中间件, 中间件将消息传送给订单系统. 订单系统再调用库存系统, 进行出货操作.")])]),v._v(" "),_("p",[v._v("可以看出, 分布式事务中, 当且仅当所有的事务均成功时整个流程才成功. 所以"),_("strong",[v._v("分布式事务的一致性是实现分布式事务的关键问题, 目前来看还没有一种很简单, 完美的方案可以应对所有场景.")])]),v._v(" "),_("h6",{attrs:{id:"三种实现方式对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三种实现方式对比"}},[v._v("#")]),v._v(" 三种实现方式对比")]),v._v(" "),_("p",[v._v("为了方便理解并记忆这三种方法, 我总结了一张表格, 从算法一致性, 执行方式, 性能等角度进行了对比:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c5668e817584e8ef8615bbdcdcd1a992-20230731163147-x9t1wx1.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-刚性事务与柔性事务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-刚性事务与柔性事务"}},[v._v("#")]),v._v(" 知识扩展:刚性事务与柔性事务")]),v._v(" "),_("p",[v._v("在讨论事务的时候, 经常会提到刚性事务与柔性事务, 但却很难区分这两种事务. 今天的知识扩展内容, 就来说说什么是刚性事务, 柔性事务, 以及两者之间有何区别?")]),v._v(" "),_("ul",[_("li",[v._v("刚性事务, 遵循 ACID 原则, 具有强一致性. 比如, 数据库事务.")]),v._v(" "),_("li",[_("strong",[v._v("柔性事务, 其实就是根据不同的业务场景使用不同的方法实现最终一致性, 也就是说可以根据业务的特性做部分取舍, 容忍一定时间内的数据不一致.")])])]),v._v(" "),_("p",[v._v("总结来讲, 与刚性事务不同, 柔性事务允许一定时间内, 不同节点的数据不一致, 但要求最终一致. 而柔性事务的最终一致性, 遵循的是 BASE 理论.")]),v._v(" "),_("p",[v._v("那, "),_("strong",[v._v("什么是 BASE 理论")]),v._v("呢?")]),v._v(" "),_("p",[_("strong",[v._v("BASE 理论包括基本可用(Basically Available), 柔性状态(Soft State)和最终一致性(Eventual Consistency).")])]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("基本可用")]),v._v(": 分布式系统出现故障的时候, 允许损失一部分功能的可用性. 比如, 某些电商 618 大促的时候, 会对一些非核心链路的功能进行降级处理.")]),v._v(" "),_("li",[_("strong",[v._v("柔性状态")]),v._v(": 在柔性事务中, 允许系统存在中间状态, 且这个中间状态不会影响系统整体可用性. 比如数据库读写分离, "),_("strong",[v._v("写库同步到读库(主库同步到从库)会有一个延时, 其实就是一种柔性状态")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("最终一致性")]),v._v(": 事务在操作过程中可能会由于同步延迟等问题导致不一致, 但最终状态下, 数据都是一致的.")])]),v._v(" "),_("p",[v._v("可见, BASE 理论为了支持大型分布式系统, "),_("strong",[v._v("通过牺牲强一致性, 保证最终一致性, 来获得高可用性")]),v._v(", 是对 ACID 原则的弱化. 具体分布式事务实现方式中, 二阶段提交, 三阶段提交方法, 遵循的是 ACID 原则, 而消息最终一致性方案遵循的就是 BASE 理论.")]),v._v(" "),_("h5",{attrs:{id:"总结-5"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-5"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节从事务的 ACID 特性出发, 介绍了分布式事务的概念, 特征, 以及如何实现分布式事务. 在关于如何实现分布式的部分, 以网购为例介绍了常见的三种实现方式, 即基于 XA 协议的二阶段提交方法, 三阶段方法以及基于分布式消息的最终一致性方法.")]),v._v(" "),_("p",[v._v("二阶段和三阶段方法是维护强一致性的算法, 它们针对刚性事务, 实现的是事务的 ACID 特性. 而基于分布式消息的最终一致性方案更适用于大规模分布式系统, 它维护的是事务的最终一致性, 遵循的是 BASE 理论, 因此适用于柔性事务.")]),v._v(" "),_("p",[v._v("在分布式系统的设计与实现中, 分布式事务是不可或缺的一部分. 可以说, 没有实现分布式事务的分布式系统, 不是一个完整的分布式系统. 分布式事务的实现过程看似复杂, 但将方法分解剖析后, 就会发现分布式事务的实现是有章可循的.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a0595b215776f8f6ab47d7e886882acd-20230731163147-68sbqa6.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_07-分布式锁-关键重地-非请勿入"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_07-分布式锁-关键重地-非请勿入"}},[v._v("#")]),v._v(" 07-分布式锁:关键重地,非请勿入")]),v._v(" "),_("p",[v._v('在之前介绍的算法中, 主要讲了如何协调多个进程获取权限和根据权限有序访问共享资源, "获得访问权限的进程可以访问共享资源, 其他进程必须等待拥有该权限的进程释放权限". 但是并没有介绍'),_("strong",[v._v("在访问共享资源时, 这个权限是如何设置或产生的, 以及设置或产生这个权限的工作原理是什么")]),v._v(".")]),v._v(" "),_("p",[v._v("本节一起看看分布式锁, 去学习分布式锁是如何解决这个问题的.")]),v._v(" "),_("h5",{attrs:{id:"为什么要使用分布锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么要使用分布锁"}},[v._v("#")]),v._v(" 为什么要使用分布锁?")]),v._v(" "),_("p",[v._v("在单机多线程环境中, 经常遇到多个线程访问同一个共享资源(这里需要注意的是: 在很多地方, 这种资源会称为临界资源, 本节统一称之为共享资源)的情况. 为了维护数据的一致性, 需要某种机制来保证只有满足某个条件的线程才能访问资源, 不满足条件的线程只能等待, 在下一轮竞争中重新满足条件时才能访问资源.")]),v._v(" "),_("p",[v._v("这个机制指的是, 为了实现分布式互斥, 在某个地方做个"),_("strong",[v._v("标记")]),v._v(", 这个标记每个线程都能看到, 到标记不存在时可以设置该标记, 当标记被设置后, 其他线程只能等待拥有该标记的线程执行完成, 并释放该标记后, 才能去设置该标记和访问共享资源. 这里的标记, 就是常说的"),_("strong",[v._v("锁")]),v._v(".")]),v._v(" "),_("p",[v._v("也就是说, **锁是实现多线程同时访问同一共享资源, 保证同一时刻只有一个线程可访问共享资源所做的一种标记. **")]),v._v(" "),_("p",[v._v("与普通锁不同的是, "),_("mark",[_("strong",[v._v("分布式锁是指分布式环境下, 系统部署在多个机器中, 实现多进程分布式互斥的一种锁")])]),v._v(". 为了保证多个进程能看到锁, 锁被存在"),_("strong",[v._v("公共存储")]),v._v("(比如 Redis, Memcache, 数据库等三方存储中), 以实现多个进程并发访问同一个临界资源, 同一时刻只有一个进程可访问共享资源, 确保数据的一致性.")]),v._v(" "),_("p",[v._v("那什么场景下需要使用分布式锁呢?")]),v._v(" "),_("p",[v._v('比如, 现在某电商要售卖某大牌吹风机(以下简称 "吹风机"), 库存只有 2 个, 但有 5 个来自不同地区的用户'),_("code",[v._v("{A,B,C,D,E}")]),v._v("​ 几乎同时下单, 那么这 2 个吹风机到底会花落谁家呢?")]),v._v(" "),_("p",[v._v("你可能会想, 这还不简单, 谁先提交订单请求, 谁就购买成功呗. 但实际业务中, 为了高并发地接受大量用户订单请求, 很少有电商网站真正实施这么简单的措施.")]),v._v(" "),_("p",[v._v("此外, 对于订单的优先级, 不同电商往往采取不同的策略, 比如有些电商根据下单时间判断谁可以购买成功, 而有些电商则是根据付款时间来判断. 但无论采用什么样的规则去判断谁能购买成功, 都必须要保证吹风机售出时, 数据库中更新的库存是正确的. 为了便于理解, 在下面的讲述中, 以下单时间作为购买成功的判断依据.")]),v._v(" "),_("p",[v._v('我们能想到的最简单方案就是, 给吹风机的库存数加一个锁. 当有一个用户提交订单后, 后台服务器给库存数加一个锁, 根据该用户的订单修改库存. 而其他用户必须等到锁释放以后, 才能重新获取库存数, 继续购买. 在这里, 吹风机的库存就是共享资源, 不同的购买者对应着多个进程, 后台服务器对共享资源加的锁就是告诉其他进程 "'),_("strong",[v._v("关键重地, 非请勿入")]),v._v('".')]),v._v(" "),_("p",[v._v("但问题就这样解决了吗? 当然没这么简单.")]),v._v(" "),_("p",[v._v("想象一下, 用户 A 想买 1 个吹风机, 用户 B 想买 2 个吹风机. 在理想状态下, 用户 A 网速好先买走了 1 个, 库存还剩下 1 个, 此时应该提示用户 B 库存不足, 用户 B 购买失败. 但实际情况是, 用户 A 和用户 B 同时获取到商品库存还剩 2 个, 用户 A 买走 1 个, 在用户 A 更新库存之前, 用户 B 又买走了 2 个, 此时用户 B 更新库存, 商品还剩 0 个. 这时电商就头大了, 总共 2 个吹风机, 却卖出去了 3 个.")]),v._v(" "),_("p",[v._v("不难看出, 如果只使用单机锁将会出现不可预知的后果. 因此在高并发场景下, 为了保证临界资源同一时间只能被一个进程使用, 从而确保数据的一致性, 就需要引入分布式锁了.")]),v._v(" "),_("p",[v._v("此外, 在大规模分布式系统中, "),_("strong",[v._v("单个机器的线程锁无法管控多个机器对同一资源的访问, 这时使用分布式锁, 就可以把整个集群当作一个应用一样去处理, 实用性和扩展性更好")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"分布式锁的三种实现方法及对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式锁的三种实现方法及对比"}},[v._v("#")]),v._v(" 分布式锁的三种实现方法及对比")]),v._v(" "),_("p",[v._v("接下来看看实现分布式锁的 3 种主流方法, 即:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("基于数据库实现分布式锁, 这里的数据库指的是关系型数据库;")])]),v._v(" "),_("li",[_("strong",[v._v("基于缓存实现分布式锁;")])]),v._v(" "),_("li",[_("strong",[v._v("基于 ZooKeeper 实现分布式锁.")])])]),v._v(" "),_("h6",{attrs:{id:"基于数据库实现分布式锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于数据库实现分布式锁"}},[v._v("#")]),v._v(" 基于数据库实现分布式锁")]),v._v(" "),_("p",[v._v("要实现分布式锁, 最简单的方式就是创建一张锁表, 然后通过操作该表中的数据来实现.")]),v._v(" "),_("p",[_("strong",[v._v("当要锁住某个资源时, 就在该表中增加一条记录, 想要释放锁的时候就删除这条记录. 数据库对共享资源做了唯一性约束, 如果有多个请求被同时提交到数据库的话, 数据库会保证只有一个操作可以成功, 操作成功的那个线程就获得了访问共享资源的锁, 可以进行操作")]),v._v(".")]),v._v(" "),_("p",[v._v("基于数据库实现的分布式锁, 是最容易理解的. 但因为数据库需要落到硬盘上, 频繁读取数据库会导致 IO 开销大, 因此这种分布式锁"),_("strong",[v._v("适用于并发量低, 对性能要求低的场景")]),v._v(". 对于双 11, 双 12 等需求量激增的场景, 数据库锁是无法满足其性能要求的. 而在平日的购物中, 可以在局部场景中使用数据库锁实现对资源的互斥访问.")]),v._v(" "),_("p",[v._v("下面还是以电商售卖吹风机的场景为例. 吹风机库存是 2 个, 有 5 个来自不同地区的用户 "),_("code",[v._v("{A,B,C,D,E}")]),v._v("​ 想要购买, 其中用户 A 想买 1 个, 用户 B 想买 2 个, 用户 C 想买 1 个.")]),v._v(" "),_("p",[v._v("用户 A 和用户 B 几乎同时下单, 但用户 A 的下单请求最先到达服务器. 因此该商家的产品数据库中增加了一条关于用户 A 的记录, 用户 A 获得了锁, 他的订单请求被处理, 服务器修改吹风机库存数, 减去 1 后还剩下 1 个.")]),v._v(" "),_("p",[v._v("当用户 A 的订单请求处理完成后, 有关用户 A 的记录被删除, 服务器开始处理用户 B 的订单请求. 这时库存只有 1 个了, 无法满足用户 B 的订单需求, 因此用户 B 购买失败.")]),v._v(" "),_("p",[v._v("从数据库中, 删除用户 B 的记录, 服务器开始处理用户 C 的订单请求, 库存中 1 个吹风机满足用户 C 的订单需求. 所以, 数据库中增加了一条关于用户 C 的记录, 用户 C 获得了锁, 他的订单请求被处理, 服务器修改吹风机数量, 减去 1 后还剩下 0 个.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/3b8319f8ff898957488b7dbf118756f1-20230731163147-4ipf24v.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, **基于数据库实现分布式锁比较简单, 绝招在于创建一张锁表, 为申请者在锁表里建立一条记录, 记录建立成功则获得锁, 消除记录则释放锁. **该方法依赖于数据库, 主要有两个缺点:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("单点故障问题")]),v._v(". 一旦数据库不可用, 会导致整个系统崩溃.")]),v._v(" "),_("li",[_("strong",[v._v("死锁问题")]),v._v(". 数据库锁没有失效时间, 未获得锁的进程只能一直等待已获得锁的进程主动释放锁. 一旦已获得锁的进程挂掉或者解锁操作失败, 会导致锁记录一直存在数据库中, 其他进程无法获得锁.")])]),v._v(" "),_("h6",{attrs:{id:"基于缓存实现分布式锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于缓存实现分布式锁"}},[v._v("#")]),v._v(" 基于缓存实现分布式锁")]),v._v(" "),_("p",[v._v("数据库的性能限制了业务的并发量, 那么对于双 11, 双 12 等需求量激增的场景是否有解决方法呢?")]),v._v(" "),_("p",[v._v("基于缓存实现分布式锁的方式, 非常适合解决这种场景下的问题. 所谓基于缓存, 也就是说把数据存放在计算机内存中, 不需要写入磁盘, 减少了 IO 读写. 接下来, 以 Redis 为例展开这部分内容.")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("Redis 通常可以使用 setnx(key, value) 函数来实现分布式锁")])]),v._v(". key 和 value 就是基于缓存的分布式锁的两个属性, 其中 key 表示锁 id, value = currentTime + timeOut, 表示当前时间 + 超时时间. 也就是说, "),_("strong",[v._v("某个进程获得 key 这把锁后, 如果在 value 的时间内未释放锁, 系统就会主动释放锁")]),v._v(".")]),v._v(" "),_("p",[v._v("setnx 函数的返回值有 0 和 1:")]),v._v(" "),_("ul",[_("li",[v._v("返回 1, 说明该服务器获得锁, setnx 将 key 对应的 value 设置为当前时间 + 锁的有效时间.")]),v._v(" "),_("li",[v._v("返回 0, 说明其他服务器已经获得了锁, 进程不能进入临界区. "),_("strong",[v._v("该服务器可以不断尝试 setnx 操作, 以获得锁")]),v._v(".")])]),v._v(" "),_("p",[v._v("还是以电商售卖吹风机的场景为例, 说明基于缓存实现的分布式锁, 假设现在库存数量是足够的.")]),v._v(" "),_("p",[v._v("用户 A 的请求因为网速快, 最先到达 Server2, setnx 操作返回 1, 并获取到购买吹风机的锁; 用户 B 和用户 C 的请求, 几乎同时到达了 Server1 和 Server3, 但因为这时 Server2 获取到了吹风机数据的锁, 所以只能加入等待队列.")]),v._v(" "),_("p",[v._v("Server2 获取到锁后, 负责管理吹风机的服务器执行业务逻辑, 只用了 1s 就完成了订单. 订单请求完成后, 删除锁的 key, 从而释放锁. 此时排在第二顺位的 Server1 获得了锁, 可以访问吹风机的数据资源. 但不巧的是, Server1 在完成订单后发生了故障, 无法主动释放锁.")]),v._v(" "),_("p",[v._v("于是, 排在第三顺位的 Server3 只能等设定的有效时间(比如 30 分钟)到期, 锁自动释放后, 才能访问吹风机的数据资源, 也就是说用户 C 只能到 00:30:01 以后才能继续抢购.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5ff7ef5723e48b204e89a6b230409e29-20230731163147-hgo1ir4.png",alt:""}})]),v._v(" "),_("p",[v._v("总结来说, "),_("strong",[v._v("Redis 通过队列来维持进程访问共享资源的先后顺序")]),v._v(". Redis 锁主要基于 setnx 函数实现分布式锁, 当进程通过 "),_("code",[v._v("setnx<key, value>")]),v._v("​ 函数返回 1 时, 表示已经获得锁. "),_("strong",[v._v("排在后面的进程只能等待前面的进程主动释放锁, 或者等到时间超时才能获得锁")]),v._v(".")]),v._v(" "),_("p",[v._v("相对于基于数据库实现分布式锁的方案来说, "),_("strong",[v._v("基于缓存实现的分布式锁的优势")]),v._v("表现在以下几个方面:")]),v._v(" "),_("ul",[_("li",[v._v("性能更好. 数据被存放在内存, 而不是磁盘, 避免了频繁的 IO 操作.")]),v._v(" "),_("li",[_("strong",[v._v("很多缓存可以跨集群部署, 避免了单点故障问题.")])]),v._v(" "),_("li",[v._v("很多缓存服务都提供了可以用来实现分布式锁的方法, 比如 Redis 的 setnx 方法等.")]),v._v(" "),_("li",[_("strong",[v._v("可以直接设置超时时间来控制锁的释放, 因为这些缓存服务器一般支持自动删除过期数据.")])])]),v._v(" "),_("p",[v._v("这个方案的不足是, "),_("strong",[v._v("通过超时时间来控制锁的失效时间, 并不是十分靠谱, 因为一个进程执行时间可能比较长, 或受系统进程做内存回收等影响, 导致时间超时, 从而不正确地释放了锁")]),v._v(".")]),v._v(" "),_("p",[v._v("为了解决基于缓存实现的分布式锁的这些问题, 再来看看基于 ZooKeeper 实现的分布式锁.")]),v._v(" "),_("h6",{attrs:{id:"基于zookeeper实现分布式锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#基于zookeeper实现分布式锁"}},[v._v("#")]),v._v(" 基于ZooKeeper实现分布式锁")]),v._v(" "),_("p",[v._v("ZooKeeper 基于树形数据存储结构实现分布式锁, 来解决多个进程同时访问同一临界资源时, 数据的一致性问题. ZooKeeper 的树形数据存储结构主要由 4 种节点构成:")]),v._v(" "),_("ul",[_("li",[v._v("持久节点. 这是默认的节点类型, 一直存在于 ZooKeeper 中.")]),v._v(" "),_("li",[v._v("持久顺序节点. 也就是说, 在创建节点时, ZooKeeper 根据节点创建的时间顺序对节点进行编号.")]),v._v(" "),_("li",[v._v("临时节点. 与持久节点不同, 当客户端与 ZooKeeper 断开连接后, 该进程创建的临时节点就会被删除.")]),v._v(" "),_("li",[v._v("临时顺序节点, 就是按时间顺序编号的临时节点.")])]),v._v(" "),_("p",[v._v("**根据它们的特征, ZooKeeper 基于临时顺序节点实现了分布锁. **")]),v._v(" "),_("p",[v._v("还是以电商售卖吹风机的场景为例. 假设用户 A, B, C 同时在 11 月 11 日的零点整提交了购买吹风机的请求, ZooKeeper 会采用如下方法来实现分布式锁:")]),v._v(" "),_("ol",[_("li",[_("p",[v._v("在与该方法对应的持久节点 shared_lock 的目录下, 为"),_("mark",[_("strong",[v._v("每个进程创建一个临时顺序节点")])]),v._v(". 如下图所示, 吹风机就是一个拥有 shared_lock 的目录, 当有人买吹风机时, 会为他创建一个临时顺序节点.")])]),v._v(" "),_("li",[_("p",[v._v("每个进程获取 shared_lock 目录下的"),_("strong",[v._v("所有临时节点列表, 注册子节点变更的 Watcher, 并监听节点")]),v._v(".")])]),v._v(" "),_("li",[_("p",[_("strong",[v._v("每个节点确定自己的编号是否是 shared_lock 下所有子节点中最小的, 若最小, 则获得锁")]),v._v(". 例如, 用户 A 的订单最先到服务器, 因此创建了编号为 1 的临时顺序节点 LockNode1. 该节点的编号是持久节点目录下最小的, 因此获取到分布式锁, 可以访问临界资源, 从而可以购买吹风机.")])]),v._v(" "),_("li",[_("p",[v._v("若本进程对应的临时节点编号不是最小的, 则分为两种情况:")]),v._v(" "),_("p",[_("strong",[v._v("a. 本进程为读请求, 如果比自己序号小的节点中有写请求, 则等待;")]),_("br"),v._v(" "),_("strong",[v._v("b. 本进程为写请求, 如果比自己序号小的节点中有读请求, 则等待.")])])])]),v._v(" "),_("p",[v._v("例如, 用户 B 也想要买吹风机, 但在他之前, 用户 C 想看看吹风机的库存量. 因此用户 B 只能等用户 A 买完吹风机, 用户 C 查询完库存量后, 才能购买吹风机.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/73fbbce05d72a159ddce89a28bb6aeb2-20230731163147-rjbmhq0.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, 使用 ZooKeeper 可以完美解决设计分布式锁时遇到的各种问题, 比如单点故障, 不可重入, 死锁等问题. 虽然 ZooKeeper 实现的分布式锁, 几乎能涵盖所有分布式锁的特性, 且易于实现, 但"),_("strong",[v._v("需要频繁地添加和删除节点, 所以性能不如基于缓存实现的分布式锁")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"三种实现方式对比-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三种实现方式对比-2"}},[v._v("#")]),v._v(" 三种实现方式对比")]),v._v(" "),_("p",[v._v("下面通过一张表格来对比一下这三种方式的特点, 以方便你理解, 记忆.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/3a8b8b6fc6cd96915d61688b8a865cec-20230731163147-cs4r1ui.png",alt:""}})]),v._v(" "),_("p",[v._v("总结来说, **ZooKeeper 分布式锁的可靠性最高, 有封装好的框架, 很容易实现分布式锁的功能, 并且几乎解决了数据库锁和缓存式锁的不足, 因此是实现分布式锁的首选方法. **")]),v._v(" "),_("p",[v._v("从上述分析可看出, 为了确保分布式锁的可用性, 在设计时应考虑到以下几点:")]),v._v(" "),_("ul",[_("li",[v._v("互斥性, 即在分布式系统环境下, 分布式锁应该能保证一个资源或一个方法在同一时间只能被一个机器的一个线程或进程操作.")]),v._v(" "),_("li",[v._v("具备锁失效机制, 防止死锁. 即使有一个进程在持有锁的期间因为崩溃而没有主动解锁, 也能保证后续其他进程可以获得锁.")]),v._v(" "),_("li",[_("strong",[v._v("可重入性")]),v._v(", 即进程未释放锁时, 可以多次访问临界资源.")]),v._v(" "),_("li",[v._v("有高可用的获取锁和释放锁的功能, 且性能要好.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-如何解决分布式锁的羊群效应问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-如何解决分布式锁的羊群效应问题"}},[v._v("#")]),v._v(" 知识扩展: 如何解决分布式锁的羊群效应问题?")]),v._v(" "),_("p",[v._v("在分布式锁问题中, 会经常遇到羊群效应. 所谓羊群效应, 就是在整个分布式锁的竞争过程中, "),_("strong",[v._v('大量的 "Watcher 通知" 和 "子节点列表的获取" 操作重复运行, 并且大多数节点的运行结果都是判断出自己当前并不是编号最小的节点, 继续等待下一次通知, 而不是执行业务逻辑')]),v._v(".")]),v._v(" "),_("p",[v._v("这就会对 ZooKeeper 服务器造成巨大的性能影响和网络冲击. 更甚的是, "),_("strong",[v._v("如果同一时间多个节点对应的客户端完成事务或事务中断引起节点消失, ZooKeeper 服务器就会在短时间内向其他客户端发送大量的事件通知")]),v._v(".")]),v._v(" "),_("p",[v._v("**那如何解决这个问题呢? **具体方法可以分为以下三步.")]),v._v(" "),_("ol",[_("li",[v._v("在与该方法对应的持久节点的目录下, 为每个进程创建一个临时顺序节点.")]),v._v(" "),_("li",[v._v("每个进程获取所有临时节点列表, 对比自己的编号是否最小, 若最小, 则获得锁.")]),v._v(" "),_("li",[v._v("若本进程对应的临时节点编号不是最小的, 则继续判断:\n"),_("ul",[_("li",[_("strong",[v._v("若本进程为读请求, 则向比自己序号小的最后一个写请求节点注册 watch 监听, 当监听到该节点释放锁后, 则获取锁;")])]),v._v(" "),_("li",[_("strong",[v._v("若本进程为写请求, 则向比自己序号小的最后一个读请求节点注册 watch 监听, 当监听到该节点释放锁后, 获取锁.")])])])])]),v._v(" "),_("h5",{attrs:{id:"总结-6"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-6"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节以电商购物为例, 首先剖析了什么是分布式锁, 以及为什么需要分布式锁; 然后介绍了三种实现分布式锁的方法, 包括基于数据库实现, 基于缓存实现(以 Redis 为例), 以及基于 ZooKeeper 实现.")]),v._v(" "),_("p",[v._v("分布式锁是解决多个进程同时访问临界资源的常用方法, 在分布式系统中非常常见, 比如开源的 ZooKeeper, Redis 中就有所涉及.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/fab3e57e9318293898aa04d68b79bc22-20230731163147-kjy93nk.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"分布式资源管理与负载调度"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式资源管理与负载调度"}},[v._v("#")]),v._v(" 分布式资源管理与负载调度")]),v._v(" "),_("h4",{attrs:{id:"_09-分布式体系结构之集中式结构-一人在上-万人在下"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_09-分布式体系结构之集中式结构-一人在上-万人在下"}},[v._v("#")]),v._v(" 09-分布式体系结构之集中式结构:一人在上,万人在下")]),v._v(" "),_("p",[v._v("很多场景下, 请求都会汇总到一台服务器上, 由这台服务器统一协调请求和其他服务器之间的关系. 这种由一台服务器统一管理其他服务器的方式, 就是分布式体系结构中的"),_("strong",[v._v("集中式结构")]),v._v('(也称为 Master/Slave 架构), 其中统一管理其他服务器的服务器是主, 其他服务器是从, 可以形象地比喻为 "一人在上, 万人在下".')]),v._v(" "),_("h5",{attrs:{id:"什么是集中式结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是集中式结构"}},[v._v("#")]),v._v(" 什么是集中式结构?")]),v._v(" "),_("p",[_("strong",[v._v("集中式结构就是, 由一台或多台服务器组成中央服务器, 系统内的所有数据都存储在中央服务器中, 系统内所有的业务也均先由中央服务器处理")]),v._v(". 多个节点服务器与中央服务器连接, 并将自己的信息汇报给中央服务器, 由中央服务器统一进行资源和任务调度: 中央服务器根据这些信息, 将任务下达给节点服务器; 节点服务器执行任务, 并将结果反馈给中央服务器.")]),v._v(" "),_("p",[v._v("集中式结构最大的特点, 就是部署结构简单. 这是因为, 集中式系统的中央服务器往往是多个具有较强计算能力和存储能力的计算机, 为此中央服务器进行统一管理和调度任务时, 无需考虑对任务的多节点部署, 而节点服务器之间无需通信和协作, 只要与中央服务器通信协作即可, 具体示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/2e3ba5c2104311e48e47362b290cd5ee-20230731163147-gsvc2f6.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"经典集中式结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#经典集中式结构"}},[v._v("#")]),v._v(" 经典集中式结构")]),v._v(" "),_("p",[v._v("现在理解了什么是集中式结构, 为了加深理解, 接下来以 Google Borg, Kubernetes 和 Apache Mesos 三个经典的集群管理系统为例, 深入学习集中式结构的原理.")]),v._v(" "),_("h6",{attrs:{id:"google-borg"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#google-borg"}},[v._v("#")]),v._v(" Google Borg")]),v._v(" "),_("p",[v._v("Borg 是 Google 内部使用的集群管理系统, 采用了典型的集中式结构, 负责提交, 调度, 开始, 重启和管理 Google 运行在其上的所有应用.")]),v._v(" "),_("p",[v._v("在 Borg 中, 一个集群称为一个 Cell, 每个 Cell 里面有一个 Leader, 称为 BorgMaster, 即为中央服务器; 其他服务器为节点服务器或从服务器, 被称为 Borglet.")]),v._v(" "),_("p",[v._v("首先一起看看"),_("strong",[v._v("BorgMaster")]),v._v(". 它由两个进程组成, 一个是 Borgmaster 主进程, 一个是独立的 scheduler 进程:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("主进程处理客户端的 RPC 请求, 比如任务的执行状态更新或者查询等; 同时, 管理系统中所有实体的状态(比如, 服务器, 任务等), 并负责和 Borglet 通信.")])]),v._v(" "),_("li",[v._v("scheduler 进程负责任务调度, 通过任务对资源的需求以及当前 Borglet 所在服务器的资源情况进行匹配, 为任务寻找一个合适的节点服务器执行.")])]),v._v(" "),_("p",[_("strong",[v._v("接下来一起看看 Borglet.")]),v._v("  它是运行在每个节点机器的一个 agent, 负责任务的拉起, 停止, 重启等, 并管理和搜集本服务器资源, 将任务的状态, 服务器状态等信息上报给 BorgMaster. 而 BorgMaster 会周期性地轮询每个 Borglet, 以获取节点服务器的状态和资源信息等.")]),v._v(" "),_("p",[v._v("Borg 的整体架构示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5881b9186023965a91690e61ce3942cc-20230731163147-ieshb9f.png",alt:""}})]),v._v(" "),_("p",[v._v("Borg 的主要用户是 Google 的开发者以及运行 Google 应用和服务的系统管理员(网站可靠性工程师, 简称 SRE). 用户以 Job 的形式向 Borg 提交工作, 每个 Job 由运行一个或多个运行相同程序的 Task 组成. 每个 Job 运行在一个 Borg Cell 中, 并将一组机器当做一个单元进行管理.")]),v._v(" "),_("p",[v._v("Borg 可以运行各种各样的任务, 这些任务主要分为两类:")]),v._v(" "),_("ul",[_("li",[v._v("第一类是"),_("strong",[v._v("长服务")]),v._v(", 即长时间运行不停止的服务, 并且要求能够处理短暂的, 延迟敏感的请求(延迟要求在几微秒到几百毫秒之间). 这些服务主要用于面向终端用户的服务(比如 Gmail, Google Docs, Web 搜索), 以及内部的一些基础设施服务(比如 BigTable).")]),v._v(" "),_("li",[v._v("第二类是"),_("strong",[v._v("批处理任务")]),v._v(". 通常需要几秒到几天的时间来完成的批处理 Job, 这些 Job 对短时间的性能波动并不是非常敏感.")])]),v._v(" "),_("p",[v._v("这些负载通常在 Cell 之间混合分布, 每个 Cell 随着主要租户以及时间的不同会运行各种不同的应用: 批处理类型的 Job 来了又走, 而许多面向终端用户的 Job 又期望一个能长时间使用的模式.")]),v._v(" "),_("p",[v._v("对于这些不同的服务, 要求 Borg 能很好地处理所有的情况. Borg 主要有三大优点:")]),v._v(" "),_("ul",[_("li",[v._v("开发者只需关注应用, 不需要关注底层资源管理. 它隐藏了资源管理以及错误处理, 因此用户能集中精力开发应用.")]),v._v(" "),_("li",[v._v("高可靠性和可用性, 支持多种应用.")]),v._v(" "),_("li",[v._v("支持上千级服务器的管理和运行.")])]),v._v(" "),_("p",[v._v("Borg 并不是第一个解决这些问题的系统, 但却是少数能在这么大规模处理这些问题的同时, 还能实现这样的弹性和完整性的系统之一.")]),v._v(" "),_("h6",{attrs:{id:"kubernetes"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kubernetes"}},[v._v("#")]),v._v(" Kubernetes")]),v._v(" "),_("p",[v._v("Kubernetes 是 Google 开源的容器集群管理系统, 是 Borg 的一个开源版本. Kubernetes 是用于自动部署, 扩展和管理容器化应用程序的开源系统. 其核心是在集群的节点上运行容器化应用, 可以进行自动化容器操作, 包括部署, 调度和在节点间弹性伸缩等.")]),v._v(" "),_("p",[v._v("Kubernetes 也是典型的集中式结构, "),_("strong",[v._v("一个 Kubernetes 集群, 主要由 Master 节点和 Worker 节点组成")]),v._v(", 以及客户端命令行工具 kubectl 和其他附加项.")]),v._v(" "),_("p",[_("strong",[v._v("先来看看 Master 节点.")]),v._v("  它运行在中心服务器上, Master 节点由 API Server, Scheduler, Cluster State Store 和 Control Manger Server 组成, 负责对集群进行调度管理.")]),v._v(" "),_("ul",[_("li",[v._v("API Server: 是所有 REST 命令的入口, 负责处理 REST 的操作, 确保它们生效, 并执行相关业务逻辑.")]),v._v(" "),_("li",[v._v("Scheduler: 根据容器需要的资源以及当前 Worker 节点所在节点服务器的资源信息, 自动为容器选择合适的节点服务器.")]),v._v(" "),_("li",[v._v("Cluster State Store: 集群状态存储, 默认采用 etcd, etcd 是一个分布式 key-value 存储, 主要用来做共享配置和服务发现.")]),v._v(" "),_("li",[v._v("Control Manager: 用于执行大部分的集群层次的功能, 比如执行生命周期功能(命名空间创建和生命周期, 事件垃圾收集, 已终止垃圾收集, 级联删除垃圾收集等)和 API 业务逻辑.")])]),v._v(" "),_("p",[_("strong",[v._v("接下来看看 Worker 节点.")]),v._v("  它作为真正的"),_("strong",[v._v("工作节点, 运行在从节点服务器, 包括 kubelet 和 kube-proxy 核心组件, 负责运行业务应用的容器")]),v._v(".")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("kubelet")]),v._v(": 用于通过命令行与 API Server 进行交互, 根据接收到的请求对 Worker 节点进行操作. 也就是说, 通过与 API Server 进行通信, 接收 Master 节点根据调度策略发出的请求或命令, 在 Worker 节点上管控容器(Pod), 并管控容器的运行状态(比如, 重新启动出现故障的 Pod)等. "),_("strong",[v._v("Pod 是 Kubernetes 的最小工作单元, 每个 Pod 包含一个或多个容器")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("kube-proxy")]),v._v(": 负责为容器(Pod)创建网络代理 / 负载平衡服务, 从 API Server 获取所有 Server 信息, 并根据 Server 信息创建代理服务, 这种代理服务称之为 Service. "),_("strong",[v._v("Kube-proxy 主要负责管理 Service 的访问入口, 即实现集群内的 Pod 客户端访问 Service, 或者是集群外访问 Service, 具有相同服务的一组 Pod 可抽象为一个 Service")]),v._v(". 每个 Service 都有一个虚拟 IP 地址(VIP)和端口号供客户端访问.")])]),v._v(" "),_("p",[v._v("Kubernetes 架构示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/226cb80c12032e875b42ac4c72d096e0-20230731163147-umtsgia.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("图中, Kube DNS 负责为整个集群提供 DNS 服务; CNI 是 Container Network Interface 的一个标准的通用接口, 用于连接容器管理系统和网络插件.")])]),v._v(" "),_("p",[v._v("与 Borg 不同的是, Kubernetes 主要是一个容器编排引擎, 不仅支持 Docker, 还支持 Rocket(另一种容器技术). Kubernetes 也已经被很多公司采用, 比如网易云, 华为在需要使用容器进行资源隔离以运行相关业务的场景下, 采用了大规模 Kubernetes 集群.")]),v._v(" "),_("p",[v._v("在容器管理方面, Kubernetes 有很多优势.")]),v._v(" "),_("ul",[_("li",[v._v("**自动化容器的部署和复制. **Kubernetes 执行容器编排, 因此不必人工编写这些任务的脚本.")]),v._v(" "),_("li",[v._v("**将容器组织为组, 弹性伸缩. **Kubernetes 引入 Pod 机制, Pod 代表着能够作为单一应用程序加以控制的一组容器集合. 通过 Pod 机制, Kubernetes 实现了多个容器的协作, 能够有效避免将太多功能集中到单一容器镜像这样的错误实践中. 此外, 软件可以向外扩展跨越多个 Pods 实现初步部署, 且相关部署可随时进行规模伸缩.")]),v._v(" "),_("li",[v._v("**容器间负载均衡. **Services 用于将具备类似功能的多个 Pod 整合为一组, 可轻松进行配置以实现其可发现性, 可观察性, 横向扩展以及负载均衡.")]),v._v(" "),_("li",[_("strong",[v._v("易于版本控制与滚动更新.")]),v._v('  Kubernetes 采取 "滚动方式" 实现编排, 且可跨越部署范围内的全部 Pod. 这些滚动更新可进行编排, 并以预定义方式配合当前可能尚不可用的 Pods 数量, 以及暂时存在的闲置 Pods 数量. Kubernetes 利用新的应用程序镜像版本对已部署 Pods 进行更新, 并在发现当前版本存在不稳定问题时回滚至早期部署版本.')])]),v._v(" "),_("h6",{attrs:{id:"mesos"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mesos"}},[v._v("#")]),v._v(" Mesos")]),v._v(" "),_("p",[v._v("理解了 Google Borg 和 Kubernetes 的集中式结构, 接下来再看看 Apache 旗下的开源分布式资源管理框架 Mesos. 它被称为是分布式系统的内核, 最初由加州大学伯克利分校的 AMPLab 开发, 后在 Twitter 得到广泛使用.")]),v._v(" "),_("p",[v._v("Mesos 的开发受到了 Borg 系统的启发, 也是采用的典型的集中式架构. "),_("strong",[v._v("Mesos 与 Borg 不同之处在于")]),v._v(", Borg 的 Master 直接对接用户应用, 也就是说用户可以向 Borg 的 Master 直接请求任务. 但 Mesos 不可以, "),_("strong",[v._v("Mesos 只负责底层资源的管理和分配, 并不涉及存储, 任务调度等功能, 因此 Mesos Master 对接的是 Spark, Hadoop, Marathon 等框架, 用户的任务需要提交到这些框架上. 也正因为此, Mesos 的任务调度框架是双层结构")]),v._v(".")]),v._v(" "),_("p",[v._v("在 Mesos 中, 一个集群包括 Mesos Master 和多个 Mesos Agent. 其中, Mesos Master 运行在中央服务器, Mesos Agent 运行在节点服务器上.")]),v._v(" "),_("p",[v._v("Mesos Master 负责收集和管理所有 Agent 所在服务器的资源和状态, 并且对接 Spark, Hadoop 等框架, 将集群中服务器的资源信息告知给这些框架, 以便这些框架进行任务资源匹配和调度. Mesos Agent 负责任务的拉起, 停止, 重启等, 并负责收集所在服务器的资源 (比如 CPU, 内存等) 信息和状态, 上报给 Mesos Master.")]),v._v(" "),_("p",[_("strong",[v._v("Mesos Master 通常采用一主两备的方式, 以方便故障处理和恢复. 而 Mesos Master 的选主策略, 采用的就是 ZAB 算法.")])]),v._v(" "),_("p",[v._v("Mesos 架构示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/12f151a46be3d0427c599156023ce708-20230731163147-sdeivxm.png",alt:""}})]),v._v(" "),_("p",[v._v("如上所述, "),_("strong",[v._v("Mesos 对接的是框架, 并且可以同时对接多个框架")]),v._v(", 目前已经被很多公司使用. 比如, 国外的 Twitter, Apple, Airbnb, Uber 等, 国内的爱奇艺, 去哪儿, 携程, 当当等.")]),v._v(" "),_("p",[v._v("这些公司选择 Mesos, 主要是因为它具有如下优势:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("效率")]),v._v('. Mesos 对物理资源进行了逻辑抽象, 在应用层而不是物理层分配资源, 通过容器而不是虚拟机(VM)分配任务. 因为应用程序的调度器知道如何最有效地利用资源, 所以在应用层分配资源能够为每个应用程序的特殊需求做考量; 而通过容器分配任务则能更好地进行 "装箱".')]),v._v(" "),_("li",[_("strong",[v._v("可扩展性")]),v._v(". Mesos 可扩展设计的关键是两级调度架构, 其中 Framework 进行任务调度, Mesos Master 进行资源分配. 由于 Master 不必知道每种类型的应用程序背后复杂的调度逻辑, 不必为每个任务做调度, 因此可以用非常轻量级的代码实现, 更易于扩展集群规模.")]),v._v(" "),_("li",[_("strong",[v._v("模块化.")]),v._v("  每接入一种新的框架, Master 无需增加新的代码, 并且 Agent 模块可以复用, 为此开发者可以专注于应用和框架的选择. 这就使得 Mesos 可以支持多种框架, 适应不同的应用场景.")])]),v._v(" "),_("p",[v._v("随着分布式应用程序和微服务的流行, 越来越多的用户正在寻找一种技术, 来帮助他们管理这些复杂的应用程序. 而 Mesos 为数据中心带来的这些好处, 就使得越来越多的人关注 Mesos 及其相关项目.")]),v._v(" "),_("h5",{attrs:{id:"分析对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分析对比"}},[v._v("#")]),v._v(" 分析对比")]),v._v(" "),_("p",[v._v("Borg, Kubernetes 和 Mesos 采用的都是集中式结构, 要理解它们的实现原理, 就要清楚其架构. 所以, 虽然这部分内容理解起来有难度, 但希望你可以深入进去探其本质, 这样在实际操作中, 就可以从用途出发选择合适的集群管理架构.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/ef6f1a568a1d0989e2a3316601552d5f-20230731163147-p0rekb0.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-mesos是如何支持容器部署的"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-mesos是如何支持容器部署的"}},[v._v("#")]),v._v(" 知识扩展:Mesos是如何支持容器部署的?")]),v._v(" "),_("p",[v._v("目前, 容器技术十分热门, 解决了服务打包发布, 资源隔离的问题. Kubernetes 的设计主要针对的就是容器, 那么 Mesos 又是如何支持容器部署呢?")]),v._v(" "),_("p",[_("strong",[v._v("Mesos 本身只负责资源管理, 不负责任务调度")]),v._v(". 但 Mesos 可以对接不同的框架, Mesos+Marathon 可以支持容器调度和部署. Marathon 支持容器的调度, 将容器部署请求发给 Mesos Master, Mesos Master 再将请求转发给 Mesos Agent, Mesos Agent 的执行器会将容器拉起.")]),v._v(" "),_("p",[_("strong",[v._v("目前, Mesos+Marathon 支持的容器, 主要包括 Docker 和 cgroups.")])]),v._v(" "),_("h5",{attrs:{id:"总结-7"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-7"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享了分布式系统中的集中式架构, 并以 Borg, Kubernetes, Mesos 这三款知名的集群管理系统为例, 描述了集中式架构的设计目的, 框架结构, 以及各组件模块的功能等. 这三种集群管理系统虽然具有不同的功能组件, 但整体框架采用的都是集中式架构. 因此只要理解了一个集群管理系统的架构, 再去理解其他集中式的集群管理架构就会很容易了.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f26e1bc739baae72cd6b0ec7d87a992f-20230731163147-gmz29s2.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_10-分布式体系结构之非集中式结构-众生平等"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_10-分布式体系结构之非集中式结构-众生平等"}},[v._v("#")]),v._v(" 10-分布式体系结构之非集中式结构:众生平等")]),v._v(" "),_("p",[v._v("上一节了解了分布式体系结构中的集中式结构. 虽然很多云上的管理都采用了集中式结构, 但是"),_("strong",[v._v("这种结构对中心服务器性能要求很高, 而且存在单点瓶颈和单点故障问题")]),v._v(".")]),v._v(" "),_("p",[v._v("为了解决这个问题, 分布式领域中又出现了另一经典的系统结构, 即非集中式结构, 也叫作分布式结构. 那什么是非集中式结构呢, 它的原理是什么样的, 又有哪些集群采用了这种结构呢?")]),v._v(" "),_("h5",{attrs:{id:"什么是非集中式结构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是非集中式结构"}},[v._v("#")]),v._v(" 什么是非集中式结构?")]),v._v(" "),_("p",[v._v("在非集中式结构中, 服务的执行和数据的存储被分散到不同的服务器集群, 服务器集群间通过消息传递进行通信和协调.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/de3ce261a145470f925be1a1f0480e88-20230731163147-c9bxzyr.png",alt:""}})]),v._v(" "),_("p",[v._v("也就是说, 在非集中式结构中, "),_("strong",[v._v("没有中央服务器和节点服务器之分, 所有的服务器地位都是平等(对等)的")]),v._v(". 这样一来, 相比于集中式结构, 非集中式结构就降低了某一个或者某一簇计算机集群的压力, "),_("strong",[v._v("在解决了单点瓶颈和单点故障问题的同时, 还提升了系统的并发度, 比较适合大规模集群的管理")]),v._v(". 所以近几年来, Google,  Amazon, Facebook, 阿里巴巴, 腾讯等互联网公司在一些业务中也相继采用了非集中式结构.")]),v._v(" "),_("p",[v._v("接下来将介绍 3 种典型的非集中式架构系统, 包括 Akka 集群, Redis 集群和 Cassandra 集群, 来帮助你深入理解非集中式架构.")]),v._v(" "),_("h5",{attrs:{id:"akka-集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#akka-集群"}},[v._v("#")]),v._v(" Akka 集群")]),v._v(" "),_("p",[v._v("在介绍 Akka 集群的结构之前, 先了解一下什么是 Akka 框架.")]),v._v(" "),_("p",[v._v("Akka 框架基于 Actor 模型, 提供了一个用于构建可扩展的, 弹性的, 快速响应的应用程序的平台. 其中, Actor 是一个封装了状态和行为的对象, 它接收消息并基于该消息执行计算. Actor 之间互相隔离, 不共享内存, 但 Actor 之间可通过交换消息(mail)进行通信(每个 Actor 都有自己的 MailBox).")]),v._v(" "),_("p",[v._v("比如在分布式系统中, 一个服务器或一个节点可以视为一个 Actor, Actor 与 Actor 之间采用 mail 进行通信, 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/56eec8968df729091c3c8adbf3cb5163-20230731163147-x7me4ow.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, Actor 发送的 Mail 消息会存储在接收方的 MailBox 中. 默认情况下, 接收方按照 mail 到达的先后顺序, 从 MailBox 中提取 mail 消息, 并进行相应的计算处理.")]),v._v(" "),_("p",[v._v("显然, Actor 模型为系统并发度提供了非常好的解决方案, 且是一个异步的, 非阻塞的, 高性能的事件驱动编程模型. Akka 集群充分利用了 Actor 模型的优势, 提供了一个非集中式架构的集群管理模块, 用来构建可扩展的, 弹性的分布式应用程序.")]),v._v(" "),_("p",[_("strong",[v._v("Akka 集群负责 Actor 模型底层的节点管理, 包括故障检测, 节点加入/退出集群等")]),v._v(". 也就是说, Akka 集群为 Actor 模型提供了一个可容错, 去中心化的节点集群管理系统, 来保证 Actor 的运行和 Actor 之间的通信.")]),v._v(" "),_("p",[v._v("如下图所示, Akka 集群是一个完全去中心化的分布式集群管理系统. 一个集群由多个节点组成, 每个节点都可以进行数据处理和任务执行, 节点之间均可进行通信. 节点有 Leader 节点和非 Leader 节点之分. 与非 Leader 节点相比, "),_("strong",[v._v("Leader 节点只是增加了负责节点的加入和移除集群的功能")]),v._v(", 所以并不会影响非集中式结构中节点的平等关系.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1366abb5f8df582d3e915b91539cbe7d-20230731163147-yaw0ii6.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, Akka 集群的两个重点是数据传输和集群组建及管理, 所以接下来将从这两个方面与你介绍 Akka 集群.")]),v._v(" "),_("p",[_("strong",[v._v("首先看一下数据传输.")]),v._v("  在 Akka 集群中, 节点是对等的, 也就是说每个节点是可以并发处理的, 因此必然存在数据传输和一致性的问题.")]),v._v(" "),_("p",[v._v("比如要针对数据进行操作, 将 X=1 修改为 X=2. 现在集群中节点 1 进行了修改使得 X=2, 但其他节点上还是 X=1, 因此节点 1 需要将 X=2 的消息告知其他节点, 以保证最终集群中所有节点上均为 X=2. 其实, 这个问题就是分布式共识问题.")]),v._v(" "),_("p",[_("strong",[v._v("Akka 集群主要采用的是谁的时间戳最新(也就是数据最新), 就以谁为准的原则.")]),v._v("  在这里要重点讲述的是, 如何将 X=2 这个消息传输给集群中的每个节点.")]),v._v(" "),_("p",[v._v("Akka 集群采用了 "),_("strong",[v._v("Gossip 协议")]),v._v(", 该协议是最终一致性协议. "),_("strong",[v._v("它的原理是每个节点周期性地从自己维护的集群节点列表中, 随机选择 k 个节点, 将自己存储的数据信息发给这 k 个节点, 接收到该信息的节点采用前面讲的共识原则, 对收到的数据和本地数据进行合并, 这样迭代几个周期后, 集群中所有节点上的数据信息就一致了")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("接下来看一下集群组建及管理.")]),v._v("  下图展示了 Akka 集群的创建过程. 在创建集群时, 节点被分为三种类型, 即:")]),v._v(" "),_("ul",[_("li",[v._v("种子节点. 使用静态配置文件方式或者系统运行时指定方式, 可以生成种子节点; 种子节点是普通节点加入集群的联系点, 可以自动接收新加入集群的节点的信息.")]),v._v(" "),_("li",[v._v("首种子节点. 首种子节点是配置文件中的第一个种子节点, 其功能是集群第一次启动时, 首种子节点启动起来, 集群才能组建成功, 保证集群第一次创建时只有一个集群. 如下图 A 节点, 就是 Akka 集群的首种子节点.")]),v._v(" "),_("li",[v._v("普通节点. 可以向种子节点或集群中的任意节点发送 Join 消息, 请求加入集群. 如下图的 B 和 C 节点, 通过向 A 节点发送 Join 消息, 从而加入到 Akka 集群.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a56b60ea33e27576f95af395f1a28348-20230731163147-gf3h8vw.png",alt:""}})]),v._v(" "),_("p",[v._v("Akka 集群的每个节点启动后, 读取配置文件获取种子节点列表, 然后开始组建集群:")]),v._v(" "),_("ul",[_("li",[v._v("如果本节点为首种子节点, 则把自己加入到集群列表中, 即以自己为中心构建集群;")]),v._v(" "),_("li",[v._v("如果本节点为种子节点, 则向首种子节点请求加入集群, 当首种子节点回复同意消息后, 可以加入集群, 否则不可加入集群;")]),v._v(" "),_("li",[v._v("如果本节点为普通节点, 则可以向任一种子节点(包括首种子节点)请求加入集群, 收到同意后, 则加入集群, 否则不可加入集群.")])]),v._v(" "),_("p",[v._v("加入首种子节点或种子节点的节点信息, 会通过 Gossip 协议的传播方式传播给当前已加入的所有节点, 以完成集群组建. 当集群组建完成后, 就不存在种子节点与普通节点之分了, 每个节点均可执行 Actor 应用程序.")]),v._v(" "),_("p",[v._v("Akka 集群可以构建可扩展的, 弹性的分布式应用程序, 因此在 JVM 中应用了 Akka 框架, 从而实现并发编程. 目前, 豌豆荚, 蘑菇街等公司采用了 Akka 集群.")]),v._v(" "),_("p",[_("strong",[v._v("小结一下. Akka 集群是一个完全去中心化的集群管理系统, 当集群组建完成后, 每个节点均可执行 Actor 应用程序, 因此支持并发操作. 但这个并发操作引入了数据同步和一致性问题, 所以 Akka 集群采用了 Gossip 协议进行数据同步, 通过谁的时间戳最新就以谁为准, 来解决一致性问题.")])]),v._v(" "),_("h5",{attrs:{id:"redis-集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis-集群"}},[v._v("#")]),v._v(" Redis 集群")]),v._v(" "),_("p",[v._v("在实际业务场景中, 除了面向应用程序平台的分布式集群管理之外, 分布式数据存储也是一个非常重要的话题. 在这其中, 分布式数据存储中的集群管理便是一个关键因素.")]),v._v(" "),_("p",[v._v("Redis 是一个开源的高性能分布式 key-value 数据库, 应用广泛, 其特征主要表现为:")]),v._v(" "),_("ul",[_("li",[v._v("支持数据的持久化, 可以将内存中的数据保存在磁盘中, 重启时可以再次加载并使用;")]),v._v(" "),_("li",[v._v("支持多种数据结构, 不仅支持简单的 key-value 类型的数据, 同时还提供 list, set, hash 等数据结构的存储;")]),v._v(" "),_("li",[v._v("支持数据的备份, 即 Master/Slave 模式的数据备份.")])]),v._v(" "),_("p",[_("strong",[v._v("Redis 的这些特征均是为数据存储进行服务的, 数据可分片存储在不同的 Redis 节点上, 多个 Redis 节点间可共享数据, 而提供这项能力的就是 Redis 集群")]),v._v(".")]),v._v(" "),_("p",[v._v("Redis 集群中不存在中央节点, 是典型的去中心化结构, 每个节点均可与其他节点通信. 所有节点均可负责存储数据, 记录集群的状态(包括键值到正确节点的映射), 客户端可以访问或连接到任一节点上. 集群节点同样能自动发现其他节点, 检测故障的节点, 并在需要的时候在从节点中推选出主节点. Redis 集群的架构图如下所示.")]),v._v(" "),_("p",[_("strong",[v._v("当然, 节点之间的数据传输仍采用了 Gossip 协议, 来保证集群中数据的最终一致性.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/671d1480d4422707498168ce953e5295-20230731163147-ociqch7.png",alt:""}})]),v._v(" "),_("p",[v._v("Redis 集群中的节点用于数据存储, 所以"),_("strong",[v._v("在设计时, 需要考虑数据的可靠性和分片存储问题")]),v._v(".")]),v._v(" "),_("p",[v._v("对于可靠性的问题, 集群中每个节点均存在主备, 也就是说每台服务器上都运行两个 Redis 服务, 分别为主备, 主故障后, 备升主.")]),v._v(" "),_("p",[v._v("而对于数据的分片存储问题, Redis 集群引入了"),_("strong",[v._v("哈希槽")]),v._v("的概念. Redis 集群内置了 16384 个哈希槽, 每个节点负责一部分哈希槽. 当客户端要存储一个数据或对象时, 对该对象的 key 通过 CRC16 校验后对 16384 取模, 也就是 "),_("code",[v._v("HASH_SLOT = CRC16(key) mod 16384")]),v._v("​ 来决定哈希槽, 从而确定存储在哪个节点上.")]),v._v(" "),_("p",[v._v("比如, 当前集群有 3 个节点, 那么:")]),v._v(" "),_("ul",[_("li",[v._v("节点 A 包含 0 到 5500 号哈希槽;")]),v._v(" "),_("li",[v._v("节点 B 包含 5501 到 11000 号哈希槽;")]),v._v(" "),_("li",[v._v("节点 C 包含 11001 到 16383 号哈希槽.")])]),v._v(" "),_("p",[v._v("Redis 集群采用集群分片方式实现了数据的分片存储, 从而将 Redis 的写操作分摊到了多个节点上, 提高了写并发能力.")]),v._v(" "),_("p",[v._v("小结一下. Redis 集群是一个非集中式集群管理系统, 没有中心节点, 不会因为某个节点造成性能瓶颈, 每个节点均支持数据存储, 且采用分片存储方式, 提高了写的并发能力. 同时, 每个节点的设计采用主备设计, 提高了数据的可靠性.")]),v._v(" "),_("h5",{attrs:{id:"cassandra-集群"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#cassandra-集群"}},[v._v("#")]),v._v(" Cassandra 集群")]),v._v(" "),_("p",[v._v("除了 Redis 外, 还有一个开源分布式 key-value 数据库系统 Cassandra. 接下来就再分享下 Cassandra 集群的设计, 以加深你对非集中式架构的理解.")]),v._v(" "),_("p",[v._v("与 Redis 类似, Cassandra 也支持数据的分布式存储和操作. 因此 Cassandra 的集群架构与数据分片存储方案与 Redis 集群类似.")]),v._v(" "),_("p",[v._v("如下图所示, "),_("mark",[_("strong",[v._v("Cassandra 集群的系统架构是基于一致性哈希的完全 P2P 结构, 没有 Master 的概念, 所有节点都是同样的角色, 彻底避免了因为单点问题导致的系统不稳定. Cassandra 集群节点间的状态同步, 也是通过 Gossip 协议来进行 P2P 通信的")])]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b5c2da46798fc10f73b258f8844f6d1d-20230731163147-094fsz2.png",alt:""}})]),v._v(" "),_("p",[v._v("集群中的每个节点, 都可以存储数据, 并接收来自客户端的请求. "),_("strong",[v._v("Cassandra 集群数据存储与 Redis 的不同之处是, Redis 集群每个节点代表一部分哈希槽, 一个哈希槽代表一个哈希值区间, 而 Cassandra 集群中每个节点代表一个哈希值")]),v._v(".")]),v._v(" "),_("p",[v._v("在 Cassandra 集群中, 每次客户端随机选择集群中的一个节点来请求数据, 对应接收请求的节点将对应的 key 在一致性哈希环上定位出是哪些节点应该存储这个数据, 然后将请求转发到对应的节点上, 并将对应若干节点的查询反馈返回给客户端.")]),v._v(" "),_("h5",{attrs:{id:"对比分析"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比分析"}},[v._v("#")]),v._v(" 对比分析")]),v._v(" "),_("p",[v._v("好了, 以上就是 Akka 集群, Redis 集群和 Cassandra 集群的主要内容了. 为了便于理解与记忆, 将这 3 个集群的主要特征梳理为了一张表格, 如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7ea99f16eb53e3dfbcb14e49c6325a8e-20230731163147-bvb7jmm.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-如何优化gossip协议中的重复消息问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-如何优化gossip协议中的重复消息问题"}},[v._v("#")]),v._v(" 知识扩展:如何优化Gossip协议中的重复消息问题?")]),v._v(" "),_("p",[v._v("非集中式结构的通信协议采用了 Gossip 协议. 而 Gossip 是一种谣言传播协议, 每个节点周期性地从节点列表中选择 k 个节点, 将本节点存储的信息传播出去, 直到所有节点信息一致, 即算法收敛了.")]),v._v(" "),_("p",[v._v("这里有个问题, 如果每次都是随机选择 k 个节点的话, 势必会存在"),_("strong",[v._v("重复选择同样节点的可能, 增加消息量")]),v._v(". 这个问题是否可以优化, 又应该如何优化呢?")]),v._v(" "),_("p",[v._v("首先, 这个问题肯定是可以优化的. 解决方案是, "),_("strong",[v._v("每个节点记录当前传输的消息且还未达到收敛的时候, 已经发送给了哪些节点, 然后每次选择时从没有发送过的节点列表中随机选择 k 个节点, 直到所有节点均被传输或集群收敛为止. 这样, 一方面减少了重复消息量, 另一方面加快了收敛速度")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"总结-8"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-8"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("集中式结构虽然易于理解, 但容易出现单点瓶颈和单点故障等问题, 而非集中结构才是超大规模分布式系统的首选结构. 所以本节以 Akka 集群, Redis 集群和 Cassandra 集群的结构为例, 详细介绍了非集中式架构.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c0605f8a086aee2fbc9143577f5536ff-20230731163147-f0qpbl5.png",alt:""}})]),v._v(" "),_("p",[v._v("虽然这三种集群的节点组织结构各有不同, 但节点之间"),_("strong",[v._v("都是通过 Gossip 协议来传递信息的")]),v._v(". 因此, 在实现过程中, 集群的消息传输, 节点的功能等, 在不同的分布式系统中都是类似的, 而难点主要在于集群结构的设计.")]),v._v(" "),_("h4",{attrs:{id:"_11-分布式调度架构之单体调度-物质文明-精神文明一手抓"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_11-分布式调度架构之单体调度-物质文明-精神文明一手抓"}},[v._v("#")]),v._v(" 11-分布式调度架构之单体调度:物质文明,精神文明一手抓")]),v._v(" "),_("p",[v._v("前两节分析了云资源管理的集中式架构和非集中式架构. 可以看出, "),_("strong",[v._v("分布式系统架构的目的是, 将多个服务器资源管理起来, 寻找合适的服务器去执行用户任务")]),v._v(".")]),v._v(" "),_("p",[v._v("那什么是合适的服务器呢? 衡量一个服务器是否合适会涉及很多条件或约束, 比如在一些场景下, 任务存在优先级, 那当需要执行多个任务的时候, 通常需要满足优先级高的任务优先执行的条件. 但在这些条件中, 服务器资源能够满足用户任务对资源的诉求是必须的.")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("而为用户任务寻找合适的服务器这个过程, 在分布式领域中叫作调度")])]),v._v(". 在分布式系统架构中, 调度器就是一个非常重要的组件. 它通常会提供多种调度策略, 负责完成具体的调度工作.")]),v._v(" "),_("p",[v._v("当然, 不同的分布式架构的调度器原理也不一样, 最常见或最直观的是"),_("strong",[v._v("单体调度")]),v._v(', 就是任务和分布式系统中的空闲资源直接进行匹配调度. 也就是说, 调度器同时管理任务和资源, 如果把资源比作 "物质文明", 把任务比作 "精神文明", 那么单体调度就是 "物质文明和精神文明一手抓".')]),v._v(" "),_("h5",{attrs:{id:"什么是单体调度"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是单体调度"}},[v._v("#")]),v._v(" 什么是单体调度?")]),v._v(" "),_("p",[v._v("首先了解一下什么是单体调度. 分布式系统中的单体调度是指, "),_("strong",[v._v("一个集群中只有一个节点运行调度进程, 该节点对集群中的其他节点具有访问权限, 可以搜集其他节点的资源信息, 节点状态等进行统一管理, 同时根据用户下发的任务对资源的需求, 在调度器中进行任务与资源匹配, 然后根据匹配结果将任务指派给其他节点")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("单体调度器拥有全局资源视图和全局任务, 可以很容易地实现对任务的约束并实施全局性的调度策略")]),v._v(". 目前很多集群管理系统采用了单体调度设计, 比如 Google Borg, Kubernetes 等.")]),v._v(" "),_("p",[v._v("如下图所示, 图中展示了一个典型的单体调度框架. Master 节点上运行了调度进程(负责资源管理, Tasks 和资源匹配); Node 1, Node 2, ...,  Node N 对应着 Master/Slave 架构中的 Slave 节点.")]),v._v(" "),_("p",[_("strong",[v._v("Slave 节点会将 Node State 上报给 Master 节点的 Cluster State 模块, Cluster State 模块用于管理集群中节点的资源等状态, 并将节点的资源状态传送给 Scheduling Logic 模块, 以便 Scheduling Logic 模块进行 Tasks 与资源匹配, 并根据匹配结果将 Task 发送给匹配到的节点.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/db823b8de64a793ac19e9c219acbc2d4-20230731163147-et1g2fw.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"单体调度设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#单体调度设计"}},[v._v("#")]),v._v(" 单体调度设计")]),v._v(" "),_("p",[v._v('在集群管理中, 单体调度模块称为 "Scheduler" 或 "单体调度器". '),_("strong",[v._v("单体调度器也叫作集中式调度器, 指的是使用中心化的方式去管理资源和调度任务.")])]),v._v(" "),_("p",[v._v("也就是说, 调度器本身在系统中以单实例形式存在, 所有的资源请求和任务调度都通过这个实例进行. 集中式调度器的常见模型, 如下图所示. 可以看到, 在这一模型中, "),_("strong",[v._v("资源的使用状态和任务的执行状态都由调度器进行管理")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bf86433c34daed5be448d3aa822d0ecd-20230731163147-bjydra3.png",alt:""}})]),v._v(" "),_("p",[v._v("在 Borg 和 Kubernetes 这两个集群管理系统中, "),_("strong",[v._v("Scheduler 是它们的核心")]),v._v(". 而 Kubernetes 又是 Borg 的开源版本. 所以接下来就以 Borg 为例, 讲述它的调度器是如何设计的, 才能保证在上万台机器规模的集群上, 运行来自几千个不同应用的几十万个作业.")]),v._v(" "),_("h5",{attrs:{id:"borg调度设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#borg调度设计"}},[v._v("#")]),v._v(" Borg调度设计")]),v._v(" "),_("p",[_("strong",[v._v("调度的初衷是为作业或任务寻找合适的资源, 也就是说作业或任务是调度的对象")]),v._v(". 那么作业和任务到底是什么呢? 下面先了解一下作业和任务的概念以及关系.")]),v._v(" "),_("p",[v._v("先来看看作业和任务的定义.")]),v._v(" "),_("p",[v._v("一个 Borg 作业的属性包括名称, 拥有者和任务个数. 作业可以有一些约束来强制其任务运行在有特定属性的机器上, 比如处理器架构, 操作系统版本, 是否有外网 IP 地址等. 这些约束可以是硬性的也可以是柔性的, 其中柔性约束表示偏好, 而非需求. 一个作业只在一个集群中运行.")]),v._v(" "),_("p",[v._v("而"),_("strong",[v._v("一个任务对应的是一组 Linux 进程")]),v._v(", 运行在一台机器上的一个容器内或直接运行在节点上. 任务也有一些属性, 比如资源需求量, 在作业中的序号等.")]),v._v(" "),_("p",[v._v("那么, "),_("strong",[v._v("作业和任务是什么关系呢?")]),v._v("  概括来说, "),_("strong",[v._v("一个作业可以包含多个任务")]),v._v(". 作业类似于用户在一次事务处理或计算过程中要求计算机所做工作的总和, 而任务就是一项项具体的工作, 二者属于包含关系.")]),v._v(" "),_("p",[v._v("一个作业中的任务大多有相同的属性, 但也可以被覆盖, 比如特定任务的命令行参数, 各维度的资源(比如, CPU 核, 内存, 硬盘空间, 硬盘访问速度, TCP 端口等).")]),v._v(" "),_("p",[_("strong",[v._v("多个任务可以在多台机器上同时执行")]),v._v(", 从而加快作业的完成速度, 提高系统的并行程度. 而具体将哪个任务分配给哪个机器去完成, 就是调度器要做的事儿了.")]),v._v(" "),_("p",[v._v("接下来, 就讲述下 Borg 的 Scheduler 组件, 来帮助理解 Borg 内部的任务调度流程, 以加深对单体调度的理解. 其实, "),_("strong",[v._v("很多框架比如 Hadoop, Spark 等都是采用了单体调度设计")]),v._v(", 它们整体的思想类似, 所以我希望通过对 Borg 调度的讲解, 能够帮助你理解你所在业务中的调度逻辑.")]),v._v(" "),_("p",[v._v("先来回忆下 Borg 的系统架构图吧.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1c06657e5b7d887358c77a1c2541fea0-20230731163147-kx9sqgq.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("Scheduler 负责任务的调度, 当用户提交一个作业给 BorgMaster 后, BorgMaster 会把该作业保存到 Paxos 仓库中, 并将这个作业的所有任务加入等待队列中. 调度器异步地扫描等待队列, 将任务分配到满足作业约束且有足够资源的计算节点上")]),v._v(".")]),v._v(" "),_("p",[v._v("这里要再强调一下, "),_("strong",[v._v("调度是以任务为单位的, 而不是以作业为单位")]),v._v(". 调度器在扫描队列时, 按照任务的优先级从高到低进行选择, 同优先级的任务则以轮询的方式处理, 以保证用户间的公平, 并避免队首的大型作业阻塞队列.")]),v._v(" "),_("p",[v._v("接下来再看看调度器的核心部分, 也就是调度算法.")]),v._v(" "),_("h5",{attrs:{id:"borg-调度算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#borg-调度算法"}},[v._v("#")]),v._v(" Borg 调度算法")]),v._v(" "),_("p",[v._v('Borg 调度算法的核心思想是 "'),_("mark",[_("strong",[v._v("筛选可行, 评分取优")])]),v._v('", 具体包括两个阶段:')]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("可行性检查")]),v._v(", 找到一组可以运行任务的机器(Borglet);")]),v._v(" "),_("li",[_("strong",[v._v("评分")]),v._v(", 从可行的机器中选择一个合适的机器(Borglet).")])]),v._v(" "),_("p",[_("strong",[v._v("首先看一下可行性检查")]),v._v(". 在可行性检查阶段, 调度器会找到一组满足任务约束, 且有足够可用资源的机器. 比如, 现在有一个任务 A 要求能部署的节点是节点 1, 节点 3 和节点 5, 并且任务资源需求为 0.5 个 CPU, 2MB 内存. 根据任务 A 的约束条件, 可以先筛选出节点 1, 节点 3 和节点 5, 然后根据任务 A 的资源需求, 再从这 3 个节点中寻找满足任务资源需求的节点.")]),v._v(" "),_("p",[v._v("这里需要注意的是, 每个节点上的可用资源, 包括已经分配给低优先级任务但可以抢占的资源.")]),v._v(" "),_("p",[_("strong",[v._v("然后看看评分阶段.")])]),v._v(" "),_("p",[_("strong",[v._v("在评分阶段, 调度器确定每台可行机器的适宜性. Borg 根据某一评分机制, 对可行性检查阶段中筛选出的机器进行打分, 选出最适合调度的一台机器.")])]),v._v(" "),_("p",[v._v("在评分过程中, 可以制定多种评价指标, 比如考虑如何最小化被抢占的任务数, 尽量选择已经下载了相同 package 的机器, 目标任务是否跨域部署, 在目标机器上是否进行高低优先级任务的混合部署等. 根据不同的考虑因素, 可以定制不同的评分算法.")]),v._v(" "),_("p",[_("strong",[v._v('其中, 常见的评分算法, 包括 "最差匹配" 和 "最佳匹配" 两种.')])]),v._v(" "),_("p",[v._v('Borg 早期使用修改过的 E-PVM 算法来评分, 该算法的核心是将任务尽量分散到不同的机器上. 该算法的问题在于, 它会导致每个机器都有少量的无法使用的剩余资源, 因此有时称其为 "'),_("strong",[v._v("最差匹配")]),v._v('"(worst fit).')]),v._v(" "),_("p",[v._v("比如, 现在有两个机器, 机器 A 的空闲资源为 1 个 CPU 和 1G 内存, 机器 B 的空闲资源为 0.8 个 CPU 和 1.2G 内存; 同时有两个任务, Task1 的资源需求为 0.4 个 CPU 和 0.3G 内存, Task2 的资源需求为 0.3CPU 和 0.5G 内存. 按照最差匹配算法思想, Task1 和 Task2 会分别分配到机器 A 和机器 B 上, 导致机器 A 和机器 B 都存在一些资源碎片, 可能无法再运行其他 Task.")]),v._v(" "),_("p",[v._v('与之相反的是 "'),_("strong",[v._v("最佳匹配")]),v._v('"(best fit), 即把机器上的任务塞得越满越好. 这样就可以 "空" 出一些没有用户作业的机器(它们仍运行存储服务), 来直接放置大型任务.')]),v._v(" "),_("p",[v._v("比如, 在上面的例子中, 按照最佳匹配算法的思想, Task1 和 Task2 会被一起部署到机器 A 或机器 B 上, 这样未被部署的机器就可以用于执行其他大型任务了.")]),v._v(" "),_("p",[v._v("但如果用户或 Borg 错误估计了资源需求, 紧凑的装箱操作会对性能造成巨大的影响. 比如用户估计它的任务 A 需要 0.5 个 CPU 和 1G 内存, 运行该任务的服务器上由于部署了其他任务, 现在还剩 0.2 个 CPU 和 1.5G 内存, 但用户的任务 A 突发峰值时(比如电商抢购), 需要 1 个 CPU 和 3G 内存, 很明显, 初始资源估计错误, 此时服务器资源不满足峰值需求, 导致任务 A 不能正常运行.")]),v._v(" "),_("p",[v._v("所以说, "),_("strong",[v._v("最佳匹配策略不利于有突发负载的应用, 而且对申请少量 CPU 的批处理作业也不友好")]),v._v(', 因为这些作业申请少量 CPU 本来就是为了更快速地被调度执行, 并可以使用碎片资源. 还有一个问题, 这种策略有点类似 "把所有鸡蛋放到一个篮子里面", 当这台服务器故障后, 运行在这台服务器上的作业都会故障, 对业务造成较大的影响.')]),v._v(" "),_("p",[v._v("因此, 这两个评分算法各有利弊. 在实践过程中, 往往会根据实际情况来选择更适宜的评分算法. 比如"),_("strong",[v._v("对于资源比较紧缺, 且业务流量比较规律, 基本不会出现突发情况的场景, 可以选择最佳匹配算法; 如果资源比较丰富, 且业务流量会经常出现突发情况的场景, 可以选择最差匹配算法")]),v._v(".")]),v._v(" "),_("p",[v._v("Borg 的设计是支持高优先级抢占低优先级任务的, 也就是说如果评分后选中的机器上没有足够的资源来运行新任务, Borg 会抢占低优先级的任务, 从最低优先级逐级向上抢占, 直到可用资源足够运行该任务. 被抢占的任务放回到调度器的等待队列里, 而不会被迁移或使其休眠.")]),v._v(" "),_("p",[v._v("当然有很多调度框架是支持用户根据自己的场景自定义调度策略的, 比如优先级策略, 亲和性策略, 反亲和性策略等.")]),v._v(" "),_("h5",{attrs:{id:"知识扩展-多个集群-数据中心如何实现单体调度呢"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-多个集群-数据中心如何实现单体调度呢"}},[v._v("#")]),v._v(" 知识扩展:多个集群/数据中心如何实现单体调度呢?")]),v._v(" "),_("p",[v._v("本节讲述的单体调度, 其实是针对一个集群或一个数据中心的, "),_("strong",[v._v("那么多个集群或多个数据中心, 能不能基于单体调度实现呢")]),v._v("?")]),v._v(" "),_("p",[v._v("答案是肯定的, 这就是"),_("strong",[v._v("集群联邦")]),v._v("的概念了. 所谓"),_("strong",[v._v("集群联邦, 就是将多个集群联合起来工作, 核心思想是增加一个控制中心, 由它提供统一对外接口, 多个集群的 Master 向这个控制中心进行注册, 控制中心会管理所有注册集群的状态和资源信息, 控制中心接收到任务后会根据任务和集群信息进行调度匹配, 选择到合适的集群后, 将任务发送给相应的集群去执行")]),v._v(".")]),v._v(" "),_("p",[v._v("集群联邦的概念, 其实就是单体调度的"),_("strong",[v._v("分层实现")]),v._v(". 如果对集群联邦感兴趣的话, 推荐看一下 Kubernetes 的集群联邦设计和工作原理.")]),v._v(" "),_("h5",{attrs:{id:"总结-9"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-9"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节以 Borg 为例, 讲述了单体调度架构的设计及调度算法. 单体调度是指一个集群中只有一个节点运行调度进程, 该调度进程负责集群资源管理和任务调度, 也就是说单体调度器拥有全局资源视图和全局任务.")]),v._v(" "),_("p",[v._v("单体调度的特征, 可以总结为以下四点:")]),v._v(" "),_("ul",[_("li",[v._v("单体调度器可以很容易实现对作业的约束并实施全局性的调度策略, 因此适合批处理任务和吞吐量较大, 运行时间较长的任务.")]),v._v(" "),_("li",[v._v("单体调度系统的状态同步比较容易且稳定, 这是因为资源使用和任务执行的状态被统一管理, 降低了状态同步和并发控制的难度.")]),v._v(" "),_("li",[v._v("调度算法只能全部内置在核心调度器当中, 因此调度框架的灵活性和策略的可扩展性不高.")]),v._v(" "),_("li",[v._v("单体调度存在单点故障的可能性.")])]),v._v(" "),_("p",[v._v("下面再用一个思维导图总结一下今天的主要内容, 以方便理解记忆.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c599b3d3d282458a99943b71d23e5de2-20230731163147-22zh8g6.png",alt:""}})]),v._v(" "),_("p",[v._v("单体调度器虽然具有单点瓶颈或单点故障问题, 但因为其具有全局资源视图和全局任务, 简单易维护, 被很多公司广泛采用. 另外 Borg 集群管理系统, 以及其开源版 Kubernetes 集群管理系统, 使用的都是单体调度结构.")]),v._v(" "),_("p",[v._v("单体调度结构虽然结构单一, 但是其调度算法可以扩展甚至自定义, 也就是说可以根据业务特征, 自定义调度策略, 比如优先级策略, 亲和性策略等.")]),v._v(" "),_("h4",{attrs:{id:"_12-分布式调度架构之两层调度-物质文明-精神文明两手抓"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_12-分布式调度架构之两层调度-物质文明-精神文明两手抓"}},[v._v("#")]),v._v(" 12-分布式调度架构之两层调度:物质文明,精神文明两手抓")]),v._v(" "),_("p",[v._v("上一节分享了单体调度. 单体调度的核心是, 所有节点的资源以及用户的任务均由中央服务器统一管理和调度. 因此, "),_("strong",[v._v("中央服务器很容易成为单点瓶颈, 会直接导致其支持的调度规模和服务类型受限")]),v._v(".")]),v._v(" "),_("p",[v._v("于是两层调度就出现了. 那到底什么是两层调度呢, 它是如何设计的, 又有哪些调度算法呢?")]),v._v(" "),_("h5",{attrs:{id:"什么是两层调度"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是两层调度"}},[v._v("#")]),v._v(" 什么是两层调度?")]),v._v(" "),_("p",[v._v("在单体调度架构中, 中央服务器的单点瓶颈问题, 会限制调度的效率和支持的任务类型. 中央服务器的性能会限制调度的效率, 很好理解, 但为什么会限制支持的任务类型呢?")]),v._v(" "),_("p",[v._v("简单地说, "),_("strong",[v._v("这是因为不同的服务具有不同的特征, 对调度框架和计算的要求都不一样")]),v._v(". 比如说, 你的业务最开始时只有批处理任务, 后来发展到同时还包括流数据任务, 但批处理任务是处理静态数据, 流数据任务却是处理实时数据. 显然, 单体调度框架会随着任务类型增加而变得越来越复杂, 最终出现扩展瓶颈.")]),v._v(" "),_("p",[v._v("那么, 为了提升调度效率并支持多种类型的任务, 最直接的一个想法就是, "),_("strong",[v._v("能不能把资源和任务分开调度, 也就是说一层调度器只负责资源管理和分配, 另外一层调度器负责任务与资源的匹配呢")]),v._v(".")]),v._v(" "),_("p",[v._v("很显然, 这个解决方案是可以的. 这种调度架构, 就是通常所说的"),_("strong",[v._v("两层调度")]),v._v('. 如果还是把资源比作物质文明, 把任务比作精神文明的话, 两层调度就可以理解为 "物质文明与精神文明两手抓".')]),v._v(" "),_("p",[_("strong",[v._v("两层调度结构对应的就是两层调度器, 资源的使用状态同时由中央调度器和第二层调度器管理, 中央调度器从整体上进行资源的管理与分配, 将资源分配到第二层调度器; 再由第二层调度器负责将资源与具体的任务配对, 因此第二层调度可以有多个调度器, 以支持不同的任务类型.")])]),v._v(" "),_("p",[v._v("如下图所示, Scheduler-1 表示第一层调度, 负责收集和管理集群中的资源信息; Scheduler-2 表示第二层调度, Scheduler-1 会将集群资源发送给 Scheduler-2, 然后 Scheduler-2 根据任务的资源需求和 Scheduler-1 发送的资源信息进行任务匹配和调度.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6f6f0db44b9a252802da3c24915dcb4d-20230731163147-ohd2e22.png",alt:""}})]),v._v(" "),_("p",[v._v("两层调度器中的第一层调度器仍是一个经简化的中央调度器, 通常放在分布式集群管理系统中, 而第二层调度则是由各个应用程序框架完成. 两层调度器的职责分别是: 第一层调度器负责管理资源并向框架分配资源, 第二层调度器接收分布式集群管理系统中第一层调度器分配的资源, 然后根据任务和接收到的资源进行匹配.")]),v._v(" "),_("p",[v._v("采用两层调度结构的集群管理系统有很多, 典型代表是 Apache Mesos 和 Hadoop YARN. 本节继续以 Mesos 为例, 来学习两层调度的架构设计和对应的分配算法.")]),v._v(" "),_("h5",{attrs:{id:"两层调度设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#两层调度设计"}},[v._v("#")]),v._v(" 两层调度设计")]),v._v(" "),_("p",[_("strong",[v._v("由于 Mesos 只负责底层资源的管理和分配, 并不涉及存储, 任务调度等功能, 因此 Mesos 要实现类似 Borg 那样的资源与任务管理, 还需要上层框架的配合")]),v._v(".")]),v._v(" "),_("p",[v._v("具体到两层调度架构上, Mesos 本身实现的调度器为第一层调度, 负责资源管理, 然后将第二层任务调度交给了框架完成. 接下来就具体看看.")]),v._v(" "),_("h6",{attrs:{id:"两层调度架构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#两层调度架构"}},[v._v("#")]),v._v(" 两层调度架构")]),v._v(" "),_("p",[v._v("以 Mesos 为基础的分布式资源管理与调度框架包括两部分, 即 Mesos 资源管理集群和框架.")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("资源管理集群是由一个 Master 节点和多个 Slave 节点组成的集中式系统. 每个集群有且仅有一个 Master 节点, 负责管理 Slave 节点, 并对接上层框架; Slave 节点向 Master 节点周期汇报资源状态信息, 并执行框架提交的任务.")])]),v._v(" "),_("li",[_("strong",[v._v('框架(Framework)运行在 Mesos 上, 是负责应用管理与调度的 "组件", 比如 Hadoop, Spark, MPI 和 Marathon 等, 不同的框架用于完成不同的任务, 比如批处理任务, 实时分析任务等. 框架主要由调度器(Scheduler)和执行器(Executor)组成, 调度器可以从 Master 节点获取集群节点的信息, 执行器在 Slave 节点上执行任务.')])])]),v._v(" "),_("p",[v._v("从上述的架构描述可以看出, Mesos 是一个典型的双层调度框架. Mesos Master 上有一个调度器(也就是 Allocation Module), 负责管理并分配集群中的所有资源, 是第一层调度. 框架上负责任务的管理与调度的调度器, 是第二层调度, 如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/19d2115c6c20c164e42ac7c77f5ad808-20230731163147-04pvto4.png",alt:""}})]),v._v(" "),_("p",[v._v("接下来再看看 Mesos 两层调度的基本原理吧.")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("框架向 Mesos Master 注册;")])]),v._v(" "),_("li",[_("strong",[v._v("Mesos Slave 节点定期或周期向 Mesos Master 上报本节点的空闲资源;")])]),v._v(" "),_("li",[_("strong",[v._v("Mesos Master 的 Scheduler 进程收集所有节点的空闲资源信息, 并以 Resource Offer 的方式将空闲资源发送给注册的框架;")])]),v._v(" "),_("li",[_("strong",[v._v("框架的 Scheduler 接收到 Mesos 发送的资源后, 进行任务调度与匹配, 匹配成功后, 将匹配结果下发给 Mesos Master, 并由 Mesos Master 转发给相应节点的执行器执行任务.")])])]),v._v(" "),_("p",[v._v("可以看出, Mesos 实现双层调度时, 采用 Resource Offer 机制衔接了第一层和第二层调度. "),_("strong",[v._v("Resource Offer 机制")]),v._v("指的是, Mesos Master 主动将节点空闲资源, 以类似发放(Offer)的方式发给每个框架, 如果框架需要则使用, 不需要则还回.")]),v._v(" "),_("p",[v._v("也就是说, 通过 Resource Offer 机制, 第一层调度将资源主动告知第二层调度, 然后第二层调度进行具体的任务匹配, 从而实现了任务调度与资源管理的分离, Mesos Master 通过资源分配算法决定给各个 Framework 提供多少资源, 而 Framework 则决定接受哪些资源, 以及哪些任务使用这些资源运行. 这样一来, 一个两层调度架构就实现了.")]),v._v(" "),_("p",[v._v("在 Mesos 的两层调度中, Framework 第二层调度器中的任务与资源匹配的调度策略很常见, 也有很多文章做了比较深入的分析了, 所以如果想要深入研究的话, 可以参考下 Hadoop, Spark 等的调度策略.")]),v._v(" "),_("p",[v._v("接下来重点看下 Mesos 第一层调度算法, 理解其如何为框架分配资源, 以支持多用户多框架.")]),v._v(" "),_("h6",{attrs:{id:"资源分配算法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#资源分配算法"}},[v._v("#")]),v._v(" 资源分配算法")]),v._v(" "),_("p",[v._v("Mesos 的资源分配算法解决的问题是, "),_("strong",[v._v("决策需要将当前可用资源分配给哪些框架以及分配多少")]),v._v(". 接下来, 将重点介绍两种主要的资源分配算法, 即: "),_("mark",[_("strong",[v._v("最大最小公平算法(Max-min Fairness, MMF)和主导资源公平算法(Dominant Resource Fairness, DRF)")])]),v._v(" .")]),v._v(" "),_("p",[_("strong",[v._v("首先, 看看最大最小公平算法.")]),v._v("  这是一种在兼顾公平的前提下, 尽可能让更多人满意的资源分配算法. 为什么这么说呢? 因为这个算法有 3 个主要原则:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("按照用户对资源需求量递增的顺序进行空闲资源分配;")])]),v._v(" "),_("li",[_("strong",[v._v("不存在用户得到的资源超过自己需求的情况;")])]),v._v(" "),_("li",[_("strong",[v._v("对于分配的资源不满足需求的用户, 所获得的资源是相等的.")])])]),v._v(" "),_("p",[v._v("在执行资源分配时, 最大最小公平算法按照上述 3 条原则进行多次迭代, 每次迭代中资源均平均分配, 如果还有剩余资源, 就进入下一次迭代, 一直到所有用户资源得到满足或集群资源分配完毕, 迭代结束.")]),v._v(" "),_("p",[v._v("接下来通过一个具体的例子来看看最大最小公平算法的资源分配流程.")]),v._v(" "),_("p",[v._v("假设, 现在有总量为 100 的空闲资源, 有 4 个用户 A, B, C, D 对该资源的需求量分别为(35, 10, 25, 45), 分配流程如下所示:")]),v._v(" "),_("ol",[_("li",[v._v("按照用户对资源的需求量升序排列, 则 4 个用户的需求量为(B:10, C:25, A:35, D:45).")]),v._v(" "),_("li",[v._v("平均分配空闲资源. 资源空闲总量 100, 除以用户数 4, 则"),_("strong",[v._v("平均空闲资源量为 25")]),v._v("; 按照第一步中需求量分配后, 用户资源需求量为(0, 0, 10, 20), 且用户 B 由于资源需求量小于 25, 因此会剩余资源. 此时空闲资源量为 15, 资源需求人数为 2.")]),v._v(" "),_("li",[v._v("重复第二步, 平均分配资源, 15/2=7.5, 即分别为用户 A 和 D 分配 7.5 份资源, 此时用户资源需求量为(0, 0, 2.5, 12.5), 空闲资源量为 0, 资源需求人数为 2.")]),v._v(" "),_("li",[v._v("所有资源已分配完, 算法终止.")])]),v._v(" "),_("p",[v._v("最大最小公平算法的执行流程, 如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/820009e8c1caf9a546d73ff30a15f0c1-20230731163147-8kz3az6.png",alt:""}})]),v._v(" "),_("p",[v._v("在这个案例中, 最大最小公平算法是由于所有资源全部分配完才终止的. 至此, 对于需求量为(10, 25, 35, 45)的用户们来说, 分配到的资源是(10, 25, 32.5, 32.5). 这个算法的另外一个结束条件是, "),_("strong",[v._v("资源分配满足了所有用户的资源需求, 即当没有用户有资源需求时, 算法也会终止")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("接下来, 再看看主导资源公平算法.")])]),v._v(" "),_("p",[v._v("最大最小公平算法采用了绝对公平的方式分配资源, 会"),_("strong",[v._v("导致大量的资源浪费")]),v._v(", 比如用户需求量为 35 和 45 的用户 A 和用户 D, 均分配了 32.5 的空闲资源, 但由于资源不满足需求, 这两个用户均无法使用.")]),v._v(" "),_("p",[v._v("而主导资源公平算法在考虑用户公平性的前提下, 还考虑了用户对不同资源类型的需求, 以尽可能地合理分配资源. 也就是说, 同样的资源量, "),_("strong",[v._v("主导资源公平算法可以尽可能地满足更多的用户")]),v._v(".")]),v._v(" "),_("p",[v._v("在 Mesos 中, 框架对资源的需求往往包括对 CPU, 内存等多种类型资源的需求. 针对多种资源的需求, "),_("strong",[v._v("主导资源公平算法首先计算已经分配给用户的每一种资源的占用率(Resource Share)")]),v._v(" , 比如已经分配的 CPU 占总资源量的多少, 已经分配的内存占总资源量的多少. 所有资源占用率中的最大值称作该"),_("strong",[v._v("用户的主导资源占用率")]),v._v(", 而主导资源占用率对应的资源就是用户的主导资源.")]),v._v(" "),_("p",[v._v("通过一个具体的案例, 看看如何判断用户的主导资源. 如下图所示, 假设系统中的资源共包括 18 个 CPU 和 36 GB 内存, 有两个 Framework(Framework A 和 Framework B)分别运行了两种任务, 假设 Framework A 运行内存密集型任务, Framework B 运行 CPU 密集型任务, 且每个任务所需要的资源量是一致的, 分别是 (2 CPU, 8 GB) 和 (6 CPU, 2 GB).")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/8378f5a794eeae6d86e315e9ce7f8f84-20230731163147-8x42buw.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("第一步: 计算资源分配量.")])]),v._v(" "),_("p",[v._v("假设 x 和 y 分别是 Framework A 和 Framework B 分配的任务数, 那么 Framework A 消耗的资源为 "),_("code",[v._v("{2x CPU, 8x GB}")]),v._v("​, Framework B 消耗的资源数为 "),_("code",[v._v("{6y CPU, 2y GB}")]),v._v("​, 分配给两个 Framework 的总资源量为 "),_("code",[v._v("(2x + 6y)")]),v._v("​ 个 CPU 和 "),_("code",[v._v("(8x + 2y)GB")]),v._v("​ 内存.")]),v._v(" "),_("p",[_("strong",[v._v("第二步: 确定主导资源.")])]),v._v(" "),_("p",[v._v("对于 Framework A 来说, 每个任务要消耗总 CPU 资源的 2/18, 总内存资源的 8/36, 所以 "),_("strong",[v._v("Framework A 的主导资源为内存")]),v._v("; 对于 Framework B 来说, 每个任务要消耗总 CPU 资源的 6/18 和总内存资源的 2/36, 因而 "),_("strong",[v._v("Framework B 的主导资源为 CPU")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("第三步: DRF 算法的核心是平衡所有用户的主导资源占用率, 尽可能试图最大化所有用户中最小的主导资源占用率")]),v._v(".")]),v._v(" "),_("p",[v._v("通过求解下列公式, 可以计算出 Framework A 和 Framework B 分配的任务数, 并且要在满足公式的条件下, 使得 x 和 y 越大越好.")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[_("span",{pre:!0,attrs:{class:"token number"}},[v._v("2")]),v._v("x "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("+")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("6")]),v._v("y ≤ "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("188")]),v._v("x "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("+")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("2")]),v._v("y ≤ "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("368")]),v._v("x "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("36")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("=")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("6")]),v._v("y "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("18")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("通过求解可以得出: x=3, 即 Framework A 可以运行 3 个任务; y=2, 即 Framework B 可以运行 2 个任务. 这样分配的话, 每个 Framework 获取了相同比例的主导资源, 即: A 获取了 2/3 的内存, B 获取了 2/3 的 CPU, 从而在"),_("strong",[v._v("主导资源上体现了调度算法的公平性")]),v._v(".")]),v._v(" "),_("p",[v._v("在实际任务分配过程中, 主导资源率是根据已经分配给 Framework 的资源, 占集群中总资源量的多少进行计算的, 并且在每次分配过程中, 会选择主导资源最小的 Framework 进行分配, 也就是试图最大化所有用户中最小的主导资源占用率.")]),v._v(" "),_("p",[v._v('如果想深入研究主导资源公平算法的话, 可参考"'),_("a",{attrs:{href:"https://cs.stanford.edu/~matei/papers/2011/nsdi_drf.pdf",target:"_blank",rel:"noopener noreferrer"}},[v._v("Dominant Resource Fairness: Fair Allocation of Multiple Resource Types"),_("OutboundLink")],1),v._v('"这篇论文.')]),v._v(" "),_("p",[_("strong",[v._v("现在来对比下这两种调度算法.")])]),v._v(" "),_("p",[_("strong",[v._v("最大最小公平算法适用于单一类型的资源分配场景, 而主导资源公平算法适用于多种类型资源混合的场景. 并且, 最大最小公平算法从公平的角度出发, 为每个用户分配不多于需求量的资源; 而主导资源公平算法从任务出发, 目的在于尽量充分利用资源使得能够执行的任务越多越好.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-两层调度如何保证不同的业务不会互相干扰"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-两层调度如何保证不同的业务不会互相干扰"}},[v._v("#")]),v._v(" 知识扩展:两层调度如何保证不同的业务不会互相干扰?")]),v._v(" "),_("p",[v._v("类似 Mesos 这样的两层调度机制, 可以同时支持多个框架和多种类型的业务, 那么如何保证这些业务运行时不会互相干扰呢?")]),v._v(" "),_("p",[v._v("首先, 思考一下什么情况下会存在业务运行时相互干扰呢. 答案就是, "),_("strong",[v._v("当多个业务运行在同一台机器上, 共同使用 CPU, 内存, 以及系统环境时会存在相互干扰")]),v._v(".")]),v._v(" "),_("p",[v._v("要解决这个问题, 我想你肯定会问, 不同的业务能在独立的环境中运行吗? 也就是说, 隔离不同的业务资源和环境, 应该就不会存在相互干扰了. 不错, "),_("strong",[v._v("解决这个问题的办法就是资源隔离")]),v._v(", 就好比虚拟机一样, 在同样的服务器上安装多个虚拟机, 不同的用户在不同的虚拟机上运行, 这些用户互不干扰. 在 Mesos 中, "),_("strong",[v._v("实现这种资源隔离的是容器")]),v._v(". Mesos 正是用容器隔离开了不同的业务, 使得它们运行时不会互相干扰.")]),v._v(" "),_("h5",{attrs:{id:"总结-10"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-10"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节以 Mesos 为例, 讲述了两层调度的架构设计和资源分配算法.")]),v._v(" "),_("p",[v._v("两层调度是一种资源和任务分开调度的设计, 也就是说一层调度器只负责资源的管理和分配, 另外一层调度器负责任务与资源的匹配.")]),v._v(" "),_("p",[v._v("在 Mesos 中, 第一层资源调度由 Mesos 提供, 第二层任务调度由框架提供, Mesos 将资源以 Resource Offer 的形式发放给框架调度器, 框架调度器根据任务需求和得到的资源信息进行任务匹配调度, 为此提高了调度的并发性. 而关于第一层的调度算法, 通常有最大最小公平算法和主导资源公平算法等.")]),v._v(" "),_("p",[v._v("两层调度的一个问题是, 由于第二层调度只能获得部分资源视图, 因此无法实现全局最优调度.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/21ddcc894ca6500c34a2f8d3ae5205c9-20230731163147-xsct8oc.png",alt:""}})]),v._v(" "),_("p",[v._v("两层调度提供了多租户多框架的支持, 如果业务类型比较多或者面向的是不同的租户的话, 建议采用两层调度框架.")]),v._v(" "),_("h4",{attrs:{id:"_13-分布式调度架构之共享状态调度-物质文明-精神文明多手协商抓"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_13-分布式调度架构之共享状态调度-物质文明-精神文明多手协商抓"}},[v._v("#")]),v._v(" 13-分布式调度架构之共享状态调度:物质文明,精神文明多手协商抓")]),v._v(" "),_("p",[v._v("上一节一起学习了两层调度. 在两层调度架构中, 第二层调度只知道集群中的部分资源, 无法进行全局最优调度. 那么, "),_("strong",[v._v("是否有办法解决全局最优调度的问题")]),v._v("呢? 答案是肯定的, 解决办法就是"),_("strong",[v._v("共享状态调度")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"什么是共享状态调度"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是共享状态调度"}},[v._v("#")]),v._v(" 什么是共享状态调度?")]),v._v(" "),_("p",[v._v("通过前两节的讲述, 不难发现, 集群中需要管理的对象主要包括两种:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("一是, 资源的分配和使用状态;")])]),v._v(" "),_("li",[_("strong",[v._v("二是, 任务的调度和执行状态;")])])]),v._v(" "),_("p",[v._v("在单体调度中, 这两种对象都是由单体调度器管理的, 因此可以比较容易地保证全局状态的一致性, 但问题是可扩展性较差(支持业务类型受限), 且存在单点瓶颈问题.")]),v._v(" "),_("p",[v._v("而在两层调度中, 这两种对象分别由第一层中央调度器和第二层 Framework 调度器管理, 由于 Framwork 调度器只能看到部分资源, 因此"),_("strong",[v._v("不能保证全局状态的一致性, 也不容易实现全局最优的调度")]),v._v(".")]),v._v(" "),_("p",[v._v("为了解决这些问题, 一种新的调度器架构被设计了出来. 这种架构基本上沿袭了单体调度器的模式, "),_("strong",[v._v("通过将单体调度器分解为多个调度器, 每个调度器都有全局的资源状态信息, 从而实现最优的任务调度, 提供了更好的可扩展性")]),v._v(".")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("这种调度架构在支持多种任务类型的同时, 还能拥有全局的资源状态信息. 要做到这一点, 这种调度架构的多个调度器需要共享集群状态, 包括资源状态和任务状态等")]),v._v(". 因此这种调度架构称为"),_("strong",[v._v("共享状态调度器")]),v._v(".")]),v._v(" "),_("p",[v._v('如果继续把资源比作物质文明, 把任务比作精神文明的话, 相对于单体调度和两层调度来说, 共享状态调度就是 "物质文明与精神文明多手协商抓".')]),v._v(" "),_("p",[v._v("共享状态调度架构的示意图, 如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/166b0397547b751ed084a782a8b200a8-20230731163147-q3xbyql.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, **共享状态调度架构为了提供高可用性和可扩展性, 将集群状态之外的功能抽出来作为独立的服务. **具体来说就是:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("State Storage 模块(资源维护模块)负责存储和维护资源及任务状态, 以便 Scheduler 查询资源状态和调度任务;")])]),v._v(" "),_("li",[_("strong",[v._v("Resource Pool 即为多个节点集群, 接收并执行 Scheduler 调度的任务;")])]),v._v(" "),_("li",[_("strong",[v._v("而 Scheduler 只包含任务调度操作, 而不是像单体调度器那样还需要管理集群资源等.")])])]),v._v(" "),_("p",[v._v("共享状态调度也支持多种任务类型, 但与两层调度架构相比, 主要有两个不同之处:")]),v._v(" "),_("ul",[_("li",[v._v("存在多个调度器, 每个调度器都可以拥有集群全局的资源状态信息, 可以根据该信息进行任务调度;")]),v._v(" "),_("li",[_("strong",[v._v("共享状态调度是乐观并发调度")]),v._v(", 在执行了任务匹配算法后, 调度器将其调度结果提交给 State Storage, 由其决定是否进行本次调度, 从而解决竞争同一种资源而引起的冲突问题, 实现全局最优调度. 而两层调度是悲观并发调度, 在执行任务之前避免冲突, 无法实现全局最优匹配.")])]),v._v(" "),_("p",[v._v("看到这里, 再说说"),_("strong",[v._v("乐观并发调度和悲观并发调度的区别")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("乐观并发调度, 强调事后检测, 在事务提交时检查是否避免了冲突: 若避免, 则提交; 否则回滚并自动重新执行. 也就是说, 它是在执行任务匹配调度算法后, 待计算出结果后再进行冲突检测.")])]),v._v(" "),_("p",[_("strong",[v._v("悲观并发调度, 强调事前预防, 在事务执行时检查是否会存在冲突. 不存在, 则继续执行; 否则等待或回滚. 也就是说, 在执行任务匹配调度算法前, 通过给不同的 Framework 发送不同的资源, 以避免冲突.")])]),v._v(" "),_("p",[v._v("现在已经对共享状态调度有了一个整体印象, 知道了它可以解决什么问题. 那么接下来再看看这种调度架构是如何设计的.")]),v._v(" "),_("h5",{attrs:{id:"共享状态调度设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#共享状态调度设计"}},[v._v("#")]),v._v(" 共享状态调度设计")]),v._v(" "),_("p",[v._v("共享状态调度的理念最早是 Google 针对两层调度器的不足, 提出的一种调度架构. 这种调度结构的典型代表有 Google 的 Omega, 微软的 Apollo, 以及 Hashicorp 的 Nomad 容器调度器.")]),v._v(" "),_("p",[v._v("作为 Google 公司的第二代集群管理系统, Omega 在设计时参考了 Borg 的设计, 吸收了 Borg 的优点, 并改进了其不足之处. 所以接下来就以 Omega 为例讲述共享状态调度的架构和工作原理.")]),v._v(" "),_("h6",{attrs:{id:"omega调度架构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#omega调度架构"}},[v._v("#")]),v._v(" Omega调度架构")]),v._v(" "),_("p",[v._v('Omega 集群中有一个 "Cell" 的概念, '),_("strong",[v._v("每个 Cell 管理着部分物理集群, 一个集群有多个 Cell")]),v._v('. 实际上, 可以直接将这里的 "Cell" 理解为一个集群的子集群或子节点的集合.')]),v._v(" "),_("p",[v._v("Omega 集群的调度架构示意图, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/892783d2b074281c7dec66503f83afaa-20230731163147-ihkwppi.png",alt:""}})]),v._v(" "),_("p",[v._v("在介绍共享状态调度的架构时提到, State Storage 模块负责存储和维护资源及任务状态, 里面有一个 Cell State 文件, 记录着全局共享的集群状态. "),_("strong",[v._v("实际上, State Storage 组件中的集群资源状态信息, 就是主本, 而 Cell State 就是以主副本的形式存在的")]),v._v(". 每个调度器都包含一个私有的 Cell State 副本, 也就是拥有了一个集群资源状态信息的副本, 进而达到了共享集群资源状态信息的目的.")]),v._v(" "),_("p",[_("strong",[v._v("在 Omega 系统中, 没有中央资源分配器, 所有资源分配决策都在调度器(Scheduler)中进行. 每个调度器都可以根据私有的 Cell State 副本, 来制定调度决策")]),v._v(".")]),v._v(" "),_("p",[v._v("调度器可以查看 Cell 的整个状态, 并申请任何可用的集群资源. 一旦调度器做出资源调度决策, 它就会在原子提交中更新本地的 Cell State 的资源状态副本. 若同时有多个调度器申请同一份资源, State Storage 模块可以根据任务的优先级, 选择优先级最高的那个任务进行调度.")]),v._v(" "),_("p",[_("strong",[v._v("可以看出, 在 Omega 系统中的每个调度器, 都具有对整个集群资源的访问权限, 从而允许多个调度器自由地竞争空闲资源, 并在更新集群状态时使用乐观并发控制来调解资源冲突问题.")]),v._v("  这样一来, Omega 就有效地解决了两层调度中 Framework 只拥有局部资源, 无法实现全局最优的问题.")]),v._v(" "),_("p",[v._v("接下来看一下 Omega 共享调度的工作原理.")]),v._v(" "),_("h6",{attrs:{id:"omega共享调度工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#omega共享调度工作原理"}},[v._v("#")]),v._v(" Omega共享调度工作原理")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("Omega 使用事务管理状态的设计思想, 将集群中资源的使用和任务的调度类似于基于数据库中的一条条事务(Transaction)一样进行管理")])]),v._v(". 显然, 数据库是一个共享的状态, 对应 Omega 中的 Cell State, 而每个调度器都要根据数据库的信息(即集群的资源信息)去独立完成自己的任务调度策略.")]),v._v(" "),_("p",[v._v("接下来具体看看.")]),v._v(" "),_("p",[v._v("如下图所示, 在一个应用执行的过程中, "),_("strong",[v._v("调度器会将一个 Job 中的所有 Task 与 Resource 进行匹配, 可以说 Task 与 Resource 之间是进行多对多匹配的")]),v._v(". 其间, 调度器会设置多个 Checkpoint 来检测 Resource 是否都已经被占用, 只有这个 Job 的所有 Task 可以匹配到可用资源时, 这个 Job 才可以被调度.")]),v._v(" "),_("p",[v._v("这里的 Job 相当于一个事务, 也就是说, 当所有 Task 匹配成功后, 这个事务就会被成功 Commit, 如果存在 Task 匹配不到可用资源, 那么这个事务需要执行回滚操作, Job 调度失败.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7bcf60cc112f79cc100c0df73946a47a-20230731163147-399fsy4.png",alt:""}})]),v._v(" "),_("p",[v._v("无论事务是否执行成功, 调度器都会在事务执行之后, 重新从主本那里同步更新本地 Cell State 的资源状态副本, 以保证本地集群信息状态的有效性. 若事务未成功执行, 则调度器会在必要时重新运行其调度算法并再次尝试申请资源.")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("调度器对 Job 的调度是具有原子性的, 一个 Job 的所有 Task 都是一起调度的, 即使部分 Task 调度失败了, 调度器再次调度时也必须再次调度整个 Job")]),v._v(". 多个调度器可以并行调度, 无需等待其他调度器调度结果, 若存在冲突时, 进行冲突处理, 比如根据 Job 的优先级, 优先级高则获得资源.")]),v._v(" "),_("p",[v._v("由此可以看到, "),_("strong",[v._v("Omega 涉及了 Job 并发调度")]),v._v(". 针对这一点, Omega 采用了传统数据库中的乐观锁(MVCC, Multi-Version Concurrency Control, 基于多版本的并发访问控制), 即每一个应用都发放了所有的可用资源, 在更新集群状态时使用乐观并发控制来解决资源冲突问题, 来提高 Omega 的并发度.")]),v._v(" "),_("p",[v._v("不同的 Omega 调度器可以实现不同的策略, 但有一些调度规则是所有调度器必须达成一致的, 比如哪些资源是允许分配的, 如何评估作业的优先级等.")]),v._v(" "),_("p",[v._v("因此, "),_("strong",[v._v("Omega 调度器将两层调度器中的集中式资源调度模块简化成了一些持久化的共享数据(状态)和针对这些数据的验证代码")]),v._v('. 而这里的 "共享数据", 实际上就是整个集群的实时资源状态信息, 而验证代码就是解决调度冲突的调度规则.')]),v._v(" "),_("h5",{attrs:{id:"知识扩展-单体调度-两层调度和共享调度的区别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-单体调度-两层调度和共享调度的区别是什么"}},[v._v("#")]),v._v(" 知识扩展:单体调度,两层调度和共享调度的区别是什么?")]),v._v(" "),_("p",[v._v("现在已经学习了单体调度, 双层调度和共享调度, 那么这三种调度的区别是什么? 接下来就一起回忆并对比下.")]),v._v(" "),_("p",[v._v("下面把这三种调度的架构示意图放到一起, 先帮你有一个整体认识.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f199edbcd4e311f366dbe99321d296d6-20230731163147-n9l3kw3.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("单体调度")]),v._v(", 是由一个中央调度器去管理整个集群的资源信息和任务调度, 也就是说"),_("strong",[v._v("所有任务只能通过中央调度器进行调度")]),v._v(". 这种调度架构的优点是, 中央调度器拥有整个集群的节点资源信息, 可以实现"),_("strong",[v._v("全局最优调度")]),v._v(". 但它的缺点是, 无调度并发性, 且中央服务器存在"),_("strong",[v._v("单点瓶颈问题")]),v._v(", 导致支持的调度规模和服务类型受限, 同时会限制集群的调度效率. 因此, 单体调度适用于小规模集群.")]),v._v(" "),_("p",[_("strong",[v._v("两层调度")]),v._v(", 是将资源管理和任务调度分为两层来调度. 其中, "),_("strong",[v._v("第一层调度器负责集群资源管理, 并将可用资源发送给第二层调度; 第二层调度接收到第一层调度发送的资源, 进行任务调度")]),v._v(". 这种调度架构的优点是, 避免了单体调度的单点瓶颈问题, 可以支持更大的服务规模和更多的服务类型. 但其缺点是, 第二层调度器往往只对全局资源信息有部分可观察性, 因此"),_("strong",[v._v("任务匹配算法无法实现全局最优")]),v._v(". 双层调度适用于中等规模集群.")]),v._v(" "),_("p",[_("strong",[v._v("共享状态调度")]),v._v(", 多个调度器, 每个调度器都可以看到集群的全局资源信息, 并根据这些信息进行任务调度. 相较于其他两个调度架构来说, 共享状态调度架构适用的集群规模最大. "),_("strong",[v._v("这种调度架构的优点是, 每个调度器都可以获取集群中的全局资源信息, 因此任务匹配算法可以实现全局最优性. 但也因为每个调度器都可以在全局范围内进行任务匹配, 所以多个调度器同时调度时, 很可能会匹配到同一个节点, 从而造成资源竞争和冲突")]),v._v(".")]),v._v(" "),_("p",[v._v("虽然 Omega 的论文宣称可以通过乐观锁机制, 避免冲突. 但在工程实践中, 如果没有妥善处理资源竞争的问题, 则很可能会产生资源冲突, 从而导致任务调度失败. 这时用户就需要对调度失败的任务进行处理, 比如重新调度, 任务调度状态维护等, 从而进一步增加了任务调度操作的复杂度.")]),v._v(" "),_("p",[v._v("下面将单体调度, 两层调度, 共享状态调度总结在了一张表格中:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bf5c20bc0afe72e1b86064e29136204f-20230731163147-3vyr5mg.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"总结-11"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-11"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享了分布式调度架构设计中的共享状态调度.")]),v._v(" "),_("p",[v._v("首先讲述了什么是共享状态调度. 概括地说, "),_("strong",[v._v("共享状态调度是将单体调度器分解为多个服务, 由多个服务共享集群状态, 包括资源状态和任务状态等")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来以 Google 的 Omega 集群管理系统为例, 分享了共享状态调度的架构和工作原理. 共享状态调度包含多个调度器, 每个调度器都可以看到集群的全局资源信息, 并根据这些信息进行任务调度.")]),v._v(" "),_("p",[v._v("最后要说明的是, "),_("strong",[v._v("共享状态调度是乐观并发调度, 调度器将其调度的结果以原子的方式提交给资源维护模块, 由其决定是否进行本次调度")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/32f46e13efcdd76715468ecde3960c98-20230731163147-3krnl47.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("在分布式领域中, 共享状态调度, 是 Google 号称的下一代集群管理系统 Omega 的调度机制, 可以解决双层调度无法实现全局最优的问题, 同时也避免了单体调度的单点瓶颈问题.")])]),v._v(" "),_("p",[v._v("但说到这儿你可能会回想起曾经看到的两句话:")]),v._v(" "),_("ol",[_("li",[v._v("为了达到设计目标, Omega 的实现逻辑变得越来越复杂. 在原有的 Borg 共享状态模型已经能满足绝大部分需要的情况下, Omega 的前景似乎没有那么乐观.")]),v._v(" "),_("li",[v._v("Omega 系统缺点是, 在小集群下没有优势.")])]),v._v(" "),_("p",[v._v("这里再解释下, 为什么说 Omega 是 Google 准备打造的下一代集群管理系统.")]),v._v(" "),_("p",[v._v("从调度架构方面来看, Borg 无法支持同时存在多种业务类型的场景, 并且存在单点瓶颈问题. 而 Omega 解决了 Borg 的这两个问题, 但是当多个调度器并行调度时, 可能存在资源冲突, 当资源申请产生冲突时, 会导致大量任务或任务多次调度失败, 增加了任务调度失败的故障处理的复杂度, 比如需要进行作业回滚, 任务状态维护等.")]),v._v(" "),_("p",[v._v("因此, "),_("strong",[v._v("设计一个好的冲突避免策略是共享状态调度的关键")]),v._v(". 对于小规模集群来说, 其集群规模, 任务数量等都不大, 使用单体调度就可以满足其任务调度的需求, 避免了考虑复杂的冲突避免策略. 也就是说, 共享状态调度比较适合大规模, 同时存在多种业务类型的场景, 不太适合小规模集群.")]),v._v(" "),_("h3",{attrs:{id:"分布式计算技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式计算技术"}},[v._v("#")]),v._v(" 分布式计算技术")]),v._v(" "),_("h4",{attrs:{id:"_15-分布式计算模式之mr-一门同流合污的艺术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_15-分布式计算模式之mr-一门同流合污的艺术"}},[v._v("#")]),v._v(" 15-分布式计算模式之MR:一门同流合污的艺术")]),v._v(" "),_("p",[v._v("前面介绍两层调度时提到, Mesos 的第二层调度是由 Framework 完成的. "),_("strong",[v._v("这里的 Framework 通常就是计算框架, 比如 Hadoop, Spark 等. 用户基于这些计算框架, 可以完成不同类型和规模的计算")]),v._v(".")]),v._v(" "),_("p",[v._v('接下来就要进入 "第三站: 分布式计算技术" 了. 这部分会详细介绍'),_("mark",[_("strong",[v._v("分布式领域中的 4 种计算模式, 包括 MapReduce, Stream, Actor 和流水线")])]),v._v(".")]),v._v(" "),_("p",[v._v('本节就先从 MR 模式开始. Hadoop 这个框架主要用于解决海量数据的计算问题. 那它是如何做到海量数据计算的呢? 你可能会想, 既然是海量数据, 规模这么大, 那就分成多个进程, 每个进程计算一部分, 然后汇总一下结果, 就可以提升运算速度了. 其实, 整个计算流程, 可以很形象地用一个词来解释, 就是"同流合污".')]),v._v(" "),_("p",[v._v("没错, 就是这种想法, 在分布式领域中就叫作 MR 模式, 即 "),_("strong",[v._v("Map Reduce 模式")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"什么是分而治之"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分而治之"}},[v._v("#")]),v._v(" 什么是分而治之?")]),v._v(" "),_("p",[v._v("分而治之(Divide-and-Conquer), 是计算机处理问题的一个很重要的思想, 简称为分治法. 顾名思义, 分治法就是将一个复杂的, 难以直接解决的大问题, 分割成一些规模较小的, 可以比较简单的或直接求解的子问题, 这些子问题之间相互独立且与原问题形式相同, 递归地求解这些子问题, 然后将子问题的解合并得到原问题的解.")]),v._v(" "),_("p",[v._v("比如, 现在要统计全中国的人口数, 由于中国的人口规模很大, 如果让工作人员依次统计每个省市的人口数, 工作量会非常大. 在实际统计中, 我们通常会按照省分别统计, 比如湖南省的工作人员统计湖南省的人口数, 湖北省的工作人员统计湖北省的人口数等, 然后汇总各个省的人口数, 即可得到全国人口数. 这就是一个非常好的分而治之的例子.")]),v._v(" "),_("p",[v._v("当然, 这种分治的思想还广泛应用于计算机科学的各个领域中, 分布式领域中的很多场景和问题也非常适合采用这种思想解决, 并为此设计出了很多计算框架. 比如, "),_("strong",[v._v("Hadoop 中的 MapReduce")]),v._v(".")]),v._v(" "),_("p",[v._v("那么, "),_("strong",[v._v("在分布式领域, 具体有哪些问题适合采用分治法呢?")]),v._v("  要回答这个问题, 先看下适合分治法的问题具有哪些特征吧.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("问题规模比较大或复杂, 且问题可以分解为几个规模较小的, 简单的同类型问题进行求解;")])]),v._v(" "),_("li",[_("strong",[v._v("子问题之间相互独立, 不包含公共子问题;")])]),v._v(" "),_("li",[_("strong",[v._v("子问题的解可以合并得到原问题的解.")])])]),v._v(" "),_("p",[v._v("根据这些特征, 可以想到, 诸如电商统计全国商品数量时, 按区域或省市进行统计, 然后将统计结果合并得到最终结果等大数据处理场景, 均可以采用分治法.")]),v._v(" "),_("p",[v._v("同时, 根据这些特征可以推导出, "),_("strong",[v._v("采用分治法解决问题的核心步骤是")]),v._v(":")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("分解原问题")]),v._v(". 将原问题分解为若干个规模较小, 相互独立, 且与原问题形式相同的子问题.")]),v._v(" "),_("li",[_("strong",[v._v("求解子问题")]),v._v(". 若子问题规模较小且容易被解决则直接求解, 否则递归地求解各个子问题.")]),v._v(" "),_("li",[_("strong",[v._v("合并解")]),v._v(", 就是将各个子问题的解合并为原问题的解.")])]),v._v(" "),_("p",[v._v("接下来就一起看看分布式系统中分治法的原理和应用.")]),v._v(" "),_("h5",{attrs:{id:"分治法的原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分治法的原理"}},[v._v("#")]),v._v(" 分治法的原理")]),v._v(" "),_("p",[v._v("分布式原本就是为处理大规模应用而生的, 所以基于分布式系统, 如何分而治之地处理海量数据就是分布式领域中的一个核心问题.")]),v._v(" "),_("p",[v._v("Google 提出的 MapReduce 分布式计算模型(Hadoop MapReduce 是 Google 的开源实现), 作为分治法的典型代表, 最开始用于搜索领域, 后来被广泛用于解决各种海量数据的计算问题. 下面将以 MapReduce 为例, 介绍分治法的抽象模型, 工作原理和实践应用.")]),v._v(" "),_("h6",{attrs:{id:"抽象模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#抽象模型"}},[v._v("#")]),v._v(" 抽象模型")]),v._v(" "),_("p",[v._v("如下图所示, "),_("strong",[v._v('MapReduce 分为 Map 和 Reduce 两个核心阶段, 其中 Map 对应"分", 即把复杂的任务分解为若干个"简单的任务"执行; Reduce 对应着"合", 即对 Map 阶段的结果进行汇总')]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/0e8228b075b279c7bb508c48f9dbb640-20230731163147-7rbe6yz.png",alt:""}})]),v._v(" "),_("p",[v._v("在第一阶段, 也就是 Map 阶段, 将大数据计算任务拆分为多个子任务, 拆分后的子任务通常具有如下特征:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("相对于原始任务来说, 划分后的子任务与原任务是同质的")]),v._v(", 比如原任务是统计全国人口数, 拆分为统计省的人口数子任务时, 都是统计人口数; 并且, 子任务的数据规模和计算规模会小很多.")]),v._v(" "),_("li",[_("strong",[v._v("多个子任务之间没有依赖, 可以独立运行, 并行计算")]),v._v(", 比如按照省统计人口数, 统计河北省的人口数和统计湖南省的人口数之间没有依赖关系, 可以独立, 并行的统计.")])]),v._v(" "),_("p",[v._v("第二阶段, 也就是 Reduce 阶段, 第一阶段拆分的子任务计算完成后, 汇总所有子任务的计算结果, 以得到最终结果. 也就是汇总各个省统计的人口数, 得到全国的总人口数.")]),v._v(" "),_("h6",{attrs:{id:"mapreduce工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce工作原理"}},[v._v("#")]),v._v(" MapReduce工作原理")]),v._v(" "),_("p",[v._v("那在 MapReduce 里, 各个组件是如何分工完成一个复杂任务的呢? 为了解答这个问题, 先解一下 MapReduce 的组件结构.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/ef79c0c54e9dcfaddf9efeebf6c473ed-20230731163147-olsio49.png",alt:""}})]),v._v(" "),_("p",[v._v("如上图所示, MapReduce 主要包括以下三种组件:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("Master")]),v._v(", 也就是 MRAppMaster, 该模块像一个大总管一样, 独掌大权, "),_("strong",[v._v("负责分配任务, 协调任务的运行, 并为 Mapper 分配 map() 函数操作, 为 Reducer 分配 reduce() 函数操作")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("Mapper worker, 负责 Map 函数功能, 即负责执行子任务")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("Reducer worker, 负责 Reduce 函数功能, 即负责汇总各个子任务的结果.")])])]),v._v(" "),_("p",[v._v("基于这三种组件, MapReduce 的工作流程如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/21d361d40ec32ce3c9fe0381e561fbf4-20230731163147-ai0v3by.png",alt:""}})]),v._v(" "),_("p",[v._v('程序从 User Program 开始进入 MapReduce 操作流程. 其中图中的 "step1, step2, ..., step6" 表示操作步骤.')]),v._v(" "),_("ul",[_("li",[v._v("step1: User Program 将任务下发到 "),_("strong",[v._v("MRAppMaster")]),v._v(" 中. 然后, MRAppMaster 执行任务拆分步骤, 把 User Program 下发的任务划分成 M 个子任务(M 是用户自定义的数值). 假设, MapReduce 函数将任务划分成了 5 个, 其中 Map 作业有 3 个, Reduce 作业有 2 个; 集群内的 MRAppMaster 以及 Worker 节点都有任务的副本.")]),v._v(" "),_("li",[v._v("step2: "),_("strong",[v._v("MRAppMaster 分别为 Mapper 和 Reducer 分配相应的 Map 和 Reduce 作业")]),v._v(". Map 作业的数量就是划分后的子任务数量, 也就是 3 个; Reduce 作业是 2 个.")]),v._v(" "),_("li",[v._v("step3: 被分配了 Map 作业的 Worker, 开始读取子任务的输入数据, 并从输入数据中抽取出 "),_("code",[v._v("<key, value>")]),v._v("​ 键值对, 每一个键值对都作为参数传递给 map() 函数.")]),v._v(" "),_("li",[v._v("step4: "),_("strong",[v._v("map() 函数的输出结果存储在环形缓冲区 kvBuffer 中, 这些 Map 结果会被定期写入本地磁盘中, 被存储在 R 个不同的磁盘区")]),v._v(". 这里的 R 表示 Reduce 作业的数量, 也是由用户定义的. 在这个案例中, R=2. 此外, 每个 Map 结果的存储位置都会上报给 MRAppMaster.")]),v._v(" "),_("li",[v._v("step5: "),_("strong",[v._v("MRAppMaster 通知 Reducer 它负责的作业在哪一个分区, Reducer 远程读取相应的 Map 结果, 即中间键值对")]),v._v("​. 当 Reducer 把它负责的所有中间键值对都读过来后, 首先根据键值对的 key 值对中间键值对进行排序, 将相同 key 值的键值对聚集在一起, 从而有利于 Reducer 对 Map 结果进行统计.")]),v._v(" "),_("li",[v._v("step6: "),_("strong",[v._v("Reducer 遍历排序后的中间键值对, 将具有相同 key 值的键值对合并")]),v._v(", 并将统计结果作为输出文件存入负责的分区中.")])]),v._v(" "),_("p",[v._v("从上述流程可以看出, "),_("strong",[v._v("整个 MapReduce 的工作流程主要可以概括为 5 个阶段")]),v._v(", 即: "),_("mark",[_("strong",[v._v("Input(输入), Splitting(拆分), Mapping(映射), Reducing(化简)以及 Final Result(输出)")])]),v._v(" .")]),v._v(" "),_("p",[v._v("所有 MapReduce 操作执行完毕后, MRAppMaster 将 R 个分区的输出文件结果返回给 User Program, 用户可以根据实际需要进行操作. 比如通常并不需要合并这 R 个输出文件, 而是将其作为输入交给另一个 MapReduce 程序处理.")]),v._v(" "),_("h6",{attrs:{id:"mapreduce实践应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce实践应用"}},[v._v("#")]),v._v(" MapReduce实践应用")]),v._v(" "),_("p",[v._v("通过上述的流程描述, 大概已经知道 MapReduce 的工作流程了. 接下来分享一个电商统计用户消费记录的例子, 再巩固一下 MapReduce 的功能. 需要注意的是, 为了方便理解, 对下面用的数据做了一定的处理, 并不完全是真实场景中的数据.")]),v._v(" "),_("p",[v._v("每隔一段时间, 电商都会统计该时期平台的订单记录, 从而分析用户的消费倾向. 在不考虑国外消费记录的前提下, 全国范围内的订单记录已经是一个很大规模的工程了. 电商往往会在每个省份, 多个城市分布式地部署多个服务器, 用于管理某一地区的平台数据. "),_("strong",[v._v("因此针对全国范围内的消费统计, 可以拆分成对多个省份的消费统计, 并再一次细化到统计每一个城市的消费记录")]),v._v(".")]),v._v(" "),_("p",[v._v("为方便描述, 假设现在要统计苏锡常地区第二季度手机订单数量 Top3 的品牌. 来看看具体的统计步骤.")]),v._v(" "),_("p",[v._v("任务拆分(Splitting 阶段). 根据地理位置, 分别统计苏州, 无锡, 常州第二季度手机订单 Top3 品牌, 从而将大规模任务划分为 3 个子任务. 通过循环调用 map() 函数, 统计每个品牌手机的订单数量. 其中, key 为手机品牌, value 为手机购买数量(单位: 万台). 如下图 Mapping 阶段所示(为简化描述, 图中直接列出了统计结果).")]),v._v(" "),_("p",[v._v("与前面讲到的计算流程不同的是, Mapping 阶段和 Reducing 阶段中间多了一步 Shuffling 操作. Shuffling 阶段主要是读取 Mapping 阶段的结果, 并将不同的结果划分到不同的区. 在大多数参考文档中, Mapping 和 Reducing 阶段的任务分别定义为映射以及归约. 但在映射之后, 要对映射后的结果进行排序整合, 然后才能执行归约操作, 因此往往将这一排序整合的操作单独放出来, 称之为 Shuffling 阶段.")]),v._v(" "),_("p",[v._v("Reducing 阶段, 归并同一个品牌的购买次数. 得到苏锡常地区第二季度 Top3 品牌手机的购买记录.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a52acf00a2c7e56718152e27655b4fb3-20230731163147-wqyp9bj.png",alt:""}})]),v._v(" "),_("p",[v._v("由上述流程可以看出, "),_("strong",[v._v("Map/Reduce 作业和 map()/reduce() 函数是有区别的")]),v._v(":")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("Map 阶段由一定数量的 Map 作业组成, 这些 Map 作业是并发任务, 可以同时运行, 且操作重复")]),v._v(". Map 阶段的功能主要由 map() 函数实现. 每个 Map 作业处理一个子任务(比如一个城市的手机消费统计), 需要调用多次 map() 函数来处理(因为城市内不同的居民倾向于不同的手机).")]),v._v(" "),_("li",[_("strong",[v._v("Reduce 阶段执行的是汇总任务结果, 遍历 Map 阶段的结果从而返回一个综合结果")]),v._v(". 与 Reduce 阶段相关的是 reduce() 函数, 它的输入是一个键(key)和与之对应的一组数据(values), 其功能是将具有相同 key 值的数据进行合并. Reduce 作业处理一个分区的中间键值对, 期间要对每个不同的 key 值调用一次 reduce() 函数. 在完成 Map 作业后, 每个分区中会存在多个临时文件; 而执行完 Reduce 操作后, 一个分区最终只有一个输出文件.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-fork-join计算模式是什么意思呢"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-fork-join计算模式是什么意思呢"}},[v._v("#")]),v._v(" 知识扩展:Fork-Join计算模式是什么意思呢?")]),v._v(" "),_("p",[v._v("MapReduce 是一种分而治之的计算模式, 在分布式领域中, 除了典型的 Hadoop 的 MapReduce(Google MapReduce 的开源实现), 还有 Fork-Join.")]),v._v(" "),_("p",[v._v("Fork-Join 是 Java 等语言或库提供的"),_("strong",[v._v("原生多线程并行处理框架")]),v._v(", 采用线程级的分而治之计算模式. 它充分利用多核 CPU 的优势, "),_("strong",[v._v('以递归的方式把一个任务拆分成多个 "小任务", 把多个 "小任务" 放到多个处理器上并行执行, 即 Fork 操作. 当多个 "小任务" 执行完成之后, 再将这些执行结果合并起来即可得到原始任务的结果, 即 Join 操作')]),v._v(".")]),v._v(" "),_("p",[v._v("虽然 MapReduce 是进程级的分而治之计算模式, 但与 Fork-Join 的核心思想是一致的. 因此, Fork-Join 又被称为 Java 版的 MapReduce 框架.")]),v._v(" "),_("p",[v._v("但, MapReduce 和 Fork-Join 之间有一个本质的区别:")]),v._v(" "),_("ol",[_("li",[v._v('Fork-Join 不能大规模扩展, 只适用于在单个 Java 虚拟机上运行, 多个小任务虽然运行在不同的处理器上, 但可以相互通信, 甚至一个线程可以 "窃取" 其他线程上的子任务.')]),v._v(" "),_("li",[v._v("MapReduce 可以大规模扩展, 适用于大型计算机集群. 通过 MapReduce 拆分后的任务, 可以跨多个计算机去执行, 且各个小任务之间不会相互通信.")])]),v._v(" "),_("h5",{attrs:{id:"总结-12"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-12"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("所谓分而治之, 就是将一个复杂的, 难以直接解决的大问题, 分割成一些规模较小的, 可以直接求解的子问题, 这些子问题互相独立且与原问题形式相同, 递归地解这些子问题, 然后将子问题的解合并以后就是原问题的解.  分布式计算模型 MapReduce 就运用了分而治之的思想, 通过 Map 操作将大任务分成多个较小的任务去执行, 得到的多个结果再通过 Reduce 操作整合成一个完整的结果. 本节就以 MapReduce 为例, 讲述了分布式领域中分治法的模型, 原理与应用.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/48c90a5fcb7819293ad79ecc688258f2-20230731163147-h496b81.png",alt:""}})]),v._v(" "),_("p",[v._v("分而治之的思想, 是简单且实用的处理复杂问题的方法. 所以无论是计算机领域还是其他研究领域亦或日常生活中, 都可以用分治法去处理很多复杂庞大的问题, 将大问题划分成多个小问题, 化繁为简, 化整为零.")]),v._v(" "),_("h4",{attrs:{id:"_16-分布式计算模式之stream-一门背锅的艺术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_16-分布式计算模式之stream-一门背锅的艺术"}},[v._v("#")]),v._v(" 16-分布式计算模式之Stream:一门背锅的艺术")]),v._v(" "),_("p",[v._v("上一节介绍了分布式计算模式中的 MapReduce 模式. 这种模式的核心思想是, 将大任务拆分成多个小任务, 针对这些小任务分别计算后, 再合并各小任务的结果以得到大任务的计算结果. 这种模式下任务运行完成之后, 整个任务进程就结束了, 属于"),_("strong",[v._v("短任务模式")]),v._v(". 但任务进程的启动和停止是一件很耗时的事儿, "),_("strong",[v._v("因此 MapReduce 对处理实时性的任务就不太合适了")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("实时性任务主要是针对流数据的处理, 对处理时延要求很高, 通常需要有常驻服务进程, 等待数据的随时到来随时处理, 以保证低时延. 处理流数据任务的计算模式, 在分布式领域中叫作 Stream.")])]),v._v(" "),_("p",[v._v("本节将针对流数据的处理展开分享, 学习 Stream 这种计算模式.")]),v._v(" "),_("h5",{attrs:{id:"什么是stream"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是stream"}},[v._v("#")]),v._v(" 什么是Stream?")]),v._v(" "),_("p",[v._v("近年来, 由于网络监控, 传感监测, AR/VR 等实时性应用的兴起, 一类需要处理流数据的业务发展了起来. 比如各种直播平台中, 需要处理直播产生的音视频数据流等. 这种如流水般持续涌现, 且需要实时处理的数据, 称为"),_("strong",[v._v("流数据")]),v._v(".")]),v._v(" "),_("p",[v._v("总结来讲, 流数据的特征主要包括以下 4 点:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("数据如流水般持续, 快速地到达;")])]),v._v(" "),_("li",[_("strong",[v._v("海量数据规模, 数据量可达到 TB 级甚至 PB 级;")])]),v._v(" "),_("li",[_("strong",[v._v("对实时性要求高, 随着时间流逝, 数据的价值会大幅降低;")])]),v._v(" "),_("li",[_("strong",[v._v("数据顺序无法保证, 也就是说系统无法控制将要处理的数据元素的顺序.")])])]),v._v(" "),_("p",[v._v("在分布式领域中, 处理流数据的计算模式, 就是"),_("strong",[v._v("流计算, 也叫作 Stream")]),v._v(". 这个名字是不是非常形象呢?")]),v._v(" "),_("p",[_("strong",[v._v("流计算的职责是实时获取来自不同数据源的海量数据, 进行实时分析处理, 获得有价值的信息.")]),v._v('  它是一个对实时性要求非常高的计算形式, 如果数据处理不及时, 很容易导致过时, 没用的结果, 这时就需要对造成的后果进行 "背锅". 从这个角度来说, Stream 可谓"一门背锅的艺术".')]),v._v(" "),_("p",[v._v("类比于水流的持续不断且变幻莫测, 流数据也是以大量, 快速, 时变的流形式持续在应用中产生, 因此"),_("strong",[v._v("流计算一般用于处理数据密集型应用")]),v._v(". 比如, 百度, 淘宝等大型网站中, 每天都会产生大量的流数据, 这些数据包括用户的搜索内容, 用户的浏览记录等. 实时采集用户数据, 并通过流计算进行实时数据分析, 可以了解每个时刻数据流的变化情况, 甚至可以分析用户的实时浏览轨迹, 从而进行个性化内容实时推荐, 提高用户体验. 此外常用的爱奇艺, 腾讯等音视频平台, 对电影, 电视剧等数据的处理, 也是采用了流计算模式.")]),v._v(" "),_("p",[v._v("那么, 这种实时的流计算到底是如何运行的呢? 接下来就一起看看流计算的工作原理.")]),v._v(" "),_("h5",{attrs:{id:"stream工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#stream工作原理"}},[v._v("#")]),v._v(" Stream工作原理")]),v._v(" "),_("p",[v._v("MapReduce 是一种批量计算的形式. 这种模式下, 会先收集数据并将其缓存起来, 等到缓存写满时才开始处理数据. 因此批量计算的一个缺点就是, "),_("strong",[v._v("从数据采集到得到计算结果之间经历的时间很长")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("而流计算强调的是实时性, 数据一旦产生就会被立即处理, 当一条数据被处理完成后, 会序列化存储到缓存中, 然后立刻通过网络传输到下一个节点, 由下一个节点继续处理, 而不是像 MapReduce 那样, 等到缓存写满才开始处理, 传输. 为了保证数据的实时性, 在流计算中, 不会存储任何数据, 就像水流一样滚滚向前.")])]),v._v(" "),_("p",[v._v("所以说, 流计算属于"),_("strong",[v._v("持续性, 低时延, 事件驱动型")]),v._v("的计算作业.")]),v._v(" "),_("p",[v._v("从这些分析中可以看出, "),_("strong",[v._v("使用流计算进行数据处理, 一般包括 3 个步骤")]),v._v(", 如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/bdfc12214aeb706c47867a209fef7a89-20230731163147-dck0r7v.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("第一步, 提交流式计算作业.")]),v._v("  流式计算作业是一种常驻计算服务, 比如实时交通监测服务, 实时天气预报服务等. 对于流式计算作业, 首先必须预先定义计算逻辑, 并提交到流计算系统中, 使得流计算系统知道自己该如何处理数据. 系统在整个运行期间, 由于收集的是同一类型的数据, 执行的是同一种服务, 因此"),_("strong",[v._v("流式计算作业的处理逻辑不可更改")]),v._v(". 如果用户停止当前作业运行后再次提交作业, 由于流计算不提供数据存储服务, 因此之前已经计算完成的数据无法重新再次计算.")]),v._v(" "),_("p",[_("strong",[v._v("第二步, 加载流式数据进行流计算.")]),v._v("  流式计算作业一旦启动"),_("strong",[v._v("将一直处于等待事件触发的状态, 一旦有小批量数据进入流式数据存储, 系统会立刻执行计算逻辑并迅速得到结果")]),v._v(". 从上图中可以看出, 在流计算系统中, 有多个流处理节点, 流处理节点会对数据进行预定义的处理操作, 并在处理完后按照某种规则转发给后续节点继续处理. 此外, 流计算系统中还存在管理节点, 主要负责管理处理节点以及数据的流动规则. 其中处理节点的个数以及数据转发的规则, 都在第一步作业提交时定义.")]),v._v(" "),_("p",[_("strong",[v._v("第三步, 持续输出计算结果.")]),v._v("  流式计算作业在得到小批量数据的计算结果后, 可以立刻将结果数据写入在线/批量系统, 无需等待整体数据的计算结果, 以进一步做到实时计算结果的实时展现.")]),v._v(" "),_("p",[v._v("小结一下. 流计算不提供流式数据的存储服务, 数据是持续流动的, 在计算完成后就会立刻丢弃. 流计算适用于需要处理持续到达的流数据, 对数据处理有较高实时性要求的场景. 为了及时处理流数据, 流计算框架必须是低延迟, 可扩展, 高可靠的.")]),v._v(" "),_("p",[v._v("流计算的应用场景有很多, 比如它是网络监控, 传感监测, AR/VR, 音视频流等实时应用的发展的基础. 所以, 目前流计算相关的框架和平台也有很多了, 主流的划分方式是将其分为如下 3 类:")]),v._v(" "),_("ol",[_("li",[v._v("商业级的流计算平台, 比如 IBM 的 InfoSphere Streams 和 TIBCO 的 StreamBase. InfoSphere Streams 支持同时分析多种数据类型并实时执行复杂计算. StreamBase 是一个用于实时分析的软件, 可以快速构建分析系统, 即时做出决策. StreamBase 可以为投资银行, 对冲基金, 政府机构等提供实时数据分析服务.")]),v._v(" "),_("li",[v._v("开源流计算框架, 典型代表是 Apache "),_("strong",[v._v("Storm")]),v._v("(由 Twitter 开源)和 S4(由 Yahoo 开源). Storm 是一个分布式的, 容错的实时计算系统, 可以持续进行实时数据流处理, 也可以用于分布式 RPC. S4 是一个通用的, 分区容错的, 可扩展的, 可插拔的分布式流式系统. 这些开源的分布式流计算系统由于具备开源代码, 因此比较适合开发人员将其搭建在自身业务系统中.")]),v._v(" "),_("li",[v._v("各大公司根据自身业务特点而开发的流计算框架, 比如 Facebook 的 Puma, 百度的 Dstream(旨在处理有向无环的数据流), 淘宝的银河流数据处理平台(一个通用的, 低延迟, 高吞吐, 可复用的流数据实时计算系统).")])]),v._v(" "),_("p",[v._v("除了这些框架外, 还会经常听到 Spark, Flink 等. "),_("strong",[v._v("Spark 和 Flink 与 Storm 框架的不同之处在于, Spark 和 Flink 除了支持流计算, 还支持批量计算, 因此这里没有直接将它们列入上述的流计算框架中")]),v._v(". 如果业务中需要用到或者需要参考某种计算框架或者平台的话, 可以再参考其官方文档或者相关的技术文章.")]),v._v(" "),_("p",[v._v("接下来就以 Storm 这个开源的流计算框架为例, 通过介绍 Storm 的工作原理, 以加深对流计算模式的进一步理解.")]),v._v(" "),_("h5",{attrs:{id:"storm的工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#storm的工作原理"}},[v._v("#")]),v._v(" Storm的工作原理")]),v._v(" "),_("p",[v._v('说到 Storm 的工作原理, 先来对比下 Storm 与 MapReduce 的区别. Hadoop 上运行的是 "MapReduce 作业", 而 Storm 上运行的是 "'),_("mark",[_("strong",[v._v("计算拓扑(Topologies)")])]),v._v(' ". "作业" 和 "拓扑" 的一个关键区别是: '),_("mark",[_("strong",[v._v("MapReduce 的一个作业在得到结果之后总会结束; 而拓扑描述的是计算逻辑, 该计算逻辑会永远在集群中运行(除非你杀死该进程)")])]),v._v(" .")]),v._v(" "),_("p",[v._v("如下图所示, Storm 集群上有两种节点, 即"),_("strong",[v._v("主节点(Master Node)和工作节点(Worker Nodes)")]),v._v(" .")]),v._v(" "),_("ol",[_("li",[v._v('主节点上运行着一个名为 "Nimbus" 的守护进程. Nimbus 负责为集群分发代码, 为工作节点分配任务以及进行故障监控. 一个 Storm 集群在工作过程中, 只有一个 Nimbus 进程工作.')]),v._v(" "),_("li",[v._v('每个工作节点上都运行着一个名为 "Supervisor" 的守护进程. Supervisor 负责监听分配给它所在的机器上的工作, 负责接收 Nimbus 分配的任务, 并根据需要启动和停止工作进程, 其中每个工作进程都执行一个子任务. 因此, '),_("strong",[v._v("一个正在运行的拓扑任务, 是由分布在许多计算机上的许多工作进程组成")]),v._v(".")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/795cb0593fc0ad54087df3c1b3ca205e-20230731163147-he5b0og.png",alt:""}})]),v._v(" "),_("p",[v._v("前面介绍了 "),_("strong",[v._v("Nimbus 是负责分发任务或代码的, Supervisor 是负责接收任务, 并启动和停止工作进程以执行任务的")]),v._v(". 那么 Nimbus 和 Supervisors 之间, 具体是怎么协同的呢? 下面一起看一下.")]),v._v(" "),_("p",[v._v("如果所有数据和信息均存储在 Master Node 上, Master Node 故障后, 会导致整个集群信息丢失, 因此引入了 ZooKeeper 集群来加强可靠性. "),_("strong",[v._v("为此 Master Node 与 Worker Node 之间的交互通过 ZooKeeper 完成, 由于 Nimbus 和 Supervisors 是 Master Node 和 Worker Node 之间负责交互的进程, 因此 Nimbus 和 Supervisors 之间的所有协调都是通过 ZooKeeper 集群完成的, 比如 Nimbus 会将任务的分配情况或信息发送给 ZooKeeper 集群, 然后 Supervisors 向 ZooKeeper 集群获取任务, 并启动工作进程以执行任务")]),v._v(".")]),v._v(" "),_("p",[v._v("当 Supervisor 接收到分配的任务后, 会启动工作节点的工作进程 (Worker) 去执行任务. 一个计算任务可以分成任务数据的读取以及任务执行两部分. "),_("strong",[v._v("Worker 提供了两个组件 Spout 和 Bolt, 分别进行数据读取和任务执行")]),v._v(".")]),v._v(" "),_("p",[v._v("在详细介绍 Worker 组件之前, 首先介绍一下 Storm 的核心抽象: "),_("mark",[_("strong",[v._v("数据流")])]),v._v(". 数据流是一个无界序列, 是在分布式环境中并行创建, 处理的一组元组(tuple). 数据流可以由一种能够表述数据流中元组的域(fields)的模式来定义.")]),v._v(" "),_("p",[_("strong",[v._v("Storm 为进行数据流转换提供了基本组件 Spout 和 Bolt")]),v._v(". Spout 和 Bolt 有用户自定义的接口, 用于运行特定应用程序的逻辑. 如下图所示, Storm 上运行的计算拓扑其实是由一系列 Spout 和 Bolt 组成的有向无环图, 这个有向无环图代表了计算逻辑.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/0256db83fc0fd3e59c2bab27940265cb-20230731163147-fvjya7s.png",alt:""}})]),v._v(" "),_("p",[v._v("备注: 图中箭头, 表示数据元组的传递方向.")]),v._v(" "),_("p",[v._v("接下来看看 "),_("strong",[v._v("Spout 和 Bolt 的含义")]),v._v(".")]),v._v(" "),_("ol",[_("li",[v._v("Spout 用于接收源数据. 通常情况下, Spout 会从一个外部的数据源读取数据元组, 然后将它们发送到拓扑中. 例如, Spout 从 Twitter API 读取推文并将其发布到拓扑中.")]),v._v(" "),_("li",[v._v("Bolt 负责处理输入的数据流, 比如数据过滤(filtering), 函数处理(functions), 聚合(aggregations), 联结(joins), 数据库交互等. 数据处理后可能输出新的流作为下一个 Bolt 的输入. 每个 Bolt 往往只具备单一的计算逻辑. 当执行简单的数据流转换时, 比如仅进行数据过滤, 则通常一个 Bolt 可以实现; 而复杂的数据流转换通常需要使用多个 Bolt 并通过多个步骤完成, 比如在神经网络中, 对原始数据进行特征转换, 需要经过数据过滤, 清洗, 聚类, 正则化等操作.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-流计算和批量计算的区别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-流计算和批量计算的区别是什么"}},[v._v("#")]),v._v(" 知识扩展:流计算和批量计算的区别是什么?")]),v._v(" "),_("p",[v._v("MapReduce 可以说是一种批量计算, 与用于实时数据处理的流计算, 是什么关系呢?")]),v._v(" "),_("p",[v._v("虽然流计算和批量计算属于两种不同的计算模式, 但并不是非此即彼的关系, 只是适用于不同的计算场景.")]),v._v(" "),_("p",[v._v("在流计算中, 数据具有时效性, 因此在 5G 以及人工智能应用的驱动下, 专注于实时处理的流计算越来越得到广泛的关注. 流计算的低延时, 易扩展等性能非常适用于对时延要求高的终端应用(比如直播中音视频的处理等), 从而极大提高用户的服务体验. 而批量计算适用于对时延要求低的任务.")]),v._v(" "),_("p",[v._v("在实际运用中, 可以根据计算要求, 选择不同的计算模式. 下面将这两种计算模式的特点, 总结为了一张表格.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/9a21bcc86e918b73811c81043ab5730c-20230731163147-z1wp343.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"总结-13"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-13"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v('本节介绍了分布式计算模式中的流计算. 流数据的价值会随时间的流逝而降低, "时间就是金钱" 在流计算中体现得淋漓尽致. 这就要求流计算框架必须是低延迟, 可扩展, 高可靠的.')]),v._v(" "),_("p",[v._v("在介绍流计算的工作原理时, 首先介绍了它的 3 个步骤, 即"),_("strong",[v._v("提交流式计算作业, 加载流式数据进行流计算和持续输出计算结果")]),v._v(". 然后以流计算开源框架中的 Storm 为例, 讲述了 Storm 的核心组件以及通过 Spout 和 Bolt 构建有向无环图代表流计算逻辑, 以实现流计算, 以加深对流计算原理的理解.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5d49edb0551946af7ed4a4e6cc20a615-20230731163147-89xw0pn.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_17-分布式计算模式之actor-一门甩锅的艺术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_17-分布式计算模式之actor-一门甩锅的艺术"}},[v._v("#")]),v._v(" 17-分布式计算模式之Actor:一门甩锅的艺术")]),v._v(" "),_("p",[v._v("前两节学习了 MapReduce 和 Stream 计算模式, 相信你对批处理和流计算也有了一定的了解. 虽然这两种计算模式对数据的处理方式不同, 但都是"),_("strong",[v._v("以特定数据类型(分别对应静态数据和动态数据)作为计算维度")]),v._v(".")]),v._v(" "),_("p",[v._v("在接下来两节将"),_("strong",[v._v("从计算过程或处理过程的维度")]),v._v(", 介绍另外两种分布式计算模式, 即 "),_("strong",[v._v("Actor 和流水线")]),v._v(". 分布式计算的本质就是在分布式环境下, 多个进程协同完成一件复杂的事情, 但每个进程各司其职, 完成自己的工作后, 再交给其他进程去完成其他工作. 当然, 对于没有依赖的工作, 进程间是可以并行执行的.")]),v._v(" "),_("p",[v._v('分布式进程那么多, 如果需要开发者自己去维护每个进程之间的数据, 状态等信息, 这个开发量可不是一般得大, 而且特别容易出错. 那有没有什么办法可以让开发者只关注自己的逻辑呢? 答案是肯定的, Actor 计算模式就能满足你的需求. 也就是说, 你可以把数据, 状态等都扔给 Actor. 这是不是"一门甩锅的艺术"呢?')]),v._v(" "),_("h5",{attrs:{id:"什么是actor"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是actor"}},[v._v("#")]),v._v(" 什么是Actor?")]),v._v(" "),_("p",[v._v("前面提到 Akka 框架基于 Actor 模型, 提供了一个用于构建可扩展的, 弹性的, 快速响应的应用程序的平台.")]),v._v(" "),_("p",[v._v('其中, Actor 类似于一个 "黑盒" 对象, 封装了自己的状态和行为, 使得其他 Actor 无法直接观察到它的状态, 调用它的行为. 多个 Actor 之间通过消息进行通信, 这种消息类似于电子邮箱中的邮件. Actor 接收到消息之后, 才会根据消息去执行计算操作.')]),v._v(" "),_("p",[v._v("那么, "),_("strong",[v._v("Actor 模型又是什么呢?")]),v._v("  Actor 模型, 代表一种"),_("strong",[v._v("分布式并行计算模型")]),v._v(". 这种模型有自己的一套规则, 规定了 Actor 的内部计算逻辑, 以及多个 Actor 之间的通信规则. 在 Actor 模型里, 每个 Actor 相当于系统中的一个组件, 都是基本的计算单元.")]),v._v(" "),_("p",[_("strong",[v._v("Actor 模型的计算方式与传统面向对象编程模型(Object-Oriented Programming, OOP)类似")]),v._v(", 一个对象接收到一个方法的调用请求(类似于一个消息), 从而去执行该方法.")]),v._v(" "),_("p",[v._v("但 OOP 因为数据封装在一个对象中, 不能被外部访问, 当多个外部对象通过方法调用方式, 即同步方式进行访问时, 会存在死锁, 竞争等问题, 无法满足分布式系统的高并发性需求. "),_("strong",[v._v("而 Actor 模型通过消息通信, 采用的是异步方式, 克服了 OOP 的局限性, 适用于高并发的分布式系统")]),v._v(".")]),v._v(" "),_("p",[v._v("举一个最简单的例子, 假如现在定义了三个对象 A, B 和 C, 对象 C 中有一个函数 Function, 现在对象 A 和对象 B 同时调用对象 C 中的 Function, 此时对象 C 中的 Function 就成为了共享资源, 有可能会存在竞争, 死锁等问题.")]),v._v(" "),_("p",[v._v("而对于 Actor 模式, 对象 A, B 和 C 对应着 Actor A, Actor B 和 Actor C, 当 Actor A 和 Actor B 需要执行 Actor C 中的 Function 逻辑时, Actor A 和 Actor B 会将消息发送给 Actor C, Actor C 的消息队列存储着 Actor A 和 Actor B 的消息, 然后根据消息的先后顺序, 执行 Function 即可.")]),v._v(" "),_("p",[v._v("也就是说, Actor 模式采用了异步模式, 并且每个 Actor 封装了自己的数据, 方法等, 解决了 OOP 存在的死锁, 竞争等问题.")]),v._v(" "),_("h5",{attrs:{id:"actor计算模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#actor计算模式"}},[v._v("#")]),v._v(" Actor计算模式")]),v._v(" "),_("p",[v._v("接下来, 再一起看看 Actor 计算模式. 如下图所示, 描述了具有 3 个 Actor 的 Actor 模型.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/56eec8968df729091c3c8adbf3cb5163-20230731163147-36w216u.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, "),_("mark",[_("strong",[v._v("Actor 模型的三要素是状态, 行为和消息")])]),v._v(", 有一个很流行的等式: Actor 模型 = (状态 + 行为) + 消息.")]),v._v(" "),_("p",[v._v("接下来一起看看这三要素的具体含义.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("状态(State)")]),v._v(" . Actor 的状态指的是, Actor 组件本身的信息, 相当于 OOP 对象中的属性. Actor 的状态会受 Actor 自身行为的影响, 且只能被自己修改.")]),v._v(" "),_("li",[_("strong",[v._v("行为(Behavior)")]),v._v(" . Actor 的行为指的是, Actor 的计算处理操作, 相当于 OOP 对象中的成员函数. Actor 之间不能直接调用其他 Actor 的计算逻辑. Actor 只有收到消息才会触发自身的计算行为.")]),v._v(" "),_("li",[_("strong",[v._v("消息(Mail)")]),v._v(" . Actor 的消息以邮件形式在多个 Actor 之间通信传递, 每个 Actor 会有一个自己的邮箱(MailBox), 用于接收来自其他 Actor 的消息, 因此 Actor 模型中的消息也称为邮件. 一般情况下, 对于邮箱里面的消息, Actor 是按照消息达到的先后顺序(FIFO)进行读取和处理的.")])]),v._v(" "),_("p",[v._v("了解了 Actor 的三要素后, 再一起看下 Actor 的工作原理.")]),v._v(" "),_("h6",{attrs:{id:"actor工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#actor工作原理"}},[v._v("#")]),v._v(" Actor工作原理")]),v._v(" "),_("p",[v._v("为了方便理解 Actor 的工作原理, 下面会通过讲述 3 个 Actor 之间"),_("strong",[v._v("基于消息和消息队列的工作流程")]),v._v("进行说明. 这 3 个 Actor 的工作流程, 如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a3b6d6884e63ff977ea05bc001c26b39-20230731163147-gupd1eu.png",alt:""}})]),v._v(" "),_("p",[v._v("Actor1 和 Actor3 先后向 Actor2 发送消息, 消息被依次放入 Actor2 的 MailBox 队列的队尾;")]),v._v(" "),_("p",[v._v("Actor2 从 MailBox 队列的队首依次取出消息执行相应的操作, 由于 Actor1 先把消息发送给 Actor2, 因此 Actor2 先处理 Actor1 的消息;")]),v._v(" "),_("p",[v._v("Actor2 处理完 Actor1 的消息后, 更新内部状态, 并且向其他 Actor 发送消息, 然后处理 Actor3 发送的消息.")]),v._v(" "),_("p",[v._v("了解了 Actor 之间的消息交互和处理流程, 再以一个具体案例详细解读一下 Actor 之间的消息传递过程.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a58fa8723244ab74e4bd0313f5979893-20230731163147-3m5i7ua.png",alt:""}})]),v._v(" "),_("p",[v._v("在系统中, 不同的组件/模块可以视为不同的 Actor. 现在有一个执行神经网络的应用, 其中有两个组件 A 和 B, 分别表示数据处理模块和模型训练模块. 假设可以将组件 A 和 B 看作两个 Actor, 训练过程中的数据可以通过消息进行传递. 如上图所示, 完整的消息传输过程为:")]),v._v(" "),_("ul",[_("li",[v._v("组件 A 创建一个 Actor System, 用来创建并管理多个 Actor.")]),v._v(" "),_("li",[v._v("组件 A 产生 QuoteRequest 消息(即 mail 消息, 比如数据处理后的数据), 并将其发送给 ActorRef. ActorRef 是 Actor System 创建的组件 B 对应 Actor 的一个代理.")]),v._v(" "),_("li",[v._v("ActorRef 将消息(经过数据处理后的数据)传输给 Message Dispatcher 模块. Message Dispatcher 类似于快递的中转站, 负责接收和转发消息.")]),v._v(" "),_("li",[v._v("Message Dispatcher 将消息(数据处理后的数据)加入组件 B 的 MailBox 队列的队尾.")]),v._v(" "),_("li",[v._v("Message Dispatcher 将 MailBox 加入线程. 需要注意的是, 只有当 MailBox 是线程时, 才能处理 MailBox 中的消息.")]),v._v(" "),_("li",[v._v("组件 B 的 MailBox 将队首消息(数据)取出并删除, 队首消息交给组件 B 处理, 进行模型训练.")])]),v._v(" "),_("h6",{attrs:{id:"actor关键特征"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#actor关键特征"}},[v._v("#")]),v._v(" Actor关键特征")]),v._v(" "),_("p",[v._v("通过上面的描述, 可以看出 Actor 的通信机制与日常的邮件通信非常类似. 因此可以进一步总结出 Actor 模型的一些特点:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("实现了更高级的抽象.")]),v._v("  前面提到过, Actor 与 OOP 对象类似, 封装了状态和行为. 但 Actor 之间是异步通信的, 多个 Actor 可以独立运行且不会被干扰, 解决了 OOP 存在的竞争问题.")]),v._v(" "),_("li",[v._v("**非阻塞性. **在 Actor 模型中, Actor 之间是异步通信的, 所以当一个 Actor 发送信息给另外一个 Actor 之后, 无需等待响应, 发送完信息之后可以在本地继续运行其他任务. 也就是说, Actor 模型通过引入消息传递机制, 从而避免了阻塞.")]),v._v(" "),_("li",[_("strong",[v._v("无需使用锁")]),v._v(". Actor 从 MailBox 中一次只能读取一个消息, 也就是说, Actor 内部只能同时处理一个消息, 是一个天然的互斥锁, 所以无需额外对代码加锁.")]),v._v(" "),_("li",[v._v("**并发度高. **每个 Actor 只需处理本地 MailBox 的消息, 因此多个 Actor 可以并行地工作, 从而提高整个分布式系统的并行处理能力.")]),v._v(" "),_("li",[v._v("**易扩展. **每个 Actor 都可以创建多个 Actor, 从而减轻单个 Actor 的工作负载. 当本地 Actor 处理不过来的时候, 可以在远程节点上启动 Actor 然后转发消息过去.")])]),v._v(" "),_("p",[v._v("虽然 Actor 模型有上述的诸多优点, 但它并不适用于分布式领域中所有的应用平台或计算框架. 因为 Actor 模型还存在如下一些不足之处:")]),v._v(" "),_("ol",[_("li",[v._v("Actor 提供了模块和封装, 但缺少继承和分层, 这使得即使多个 Actor 之间有公共逻辑或代码部分, 都必须在每个 Actor 中重写这部分代码, 也就是说"),_("strong",[v._v("重用性小")]),v._v(", 业务逻辑的改变会导致整体代码的重写.")]),v._v(" "),_("li",[_("strong",[v._v("Actor 可以动态创建多个 Actor, 使得整个 Actor 模型的行为不断变化, 因此在工程中不易实现 Actor 模型")]),v._v(". 此外, 增加 Actor 的同时, 也会增加系统开销.")]),v._v(" "),_("li",[_("strong",[v._v("Actor 模型不适用于对消息处理顺序有严格要求的系统")]),v._v(". 因为在 Actor 模型中, 消息均为异步消息, 无法确定每个消息的执行顺序. 虽然可以通过阻塞 Actor 去解决顺序问题, 但显然会严重影响 Actor 模型的任务处理效率.")])]),v._v(" "),_("p",[v._v("尽管 Actor 模型在需要同步处理的应用等场景具有局限性, 但它在异步场景中应用还是比较广泛的. 接下来就一起看看 Actor 目前都应用在哪些地方.")]),v._v(" "),_("h5",{attrs:{id:"actor模型的应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#actor模型的应用"}},[v._v("#")]),v._v(" Actor模型的应用")]),v._v(" "),_("p",[v._v("Actor 模型在 1973 年被提出, 已广泛应用在多种框架和语言中. 可以说, 很多框架或语言支持 Actor 编程模型, "),_("strong",[v._v("是为了给开发者提供一个通用的编程框架, 让用户可以聚焦到自己的业务逻辑上, 而不用像面向对象等编程模型那样需要关心死锁, 竞争等问题")]),v._v(".")]),v._v(" "),_("p",[v._v("那么, 到底有哪些框架或语言支持 Actor 编程模型呢? 将下来列举几个典型的框架或语言.")]),v._v(" "),_("ol",[_("li",[v._v("Erlang/OTP. Erlang 是一种通用的, 面向并发的编程语言, 使用 Erlang 编写分布式应用比较简单, 而 OTP 就是 Erlang 技术栈中的标准库. Actor 模型在 Erlang 语言中得到广泛支持和应用, 其他语言的 Actor 逻辑实现在一定程度上都是参照了 Erlang 的模式. 实现了 Actor 模型逻辑的 Erlang/OTP, 可以用于构建一个开发和运行时环境, 从而实现分布式, 实时的, 高可用性的系统.")]),v._v(" "),_("li",[_("strong",[v._v("Akka")]),v._v(". Akka 是一个为 Java 和 Scala 构建高度并发, 分布式和弹性的消息驱动应用程序的工具包. Akka 框架基于 Actor 模型, 提供了一个用于构建可扩展的, 弹性的, 快速响应的应用程序的平台. 通过使用 Actors 和 Streams 技术,  Akka 为用户提供了多个服务器, 使用户更有效地使用服务器资源并构建可扩展的系统.")]),v._v(" "),_("li",[_("strong",[v._v("Quasar")]),v._v(" (Java). Quasar 是一个开源的 JVM 库, 极大地简化了高度并发软件的创建. Quasar 在线程实现时, 参考了 Actor 模型, 采用异步编程逻辑, 从而为 JVM 提供了高性能, 轻量级的线程, 可以用在 Java 和 Kotlin 编程语言中.")])]),v._v(" "),_("h5",{attrs:{id:"总结-14"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-14"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节介绍了分布式计算中, 一门甩锅的计算模型, 即 Actor 模型. 首先介绍了什么是 Actor 模型以及 Actor 模型的三要素, 包括状态, 行为和消息.")]),v._v(" "),_("p",[v._v("其次介绍了 Actor 的工作原理, 并通过实例介绍了 Actor 之间通过消息及消息队列进行异步通信的流程, 以便于进一步理解 Actor 的工作原理.")]),v._v(" "),_("p",[v._v("最后介绍了几个当前支持 Actor 编程模型的框架和语言, 以便于你在需要采用 Actor 模型编程时做一个参考.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/992bbc9f6d701ba08b3e84bb79119eaf-20230731163147-15t4m4x.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_18-分布式计算模式之流水线-你方唱罢我登场"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_18-分布式计算模式之流水线-你方唱罢我登场"}},[v._v("#")]),v._v(" 18-分布式计算模式之流水线:你方唱罢我登场")]),v._v(" "),_("p",[v._v("在现实生活中, 经常会出现这样的情况, "),_("strong",[v._v("前一个任务的结果是另外一个任务的输入")]),v._v(". 比如工厂生产一瓶饮料, 首先需要往瓶子里装上饮料, 待饮料装满后, 再封口. 如果装饮料和封口分别为子任务, 那么前一个任务(装饮料)结束后才可以开始第二个任务(封口). 类似这样的作业, 就是常说的"),_("strong",[v._v("流水线作业")]),v._v(".")]),v._v(" "),_("p",[v._v("在分布式领域中解决类似具有依赖关系的流水线作业的计算模式, 叫作"),_("strong",[v._v("流水线计算模式")]),v._v(". 其实, 流水线计算模式是数据并行计算的一种形式, 就是将一个任务拆分为多个步骤(子任务), 然后多个这样的任务通过对步骤(子任务)的重叠执行, 以实现数据并行处理的场景.")]),v._v(" "),_("p",[v._v('这种流水线模式在计算机领域中最先用于 CPU 指令设计, 后来推广到机器学习领域进行数据处理, 模型训练等. 在流水线计算模式中, 由于前一个子任务执行后, 会扔给下一个子任务, 由下一个子任务去展现自己的能力, 因此可以形象地比喻为 "你方唱罢我登场".')]),v._v(" "),_("h5",{attrs:{id:"什么是流水线模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是流水线模式"}},[v._v("#")]),v._v(" 什么是流水线模式?")]),v._v(" "),_("p",[v._v("其实, "),_("strong",[v._v("分布式领域的流水线计算模式, 就是参考了工业生产中的流水作业模式, 将一个任务分为多个步骤执行, 使得不同任务可以并行执行")]),v._v(". 此外, 你肯定还会想到计算机技术中的流水线计算.")]),v._v(" "),_("p",[v._v("计算机中的**流水线(Pipeline)**技术是一种将每条指令拆分为多个步骤, 多条指令的不同步骤重叠操作, 从而实现几条指令并行处理的技术. 现代 CPU 指令采用了流水线设计, 将一条 CPU 指令分为取指(IF), 译码(ID), 执行(EX), 访存(MEM), 回写(WB)五级流水线来执行.")]),v._v(" "),_("p",[v._v("如下图所示, 在第一条指令执行译码操作时, 第二条指令就可以执行取指操作了, 从而实现了多条指令的并行操作.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/59d3f60fff0e850d5c6e152e9a373cd6-20230731163147-lxdyra8.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("在分布式领域中, 流水线计算模式也类似, 它是将一个大任务拆分为多个步骤执行, 不同的步骤可以采用不同的进程执行")]),v._v(". 这使得不同任务可以并行执行, 从而提高了系统效率.")]),v._v(" "),_("p",[v._v("以机器学习中的数据预处理为例, 假设现在有 5 个样本数据, 每个样本数据进行数据预处理的流程, 包括数据去重, 数据缺失值处理, 数据归一化 3 个步骤, 且需要按照顺序执行. 也就是说, 数据预处理这个任务可拆分为数据去重 —> 数据缺失值处理 —> 数据归一化 3 个子任务.")]),v._v(" "),_("p",[v._v("如果现在有 3 个节点, 节点 1 执行数据去重, 节点 2 执行数据缺失值处理, 节点 3 执行数据归一化. 那么, 节点 1 处理完样本 1 的数据, 将处理后的数据发送节点 2 后, 则节点 1 可以继续处理样本 2 的数据, 同时节点 2 处理样本 1 的数据, 以此类推, 就实现了多任务的并行执行.")]),v._v(" "),_("p",[v._v("接下来再具体看看分布式领域中的流水线计算模式.")]),v._v(" "),_("h5",{attrs:{id:"流水线计算模式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#流水线计算模式"}},[v._v("#")]),v._v(" 流水线计算模式")]),v._v(" "),_("p",[v._v("流水线计算模式的应用非常广泛, 在 AI 技术中也非常常见. 因此接下来会以机器学习为例, 介绍流水线计算模式. 当然, 流水线计算模式的原理是通用的, 也可以应用到其他领域, 比如通信领域中使用 HTTP 流水线传输, 计算机图形学中的图流水线等.")]),v._v(" "),_("p",[v._v("随着神经网络, 深度学习在全世界掀起了 All in AI 的热潮, 用于加速的 GPU 和 TPU 也被越来越多的人使用. 虽然诸如 GPU, TPU 之类的加速器可以从根本上减少执行单个训练步骤所需的时间, 但"),_("strong",[v._v("为了达到最佳性能, 仍然需要高效的输入流水线机制.")])]),v._v(" "),_("p",[v._v("比如, 在流水线模式中数据预处理与 GPU/TPU 进行模型训练可以重叠进行; 再比如, 第 N 个样本进行模型训练时, 第 N+1 个样本可以进行数据预处理, 也就是说在第 N+1 个样本进行预处理前, 已经将第 N 个样本处理后的数据提供给了模型训练, 进一步减少了整体的数据处理和模型训练时间.")]),v._v(" "),_("p",[v._v("Tensorflow 是 Google 开源的一个分布式机器学习框架, 已被各大公司采用, 比如网易, eBay, Intel 等公司. 接下来就以 TensorFlow 的输入流水线模式为例, 介绍流水线技术模式的原理, 并了解如何构建机器学习的流水线.")]),v._v(" "),_("h6",{attrs:{id:"流水线计算模式的原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#流水线计算模式的原理"}},[v._v("#")]),v._v(" 流水线计算模式的原理")]),v._v(" "),_("p",[v._v("TensorFlow 运用了流水线模式对输入数据进行预处理, 因此称为输入流水线(TensorFlow Training Input Pipelines). 其数据输入流水线主要包含 3 个步骤:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("提取(Extract)")]),v._v(" . 通过多种途径读取数据, 比如内存, 本地的 HDD 或 SSD, 远程的 HDFS, GCS 等. 数据的种类也有很多, 比如图像数据, 文本数据, 视频数据等.")]),v._v(" "),_("li",[_("strong",[v._v("转换(Transform)")]),v._v(" . 使用 CPU 处理器对输入的数据进行解析以及预处理操作, 包括混合重排(shuffling), 批处理(batching), 以及一些特定的转换. 比如图像解压缩和扩充, 文本矢量化, 视频时序采样等.")]),v._v(" "),_("li",[_("strong",[v._v("加载(Load")]),v._v("). 将转换后的数据加载到执行机器学习模型的加速器设备上, 比如 GPU 或 TPU.")])]),v._v(" "),_("p",[v._v("由于输入流水线包含了提取, 转换, 加载 3 个步骤, 因此 "),_("strong",[v._v("TensorFlow 的数据输入流水线也称为 ETL 流水线")]),v._v(". TensorFlow 提供了一个官方 API 也就是 tf.data, 利用简单, 可重用的数据片段构建复杂的输入流水线.")]),v._v(" "),_("p",[v._v("没错, 在加速模型训练方面, 输入流水线是非常重要的一个模块. 由上述流程可知, 要执行训练步骤, 首先需要提取并使用 CPU 转换数据, 然后将其提供给在加速器上运行的模型.")]),v._v(" "),_("p",[v._v("如果不引入流水线模型的话, 当 CPU 正在预处理数据时, 加速器处于空闲状态. 同样, 当 GPU/TPU 正在训练模型时, CPU 处于空闲状态. 因此, 训练的用时是 CPU 预处理时间和加速器训练时间的总和.")]),v._v(" "),_("p",[v._v("为了帮助理解, "),_("strong",[v._v("一起看下")]),v._v("​******TensorFlow 官网**"),_("strong",[_("strong",[v._v("​")]),v._v("给出的一个示例")]),v._v(". 这个例子展示了一个不使用流水线技术和使用流水线技术时, CPU, GPU/TPU 的训练过程对比. 先看看不使用流水线技术的训练过程. 如下图所示, Prepare 1 表示 CPU 正在对第 1 个样本数据进行预处理操作, Train 1 表示 GPU/TPU 正在训练第 1 个样本数据.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e92692e9a4d8068bfa19d6565a7b5f7a-20230731163147-1v2iw8d.png",alt:""}})]),v._v(" "),_("p",[v._v("备注: 图片来源为 www.tensorflow.org/guide.")]),v._v(" "),_("p",[v._v('图中的 "idle" 指的是空闲时间. 可以看出, 如果不使用流水线, CPU 和 GPU/TPU 运作的时间没有重叠, 因此在大部分时间都可能处于空闲状态.')]),v._v(" "),_("p",[v._v("接下来, 再看看使用流水线技术的训练过程. 流水线模型可以将训练步骤的数据预处理和数据训练过程重叠到一起. 比如, 当 GPU/TPU 正在训练第 N 个样本数据时, CPU 可以预处理第 N+1 个样本数据. 这样做不仅可以最大限度地缩短训练的单步用时, 还可以缩短提取和转换数据所需的时间, 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/134d9296ac44af737e30efd77639a8d5-20230731163147-60w0qeh.png",alt:""}})]),v._v(" "),_("p",[v._v("图片来源: www.tensorflow.org/guide")]),v._v(" "),_("p",[v._v("很明显, 采用流水线的设计可以充分利用 CPU 和 GPU/TPU, 从而避免资源闲置, 加速训练过程.")]),v._v(" "),_("p",[_("strong",[v._v("小结一下.")]),v._v("  TensorFlow 的输入流水线模式将对数据的操作拆分为提取, 转换, 加载 3 个不重叠的部分. 当 CPU 对第 N 个样本的数据完成预处理之后, 会将预处理后的数据发送给 GPU/TPU, 然后 CPU 继续对第 N+1 个样本的数据进行预处理, 同时 GPU/TPU 对第 N 个样本数据进行模型训练. 也就是说, 这种计算模式实现了多样本数据处理和模型训练的并行执行.")]),v._v(" "),_("p",[v._v("可以看出, 在模型训练中引入流水线模式, 可以提高 CPU, GPU/TPU 的利用率, 还可以加速训练过程.")]),v._v(" "),_("h6",{attrs:{id:"实践-构建机器学习流水线"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#实践-构建机器学习流水线"}},[v._v("#")]),v._v(" 实践:构建机器学习流水线")]),v._v(" "),_("p",[v._v("前面提到在 TensorFlow 中, 流水线模式主要运用在数据读取阶段. 那么, 对于一个复杂的机器学习任务, 是否也可以构建一套流水线作业呢?")]),v._v(" "),_("p",[v._v("答案是肯定的. 接下来就一起看看, 如何构建机器学习流水线.")]),v._v(" "),_("p",[v._v("一个典型的机器学习训练模型按照流水线计算模式拆分, 可以包括如下所示的 5 个步骤:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("数据输入")]),v._v(", 指的是从不同的数据源中导入数据.")]),v._v(" "),_("li",[_("strong",[v._v("数据转换")]),v._v(", 主要是要把输入的无结构数据转换成合适的格式, 以便特征提取.")]),v._v(" "),_("li",[_("strong",[v._v("特征提取")]),v._v(", 指的是从数据集中提取特征数据.")]),v._v(" "),_("li",[_("strong",[v._v("模型训练")]),v._v(", 包括提供一个算法, 并提供一些训练数据让模型可以学习. 学习算法会从训练数据中发现模型, 并生成输出模型.")]),v._v(" "),_("li",[v._v("'"),_("strong",[v._v("模型验证")]),v._v(", 指的是通过训练得到的结果, 对模型进行错误率验证. 比如, 图像分类中分类结果的验证, 预测中的准确度验证, 从而提高模型的准确性.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/07cbfb7562e6eeed82e5216cf8c2bd38-20230731163147-753cydk.png",alt:""}})]),v._v(" "),_("p",[v._v("值得注意的是, 在数据输入和数据转换之间, 有时需要进行数据清洗. 数据清洗主要是剔除错误数据和不重要的数据, 从而降低模型训练的错误率.")]),v._v(" "),_("p",[v._v("接下来"),_("strong",[v._v("以图像分类为例, 介绍机器学习流水线的流程.")]),v._v("  关于图像分类的详细知识点, 可以自行查阅相关资料.")]),v._v(" "),_("p",[v._v("如下图所示, 假如现在有 10000 张小狗照片, 需要训练出一个关于小狗的预测模型.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/2aabe4ed15e65b654cee3f4427150966-20230731163147-161sxzm.png",alt:""}})]),v._v(" "),_("p",[v._v("假设这 10000 张照片中, 8000 张作为训练集, 2000 张作为测试集, 采用 CNN 进行模型训练. CNN 包括输入层, 卷积层, 池化层, 全连接层, 其中输入层为数据输入, 卷积层和池化层为特征提取, 全连接层是连接所有特征, 输出数据到分类器中, 以得到训练结果.")]),v._v(" "),_("p",[v._v("如上图所示, 生成小狗预测模型的流水线可以分为数据输入, 数据转换, 特征提取, 模型训练, 模型验证 5 部分. 具体流程如下:")]),v._v(" "),_("ul",[_("li",[v._v("输入数据, 也就是输入图像数据, 即 8000 张图片, 其中图像以像素表示. 比如, 图片的大小是 480480, 那么图像输入数据格式可以是 480480*3 的数组. 3 代表的是, RGB 的维度.")]),v._v(" "),_("li",[v._v("数据转换, 也就是对输入的图像数据进行解析, 正则化处理, 消除一些噪声数据, 得到格式化的数据.")]),v._v(" "),_("li",[v._v("特征提取, 指的是得到格式化的数据之后, 就可以对输入图像进行特征提取, 通过卷积操作提取小狗的一些轮廓特征, 比如耳朵, 尾巴, 身体等, 然后通过池化层识别出主要特征, 比如小狗的耳朵, 眼睛, 舌头等, 对特征进行精简.")]),v._v(" "),_("li",[v._v("模型训练. 在 CNN 中模型训练其实和特征提取是相辅相成的, 也就是特征提取后, 实现特征提取的那些参数就是模型参数, 而训练过程, 会根据梯度下降法等对参数进行调整, 以使得在模型验证阶段预测结果逼近真实结果. 也就是说, 特征提取和模型训练这两步, 在 CNN 中是放到一起的, 这里为了方便理解, 才显式地把这两步划分了出来.")]),v._v(" "),_("li",[v._v("模型验证. 将带有标签的测试数据集的图像(2000 张)输入到小狗预测模型, 将预测结果与实际结果进行对比, 如果误差比较大, 则对模型参数进行优化并进入下一次迭代训练; 如果误差较小, 那么得到的结果就是最终的小狗预测模型.")])]),v._v(" "),_("blockquote",[_("p",[v._v("知识扩展: 流水线模式和 MapReduce 模式中, 都有将大任务拆分为多个子任务, 两者的区别是什么?")])]),v._v(" "),_("p",[v._v("如题目所述, 流水线计算模式与分而治之的 MapReduce 计算模式有相似之处, 都是将一个完整的, 大的任务进行划分, 但它们"),_("strong",[v._v("划分的模式")]),v._v("不一样:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("MapReduce 以任务为粒度")]),v._v(", 将大的任务划分成多个小任务, 每个任务都需要执行完整的, 相同的步骤, 同一任务能被并行执行, 可以说是任务并行的一种计算模式;")]),v._v(" "),_("li",[_("strong",[v._v("而流水线计算模式以步骤为粒度")]),v._v(", 一个任务拆分为多个步骤, 每个步骤执行的是不同的逻辑, 多个同类型任务通过步骤重叠以实现不同任务的并行计算, 可说是数据并行的一种模式.")])]),v._v(" "),_("p",[v._v("此外, 它们的子任务(步骤)间的关系不同:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("在 MapReduce 中, 各个子任务可以独立执行, 互不干扰")]),v._v(", 多个子任务执行完后, 进行结果合并得到整个任务的结果, 因此要求子任务之间是没有依赖关系的;")]),v._v(" "),_("li",[_("strong",[v._v("而在流水线模式中, 多个子任务之间是具有依赖关系的")]),v._v(", 前一个子任务的输出是后一个子任务的输入.")])]),v._v(" "),_("p",[v._v("所以, 综合来讲, MapReduce 计算模式适合任务并行的场景, 而流水线计算模式适合同类型任务数据并行处理的场景.")]),v._v(" "),_("h5",{attrs:{id:"总结-15"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-15"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节介绍了什么是分布式计算模式中的流水线模式. 它参考了工业生产中的流水作业模式, 将一个任务分为多个步骤执行, 不同任务之间的步骤可以重叠执行, 这使得多个不同任务可以并行执行.")]),v._v(" "),_("p",[v._v("然后以典型的机器学习流程为例, 介绍了机器学习流水线处理流程, 以加深对分布式流水线计算模型的理解.")]),v._v(" "),_("p",[v._v("最后以 CNN 进行小狗分类模型训练为例, 通过讲述数据输入, 数据处理, 特征提取(卷积, 池化等操作), 模型训练, 模型验证等过程, 带你进一步理解了流水线计算模式在实际应用中的原理.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/150061f743a669bda0a5cfa1acc210fa-20230731163147-1rp5qy6.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"分布式通信技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式通信技术"}},[v._v("#")]),v._v(" 分布式通信技术")]),v._v(" "),_("h4",{attrs:{id:"_19-分布式通信之远程调用-我是你的千里眼"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_19-分布式通信之远程调用-我是你的千里眼"}},[v._v("#")]),v._v(" 19-分布式通信之远程调用:我是你的千里眼")]),v._v(" "),_("p",[v._v("通过前面的学习, 不知道你有没有发现分布式的"),_("strong",[v._v("本质就是多进程协作, 共同完成任务")]),v._v('. 要协作, 自然免不了通信. 那么, 多个进程之间是如何通信的呢? 这也就是在 "第四站: 分布式通信技术" 模块中要讲解的问题.')]),v._v(" "),_("h5",{attrs:{id:"什么是远程调用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是远程调用"}},[v._v("#")]),v._v(" 什么是远程调用?")]),v._v(" "),_("p",[v._v("首先通过一个例子, 来让你对远程调用和本地调用有一个直观了解.")]),v._v(" "),_("p",[v._v("以电商购物平台为例, 每一笔交易都涉及订单系统, 支付系统及库存系统, 假设三个系统分别部署在三台机器 A, B, C 中独立运行, 订单交易流程如下所示:")]),v._v(" "),_("ul",[_("li",[v._v("用户下单时, 调用本地(机器 A)的订单系统进行下单;")]),v._v(" "),_("li",[v._v("下单完成后, 会远程调用机器 B 上的支付系统进行支付, 待支付完成后返回结果, 之后在本地更新订单状态;")]),v._v(" "),_("li",[v._v("在本地远程调用机器 C 上的仓库系统出货, 出货完成后返回出货结果.")])]),v._v(" "),_("p",[v._v('在整个过程中, "下单" 和 "订单状态更新" 两个操作属于本地调用, 而 "支付" 和 "出货" 这两个操作是通过本地的订单系统调用其他两个机器上的函数(方法)实现的, 属于远程调用.')]),v._v(" "),_("p",[v._v("整个订单交易流程如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f766599fd8481c06186b440bdfd253b7-20230731163147-higlzwp.png",alt:""}})]),v._v(" "),_("p",[v._v("通过这个例子, 你应该对本地调用和远程调用有了一个初步的认识了. 那到底什么是本地调用, 什么是远程调用呢?")]),v._v(" "),_("p",[_("strong",[v._v("本地调用")]),v._v("通常指的是, 进程内函数之间的相互调用; 而"),_("strong",[v._v("远程调用")]),v._v(", 是进程间函数的相互调用, 是进程间通信 "),_("strong",[v._v("IPC(Inter-Process Communication)")]),v._v(" 的一种方式.")]),v._v(" "),_("p",[v._v("在分布式领域中, 一个系统由很多服务组成, 不同的服务由各自的进程单独负责. 因此, 远程调用在分布式通信中尤为重要.")]),v._v(" "),_("p",[v._v("根据进程是否部署在同一台机器上, 远程调用可以分为如下两类:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("本地过程调用(Local Procedure Call, LPC)")]),v._v(" , 是指运行在同一台机器上的进程之间的互相通信, 即在多进程操作系统中, 运行的不同进程之间可以通过 LPC 进行函数调用.")]),v._v(" "),_("li",[_("strong",[v._v("远程过程调用(Remote Procedure Call, RPC)")]),v._v(" , 是指不同机器中运行的进程之间的相互通信, 某一机器上运行的进程在不知道底层通信细节的情况下, 就像访问本地服务一样, 去调用远程机器上的服务.")])]),v._v(" "),_("p",[v._v("在这两种远程调用中, RPC 中的不同进程是跨机器的, 适用于分布式场景. 本节主要针对 RPC 进行详细讲解. 接下来,再提到远程调用时, 主要指的就是 RPC 了.")]),v._v(" "),_("h5",{attrs:{id:"远程调用的原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#远程调用的原理及应用"}},[v._v("#")]),v._v(" 远程调用的原理及应用")]),v._v(" "),_("p",[v._v("B/S (Browser/Server, 浏览器/服务器) 架构这种架构中, 被调用方(服务器)有一个开放的接口, 然后调用方(用户)通过 Browser 使用这个接口, 来间接调用被调用方相应的服务, 从而实现远程调用. 比如, 用户 A 在自己的电脑上通过浏览器查询北京今天的天气, 浏览器会将用户查询请求通过远程调用方式调用远程服务器相应的服务, 然后为用户返回北京今天的天气预报.")]),v._v(" "),_("p",[v._v("但是, B/S 架构是基于 HTTP 协议实现的, 每次调用接口时, 都需要先进行 HTTP 请求. 这样既繁琐又浪费时间, 不适用于有低时延要求的大规模分布式系统, 所以远程调用的实现大多采用更底层的网络通信协议.")]),v._v(" "),_("p",[v._v("接下来, 将介绍两种常用的远程调用机制: "),_("strong",[v._v("远程过程调用 RPC")]),v._v("(Remote Procedure Call) 和"),_("strong",[v._v("远程方法调用 RMI")]),v._v("(Remote Method Invocation).")]),v._v(" "),_("p",[v._v("首先一起看一下 RPC 的原理和应用.")]),v._v(" "),_("h6",{attrs:{id:"rpc的原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#rpc的原理及应用"}},[v._v("#")]),v._v(" RPC的原理及应用")]),v._v(" "),_("p",[_("strong",[v._v("简单地说, RPC 就是调用方采用参数传递的方式, 通过调用本机器上的一个函数或方法, 去执行远程机器上的函数或方法(可以统称为服务), 并返回结果. 在整个过程中, RPC 会隐藏具体的通信细节.")])]),v._v(" "),_("p",[v._v('如下图所示, 以刚才电商购物平台例子中的 "支付" 操作为例, 来详细看看一次 RPC 调用的完整流程:')]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/42a7bc5c338fb60ad1eb2fbd6bd32ceb-20230731163147-pz2wm5u.png",alt:""}})]),v._v(" "),_("ul",[_("li",[v._v("本地服务器也就是机器 A 中的订单系统, 调用本地服务器上的支付系统中的支付操作 Pay(Order), 该方法会直接调用 Client Stub(其中, Stub 是用于转换 RPC 过程中在订单系统和支付系统所在机器之间传递的参数), 这是一次正常的本地调用.")]),v._v(" "),_("li",[_("strong",[v._v("Client Stub 将方法 Pay, 参数 Order 等打包成一个适合网络传输的消息, 通过执行一次系统调用(也就是调用操作系统中的函数)来发送消息.")])]),v._v(" "),_("li",[v._v("订单系统所在机器 A 的本地操作系统通过底层网络通信, 将打包好的消息根据支付系统所在机器 B 的地址发送出去.")]),v._v(" "),_("li",[v._v("机器 B 上的操作系统接收到消息后, 将消息传递给 Server Stub.")]),v._v(" "),_("li",[v._v("机器 B 上的 Server Stub 将接收到的消息进行解包, 获得里面的参数, 然后调用本地的支付订单的操作 Pay(Order).")]),v._v(" "),_("li",[v._v("机器 B 上的支付操作 Pay(Order) 完成后, 将结果发送给 Server Stub, 其中结果可使用 XDR(External Data Representation, 一种可以在不同计算机系统间传输的数据格式)语言表示.")]),v._v(" "),_("li",[v._v("机器 B 上的 Server Stub 将结果数据打包成适合网络传输的消息, 然后进行一次系统调用发送消息.")]),v._v(" "),_("li",[v._v("机器 B 的本地操作系统通过底层网络将打包好的消息发送回机器 A.")]),v._v(" "),_("li",[v._v("机器 A 的操作系统接收到来自机器 B 的消息, 并将消息发送给本地的 Client Stub.")]),v._v(" "),_("li",[v._v("本地的 Client Stub 将消息解包, 然后将解包得到的结果返回给本地的订单系统.")])]),v._v(" "),_("p",[v._v("到此, 整个 RPC 过程结束.")]),v._v(" "),_("p",[v._v("从整个流程可以看出, 机器 A 上的 Pay(Order), Client Stub 和网络调用之间的交互属于本地调用, 机器 B 上的 Pay(Order), Server Stub 和网络调用之间的交互也属于本地调用. 而机器 A 和机器 B 之间的远程调用的核心是, 发生在机器 A 上的网络调用和机器 B 上的网络调用.")]),v._v(" "),_("p",[_("strong",[v._v("RPC 的目的, 其实就是要将第 2 到第 8 步的几个过程封装起来, 让用户看不到这些细节")]),v._v(". 从用户的角度看, 订单系统的进程只是做了一次普通的本地调用, 然后就得到了结果.")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("订单系统进程并不需要知道底层是如何传输的, 在用户眼里, 远程过程调用和调用一次本地服务没什么不同. 这就是 RPC 的核心.")])]),v._v(" "),_("p",[v._v("接下来再一起看一下 "),_("strong",[v._v("RPC 与本地调用(进程内函数调用)的区别")]),v._v(", 以加深对 RPC 的理解.")]),v._v(" "),_("p",[v._v("可以先想象一下, 本地调用过程是怎样的.")]),v._v(" "),_("p",[v._v("简单来说, 同一进程是共享内存空间的, 用户可以通过  "),_("strong",[v._v("{函数名 + 参数}")]),v._v("  直接进行函数调用. 而在 RPC 中, 由于不同进程内存空间无法共享, 且涉及网络传输, 所以不像本地调用那么简单. 所以 RPC 与本地调用主要有三点不同.")]),v._v(" "),_("p",[_("strong",[v._v("第一个区别是, 调用 ID 和函数的映射.")]),v._v("  在本地调用中, 进程内可"),_("strong",[v._v("共享内存地址空间")]),v._v(", 因此程序可直接通过函数名来调用函数. 而函数名的本质就是一个函数指针, 可以看成函数在内存中的地址. 比如, 调用函数 f(), 编译器会找到函数 f() 相应的内存地址. 但在 RPC 中, 只通过函数名是不行的, 因为不同进程的地址空间是不一样的.")]),v._v(" "),_("p",[v._v("所以在 RPC 中, "),_("strong",[v._v("所有的函数必须要有一个调用 ID 来唯一标识. 一个机器上运行的进程在做远程过程调用时, 必须附上这个调用 ID")]),v._v(". 另外还需要在通信的两台机器间, 分别维护一个"),_("strong",[v._v("函数与调用 ID 的映射表")]),v._v(". 两台机器维护的表中, 相同的函数对应的调用 ID 必须保持一致. 当一台机器 A 上运行的进程 P 需要远程调用时, 它就先查一下机器 A 维护的映射表, 找出对应的调用 ID, 然后把它传到另一台机器 B 上, 机器 B 通过查看它维护的映射表, 从而确定进程 P 需要调用的函数, 然后执行对应的代码, 最后将执行结果返回到进程 P.")]),v._v(" "),_("p",[_("strong",[v._v("第二个区别是, 序列化和反序列化.")]),v._v("  调用方调用远程服务时, 需要向被调用方传输调用 ID 和对应的函数参数, 那调用方究竟是怎么把这些数据传给被调用方的呢?")]),v._v(" "),_("p",[v._v("在本地调用中, 进程之间共享内存等, 因此只需要把参数压到栈里, 然后进程自己去栈里读取就行. 但是在 RPC 中, 两个进程分布在不同的机器上, 使用的是不同机器的内存, 因此不可能通过内存来传递参数. 而网络协议传输的内容是二进制流, 无法直接传输参数的类型, 因此这就"),_("strong",[v._v("需要调用方把参数先转成一个二进制流, 传到被调用方后, 被调用方再把二进制流转换成自己能读取的格式. 这个过程就叫作序列化和反序列化")]),v._v(". 同理, 被调用方返回的结果也需要有序列化和反序列化的过程, 不然调用方无法获取到结果. 也就是说, RPC 与本地调用相比, 参数的传递需要进行序列化和反序列化操作.")]),v._v(" "),_("p",[_("strong",[v._v("第三个区别是, 网络传输协议.")]),v._v("  序列化和反序列化解决了调用方和被调用方之间的"),_("strong",[v._v("数据传输格式")]),v._v("问题, 但要想序列化后的数据能在网络中顺利传输, 还需要有相应的网络协议, 比如 TCP, UDP 等, 因此就需要有一个底层通信层.")]),v._v(" "),_("p",[v._v("调用方通过该通信层把调用 ID 和序列化后的参数传给被调用方, 被调用方同样需要该通信层将序列化后的调用结果返回到调用方.")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("只要调用方和被调用方可以互传数据, 就可以作为这个底层通信层")]),v._v(". 因此, 它所使用的网络协议可以有很多, 只要能完成网络传输即可. 目前来看, 大部分 RPC 框架采用的是 TCP 协议.")]),v._v(" "),_("p",[v._v("说完 RPC 的核心原理, 下面以一个具有代表性的 "),_("strong",[v._v("RPC 框架 Apache Dubbo 为例")]),v._v(", 来加深了解 RPC. 在讲解 Dubbo 之前, 可以先想一下: 如果你是一个 RPC 框架的设计者, 会如何设计呢?")]),v._v(" "),_("p",[v._v("首先必须得有服务的"),_("strong",[v._v("提供方和调用方")]),v._v(". 如下图所示, 假设服务提供方 1～4 为调用方 1～4 提供服务, 每个调用方都可以任意访问服务提供方.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/98878dac05cfb045a5c85093256f155e-20230731163147-grfq4ea.png",alt:""}})]),v._v(" "),_("p",[v._v("当服务提供方和服务调用方越来越多时, 服务调用关系会愈加复杂. 假设服务提供方有 n 个, 服务调用方有 m 个, 则调用关系可达 n * m, 这会导致系统的通信量很大. 此时, 你可能会想到, 为什么不使用一个"),_("strong",[v._v("服务注册中心")]),v._v("来进行统一管理呢, 这样调用方只需要到服务注册中心去查找相应的地址即可.")]),v._v(" "),_("p",[v._v("这个想法很好, 如下图所示, "),_("mark",[_("strong",[v._v("在服务调用方和服务提供方之间增加一个服务注册中心, 这样调用方通过服务注册中心去访问提供方相应的服务, 这个服务注册中心相当于服务调用方和提供方的中心枢纽")])]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c149a21c05206e42245492d01cb8abe5-20230731163147-zlafx2r.png",alt:""}})]),v._v(" "),_("p",[v._v("这样是不是好多了呢?")]),v._v(" "),_("p",[v._v("Dubbo 就是在引入服务注册中心的基础上, 又加入了"),_("strong",[v._v("监控中心组件")]),v._v("(用来监控服务的调用情况, 以方便进行服务治理), 实现了一个 RPC 框架. 如下图所示, Dubbo 的架构主要包括 4 部分:")]),v._v(" "),_("ol",[_("li",[v._v("**服务提供方. **服务提供方会向服务注册中心注册自己提供的服务.")]),v._v(" "),_("li",[v._v("**服务注册中心. **服务注册与发现中心, 负责存储和管理服务提供方注册的服务信息和服务调用方订阅的服务类型等.")]),v._v(" "),_("li",[_("strong",[v._v("服务调用方.")]),v._v("  根据服务注册中心返回的"),_("strong",[v._v("服务所在的地址列表")]),v._v(", 通过远程调用访问远程服务.")]),v._v(" "),_("li",[v._v("**监控中心. **统计服务的调用次数和调用时间等信息的监控中心, 以方便进行服务管理或服务失败分析等.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a297827eb46465102e77c8ca46d4f19b-20230731163147-ngbw0um.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, Dubbo 的大致工作流程如下:")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("服务提供方需要向服务注册中心注册自己提供的服务;")])]),v._v(" "),_("li",[_("strong",[v._v("服务调用方需要向注册中心预订调用服务的提供方地址列表;")])]),v._v(" "),_("li",[_("strong",[v._v("服务注册中心将服务对应的提供方地址列表返回给调用方;")])]),v._v(" "),_("li",[_("strong",[v._v("服务调用方根据服务地址信息进行远程服务调用;")])]),v._v(" "),_("li",[_("strong",[v._v("服务调用方和服务提供方定时向监控中心发送服务调用次数及调用时间等信息.")])])]),v._v(" "),_("p",[v._v("接下来再学习另一个远程调用机制 RMI.")]),v._v(" "),_("h6",{attrs:{id:"rmi的原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#rmi的原理及应用"}},[v._v("#")]),v._v(" RMI的原理及应用")]),v._v(" "),_("p",[v._v("RMI 是一个基于 Java 环境的应用编程接口, 能够让本地 Java 虚拟机上运行的对象, 像调用本地对象一样调用远程 Java 虚拟机上的对象.")]),v._v(" "),_("p",[_("strong",[v._v("RMI 可以说是 RPC 的一种具体形式")]),v._v(", 其原理与 RPC 基本一致, 唯一不同的是 "),_("strong",[v._v("RMI 是基于对象的, 充分利用了面向对象的思想去实现整个过程, 其本质就是一种基于对象的 RPC 实现")]),v._v(".")]),v._v(" "),_("p",[v._v("RMI 的具体原理如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/dc01437e5a852cb25c14bb93b722fad3-20230731163147-dx2bcig.png",alt:""}})]),v._v(" "),_("p",[v._v("RMI 的实现中, 客户端的订单系统中的 Stub 是客户端的一个辅助对象, 用于与服务端实现远程调用; 服务端的支付系统中 Skeleton 是服务端的一个辅助对象, 用于与客户端实现远程调用.")]),v._v(" "),_("p",[v._v("也就是说, 客户端订单系统的 Pay(Order) 调用本地 Stub 对象上的方法, Stub 打包调用信息, 比如变量, 方法名等, 通过网络发送给服务端的 Skeleton 对象, Skeleton 对象将收到的包进行解析, 然后调用服务端 Pay(Order) 系统中的相应对象和方法进行计算, 计算结果又会以类似的方式返回给客户端.")]),v._v(" "),_("p",[v._v("为此, 可以看出 "),_("strong",[v._v("RMI 与 PRC 最大的不同在于调用方式和返回结果的形式")]),v._v(", RMI 通过对象作为远程接口来进行远程方法的调用, 返回的结果也是对象形式, 可以是 Java 对象类型, 也可以是基本数据类型. RMI 的典型实现框架有 EJB(Enterprise JavaBean, 企业级 JavaBean), 如果需要深入了解这个框架的话, 可以参考其官方文档.")]),v._v(" "),_("h6",{attrs:{id:"rpc-与-rmi-对比分析"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#rpc-与-rmi-对比分析"}},[v._v("#")]),v._v(" RPC 与 RMI 对比分析")]),v._v(" "),_("p",[v._v("上面学习了 RPC 和 RMI, 接下来我过一个表格来对比下它们的异同, 以方便进一步理解与记忆.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/751010ceb84492ea528c399d9a234be1-20230731163147-y7dyjyh.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-远程过程调用存在同步和异步吗"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-远程过程调用存在同步和异步吗"}},[v._v("#")]),v._v(" 知识扩展:远程过程调用存在同步和异步吗?")]),v._v(" "),_("p",[v._v("分布式领域中, 经常会听到同步和异步这两个词, 那么远程过程调用存在同步和异步吗?")]),v._v(" "),_("p",[v._v("答案是肯定的.")]),v._v(" "),_("p",[_("strong",[v._v("远程过程调用包括同步调用和异步调用")]),v._v("两种, 它们的含义分别是:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("同步调用, 指的是调用方等待被调用方执行完成并返回结果")]),v._v(". 这就好比在现实生活中, 用户 A 让用户 B 完成一篇文章, 用户 A 就在那里等着, 一直等用户 B 将写好的文章交给用户 A 后才离开, 并对文章进行审核.")]),v._v(" "),_("li",[_("strong",[v._v("异步调用, 指的是调用方调用后不用等待被调用方执行结果返回, 并可以通过回调通知等方式获取返回结果")]),v._v(". 这就好比在现实生活中, 用户 A 让用户 B 完成一篇文章, 用户 A 告知用户 B 后, 用户 A 离开去做其他事情, 当用户 B 完成文章后反馈给用户 A, 用户 A 收到反馈后开始审核文章.")])]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("同步调用和异步调用的区别是, 是否等待被调用方执行完成并返回结果")]),v._v(". 因此, 同步调用通常适用于需要关注被调用方计算结果的场景, 比如用户查询天气预报, 调用方需要直接返回结果; 异步调用通常适用于对响应效率要求高, 但对结果正确性要求相对较低的场景, 比如用户下发部署一个任务, 但真正执行该任务需要进行资源匹配和调度, 进程拉起等过程, 时间比较长, 如果用户进程阻塞在那里, 会导致体验很差, 这种情况下可以采用异步调用.")]),v._v(" "),_("h5",{attrs:{id:"总结-16"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-16"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节主要分享了分布式通信中的远程调用. 以电商购物平台为例, 首先让你对本地调用和远程调用有了一定的认识, 然后分析了两种常用的远程调用机制 RPC 和 RMI, 并对两者进行了比较. 除此之外, 还介绍了 Dubbo 这个代表性的 RPC 框架.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5af3eeb45a97316452c5d8b966561938-20230731163147-iy334c5.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_20-分布式通信之发布订阅-送货上门"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_20-分布式通信之发布订阅-送货上门"}},[v._v("#")]),v._v(" 20-分布式通信之发布订阅:送货上门")]),v._v(" "),_("p",[v._v("上一节学习了分布式通信中的远程调用. "),_("strong",[v._v("远程调用的核心是在网络服务层封装了通信协议, 序列化, 传输等操作, 让用户调用远程服务如同进行本地调用一样")]),v._v(".")]),v._v(" "),_("p",[v._v("其实, 这种方式就是通过网络服务层的封装实现了不同机器上不同进程之间的直接通信, 因为是直接通信, 所以通过线程阻塞的方式实现同步调用比较容易, 因此"),_("strong",[v._v("通常被用于同步调用")]),v._v(". 比如, 机器 1 上的进程 A 调用机器 2 上的进程 B, 进程 A 被挂起, 进程 B 开始执行, 当进程 B 将值返回给 A 时, A 继续执行. 虽然这种方式也可以用于异步通信, 但因为进程之间是直接交互的, 所以当进程比较多时, 会导致进程维护通信的复杂度非常高, 且一个进程通信接口改变, 与其通信的进程都会受到影响.")]),v._v(" "),_("p",[v._v("随着业务和分布式计算规模的逐渐增大和复杂化, 远程调用模型有点心有余力而不足了, 为此"),_("strong",[v._v("出现了专门的异步通信模式, 也就是消息发布订阅模式和消息队列模式")]),v._v(". 在接下来的两篇文章中, 将详细讲述这两种通信模式.")]),v._v(" "),_("h5",{attrs:{id:"什么是发布订阅"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是发布订阅"}},[v._v("#")]),v._v(" 什么是发布订阅?")]),v._v(" "),_("p",[v._v("其实, 发布订阅的思想在生活中随处可见.")]),v._v(" "),_("p",[v._v("比如, 学术届电子论文的订阅方式. 通常各个会议方或出版社会将学术论文发布到论文网站(或平台上, 比如 ACM, 知网等), 然后学生或老师向论文网站订阅自己感兴趣的论文. 当会议方或出版社将论文发布到论文网站后, 论文网站会根据订阅信息, 将相应的论文推送给订阅者(比如通过邮件的方式). 这里的会议方或出版社就相当于生产者, 负责发布论文, 学生或老师就相当于消费者, 而论文网站就相当于一个消息中心.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/142a2436974bddbbd8779ed3201456f9-20230731163147-u4h71v0.png",alt:""}})]),v._v(" "),_("p",[v._v("由此可以看出, "),_("strong",[v._v("发布订阅的三要素是生产者, 消费者和消息中心,")]),v._v('  生产者负责产生数据放到消息中心, 消费者向消息中心订阅自己感兴趣的消息, 当发布者推送数据到消息中心后, 消息中心根据消费者订阅情况将相关数据推送给对应的订阅者. 这种将数据送到消费者手里的行为, 是不是和现在常说的 "送货上门" 一样呢?')]),v._v(" "),_("h5",{attrs:{id:"发布订阅的原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#发布订阅的原理及应用"}},[v._v("#")]),v._v(" 发布订阅的原理及应用")]),v._v(" "),_("p",[v._v("这个论文订阅的例子, 充分体现了发布订阅的思想. 接下来就进一步分析下发布订阅的原理.")]),v._v(" "),_("h6",{attrs:{id:"发布订阅的基本工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#发布订阅的基本工作原理"}},[v._v("#")]),v._v(" 发布订阅的基本工作原理")]),v._v(" "),_("p",[v._v("在分布式通信领域中, 消息系统一般有两种典型的模式. 一种是"),_("strong",[v._v("点对点模式")]),v._v("(P2P, Point to Point), 另一种是"),_("strong",[v._v("发布订阅模式")]),v._v("(Pub/Sub, Publish/Subscribe). 接下来就一起看看这两种模式, 以深入理解发布订阅模式的原理.")]),v._v(" "),_("p",[v._v("首先一起看一下"),_("strong",[v._v("什么是点对点模式")]),v._v(".")]),v._v(" "),_("p",[v._v("生产者将消息发送到消息中心, 然后消费者从消息中心取出对应的消息进行消费. 消息被消费后, 消息中心不再存储该消息, 因此其他消费者无法再消费该消息. 也就是说, 点对点模式虽然支持多个消费者, 但一个消息只能被一个消费者消费, 不允许重复消费.")]),v._v(" "),_("p",[v._v("这种模式就好比, 限定了每篇论文只能被一个用户消费, 比如现在有一篇分布式相关的论文, 这篇论文推送给学生 A 之后, 论文网站就必须将其删除或下架, 也就是说其他用户无法再获取或阅读该论文了. (当然实际情况并不是这样的, 这里只是为了方便理解, 我做了相应的假设.)")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7ad2ca93cbc8f132ce3747579aff8e06-20230731163147-azpzsb6.png",alt:""}})]),v._v(" "),_("p",[v._v("接下来看一下"),_("strong",[v._v("发布订阅模式")]),v._v(".")]),v._v(" "),_("p",[v._v("生产者可以发送消息到消息中心, 而消息中心通常以主题(Topic)进行划分, 每条消息都会有相应的主题, 消息会被存储到自己所属的主题中, 订阅该主题的所有消费者均可获得该消息进行消费.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/dc702476e606dbffda274dcf921e3b38-20230731163147-q9vw9qa.png",alt:""}})]),v._v(" "),_("p",[v._v("比如图中假设生产者 1 发布一个 Topic 相关数据或消息, 消费者 1～3 均订阅了该 Topic 消息, 则该消息会推送消费者 1～3, 也就是说同一个消息被 3 个消费者消费了.")]),v._v(" "),_("p",[v._v("这种模式就好比, 不同的方向代表不同的主题, 比如分布式领域代表一个主题, 当会议方或出版社发布分布式相关的论文时, 该论文会被存储到论文网站的分布式主题下, 同时学生或老师也会根据自己感兴趣的主题进行订阅. 如果学生 A 订阅了分布式主题, 那么当会议方或出版社发布分布式相关的论文后, 会议网站会将这些论文推送给学生 A.")]),v._v(" "),_("p",[v._v("**与点对点模式相比, 发布订阅模式中一个消息可以被多个消费者进行消费, 这也是和点对点模式的本质区别. **")]),v._v(" "),_("p",[v._v("以上就是发布订阅中的两种典型模式了.")]),v._v(" "),_("p",[v._v("在分布式系统中, 通常会为多用户服务, 而多个用户通常会关注相同类型的消息, 因此发布订阅模式在分布式系统中非常常见. 接下来, 再结合经典的分布式发布订阅消息系统 Kafka 的发布订阅原理及工作机制, 来帮助巩固对发布订阅的理解.")]),v._v(" "),_("h6",{attrs:{id:"kafka发布订阅原理及工作机制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kafka发布订阅原理及工作机制"}},[v._v("#")]),v._v(" Kafka发布订阅原理及工作机制")]),v._v(" "),_("p",[v._v("Kafka 是一种典型的发布订阅消息系统, 其系统架构也是包括生产者, 消费者和消息中心三部分.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("生产者")]),v._v("(Producer)负责发布消息到消息中心, 比如电子论文的会议方或出版社;")]),v._v(" "),_("li",[_("strong",[v._v("消费者")]),v._v("(Consumer)向消息中心订阅自己感兴趣的消息, 获得数据后进行数据处理, 比如订阅电子论文的老师或学生;")]),v._v(" "),_("li",[_("strong",[v._v("消息中心")]),v._v("(Broker)负责存储生产者发布的消息和管理消费者订阅信息, 根据消费者订阅信息, 将消息推送给消费者, 比如论文网站. 在 Kafka 中, 消息中心本质上就是一组服务器, 也可以说是 Kafka 集群.")])]),v._v(" "),_("p",[v._v("Kafka 的架构图, 如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/cf5f2e0813756514948312d3a5bf5eaa-20230731163147-e3bbn66.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看到, Kafka 中除了 Producer, Broker, Consumer 之外, 还有一个 ZooKeeper 集群. "),_("strong",[v._v("Zookeeper 集群用来协调和管理 Broker 和 Consumer, 实现了 Broker 和 Consumer 的解耦, 并为系统提供可靠性保证")]),v._v(".")]),v._v(" "),_("p",[v._v("ZooKeeper 集群可以看作是一个提供了分布式服务协同能力的第三方组件, Consumer 和 Broker 启动时均会向 ZooKeeper 进行注册, 由 ZooKeeper 进行统一管理和协调. ZooKeeper 中会"),_("strong",[v._v("存储一些元数据信息")]),v._v(", 比如对于 Broker, 会存储主题对应哪些分区(Partition), 每个分区的存储位置等; 对于 Consumer, 会存储消费组(Consumer Group)中包含哪些 Consumer, 每个 Consumer 会负责消费哪些分区等.")]),v._v(" "),_("p",[v._v("接下来看看"),_("strong",[v._v("分区和消费组的原理和作用")]),v._v(".")]),v._v(" "),_("p",[v._v("从上面的介绍可以看出, Broker 负责存储消息数据, Consumer 负责消费数据, Consumer 消费数据的能力会影响 Broker 数据存储是否溢出的问题. 若 Consumer 消费太慢, 会导致 Broker 存储溢出, Broker 就会丢弃一部分消息.")]),v._v(" "),_("p",[v._v("因此, Broker 和 Consumer 是 Kafka 的核心. 接下来, 将进一步了解 Kafka 中 Broker 和 Consumer 的关键技术, 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b12876a1504b5b4bf6ed6b06678bf80c-20230731163147-o3guvzm.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("首先看一下 Broker.")])]),v._v(" "),_("p",[v._v("在 Kafka 中, 为了解决消息存储的负载均衡和系统可靠性问题, 所以引入了"),_("strong",[v._v("主题和分区")]),v._v("的概念. 其中, "),_("strong",[v._v("主题是一个逻辑概念")]),v._v(", 指的是消息类型或数据类型, 就好比电子论文案例所讲的分布式是一个主题.")]),v._v(" "),_("p",[_("strong",[v._v("而分区是针对主题而言的, 指的是一个主题的内容可以被划分成多个集合, 分布在不同的 Broker 上, 不同的 Broker 在不同的节点上. 这里的集合就是分区, 其中同一个分区只属于一个 Broker.")])]),v._v(" "),_("p",[v._v("那"),_("strong",[v._v("分区有什么好处呢?")])]),v._v(" "),_("p",[v._v("在我看来, 分区的好处主要包括如下两点:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("实现负载均衡, 避免单个 Broker 上的负载过高")]),v._v(". 比如, Topic 0 被分为 Partiton-0, Partiton-1 和 Partiton-2 三个分区, 分别分布在 Broker 0, Broker 1 和 Broker 2 上. 这就使得 Topic 0 的消息可以分布在这 3 个分区中, 实现负载均衡.")]),v._v(" "),_("li",[_("strong",[v._v("实现消息的备份, 从而保证系统的高可靠")]),v._v(". 比如, Topic 1 包含两个分区 Partiton-0, Partiton-1, 每个分区内容一致, 分别存储在 Broker 0 和 Broker 1 上, 借此实现了数据备份.")])]),v._v(" "),_("p",[_("strong",[v._v("接下来再看看 Consumer.")])]),v._v(" "),_("p",[_("strong",[v._v("Kafka 中的消费组, 指的是多个消费者的一个集合. 一个消费组中的消费者共同消费主题消息, 并且主题中每个消息只可以由消费组中的某一个消费者进行消费.")])]),v._v(" "),_("p",[v._v("引入消费组的目的是什么呢? 在消息过多的情况下, 单个消费者消费能力有限时, 会导致消费效率过低, 从而导致 Broker 存储溢出, 丢弃一部分消息. Kafka 为了解决这个问题, 所以引入了消费组.")]),v._v(" "),_("p",[v._v("这样一来, 对发布订阅的基本工作机制就比较清楚了. 接下来再结合电商购物平台的例子, 来看看发布订阅技术的具体应用.")]),v._v(" "),_("h6",{attrs:{id:"发布订阅实践应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#发布订阅实践应用"}},[v._v("#")]),v._v(" 发布订阅实践应用")]),v._v(" "),_("p",[v._v("假设在电商购物平台(为了方便理解, 对电商购物平台做了一定的简化)中, 用户首先在订单系统下单, 下单后库存系统会进行出货, 通知系统则负责通知用户, 整个流程可以用发布订阅的模式进行, 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/52434a1011cc91407a67fcdedbcd214c-20230731163147-nl4nnfj.png",alt:""}})]),v._v(" "),_("ol",[_("li",[v._v("订单系统对应发布订阅模式中的生产者, 消息中心有个主题专门存放下单信息, 每次用户下单后, 订单系统会向该主题写入数据;")]),v._v(" "),_("li",[v._v("库存系统和通知系统对应发布订阅模式中的消费者, 它们会向消息中心订阅下单信息相关的主题;")]),v._v(" "),_("li",[v._v("订单系统向消息中心发布订单信息后, 库存系统和通知系统都会获取到相应的下单信息, 然后进行各自后续的操作, 即库存系统进行出货, 通知系统通过短信或邮件等方式通知用户.")])]),v._v(" "),_("p",[v._v("接下来总结下"),_("strong",[v._v("发布订阅模式的关键特征")]),v._v(".")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("实现了系统解耦, 易于维护")]),v._v(". 生产者只负责消息的发布, 不需要知道消费者的数量, 也不需要知道消费者获取消息用来做什么, 而消费者也不需要知道什么时候发布者会发布消息. 所以, 生产者和消费者互相独立, 进而实现了系统解耦, 每个部分可以单独维护, 减少了因为生产者和消费者的耦合引入的一些相互影响. 比如, 如果两者耦合在一起, 当生产者逻辑更改需要修改代码时, 消费者部分的代码也受影响, 因此每个部分单独维护降低了维护的复杂度.")]),v._v(" "),_("li",[_("strong",[v._v("实现了异步执行, 避免高负载")]),v._v(". 生产者发布消息到消息中心, 当消息超过消息中心可以存储的容量后, 消息中心会丢弃掉超出的消息, 这样系统就不会因为消息数量多而导致系统故障.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-观察者模式和发布订阅模式的区别是什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-观察者模式和发布订阅模式的区别是什么"}},[v._v("#")]),v._v(" 知识扩展:观察者模式和发布订阅模式的区别是什么?")]),v._v(" "),_("p",[v._v("观察者模式也会在分布式系统中都会经常用到. 那么观察者模式和发布订阅模式的区别到底是什么呢?")]),v._v(" "),_("p",[v._v("顾名思义, 观察者模式下有观察者, 那么就有被观察者, 两者之间的关系是什么呢? 观察者负责监控被观察者的状态变更, 如果被观察者的状态发生了改变, 那么观察者根据状态的变更执行相关操作. 举个例子, 现在进程 A 是被观察者, 进程 B 和进程 C 是观察者, 当进程 B 观察到进程 A 中变量 X 由 3 变为 4 时, 执行 X+1 的操作; 当进程 C 观察到进程 A 中变量 X 由 3 变为 4 时, 执行 X-1 的操作. 也就是说, 观察者模式, "),_("strong",[v._v("定义了被观察者与观察者的直接交互或通信关系")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来看一下发布订阅模式. 发布订阅模式中存在发布者, 订阅者和消息中心, 订阅者需要向消息中心指定自己对哪些数据感兴趣, 发布者推送的数据放入消息中心后, 消息中心根据订阅者订阅信息推送数据. 也就是说, "),_("strong",[v._v("发布者和订阅者之间引入了消息中心, 实现的是间接通信")]),v._v(".")]),v._v(" "),_("p",[v._v("总结来讲, "),_("strong",[v._v("观察者模式采用了直接通信, 观察者和被观察者通信时延会低一些, 但它们的依赖关系比较强, 不管是被观察者还是观察者逻辑或接口有更改, 另外一个均会受影响. 而发布者和订阅者模式采用间接通信, 引入了消息中心, 相对比较厚重, 且通信时延相对会高一点, 但实现了订阅者与发布者的解耦")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"总结-17"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-17"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节首先通过论文订阅的案例, 介绍了什么是发布订阅以及发布订阅的基本原理, 然后介绍了一个经典的分布式发布订阅消息系统 Kafka, 最后以一个电商购物平台的案例描述了发布订阅模式的应用场景.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c321f437850ceb6991f82d0c419153a6-20230731163147-59rf3u8.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_21-分布式通信之消息队列-货物自取"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_21-分布式通信之消息队列-货物自取"}},[v._v("#")]),v._v(" 21-分布式通信之消息队列:货物自取")]),v._v(" "),_("p",[v._v("上一节学习了分布式通信技术中的发布订阅. 总结来说, 发布订阅就是发布者产生数据到消息中心, 订阅者订阅自己感兴趣的消息, 消息中心根据订阅者的订阅情况, 将相关消息或数据发送给对应的订阅者.")]),v._v(" "),_("p",[v._v("在实际使用场景中, 还有一种常用的通信方式, 就是"),_("strong",[v._v("将消息或数据放到一个队列里, 谁需要谁就去队列里面取")]),v._v('. 在分布式领域中, 这种模式叫 "消息队列". 与发布订阅相比, 消息队列技术的核心思想可以概括为 "货物自取".')]),v._v(" "),_("h5",{attrs:{id:"什么是消息队列"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是消息队列"}},[v._v("#")]),v._v(" 什么是消息队列?")]),v._v(" "),_("p",[v._v("回想一下, 在上一篇学术电子论文订阅的例子中, 出版社或会议方将论文发布到论文网站(或平台)上, 然后论文网站再将论文推送给订阅相关论文的老师或学生. 这里的论文网站就是"),_("strong",[v._v("消息中心")]),v._v(", 负责根据订阅信息将论文送货上门, 角色非常关键.")]),v._v(" "),_("p",[v._v("但其实除了将论文送货上门外, 还能想到另外一种模式, 也就是出版社或会议方将论文发布到论文网站进行存储, 老师或学生根据需要到论文网站按需购买文章.")]),v._v(" "),_("p",[v._v("这种思想, 在分布式通信领域中称为消息队列模式, 论文网站充当的就是消息队列的角色, 也非常关键. 接下来, 再通过一个具体的应用案例来深入地理解什么是消息队列.")]),v._v(" "),_("p",[v._v("比如, 很多系统都提供了用户注册功能, 注册完成后发送通知邮件. 如下图所示, 假设用户通过邮箱进行注册, 填写完注册信息并点击提交后, 系统的处理过程主要分为两步:")]),v._v(" "),_("ul",[_("li",[v._v("检查用户注册信息的合法性, 如果合法则将注册信息写入数据库中, 若不合法, 直接返回, 流程结束;")]),v._v(" "),_("li",[v._v("将用户注册信息写入数据库后, 给用户发送通知邮件, 以告知用户注册的相关信息, 比如注册账号等信息.")])]),v._v(" "),_("p",[v._v("假设系统将注册信息写入数据库需要花费 400ms, 给用户发送通知邮件需要花费 600ms.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/2fd0d68a58b66b525d6132d7dd8c77ea-20230731163147-p3s6pz4.png",alt:""}})]),v._v(" "),_("p",[v._v("这时, 注册消息写入数据库和发送通知邮件这两个组件间是直接交互, 且是同步通信方式. 那么, 从用户提交注册到收到响应, 需要等系统完成这两个步骤. 也就是说, 如果不考虑通信延迟的话, 注册系统对用户的响应时间是 1000ms, 即 1s.")]),v._v(" "),_("p",[v._v("如下图所示, 如果引入消息队列作为注册消息写入数据库和发送通知邮件这两个组件间的中间通信者, 那么这两个组件就可以实现异步通信, 异步执行. 引入消息队列后, 上述步骤可以分为三步:")]),v._v(" "),_("ul",[_("li",[v._v("检查用户注册信息的合法性, 如果合法则将注册信息写入数据库中, 若不合法则直接返回, 流程结束;")]),v._v(" "),_("li",[v._v("注册消息写入消息数据库后, 将消息写入消息队列的队尾;")]),v._v(" "),_("li",[v._v("发送通知邮件的组件去消息队列取出队首的消息, 给用户发送通知邮件, 告知用户注册的相关信息.")])]),v._v(" "),_("p",[v._v("也就是说, 采用消息队列模式, 只需要第 2 步完成, 即可给用户返回响应. 第 3 步发送通知邮件可以在返回响应之后执行.")]),v._v(" "),_("p",[v._v("用户的注册信息写入数据库之后, 通过数据库的可靠性设计来保证用户注册信息不会丢失, 也就是说发送通知邮件的组件一定可以获取到用户注册信息, 即保证会给注册用户发送通知邮件. 也就是说, "),_("strong",[v._v("消息队列的引入不会影响用户注册网站, 但会提升用户响应效率")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f647e6fe51babb0511fe89afeb5f2251-20230731163147-qy6n389.png",alt:""}})]),v._v(" "),_("p",[v._v("通常情况下, 将消息写入消息队列的速度很快, 假设需要 100ms. 那么引入消息队列后, 发送通知邮件实现了异步读取, 系统响应时间缩短为 500ms, 响应速度提升了一倍, 提升了用户体验.")]),v._v(" "),_("p",[v._v("讲完了用户注册这个例子, 再来看消息队列的定义就比较容易理解了.")]),v._v(" "),_("p",[v._v("队列是一种具有先进先出特点的数据结构**, 消息队列是基于队列实现的, 存储具有特定格式的消息数据**, 比如定义一个包含消息类型, 标志消息唯一性的 ID, 消息内容的一个结构体作为消息数据的特定格式. 消息以特定格式放入这个队列的尾部后可以直接返回, 并不需要系统马上处理, 之后会有其他进程从队列头部开始读取消息, 按照消息放入的顺序逐一处理.")]),v._v(" "),_("p",[v._v("从上面的例子中, 也可以看出引入消息队列的好处是, 提高响应速度, 以及实现组件间的解耦.")]),v._v(" "),_("h5",{attrs:{id:"消息队列的原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#消息队列的原理"}},[v._v("#")]),v._v(" 消息队列的原理")]),v._v(" "),_("p",[v._v("现在把消息队列的工作原理从用户注册这个例子中剥离出来, 给一个更加直接的解释.")]),v._v(" "),_("h6",{attrs:{id:"消息队列工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#消息队列工作原理"}},[v._v("#")]),v._v(" 消息队列工作原理")]),v._v(" "),_("p",[v._v("消息队列的核心结构, 如下图所示. 与发布订阅模式类似, 消息队列模式也是包括 3 个核心部分:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("生产者")]),v._v(". 生产者会产生消息或数据, 并将消息或数据插入到消息队列中.")]),v._v(" "),_("li",[_("strong",[v._v("消息队列")]),v._v(". 一种具有先进先出特点的数据结构, 用于存储消息.")]),v._v(" "),_("li",[_("strong",[v._v("消费者")]),v._v(". 从消息队列中获取消息或数据, 进行相关处理.")])]),v._v(" "),_("p",[v._v("具体流程是, 生产者将发送的消息插入消息队列, 也就是入队, 之后会有一个消费者从消息队列中逐次取出消息进行处理, 完成出队.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e9d35abee66dd3977b349f247423b549-20230731163147-zgwm2qz.png",alt:""}})]),v._v(" "),_("p",[v._v("了解了消息队列的工作原理, 接下来以阿里开源的 RocketMQ 为例, 进一步介绍消息队列的原理, 工作机制和实践应用.")]),v._v(" "),_("h6",{attrs:{id:"rocketmq消息队列原理及工作机制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq消息队列原理及工作机制"}},[v._v("#")]),v._v(" RocketMQ消息队列原理及工作机制")]),v._v(" "),_("p",[v._v("首先, 看一下 RocketMQ 的架构图, 形成一个整体认知.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/72b234793067a23e76d0525e1e9dafd4-20230731163147-i750c91.png",alt:""}})]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("RokcetMQ 共包括 NameServer Cluster, Producer Cluster, Broker Cluster 和 Consumer Cluster 共 4 部分")])]),v._v(". 接下来一起看看每部分的具体功能.")]),v._v(" "),_("p",[_("strong",[v._v("NameServer Cluster")]),v._v(", 指的是名字服务器集群. 这个集群的功能与 Kafka 中引入的 ZooKeeper 类似, 提供分布式服务的"),_("strong",[v._v("协同和管理功能")]),v._v(", 在 RocketMQ 中主要是管理 Broker 的信息, 包括有哪些 Broker, Broker 的地址和状态等, 以方便生产者获取 Broker 信息发布消息, 以及订阅者根据 Broker 信息获取消息.")]),v._v(" "),_("p",[_("strong",[v._v("Producer Cluster")]),v._v(", 指的是"),_("strong",[v._v("生产者集群")]),v._v(", 负责接收用户数据, 然后将数据发布到消息队列中心 Broker Cluster. 那么, 生产者按照集群的方式进行部署, 好处是什么呢? 在我看来, 好处可以概括为以下两点:")]),v._v(" "),_("ol",[_("li",[v._v("一是, 多个 Producer 可以并发接收用户的输入数据, 提升业务处理效率;")]),v._v(" "),_("li",[v._v("二是, 考虑到"),_("strong",[v._v("可靠性问题")]),v._v(", 如果只有一个 Producer 接收用户输入数据, 当这个 Producer 故障后, 整个业务就无法运行了.")])]),v._v(" "),_("p",[_("strong",[v._v("Consumer Cluster")]),v._v(", 指的是"),_("strong",[v._v("消费者集群")]),v._v(", 负责从 Broker 中获取消息进行消费. Consumer 以集群方式进行部署的好处是, 提升消费者的消费能力, 以避免消息队列中心存储溢出, 消息被丢弃.")]),v._v(" "),_("p",[_("strong",[v._v("Broker Cluster")]),v._v(", 指的是 Broker 集群, 负责"),_("strong",[v._v("存储 Producer Cluster 发布的数据")]),v._v(", 以方便消费者进行消费. Broker Cluster 中的每个 Broker 都进行了"),_("strong",[v._v("主从设计")]),v._v(", 即每个 Broker 分为 Broker Master 和 Broker Slave, Master 既可以写又可以读, Slave 不可以写只可以读. 每次 Broker Master 会把接收到的消息同步给 Broker Slave, 以实现数据备份. 一旦 Broker Master 崩溃了, 就可以切换到 Broker Slave 继续提供服务. 这种设计的好处是, 提高了系统的可靠性.")]),v._v(" "),_("p",[v._v('可以看出, Broker Cluster 就是今天要讲的核心 "消息队列中心", 那么它到底是如何采用队列实现的呢? 接下来就一起看看 '),_("strong",[v._v("Broker Cluster 的实现方式")]),v._v(".")]),v._v(" "),_("p",[v._v("如下图所示, 在 Broker Cluster 中, 消息的存储采用"),_("strong",[v._v("主题(Topic)+ 消息队列(Queue)")]),v._v(" 的方式实现:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/944a02812a3ea2881e1a7e47ef319049-20230731163147-isdt2jy.png",alt:""}})]),v._v(" "),_("p",[v._v("与 Kafka 一样, RocketMQ 中的主题也是一个逻辑概念. "),_("strong",[v._v("一个主题可以分区, 分布在各个不同的 Broker 中, 每个 Broker 上只有该主题的部分数据")]),v._v(". 每个主题分区中, 队列的数量可以不同, 由用户在创建主题时指定. 队列是资源分配的基本单元, 消息进行存储时会存放到相应主题的分区中.")]),v._v(" "),_("p",[v._v("上面介绍了 RocketMQ 的关键组件. 接下来再看看 "),_("strong",[v._v("RocketMQ 的工作流程")]),v._v(", 如下图所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4a4fd2b59273db10d13e5e0910ec5a7f-20230731163147-vmv80y8.png",alt:""}})]),v._v(" "),_("p",[v._v("首先启动 NameServer, 然后启动 Broker. Broker 启动后, 会主动找 NameServer 建立连接, 并将自己的信息注册到 NameServer 上. 注册完毕后, "),_("strong",[v._v("Broker 会周期性地给 NameServer 发送心跳包")]),v._v(", 比如每隔 1s 发送一次, 以告知 NameServer 自己还活着; 心跳包里还可以包括 Broker 当前存储的数据信息, 也就是说 Broker 可以周期性地向 NameServer 更新自己的数据信息, 以保证 NameServer 上存储的数据是最新的.")]),v._v(" "),_("p",[v._v("创建主题, 并确定这个主题的数据放入哪些 Broker 中.")]),v._v(" "),_("p",[_("strong",[v._v("当 Producer 生产消息发送到主题时, 需要先到 NameServer 查询该主题存放在哪些 Broker 中, 获取到相关 Broker 信息后, 将消息发送给这些 Broker 进行存储")]),v._v(".")]),v._v(" "),_("p",[v._v("Consumer 要从主题消费消息, 也需要首先到 NameServer 查询一下该主题的消息存储在哪些 Broker 上, 然后去相应的 Broker 获取消息进行消费.")]),v._v(" "),_("p",[v._v("接下来, 再看看"),_("strong",[v._v("消息队列模式适用于什么场景")]),v._v(".")]),v._v(" "),_("p",[v._v("消息队列模式, 是根据消费者需求到消息队列获取数据消费的, 消费者只需要知道消息队列地址即可, 消息队列中心也无需提前知道消费者信息. 也就是说, 这种模式对消费者没有特别需求, 因此比较适合消费者为临时用户的场景.")]),v._v(" "),_("p",[v._v("比如目前, 阿里内部将 RocketMQ 应用于购物交易, 充值, 消息推送等多个场景, 因为在这些场景下, 每个消费者不是常驻进程或服务, 几乎都是临时存在.")]),v._v(" "),_("blockquote",[_("p",[v._v("知识扩展: 发布订阅和消息队列模式都支持系统解耦, 两者是否一致呢?")])]),v._v(" "),_("p",[v._v("概括地说, 发布订阅和消息队列模式虽然都支持系统解耦, 但它们在实现时采用的数据结构和方式并不相同.")]),v._v(" "),_("p",[v._v("首先, 看一下它们实现解耦的数据结构.")]),v._v(" "),_("ol",[_("li",[v._v("发布订阅模式采用了消息中心, 消息队列模式采用了消息队列中心, 它们均用来存储生产者发布的数据, 并均有主题, Broker 等概念;")]),v._v(" "),_("li",[v._v("唯一不同之处, 是消息队列模式中采用了具有先进先出特征的队列结构进行存储, 而订阅发布采用了 map 或数组等方式存储.")])]),v._v(" "),_("p",[v._v("然后再看看它们实现解耦的方式.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("消息队列模式中, 生产者发布数据到消息队列中心, 消息队列中心会存储数据, 等待消费者按需获取数据")]),v._v(". 这样生产者就不需要和消费者进行直接通信了, 实现了生产者和消费者的解耦.")]),v._v(" "),_("li",[v._v("而在发布订阅模式中, 消费者需要提前向消息中心订阅自己感兴趣的数据, 待生产者发布数据到消息中心后, 消息中心根据订阅者订阅信息将数据主动推送给消费者, 也实现了消费者和生产者的解耦.")])]),v._v(" "),_("p",[v._v("对于消息队列模式, 消息队列中心无需提前获取消费者信息, 因此对消费者比较灵活, 适合消费者为临时用户的场景; 而发布订阅模式, 需要消费者提前向消息中心订阅消息, 也就是说消息中心需要提前获取消费者信息, 比较适合消费者为长驻进程或服务的场景.")]),v._v(" "),_("h5",{attrs:{id:"总结-18"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-18"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享的是分布式通信技术中的消息队列模式. 首先通过用户注册的案例, 介绍了什么是消息队列模式, 以及它的好处. 其中, 消息队列模式中的核心是以一种具有先进先出特点的队列结构来存储数据, 实现组件间的解耦和异步执行.")]),v._v(" "),_("p",[v._v("然后介绍了消息队列的基本原理, 并以 RocketMQ 为例对其架构, 核心组件和工作原理做了更深入的讲解, 以帮助你进一步了解消息队列模型.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/eceda38a0bd0e9e104d67489f8e2880a-20230731163147-x167a3z.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"分布式数据存储"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式数据存储"}},[v._v("#")]),v._v(" 分布式数据存储")]),v._v(" "),_("h4",{attrs:{id:"_23-cap理论-这顶帽子我不想要"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_23-cap理论-这顶帽子我不想要"}},[v._v("#")]),v._v(" 23-CAP理论:这顶帽子我不想要")]),v._v(" "),_("p",[v._v("开篇词中将分布式计算划分为了四横四纵. 前面已经学习了四横中的分布式计算, 分布式通信和分布式资源池化三横的相关知识. 比如, 在分布式计算中, 学习了分布计算模式, 包括 MapReduce, Stream, Actor 和流计算的原理和实际应用; 在分布式通信中, 学习了远程调用, 订阅发布和消息队列模式的原理和应用; 在分布式资源池化中, 学习了分布式系统架构和分布式调度架构.")]),v._v(" "),_("p",[v._v("相信通过对这些内容的学习, 你已经对分布式技术有比较深刻的了解了. 分布式系统处理的关键对象是数据, 前面这些文章也都是为数据处理服务的. 那么, "),_("strong",[v._v("数据本身相关的分布式技术")]),v._v('有哪些呢? 这就是接下来的几讲, 将学习的四横中的最后一横 "分布式数据存储与管理" 的相关技术.')]),v._v(" "),_("p",[v._v("在正式介绍分布式数据存储技术之前, 需要先带了解一个基本理论, 也就是 CAP 理论. 前面提到, 分布式系统处理的关键对象是数据, 而数据其实是与用户息息相关的. CAP 理论指导分布式系统的设计, 以保证系统的可用性, 数据一致性等特征. 比如电商系统中, 保证用户可查询商品数据, 保证不同地区访问不同服务器查询的数据是一致的等.")]),v._v(" "),_("h5",{attrs:{id:"什么是cap"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是cap"}},[v._v("#")]),v._v(" 什么是CAP?")]),v._v(" "),_("p",[v._v("先来看看"),_("strong",[v._v("这三个字母分别指的是什么")]),v._v(". 接下来结合电商的例子, 带你理解 CAP 的含义.")]),v._v(" "),_("p",[v._v("假设某电商, 在北京, 杭州, 上海三个城市建立了仓库, 同时建立了对应的服务器 "),_("code",[v._v("{A, B, C}")]),v._v("​ 用于存储商品信息. 比如, 某电吹风在北京仓库有 20 个, 在杭州仓库有 10 个, 在上海仓库有 30 个. 那么, CAP 这三个字母在这个例子中分别代表什么呢?")]),v._v(" "),_("p",[_("strong",[v._v("C 代表 Consistency")]),v._v(", 一致性是指"),_("strong",[v._v("所有节点在同一时刻的数据是相同的, 即更新操作执行结束并响应用户完成后, 所有节点存储的数据会保持相同")]),v._v(". 在电商系统中, A, B, C 中存储的该电吹风的数量应该是 20+10+30=60. 假设, 现在有一个北京用户买走一个电吹风, 服务器 A 会更新数据为 60-1=59, 与此同时要求 B 和 C 也更新为 59, 以保证在同一时刻, 无论访问 A, B, C 中的哪个服务器, 得到的数据均是 59.")]),v._v(" "),_("p",[_("strong",[v._v("A 代表 Availability, 可用性是指系统提供的服务一直处于可用状态, 对于用户的请求可即时响应")]),v._v(". 在电商系统中, 用户在任一时刻向 A, B, C 中的任一服务器发出请求时, 均可得到即时响应, 比如查询商品信息等.")]),v._v(" "),_("p",[_("strong",[v._v("P 代表 Partition Tolerance")]),v._v(", "),_("strong",[v._v("分区容错性是指在分布式系统遇到网络分区的情况下, 仍然可以响应用户的请求")]),v._v(". 网络分区是指因为网络故障导致网络不连通, 不同节点分布在不同的子网络中, 各个子网络内网络正常. 在电商系统中, 假设 C 与 A 和 B 的网络都不通了, A 和 B 是相通的. 也就是说, 形成了两个分区 {A, B} 和 {C}, 在这种情况下, 系统仍能响应用户请求.")]),v._v(" "),_("p",[v._v("一致性, 可用性和分区容错性, 就是分布式系统的三个特征. 那么平时说的 "),_("strong",[v._v("CAP 理论又是什么呢")]),v._v("?")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("CAP 理论指的就是, 在分布式系统中 C, A, P 这三个特征不能同时满足, 只能满足其中两个")])]),v._v(", 如下图所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/03f5bdccbbee355baa138fe8442be861-20230731163147-1anhsu3.png",alt:""}})]),v._v(" "),_("p",[v._v("接下来就通过一个例子进一步解释下, "),_("strong",[v._v("什么是 CAP 以及 CAP 为什么不能同时满足")]),v._v(".")]),v._v(" "),_("p",[v._v("如下图所示, 网络中有两台服务器 Server1 和 Server2, 分别部署了数据库 DB1 和 DB2, 这两台机器组成一个服务集群, DB1 和 DB2 两个数据库中的数据要保持一致, 共同为用户提供服务. 用户 User1 可以向 Server1 发起查询数据的请求, 用户 User2 可以向服务器 Server2 发起查询数据的请求, 它们共同组成了一个分布式系统.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e2ea2a115cf8f871374c03d01dc13103-20230731163147-l4fd3nh.png",alt:""}})]),v._v(" "),_("p",[v._v("对这个系统来说, 分别满足 C, A 和 P 指的是:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("在满足一致性 C 的情况下, Server1 和 Server2 中的数据库始终保持一致, 即 DB1 和 DB2 内容要始终保持相同")]),v._v(";")]),v._v(" "),_("li",[_("strong",[v._v("在满足可用性 A 的情况下, 用户无论访问 Server1 还是 Server2, 都会得到即时响应;")])]),v._v(" "),_("li",[_("strong",[v._v("在满足分区容错性 P 的情况下, Server1 和 Server2 之间即使出现网络故障也不会影响 Server1 和 Server2 分别处理用户的请求.")])])]),v._v(" "),_("p",[_("strong",[v._v("当用户发起请求时, 收到请求的服务器会及时响应, 并将用户更新的数据同步到另一台服务器, 保证数据一致性")]),v._v(". 具体的工作流程, 如下所示:")]),v._v(" "),_("ul",[_("li",[v._v("用户 User1 向服务器 Server1 发起请求, 将数据库 DB1 中的数据 a 由 1 改为 2;")]),v._v(" "),_("li",[v._v("系统会进行数据同步, 即图中的 S 操作, 将 Server1 中 DB1 的修改同步到服务器 Server2 中, 使得 DB2 中的数据 a 也被修改为 2;")]),v._v(" "),_("li",[v._v("当 User2 向 Server2 发起读取数据 a 的请求时, 会得到 a 最新的数据值 2.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a4a27468cae924d179432830a30e6589-20230731163147-inspf5g.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v('这其实是在网络环境稳定, 系统无故障的情况下的工作流程. 但在实际场景中, 网络环境不可能百分之百不出故障, 比如网络拥塞, 网卡故障等, 会导致网络故障或不通, 从而导致节点之间无法通信, 或者集群中节点被划分为多个分区, 分区中的节点之间可通信, 分区间不可通信. 这种由网络故障导致的集群分区情况, 通常被称为 "网络分区".')])]),v._v(" "),_("p",[v._v("在分布式系统中, "),_("mark",[_("strong",[v._v("网络分区不可避免, 因此分区容错性 P 必须满足")])]),v._v(". 接下来就讨论一下"),_("strong",[v._v("在满足分区容错性 P 的情况下, 一致性 C 和可用性 A 是否可以同时满足.")])]),v._v(" "),_("p",[v._v("假设 Server1 和 Server2 之间网络出现故障, User1 向 Server1 发送请求, 将数据库 DB1 中的数据 a 由 1 修改为 2, 而 Server2 由于与 Server1 无法连接导致数据无法同步, 所以 DB2 中 a 依旧是 1. 这时 "),_("strong",[v._v("User2 向 Server2 发送读取数据 a 的请求时, Server2 无法给用户返回最新数据, 那该如何处理呢?")])]),v._v(" "),_("p",[v._v("能想到的处理方式有如下两种.")]),v._v(" "),_("p",[v._v("第一种处理方式是, "),_("mark",[_("strong",[v._v("保证一致性 C, 牺牲可用性 A")])]),v._v(": Server2 选择让 User2 的请求阻塞, 一直等到网络恢复正常, Server1 被修改的数据同步更新到 Server2 之后, 即 DB2 中数据 a 修改成最新值 2 后, 再给用户 User2 响应.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1657b442dba48ae53cafd2860579652a-20230731163147-j24fxxl.png",alt:""}})]),v._v(" "),_("p",[v._v("第二种处理方式是, "),_("mark",[_("strong",[v._v("保证可用性 A, 牺牲一致性 C")])]),v._v(": Server2 选择将旧的数据 a=1 返回给用户, 等到网络恢复, 再进行数据同步.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6d62d401f15b4f936507563fa3a51fb6-20230731163147-74h0oay.png",alt:""}})]),v._v(" "),_("p",[v._v("除了以上这两种方案, 没有其他方案可以选择. 可以看出: "),_("strong",[v._v("在满足分区容错性 P 的前提下, 一致性 C 和可用性 A 只能选择一个, 无法同时满足")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"cap选择策略及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#cap选择策略及应用"}},[v._v("#")]),v._v(" CAP选择策略及应用")]),v._v(" "),_("p",[v._v("通过上面的分析, 已经知道了分布式系统无法同时满足 CAP 这三个特性, 那该如何进行取舍呢?")]),v._v(" "),_("p",[v._v("其实 C, A 和 P, 没有谁优谁劣, 只是不同的分布式场景适合不同的策略. 接下来"),_("strong",[v._v("就以一些具体场景为例, 分别介绍保 CA 弃 P, 保 CP 弃 A, 保 AP 弃 C 这三种策略, 以帮助你面对不同的分布式场景时, 知道如何权衡这三个特征.")])]),v._v(" "),_("p",[v._v("比如, 对于涉及钱的交易时, 数据的一致性至关重要, 因此保 CP 弃 A 应该是最佳选择. 2015 年发生的支付宝光纤被挖断的事件, 就导致支付宝就出现了不可用的情况. 显然支付宝当时的处理策略就是, 保证了 CP 而牺牲了 A.")]),v._v(" "),_("p",[v._v("而对于其他场景, 大多数情况下的做法是选择 AP 而牺牲 C, 因为很多情况下不需要太强的一致性(数据始终保持一致), 只要满足最终一致性即可. 最终一致性指的是, 不要求集群中节点数据每时每刻保持一致, 在"),_("strong",[v._v("可接受的时间内最终能达到一致")]),v._v("就可以了. 前面介绍的基于分布式消息的最终一致性方案对事务进行处理时, 就是选择 AP 而牺牲 C 的例子. 这个方案中, 在应用节点之间引入了消息中间件, 不同节点之间通过消息中间件进行交互, 比如主应用节点要执行修改数据的事务, 只需要将信息推送到消息中间件, 即可执行本地的事务, 而不需要备应用节点同意修改数据才能真正执行本地事务, 备应用节点可以从消息中间件获取数据.")]),v._v(" "),_("h6",{attrs:{id:"保ca弃p"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#保ca弃p"}},[v._v("#")]),v._v(" 保CA弃P")]),v._v(" "),_("p",[v._v("首先看一下保 CA 弃 P 的策略.")]),v._v(" "),_("p",[v._v("在分布式系统中, 现在的网络基础设施无法做到始终保持稳定, 网络分区(网络不连通)难以避免. 牺牲分区容错性 P, 就相当于放弃使用分布式系统. 因此在分布式系统中, 这种策略不需要过多讨论.")]),v._v(" "),_("p",[v._v("既然"),_("strong",[v._v("分布式系统不能采用这种策略")]),v._v(", 那单点系统毫无疑问就需要满足 CA 特性了. 比如关系型数据库 DBMS(比如 MySQL, Oracle)部署在单台机器上, 因为不存在网络通信问题, 所以保证 CA 就可以了.")]),v._v(" "),_("h6",{attrs:{id:"保cp弃a"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#保cp弃a"}},[v._v("#")]),v._v(" 保CP弃A")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("如果一个分布式场景需要很强的数据一致性, 或者该场景可以容忍系统长时间无响应的情况下, 保 CP 弃 A 这个策略就比较适合")])]),v._v(".")]),v._v(" "),_("p",[v._v("一个保证 CP 而舍弃 A 的分布式系统, 一旦发生网络分区会导致数据无法同步情况, 就要牺牲系统的可用性, 降低用户体验, 直到节点数据达到一致后再响应用户. 这种策略通常用在涉及"),_("strong",[v._v("金钱交易")]),v._v("的分布式场景下, 因为它任何时候都不允许出现数据不一致的情况, 否则就会给用户造成损失. 因此, 这种场景下必须保证 CP.")]),v._v(" "),_("p",[v._v("保证 CP 的系统有很多, 典型的有 "),_("mark",[_("strong",[v._v("Redis, HBase, ZooKeeper")])]),v._v(" 等. 接下来就"),_("strong",[v._v("以 ZooKeeper 为例来了解它是如何保证 CP 的.")])]),v._v(" "),_("p",[v._v("首先看一下 ZooKeeper 架构图.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/de5e7e7222394880636513f6f6f42333-20230731163147-10wexhg.png",alt:""}})]),v._v(" "),_("p",[v._v("ZooKeeper 集群包含多个节点(Server), 这些节点会通过分布式选举算法选出一个 Leader 节点. 在 ZooKeeper 中选举 Leader 节点采用的是 ZAB 算法.")]),v._v(" "),_("p",[v._v("在 ZooKeeper 集群中, Leader 节点之外的节点被称为 Follower 节点, "),_("strong",[v._v("Leader 节点会专门负责处理用户的写请求")]),v._v(":")]),v._v(" "),_("ol",[_("li",[v._v("当用户向节点发送写请求时, 如果请求的节点刚好是 Leader, 那就直接处理该请求;")]),v._v(" "),_("li",[_("strong",[v._v("如果请求的是 Follower 节点, 那该节点会将请求转给 Leader, 然后 Leader 会先向所有的 Follower 发出一个 Proposal, 等超过一半的节点同意后, Leader 才会提交这次写操作, 从而保证了数据的强一致性.")])])]),v._v(" "),_("p",[v._v("具体示意图如下所示:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/32927592923edea11a2eab822af2747e-20230731163147-89t0g0i.png",alt:""}})]),v._v(" "),_("p",[v._v("当出现网络分区时, 如果其中一个分区的节点数大于集群总节点数的一半, 那么这个分区可以再选出一个 Leader, 仍然对用户提供服务, 但在选出 Leader 之前, 不能正常为用户提供服务; 如果形成的分区中, 没有一个分区的节点数大于集群总节点数的一半, 那么系统不能正常为用户提供服务, 必须待网络恢复后, 才能正常提供服务.")]),v._v(" "),_("p",[_("strong",[v._v("这种设计方式保证了分区容错性, 但牺牲了一定的系统可用性.")])]),v._v(" "),_("h6",{attrs:{id:"保ap弃c"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#保ap弃c"}},[v._v("#")]),v._v(" 保AP弃C")]),v._v(" "),_("p",[_("strong",[v._v("如果一个分布式场景需要很高的可用性, 或者说在网络状况不太好的情况下, 该场景允许数据暂时不一致, 那这种情况下就可以牺牲一定的一致性了")]),v._v(".")]),v._v(" "),_("p",[v._v("网络分区出现后, 各个节点之间数据无法马上同步, 为了保证高可用, 分布式系统需要即刻响应用户的请求. 但此时可能某些节点还没有拿到最新数据, 只能将本地旧的数据返回给用户, 从而导致数据不一致的情况.")]),v._v(" "),_("p",[_("strong",[v._v("适合保证 AP 放弃 C 的场景有很多.")]),v._v("  比如很多查询网站, 电商系统中的商品查询等, 用户体验非常重要, 所以大多会保证系统的可用性, 而牺牲一定的数据一致性.")]),v._v(" "),_("p",[v._v("以电商购物系统为例, 如下图所示, 某电吹风在北京仓库有 20 个, 在杭州仓库有 10 个, 在上海仓库有 30 个. 初始时, 北京, 杭州, 上海分别建立的服务器 "),_("code",[v._v("{A, B, C}")]),v._v("​ 存储该电吹风的数量均为 60 个.")]),v._v(" "),_("p",[v._v("假如, 上海的网络出现了问题, 与北京和杭州网络均不通, 此时北京的用户通过北京服务器 A 下单购买了一个电吹风, 电吹风数量减少到 59, 并且同步给了杭州服务器 B. 也就是说, 现在用户的查询请求如果是提交到服务器 A 和 B, 那么查询到的数量为 59. 但通过上海服务器 C 进行查询的结果, 却是 60.")]),v._v(" "),_("p",[v._v("当然, 待网络恢复后, 服务器 A 和 B 的数据会同步到 C, C 更新数据为 59, 最终三台服务器数据保持一致, 用户刷新一下查询界面或重新提交一下查询, 就可以得到最新的数据. 而对用户来说, 他们并不会感知到前后数据的差异, 到底是因为其他用户购买导致的, 还是因为网络故障导致数据不同步而产生的.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f7d6ceb3113b7151bc7242434e50f97e-20230731163147-ebb7kn2.png",alt:""}})]),v._v(" "),_("p",[v._v("当然, 你可能会说, 为什么上海服务器不能等网络恢复后, 再响应用户请求呢? 可以想象一下, 如果用户提交一个查询请求, 需要等上几分钟, 几小时才能得到反馈, 那么用户早已离去了. 也就是说这种场景适合优先保证 AP, 因为如果等到数据一致之后再给用户返回的话, 用户的响应太慢, 可能会造成严重的用户流失.")]),v._v(" "),_("p",[v._v("目前, 采用保 AP 弃 C 的系统也有很多, 比如 "),_("strong",[v._v("CoachDB, Eureka, Cassandra, DynamoDB")]),v._v(" 等.")]),v._v(" "),_("h6",{attrs:{id:"对比分析-2"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比分析-2"}},[v._v("#")]),v._v(" 对比分析")]),v._v(" "),_("p",[v._v("总结一下.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/fe740ae4bf7d734b8915d526fb57883f-20230731163147-nxxd35s.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-cap和acid的-c-a-是一样的吗"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-cap和acid的-c-a-是一样的吗"}},[v._v("#")]),v._v(' 知识扩展:CAP和ACID的"C""A"是一样的吗?')]),v._v(" "),_("p",[v._v("首先看一下 CAP 中的 C 和 ACID 中的 C 是否一致.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("CAP 中的 C 强调的是数据的一致性")]),v._v(", 也就是集群中节点之间通过复制技术保证每个节点上的数据在同一时刻是相同的.")]),v._v(" "),_("li",[_("strong",[v._v("ACID 中的 C 强调的是事务执行前后, 数据的完整性保持一致或满足完整性约束")]),v._v(". 也就是不管在什么时候, 不管并发事务有多少, 事务在分布式系统中的状态始终保持一致.")])]),v._v(" "),_("p",[v._v("其次看一下 CAP 中的 A 和 ACID 中的 A.")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("CAP 中的 A 指的是可用性(Availability)")]),v._v(" , 也就是系统提供的服务一直处于可用状态, 即对于用户的请求可即时响应.")]),v._v(" "),_("li",[_("strong",[v._v("ACID 中的 A 指的是原子性(Atomicity)")]),v._v(" , 强调的是事务要么执行成功, 要么执行失败.")])]),v._v(" "),_("p",[v._v('因此, CAP 和 ACID 中的 "C" 和 "A" 是不一样的, 不能混为一谈.')]),v._v(" "),_("h5",{attrs:{id:"总结-19"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-19"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1060ac8b5642d4c1fb6a1121f2a8ab59-20230731163147-tyo96s4.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_24-分布式数据存储系统之三要素-顾客-导购与货架"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_24-分布式数据存储系统之三要素-顾客-导购与货架"}},[v._v("#")]),v._v(" 24-分布式数据存储系统之三要素:顾客,导购与货架")]),v._v(" "),_("p",[v._v("上一节学习了 CAP 理论. 该理论指出, 在分布式系统中, 不能同时满足一致性, 可用性和分区容错性, 指导了分布式数据存储系统的设计.")]),v._v(" "),_("p",[v._v("随着数据量和访问量的增加, 单机性能已经不能满足用户需求, 分布式集群存储成为一种常用方式. 把数据分布在多台存储节点上, 可以为大规模应用提供大容量, 高性能, 高可用, 高扩展的存储服务. 而分布式存储系统就是其具体实现.")]),v._v(" "),_("p",[v._v("本节学习"),_("strong",[v._v("分布式存储系统的关键三要素")]),v._v(", 让你对分布式数据存储系统有一个直观的理解. 后面会针对这三要素中的关键技术进一步展开, 以更深入地理解分布式数据存储系统.")]),v._v(" "),_("h5",{attrs:{id:"什么是分布式数据存储系统"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分布式数据存储系统"}},[v._v("#")]),v._v(" 什么是分布式数据存储系统?")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("分布式存储系统的核心逻辑, 就是将用户需要存储的数据根据某种规则存储到不同的机器上, 当用户想要获取指定数据时, 再按照规则到存储数据的机器里获取.")])])]),v._v(" "),_("p",[v._v("如下图所示, 当用户(即应用程序)想要访问数据 D, "),_("strong",[v._v("分布式操作引擎通过一些映射方式, 比如 Hash, 一致性 Hash, 数据范围分类等, 将用户引导至数据 D 所属的存储节点获取数据")]),v._v(".")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4cc19441012a0d224c35bdc1db81dfff-20230731163147-0l1lumg.png",alt:""}})]),v._v(" "),_("p",[v._v("静下心来想一下, 获取数据的整个过程与到商店购物的过程是不是有些类似呢?")]),v._v(" "),_("p",[v._v("顾客到商店购物时, 导购会根据顾客想要购买的商品引导顾客到相应的货架, 然后顾客从这个货架上获取要购买的商品, 完成购物. 这里的顾客就是图中的应用程序, 导购就相当于分布式操作引擎, 它会按照一定的规则找到相应的货架, 货架就是存储数据的不同机器节点.")]),v._v(" "),_("p",[v._v("其实这个过程就是分布式存储系统中获取数据的通用流程, "),_("strong",[v._v("顾客, 导购和货架")]),v._v("组成了分布式存储系统的三要素, 分别对应着分布式领域中的"),_("strong",[v._v("数据生产者/消费者, 数据索引和数据存储")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来就详细看看这三个要素.")]),v._v(" "),_("h5",{attrs:{id:"分布式数据存储系统三要素"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式数据存储系统三要素"}},[v._v("#")]),v._v(" 分布式数据存储系统三要素")]),v._v(" "),_("p",[v._v("顾客就是数据的生产者和消费者, 也就是说顾客代表两类角色, 生产者会生产数据(比如, 商店购物例子中的供货商就属于生产类顾客), 将数据存储到分布式数据存储系统中, 消费者是从分布式数据存储系统中获取数据进行消费(比如, 商店购物例子中购买商品的用户就属于消费类顾客); 导购就是数据索引, 将访问数据的请求转发到数据所在的存储节点; 货架就是存储设备, 用于存储数据.")]),v._v(" "),_("h6",{attrs:{id:"顾客-生产和消费数据"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#顾客-生产和消费数据"}},[v._v("#")]),v._v(" 顾客:生产和消费数据")]),v._v(" "),_("p",[v._v("顾客相当于分布式存储系统中的应用程序, 而数据是应用程序的原动力. "),_("strong",[v._v("根据数据的产生和使用, 顾客分为生产者和消费者两种类型. 生产者负责给存储系统添加数据, 而消费者则可以使用系统中存储的数据")]),v._v(".")]),v._v(" "),_("p",[v._v("就像是火车票存储系统, 如图所示, 铁路局就相当于生产者类型的顾客, 而乘客就相当于消费者类型的顾客. 铁路局将各个线路的火车票信息发布到订票网站的后台数据库中, 乘客通过订票网站访问数据库, 来进行查询余票, 订票, 退票等操作.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/97ebfcaacdf2695d4643b175f3378f86-20230731163147-x44iwz1.png",alt:""}})]),v._v(" "),_("p",[v._v("生产者和消费者生产和消费的数据通常是多种多样的, 不同应用场景中数据的类型, 格式等都不一样. **根据数据的特征, 这些不同的数据通常被划分为三类: 结构化数据, 半结构化数据和非结构化数据. **")]),v._v(" "),_("ol",[_("li",[v._v("结构化数据通常是指关系模型数据, 其特征是数据关联较大, 格式固定. 火车票信息比如起点站, 终点站, 车次, 票价等, 就是一种结构化数据. "),_("strong",[v._v("结构化数据具有格式固定的特征, 因此一般采用分布式关系数据库进行存储和查询")]),v._v(".")]),v._v(" "),_("li",[v._v("半结构化数据通常是指非关系模型的, 有基本固定结构模式的数据, 其特征是数据之间关系比较简单. 比如 HTML 文档, 使用标签书写内容. 半结构化数据大多可以采用键值对形式来表示, 比如 HTML 文档可以将标签设置为 key, 标签对应的内容可以设置为 value, 因此"),_("strong",[v._v("一般采用分布式键值系统进行存储和使用")]),v._v(".")]),v._v(" "),_("li",[_("strong",[v._v("非结构化数据是指没有固定模式的数据, 其特征是数据之间关联不大")]),v._v(". 比如文本数据就是一种非结构化数据. 这种数据可以存储到文档中, 通过 "),_("strong",[v._v("ElasticSearch")]),v._v("(一个分布式全文搜索引擎)等进行检索.")])]),v._v(" "),_("h6",{attrs:{id:"导购-确定数据位置"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#导购-确定数据位置"}},[v._v("#")]),v._v(" 导购:确定数据位置")]),v._v(" "),_("p",[v._v("导购是分布式存储系统必不可少的要素, 如果没有导购, 顾客就需要逐个货架去寻找自己想要的商品. 想象一下, 如果去订票网站订火车票, 按照自己的需求点击查询车票后, 系统会逐个扫描分布式存储系统中每台机器的数据, 寻找你想要购买的火车票. 如果系统中存储的数据不多, 响应时间也不会太长, 毕竟计算机的速度还是很快的; 但如果数据分布在几千台甚至上万台机器中, 系统逐个机器扫描后再给你响应, 我相信你会对这个订票网站很失望.")]),v._v(" "),_("p",[v._v("这种定位数据存储位置的方式会浪费很多时间, 严重影响购票体验. 因此在分布式存储系统中, 必须有相应的数据导购, 否则系统响应会很慢, 效率很低. 为解决这个问题, "),_("strong",[v._v("数据分片技术")]),v._v("就走入了分布式存储系统的大家庭.")]),v._v(" "),_("p",[_("strong",[v._v("数据分片技术, 是指分布式存储系统按照一定的规则将数据存储到相对应的存储节点中")]),v._v(", 或者到相对应的存储节点中获取想要的数据, 这是一种很常用的导购技术. 这种技术, 一方面可以降低单个存储节点的存储和访问压力; 另一方面, 可以通过规定好的规则快速找到数据所在的存储节点, 从而大大降低搜索延迟, 提高用户体验.")]),v._v(" "),_("p",[v._v("也就是说, 当铁路局发布各个线路的火车票信息时, 会按照一定规则存储到相应的机器中, 比如北京到上海的火车票存储到机器 A 中, 西安到重庆的火车票存储到机器 B 中. 当乘客查询火车票时, 系统就可以根据查询条件迅速定位到相对应的存储机器, 然后将数据返回给用户, 响应时间就大大缩短了. 如图所示, 当查询北京-上海的火车票相关信息时, 可以与机器 A 进行数据交互.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4d81d4d7a07788b9bcc40578ef255083-20230731163147-whc79iv.png",alt:""}})]),v._v(" "),_("p",[v._v("这个例子中按照数据起点, 终点的方式划分数据, 将数据分为几部分存储到不同的机器节点中, 就是数据分片技术的一种. 当查询数据时, 系统可以根据查询条件迅速找到对应的存储节点, 从而实现快速响应.")]),v._v(" "),_("p",[v._v("上述的例子中, "),_("strong",[v._v("按照数据特征进行了数据分片, 当然还有其他很多数据分片的方案. 比如按照数据范围, 采用哈希映射, 一致性哈希环等对数据划分")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来, 就"),_("strong",[v._v("针对数据范围这种数据分片方案做一个具体介绍")]),v._v(".")]),v._v(" "),_("p",[v._v("针对数据范围的数据分片方案是指, 按照某种规则划分数据范围, 然后将在这个范围内的数据归属到一个集合中. 这就好比数学中通常讲的整数区间, 比如 1～1000 的整数, "),_("code",[v._v("[1,100]")]),v._v("​ 的整数属于一个子集, "),_("code",[v._v("[101,1000]")]),v._v("​ 的整数属于另一个子集.")]),v._v(" "),_("p",[v._v("对于前面讲的火车票的案例, 按照数据范围分片的话, 可以将属于某条线的所有火车票数据划分到一个子集或分区进行存储, 比如机器 A 存储京广线的火车票数据, 机器 B 存储京沪线的火车票数据. 也就是说, 数据范围的方案是按照范围或区间进行存储或查询.")]),v._v(" "),_("p",[v._v("如图所示, 当用户查询北京-上海的火车票相关信息时, 首先判断查询条件属于哪个范围, 由于北京-上海的火车线路属于京沪线, 因此系统按照规则将查询请求转到存取京沪线火车票数据的机器 B, 然后由机器 B 进行处理并给用户返回响应结果.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f504b679c9d241db18e01fab4d7323ab-20230731163147-8a3xhym.png",alt:""}})]),v._v(" "),_("p",[v._v("为了提高分布式系统的可用性与可靠性, "),_("mark",[_("strong",[v._v("除了通过数据分片减少单个节点的压力外, 数据复制也是一个非常重要的方法. 数据复制就是将数据进行备份, 以使得多个节点存储该数据")])]),v._v(".")]),v._v(" "),_("p",[v._v("想象一下, 当某个存储节点出现故障时, 如果只采用数据分片技术, 那这个节点的数据就会丢失, 从而给用户造成损失. 因此, 数据复制在分布式存储系统中是不可或缺的. 关于数据复制技术, 会在后面详细讲解.")]),v._v(" "),_("p",[v._v("接下来说说数据复制和数据分片技术的区别. 关于它们之间的区别, 可以先看看下面这张图片:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/afd132626257f1239ee5cb6e8df8d275-20230731163147-l4vge06.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("数据 A 被拆分为两部分存储在两个节点 Node1 和 Node2 上, 属于数据分片; 而对数据 B 来说, 同一份完整的数据在两个节点中均有存储, 就属于数据复制")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("在实际的分布式存储系统中, 数据分片和数据复制通常是共存的")]),v._v(":")]),v._v(" "),_("ol",[_("li",[v._v("数据通过分片方式存储到不同的节点上, 以减少单节点的性能瓶颈问题;")]),v._v(" "),_("li",[v._v("而数据的存储通常用主备方式保证可靠性, 也就是对每个节点上存储的分片数据, 采用主备方式存储, 以保证数据的可靠性. 其中, 主备节点上数据的一致, 是通过数据复制技术实现的.")])]),v._v(" "),_("p",[v._v("讲到这里再回忆下前面 Kafka 集群的总体架构图. 我从中抽取出 Kafka 集群消息存储架构图, 如下所示.")]),v._v(" "),_("p",[v._v("消息数据以 Partition(分区)进行存储, 一个 Topic(主题)可以由多个 Partition 进行存储, Partition 可以分布到多个 Broker 中; 同时, Kafka 还提供了 Partition 副本机制(对分区存储的信息进行备份, 比如 Broker 1 中的 Topic-1 Partion-0 是对 Broker 0 上的 Topic-1 Partition-0 进行的备份), 从而保证了消息存储的可靠性.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c009de2b875bfb63af78f5946383f3db-20230731163147-mrafs85.png",alt:""}})]),v._v(" "),_("p",[v._v("这就是数据分片和数据复制共存的一个典型应用场景.")]),v._v(" "),_("h6",{attrs:{id:"货架-存储数据"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#货架-存储数据"}},[v._v("#")]),v._v(" 货架:存储数据")]),v._v(" "),_("p",[v._v("货架是用来存储数据的, 因为数据是由顾客产生和消费的, "),_("strong",[v._v("因此货架存储的数据类型与顾客产生和消费的数据类型是一致的, 即包括结构化数据, 半结构化数据和非结构化数据")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v('针对这三种不同的数据类型, 存储 "货架" 可以大致划分为以下三种')]),v._v(":")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("分布式数据库, 通过表格来存储结构化数据, 方便查找")]),v._v(". 常用的分布式数据库有 MySQL Sharding, Microsoft SQL Azure, Google Spanner, Alibaba OceanBase 等.")]),v._v(" "),_("li",[_("strong",[v._v("分布式键值系统, 通过键值对来存储半结构化数据")]),v._v(". 常用的分布式键值系统有 Redis, Memcache 等, 可用作缓存系统.")]),v._v(" "),_("li",[_("strong",[v._v("分布式存储系统, 通过文件, 块, 对象等来存储非结构化数据")]),v._v(". 常见的分布式存储系统有 Ceph, GFS, HDFS, Swift 等.")])]),v._v(" "),_("p",[v._v("而**对货架材料也就是存储介质的选择, 本质就是选择将数据存储在磁盘还是内存(缓存)上: **")]),v._v(" "),_("ol",[_("li",[v._v("磁盘存储量大, 但 IO 开销大, 访问速度较低, 常用于存储不经常使用的数据. 比如电商系统中, 排名比较靠后或购买量比较少, 甚至无人购买的商品信息, 通常就存储在磁盘上.")]),v._v(" "),_("li",[v._v("内存容量小, 访问速度快, 因此常用于存储需要经常访问的数据. 比如电商系统中, 购买量比较多或排名比较靠前的商品信息, 通常就存储在内存中.")])]),v._v(" "),_("h5",{attrs:{id:"知识扩展-业界主流的分布式数据存储系统有哪些"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-业界主流的分布式数据存储系统有哪些"}},[v._v("#")]),v._v(" 知识扩展:业界主流的分布式数据存储系统有哪些?")]),v._v(" "),_("p",[v._v('在前面介绍货架的时候, 有提到针对结构化数据, 半结构化数据和非结构化数据, 分别对应不同的 "货架", 即分布式数据库, 分布式键值系统和分布式文件系统进行存储.')]),v._v(" "),_("p",[v._v("在这里重点对比分析分布式数据库和分布式文件系统的几款主流的系统, 以便于理解和选型. 首先看一下主流的分布式数据库, 主要包括 MySQL Sharding, SQL Azure, Spanner, OceanBase 等, 具体对比分析如下表所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f7a12fc200b65de66f4651ca6217eec9-20230731163147-hh0alky.png",alt:""}})]),v._v(" "),_("p",[v._v("然后看一下主流的分布式存储系统, 主要包括 Ceph, GFS, HDFS 和 Swift 等, 具体对比分析如下所示.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/644e97429ff9f3c7ea3d37f9c7852179-20230731163147-mzgy9h4.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"总结-20"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-20"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享的是分布式数据存储系统的三要素, 即顾客, 导购和货架, 对应到分布式领域的术语就是数据生产者/消费者, 数据索引和数据存储.")]),v._v(" "),_("p",[v._v("其中, 顾客包括产生数据的顾客和消费数据的顾客两类; 导购, 就是数据索引引擎, 包括数据存储时确定数据位置, 以及获取数据时确定数据所在位置; 货架, 负责数据存储, 包括磁盘, 缓存等存储介质等.")]),v._v(" "),_("p",[v._v("不同应用场景中, 顾客产生的数据类型, 格式等通常都不一样. 根据数据的特征, 这些不同的数据可以被划分为三类: 结构化数据, 半结构化数据和非结构化数据. 与之相对应的, 货架也就是数据存储系统, 也包括三类: 分布式数据库, 分布式键值系统和分布式文件系统.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/8b0397878045035b30f1bc54d3d3e3e4-20230731163147-uze0aa7.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_25-数据分布方式之哈希与一致性哈希-掐指一算-与-掐指两算-的事"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_25-数据分布方式之哈希与一致性哈希-掐指一算-与-掐指两算-的事"}},[v._v("#")]),v._v(' 25-数据分布方式之哈希与一致性哈希:"掐指一算"与"掐指两算"的事')]),v._v(" "),_("p",[v._v("上一节了解了分布式存储系统的三个要素: 顾客, 导购和货架. 其中, 导购实现了分布式数据存储系统中数据索引的功能, 包括存储数据时确定存储位置, 以及获取数据时确定数据所在位置. 那么, 在分布式系统中, 具体是如何实现数据索引或数据分布的呢? 目前最常用的方法就是"),_("strong",[v._v("哈希和一致性哈希")]),v._v(".")]),v._v(" "),_("p",[v._v("首先来看一下"),_("strong",[v._v("数据分布设计的原则")]),v._v(". 数据分布设计原则是分布式存储系统设计的基本原则, 指导了哈希和一致性哈希方法的选择和应用.")]),v._v(" "),_("h5",{attrs:{id:"数据分布设计原则"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据分布设计原则"}},[v._v("#")]),v._v(" 数据分布设计原则")]),v._v(" "),_("p",[v._v("其实, 这里的数据分布, 主要就是"),_("strong",[v._v("数据分片")]),v._v(". 数据分片解决了确定数据位置的问题, 本节主要讲解按照数据范围, 采用哈希, 一致性哈希等对数据划分的方法.")]),v._v(" "),_("p",[v._v("假设现在有上百 G 数据需要进行分布式存储, 也就是要存储到不同的节点上. 提到这个问题, 你可能立刻就会想到很多种方法, 比如"),_("strong",[v._v("随机分布, 范围分布, 映射分布")]),v._v("等. 那么应该如何选择到底要使用哪种方法呢?")]),v._v(" "),_("p",[_("strong",[v._v("在分布式数据存储系统中, 存储方案选型时, 通常会考虑")]),v._v("​"),_("mark",[_("strong",[v._v("数据均匀, 数据稳定和节点异构性")])]),v._v("​"),_("strong",[v._v("这三个维度.")])]),v._v(" "),_("p",[v._v("从"),_("strong",[v._v("数据均匀")]),v._v("的维度考虑, 主要包括两个方面:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("不同存储节点中存储的数据要尽量均衡, 避免让某一个或某几个节点存储压力过大, 而其他节点却几乎没什么数据")]),v._v(". 比如现在有 100G 数据, 4 个同类型节点, 通常希望数据存储时尽可能均衡, 比如每个节点存储 25G 数据.")]),v._v(" "),_("li",[v._v("另外, "),_("strong",[v._v("用户访问也要做到均衡, 避免出现某一个或某几个节点的访问量很大, 但其他节点却无人问津的情况")]),v._v(". 比如, 现在有 1000 个请求, 对于上述存储数据的 4 个节点, 处理用户访问请求尽量均衡, 比如每个节点处理 250 个请求, 当然这是非常理想的情况, 实际情况下, 每个节点之间相差不太大即可.")])]),v._v(" "),_("p",[v._v("从"),_("strong",[v._v("数据稳定")]),v._v("的维度考虑, "),_("strong",[v._v("当存储节点出现故障需要移除或者扩增时, 数据按照分布规则得到的结果应该尽量保持稳定, 不要出现大范围的数据迁移")]),v._v(".")]),v._v(" "),_("p",[v._v("比如, 现有 100G 数据, 刚开始有 4 个同类型节点(节点 1~4), 每个节点存储 25G 数据, 现在节点 2 故障了, 也就是说每个节点需要存储 100G/3 数据. 数据稳定, 就是尽可能只迁移节点 2 上的数据到其他节点上, 而不需要对大范围或所有数据进行迁移存储. 当然如果有扩展同类型节点, 也是尽可能小范围迁移数据到扩展的节点上. 具体的迁移方法, 可以采用一致性哈希方法.")]),v._v(" "),_("p",[v._v("从"),_("strong",[v._v("节点异构性")]),v._v("的维度考虑, "),_("strong",[v._v("不同存储节点的硬件配置可能差别很大")]),v._v(". 比如, 有的节点硬件配置很高, 可以存储大量数据, 也可以承受更多的请求; 但有的节点硬件配置就不怎么样, 存储的数据量不能过多, 用户访问也不能过多. 如果这种差别很大的节点, 分到的数据量, 用户访问量都差不多, 本质就是一种不均衡. 所以一个好的数据分布算法"),_("strong",[v._v("应该考虑节点异构性")]),v._v(".")]),v._v(" "),_("p",[v._v("当然, 除了上面这 3 个维度外, 一般还会考虑隔离故障域, 性能稳定性等因素.")]),v._v(" "),_("p",[_("strong",[v._v("隔离故障域")]),v._v(", 是为了保证数据的可用和可靠性. 比如, 通常通过备份来实现数据的可靠性. 但如果每个数据及它的备份, 被分布到了同一块硬盘或节点上, 就有点违背备份的初衷了. 所以一个好的数据分布算法, 应该为每个数据映射一组存储节点, 这些节点应该尽量在不同的故障域, 比如不同机房, 不同机架等.")]),v._v(" "),_("p",[_("strong",[v._v("性能稳定性")]),v._v("是指, 数据存储和查询的效率要有保证, 不能因为节点的添加或者移除, 造成存储或访问性能的严重下降.")]),v._v(" "),_("p",[v._v("了解了数据分布的设计原则后, 接下来再看看主流的数据分布式方法, 哈希和一致性哈希. 其中, 哈希和一致性哈希是数据分布的基础方法, 在不同场景下, 数据分布设计的原则需要考虑的维度也不一样. 随着维度的增加, 一致性哈希又可进一步演进为带有限负载的一致性哈希和带虚拟节点的一致性哈希方法.")]),v._v(" "),_("p",[v._v("接下来就一起看看这 4 种方法的具体原理和应用场景.")]),v._v(" "),_("h5",{attrs:{id:"数据分布方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据分布方法"}},[v._v("#")]),v._v(" 数据分布方法")]),v._v(" "),_("p",[v._v("哈希是指, 将数据按照提前规定好的函数(哈希函数)映射到相应的存储节点, 即进行一个哈希计算, 得到的结果就是数据应该存储的节点.")]),v._v(" "),_("p",[v._v("一致性哈希同样是采用哈希函数, 进行两步哈希:")]),v._v(" "),_("ul",[_("li",[v._v("对存储节点进行哈希计算, 也就是对存储节点做哈希映射;")]),v._v(" "),_("li",[v._v("当对数据进行存储或访问时, 首先对数据进行映射得到一个结果, 然后找到比该结果大的第一个存储节点, 就是该数据应该存储的地方.")])]),v._v(" "),_("p",[v._v("总结来讲, 哈希是一步计算直接得到相应的存储节点, 而一致性哈希需要两步才可以找到相应的存储节点.")]),v._v(" "),_("p",[v._v("接下来先一起看看哈希的具体原理.")]),v._v(" "),_("h6",{attrs:{id:"哈希"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#哈希"}},[v._v("#")]),v._v(" 哈希")]),v._v(" "),_("p",[v._v("哈希是一种非常常用的数据分布方法, 其核心思想是, 首先确定一个哈希函数, 然后通过计算得到对应的存储节点.")]),v._v(" "),_("p",[v._v("假设, 有三个存储节点, 分别为 Node1, Node2 和 Node3; 现有以下数据, ID 的范围为 "),_("code",[v._v("[0,1000]: D0:{ id:100, name:'a0'}, D1:{ id:200, name:'a1'} , D2:{ id:300, name:'a2'}, D3:{ id:400, name:'a3'}, D4:{ id:500, name:'a4'}, D5:{ id:600, name:'a5'}, D6:{ id:700, name:'a6'}")]),v._v("​.")]),v._v(" "),_("p",[v._v("假设, "),_("strong",[v._v('哈希函数为 "id % 节点个数", 通过计算可以得到每个数据应该存入的节点')]),v._v('. 在这个例子中, 哈希函数是 "'),_("code",[v._v("id % 3")]),v._v('​", 结果为 0 的数据存入 Node1, 结果为 1 的数据存入 Node2, 结果为 2 的数据存入 Node3.')]),v._v(" "),_("p",[v._v("如图所示, Node1 将存储数据 D2(300 % 3 = 0)和 D5(600 % 3 = 0), Node2 将存储数据 D0(100 % 3 = 1), D3(400 % 3 = 1)和 D6(700 % 3 = 1), Node3 将存储数据 D1(200 % 3 = 2)和 D4(500 % 3 = 2).")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/52406f4e864b34684a8518b015bcce66-20230731163147-lbub35k.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, 哈希算法的一个优点是, 只要哈希函数设置得当, 可以很好地保证数据均匀性, 但有一个较为严重的缺点, 就是"),_("strong",[v._v("稳定性较差")]),v._v(".")]),v._v(" "),_("p",[v._v("比如随着数据量的增加, 三个节点的容量无法再满足存储需求了, 需要再添加一个节点. 这时哈希函数变成了 "),_("code",[v._v("id % 4")]),v._v("​, 原先存储在那三个节点的数据需要重新计算, 然后存入相应节点, 即"),_("strong",[v._v("需要大规模的数据迁移, 显然会降低稳定性")]),v._v(".")]),v._v(" "),_("p",[v._v("所以"),_("strong",[v._v("哈希方法适用于同类型节点且节点数量比较固定的场景.")])]),v._v(" "),_("p",[v._v("接下来再看看一致性哈希.")]),v._v(" "),_("h6",{attrs:{id:"一致性哈希"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一致性哈希"}},[v._v("#")]),v._v(" 一致性哈希")]),v._v(" "),_("p",[_("strong",[v._v("一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上, 存储节点可以根据 IP 地址进行哈希, 数据通常通过顺时针方向寻找的方式, 来确定自己所属的存储节点, 即从数据映射在环上的位置开始, 顺时针方向找到的第一个存储节点.")])]),v._v(" "),_("p",[v._v("下面看看如何用一致性哈希方法来实现上述案例的数据存储.")]),v._v(" "),_("p",[v._v("如图所示, 假设数据 D0~D7 按照 ID 进行等值映射, 即映射值与 ID 值相等, 比如数据 D0 映射到哈希环上的值为 100, 数据 D1 映射到哈希环上的值为 200···; 同时, 假设存储节点 Node1, Node2 和 Node3 映射到哈希环上的值分别为 400, 600, 900.")]),v._v(" "),_("p",[v._v("按照规则, D0, D1, D2 和 D3 顺时针方向的下一个存储节点为 Node1, 因此 Node1 将存储数据 D0(id = 100), D1(id = 200), D2(id = 300)和 D3(id = 400); 同理, Node2 将存取数据 D4(id = 500)和 D5(id = 600), Node3 将存取数据 D6(id = 700).")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6dbbcd1be7a5b8885b4f5937b17c089e-20230731163147-kcb1kla.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, "),_("strong",[v._v("一致性哈希是对哈希方法的改进, 在数据存储时采用哈希方式确定存储位置的基础上, 又增加了一层哈希, 也就是在数据存储前, 对存储节点预先进行了哈希")]),v._v(".")]),v._v(" "),_("p",[v._v("这种改进可以很好地解决哈希方法存在的稳定性问题. 当节点加入或退出时, "),_("strong",[v._v("仅影响该节点在哈希环上顺时针相邻的后继节点")]),v._v(". 比如, 当 Node2 发生故障需要移除时, 由于 Node3 是 Node2 顺时针方向的后继节点, 本应存储到 Node2 的数据就会存储到 Node3 中, 其他节点不会受到影响, 因此不会发生大规模的数据迁移.")]),v._v(" "),_("p",[v._v("所以, "),_("strong",[v._v("一致性哈希方法比较适合同类型节点, 节点规模会发生变化的场景")]),v._v(". 目前, Cassandra 就使用了一致性哈希方法.")]),v._v(" "),_("p",[v._v("一致性哈希方法虽然提升了稳定性, 但随之而来的"),_("strong",[v._v("均匀性问题也比较明显, 即对后继节点的负载会变大")]),v._v(". 有节点退出后, 该节点的后继节点需要承担该节点的所有负载, 如果后继节点承受不住, 便会出现节点故障, 导致后继节点的后继节点也面临同样的问题.")]),v._v(" "),_("p",[v._v("那么, 有没有更好的方法来解决这个问题呢?")]),v._v(" "),_("p",[v._v("Google 在 2017 年提出了带有限负载的一致性哈希算法, 就对这个问题做了一些优化.")]),v._v(" "),_("h6",{attrs:{id:"带有限负载的一致性哈希"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#带有限负载的一致性哈希"}},[v._v("#")]),v._v(" 带有限负载的一致性哈希")]),v._v(" "),_("p",[_("strong",[v._v("带有限负载的一致性哈希方法的核心原理是, 给每个存储节点设置了一个存储上限值来控制存储节点添加或移除造成的数据不均匀. 当数据按照一致性哈希算法找到相应的存储节点时, 要先判断该存储节点是否达到了存储上限; 如果已经达到了上限, 则需要继续寻找该存储节点顺时针方向之后的节点进行存储.")])]),v._v(" "),_("p",[v._v("下面看看如何用带有限负载的一致性哈希方法, 来实现上述案例的数据存储.")]),v._v(" "),_("p",[v._v("如图所示, 假设每个存储节点设置的上限值为 3, 按照一致性哈希算法, 当存储数据 D3(id = 400)时, 会发现应该存储到 Node1 中, 但 Node1 已经存储了三个数据 D0(id = 100), D1(id = 200)和 D2(id = 300), 达到了存储上限, 因此会存储到该节点顺时针方向的下一个节点 Node2 中. 当然在存储前, 也会先检查 Node2 是否达到了存储上限, 如果达到了, 会继续寻找其他节点.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c33ef1be902cde6e87a6c2f17ae0b536-20230731163147-zwxfhnl.png",alt:""}})]),v._v(" "),_("p",[v._v('如果想要了解该算法的详细内容, 可以阅读 "Consistent Hashing with Bounded Loads" 这篇论文.')]),v._v(" "),_("p",[_("strong",[v._v("带有限负载的一致性哈希方法比较适合同类型节点, 节点规模会发生变化的场景")]),v._v(". 目前, 在 Google Cloud Pub/Sub, HAProxy 中已经实现该方法, 应用于 Google, Vimeo 等公司的负载均衡项目中.")]),v._v(" "),_("p",[v._v("其实, **哈希, 一致性哈希, 带有限负载的一致性哈希, 都没有考虑节点异构性的问题. **如果存储节点的性能好坏不一, 数据分布方案还按照这些方法的话, 其实还是没做到数据的均匀分布.")]),v._v(" "),_("p",[v._v("接下来再看一种主要针对存储节点为异构节点场景的方法, 即"),_("strong",[v._v("带虚拟节点的一致性哈希")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"带虚拟节点的一致性哈希"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#带虚拟节点的一致性哈希"}},[v._v("#")]),v._v(" 带虚拟节点的一致性哈希")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("带虚拟节点的一致性哈希方法, 核心思想是根据每个节点的性能, 为每个节点划分不同数量的虚拟节点, 并将这些虚拟节点映射到哈希环中, 然后再按照一致性哈希算法进行数据映射和存储.")])])]),v._v(" "),_("p",[v._v("假设 Node1 性能最差, Node2 性能一般, Node3 性能最好. 以 Node1 的性能作为参考基准, Node2 是 Node1 的 2 倍, Node3 是 Node1 的 3 倍.")]),v._v(" "),_("p",[v._v("因此, Node1 对应一个虚拟节点 Node1_1, Node2 对应 2 个虚拟节点 Node2_1 和 Node2_2, Node3 对应 3 个虚拟节点 Node3_1, Node3_2 和 Node3_3. 假设虚拟节点 Node1_1, Node2_1, Node2_2, Node3_1, Node3_2, Node3_3 的哈希值, 分别为 100, 200, 300, 400, 500, 600.")]),v._v(" "),_("p",[v._v("那么, 按照带虚拟节点的哈希一致性方法, 数据 D0 和 D6 按顺时针方向的下一个虚拟存储节点为 Node 1-1, 因此节点 Node1 将会存储数据 D0(id = 100)和 D6(id = 700); 同理, Node2 将会存储数据 D1(id = 200)和 D2(id = 300), Node3 将会存储数据 D3(id = 400), D4(id = 500)和 D5(id = 600).")]),v._v(" "),_("p",[v._v("​"),_("img",{attrs:{src:"/img/46e4ec23168e17e178edfd03c7baad66-20230731163147-ql22qkc.png",alt:""}}),v._v("​")]),v._v(" "),_("p",[v._v("可以看出, "),_("strong",[v._v("带虚拟节点的一致性哈希方法比较适合异构节点, 节点规模会发生变化的场景")]),v._v(". 目前 Memcached 缓存系统实现了该方法.")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("这种方法不仅解决了节点异构性问题, 还提高了系统的稳定性. 当节点变化时, 会有多个节点共同分担系统的变化, 因此稳定性更高.")])])]),v._v(" "),_("p",[_("strong",[v._v("比如, 当某个节点被移除时, 对应该节点的多个虚拟节点均会移除, 而这些虚拟节点按顺时针方向的下一个虚拟节点, 可能会对应不同的物理节点, 即这些不同的物理节点共同分担了节点变化导致的压力.")])]),v._v(" "),_("p",[v._v("当然, 这种方法引入了虚拟节点, 增加了节点规模, 从而增加了节点的维护和管理的复杂度, 比如新增一个节点或一个节点故障时, 对应到虚拟节点构建的哈希环上需要新增和删除多个节点, 数据的迁移等操作相应地也会很复杂.")]),v._v(" "),_("h6",{attrs:{id:"四种数据分布方法对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#四种数据分布方法对比"}},[v._v("#")]),v._v(" 四种数据分布方法对比")]),v._v(" "),_("p",[v._v("为方便理解与记忆, 再通过一个表格对比分析下这四种方法. 请注意, 以下方法之间的对比都是相对的比较, 实际性能优劣与哈希函数的设定以及具体的数据场景密切相关.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/eccfac0e2d173d09660b32d05f76d1f4-20230731163147-d3bxta1.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-数据分片和数据分区有何区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-数据分片和数据分区有何区别"}},[v._v("#")]),v._v(" 知识扩展: 数据分片和数据分区有何区别?")]),v._v(" "),_("p",[v._v("数据分区是从"),_("strong",[v._v("数据存储块")]),v._v('的维度进行划分, 不同的分区物理上归属于不同的节点. 比如现在有 2 个节点 Node1 和 Node2, 2 个数据分区 Partition1 和 Partition2, Partition1 属于 Node1, Partition2 属于 Node2. 对于数据分区, 可用于存储不同的数据, 也可以用来存储相同的数据实现数据备份. 数据分区可以归结为是"货架"相关的关键技术, 也就是为数据存储提供合适的位置.')]),v._v(" "),_("p",[v._v("接下来再看一下数据分片. 数据分片是从"),_("strong",[v._v("数据")]),v._v("的维度进行划分, "),_("strong",[v._v("是指将一个数据集合按照一定的方式划分为多个数据子集, 不同的数据子集存在不同的存储块上, 而这些存储块可以在不同的节点上, 也可以在同一节点上")]),v._v('. 具体的数据分片策略可以采用哈希, 一致性哈希等方法. 数据分片是实现 "导购" 的关键技术, 目的是构建索引, 为数据确定位置, 包括存储数据和查询数据时确定数据位置.')]),v._v(" "),_("p",[v._v('由此可见, **数据分片和数据分区是两个不同的概念, 且属于分布式存储系统中不同角色的技术, 前者是实现"导购"的关键技术, 后者是"货架"相关的技术, 不可直接等同. **')]),v._v(" "),_("p",[v._v("但正因为一个是导购相关的关键技术, 一个是货架相关的技术, 一个提供确定数据索引的位置, 一个提供合适的数据存储位置, 因此这两个技术是可以共存的, 比如下面这个例子.")]),v._v(" "),_("p",[v._v("有 3 个节点 "),_("code",[v._v("{Node1, Node2, Node3}")]),v._v("​, 有 3 个分区 "),_("code",[v._v("{Partition1, Partition2, Partition3}")]),v._v("​ 用于存储用户信息, 每个节点上 1 个分区. 现在有 1000 个用户信息需要存储, 用户 id 编号为 [1, 1000], 为防止将所有信息存储到一个节点上, 所有用户发起请求时, 该节点成为瓶颈, 为此需要将这 1000 个用户信息存储到 3 个节点上.")]),v._v(" "),_("p",[v._v("假设采用最简单的哈希方法, 用户 id % 节点总数 (3) 进行哈希映射, "),_("code",[v._v("id % 3 = 0")]),v._v("​ 的所有用户信息存储到节点 1 的 Partition1,  "),_("code",[v._v("id % 3 = 1")]),v._v("​ 的所有用户信息存储到节点 2 的 Partition2, "),_("code",[v._v("id % 3 = 2")]),v._v("​ 的所有用户信息存储到节点 3 的 Partition3.")]),v._v(" "),_("h5",{attrs:{id:"总结-21"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-21"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节学习了数据分布式方法中的哈希与一致性哈希. 首先, 了解了分布式数据存储系统中, 设计数据分布方法需要考虑的原则, 主要包括数据均匀性, 稳定性和节点异构性.")]),v._v(" "),_("p",[v._v("其次, 基于数据分布设计原则, 介绍了哈希, 一致性哈希, 带有限负载的一致性哈希和带虚拟节点的一致性哈希方法.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/83fc73586efece08f301f7f58a3f400d-20230731163147-evrujnp.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_26-分布式数据复制技术-分身有术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_26-分布式数据复制技术-分身有术"}},[v._v("#")]),v._v(" 26-分布式数据复制技术:分身有术")]),v._v(" "),_("p",[v._v('前面提到, 数据分片和数据复制技术均是实现"导购"的关键技术. 其中, 数据分片是确定数据位置, 数据复制是实现数据可靠性的关键方法.')]),v._v(" "),_("p",[_("strong",[v._v("在实际情况下, 仅考虑数据分片, 其实是无法真正应用到生产环境的")]),v._v(". 因为, 故障导致数据丢失和不可用是很常见的情况. 因此, 在进行分布式数据存储设计时, 通常会考虑"),_("strong",[v._v("对数据进行备份, 以提高数据的可用性和可靠性")]),v._v(', 而实现数据备份的关键技术就是 "'),_("strong",[v._v("数据复制技术")]),v._v('".')]),v._v(" "),_("h5",{attrs:{id:"什么是数据复制技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是数据复制技术"}},[v._v("#")]),v._v(" 什么是数据复制技术?")]),v._v(" "),_("p",[v._v("概括来讲, "),_("strong",[v._v("数据复制是一种实现数据备份的技术")]),v._v(". 比如现在有节点 1 和节点 2, 节点 1 上存储了 10M 用户数据, 直观地说, 数据复制技术就是将节点 1 上的这 10M 数据拷贝到节点 2 上, 以使得节点 1 和节点 2 上存储了相同的数据, 也就是节点 2 对节点 1 的数据进行了备份. 当节点 1 出现故障后, 可以通过获取节点 2 上的数据, 实现分布式存储系统的自动容错.")]),v._v(" "),_("p",[v._v("也就是说, "),_("strong",[v._v("数据复制技术, 可以保证存储在不同节点上的同一份数据是一致的")]),v._v(". 这样当一个节点故障后, 可以从其他存储该数据的节点获取数据, 避免数据丢失, 进而提高了系统的可靠性.")]),v._v(" "),_("p",[v._v('这是不是就像数据有了自己的 "分身" 呢? 那分布式系统是如何实现数据 "分身有术" 的呢? 接下来通过一个例子来具体看下.')]),v._v(" "),_("p",[v._v("在分布式数据库系统中, 通常会设置主备数据库, 当主数据库出现故障时, 备数据库可以替代主数据库进行后续的工作, 从而保证业务的正常运行. 这里备数据库继续提供服务就是提高了分布式存储系统的可用性及可靠性. 在这个过程中, 又是如何实现备数据库替代主数据库的呢? 这就涉及到数据一致性的问题了, 即只有主备数据库中的数据保持一致时, 才可实现主备的替换. 在这个例子中, "),_("strong",[v._v("数据复制技术实际就是指, 如何让主备数据库保持数据一致的技术.")])]),v._v(" "),_("p",[v._v("理解了数据复制技术的基本含义, 再一起看看数据复制技术的具体原理和应用.")]),v._v(" "),_("h5",{attrs:{id:"数据复制技术原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据复制技术原理及应用"}},[v._v("#")]),v._v(" 数据复制技术原理及应用")]),v._v(" "),_("p",[v._v("CAP 理论中, 在分布式存储系统中, "),_("strong",[v._v("分区容错性是肯定要满足的, 为此需要在一致性和可用性之间做出权衡")]),v._v(". 所以, 对于数据的一致性, 通常是指不同节点上数据要保持一致. 要实现不同节点上的数据一致, 数据复制技术必不可少. 为此, 对于分布式存储系统中的数据复制技术来讲, "),_("strong",[v._v("也需要在一致性和可用性之间做出一些权衡")]),v._v(". 因此这就导致出现了多种数据复制技术方法, 大体上有三类:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("第一类方法, 比较注重一致性, 比如同步复制技术;")])]),v._v(" "),_("li",[_("strong",[v._v("第二类方法, 则更注重可用性, 比如异步复制技术;")])]),v._v(" "),_("li",[_("strong",[v._v("第三类方法, 是介于前两者之间的, 比如半同步复制技术.")])])]),v._v(" "),_("p",[v._v("接下来就针对同步数据复制技术, 异步数据复制技术, 以及半同步数据复制技术分别进行详细讲解.")]),v._v(" "),_("h6",{attrs:{id:"同步复制技术原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#同步复制技术原理及应用"}},[v._v("#")]),v._v(" 同步复制技术原理及应用")]),v._v(" "),_("p",[_("strong",[v._v("同步复制技术是指, 当用户请求更新数据时, 主数据库必须要同步到备数据库之后才可给用户返回, 即如果主数据库没有同步到备数据库, 用户的更新操作会一直阻塞. 这种方式保证了数据的强一致性, 但牺牲了系统的可用性.")])]),v._v(" "),_("p",[v._v("接下来看一个具体的案例.")]),v._v(" "),_("p",[v._v("在一个分布式数据库系统中, 有两个节点, 分别作为主节点和备节点. 通常情况下, 两个节点均可接收用户读请求, 然后将本节点的数据及时返回给用户, 也就是说读请求响应比较快. 而如果用户发送的是写请求, 写操作必须由主节点进行, 即使用户将写请求发送到备节点, 备节点也会将该请求转发给主节点, 因此写请求通常比读请求响应慢. "),_("strong",[v._v("MySQL 集群的读写分离")]),v._v("就是一个典型实例.")]),v._v(" "),_("p",[_("strong",[v._v("如此设计的原因是, 读请求不需要改变数据, 只需要在更改数据时保证数据一致, 就可以随时读; 而写请求, 因为要修改数据, 如果每个节点均修改同一数据, 则可能导致数据不一致. 因此只有主节点可以进行写操作, 但又要保证主节点和备节点的数据一致, 这就是数据复制技术要发挥的作用了")]),v._v(".")]),v._v(" "),_("p",[v._v("对于上述场景, 如果采用同步复制技术的话, 对于写请求, 主数据库会执行写操作, 并将数据同步到所有备数据库之后才可以响应用户. 如图所示, 客户端向主数据库发起更新操作 V, 将 X 设置为 2, 主数据库会将写请求同步到备数据库, 备数据库操作完后会通知主数据库同步成功, 然后主数据库才会告诉客户端更新操作成功. MySQL 集群支持的全复制模式就采用了同步复制技术.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/0e8d1745cf5ee1438a9828e468bdd6dd-20230731163147-64ordm8.png",alt:""}})]),v._v(" "),_("p",[v._v("在同步复制技术中, 主数据库需要等待所有备数据库均操作成功才可以响应用户, 性能不是很好, 会影响用户体验, 因此, "),_("strong",[v._v("同步复制技术经常用于分布式数据库主备场景")]),v._v("(对于一主多备场景, 由于多个备节点均要更新成功后, 主节点才响应用于, 所需时延比较长)"),_("strong",[v._v("或对数据一致性有严格要求的场合")]),v._v(", 比如"),_("strong",[v._v("金融, 交易")]),v._v("之类的场景.")]),v._v(" "),_("h6",{attrs:{id:"异步复制技术原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#异步复制技术原理及应用"}},[v._v("#")]),v._v(" 异步复制技术原理及应用")]),v._v(" "),_("p",[_("strong",[v._v("异步复制技术是指, 当用户请求更新数据时, 主数据库处理完请求后可直接给用户响应, 而不必等待备数据库完成同步, 即备数据库会异步进行数据的同步, 用户的更新操作不会因为备数据库未完成数据同步而导致阻塞. 显然, 这种方式保证了系统的可用性, 但牺牲了数据的一致性.")])]),v._v(" "),_("p",[v._v("如图所示, 客户端 1 向主数据库发起更新操作 V, 主数据库执行该操作, 将 X=1 修改为 X=2, 执行后直接返回给客户端 1 更新操作成功, 而未将数据同步到备数据库. 因此, 当客户端 2 请求主数据库的数据 X 时, 可以得到 X=2, 但客户端 3 请求备数据库中的数据 X 时, 却只能得到 X=1, 从而导致请求结果不一致.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/ef5d368e22cd498e8ff02cb94262b8b6-20230731163147-aqnpbj1.png",alt:""}})]),v._v(" "),_("p",[v._v("当然分布式数据库主备模式场景下, 若对数据一致性要求不高, 也可以采用异步复制方法. "),_("mark",[_("strong",[v._v("MySQL 集群默认的数据复制模式采用的是异步复制技术")])]),v._v(", 就以 MySQL 集群默认的复制模式为例, 简单描述下主备数据库同步的流程.")]),v._v(" "),_("p",[_("strong",[v._v("主数据库完成写操作后, 可直接给用户回复执行成功, 将写操作写入 binary log 中, binary log 中记录着主数据库执行的所有更新操作, 以便备数据库获取更新信息. 备数据库启动一个 IO 线程专门读取 binary log 中的内容然后写入 relay log 中. 备数据库启动一个 SQL 线程会定时检查 relay log 里的内容, 如发现有新内容则会立即在备数据库中执行, 从而实现数据的一致.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6dcf5dbae5ac30d053dca8504a3b7aae-20230731163147-65gsiis.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("异步复制技术大多应用在对用户请求响应时延要求很高的场景")]),v._v(", 比如很多网站或 App 等需要面向实际用户, 这时后台的数据库或缓存如果采用同步复制技术, 可能会流失用户, 因此这种场景采用异步复制技术就比较合适.")]),v._v(" "),_("p",[v._v("除了 MySQL 集群, 在缓存数据库 Redis 集群中, 采用的也是异步复制技术, 因此性能较高. 但在 Redis 中还会有其他机制来保证数据的一致性, 后面会详细介绍.")]),v._v(" "),_("h6",{attrs:{id:"半同步复制技术原理及应用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#半同步复制技术原理及应用"}},[v._v("#")]),v._v(" 半同步复制技术原理及应用")]),v._v(" "),_("p",[v._v("同步复制技术会满足数据的强一致性, 但会牺牲一定的可用性; 异步复制技术会满足高可用, 但一定程度上牺牲了数据的一致性. 介于两者中间的是, 半同步复制技术.")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("半同步复制技术的核心是, 用户发出写请求后, 主数据库会执行写操作, 并给备数据库发送同步请求, 但主数据库不用等待所有备数据库回复数据同步成功便可响应用户, 也就是说主数据库可以等待一部分备数据库同步完成后响应用户写操作执行成功")])]),v._v(".")]),v._v(" "),_("p",[v._v("**半同步复制技术通常有两种方式: **")]),v._v(" "),_("ol",[_("li",[v._v("一种是当主数据库收到多个备数据库中的"),_("strong",[v._v("某一个")]),v._v("回复数据同步成功后, 便可给用户响应写操作完成;")]),v._v(" "),_("li",[v._v("另一种是主数据库等"),_("strong",[v._v("超过一半节点")]),v._v("(包括主数据库)回复数据更新成功后, 再给用户响应写操作成功.")])]),v._v(" "),_("p",[v._v("显然, 第二种半同步复制方案要求的一致性比第一种要高一些, 但相对可用性会低一些.")]),v._v(" "),_("p",[v._v("前面所讲的 MySQL 集群, 在一主多备场景下, 也支持半同步复制模式, 一般采用的是第一种半同步复制技术, 这种技术既不会影响过多的性能, 还可以更好地实现对数据的保护.")]),v._v(" "),_("p",[v._v("前面提到的具有 CP 特性的 ZooKeeper 集群采用的数据复制技术就是第二种半同步复制方案. 在 ZooKeeper 集群中, 写请求必须由 Leader 节点进行处理, 每次写请求 Leader 会征求其他 Follower 的同意, "),_("strong",[v._v("只有当多数节点同意后写操作才可成功, 因此保证了较高的一致性")]),v._v(".")]),v._v(" "),_("p",[v._v("除此之外, 还有很多系统采用了第二种半同步复制方案, 比如微软云关系型数据库 Microsoft SQL Azure 的后端存储系统 Cloud SQL Server, Kubenetes 中保存集群所有网络配置和对象状态信息的 Etcd 组件(该组件采用的是 Raft 一致性协议)等.")]),v._v(" "),_("p",[v._v("实际上, "),_("strong",[v._v("多数的分布式存储系统可以通过配置来选择不同的数据复制技术")]),v._v(". 比如上面讲过的 MySQL 数据库集群, 就支持全同步复制, 异步复制和半同步复制三种模式, 再比如 Oracle 数据库, 也提供了三种模式:")]),v._v(" "),_("ol",[_("li",[v._v("最大保护模式, 对于写请求, 要求主数据库必须完成至少一个备数据库的数据同步才可成功返回给客户端, 采用的是半同步复制技术中的第一种方式.")]),v._v(" "),_("li",[v._v("最大性能模式, 对于写请求, 只要主数据库执行成功即可返回给客户端, 采用的是异步复制技术. 这种方式极大地提高了系统的可用性, 但一致性难以保证.")]),v._v(" "),_("li",[v._v("最大可用性模式, 介于最大保护模式和最大性能模式两者之间. 这种模式是指, 系统在通常情况下采用最大保护模式, 但当主备之间出现网络故障时, 切换为最大性能模式, 等到网络恢复后, 备数据库再进行数据同步. 这种方式在系统的一致性和可用性之间做了一个权衡.")])]),v._v(" "),_("h6",{attrs:{id:"三种数据复制技术对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三种数据复制技术对比"}},[v._v("#")]),v._v(" 三种数据复制技术对比")]),v._v(" "),_("p",[v._v("以上就是同步复制技术, 异步复制技术和半同步复制技术的核心知识点了. 接下来通过一张表格对比下这三种方法, 以便于记忆和理解.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/ad2361ebc5537275498587b5037ad923-20230731163147-06po08p.png",alt:""}})]),v._v(" "),_("blockquote",[_("p",[v._v("知识扩展: 在半同步复制技术中, 对于未回复数据更新结果的节点, 如何解决数据不一致或冲突呢?")])]),v._v(" "),_("p",[v._v("对于半同步复制技术, 因为只有部分备节点更新数据后, 主节点即可返回响应用户. 那么, "),_("strong",[v._v("对于未回复数据更新结果的节点, 如何解决可能存在的数据不一致或冲突呢")]),v._v("?")]),v._v(" "),_("p",[v._v("对于这个问题, 不同的场景有不同的处理方式, 需要根据用户的需求进行选择, 比如"),_("strong",[v._v("以最新数据为准, 以最大数据为准等, 没有统一的评判规则, 和用户的需求紧密相关")]),v._v(". 由于在分布式系统中, 很多系统采用了 Raft 算法, 因此这里以 Raft 算法的处理策略为例展开介绍, 以便理解大部分常用的分布式系统的处理策略.")]),v._v(" "),_("p",[_("strong",[v._v("Raft 算法采用的是第二种半同步复制技术, 也就是主数据库等超过一半节点(包括主数据库)回复数据更新成功后, 再给用户响应写操作成功. 当有 Follower 节点的数据与 Leader 节点数据不一致时, 采用强制复制策略来解决不一致情况.")])]),v._v(" "),_("p",[v._v("由于所有的数据更新操作最先在 Leader 节点执行, "),_("strong",[v._v("因此当产生冲突时, 以 Leader 节点为准")]),v._v(". Leader 节点上会对比与自己数据不一致的 Follower 节点所存储的信息, 找到两者最后达成一致的地方, 然后强制将这个地方之后的数据复制到该 Follower 节点上.")]),v._v(" "),_("p",[v._v("具体方法是, Leader 节点将每一次数据操作看作一条记录, 并对这条记录标记一个 index, 用于索引. Leader 节点会为每个 Follower 节点维护一个记录状态变量 nextIndex, 即下一个记录的索引位置(nextIndex 的值为 Leader 节点当前存储数据记录的下一个 Index 值). Leader 节点会将 nextIndex 发送给 Follower 节点, 若 Follower 节点发现与本节点的 nextIndex 不一致, 则告知 Leader 节点不一致, Leader 节点将 nextIndex 减 1, 重复上述过程, 直到与 Follower 节点的 nextIndex 相等位置, 即找到了两者最后达成一致的地方.")]),v._v(" "),_("p",[v._v("比如, 对于变量 X, Leader 节点记录的操作是 "),_("code",[v._v("{(Index 1, X = 1, Version:0), (Index 2, X=2, Version:1), (Index3 , X=3, Version:2)}")]),v._v("​, 其中, Follower 节点 2 记录的操作为 "),_("code",[v._v("{(Index 2, X=1, Version:0), (Index 6, X=4, Version:2)}")]),v._v("​.")]),v._v(" "),_("p",[v._v("那么, Leader 节点发现两者最后一致的状态是 "),_("code",[v._v("{(Index 1, X=1, Version:0)}")]),v._v("​, 为此将后续的 "),_("code",[v._v("{(Index 2, X=2, Version:1), (Index 3, X=3, Version:2)}")]),v._v("​ 复制到节点 2 上, 则节点 2 更新为 "),_("code",[v._v("(Index 1, X = 1, Version: 0), (Index 2, X=2, Version:1), (Index3 , X=3, Version:2)}")]),v._v("​. 从而, 节点 2 与 Leader 节点的数据保持一致.")]),v._v(" "),_("h5",{attrs:{id:"总结-22"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-22"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分析的是分布式数据复制技术. 首先通过分布式数据库主备节点数据一致的例子, 直观的讲解了什么是数据复制技术. 然后介绍了数据复制技术的原理及应用, 以及同步复制技术, 异步复制技术和半同步复制技术这三种方法. 其中, 对于用户更新数据的请求, 同步复制技术要求主备节点均更新完成, 才返回结果告知用户更新成功; 异步复制技术只需要主节点更新成功, 就可返回结果; 半同步复制技术, 要求主节点更新成功, 且备节点中至少有 1 个或过半节点更新成功, 才可返回结果.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/6364b28e3ac8f00dfcf59fd723a667f8-20230731163147-09tvess.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_27-分布式数据之缓存技术-身手钥钱-随身带"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_27-分布式数据之缓存技术-身手钥钱-随身带"}},[v._v("#")]),v._v(' 27-分布式数据之缓存技术:"身手钥钱"随身带')]),v._v(" "),_("p",[v._v('本节讲解分布式存储中 "货架" 的关键技术---缓存技术.')]),v._v(" "),_("p",[v._v("在计算机领域的各个方面, 缓存都非常重要, 是提升访问性能的一个重要技术. 为什么这么说呢? 从单个计算机的体系结构来看, 内存和处理器速度差异很大, 如果不采用缓存技术, 处理器的性能会受到很大的限制. 再看计算机应用, 如果不采用缓存技术, 对于每个请求, 应用都要与后台数据库做一次交互, 而数据库中的数据存储在磁盘上, 因此每次请求都要和磁盘做交互, 而磁盘访问的性能很低, 造成访问延迟. 除此之外, 还有网络访问, 如果没有缓存机制, 每次访问主机都要与远程机器做交互, 速度又可想而知.")]),v._v(" "),_("h5",{attrs:{id:"什么是分布式缓存"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是分布式缓存"}},[v._v("#")]),v._v(" 什么是分布式缓存?")]),v._v(" "),_("p",[_("strong",[v._v("缓存技术")]),v._v("一般是指, 用一个更快的存储设备存储一些经常用到的数据, 供用户快速访问. 用户不需要每次都与慢设备去做交互, 因此可以提高访问效率.")]),v._v(" "),_("p",[_("strong",[v._v("分布式缓存")]),v._v("就是指在分布式环境或系统下, 把一些热门数据存储到离用户近, 离应用近的位置, 并尽量存储到更快的设备, 以减少远程数据传输的延迟, 让用户和应用可以很快访问到想要的数据.")]),v._v(" "),_("p",[v._v("其实, "),_("strong",[v._v("我们通常说的分布式数据缓存, 属于计算机应用中的缓存的一种")]),v._v(". 而计算机应用中的缓存, 一般指内存, 即内存存储了用户经常访问的数据, 用户或应用不再需要到磁盘中去获取相应的数据, 大幅提高访问速度.")]),v._v(" "),_("p",[v._v("如下图所示, 数据 A 是应用经常访问的数据, 而数据 B 很少被应用访问, 因此当应用访问数据 A 时, 不需要到磁盘, 而直接访问内存即可得到对应的值, 速度较快; 相反, 访问数据 B 时, 由于内存中没有缓存数据 B, 所以应用需要到磁盘中获取对应的值, 速度较慢.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/235a5055f8b5f8b3f60f9f9cd199cfed-20230731163147-tz22u9q.png",alt:""}})]),v._v(" "),_("p",[v._v("今天分享的分布式数据存储相关的缓存技术, 就是以内存做为磁盘的缓存.")]),v._v(" "),_("h5",{attrs:{id:"分布式缓存原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式缓存原理"}},[v._v("#")]),v._v(" 分布式缓存原理")]),v._v(" "),_("p",[v._v("接下来以主流的分布式缓存系统 Redis 和 Memcached 为例, 讲述分布缓存技术.")]),v._v(" "),_("h6",{attrs:{id:"redis分布缓存原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis分布缓存原理"}},[v._v("#")]),v._v(" Redis分布缓存原理")]),v._v(" "),_("p",[v._v("Redis 的全称是 Remote Dictionary Server(远程字典服务器). 可以直观地看出, 它是以字典结构将数据存储在内存中, 应用可直接到内存读写 Redis 存储的数据. Redis 集群是一个典型的去中心化结构, 每个节点都负责一部分数据的存储, 同时, 每个节点还会进行主备设计来提高 Redis 的可靠性.")]),v._v(" "),_("p",[v._v("接下来分享下, Redis 中与缓存关系最紧密的三个特性 "),_("strong",[v._v(": 支持多数据结构, 支持持久化和主备同步.")])]),v._v(" "),_("p",[_("strong",[v._v("第一, Redis 支持多数据结构")]),v._v(".")]),v._v(" "),_("p",[v._v("Redis 是一个基于内存的 key-value 数据库, 为了方便支持多应用的缓存, 比如缓存文本类型, 数据库的查询结果(字段与字段对应的值)等等, 支持的数据结构不仅有简单的 k／v 类型, 还可以支持 List, Set, Hash 等复杂类型的存储.")]),v._v(" "),_("p",[v._v("**第二, Redis 支持持久化. **")]),v._v(" "),_("p",[v._v("持久化是指将数据从内存这种易失性存储设备中写入磁盘, 从而让数据永久保存. Redis 中存储的数据虽然是基于内存的, 但它也提供了持久化的机制, 主要有两种方式: RDB 和 AOF.")]),v._v(" "),_("p",[_("strong",[v._v("RDB")]),v._v("(Redis DataBase), 也称快照方式, 简单来说就是 Redis 会定时将内存中的数据备份到磁盘中, 形成一个快照, 比如每天保存一下过去一周的数据. 这样当节点出现故障时, 可以根据快照恢复到不同版本的数据. 这种方式有一个明显的缺点, 是会造成数据丢失, 即当节点出现故障时, 新数据可能还未备份到磁盘中.")]),v._v(" "),_("p",[_("strong",[v._v("AOF")]),v._v("(Append Only File)的出现主要弥补了 RDB 数据不一致的问题, 其思想与数据库复制技术中 binary log 类似, 即记录下 Redis 中所有的更新操作.")]),v._v(" "),_("p",[v._v("**第三, Redis 支持主备同步. **")]),v._v(" "),_("p",[v._v("在 Redis 中, 采用的是异步复制技术, 但 Redis 可以"),_("strong",[v._v("通过配置 min-replicas-to-write 和 min-replicas-max-lag 这两个参数来有效地保证数据一致性")]),v._v(".")]),v._v(" "),_("p",[v._v("比如, 设置 min-replicas-to-write=3, min-replicas-max-lag=10, 表示当"),_("strong",[v._v("至少有 3 个备数据库连接主数据库的延迟时间小于 10s 时, 主数据库才可以执行写操作")]),v._v(". 延迟时间是从最后一次收到备数据库的心跳开始计算, 通常每秒发送一次心跳.")]),v._v(" "),_("p",[v._v("除了上面对写操作的同步, 在 Redis 中还有两种情况是需要进行数据同步的:")]),v._v(" "),_("ol",[_("li",[v._v("一种情况是初次同步, 即备数据库刚启动时的数据同步;")]),v._v(" "),_("li",[v._v("另一种情况是, 因网络故障导致主备数据库断开连接, 待网络恢复后的备数据库的数据同步.")])]),v._v(" "),_("p",[v._v("针对这两种情况, Redis 提供了两种同步模式, 即完整重同步和部分重同步.")]),v._v(" "),_("p",[_("strong",[v._v("完整重同步")]),v._v("的流程如下所示:")]),v._v(" "),_("ul",[_("li",[v._v("当备服务器启动时, 会向主服务器发送 SYNC 命令;")]),v._v(" "),_("li",[v._v("主服务器收到命令后会生成 RDB(快照)文件, 并记录从现在起新执行的写操作;")]),v._v(" "),_("li",[v._v("RDB 生成后会发送给备服务器, 备服务器通过 RDB 文件进行数据更新;")])]),v._v(" "),_("p",[v._v("更新完成后, 主服务器再将新记录的写操作发送给备服务器, 备服务器执行完这些新记录的写操作, 便与主服务器的数据保持一致了.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7629636e7bf365ceeb31a4002c2a7645-20230731163147-y5xn98o.png",alt:""}})]),v._v(" "),_("p",[v._v("简单地说, "),_("strong",[v._v("部分重同步")]),v._v("就是, 当网络恢复后, 主数据库将主备数据库断开连接之后的一系列写操作发送给备服务器, 备数据库执行这些写操作, 从而保证数据保持一致.")]),v._v(" "),_("p",[v._v("在这种方式的实现中, 主备数据库会共同维护一个复制偏移量, 这样主数据库就知道应该将哪些写操作发给备数据库, 备数据库同步时也知道应该从哪里继续执行操作.")]),v._v(" "),_("p",[v._v("如图所示, 主数据库的复制偏移量为 5000 时, 向备数据库发送了 100 个字节的数据, 发送结束后复制偏移量为 5100. 此时主备数据库连接断开, 备数据库没有接收到这 100 个字节的数据, 等到备数据库重新与主数据库连接上之后, 会给主数据库发送 PSYNC 命令, 并带上自己的复制偏移量 5000, 主数据库接收到信息后, 根据接收到的复制偏移量, 将 5000 之后的数据发给备数据库, 从而完成数据的部分重同步.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/1478cee69af45a5733fb2397fccaefe3-20230731163147-d2hakg3.png",alt:""}})]),v._v(" "),_("p",[v._v("以上就是分布式缓存系统 Redis 中涉及的关键技术, 包括支持的数据结构, 数据持久化方法和数据同步方法, 相信通过上面的介绍, 你对分布式缓存技术已经有了一定的了解.")]),v._v(" "),_("p",[v._v("接下来再看另一个缓存数据库 Memcached.")]),v._v(" "),_("h6",{attrs:{id:"memcached分布式缓存原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#memcached分布式缓存原理"}},[v._v("#")]),v._v(" Memcached分布式缓存原理")]),v._v(" "),_("p",[v._v("与 Redis 类似, Memcached 也是一个基于内存的高性能 key-value 缓存数据库. Memcached 比 Redis 问世更早, 也有很多公司在使用, 比如 Facebook, Vox, LiveJournal 等.")]),v._v(" "),_("p",[v._v("其实, Memecached 的缓存原理和 Redis 类似. 所以接下来的内容, 会着重讲述这两个数据库在支持的数据结构, 持久化和主备同步上的不同. 这样就可以对比着学习这两个数据库, 也会理解得更全面, 深入些.")]),v._v(" "),_("p",[v._v("首先要了解一下 Memcached 的集群结构.")]),v._v(" "),_("p",[v._v("Redis 的集群结构是每个节点负责一部分哈希槽, 且每个节点可以设计主备. 与 Redis 不同, Memcached 集群采用一致性哈希的思路, 使用的是 Ketama 算法. 该算法的主要思想就是, "),_("strong",[v._v("带虚拟节点的一致性哈希算法")]),v._v(".")]),v._v(" "),_("p",[v._v("在实际应用中, 每个物理节点对应 100~200 个虚拟节点, 才能到达一个较好的存储均衡. 这里为了方便理解, 对 Memcached 的集群结构做了简化, 如下图所示, 物理节点 1 对应两个虚拟节点 1-1, 1-2, 物理节点 2 对应三个虚拟节点 2-1, 2-2 和 2-3.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/151a743ed7ab1081aa7fb2d58983901e-20230731163147-h9fx41v.png",alt:""}})]),v._v(" "),_("p",[v._v("采用带虚拟节点的一致性哈希方法, 有一个优点是, 当添加或移除节点时, 不会出现大规模的数据迁移.")]),v._v(" "),_("p",[v._v("对于数据结构的支持, Memcached 仅支持简单的 k／v 数据类型, 如果想要存储复杂的数据类型, 比如 List, Set 和 Hash 等, 需要客户端自己处理, 将其转化为字符串然后进行存储. 这样就导致了一个缺点, 操作不灵活. 比如 Memcached 存储的数组中有一个元素需要修改, 则需要将整个数组的数据取出来, 修改后再整体写入到数据库中 .")]),v._v(" "),_("p",[v._v("而对于持久化, Memcached 是不支持的. 这意味着断电时, Memcached 中存储的数据将会全部丢失. 因为内存是一种易失性存储设备, 断电后将不会存储数据.")]),v._v(" "),_("p",[v._v("在 Memcached 中, 服务器和服务器之间没有任何通信, 即自身不支持主备. 如果想要实现高可用, 需要通过第三方实现. 比如 Repcached 实现了 Memcached 的复制功能, 支持一主一备, 从而使 Memcached 满足高可用.")]),v._v(" "),_("h6",{attrs:{id:"对比分析-3"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比分析-3"}},[v._v("#")]),v._v(" 对比分析")]),v._v(" "),_("p",[v._v("上面以 Redis 和 Memcached 这两个主流的分布式缓存系统为例, 学习了分布式缓存技术. 接下来以一个表格对它们进行分析对比, 以便于理解和查阅.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/847e3c17b558a88f40f53454b73a378d-20230731163147-5g15aem.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"总结-23"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-23"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节分享了分布式数据的缓存技术. 首先以水缸的例子直观了解了什么是缓存, 并引出了什么是分布式数据缓存. 分布式数据缓存是以内存作为磁盘的缓存, 存储一些用户经常需要用的数据, 以提高访问速度.")]),v._v(" "),_("p",[v._v("其次以主流的 Redis 和 Memcached 为例, 介绍了分布式缓存技术中的关键技术, 包括支持的数据存储结构(比如 k/v, Set, List 等), 持久化技术(包括快照方式等)和数据同步技术.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/8b5826ecdd598e88cffe09835cbe4bb4-20230731163147-vawaoul.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"分布式高可靠"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式高可靠"}},[v._v("#")]),v._v(" 分布式高可靠")]),v._v(" "),_("h4",{attrs:{id:"_28-分布式高可靠之负载均衡-不患寡-而患不均"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_28-分布式高可靠之负载均衡-不患寡-而患不均"}},[v._v("#")]),v._v(" 28-分布式高可靠之负载均衡:不患寡,而患不均")]),v._v(" "),_("p",[v._v("到目前为止, 已经介绍了分布式起源, 分布式协调与同步, 分布式资源管理与负载调度, 分布式计算技术, 分布式通信技术和分布式数据存储. 可以说, 掌握了这些内容, 基本上就掌握了分布式的关键技术.")]),v._v(" "),_("p",[v._v("然而, 只有可靠的分布式系统才能真正应用起来. 那么, "),_("strong",[v._v("分布式系统的可靠性又是如何实现")]),v._v("的呢? 接下来几篇文章, 会学习分布式可靠性相关的知识, 包括"),_("strong",[v._v("负载均衡, 流量控制, 故障隔离和故障恢复")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"什么是负载均衡"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是负载均衡"}},[v._v("#")]),v._v(" 什么是负载均衡?")]),v._v(" "),_("p",[v._v("举个例子. 以超市收银为例, 假设现在只有一个窗口, 一个收银员:")]),v._v(" "),_("ol",[_("li",[v._v("一般情况下, 收银员平均 2 分钟服务一位顾客, 10 分钟可以服务 5 位顾客;")]),v._v(" "),_("li",[v._v("到周末高峰期时, 收银员加快收银, 平均 1 分钟服务一位顾客, 10 分钟最多服务 10 位顾客, 也就是说一个顾客最多等待 10 分钟;")]),v._v(" "),_("li",[v._v("逢年过节, 顾客数量激增, 一下增加到 30 位顾客, 如果仍然只有一个窗口和一个收银员, 那么所有顾客就只能排队等候了, 一个顾客最多需要等待 30 分钟. 这样购物体验, 就非常差了.")])]),v._v(" "),_("p",[v._v("那有没有解决办法呢?")]),v._v(" "),_("p",[v._v("当然有. 那就是新开一个收银窗口, 每个收银窗口服务 15 个顾客, 这样最长等待时间从 30 分钟缩短到 15 分钟. 但如果这两个窗口的排队顾客数严重不均衡, 比如一个窗口有 5 个顾客排队, 另一个窗口却有 25 个顾客排队, 就不能最大化地提升顾客的购物体验.")]),v._v(" "),_("p",[_("strong",[v._v("所以尽可能使得每个收银窗口排队的顾客一样多, 才能最大程度地减少顾客的最长排队时间, 提高用户体验.")])]),v._v(" "),_("p",[v._v('看完这个例子, 你是不是想到了一句话 "不患寡, 而患不均"? 这其实就是负载均衡的基本原理.')]),v._v(" "),_("p",[v._v("通常情况下, "),_("strong",[v._v("负载均衡可以分为两种")]),v._v(":")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("一种是请求负载均衡, 即将用户的请求均衡地分发到不同的服务器进行处理;")])]),v._v(" "),_("li",[_("strong",[v._v("另一种是数据负载均衡, 即将用户更新的数据分发到不同的存储服务器.")])])]),v._v(" "),_("p",[v._v("数据分布算法很重要的一个衡量标准, 就是均匀分布. 可见哈希和一致性哈希等, 其实就是数据负载均衡的常用方法. 本节就"),_("strong",[v._v("着重说说服务请求的负载均衡技术.")])]),v._v(" "),_("p",[v._v("分布式系统中, 服务请求的负载均衡是指当处理大量用户请求时, 请求应尽量均衡地分配到多台服务器进行处理, 每台服务器处理其中一部分而不是所有的用户请求, 以完成高并发的请求处理, 避免因单机处理能力的上限, 导致系统崩溃而无法提供服务的问题. 比如, 有 N 个请求, M 个节点, 负载均衡就是将 N 个请求, 均衡地转发到这 M 个节点进行处理.")]),v._v(" "),_("h5",{attrs:{id:"服务请求的负载均衡方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#服务请求的负载均衡方法"}},[v._v("#")]),v._v(" 服务请求的负载均衡方法")]),v._v(" "),_("p",[v._v("通常情况下, 计算机领域中, 在不同层有不同的负载均衡方法. 比如, 从网络层的角度, 通常有基于 DNS, IP 报文等的负载均衡方法; 在中间件层(也就是我们专栏主要讲的分布式系统层), 常见的负载均衡策略主要包括轮询策略, 随机策略, 哈希和一致性哈希等策略.")]),v._v(" "),_("p",[v._v("今天着重分析的就是, "),_("strong",[v._v("中间件层所涉及的负载均衡策略")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"轮询策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#轮询策略"}},[v._v("#")]),v._v(" 轮询策略")]),v._v(" "),_("p",[v._v("轮询策略是一种实现简单, 却很常用的负载均衡策略, 核心思想是服务器轮流处理用户请求, 以尽可能使每个服务器处理的请求数相同. 生活中也有很多类似的场景, 比如学校宿舍里, 学生每周轮流打扫卫生, 就是一个典型的轮询策略.")]),v._v(" "),_("p",[_("strong",[v._v("在负载均衡领域中, 轮询策略主要包括顺序轮询和加权轮询两种方式")]),v._v(".")]),v._v(" "),_("p",[v._v("首先一起看看"),_("strong",[v._v("顺序轮询")]),v._v(". 假设有 6 个请求, 编号为请求 1-6, 有 3 台服务器可以处理请求, 编号为服务器 1-3, 如果采用顺序轮询策略, 则会按照服务器 1, 2, 3 的顺序轮流进行请求.")]),v._v(" "),_("p",[v._v("如表所示, 将 6 个请求当成 6 个步骤:")]),v._v(" "),_("ul",[_("li",[v._v("请求 1 由服务器 1 处理;")]),v._v(" "),_("li",[v._v("请求 2 由服务器 2 进行处理.")])]),v._v(" "),_("p",[v._v("以此类推, 直到处理完这 6 个请求.")]),v._v(" "),_("p",[v._v("​"),_("img",{attrs:{src:"/img/7e63fe8d7cb530d7853ff8b44cf493e6-20230731163147-5m29q1r.png",alt:""}}),v._v("​")]),v._v(" "),_("p",[v._v("最终的处理结果是, 服务器 1 处理请求 1 和请求 4, 服务器 2 处理请求 2 和请求 5, 服务器 3 处理请求 3 和请求 6.")]),v._v(" "),_("p",[v._v("接下来看一下"),_("strong",[v._v("加权轮询")]),v._v(". 加权轮询为每个服务器设置了优先级, 每次请求过来时会挑选优先级最高的服务器进行处理. 比如服务器 1~3 分配了优先级 "),_("code",[v._v("{4, 1, 1}")]),v._v("​, 这 6 个请求到来时, 还当成 6 个步骤, 如表所示.")]),v._v(" "),_("ul",[_("li",[v._v("请求 1 由优先级最高的服务器 1 处理, 服务器 1 的优先级相应减 1, 此时各服务器优先级为 "),_("code",[v._v("{3, 1, 1}")]),v._v("​;")]),v._v(" "),_("li",[v._v("请求 2 由目前优先级最高的服务器 1 进行处理, 服务器 1 优先级相应减 1, 此时各服务器优先级为 "),_("code",[v._v("{2, 1, 1}")]),v._v("​.")])]),v._v(" "),_("p",[v._v("以此类推, 直到处理完这 6 个请求. 每个请求处理完后, 相应服务器的优先级会减 1.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b9ebf53b030b52b5aac9c7e1f8c00d68-20230731163147-n85dsue.png",alt:""}})]),v._v(" "),_("p",[v._v("最终的处理结果是, 服务器 1 处理请求 1~4, 服务器 2 处理请求 5, 服务器 3 会处理请求 6.")]),v._v(" "),_("p",[v._v("以上就是顺序轮询和加权轮询的核心原理了. 轮询策略的应用比较广泛, 比如 "),_("strong",[v._v("Nginx 默认的负载均衡策略就是一种改进的加权轮询策略.")]),v._v("  下面看看它的核心原理.")]),v._v(" "),_("p",[v._v("首先解释下 Nginx 轮询策略需要用到的变量.")]),v._v(" "),_("ol",[_("li",[v._v("weight: 配置文件中为每个服务节点设置的"),_("strong",[v._v("服务节点权重")]),v._v(", 固定不变.")]),v._v(" "),_("li",[v._v("effective_weight: 服务节点的"),_("strong",[v._v("有效权重, 初始值为 weight")]),v._v(". 在 Nginx 的源码中有一个最大失败数的变量 max_fails, 当服务发生异常时, 则减少相应服务节点的有效权重, 公式为 "),_("code",[v._v("effective_weight = effective_weight - weight / max_fails;")]),v._v("​ 之后再次选取本节点, 若服务调用成功, 则增加有效权重, effective_weight++, 直至恢复到 weight.")]),v._v(" "),_("li",[v._v("current_weight: 服务节点"),_("strong",[v._v("当前权重")]),v._v(", 初始值均为 0, 之后会根据系统运行情况动态变化.")])]),v._v(" "),_("p",[v._v("假设, 各服务器的优先级是 "),_("code",[v._v("{4, 1, 1}")]),v._v("​, 还是将 6 个请求分为 6 步来进行讲解, 如表所示:")]),v._v(" "),_("ul",[_("li",[v._v("遍历集群中所有服务节点, 使用 "),_("code",[v._v("current_weight = current_weight + effective_weight")]),v._v("​, 计算此时每个服务节点的 current_weight, 得到 current_weight 为 "),_("code",[v._v("{4, 1, 1}")]),v._v("​, total 为 "),_("code",[v._v("4+1+1=6")]),v._v("​. 选出 current_weight 值最大的服务节点即服务器 1 来处理请求, 随后服务器 1 对应的 current_weight 减去此时的 total 值, 即 4 - 6, 变为了 -2 .")]),v._v(" "),_("li",[v._v("按照上述步骤执行, 首先遍历, 按照 "),_("code",[v._v("current_weight = current_weight + effective_weight")]),v._v("​ 计算每个服务节点 current_weight 的值, 结果为 "),_("code",[v._v("{2, 2, 2}")]),v._v("​, total 为 6, 选出 current_weight 值最大的服务节点. current_weight 最大值有多个服务节点时, 直接选择第一个节点即可, 在这里选择服务器 1 来处理请求, 随后服务器 1 对应的 current_weight 值减去此时的 total, 即 2 - 6, 结果为 -4.")])]),v._v(" "),_("p",[v._v("以此类推, 直到处理完这 6 个请求.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/a4c68f5143b114ec355db0362025991e-20230731163147-hk3jk9n.png",alt:""}})]),v._v(" "),_("p",[v._v("最终的处理结果为, 服务器 1 处理请求 1, 2, 4, 6, 服务器 2 处理请求 3, 服务器 3 会处理请求 5.")]),v._v(" "),_("p",[v._v("可以看到, 与普通的加权轮询策略相比, 这种轮询策略的优势在于, **当部分请求到来时, 不会集中落在优先级较高的那个服务节点. **")]),v._v(" "),_("p",[v._v("还是上面的例子, 假设只有 4 个请求, 按照普通的加权轮询策略, 会全部由服务器 1 进行处理, 即 "),_("code",[v._v("{1,1,1,1}")]),v._v("​; 而按照这种平滑的加权轮询策略的话, 会由服务器 1 和 2 共同进行处理, 即 "),_("code",[v._v("{1,1,2,1}")]),v._v("​.")]),v._v(" "),_("p",[_("strong",[v._v("轮询策略的优点")]),v._v("就是, 实现简单, 且对于请求所需开销差不多时, 负载均衡效果比较明显, 同时加权轮询策略还考虑了服务器节点的异构性, 即可以让性能更好的服务器具有更高的优先级, 从而可以处理更多的请求, 使得分布更加均衡.")]),v._v(" "),_("p",[v._v("但"),_("strong",[v._v("轮询策略的缺点")]),v._v("是, 每次请求到达的目的节点不确定, 不适用于有状态请求的场景. 并且轮询策略主要强调请求数的均衡性, 所以不适用于处理请求所需开销不同的场景. 比如, 有两个服务器(节点 A 和节点 B)性能相同, CPU 个数和内存均相等, 有 4 个请求需要处理, 其中请求 1 和请求 3 需要 1 个 CPU, 请求 2 和请求 4 需要 2 个 CPU. 根据轮询策略, 请求 1 和请求 3 由节点 A, 请求 2 和请求 4 由节点 B 处理. 由此可见, 节点 A 和节点 B 关于 CPU 的负载分别是 2 和 4, 从这个角度来看, 两个节点的负载并不均衡.")]),v._v(" "),_("p",[v._v("综上所述, "),_("strong",[v._v("轮询策略适用于用户请求所需资源比较接近的场景")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"随机策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#随机策略"}},[v._v("#")]),v._v(" 随机策略")]),v._v(" "),_("p",[v._v("随机策略也比较容易理解, 指的就是当用户请求到来时, 会随机发到某个服务节点进行处理, 可以采用随机函数实现. 这里随机函数的作用就是让请求尽可能分散到不同节点, 防止所有请求放到同一节点或少量几个节点上.")]),v._v(" "),_("p",[v._v("如图所示, 假设有 5 台服务器 Server 1~5 可以处理用户请求, 每次请求到来时, 都会先调用一个随机函数来计算出处理节点. 这里, 随机函数的结果只能是 "),_("code",[v._v("{1,2,3,4,5}")]),v._v("​ 这五个值, 然后再根据计算结果分发到相应的服务器进行处理. 比如, 图中随机函数计算结果为 2, 因此该请求会由 Server2 处理.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7c513af9400977f9e3dabc2779a16a20-20230731163147-j15i3yk.png",alt:""}})]),v._v(" "),_("p",[v._v("这种方式的优点是, 实现简单, 但缺点也很明显, 与轮询策略一样, 每次请求到达的目的节点不确定, 不适用于有状态的场景, 而且没有考虑到处理请求所需开销. 除此之外, 随机策略也"),_("strong",[v._v("没有考虑服务器节点的异构性")]),v._v(", 即性能差距较大的服务器可能处理的请求差不多. 因此随机策略适用于, 集群中服务器节点处理能力相差不大, 用户请求所需资源比较接近的场景.")]),v._v(" "),_("h6",{attrs:{id:"哈希和一致性哈希策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#哈希和一致性哈希策略"}},[v._v("#")]),v._v(" 哈希和一致性哈希策略")]),v._v(" "),_("p",[v._v("无论是轮询还是随机策略, 对于一个客户端的多次请求, 每次落到的服务器很大可能是不同的, 如果这是一台缓存服务器, 就会对缓存同步带来很大挑战. 尤其是系统繁忙时, 主从延迟带来的同步缓慢, 可能会造成同一客户端两次访问得到不同的结果. 解决方案就是, "),_("strong",[v._v("利用哈希算法定位到对应的服务器")]),v._v(".")]),v._v(" "),_("p",[v._v("数据请求就是用户请求的一种, 哈希, 一致性哈希, 带有限负载的一致性哈希和带虚拟节点的一致性哈希算法, 同样适用于请求负载均衡.")]),v._v(" "),_("p",[v._v("所以, "),_("strong",[v._v("哈希与一致性策略的优点")]),v._v("是, 哈希函数设置合理的话, 负载会比较均衡. 而且相同 key 的请求会落在同一个服务节点上, 可以用于有状态请求的场景. 除此之外, 带虚拟节点的一致性哈希策略还可以解决服务器节点异构的问题.")]),v._v(" "),_("p",[v._v("但其"),_("strong",[v._v("缺点是")]),v._v(", 当某个节点出现故障时, 采用哈希策略会出现数据大规模迁移的情况, 采用一致性哈希策略可能会造成一定的数据倾斜问题. 同样的, 这两种策略也没考虑请求开销不同造成的不均衡问题.")]),v._v(" "),_("p",[v._v("应用哈希和一致性哈希策略的框架有很多, 比如 Redis, Memcached, Cassandra 等.")]),v._v(" "),_("p",[v._v("除了以上这些策略, 还有一些负载均衡策略比较常用. 比如根据服务节点中的资源信息(CPU, 内存等)进行判断, 服务节点资源越多, 就越有可能处理下一个请求; 再比如, 根据请求的特定需求, 如请求需要使用 GPU 资源, 那就需要由具有 GPU 资源的节点进行处理等.")]),v._v(" "),_("h6",{attrs:{id:"对比分析-4"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#对比分析-4"}},[v._v("#")]),v._v(" 对比分析")]),v._v(" "),_("p",[v._v("以上, 就是轮询策略, 随机策略, 哈希和一致性哈希策略的主要内容了. 接下来再通过一个表格对比下这三种方法.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b5d024569f83eee97dcd1773240bb888-20230731163147-5ml9nkf.png",alt:""}})]),v._v(" "),_("blockquote",[_("p",[v._v("知识扩展: 如果要考虑请求所需资源不同的话, 应该如何设计负载均衡策略呢?")])]),v._v(" "),_("p",[v._v("上面提到的轮询策略, 随机策略, 以及哈希和一致性哈希策略, 主要考虑的是请求数的均衡, "),_("strong",[v._v("并未考虑请求所需资源不同造成的不均衡问题. 那么, 如何设计负载均衡策略, 才能解决这个问题呢")]),v._v("?")]),v._v(" "),_("p",[v._v("其实, 这个问题的解决方案有很多, 常见的思路主要是"),_("strong",[v._v("对请求所需资源与服务器空闲资源进行匹配, 也称调度")]),v._v(".")]),v._v(" "),_("p",[v._v("可以"),_("strong",[v._v("使用单体调度的思路")]),v._v(', 让集群选举一个主节点, 每个从节点会向主节点汇报自己的空闲资源; 当请求到来时, 主节点通过资源调度算法选择一个合适的从节点来处理该请求. 单体调度中有最差匹配和最佳匹配算法. 这两种算法各有利弊, 最差匹配算法可以尽量将请求分配到不同机器, 但可能会造成资源碎片问题; 而最佳匹配算法, 虽然可以留出一些 "空" 机器来处理开销很大的请求, 但会造成负载不均的问题. 因此它们适用于不同的场景.')]),v._v(" "),_("p",[v._v("除此之外, "),_("strong",[v._v("一致性哈希策略")]),v._v("也可以解决这个问题: "),_("strong",[v._v("让请求所需的资源和服务器节点的空闲资源, 与哈希函数挂钩, 即通过将资源作为自变量, 带入哈希函数进行计算, 从而映射到哈希环中")]),v._v(".")]),v._v(" "),_("p",[v._v("比如设置的哈希函数结果与资源正相关, 这样就可以让资源开销大的请求由空闲资源多的服务器进行处理, 以实现负载均衡. 但这种方式也有个缺点, 即哈希环上的节点资源变化后, 需要进行哈希环的更新.")]),v._v(" "),_("h5",{attrs:{id:"总结-24"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-24"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节介绍了常见的负载均衡策略, 包括轮询策略, 随机策略, 哈希和一致性哈希策略. 其中, 轮询策略和随机策略, 因为每次请求到达的目的节点不确定, 只适用于无状态请求的场景; 而哈希和一致性哈希策略, 因为相同 key 的请求会落在同一个服务节点上, 所以可以用于有状态请求的场景.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/91adc614e6107c71a25725d888540060-20230731163147-p8vnfr9.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_29-分布式高可靠之流量控制-大禹治水-在疏不在堵"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_29-分布式高可靠之流量控制-大禹治水-在疏不在堵"}},[v._v("#")]),v._v(" 29-分布式高可靠之流量控制:大禹治水,在疏不在堵")]),v._v(" "),_("p",[v._v("上一节学习了负载均衡. 负载均衡的核心在于, 将用户请求均匀分配到多个处理服务器处理, 以解决单个服务器的单点瓶颈问题. 但如果用户请求数非常多的话, 即便实现了负载均衡, 服务器能力达到上限, 还是无法处理所有的用户请求.")]),v._v(" "),_("p",[v._v("比如, 类似双十一, 双十二的秒杀场景, 用户流量突增时, 即使做了负载均衡, 仍然会感受到点击抢购时, 需要等待较长的时间. 这背后的原理是什么呢?")]),v._v(" "),_("h5",{attrs:{id:"什么是流量控制"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是流量控制"}},[v._v("#")]),v._v(" 什么是流量控制?")]),v._v(" "),_("p",[v._v("说到流量控制, 大家第一反应可能是网络传输中的流量控制. 网络传输中的流量控制, 就是让发送方发送数据的速率不要太快, 让接收方来得及接收数据, 具体的实现方法就是滑动窗口.")]),v._v(" "),_("p",[v._v("简单来讲, 滑动窗口指的是, 在任意时刻, 发送方都维持一个连续的允许发送的数据大小, 称为发送窗口; 接收方也会维持一个连续的允许接收的数据大小, 称为接收窗口. 每次发送方给接收方发送数据后, 必须收到接收方返回的确认消息, 发送窗口才可向后移动, 发送新的数据.")]),v._v(" "),_("p",[v._v("那么"),_("strong",[v._v("具体到分布式系统中, 流量控制又是什么呢")]),v._v("? 在双十一, 双十二秒杀场景中, 用户流量突增, 在这种高并发, 大流量的情况下, 服务器的处理能力成为电商系统的瓶颈, 处理不好就会导致系统崩溃, 服务不可用. 而分布式系统中的流量控制, 就是解决这类问题的一种关键技术.")]),v._v(" "),_("p",[v._v("通俗地说, "),_("strong",[v._v('分布式流量控制就是在分布式系统下, 控制每个服务器接收的请求数, 以保证服务器来得及处理这些请求, 也就是说尽可能保证用户请求持续地被处理, 而不是让大量的用户请求"阻塞"在服务器中, 等待被执行')]),v._v(".")]),v._v(" "),_("p",[v._v("接下来就一起学习下分布式系统常用的流量控制策略.")]),v._v(" "),_("h5",{attrs:{id:"分布式系统流量控制策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统流量控制策略"}},[v._v("#")]),v._v(" 分布式系统流量控制策略")]),v._v(" "),_("p",[v._v("消息队列就是实现流量控制的一种方法, 通过一个消息队列来存放用户的消息, 然后服务器到消息队列中逐个消费, 就可以避免消息过多时服务器处理不过来的情况.")]),v._v(" "),_("p",[v._v("除此之外, 分布式系统的流量控制策略还有很多, 常用的主要包括两种: "),_("strong",[v._v("漏桶策略和令牌桶策略")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"漏桶策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#漏桶策略"}},[v._v("#")]),v._v(" 漏桶策略")]),v._v(" "),_("p",[v._v('相信你看到 "漏桶" 两个字, 头脑里应该已经有了一个漏桶的样子. 确实名字就已经很形象地说明了这种策略的含义. 如下图所示, 有一个固定容量的水桶, 桶底有一个小洞, 水桶可以接收任意速率的水流, 但无论水桶里有多少水, 水从小洞流出的速率始终不变, 桶里的水满了之后, 水就会溢出.')]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/33647cca181c36159309489632ec2e83-20230731163147-45ylcu2.png",alt:""}})]),v._v(" "),_("p",[_("mark",[_("strong",[v._v('漏桶策略借鉴上述原理, 无论用户请求有多少, 无论请求速率有多大, "漏桶" 都会接收下来, 但从漏桶里出来的请求是固定速率的, 保证服务器可以处理得游刃有余. 当"漏桶"因为容量限制放不下更多的请求时, 就会选择丢弃部分请求. 这种思路其实就是一种 "宽进严出" 的策略.')])])]),v._v(" "),_("p",[v._v("比如, 在某段时间内, 系统每秒会有 10 个用户发出请求, 但这些请求经过漏桶后, 每秒始终只流出 2 个请求, 也就是说服务器每秒最多处理 2 个请求. 这样的话, 无论请求速率有多大, 都能达到限流的目的, 避免服务器在短暂时间内需要处理大量请求, 但由于处理能力受限导致系统崩溃, 从而保证了系统的高可靠.")]),v._v(" "),_("p",[v._v("这种策略的好处是, 做到了"),_("strong",[v._v("流量整形")]),v._v(", 即无论流量多大, 即便是突发的大流量, 输出依旧是一个稳定的流量. 但其"),_("strong",[v._v("缺点是, 对于突发流量的情况, 因为服务器处理速度与正常流量的处理速度一致, 会丢弃比较多的请求")]),v._v(". 但是, 当突发大流量到来时, 服务器最好能够更快地处理用户请求, 这也是分布式系统大多数情况下想要达到的效果.")]),v._v(" "),_("p",[v._v("所以说, "),_("strong",[v._v("漏桶策略适用于间隔性突发流量且流量不用即时处理的场景")]),v._v(', 即可以在流量较小时的 "空闲期", 处理大流量时流入漏桶的流量; 不适合流量需要即时处理的场景, 即突发流量时可以放入桶中, 但缺乏效率, 始终以固定速率进行处理.')]),v._v(" "),_("p",[v._v("目前, 漏桶算法已经用于很多框架了, 比如阿里开源的流量控制框架 Sentinel 中的匀速排队限流策略, 就采用了漏桶算法; 分布式追踪系统 Jaeger 中, 有一种采集策略是速率限制类型, 内部使用的也是漏桶算法等.")]),v._v(" "),_("h6",{attrs:{id:"令牌桶策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#令牌桶策略"}},[v._v("#")]),v._v(" 令牌桶策略")]),v._v(" "),_("p",[v._v("令牌桶策略, 也是一个很形象的名字, 指的是桶里放着很多令牌, 请求只有拿到令牌才能被服务器处理.")]),v._v(" "),_("p",[v._v("如图所示, "),_("mark",[_("strong",[v._v("有一个固定容量的存放令牌的桶, 以固定速率向桶里放入令牌, 桶满时会丢弃多出的令牌. 每当请求到来时, 必须先到桶里取一个令牌才可被服务器处理, 也就是说只有拿到了令牌的请求才会被服务器处理")])]),v._v(". 所以, 可以将令牌理解为门卡, 只有拿到了门卡才能顺利进入房间.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4d6c6540455f07baf82ac6853303e56e-20230731163147-a10howi.png",alt:""}})]),v._v(" "),_("p",[v._v("同样通过一个具体的例子, 来加深对令牌桶策略的理解.")]),v._v(" "),_("p",[v._v("假设令牌以每秒 3 个的速率放入到令牌桶中, 桶的容量为 10. 通常情况下, 每秒会有 2 个用户请求, 请求到来时就会到桶里取一个令牌, 由于请求的速率低于放令牌的速率, 因此令牌桶里"),_("strong",[v._v("令牌会逐渐增多, 直到达到桶的容量")]),v._v(". 超过桶容量后, 令牌会被丢弃.")]),v._v(" "),_("p",[v._v("当大流量到来时, 比如某个时刻来了 10 个请求, 此时桶里有 10 个令牌, 因此请求"),_("strong",[v._v("都会被服务器处理")]),v._v("; 但如果来的请求数不止 10 个, 令牌会被取完, 多余的请求取不到令牌, 也就没办法及时被服务器处理, 需要等待令牌.")]),v._v(" "),_("p",[v._v("通过上述的例子, 就能看出这种策略的好处: 当有突发大流量时, 只要令牌桶里有足够多的令牌, 请求就会被迅速执行. 通常情况下, 令牌桶容量的设置, 可以接近服务器处理的极限, 这样就可以有效利用服务器的资源. 因此, 这种策略"),_("mark",[_("strong",[v._v("适用于有突发特性的流量, 且流量需要即时处理的场景")])]),v._v(".")]),v._v(" "),_("p",[v._v("在实际使用中, 令牌桶算法也很常见. 比如, Google 开源工具包 Guava 提供的限流工具类 "),_("strong",[v._v("RateLimiter, 就是基于令牌桶算法来完成限流")]),v._v("的.")]),v._v(" "),_("h6",{attrs:{id:"两种策略对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#两种策略对比"}},[v._v("#")]),v._v(" 两种策略对比")]),v._v(" "),_("p",[v._v("以上就是漏桶策略和令牌桶策略的核心原理了, 接下来通过一张表格对比下这两种策略.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b6f8da2091d7ae6f0b395e760f4a760d-20230731163147-f60kosj.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"sentinel流量控制工作原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sentinel流量控制工作原理"}},[v._v("#")]),v._v(" Sentinel流量控制工作原理")]),v._v(" "),_("p",[v._v("接下来以阿里开源的流量控制框架 Sentinel 为例, 进一步介绍流量控制的工作原理.")]),v._v(" "),_("p",[_("strong",[v._v("Sentinel 的核心是, 监控应用的并发线程数或 QPS(请求数 / 每秒)指标, 当达到系统设定的阈值时, Sentinel 可以采取一定的策略对流量进行控制, 以避免应用被瞬时高流量击垮, 从而保证应用高可靠.")])]),v._v(" "),_("p",[v._v("为此, 在 Sentinel 中, 关于流量控制有两种方式: 一种是"),_("mark",[_("strong",[v._v("通过并发线程数")])]),v._v("进行流量控制, 另一种是"),_("mark",[_("strong",[v._v("通过 QPS 指标")])]),v._v("进行流量控制.")]),v._v(" "),_("p",[_("strong",[v._v("首先看一下通过并发线程数进行流量控制.")])]),v._v(" "),_("p",[v._v("要理解这种限流方式, 需要先搞清楚什么是线程池. 过多的线程会消耗非常多的系统资源, 包括线程资源消耗, 线程调度消耗等. 为了解决这个问题, 就引入了线程池. 线程池维护了多个启动着的线程, 随时等待着去执行系统分配的任务, 即系统每次需要处理任务时, 可以直接从线程池中取线程, 从而避免了创建和销毁线程的时间和资源等消耗.")]),v._v(" "),_("p",[_("mark",[_("strong",[v._v("同一时刻每个线程只能执行一个任务或请求, 因此可以通过并发线程数进行流量控制")])]),v._v(". 看一个案例.")]),v._v(" "),_("p",[v._v("如图所示, 假设现在线程池中有 3 个线程, 也就是说最大并发处理数为 3, 现在有 2 个请求 Q1 和 Q2 到来, 由于请求数少于线程数, 因此请求可以被并发执行. 线程池中启动着的线程 1 和线程 2 会进行相应的处理, 而不会创建新线程, 除此之外, 线程处理完请求后也不会被销毁, 而是回到线程池中继续等待新的请求.")]),v._v(" "),_("p",[v._v("但如果现在同时有 4 个请求到来, 那么只有 3 个请求可以被并发处理, 而剩下的一个请求要么丢弃, 要么等待空闲线程.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/baeba381e0943a67bd3520c1d0b616c6-20230731163147-tqykk03.png",alt:""}})]),v._v(" "),_("p",[v._v("在分布式系统中, 每个请求都会由一个线程去进行处理. 当请求太多系统处理不过来时, 意味着线程池可能已经被耗尽(线程池中无空闲线程), 因此当请求过多时, 执"),_("strong",[v._v("行请求的并发线程数自然会随之增加, 当超过一定的阈值(比如线程池中线程总数)时, 需要采取一定的策略来进行流量控制")]),v._v(".")]),v._v(" "),_("p",[v._v("在 Sentinel 中, 就采用了直接拒绝的方式, 即新来的请求会直接拒绝.")]),v._v(" "),_("p",[_("strong",[v._v("然后再看一下通过 QPS 指标进行流量控制.")])]),v._v(" "),_("p",[v._v("QPS 是指每秒的请求数, 大流量也就意味着 QPS 大. 当 QPS 达到阈值时, Sentinel 提供了"),_("strong",[v._v("三种流量控制策略, 分别是直接拒绝, 预热(Warm Up)和匀速排队")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("直接拒绝, 是最直接也是最暴力的方式")]),v._v(", 与并发线程数流量控制采取的方式一致, 就是当 QPS 达到系统设定的阈值时, 直接拒绝新来的请求. 这种策略乍一听起来确实不是很好, 但对于系统处理能力确切已知的情况(即阈值设定为每秒能接受的最大处理请求数), 却非常实用. 当请求超出阈值时, 可以直接拒绝, 因为系统已经没有更多的能力来处理多余的请求了. 因此, "),_("strong",[v._v("该策略适用于对系统处理能力确切已知的场景")]),v._v(".")]),v._v(" "),_("p",[v._v("接下来看看"),_("strong",[v._v("预热")]),v._v(". 当系统的 QPS 长期处于一个较低水平时, 一旦发生流量骤增, 如果直接让系统每秒处理大量的请求, 可能会因为服务器处理能力不足, 导致系统崩溃. 因此, Sentinel "),_("strong",[v._v('提供了一种 "预热" 机制, 让系统的 QPS 缓慢增加, 在一定的时间内逐渐增加到上限')]),v._v(".")]),v._v(" "),_("p",[v._v("下面以一个例子为例, 进一步理解预热的原理. 如下图所示, 假设通常情况下系统每秒处理 3 个请求, 即 QPS=3, 当用户请求增加时, 系统每秒处理的请求数相应增加, 但不会一下子提高很多. 比如每秒增加 1 个处理请求, 逐步达到 QPS=10 的处理上限, 并不再继续增加, 从而避免大流量一下子导致系统故障.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/15f0f115293f244b3e908c7e4a318e60-20230731163147-xcwfxqv.png",alt:""}})]),v._v(" "),_("p",[v._v("可以看出, 预热这种策略有点像是一种特殊的令牌桶: "),_("strong",[v._v("放令牌的速率通常保持在一个较低的水平, 当流量突增时, 放令牌的速率不会一下子提高到最高水平, 而是会慢慢增加, 直到增加到最大速率则不可再增加")]),v._v(". 因此, 该策略与令牌桶策略的适用场景类似, 即适用于具有突发特性的流量, 且流量可以即时处理的场景.")]),v._v(" "),_("p",[_("strong",[v._v("匀速排队")]),v._v("的思想, 其实本质就是"),_("strong",[v._v("漏桶策略")]),v._v(". 它会严格控制系统每秒处理的请求数, 请求数很多时, 请求之间的间隔也会保持一致.")]),v._v(" "),_("p",[v._v("如图所示, 当 QPS=5 时, 每隔 200ms 才允许服务器处理下一个请求. 假设请求队列中有 10 个请求瞬间到达, 服务器不会一下子全处理完, 而是按照请求的顺序, 每 200ms 处理一个请求, 直到处理完所有请求. 这时处理的请求就像是在匀速排队, 因此得名.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/471bb95e1e6d93028d7621523f1def05-20230731163147-mdq225s.png",alt:""}})]),v._v(" "),_("p",[v._v("该策略中, 系统会设定一个时间间隔 T, 假设最大排队时长设置为 6T, 上次请求通过的时刻为 t1. 当新的请求在 t2 时刻到来的话, 则进行判断, 首先查看是否还有其他请求在排队. 如果没有请求在排队, 分两种情况:")]),v._v(" "),_("ol",[_("li",[v._v("当 t2 - t1 的值大于或等于时间间隔 T, 请求可以通过;")]),v._v(" "),_("li",[v._v("当 t2 - t1 的值小于 T 时, 需要等待, 直到 t2 - t1 的值达到时间间隔 T 时, 才可以让请求通过.")])]),v._v(" "),_("p",[v._v("而如果新请求到来时, 已经有请求在排队, 就需要计算该新请求的预期通过时间. 比如有 3 个请求在排队, 则该新请求预期通过时间为 t1+4T, 因为需要等到在该请求前面的请求都通过后该请求才可通过, 且两个请求通过的时间间隔必须达到 T 才可以. 另外, 若排队的请求过多, 新来的请求预期等待时间超出最大排队时长, 即等待时间超过 6T 时, 则直接拒接这个请求.")]),v._v(" "),_("p",[v._v("因此, 匀速排队的适用场景与漏桶策略类似, 即适用于间隔性突发流量且流量不用即时处理的场景.")]),v._v(" "),_("h5",{attrs:{id:"总结-25"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-25"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v('本节介绍了常见的流量控制策略, 包括漏桶策略和令牌桶策略. 其中, 漏桶策略的核心是 "宽进严出", 发送给服务器进行处理的请求速率固定, 以避免超过服务器处理能力上限, 导致系统崩溃, 但这种方式不适合突发流量增加的场景. 令牌桶策略的核心是, 只要桶里有令牌, 请求就可以被处理, 只要在服务器处理能力内即可, 所以适用于处理及时且处理速率非固定的场景.')]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e459d4b7a6e69b3da707d9098b9248b4-20230731163147-1r4366d.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_30-分布式高可用之故障隔离-当断不断-反受其乱"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_30-分布式高可用之故障隔离-当断不断-反受其乱"}},[v._v("#")]),v._v(" 30-分布式高可用之故障隔离:当断不断,反受其乱")]),v._v(" "),_("p",[v._v("前两节学习了分布式系统高可靠的关键技术, 包括分布式负载均衡和流量控制. 除了高可靠, 在实际生产中, 分布式系统的高可用问题也极其重要.")]),v._v(" "),_("p",[v._v("比如, 在双十一的抢购高峰期, 如果分布式系统不能满足高可用的特性, 那么当大量用户同时抢购时就可能导致系统崩溃, 无法提供服务, 导致大量用户流失.")]),v._v(" "),_("p",[v._v("因此, 接下来将从故障隔离和恢复机制这两项关键技术入手, 学习如何保证分布式系统的高可用.")]),v._v(" "),_("h5",{attrs:{id:"什么是故障隔离"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是故障隔离"}},[v._v("#")]),v._v(" 什么是故障隔离?")]),v._v(" "),_("p",[v._v("从字面意思来看, 故障隔离就是把故障通过某种方式与其他正常模块进行隔离, 以保证某一模块出现故障后, 不会影响其他模块.")]),v._v(" "),_("p",[v._v("其实生活有很多故障隔离的例子, 比如交通. 一辆车就类似于分布式系统中的一个模块, 当一辆车在高速公路上出现故障后, 通常会将其停靠在紧急车道, 或者在其前后设置故障指示牌, 以防止其他车辆与其相撞, 引起更大的交通事故. 这种将故障车辆停靠在路边紧急车道或设置故障指标牌的方法, 就是一种故障隔离.")]),v._v(" "),_("p",[v._v("回到分布式系统, "),_("mark",[_("strong",[v._v("故障隔离, 就是采用一定的策略, 以实现当某个模块故障时, 不会影响其他模块继续提供服务, 以保证整个系统的可用性. 所以故障隔可以避免分布式系统出现大规模的故障, 甚至是瘫痪, 降低损失")])]),v._v(".")]),v._v(" "),_("p",[v._v("在分布式系统中, 要实现故障隔离, 通常需要在进行系统设计时, 提前对可能出现的故障进行预防, 以使得在出现故障后能实现故障隔离. 此外, 由于是提前设计预防的, 因此故障隔离还可以帮助快速定位故障点.")]),v._v(" "),_("p",[v._v("也就是说, 分布式系统中的故障隔离策略是在系统设计时就进行考虑, 从预防的角度来实现故障发生时, 该模块故障不会影响其他模块. 因此, "),_("strong",[v._v("本节介绍的故障隔离策略, 是整个系统设计时, 从高可用这个维度进行设计的策略.")])]),v._v(" "),_("p",[v._v("理解了故障隔离为什么可以提高分布式系统的可用性以后, 再来看看实现故障隔离有哪些常见策略.")]),v._v(" "),_("h5",{attrs:{id:"分布式故障隔离策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式故障隔离策略"}},[v._v("#")]),v._v(" 分布式故障隔离策略")]),v._v(" "),_("p",[v._v("分布式系统中的故障隔离策略有很多, 大体上可以从两个维度来划分:")]),v._v(" "),_("ol",[_("li",[_("strong",[v._v("一类是以系统功能模块为粒度进行隔离")]),v._v(". 比如, 通过系统功能/服务划分, 将系统分为多个功能/服务模块, 各个功能/服务模块之间实现松耦合, 即一个功能/服务模块出现故障, 不会影响其他功能/服务模块, 根据功能模块或服务由线程执行还是进程执行, 通常分为线程级隔离, 进程级隔离.")]),v._v(" "),_("li",[_("strong",[v._v("另一类是, 通过资源隔离来实现")]),v._v(". 比如系统中各个模块拥有自己独立的资源, 不会发生资源争抢, 从而大大提升系统性能. 根据资源所属粒度, 通常包括进程级隔离(比如采用容器隔离), 虚拟机隔离, 服务器隔离和机房隔离等.")])]),v._v(" "),_("p",[v._v("基于这个分类, 接下来将讲述三种比较常见的故障隔离策略, 包括"),_("strong",[v._v("以功能模块为粒度进行隔离的线程级隔离和进程级隔离, 以及以资源为隔离维度的资源隔离")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"线程级隔离"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#线程级隔离"}},[v._v("#")]),v._v(" 线程级隔离")]),v._v(" "),_("p",[_("strong",[v._v("线程级故障隔离, 是指使用不同的线程池处理不同的请求任务. 当某种请求任务出现故障时, 负责其他请求任务的线程池不会受到影响, 即会继续提供服务, 从而实现故障的隔离.")])]),v._v(" "),_("p",[v._v("如图所示, 以电商购物平台为例, 假设初期运行在单台机器的一个进程中, 在这个进程中有三个线程池, 分别负责订单任务, 支付任务和配送任务. 这样当订单请求出现故障时, 不会影响已下单用户的支付和仓库配送服务.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c1fb9eb13e613b6881109367edb54314-20230731163147-7r4vkac.png",alt:""}})]),v._v(" "),_("p",[_("strong",[v._v("线程级的故障隔离策略, 在生产环境中较为常用, 尤其对于单体应用")]),v._v("(单进程多线程的应用). 在单体应用场景下, 应用被单个进程执行, 但单进程中包括多个线程, 因此该场景下, 只需要实现线程级隔离即可, 实现简单, 效果好, 因此是一种很常用的方式.")]),v._v(" "),_("p",[v._v("系统实现线程级隔离后, 线程间的通信通常使用"),_("strong",[v._v("共享变量")]),v._v("来实现. 简单地说, 共享变量就是一个进程中的全局变量, 在进程的各个线程间可以同时使用. 这种通信方式, 实现简单且效果明显.")]),v._v(" "),_("h6",{attrs:{id:"进程级隔离"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#进程级隔离"}},[v._v("#")]),v._v(" 进程级隔离")]),v._v(" "),_("p",[v._v("随着业务逐渐扩大, 业务系统也会越来越复杂, 单体应用可能无法满足公司与用户的需求, 这时候就需要对系统进行拆分.")]),v._v(" "),_("p",[v._v("一种常用的方式就是, "),_("strong",[v._v("将系统按照功能分为不同的进程")]),v._v(", 分布到相同或不同的机器中. 如果系统的进程分布到不同机器上的话, 从资源的角度来看, 也可以说成是主机级的故障隔离. 因为从另一个层面看, 系统确实分布到了不同机器上, 当某个机器出现故障时, 不会对其他机器造成影响.")]),v._v(" "),_("p",[v._v("如图所示, 电商购物平台可以分为订单系统, 支付系统和配送系统三部分. 这三个子系统可以采用三个不同的进程来服务用户. 这就是一个进程级的故障隔离方案, 即不同的子系统对应不同的进程, 某一个子系统出现故障, 都不会导致其他系统不可用.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/b89e3bfcb74a177666ade900f7dc52bf-20230731163147-lye92zg.png",alt:""}})]),v._v(" "),_("p",[v._v("系统实现进程级隔离后, 进程间的协同必须通过"),_("strong",[v._v("进程间通信")]),v._v("(IPC)来实现. 进程间通信有很多方式, 大体可以分为以下两类:")]),v._v(" "),_("ol",[_("li",[v._v("如果进程都在同一台机器上, 则可以通过"),_("strong",[v._v("管道, 消息队列, 信号量, 共享内存")]),v._v("等方式来实现;")]),v._v(" "),_("li",[v._v("如果进程分布在不同机器上, 则可以通过"),_("strong",[v._v("远程调用")]),v._v("来实现.")])]),v._v(" "),_("p",[v._v("进程级故障隔离, 目前在分布式应用中应用广泛, 比如常见的电商, 火车票购买等业务都可以采用.")]),v._v(" "),_("h6",{attrs:{id:"资源隔离"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#资源隔离"}},[v._v("#")]),v._v(" 资源隔离")]),v._v(" "),_("p",[v._v("前面介绍的是以"),_("strong",[v._v("服务或功能模块")]),v._v("为粒度进行隔离的, 下面一起看下从资源角度进行隔离是怎么做的.")]),v._v(" "),_("p",[v._v("简单来说, "),_("strong",[v._v("资源隔离就是将分布式系统的所有资源分成几个部分, 每部分资源负责一个模块, 这样系统各个模块就不会争抢资源, 即资源之间互不干扰")]),v._v(". 这种方式不仅可以提高硬件资源利用率, 也便于系统的维护与管理, 可以大幅提升系统性能.")]),v._v(" "),_("p",[v._v("微服务就是一个典型的例子. 在微服务的理念中, 是尽可能将服务最小化, 服务与服务之间进行解耦合, 包括运行环境的相互隔离等. 比如, 现在通常采用容器进行隔离, 比如 Mesos 和 Kuberntes 的上层应用很多都是微服务.")]),v._v(" "),_("p",[v._v("实际上, 在微服务框架中, 一个服务通常对应一个容器, 而一个容器其实就是操作系统中一个进程, 不同容器负责不同的服务, 就类似于刚才所讲的: 不同进程负责系统不同的功能模块.")]),v._v(" "),_("p",[v._v("如图所示, 如果将电商购物平台微服务化, 则可以启动三个容器, 分别负责订单服务, 支付服务和配送服务. 一个容器对应一个进程, 因此微服务框架本质上还是一种进程级故障隔离策略.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/7c5b7e3decfc1973e7ae4cb2620456b7-20230731163147-hiozaqo.png",alt:""}})]),v._v(" "),_("p",[v._v("但与进程级隔离不同的是, "),_("strong",[v._v("微服务框架采用容器进行故障隔离")]),v._v(". 容器虽然本质上是操作系统的一个进程, 但具备普通进程不具备的特性, 比如"),_("strong",[v._v("资源隔离")]),v._v(".")]),v._v(" "),_("ol",[_("li",[v._v("一个普通进程有很大的计算或内存需求时, 可能会占满物理机上所有的 CPU, 内存资源, 导致其他进程没有资源可用, 引发进程间的资源争夺;")]),v._v(" "),_("li",[v._v("但容器可以实现资源限制, 让每个容器占用的资源都有一个上限, 比如 CPU, 内存, 均会设置一个上限值, 这个上限值限定了该容器的处理能力, 就好比一台服务器具有资源上限值一样. 因此一个容器使用的资源不会影响其他容器的资源, 从而避免资源争抢, 提高性能.")])]),v._v(" "),_("p",[v._v('那到底什么是容器呢? 容器是一种虚拟化技术, 可以为应用提供一整套运行环境. 容器通过限制自身使用的资源来实现资源隔离, 从而让容器就像一个个的 "集装箱": 容量固定, 存放着任意的物品. 目前, 比较常用的容器是 Docker. Docker 主要'),_("strong",[v._v("使用 Linux 内核中的 Linux Cgroups 模块来设置容器的资源上限, 包括 CPU, 内存, 磁盘, 网络带宽等. 通过 Cgroups 模块, 容器间就形成了资源隔离, 从而避免了容器间的资源争夺, 提升了系统性能")]),v._v(".")]),v._v(" "),_("p",[v._v("除了容器级别的资源隔离, 虚拟机级别的隔离也是资源隔离的一种常用手段, 一台物理机可以安装多个虚拟机, 每个虚拟机都会分配一定的资源, 即进行资源隔离. 除此之外, 主机级别的隔离也可以说是一种资源隔离, 每台机器的资源是独享的, 不会与其他机器发生资源争夺, 从而做到资源隔离.")]),v._v(" "),_("p",[v._v("除了以上所讲到的故障隔离策略, 其实还有一些更粗力度的隔离策略, 比如"),_("strong",[v._v("集群隔离, 机房隔离")]),v._v("等, 这些策略主要是跨集群或跨地域的隔离策略. 这些粗粒度的隔离策略, 不仅可以根据系统功能/服务等维度对系统进行划分, 比如每个功能/服务由一个集群或一个机房单独负责, 而且也是一种资源隔离策略, 即集群间或机房间资源互相隔离, 不会发生资源争夺, 互不影响.")]),v._v(" "),_("h6",{attrs:{id:"故障隔离策略综合对比"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#故障隔离策略综合对比"}},[v._v("#")]),v._v(" 故障隔离策略综合对比")]),v._v(" "),_("p",[v._v("以上就是分布式应用中常用的几种故障隔离策略了. 接下来再通过一个表格进行对比分析, 以便于理解和记忆.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/d52c43685df206b6ccfc9dbd0fc351f2-20230731163147-ym5qdoq.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"知识扩展-从用户角度看有哪些常用的故障隔离方案"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-从用户角度看有哪些常用的故障隔离方案"}},[v._v("#")]),v._v(" 知识扩展:从用户角度看有哪些常用的故障隔离方案?")]),v._v(" "),_("p",[v._v("无论是按照功能/服务划分模块, 实现进程级, 虚拟机级等故障隔离, 还是按照系统资源进行故障隔离, 它们都是一种针对服务方的故障隔离手段. 除此之外, 还有一种故障隔离策略是, 针对用户的, 即"),_("strong",[v._v("用户级别的故障隔离")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("用户级别的故障隔离是指, 将不同用户分开, 当系统出现故障时, 只影响部分用户, 而不是全体用户")]),v._v('. 比如, 发布产品前大多会有一个 "灰度发布" 过程,  就是先发布给一小部分用户进行测试, 如果没问题再大规模发布; 如果有问题也只是影响一小部分用户. 这就是一种典型的用户级别的故障隔离. 常用的用户级别故障隔离策略, 有数据分片, 负载均衡等.')]),v._v(" "),_("p",[v._v("以数据分片为例, 系统可以将不同用户的数据存储到不同的数据库, 即一个数据库只存储部分用户的信息. 这样当某个数据库出现故障时, 仅影响该故障数据库存储的用户, 而不会影响全部用户.")]),v._v(" "),_("p",[v._v("负载均衡也是这个道理. 当处理请求的某个服务器出现故障时, 只影响该故障服务器负责的用户请求, 而不会影响其他服务器负责的用户请求.")]),v._v(" "),_("h5",{attrs:{id:"总结-26"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-26"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节学习了分布式高可用技术中的故障隔离技术. 首先以汽车故障为例, 了解了故障隔离的概念, 并引出分布式系统中的故障隔离. 分布式系统中的故障隔离技术是, 在进行分布式系统可用性设计时, 考虑故障隔离的设计, 也就是提前预防或避免出现故障后对整个系统造成影响.")]),v._v(" "),_("p",[v._v("然后介绍了常见的故障隔离策略, 包括线程级隔离, 进程级隔离和资源隔离策略. 其中, 线程级隔离和进程级隔离是从对功能/服务模块进行隔离的维度进行划分的, 借助了系统本身对线程或进程的隔离机制实现故障隔离; 资源隔离是从资源的维度进行隔离, 主要通过容器, 服务器, 集群, 机房等物理资源维度进行隔离.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c4b5ca630075feca481191efbf41baa0-20230731163147-g8kmhz5.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_31-分布式高可用之故障恢复-知错能改-善莫大焉"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_31-分布式高可用之故障恢复-知错能改-善莫大焉"}},[v._v("#")]),v._v(" 31-分布式高可用之故障恢复:知错能改,善莫大焉")]),v._v(" "),_("p",[v._v("上一节学习了故障隔离. "),_("strong",[v._v("故障隔离的目的是, 对故障组件进行隔离, 以避免其影响系统中的其他组件, 尽可能保证分布式系统的可用性")]),v._v(".")]),v._v(" "),_("p",[v._v("在分布式系统中, 故障在所难免, 发生故障后仅仅进行隔离还远远不够, 还需要进行"),_("strong",[v._v("故障恢复")]),v._v(". 比如, 现在集群中有 3 个节点, 节点 1 故障后, 对节点 1 进行隔离, 如果节点 2, 节点 3 紧接着故障了, 又隔离了这两个节点. 那么, 整个集群就无法继续提供服务了, 何谈分布式系统的高可用呢?")]),v._v(" "),_("p",[v._v("为了解决这种问题, 分布式领域还有一个"),_("strong",[v._v("关键技术来保证系统的高可用, 即故障恢复")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"分布式故障基础知识"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式故障基础知识"}},[v._v("#")]),v._v(" 分布式故障基础知识")]),v._v(" "),_("p",[v._v("在介绍故障恢复之前, 先说说分布式系统中会有哪些故障类型.")]),v._v(" "),_("h6",{attrs:{id:"故障类型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#故障类型"}},[v._v("#")]),v._v(" 故障类型")]),v._v(" "),_("p",[v._v("在任何一个分布式系统中, 故障都是不可避免的. 这里的故障, 通常包括两类:")]),v._v(" "),_("ol",[_("li",[v._v("一类是物理故障, 比如硬盘损坏, 断电断网, 硬件升级等;")]),v._v(" "),_("li",[v._v("另一类是软件层故障, 比如系统存在 Bug 导致系统崩溃, 系统负载过高导致系统崩溃等.")])]),v._v(" "),_("p",[v._v("在讨论分布式系统故障时, 通常还会从是否是网络导致的故障的角度来进行故障划分, 包括"),_("strong",[v._v("节点故障和网络故障")]),v._v(", 而这两类故障可能同时包括物理故障和软件层故障. 由于软件层故障和具体的程序实现等相关, 因此主要由开发者根据自己的实现去解决; 而物理故障通常具有很多共同特征, 因此"),_("strong",[v._v("今天主要针对物理故障导致软件不可用的情况进行讲解")]),v._v(".")]),v._v(" "),_("p",[v._v("首先看一下"),_("strong",[v._v("节点故障.")])]),v._v(" "),_("p",[v._v("简单地说, 节点故障就是单个机器自身出现故障. 比如, 由机器 A, B, ..., Z 构成的分布式集群中, 机器 A 自身出现故障, 而不是非机器之间的网络连接出现故障, 就是节点故障.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/c8f90bfe0eeca1e83eb4e1942b52fb28-20230731163147-77q7zde.png",alt:""}})]),v._v(" "),_("p",[v._v("节点故障有很多种, 大体可以分为两类:")]),v._v(" "),_("ol",[_("li",[v._v("一类是硬件故障, 比如机器硬盘损坏, 内存接触不良等;")]),v._v(" "),_("li",[v._v("另一类是软件故障, 比如由于请求过多, 超过服务器处理能力上限, 导致无法处理, 又或者是机器被攻击, 导致机器瘫痪等.")])]),v._v(" "),_("p",[v._v("节点故障在软件层的表现结果是, 该机器无法为用户提供服务.")]),v._v(" "),_("p",[v._v("其次看一下"),_("strong",[v._v("网络故障")]),v._v(". 简单地说, 网络故障就是分布式集群中, 节点之间无法完成通信. 比如, 由机器 A, B, ..., Z 构成的分布式集群中, 机器间比如机器 A 和 B 之间无法完成通信, 就属于网络故障.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/f866fcc6213b1ff563106b5ecee75f95-20230731163147-dhwd4my.png",alt:""}})]),v._v(" "),_("p",[v._v("网络故障也有很多种, 比如路由器故障, DNS 故障, 网络线路断裂等. 这些物理故障在软件层的表现结果是, 机器间无法通信, 影响分布式应用正常提供服务.")]),v._v(" "),_("p",[v._v("了解了故障的类型, 还要搞明白如何检查到故障, 也就是"),_("strong",[v._v("如何进行故障检测")]),v._v(", 因为这是故障恢复的前提.")]),v._v(" "),_("h6",{attrs:{id:"故障检测"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#故障检测"}},[v._v("#")]),v._v(" 故障检测")]),v._v(" "),_("p",[v._v("故障检测, 就是指通过一定的方式识别或发现故障. 就好比把火灾, 地震等危险事件看作是故障, 采用火灾报警器, 地震仪等来检测发现火灾或地震.")]),v._v(" "),_("p",[v._v("如果可以提前检测到事件的发生, 就能将损失降到最小. "),_("strong",[v._v("在分布式系统中, 检测硬件故障通常比较麻烦, 因此会通过查看软件层的表现结果来进行故障检测")]),v._v(". 比如, 网络故障导致服务器之间无法通信, 因此就可以通过检测服务器之间是否可以通信(比如, 服务器之间心跳包是否可以正常地发送和接收), 来检测是否存在网络故障.")]),v._v(" "),_("p",[v._v("关于故障检测的具体策略, 会在后面详细展开. 当检测到故障后, 就需要进行故障恢复了.")]),v._v(" "),_("h6",{attrs:{id:"故障恢复"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#故障恢复"}},[v._v("#")]),v._v(" 故障恢复")]),v._v(" "),_("p",[_("strong",[v._v("故障恢复, 就是指修复分布式系统中出现的故障, 使系统恢复正常")]),v._v('. 简单来说, 故障恢复就是故障发生之后的弥补方案, 可以理解为对故障进行修正或修复, 以保证服务正常运行, 有点类似 "知错能改, 善莫大焉".')]),v._v(" "),_("p",[v._v("接下来就具体看看故障检测和故障恢复的原理或者说策略.")]),v._v(" "),_("h5",{attrs:{id:"分布式故障检测原理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式故障检测原理"}},[v._v("#")]),v._v(" 分布式故障检测原理")]),v._v(" "),_("p",[v._v("在分布式系统中, 常见的故障检测方法是"),_("mark",[_("strong",[v._v("心跳机制")])]),v._v(". 基于心跳进行故障检测的策略主要分为两类, 固定心跳检测策略和根据历史心跳信息预测故障策略.")]),v._v(" "),_("p",[v._v("通过固定心跳检测策略比较简单. 接下来, "),_("strong",[v._v("主要分享基于历史心跳消息预测故障的策略, 也就是常说的 φ 值故障检测")]),v._v(". φ 值故障检测是基于心跳间隔符合正态分布的假设进行计算的. 其中, φ 值是用来评估心跳是否超时的概率, 是对心跳间隔的概率求对数, 将非整数转换为整数以便于理解.")]),v._v(" "),_("p",[v._v("φ 值故障检测方法中, 通常会设置一个阈值 Ф, 若当前心跳计算得到的 φ ≥ Ф, 则判断心跳超时, 否则心跳未超时.")]),v._v(" "),_("p",[v._v("那么 "),_("strong",[v._v("φ 值是如何计算的呢?")])]),v._v(" "),_("p",[v._v("从流程上来讲, φ 值的计算可以分为三步, 即:")]),v._v(" "),_("ul",[_("li",[v._v("采样窗口存储心跳到达的时间;")]),v._v(" "),_("li",[v._v("通过样本计算出心跳到达时间间隔的分布;")]),v._v(" "),_("li",[v._v("使用得到的正态分布计算当前的 φ 值.")])]),v._v(" "),_("p",[v._v("接下来就具体看看这三个阶段.")]),v._v(" "),_("p",[v._v("**第一步: 采样窗口存储心跳到达的时间. **")]),v._v(" "),_("p",[v._v("采样窗口就是一个具有固定容量的容器, 一般存储近 k 次的心跳信息, 每次心跳到达时, 会将到达时间存储到采样窗口, 如果采样窗口已满, 则会删除窗口中最旧的数据.")]),v._v(" "),_("p",[v._v("比如, 采样窗口最多存储最近 10 次心跳到达的时间, t1, t2, ...,  t10, 当第 11 次心跳到来时, 采样窗口会将 t1 删除, 存入 t11. 到达时间的间隔很容易得到, 比如第 11 次心跳到来后, 到达时间的间隔是 t3 - t2, t4 – t3, ..., t11 – t10. "),_("strong",[v._v("通过这些采样数据, 可以计算出样本的平均值 μ 和方差 σ2, 以便后面计算 φ 值")]),v._v(". 当然随着新的心跳到来, 这些数据会进行相应的更新.")]),v._v(" "),_("p",[v._v("**第二步: 通过样本计算出心跳到达时间间隔的分布. **")]),v._v(" "),_("p",[v._v("φ 值故障检测是假设心跳到达时间间隔的分布遵循正态分布, 假设 Plater(t) 表示接收到上一次心跳之后 t 个时间片能收到下一次心跳的概率, 则通过第一步中得到的样本平均值 µ 和方差 σ2.")]),v._v(" "),_("p",[v._v("**第三步: 使用得到的正态分布计算当前的φ值. **")]),v._v(" "),_("p",[v._v("求得 φ 值后, 与阈值 Ф 进行比较, 即可判断节点是否发生故障.")]),v._v(" "),_("p",[v._v("以上就是 φ 值故障检测策略的介绍, 它的基本思想是"),_("strong",[v._v("利用了历史心跳信息, 来降低误判的可能性")]),v._v(".")]),v._v(" "),_("p",[v._v("当阈值 Ф=1 时, 误判的可能性大约为 10%; Ф=2 时, 误判的可能性大约为 1%; Ф=3 时, 误判的可能性大约为 0.1%...")]),v._v(" "),_("p",[v._v("可以看出, "),_("strong",[v._v("φ 值故障检测策略可以根据历史心跳信息动态预测下一次心跳是否超时, 并可以通过设置阈值来自由调控误判的可能性")]),v._v(". 目前, 该策略已被应用到一些框架中, 比如 Akka 集群的故障检测, 便是采用了 φ 值故障检测策略.")]),v._v(" "),_("p",[v._v("当采用故障检测策略检测到故障后, 故障如何恢复呢? 接下来就一起看看故障恢复策略.")]),v._v(" "),_("h5",{attrs:{id:"故障恢复策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#故障恢复策略"}},[v._v("#")]),v._v(" 故障恢复策略")]),v._v(" "),_("p",[v._v("关于故障恢复策略, 从"),_("strong",[v._v("单节点故障和网络故障")]),v._v("两个维度展开.")]),v._v(" "),_("p",[_("strong",[v._v("对于单节点故障问题, 往往采取主备策略")]),v._v(", 即当主节点故障后, "),_("strong",[v._v("从备节点中选出一个作为新的主节点")]),v._v(", 以继续提供服务. 这种备升主的方式比较好理解.")]),v._v(" "),_("p",[v._v("如下图所示, 用户 A 访问分布式集群时一直是与 Master 交互的, 但当 Master 故障后, 其他 Slave 会通过分布式选举算法选出一个新的主节点.")]),v._v(" "),_("p",[v._v("假设, 从 Slave 1, Slave 2 和 Slave 3 中选举出 Slave 2 作为新的 Master, 则 Slave 2 需要承担原来 Master 的职责, 继续为用户提供服务, 因此当用户 A 再次访问集群时, 提供服务的是新选出的 Master, 也就是 Slave 2. 这就是备升主的过程.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/de2258cc33a3e4a5319a882887386b54-20230731163147-5vmqog1.png",alt:""}})]),v._v(" "),_("p",[v._v("从用户 A 的角度来看, 并不会感受到服务有什么异常, 因为依旧可以正常访问集群. 因此"),_("strong",[v._v("主备策略可以大大提高分布式系统的可用性, 在分布式系统中随处可见")]),v._v(". 比如 Redis 集群和 ZooKeeper 集群等, 都是采用了这种主备策略来做故障恢复.")]),v._v(" "),_("p",[_("strong",[v._v("而对于网络故障问题的解决方案, 简单来说就是 C, A, P 选择的问题")]),v._v(", 即在分布式系统的可用性和数据一致性之间做权衡. 根据不同的应用场景, 选择不同的解决方案.")]),v._v(" "),_("p",[v._v("当分布式系统中出现网络故障时, 对于高可用性要求严格的系统, 比如要求必须及时响应用户的场景, 就需要采用保 AP 弃 C 的策略; 对于数据一致性有严格要求的系统, 比如银行, 金融系统等场景, 就需要采用保 CP 弃 A 的策略.")]),v._v(" "),_("p",[v._v("其实, 网络故障恢复问题也可以看作数据复制的问题, 即网络故障恢复后节点间数据同步的问题. 还记得同步复制, 异步复制和半同步复制技术吗? 其中, 半同步复制技术因为既能有效保证数据安全, 又能满足系统高性能的要求, 所以最受欢迎, 被大多数分布式系统采用.")]),v._v(" "),_("p",[v._v("其实, "),_("strong",[v._v("节点故障和网络故障也有交叉的地方")]),v._v(", 比如网络故障产生的原因可能是节点故障, 即因为节点故障导致节点间无法通信, 而不是纯粹的网络链路问题. 这种情况有两种可能性, 一种是节点临时性故障, 即一段时间后就会恢复; 一种是节点永久性故障, 即节点不会恢复. 针对第一种情况, 只需等到故障恢复后, 数据进行同步即可; 第二种情况则需要备升主策略来解决.")]),v._v(" "),_("h5",{attrs:{id:"知识扩展-固定心跳检测和基于历史心跳信息预测故障的策略各有什么特点呢"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-固定心跳检测和基于历史心跳信息预测故障的策略各有什么特点呢"}},[v._v("#")]),v._v(" 知识扩展:固定心跳检测和基于历史心跳信息预测故障的策略各有什么特点呢?")]),v._v(" "),_("p",[v._v("首先看一下固定心跳检测.")]),v._v(" "),_("p",[v._v("固定心跳检测的核心是, 固定周期 T 秒发送心跳, 若连续 k 次未收到心跳回复(时间 T 内), 则判断心跳超时的时间为 k*T 秒. 可以看出, k 和 T 的设置非常重要.")]),v._v(" "),_("p",[v._v("比如, 对于要求秒级故障检测的场景(时延敏感性场景), 则 "),_("code",[v._v("k * T ≤ 1s")]),v._v("​, 因此需要将 T 设置为 ms 级, 比如 200ms, k 设置为 1000/200=5 次. 但这样一来容易导致误判. 因为判断超时的时间设置得太短, 很可能是系统做内存回收或系统本身有高任务在运行导致心跳回复延后.")]),v._v(" "),_("p",[_("strong",[v._v("而对于时延不太敏感的场景, k 或 T 可以设置得大一些, 降低误判率, 但却会增加发现故障的时间.")])]),v._v(" "),_("p",[v._v("接下来看一下 φ 值故障检测. φ 值故障检测是"),_("strong",[v._v("基于心跳间隔符合正态分布的假设")]),v._v(", 通过对历史心跳数据采样来预测当前心跳是否超时的. 也就是说, "),_("strong",[v._v("心跳间隔符合比较平稳或符合规律的情况下, 比较适合, 但对于具有突发情况或心跳间隔无规律的场景误判率比较高")]),v._v(".")]),v._v(" "),_("p",[_("strong",[v._v("在网络状况确定且比较稳定的场景下, 大多数系统会采用固定心跳检测策略, 因为其可以根据网络状况与业务场景自主设定合适的 k 和 T 值, 简单有效; 而当网络状况有所变化, 且变化有规律的场景, 则可以使用 φ 值故障检测策略.")])]),v._v(" "),_("h4",{attrs:{id:"_32-如何判断并解决网络分区问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_32-如何判断并解决网络分区问题"}},[v._v("#")]),v._v(" 32-如何判断并解决网络分区问题?")]),v._v(" "),_("h5",{attrs:{id:"什么是网络分区"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是网络分区"}},[v._v("#")]),v._v(" 什么是网络分区?")]),v._v(" "),_("p",[v._v("先来看看网络分区到底是什么. 前面介绍了故障类型中的网络故障, 网络分区就是其中的一种故障类型.")]),v._v(" "),_("p",[v._v("通常情况下, 网络分区指的是在分布式集群中, 节点之间由于网络不通, 导致集群中节点形成不同的子集, 子集中节点间的网络相通, 而子集和子集间网络不通. 也可以说, "),_("strong",[v._v("网络分区是子集与子集之间在网络上相互隔离")]),v._v("了.")]),v._v(" "),_("h5",{attrs:{id:"如何判断是否发生了网络分区"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何判断是否发生了网络分区"}},[v._v("#")]),v._v(" 如何判断是否发生了网络分区?")]),v._v(" "),_("p",[v._v("那应该如何判断是否发生了网络分区呢?")]),v._v(" "),_("p",[v._v("在分布式集群中, 不同的集群架构网络分区的形态略有不同. 所以要判断是否发生了网络分区, 需要弄清楚不同的分布式集群架构, "),_("strong",[v._v("即集中式架构和非集中式架构中的网络分区形态是什么样的")]),v._v(".")]),v._v(" "),_("p",[v._v("首先来看一下"),_("strong",[v._v("集中式架构的网络分区形态")]),v._v(".")]),v._v(" "),_("p",[v._v("集中式架构中, Master 节点通常以一主多备的形式部署, Slave 节点与 Master 节点相连接, Master 节点的主和备之间会通过心跳相互通信.")]),v._v(" "),_("p",[v._v("以 Master 节点主备部署为例, 如下图所示, 集中式架构中的网络分区主要是"),_("strong",[v._v("主节点与备节点之间网络不通")]),v._v(", 且一部分 Slave 节点只能与主 Master 节点连通, 另一部分只能与备 Master 节点连通.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/5723c68ac63b094643ec1a3069926578-20230731163147-6af176k.png",alt:""}})]),v._v(" "),_("p",[v._v("然后再来看看"),_("strong",[v._v("非集中式架构中的网络分区形态")]),v._v(".")]),v._v(" "),_("p",[v._v("如下图所示, 非集中式架构中, 节点是"),_("strong",[v._v("对称")]),v._v("的, 因此网络分区的形态是"),_("strong",[v._v("形成不同子集, 子集内节点间可互相通信, 而子集之间的节点不可通信")]),v._v(". 比如, 子集群 1 中 Node1, Node2 和 Node4 可以相互通信, 子集群 2 中 Node3 和 Node5 也可以相互通信, 但子集群 1 和子集群 2 之间网络不通.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e74e5b5ef2b9ccb617ae98e0170d129a-20230731163147-ko51ftv.png",alt:""}})]),v._v(" "),_("p",[v._v("从集中式和非集中式这两种分布式集群架构的网络分区形态可以看出, "),_("mark",[_("strong",[v._v("要判断是否形成网络分区, 最朴素的方法就是判断节点之间心跳是否超时, 然后将心跳可达的节点归属到一个子集中")])]),v._v(".")]),v._v(" "),_("p",[v._v("由于非集中式系统中, 每个节点都是对等的, 提供的服务相同, 所以当多个子集群之间不可达, 或部分节点出现故障后, 尽管提供的服务质量(SLA)可能会下降, 但并不影响这些剩余节点或子集群对外提供服务. 所以, 接下来将重点讨论"),_("strong",[v._v("集中式系统的网络分区问题")]),v._v(".")]),v._v(" "),_("h5",{attrs:{id:"网络分区最微妙的地方在哪里"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#网络分区最微妙的地方在哪里"}},[v._v("#")]),v._v(" 网络分区最微妙的地方在哪里?")]),v._v(" "),_("p",[v._v("在工作和生活中遇到一个问题, 你的本能反应估计是, 有问题就解决问题好了. 而网络分区最微妙的地方在于, 很难通过程序去判断问题到底出在哪里, 而只能通过心跳等手段知道部分节点的网络不可达了.")]),v._v(" "),_("p",[v._v("但导致节点不可达的原因有很多, 有可能是网络的原因, 也有可能是节点本身的问题. 也就是说, 无法通过一些症状就判断出是否真的产生了分区. 另外也很难通过程序去判断这个问题是不是很快就会被恢复. 这也是应对网络分区问题最微妙的地方.")]),v._v(" "),_("h5",{attrs:{id:"网络分区有哪些常见的处理方法"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#网络分区有哪些常见的处理方法"}},[v._v("#")]),v._v(" 网络分区有哪些常见的处理方法?")]),v._v(" "),_("p",[v._v("为了不影响分布式系统的高可用性, 检测到网络分区后, 就需要尽快地进行处理.")]),v._v(" "),_("p",[v._v("假如, "),_("strong",[v._v("采用一种非常激进的方式去处理")]),v._v(", 即一旦发现节点不可达, 则将不可达节点从现有集群中剔除, 并在这个新集群中选出新的主.")]),v._v(" "),_("p",[v._v("以前面所示集中式集群为例, 当备 Master, Slave3 和 Slave4 节点检测到主 Master, Slave1 和 Slave2 节点不可达时, 剔除这些不可达节点后, 备 Master 升主, 连同 Slave3 和 Slave4 节点组成一个新的集群.")]),v._v(" "),_("p",[v._v("如果不可达是由于节点故障导致的, 那么这种策略没有任何问题. 这些剩余节点组成的集群可以继续对外提供服务. 但如果不可达是因为网络故障引起的, 那么集群中的另一个子集, 即主 Master, Slave1 和 Slave2, 也会采用同样的策略, 仍然对外提供服务. 这时, 集群就会出现"),_("strong",[v._v("双主问题")]),v._v("了.")]),v._v(" "),_("p",[v._v("假如, "),_("strong",[v._v("采用一种保守的方式去处理")]),v._v(", 即节点一旦发现某些节点不可达, 则直接停止自己的服务. 这样确实解决了双主的问题, 但因为不同分区之间的不可达是相互的, 且所有的分区都采取了这种停服策略, 就会导致系统中所有的节点都停止服务, 整个系统完全不可用. 这显然也不是想看到的.")]),v._v(" "),_("p",[v._v("那么, 当系统中出现节点不可达后, 如何在不出现双主的情况下, 尽可能地提升系统的可用性呢? 或者说, 有没有什么更均衡的策略呢?")]),v._v(" "),_("p",[v._v("接下来, 就分享四种均衡的网络分区处理方法, 即 Static Quorum, Keep Majority, 设置仲裁机制和基于共享资源的方式.")]),v._v(" "),_("blockquote",[_("p",[v._v("方法一: 通过 Static Quorum 处理网络分区")])]),v._v(" "),_("p",[_("strong",[v._v("Static Quorum 是一种固定票数的策略. 在系统启动之前, 先设置一个固定票数. 当发生网络分区后, 如果一个分区中的节点数大于等于这个固定票数, 则该分区为活动分区.")])]),v._v(" "),_("p",[v._v("为了保证发生分区后, 不会出现多个活动分区, 导致出现双主或多主的问题, 需要对固定票数的取值进行一些约束, 既: "),_("strong",[v._v("固定票数 ≤ 总节点数 ≤ 2 * 固定票数 - 1")]),v._v(".")]),v._v(" "),_("p",[v._v("这个策略的优点是, 简单, 容易实现, 但却存在两个问题:")]),v._v(" "),_("ol",[_("li",[v._v("一是, 对于分区数比较少的时候, 比方 2 个分区时, 该策略很容易选出一个唯一的活动分区. 但当活动分区非常多的时候, 由于各个分区的票数分散, "),_("strong",[v._v("不容易找到一个满足条件的分区")]),v._v(", 没有活动分区也就意味着整个集群不可用了.")]),v._v(" "),_("li",[v._v("二是, 由于这种策略里固定票数是固定不变的, 所以"),_("strong",[v._v("不适用于集群中有动态节点加入的场景")]),v._v(".")])]),v._v(" "),_("blockquote",[_("p",[v._v("方法二: 通过 Keep Majority 处理网络分区")])]),v._v(" "),_("p",[v._v("顾名思义, "),_("strong",[v._v("Keep Majority 就是保留具备大多数节点的子集群")]),v._v(". 由于不限定每个分区的节点数超过一个固定的票数, 所以可以应用于动态节点加入的场景.")]),v._v(" "),_("p",[v._v("假设, 集群数为 n, 出现网络分区后, 保留的子集群为节点数 "),_("code",[v._v("w >= n/2")]),v._v("​ 的集群. 为防止出现双主或两个集群同时工作的情况, 通常将集群总节点数 n 设置为奇数.")]),v._v(" "),_("p",[v._v("可想而知, 若集群总数为偶数, 比如集中式架构的例子中, 子集群 1 和 2 都包含 2 个 Slave 节点, 就会导致两个子集群同时存活, 在业务场景只允许一个主的情况下, 会导致业务运行不正确.")]),v._v(" "),_("p",[v._v("那么, 如果真的出现了集群总节点数为偶数, 两个子集群节点数均为总数一半时, 又应该如何解决分区问题呢?")]),v._v(" "),_("p",[v._v("这时可以在 Keep Majority 的基础上, 叠加一些策略, 比如保留集群节点 ID 最小的节点所在的子集群. 假设集群节点总数为 6, 现在因为网络故障形成网络分区子集群 1 "),_("code",[v._v("{主 Master, Slave1, Slave2}")]),v._v("​ 和子集群 2 "),_("code",[v._v("{备 Master, Slave3, Slave4}")]),v._v("​, 假设 Slave1 是 ID 最小的节点, 那么此时要保留包含 Slave1 的子集群 1.")]),v._v(" "),_("p",[v._v("虽然 Keep Majority 方法可以解决动态节点加入的问题, 但"),_("strong",[v._v("也不适用于产生多分区")]),v._v("的场景. 因为随着分区数增多, 节点分散, 也难以在众多分区中出现一个节点数 "),_("code",[v._v("w >= n/2")]),v._v("​ 的分区.")]),v._v(" "),_("p",[v._v("前面讲到集群跨多个网络部署时更容易产生网络分区, 因此"),_("strong",[v._v("不推荐")]),v._v("采用 Static Quorum 和 Keep Majority 方法去处理跨多网络集群的网络分区问题.")]),v._v(" "),_("blockquote",[_("p",[v._v("方法三: 通过设置仲裁机制处理网络分区")])]),v._v(" "),_("p",[v._v("设置仲裁机制的核心是, "),_("mark",[_("strong",[v._v("引入一个第三方组件或节点作为仲裁者, 该仲裁者可以与集群中的所有节点相连接, 集群中所有节点将自己的心跳信息上报给这个中心节点")])]),v._v(". 因此该中心节点拥有全局心跳信息, 可以根据全局心跳信息判断出有多少个分区. 当出现网络分区后, 由仲裁者确定保留哪个子集群, 舍弃哪些子集群.")]),v._v(" "),_("p",[v._v("如下图所示, 假设引入 Node0 作为第三个节点, 该节点 IP 为 10.12.24.35, 当出现网络分区子集群 1 "),_("code",[v._v("{Node1, Node3}")]),v._v("​ 和子集群 2 "),_("code",[v._v("{Node2, Node4}")]),v._v("​ 时, 每个子集群中选择一个 Leader 节点并 ping 一下 Node0 的 IP, 能 ping 通则保留, 否则舍弃. 比如下图中, 子集群 1 可以 ping 通, 子集群 2 ping 不通, 因此保留子集群 1.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/626741175f2a8086bdefc96d3991059b-20230731163147-akbn9aa.png",alt:"",title:"图 3 通过设置仲裁机制处理网络分区"}})]),v._v(" "),_("blockquote",[_("p",[v._v("方法四: 基于共享资源的方式处理网络分区")])]),v._v(" "),_("p",[v._v("基于共享资源处理网络分区的核心, 其实就类似于分布式锁的机制. 也就是, "),_("strong",[v._v("哪个子集群获得共享资源的锁, 就保留该子集群. 获得锁的集群提供服务, 只有当该集群释放锁之后, 其他集群才可以获取锁")]),v._v(".")]),v._v(" "),_("p",[v._v("这种方式的问题是, 如果获取锁的节点发生故障, 但未释放锁, 会导致其他子集群不可用. 因此这种方式适用于获取锁的节点可靠性有一定保证的场景.")]),v._v(" "),_("p",[v._v("基于仲裁和共享资源的网络分区处理方法, 其实都是"),_("strong",[v._v("依赖一个三方的节点或组件")]),v._v(", 然后借助这个第三方来保证系统中同时只有一个活动分区. 所以这两种处理方法适用于有一个稳定可靠的三方节点或组件的场景.")]),v._v(" "),_("p",[_("strong",[v._v("小结")])]),v._v(" "),_("p",[_("strong",[v._v("关于网络分区的处理方法, 其本质就是, 在产生分区后, 选出一个分区, 保证同时最多有一个分区对外提供服务.")]),v._v("  基于此, 我为你梳理了四种常见的处理方法, 包括 Static Quorum, Keep Majority, 设置仲裁机制和基于共享资源的方式. 其中, 基于 Static Quorum 的方法, 因为涉及固定票数策略, 所以不适用于处理多个分区, 以及有动态节点加入的场景; 基于 Keep Majority 的方法, 可以解决动态节点场景下分区问题, 但因为要求子集群节点数≥1/2 总节点数, 所以也不适用于处理多个分区的情况; 而基于仲裁和共享资源的网络分区处理方法, 其实都是依赖一个三方的节点或组件, 所以适用于有一个稳定可靠的三方节点或组件的场景.")]),v._v(" "),_("h5",{attrs:{id:"总结-27"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#总结-27"}},[v._v("#")]),v._v(" 总结")]),v._v(" "),_("p",[v._v("本节学习了分布式高可用技术中的故障恢复技术. 首先介绍了分布式系统中的故障类型, 主要包括物理故障和软件故障, 软件故障主要是由于程序或软件 Bug 等导致, 通常由开发者在开发或测试过程中解决, 而物理故障导致软件不可用的故障类型主要分为两类, 节点故障和网络故障.")]),v._v(" "),_("p",[v._v("其次介绍了故障检测方法. 故障检测方法主要是心跳检测方法, 包括固定心跳策略和基于历史信息的心跳策略. 其中, 基于历史心跳策略的核心是通过统计历史数据规律, 以预测当前心跳是否超时以进行故障检测;")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/088e1e8ccea812c2ebf68062b9384f7c-20230731163147-8rgpjnm.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"分布式核心知识串讲"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分布式核心知识串讲"}},[v._v("#")]),v._v(" 分布式核心知识串讲")]),v._v(" "),_("h4",{attrs:{id:"_33-知识串联-以购买火车票的流程串联分布式核心技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_33-知识串联-以购买火车票的流程串联分布式核心技术"}},[v._v("#")]),v._v(" 33-知识串联:以购买火车票的流程串联分布式核心技术")]),v._v(" "),_("p",[v._v('还记得在专栏之初, 介绍的 "分布式四纵四横知识体系"吗? 截止到目前, 已经学习了四横和三纵, 包括分布式计算, 分布式存储与管理, 分布式通信, 分布式资源池化, 分布式协同, 分布式调度和分布式追踪与高可用的关键技术(由于分布式追踪, 分布式部署虽属于支撑技术, 但并不会影响业务的构成, 因此没有在专栏中展开).')]),v._v(" "),_("p",[v._v("但学以致用才是最终目的, 所以在接下来的模块中, 将通过两篇总结性质的文章, 串联起前面讲到的核心知识点, 看看它们在业务中是如何应用的.")]),v._v(" "),_("p",[v._v("本节就先以购买火车票的流程, 串联下整个专栏涉及的分布式核心技术.")]),v._v(" "),_("p",[v._v("首先, 为方便理解, 并抓住其中涉及的核心技术, 对购买火车票的流程做了一个简化, 大致划分为三大核心步骤:")]),v._v(" "),_("ol",[_("li",[v._v("首先, 铁路局向购票系统发布火车票;")]),v._v(" "),_("li",[v._v("然后, 用户通过系统查询火车票, 找到需要的火车票后购买;")]),v._v(" "),_("li",[v._v("最后, 购票系统给用户响应, 完成购票.")])]),v._v(" "),_("p",[v._v("这个流程看似简单, 但涉及了很多知识. 这里有个小建议, 在学习后面的内容前, 可以先自己思考下这个过程涉及了哪些知识点, 然后再与接下来的讲述进行对比, 以验证自己对之前内容的掌握程度. 这样一来, 就可以加深对已掌握知识的理解深度, 也可以查漏补缺进而有针对性地复习其他内容.")]),v._v(" "),_("p",[v._v("那么接下来就主要分为三部分进行讲解: 铁路局发布火车票, 用户查询火车票, 以及用户购买火车票.")]),v._v(" "),_("h5",{attrs:{id:"铁路局发布火车票"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#铁路局发布火车票"}},[v._v("#")]),v._v(" 铁路局发布火车票")]),v._v(" "),_("p",[v._v("铁路局发布火车票的过程, 主要涉及分布式数据存储这一站的知识, 包括存储系统三要素, 数据分布和数据复制等技术.")]),v._v(" "),_("p",[v._v('铁路局向购票系统发布火车票的过程, 主要是将火车票信息发送到服务器集群进行存储, 需要用到存储系统三要素的相关技术. 其中, 铁路局就是存储系统三要素中的 "顾客", 火车票存储到具体哪个服务器需要构建数据索引, 也就是三要素中的 "导购", 而存储数据的服务器就是三要素中的 "货架".')]),v._v(" "),_("p",[v._v("由于涉及多个服务器存储火车票信息, 不可避免地需要考虑服务器之间数据存储的均衡, 以及快速确定火车票信息存储位置以方便后续查询和购买火车票. 因此这里需要用到分布式存储中的数据分布技术.")]),v._v(" "),_("p",[v._v("铁路局按照火车线路将火车票发布到不同的服务器上, 即在数据分片技术中提到的按照数据范围进行分片. 比如, 京广线的车票信息存储在京广线服务器集群, 京沪线的车票信息存储在京沪线服务器集群等.")]),v._v(" "),_("p",[v._v("除此之外, 为了保证可靠性, 也就是当一台服务器故障后, 该服务器存储的火车票信息可以恢复或不丢失, 通常会进行数据备份. 也就是说, 同一份数据可能会有多台服务器一起存储, 比如京广线的火车票数据存储到服务器 A1, A2 和 A3 上, 京沪线的火车票数据存储在服务器 B1, B2 和 B3 上.")]),v._v(" "),_("p",[v._v("而数据备份, 用到的就是分布式存储中的"),_("strong",[v._v("数据复制技术")]),v._v(". 由于同一份数据被多台服务器存储, 自然就需要保证数据的一致性.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/d0194acbf4d5c38d34964e81a78057a6-20230731163147-w2cck5c.png",alt:""}})]),v._v(" "),_("p",[v._v("接下来再看看用户查询火车票过程中涉及了哪些相关技术.")]),v._v(" "),_("h5",{attrs:{id:"用户查询火车票"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#用户查询火车票"}},[v._v("#")]),v._v(" 用户查询火车票")]),v._v(" "),_("p",[v._v("对于用户查询火车票来说, 大致过程是用户向服务器发起查询请求, 服务器根据用户请求, 通过数据索引, 也就是导购技术, 定位到火车票信息存储的位置, 然后获取数据返回给用户.")]),v._v(" "),_("p",[v._v("从这个流程可以看出, "),_("strong",[v._v("服务器接收用户查询请求是第一步")]),v._v(".")]),v._v(" "),_("p",[v._v("正常情况下, 用户并发请求量比较小, 很少会出现服务器能力有限导致系统崩溃的情况. 但遇到节假日或春节, 用户请求量通常会非常大, 这时如果不采取一定策略的话, 大概率会因为服务器能力受限导致系统崩溃.")]),v._v(" "),_("p",[v._v("而这里的策略, 通常就是保证分布式高可靠的"),_("strong",[v._v("负载均衡和流量控制")]),v._v(". 比如每年春运, 火车票发布的瞬间, 就有大量的用户抢票, 如果购票系统后台不使用负载均衡和流量控制的话, 服务器一下子就被击垮了.")]),v._v(" "),_("p",[v._v("除此之外, 服务器还不可避免地会出现一些小故障, 比如磁盘损坏, 网络故障等问题. 如何检测服务器故障, 以及如何进行故障恢复, 就需要用到分布式高可用的故障隔离与故障恢复的相关技术了.")]),v._v(" "),_("p",[v._v("接收用户请求后, 接下来需要将请求转发至相应的服务器集群, 然后再从中选择某一台服务器处理用户请求, 也就是获取数据并返回给用户. 本质上, 这就是在进行数据索引, 设计分布式数据存储中的数据分布方式的相关技术.")]),v._v(" "),_("p",[v._v("以用户查询从北京到上海的火车票信息为例, 查询流程如下:")]),v._v(" "),_("ol",[_("li",[v._v("首先, 根据查询条件, 系统将请求转发至存储京沪线火车票信息的服务器集群中;")]),v._v(" "),_("li",[v._v("然后, 服务器集群再使用一次负载均衡, 比如使用轮询算法, 将请求转发至某一台服务器;")]),v._v(" "),_("li",[v._v("最后, 这台服务器将火车票的车次, 余票等信息返回给用户.")])]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/e1189ea98546116f477eda7913fc3a0d-20230731163147-pfq9k69.png",alt:""}})]),v._v(" "),_("p",[v._v("在这个过程中, 还可以使用"),_("strong",[v._v("限流算法")]),v._v(", 比如漏桶, 令牌桶等策略来限制用户流量, 保证系统高可用.")]),v._v(" "),_("p",[v._v("除此之外, 在存储火车票信息的服务器中, 各个服务器的服务单独运行, 也就相当于做了一定的故障隔离, 比如图中的服务器 A1-A3, B1-B3.")]),v._v(" "),_("p",[v._v("当然, 这里"),_("strong",[v._v("还需要注意一个问题")]),v._v(". 在上面的过程中, 一直提到的是服务器集群. 既然是集群, 就会涉及集群架构, 分布式选主等策略. 以集中式架构 Master/Slave 为例, 服务器集群中会通过分布式选举算法选出一个 Master, Master 和其他服务器节点之间会维持心跳, 并通过心跳来感知服务器节点的存活状态. 比如, 京广线服务器集群选出的 Master 节点为 A2, A2 与 A1 和 A3 之间一直维持心跳.")]),v._v(" "),_("p",[v._v("当集群中 Master 节点故障后, 会从其他节点中重新选举出一个 Master 节点, 继续为用户提供服务, 也就是备升主, 以保证服务的可用性. 这里备升主就是一种故障恢复策略.")]),v._v(" "),_("p",[v._v("最后再来分析下用户购买火车票的过程.")]),v._v(" "),_("h5",{attrs:{id:"用户购买火车票"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#用户购买火车票"}},[v._v("#")]),v._v(" 用户购买火车票")]),v._v(" "),_("p",[v._v("与用户查询火车票的过程类似, "),_("strong",[v._v("用户购买火车票过程唯一不同的是, 会造成数据库的变化")]),v._v(". 换句话说, 用户查询火车票是读请求, 而购买火车票相当于一个写请求. 那么, 写请求又会造成什么新问题呢?")]),v._v(" "),_("p",[v._v("写请求与读请求的区别是, 写请求会造成数据的变化, 因此相对于查询火车票, 购买火车票的过程涉及的技术问题会多一些, 但多出的无非就是数据的一致性问题. 谈到数据的一致性, 就会想到CAP 理论, 数据复制技术, 分布式事务, 分布式锁等. 其实, 不仅仅是购买火车票, 任何一个简单的购买操作或写操作中, 都会涉及这些分布式知识.")]),v._v(" "),_("p",[v._v("本质上讲, 每次购买火车票的操作, 就是一个分布式事务, 要么执行成功要么执行失败.")]),v._v(" "),_("p",[v._v("当用户购买了火车票时, 该火车票对应时间的车次余票数量必须相应减 1, 如果减少时发现原先票数就已经为 0 了, 此时就应该提醒用户购买火车票失败, 余票为 0; 同样的, 如果票数不为 0, 则票数应该相应减 1, 并提示用户购票成功.")]),v._v(" "),_("p",[v._v("不难看出, 购买火车票会改变火车票数据, 也不可避免地会存在多个用户同时购买相同路线, 相同车次(比如京沪线的 T12)的场景. 也就是说, 这个购买过程存在多个进程同时访问共享资源的问题, 因此还要用到分布式锁的相关技术.")]),v._v(" "),_("p",[v._v("另外, **用户购买火车票的过程还会涉及用户体验, 数据一致性和网络故障等问题, 因此还涉及 C, A, P 策略的选择问题. **")]),v._v(" "),_("p",[v._v("在铁路局发布火车票的流程中, 为了保证可靠性, "),_("strong",[v._v("同一数据通常会备份到多个服务器上")]),v._v(". 当用户购买火车票导致火车票数据改变时, 主节点上的数据必须与备节点上的数据保持一致, 以防止主节点故障后, 备升主, 但数据不一致导致业务出错的情况.")]),v._v(" "),_("p",[v._v('比如, 用户 A 购买 2019 年 10 月 12 日北京到上海的 T12 的火车票, 已购买成功, 座位号为 3 车厢 23B. 假设主节点和备节点之间数据不一致, 主节点上已经减去该火车票, 但未在备节点上减去. 此时, 若主节点故障, 备节点升主, 用户 B 此时申请购买相同火车票, 系统将 3 车厢 23B 火车票又卖给了用户 B. 等到乘车时, 用户 A 和 B 就难免 "打架" 了.')]),v._v(" "),_("p",[v._v("当然, 通常因为网络故障或节点故障等原因导致主节点不能正常工作, 才会发生备升主, 而备升主其实就是故障恢复策略. 同时, 购买火车票的场景需要快速响应用户, 以保证用户体验. 因此通常优先保证系统的可用性, 稍微降低对数据一致性的要求, 但也必须保证最终一致性. 这就是平常遇到的, 查询火车票时还有余票, 但下单后却提示余票为 0, 无法购买. 导致这个结果的原因是, 下单前访问的数据库中, 数据还未同步, 显示有余票; 而下单后, 数据实现同步了, 发现余票数量已经为 0, 因此提示你无法购买该火车票.")]),v._v(" "),_("p",[v._v("实现上述策略的方法, 通常会采用半同步复制技术, 即将修改后的数据同步到多个备数据库中的某一个或几个后立即响应用户, 而不用将数据同步到所有备数据库.")]),v._v(" "),_("p",[v._v("除此之外, 业务量很大的情况下, 为了让服务更加健壮, 低耦合, 便于管理, 会根据功能拆分为不同的服务. 比如, 将整个购票系统拆分为订单系统, 支付系统和通知系统, 而当购票系统拆分为 3 个子系统后, 子系统之间不可避免的存在信息的交互, 子系统之间的交互就会涉及分布式通信的相关知识, 比如远程调用 RPC, 消息队列等.")]),v._v(" "),_("p",[v._v("如图所示, 用户购买火车票后, 会首先在订单系统下单, 下单成功后会调用支付系统的支付操作进行支付, 之后将支付成功的消息存放到消息队列中, 通知系统到消息队列中获取消息, 最后通知用户购买成功.")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/4f204d2edb8e874b23e39dc17fdd8f1d-20230731163147-kl7tup8.png",alt:""}})]),v._v(" "),_("h4",{attrs:{id:"_34-搭建一个分布式实验环境-纸上得来终觉浅-绝知此事要躬行"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_34-搭建一个分布式实验环境-纸上得来终觉浅-绝知此事要躬行"}},[v._v("#")]),v._v(" 34-搭建一个分布式实验环境: 纸上得来终觉浅, 绝知此事要躬行")]),v._v(" "),_("p",[v._v('上一讲以购买火车票为例, 串讲了分布式技术的应用, 帮助理解所学分布式技术可以应用到哪些业务中. 其实, 到目前为止, 主要是从理论上学习相关的分布式技术. 但 "纸上得来终觉浅, 绝知此事要躬行".')]),v._v(" "),_("p",[v._v("本节就以 Kubernetes 为例搭建一个分布式实验环境. 本节的内容分配:")]),v._v(" "),_("ol",[_("li",[v._v("不会特别详细地讲述搭建过程, 而是着重说明搭建的主要步骤以及可能遇到的问题;")]),v._v(" "),_("li",[v._v("在讲述搭建过程时, 串联一下其中涉及的分布式相关知识;")]),v._v(" "),_("li",[v._v("搭建完 Kubernetes 集群之后, 会以部署 Nginx 服务为例, 更直观地体验分布式技术, 以巩固, 加深对分布式技术的理解.")])]),v._v(" "),_("h5",{attrs:{id:"搭建目标"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#搭建目标"}},[v._v("#")]),v._v(" 搭建目标")]),v._v(" "),_("p",[v._v("Kubernetes 是 Google 开源的容器集群管理系统, 是 Borg 的开源版本. Kubernetes 集群属于主从架构的分布式集群.")]),v._v(" "),_("p",[_("strong",[v._v("Kubernetes 集群主要由 Master 节点和 Worker 节点组成. Master 节点就是中心服务器, 负责对集群进行调度管理; Worker 节点是真正的工作节点, 负责运行业务应用的容器")]),v._v(". 而容器是一种虚拟化技术, 通过限制自身使用的资源来实现资源隔离, 可以为应用提供一整套运行环境, 从而实现了服务运行环境的隔离, 进而实现了故障隔离.")]),v._v(" "),_("p",[v._v("接下来明确下这次搭建分布式实验室环境的目标:")]),v._v(" "),_("ol",[_("li",[v._v("搭建一个 Kubernetes 集群, 包括一个 Master 节点, 两个 Worker 节点 ;")]),v._v(" "),_("li",[v._v("在 Kubernetes 集群上创建一个 Nginx 服务.")])]),v._v(" "),_("h5",{attrs:{id:"搭建前的准备"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#搭建前的准备"}},[v._v("#")]),v._v(" 搭建前的准备")]),v._v(" "),_("p",[v._v("今天要搭建的 Kubernetes 集群, 以 3 台服务器为例, 一台作为 Master 节点, 两台作为 Worker 节点. 服务器应具备的条件如下:")]),v._v(" "),_("ol",[_("li",[v._v("Ubuntu 16.04 操作系统;")]),v._v(" "),_("li",[v._v("2GB 或以上的内存;")]),v._v(" "),_("li",[v._v("2 核 CPU 或以上;")]),v._v(" "),_("li",[v._v("服务器间网络连通;")]),v._v(" "),_("li",[v._v("每台服务器具有唯一的主机名, MAC 地址和 product_uuid;")]),v._v(" "),_("li",[v._v("通过执行命令 swapoff -a 来关闭 Swap;")]),v._v(" "),_("li",[v._v("30GB 及以上的磁盘空间;")]),v._v(" "),_("li",[v._v("具备外网访问权限, 以方便获取相关镜像.")])]),v._v(" "),_("p",[v._v("在这次部署中, 采用的机器配置如下:")]),v._v(" "),_("p",[_("img",{attrs:{src:"/img/473015886db7f70fc53d5738379136a3-20230731163147-f35o0fa.png",alt:""}})]),v._v(" "),_("h5",{attrs:{id:"kubernetes集群搭建"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#kubernetes集群搭建"}},[v._v("#")]),v._v(" Kubernetes集群搭建")]),v._v(" "),_("p",[v._v("搭建 Kubernetes 集群的步骤, 主要包括安装 Docker, 安装部署 kubeadm, kubelet, kubectl, 部署 Master 节点, 部署 Worker 节点, 安装网络插件这几步.")]),v._v(" "),_("p",[v._v("其中, 安装 Docker, 部署 Master 节点和 Worker 节点涉及分布式的, 需要在多个节点上部署, 比如 Docker 节点需要在每个 Worker 节点部署, Master 节点若为集群模式, 需要在多个节点上配置主备, Worker 节点需要与 Master 节点建立连接等.")]),v._v(" "),_("p",[v._v("接下来具体看看如何一步一步搭建出 Kubernetes 集群.")]),v._v(" "),_("h6",{attrs:{id:"_1-安装docker"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_1-安装docker"}},[v._v("#")]),v._v(" 1. 安装Docker")]),v._v(" "),_("p",[v._v("Kubernetes 是一个容器集群管理系统, 因此每个 Worker 节点会运行容器, 以实现业务运行环境隔离. 项目在每台服务器上采用如下命令安装 Docker:")]),v._v(" "),_("p",[v._v("​"),_("code",[v._v("apt-get install -y docker.io2")]),v._v("​. 安装部署 kubeadm, kubelet, kubectlkubeadm 是 Kubernetes 社区提供的一个部署工具, 该工具将 kubelet 组件之外的其他组件均采用容器部署, 实现了自动化,  避免了手动部署容器的麻烦, 简化了部署操作.")]),v._v(" "),_("p",[v._v("其中, Master 节点包括 API Server, Scheduler, Cluster State Store(默认 etcd) 和 Control Manager Srever 核心组件; Worker 节点包括 kubelet 和 kube-proxy 核心组件.")]),v._v(" "),_("p",[v._v("kubelet 组件本身是一个管控容器的组件, 需要执行配置容器网络等操作, 这些操作需要在宿主机上执行, 不采用容器部署. 因此, "),_("strong",[v._v("kubelet 组件需要单独部署, 而不能用 kubeadm 进行部署")]),v._v(".")]),v._v(" "),_("p",[v._v("除此之外, 还需要安装一下 kubectl 组件. 这个组件是 Kubernetes 的命令行工具, 通过 kubectl 可以部署和管理应用, 查看资源, 创建, 删除和更新组件.")]),v._v(" "),_("p",[v._v("那么, 如何部署 kubeadm, kubelet 和 kubectl 这三个组件呢?")]),v._v(" "),_("p",[v._v("apt 是 Linux 下常用的安装管理工具, 这里就采用 apt 来安装这三个组件.")]),v._v(" "),_("p",[v._v("首先需要添加 Kubernetes 源.")]),v._v(" "),_("p",[v._v("可以通过执行以下语句获取 Kubernetes 源(需要外网权限):")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("sudo apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get update "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("&&")]),v._v(" sudo apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get install "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("y apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("transport"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("https curl\ncurl "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("s https"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("packages"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("cloud"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("google"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("com"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("doc"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("key"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("gpg "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("|")]),v._v(" sudo apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("key add "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("\ncat "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<<")]),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("EOF")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("|")]),v._v(" sudo tee "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("etc"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("sources"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("list"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("d"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("list\ndeb https"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("io"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v(" kubernetes"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("xenial main\n"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("EOF")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br")])]),_("p",[v._v("然后使用以下命令更新源:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("sudo apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get update\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("这时就可以使用如下命令来安装 kubelet, kubectl 和 kubeadm 了:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("sudo apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get install "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("y kubelet kubeadm kubectl\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("如果没有外网访问权限, 在添加 kubernetes 源的时候可以执行以下命令来添加阿里云的 Kubernetes 源:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("cat "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<<")]),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("EOF")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("|")]),v._v(" sudo tee "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("etc"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("sources"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("list"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("d"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("list\ndeb https"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("mirrors"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("aliyun"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("com"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("apt kubernetes"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("xenial main\n"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("EOF")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br")])]),_("p",[v._v("同样的, 使用以下命令来更新源:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get update ## 忽略 gpg 的报错信息\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("最后, 使用如下命令安装 kubelet, kubectl 和 kubeadm:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("apt"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("get install "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("y kubelet kubeadm kubectl "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("--")]),v._v("allow"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("unauthenticated\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("安装好这三个组件之后, 就可以使用 kubeadm 来一键部署集群节点了.")]),v._v(" "),_("p",[v._v("首先来部署 Master 节点.")]),v._v(" "),_("h6",{attrs:{id:"_3-部署-master-节点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_3-部署-master-节点"}},[v._v("#")]),v._v(" 3.部署 Master 节点")]),v._v(" "),_("p",[v._v("这一步其实就是"),_("strong",[v._v("容器化启动 Master 节点中的各个组件, 直接使用 kubeadm 工具提供的一条命令 kubeadm init 即可自动安装")]),v._v(".")]),v._v(" "),_("p",[v._v("kubeadm init 这条命令底层其实就是将 Master 的各个组件, 比如 API Server, etcd 等, 以 Pod 形式(容器集合)运行起来. 当然也可以部署多个 Master 节点来实现集群的高可用, 比如两个 Master 节点互为主备.")]),v._v(" "),_("p",[v._v("除此之外, etcd 组件也可以采用集群方式部署, 从而保证了数据不会丢失.")]),v._v(" "),_("p",[_("strong",[v._v("在本次部署中以一个 Master 节点为例讲解集群的搭建")]),v._v(", 关于 Master 为集群的方式, 各节点上 kubernetes 配置类似, 可以参考 Kubernetes 官网.")]),v._v(" "),_("p",[v._v("在这里把 192.168.124.49 这台机器作为 Master 节点. 在该机器上"),_("strong",[v._v("直接执行 kubeadm init")]),v._v(", 即可完成部署:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("kubeadm init\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("如果有外网访问权限, 基本就可以部署成功了. 那么可以根据如下信息判断自己是否部署成功:")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[_("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("Your")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("Kubernetes")]),v._v(" control"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("plane has initialized successfully"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("!")]),v._v("\n\n"),_("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("To")]),v._v(" start using your cluster"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v(" you need "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("to")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token namespace"}},[v._v("run")]),v._v(" the following as a regular user"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("\n\nmkdir "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("p $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube\nsudo cp "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("i "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("etc"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("admin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("conf $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("config\nsudo chown $"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("id "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("u"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("$"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("id "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("g"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v(" $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("config\n\n"),_("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("You")]),v._v(" should now deploy a pod network "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("to")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token namespace"}},[v._v("the")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token class-name"}},[_("span",{pre:!0,attrs:{class:"token namespace"}},[v._v("cluster"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")])]),v._v("\nRun")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"kubectl apply -f [podnetwork].yaml"')]),v._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("with")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token namespace"}},[v._v("one")]),v._v(" of the options listed at"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("\nhttps"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("io"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("docs"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("concepts"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("cluster"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("administration"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("addons"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("\n\n"),_("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("Then")]),v._v(" you can join any number of worker nodes by running the following on each as root"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("\n\nkubeadm join "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("192.168")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v(".124")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v(".49")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("6443")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("--")]),v._v("token uv17vd"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("q3ber8i5knxg4h0x "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("br "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("--")]),v._v("discovery"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("token"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("ca"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("cert"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("hash sha256"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("c55bd70d346d809e1079565cc1fc1a05f001671cc9f2d02c55bbbc4a00bcc2a3\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br"),_("span",{staticClass:"line-number"},[v._v("6")]),_("br"),_("span",{staticClass:"line-number"},[v._v("7")]),_("br"),_("span",{staticClass:"line-number"},[v._v("8")]),_("br"),_("span",{staticClass:"line-number"},[v._v("9")]),_("br"),_("span",{staticClass:"line-number"},[v._v("10")]),_("br"),_("span",{staticClass:"line-number"},[v._v("11")]),_("br"),_("span",{staticClass:"line-number"},[v._v("12")]),_("br"),_("span",{staticClass:"line-number"},[v._v("13")]),_("br"),_("span",{staticClass:"line-number"},[v._v("14")]),_("br"),_("span",{staticClass:"line-number"},[v._v("15")]),_("br")])]),_("p",[v._v("可以看到, 想要使用集群, 需要执行以下命令, 执行结束后才可以使用 kubectl.")]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[v._v("mkdir "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("p $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube\ncp "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("i "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("etc"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("kubernetes"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("admin"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("conf $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("config\nchown $"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("id "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("u"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(":")]),v._v("$"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("id "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("-")]),v._v("g"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v(" $"),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("HOME")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),v._v("kube"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("/")]),v._v("config\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br")])]),_("p",[v._v("如果没有外网访问权限, 会报 pull image xxxxxx 的错误.")]),v._v(" "),_("p",[v._v("此时不要慌, 从报错信息中, 可以看到哪些镜像拉取不成功. 可以手动在 Docker Hub 上寻找相对应的组件及版本, 进行拉取, 然后再通过 Docker 打 tag, 修改为需要的镜像.")]),v._v(" "),_("p",[v._v("以 "),_("code",[v._v("[ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-apiserver:v1.16.3")]),v._v("​ 为例, 可以通过以下代码进行拉取.")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# 可以拉取的相对应的组件和版本")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("docker")]),v._v(" pull aiotceo/kube-apiserver:v1.16.3\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# 通过打 tag 的方式修改为所需要的镜像")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("docker")]),v._v(" tag aiotceo/kube-apiserver:v1.16.3 k8s.gcr.io/kube-apiserver:v1.16.3\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br")])]),_("p",[v._v("然后重新执行 kubeadm init 即可.")]),v._v(" "),_("p",[v._v("从以上操作也可以看出, "),_("strong",[v._v("kubeadm 的底层其实就是将容器化组件的操作实现了自动化, 省去了手动部署的麻烦")]),v._v(".")]),v._v(" "),_("p",[v._v("部署完 Master 节点后, 来继续部署 Worker 节点.")]),v._v(" "),_("h6",{attrs:{id:"_4-部署-worker-节点"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_4-部署-worker-节点"}},[v._v("#")]),v._v(" 4.部署 Worker 节点")]),v._v(" "),_("p",[v._v("部署 Worker 节点与部署 Master 节点类似, 都可以通过命令一键部署. 这里使用 kubeadm 提供的 "),_("strong",[v._v("kubeadm join 命令")]),v._v("来进行自动化部署.")]),v._v(" "),_("p",[v._v("kubeadm join 命令的底层与 kubeadm init 类似, 会自动以 Pod 形式运行 Worker 节点中需要的组件. 不同的是, 命令执行后, 底层还需要将 Worker 节点加入到 Kubernetes 集群中.")]),v._v(" "),_("p",[v._v("执行 kubeadm join 命令后(具体命令如下所示), 就可以看到 Kubernetes 集群中的节点信息了. 这条命令中需要配置 Master 节点的 IP 和 Port 信息, 目的是 Worker 节点根据 IP 和 Port 信息建立连接, 并在建立连接的基础上, 建立心跳机制.")]),v._v(" "),_("p",[v._v("到目前为止, Kubernetes 的集群已经完成大半了, 下面继续部署集群.")]),v._v(" "),_("p",[v._v("根据 Master 节点部署成功后输出结果的最后几行可以知道, 想要加入集群, 可以执行 kubeadm join 命令. 在另外 2 台机器上都执行了如下命令:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubeadm "),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("join")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("192.168")]),v._v(".124.49:6443 \n"),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("--token")]),v._v(" uv17vd.q3ber8i5knxg4h0x \n--discovery-token-ca-cert-hash sha256:c55bd70d346d809e1079565cc1fc1a05f001671cc9f2d02c55bbbc4a00bcc2a3\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br")])]),_("p",[v._v("这条命令执行后, 一个集中式架构的雏形就搭建完成了. 接下来需要安装相应的网络插件, 以实现 Kubernetes 集群中 Pod 之间的通信.")]),v._v(" "),_("h6",{attrs:{id:"_5-安装网络插件"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_5-安装网络插件"}},[v._v("#")]),v._v(" 5.安装网络插件")]),v._v(" "),_("p",[v._v("网络插件有很多, 比如 Canal, Flannel, Weave 等. 不同的插件命令不一致, 具体命令可参考官网.")]),v._v(" "),_("p",[v._v("这里以安装 Weave 插件为例, 通过执行以下命令完成安装:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[_("span",{pre:!0,attrs:{class:"token function"}},[v._v("sysctl")]),v._v(" net.bridge.bridge-nf-call-iptables"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("=")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v("\nkubectl apply "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-f")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"https://cloud.weave.works/k8s/net?k8s-version='),_("span",{pre:!0,attrs:{class:"token variable"}},[_("span",{pre:!0,attrs:{class:"token variable"}},[v._v("$(")]),v._v("kubectl version "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("|")]),v._v(" base64 "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("|")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("tr")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-d")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token string"}},[v._v("'\\n'")]),_("span",{pre:!0,attrs:{class:"token variable"}},[v._v(")")])]),v._v('"')]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br")])]),_("h6",{attrs:{id:"_6-验证"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_6-验证"}},[v._v("#")]),v._v(" 6.验证")]),v._v(" "),_("p",[v._v("到这里, 集群就部署完成了, 是不是很简单呢? 接下来就通过获取节点和 Pod 信息来验证一下集群部署是否成功.")]),v._v(" "),_("p",[v._v("可以通过刚刚安装的 kubectl 组件提供的命令查看集群的相关信息. 比如, 查看节点的运行状态可以通过 kubectl get nodes 来获得, 查看各个组件对应的 Pod 运行状态可以通过 kubectl get pods 来获得. 命令执行结果, 如下所示:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl get nodes\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# NAME           STATUS   ROLES    AGE   VERSION")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# vm1-pc   Ready    master   11h   v1.16.3")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# vm2-pc   Ready    <none>   11h   v1.16.3")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# vm3-pc   Ready    <none>   24m   v1.16.3")]),v._v("\n\nkubectl get pods --all-namespaces\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   coredns-5644d7b6d9-9dprc               1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   coredns-5644d7b6d9-ljv5w               1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   etcd-vm1-pc                      1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-apiserver-vm1-pc            1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-controller-manager-vm1-pc   1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-proxy-qpvtb                       1/1     Running   0          25m")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-proxy-v2xnb                       1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-proxy-wkxzg                       1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   kube-scheduler-vm1-pc            1/1     Running   0          11h")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   weave-net-6nj4c                        2/2     Running   0          25m")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   weave-net-lm6dh                        2/2     Running   0          37m")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# kube-system   weave-net-vwnc2                        2/2     Running   0          37m")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br"),_("span",{staticClass:"line-number"},[v._v("6")]),_("br"),_("span",{staticClass:"line-number"},[v._v("7")]),_("br"),_("span",{staticClass:"line-number"},[v._v("8")]),_("br"),_("span",{staticClass:"line-number"},[v._v("9")]),_("br"),_("span",{staticClass:"line-number"},[v._v("10")]),_("br"),_("span",{staticClass:"line-number"},[v._v("11")]),_("br"),_("span",{staticClass:"line-number"},[v._v("12")]),_("br"),_("span",{staticClass:"line-number"},[v._v("13")]),_("br"),_("span",{staticClass:"line-number"},[v._v("14")]),_("br"),_("span",{staticClass:"line-number"},[v._v("15")]),_("br"),_("span",{staticClass:"line-number"},[v._v("16")]),_("br"),_("span",{staticClass:"line-number"},[v._v("17")]),_("br"),_("span",{staticClass:"line-number"},[v._v("18")]),_("br"),_("span",{staticClass:"line-number"},[v._v("19")]),_("br"),_("span",{staticClass:"line-number"},[v._v("20")]),_("br")])]),_("p",[v._v("可以看到, "),_("strong",[v._v("节点全部是 Ready 状态, 各个组件对应的 Pod 也处于 Running 状态, 表明部署成功")]),v._v(".")]),v._v(" "),_("h6",{attrs:{id:"_7-可能遇到的问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_7-可能遇到的问题"}},[v._v("#")]),v._v(" 7.可能遇到的问题")]),v._v(" "),_("p",[v._v("如果整个安装失败的话, 可以重置, 重新安装, 即重新 kubeadm init.")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubeadm reset\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("部署 Worker 节点时, pod 部署不成功. 原因可能是因为没有外网访问权限, 镜像拉取不下来, 可以通过以下命令查看 pod 的相关信息:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# 检查所有 pod 是否正常")]),v._v("\nkubectl get pod --all-namespaces "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-o")]),v._v(" wide\n"),_("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# 如果 pod 处于非 running 状态, 则查看该 pod: ")]),v._v("\nkubectl describe pod xxxxx "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-n")]),v._v(" kube-system\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br")])]),_("p",[v._v("从错误信息里可以查看到是哪个镜像拉取不下来, 与部署 Master 节点时采用的方式一样, 到 Docker Hub 上手动拉取镜像, 并设置 Tag 即可.")]),v._v(" "),_("p",[v._v("至此, Kubernetes 集群就配置成功了.")]),v._v(" "),_("p",[v._v("集群环境搭建后, 如何验证集群是可用的呢? 或者说, 如何在集群上运行服务呢? 接下来就以 Nginx 服务为例, 带你了解如何在 Kubernetes 集群上进行服务部署.")]),v._v(" "),_("h5",{attrs:{id:"nginx服务部署"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#nginx服务部署"}},[v._v("#")]),v._v(" Nginx服务部署")]),v._v(" "),_("p",[v._v("Kubernetes 推荐使用 YAML 配置文件的方式来创建服务, 所以接下来会使用这种方式部署完成 Nginx 服务的部署.")]),v._v(" "),_("p",[v._v("部署 Nginx 服务这个 Demo 时, 会创建两个 Kubernetes 对象(Kubernetes 对象是 Kubernetes 系统中的持久实体, 用于表示集群的状态), 一个是 Deployment, 一个是 Service:")]),v._v(" "),_("ol",[_("li",[v._v("Deployment 对象规定 Pod 创建的相关信息, 比如期望创建几个 Pod, 每个 Pod 应该部署什么应用等.")]),v._v(" "),_("li",[v._v("Service 对象用来给用户访问提供接口. 它可以通过 Label Selector(标签选择器)来指定可以访问的 Pod 有哪些.")])]),v._v(" "),_("p",[v._v("因为 Pod 是 Kubernetes 中最小的工作单元, 所以 Nginx 服务都部署在 Pod 中. 下面就来创建一个 Deployment 对象来创建期望的 Pod 状态.")]),v._v(" "),_("p",[v._v("首先, 创建一个 YAML 配置文件, 将其命名为 nginx-deployment.yaml. 为将用户请求负载均衡到不同的 Pod, 减轻单个 Pod 的访问压力, 这里我会创建三个 Pod 共同运行 Nginx 服务.")]),v._v(" "),_("p",[v._v("文件内容如下:")]),v._v(" "),_("div",{staticClass:"language-yml line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-yml"}},[_("code",[_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("apiVersion")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" apps/v1\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("kind")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" Deployment\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("metadata")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("name")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("-")]),v._v("deployment\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("labels")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("app")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("spec")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("replicas")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("3")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("selector")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("matchLabels")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n      "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("app")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("template")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("metadata")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n      "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("labels")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n        "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("app")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("spec")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n      "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("containers")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n      "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("-")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("name")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n        "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("image")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("latest\n        "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("ports")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n        "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("-")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("containerPort")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("80")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br"),_("span",{staticClass:"line-number"},[v._v("6")]),_("br"),_("span",{staticClass:"line-number"},[v._v("7")]),_("br"),_("span",{staticClass:"line-number"},[v._v("8")]),_("br"),_("span",{staticClass:"line-number"},[v._v("9")]),_("br"),_("span",{staticClass:"line-number"},[v._v("10")]),_("br"),_("span",{staticClass:"line-number"},[v._v("11")]),_("br"),_("span",{staticClass:"line-number"},[v._v("12")]),_("br"),_("span",{staticClass:"line-number"},[v._v("13")]),_("br"),_("span",{staticClass:"line-number"},[v._v("14")]),_("br"),_("span",{staticClass:"line-number"},[v._v("15")]),_("br"),_("span",{staticClass:"line-number"},[v._v("16")]),_("br"),_("span",{staticClass:"line-number"},[v._v("17")]),_("br"),_("span",{staticClass:"line-number"},[v._v("18")]),_("br"),_("span",{staticClass:"line-number"},[v._v("19")]),_("br"),_("span",{staticClass:"line-number"},[v._v("20")]),_("br"),_("span",{staticClass:"line-number"},[v._v("21")]),_("br")])]),_("p",[v._v("文件中, replicas 字段就是副本数量, 也就是 Pod 数量, 设置为 3, 即创建三个 Pod 来运行 Nginx 服务; template 字段规定了单个 Pod 中运行哪些容器, 这里运行的是名称为 nginx 的容器.")]),v._v(" "),_("p",[v._v("创建完配置文件后, 通过以下命令就可以将 Deployment 对象创建成功.")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl apply "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-f")]),v._v(" nginx-deployment.yaml\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("执行后, 就等待对象的创建, 可以通过以下命令来查看创建是否成功.")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl get deployment\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("以下是创建成功后的输出:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("NAME               READY   UP-TO-DATE   AVAILABLE   AGE\nnginx-deployment   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("3")]),v._v("/3     "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("3")]),v._v("            "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("3")]),v._v("           3m17s\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br")])]),_("p",[v._v("同时也可以通过以下命令来查看创建的 Pod 的信息:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl get pod\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("以下是输出结果:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("NAME                               READY   STATUS    RESTARTS   AGE\nnginx-deployment-59c9f8dff-dtg4w   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v("/1     Running   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v("          3m15s\nnginx-deployment-59c9f8dff-f2hmv   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v("/1     Running   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v("          3m15s\nnginx-deployment-59c9f8dff-lsvdh   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),v._v("/1     Running   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v("          3m15s\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br")])]),_("p",[v._v("创建完 deployment 之后, 来创建 Service 服务. 同样是通过配置文件来创建, 文件名是 nginx-service.yaml, 内容如下:")]),v._v(" "),_("div",{staticClass:"language-yml line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-yml"}},[_("code",[_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("apiVersion")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" v1\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("kind")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" Service\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("metadata")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("name")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("-")]),v._v("service\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("labels")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("app")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n"),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("spec")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("ports")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("-")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("port")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("88")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("targetPort")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("80")]),v._v("\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("selector")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("app")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" nginx\n  "),_("span",{pre:!0,attrs:{class:"token key atrule"}},[v._v("type")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(":")]),v._v(" NodePort\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br"),_("span",{staticClass:"line-number"},[v._v("6")]),_("br"),_("span",{staticClass:"line-number"},[v._v("7")]),_("br"),_("span",{staticClass:"line-number"},[v._v("8")]),_("br"),_("span",{staticClass:"line-number"},[v._v("9")]),_("br"),_("span",{staticClass:"line-number"},[v._v("10")]),_("br"),_("span",{staticClass:"line-number"},[v._v("11")]),_("br"),_("span",{staticClass:"line-number"},[v._v("12")]),_("br"),_("span",{staticClass:"line-number"},[v._v("13")]),_("br")])]),_("p",[v._v("文件中 port 属性就是 service 对外提供的端口.")]),v._v(" "),_("p",[v._v("同样的, 采用 kubectl apply 命令创建 Nginx 服务:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl apply "),_("span",{pre:!0,attrs:{class:"token parameter variable"}},[v._v("-f")]),v._v(" nginx-service.yaml\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("执行完成后, 可以通过以下命令来查看创建是否成功:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("kubectl get "),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("service")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("以下是输出结果:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[v._v("NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("S"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v("          AGE\nkubernetes      ClusterIP   "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("10.96")]),v._v(".0.1        "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("none"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("        "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("443")]),v._v("/TCP          12h\nnginx-service   NodePort    "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("10.101")]),v._v(".29.9      "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("none"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("        "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("88")]),v._v(":30755/TCP     5m12s\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br")])]),_("p",[v._v("现在就可以通过访问 Nginx 服务来查看它是否部署成功了. 访问该服务可以通过以下命令:")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[_("span",{pre:!0,attrs:{class:"token function"}},[v._v("curl")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("10.101")]),v._v(".29.9:88\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("结果如下, 表明 Nginx 服务部署成功.")]),v._v(" "),_("div",{staticClass:"language-sh line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-sh"}},[_("code",[_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("!")]),v._v("DOCTYPE html"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("html"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("head"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("title"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("Welcome to nginx"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("!")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/title"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("style"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\nbody "),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("{")]),v._v("\nwidth: 35em"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("\nmargin: "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v(" auto"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("\nfont-family: Tahoma, Verdana, Arial, sans-serif"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("}")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/style"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/head"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("body"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("h"),_("span",{pre:!0,attrs:{class:"token operator"}},[_("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[v._v("1")]),v._v(">")]),v._v("Welcome to nginx"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("!")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/h"),_("span",{pre:!0,attrs:{class:"token operator"}},[_("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[v._v("1")]),v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required."),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("For online documentation and support please refer to\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("a "),_("span",{pre:!0,attrs:{class:"token assign-left variable"}},[v._v("href")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("=")]),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"http://nginx.org/"')]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("nginx.org"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/a"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("."),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("br /"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\nCommercial support is available at\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("a "),_("span",{pre:!0,attrs:{class:"token assign-left variable"}},[v._v("href")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("=")]),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"http://nginx.com/"')]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("nginx.com"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/a"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("."),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("em"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("Thank you "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("for")]),v._v(" using nginx."),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/em"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/p"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/body"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("<")]),v._v("/html"),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v(">")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br"),_("span",{staticClass:"line-number"},[v._v("6")]),_("br"),_("span",{staticClass:"line-number"},[v._v("7")]),_("br"),_("span",{staticClass:"line-number"},[v._v("8")]),_("br"),_("span",{staticClass:"line-number"},[v._v("9")]),_("br"),_("span",{staticClass:"line-number"},[v._v("10")]),_("br"),_("span",{staticClass:"line-number"},[v._v("11")]),_("br"),_("span",{staticClass:"line-number"},[v._v("12")]),_("br"),_("span",{staticClass:"line-number"},[v._v("13")]),_("br"),_("span",{staticClass:"line-number"},[v._v("14")]),_("br"),_("span",{staticClass:"line-number"},[v._v("15")]),_("br"),_("span",{staticClass:"line-number"},[v._v("16")]),_("br"),_("span",{staticClass:"line-number"},[v._v("17")]),_("br"),_("span",{staticClass:"line-number"},[v._v("18")]),_("br"),_("span",{staticClass:"line-number"},[v._v("19")]),_("br"),_("span",{staticClass:"line-number"},[v._v("20")]),_("br"),_("span",{staticClass:"line-number"},[v._v("21")]),_("br"),_("span",{staticClass:"line-number"},[v._v("22")]),_("br"),_("span",{staticClass:"line-number"},[v._v("23")]),_("br"),_("span",{staticClass:"line-number"},[v._v("24")]),_("br"),_("span",{staticClass:"line-number"},[v._v("25")]),_("br")])]),_("p",[v._v("在这个过程中, 有两个步骤涉及负载均衡的相关知识:")]),v._v(" "),_("ol",[_("li",[v._v("一个是创建 Deployment 时, 该 Deployment 会创建三个 Pod, 而 Pod 需要部署到某个 Worker 节点中, 因此会将 Pod 均衡部署到各个 Worker 节点中;")]),v._v(" "),_("li",[v._v("另一个是用户访问, Nginx 服务后台三个运行的 Pod 都可以提供服务, 用户访问到来时, 可以均衡分布到各个 Pod 中进行处理.")])]),v._v(" "),_("p",[v._v("到这里搭建的目标就完成了, 下面留几个实验题, 可以尝试去搭建一下或运行一下.")]),v._v(" "),_("ol",[_("li",[v._v("实验一: 搭建高可用 Kubernetes 集群, 也就是通过 etcd 实现 Master 节点以集群模式部署. 具体搭建方法可参考: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/;")]),v._v(" "),_("li",[v._v("实验二: 在 Kubenetes 上部署 Cassandra, 其中 Cassandra 作为服务部署到容器中, 以学习 Cassandra 集群的节点发现, 集群组件等原理, 具体搭建方法可参考: https://kubernetes.io/docs/tutorials/stateful-application/cassandra/;")]),v._v(" "),_("li",[v._v("实验三: 在 Kubenetes 集群上通过部署一个 MySQL 服务, 体验在 Kubenetes 集群上如何运行一个单实例有状态应用. 具体搭建方法可参考: https://kubernetes.io/docs/tasks/run-application/run-single-instance-stateful-application/.")])]),v._v(" "),_("h3",{attrs:{id:"结束语"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#结束语"}},[v._v("#")]),v._v(" 结束语")]),v._v(" "),_("h4",{attrs:{id:"结束语-为什么说提升职业竞争力要从尊重-诚实开始"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#结束语-为什么说提升职业竞争力要从尊重-诚实开始"}},[v._v("#")]),v._v(" 结束语-为什么说提升职业竞争力要从尊重,诚实开始?")]),v._v(" "),_("p",[v._v("那么, "),_("strong",[v._v('如何提升职业竞争力, 避免 "中年危机" 和 "职业生命力的焦虑" 呢')]),v._v("? 在我看来, 无外乎两个方面.")]),v._v(" "),_("p",[v._v("第一, "),_("strong",[v._v("要敬畏技术")]),v._v('. 大家经常听见各种议论, 说某种技术没有用, 某种技术太 low 了. 毛主席说: "战略上藐视敌人, 战术上重视敌人." 如果只是战略上轻视, 我觉得倒无伤大雅, 可怕的是还没有深入了解, 就从战术上轻视这些技术. 殊不知, 我们耳熟能详的很多新兴技术都是这些 "陈芝麻烂谷子" 技术的组合, 延伸.')]),v._v(" "),_("p",[v._v("比如, Docker 已成为业务发布, 部署标配的容器组件, 但其底层依赖的是 Linux Namespace 环境隔离, cgroups 资源限制等基础得不能再基础的技术. 再比如, 区块链作为一种开创性的去中心化多方信任技术, 现如今成为了国家的战略, 但其所依赖的分布式共识, P2P 网络, 非对称加密算法等没有一个是全新的技术. 这样的例子数不胜数.")]),v._v(" "),_("p",[v._v("这些案例告诉我们, 不是技术没用, 而是我们没有深入理解它们, 没有找到它们的用武之地. 我相信, 当学会了尊重技术之后, 化腐朽为神奇也就不再遥远了.")]),v._v(" "),_("p",[v._v("第二, "),_("strong",[v._v("对自己要诚实")]),v._v('. 前一阵子, 我遇到之前带的一个小兄弟. 了解了他的近况后, 我建议他在做一些重复工作之余, 提升一下自我. 没想到, 他说: "你看, 我是 985 名校毕业, 技术够好, 劝退这种事情根本不会发生到我头上." 殊不知, 那些被劝退的人是不是也曾有过这样的想法呢?')]),v._v(" "),_("p",[v._v("如果我们都无法对自己诚实, 那何谈去改变自己, 更不要说突破自己, 完善自己了. 如果一个人选择欺骗自己, 当时代抛弃他时, 可是连一声再见都不会说的.")]),v._v(" "),_("p",[v._v("所以, 我始终认为提升职业竞争力, 要从尊重和诚实开始.")]),v._v(" "),_("p",[v._v("当学会尊重和诚实后, 又"),_("strong",[v._v("应该树立什么样的技术目标呢?")]),v._v("  于我来讲, "),_("strong",[v._v('把自己塑造成一个 "倒三角" 人才(或 T 型人才)')]),v._v(" , 是一直以来的目标.")]),v._v(" "),_("p",[v._v("我博士的研究方向是并行与分布式技术, 按照 T 型人才的原则, 我努力把并行与分布式技术, 作为技术发展的根据地, 也就是字母 T 中的"),_("strong",[v._v("一竖")]),v._v(". 在不断做深, 做厚分布式技术的同时, 我会努力探索分布式技术跨界到新兴领域的可能性, 或结合分布式技术去研究一些新兴技术, 提升自己的技术广度, 也就是字母 T 中的一横.")]),v._v(" "),_("p",[v._v("有了分布式技术这只抓手, 当 IoT, 人工智能, 区块链, 云计算, 大数据, 边缘计算等新兴技术涌现后, 我发现我基本上都能插上一手, 因为这些新兴技术和分布式技术都存在交叉的地方.")]),v._v(" "),_("p",[v._v("那么对你来说, 一竖在哪里, 一横又在哪里呢?")]),v._v(" "),_("p",[v._v("‍")]),v._v(" "),_("p",[v._v("‍")])])}),[],!1,null,null,null);_.default=s.exports}}]);