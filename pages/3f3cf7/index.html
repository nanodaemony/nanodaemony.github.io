<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>运维监控系统实战(极客时间)🌸 | Pangolin Note</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="大道至简">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.56073ad3.css" as="style"><link rel="preload" href="/assets/js/app.3f3e0e10.js" as="script"><link rel="preload" href="/assets/js/2.e9fcb30c.js" as="script"><link rel="preload" href="/assets/js/3.1998f389.js" as="script"><link rel="preload" href="/assets/js/188.1bc8be96.js" as="script"><link rel="prefetch" href="/assets/js/10.0b55747f.js"><link rel="prefetch" href="/assets/js/100.b8912a99.js"><link rel="prefetch" href="/assets/js/101.a6740c8a.js"><link rel="prefetch" href="/assets/js/102.e31e89b2.js"><link rel="prefetch" href="/assets/js/103.2c5dbdae.js"><link rel="prefetch" href="/assets/js/104.0e9c02f6.js"><link rel="prefetch" href="/assets/js/105.8288396c.js"><link rel="prefetch" href="/assets/js/106.62f43c11.js"><link rel="prefetch" href="/assets/js/107.70c90211.js"><link rel="prefetch" href="/assets/js/108.b488ce56.js"><link rel="prefetch" href="/assets/js/109.12942650.js"><link rel="prefetch" href="/assets/js/11.ac3fd1ca.js"><link rel="prefetch" href="/assets/js/110.1e57ecba.js"><link rel="prefetch" href="/assets/js/111.6e33b4ea.js"><link rel="prefetch" href="/assets/js/112.bd52831b.js"><link rel="prefetch" href="/assets/js/113.868c1ac9.js"><link rel="prefetch" href="/assets/js/114.090549d1.js"><link rel="prefetch" href="/assets/js/115.d97f6c2b.js"><link rel="prefetch" href="/assets/js/116.097c4b4e.js"><link rel="prefetch" href="/assets/js/117.4024cfe2.js"><link rel="prefetch" href="/assets/js/118.e3057cba.js"><link rel="prefetch" href="/assets/js/119.4ef1fa3b.js"><link rel="prefetch" href="/assets/js/12.863eaabe.js"><link rel="prefetch" href="/assets/js/120.78f9df50.js"><link rel="prefetch" href="/assets/js/121.8e16df87.js"><link rel="prefetch" href="/assets/js/122.f21c0107.js"><link rel="prefetch" href="/assets/js/123.ea1cb375.js"><link rel="prefetch" href="/assets/js/124.01c04c6e.js"><link rel="prefetch" href="/assets/js/125.d383e301.js"><link rel="prefetch" href="/assets/js/126.3162cb47.js"><link rel="prefetch" href="/assets/js/127.c6bebae6.js"><link rel="prefetch" href="/assets/js/128.d659db60.js"><link rel="prefetch" href="/assets/js/129.2afdcf48.js"><link rel="prefetch" href="/assets/js/13.4f59ce35.js"><link rel="prefetch" href="/assets/js/130.beb9ed9d.js"><link rel="prefetch" href="/assets/js/131.35b05f8a.js"><link rel="prefetch" href="/assets/js/132.d77f4f93.js"><link rel="prefetch" href="/assets/js/133.4ceda6e5.js"><link rel="prefetch" href="/assets/js/134.11390c5f.js"><link rel="prefetch" href="/assets/js/135.32f9e38f.js"><link rel="prefetch" href="/assets/js/136.6d8bb0f2.js"><link rel="prefetch" href="/assets/js/137.9c0ffeef.js"><link rel="prefetch" href="/assets/js/138.88d86e5f.js"><link rel="prefetch" href="/assets/js/139.8c2c3d6c.js"><link rel="prefetch" href="/assets/js/14.11c82d35.js"><link rel="prefetch" href="/assets/js/140.c5c375d3.js"><link rel="prefetch" href="/assets/js/141.d703f30b.js"><link rel="prefetch" href="/assets/js/142.6a005a44.js"><link rel="prefetch" href="/assets/js/143.9b2edf6f.js"><link rel="prefetch" href="/assets/js/144.3fd013c9.js"><link rel="prefetch" href="/assets/js/145.b05079c5.js"><link rel="prefetch" href="/assets/js/146.ed5360a6.js"><link rel="prefetch" href="/assets/js/147.7408d86f.js"><link rel="prefetch" href="/assets/js/148.f390b370.js"><link rel="prefetch" href="/assets/js/149.95017f0a.js"><link rel="prefetch" href="/assets/js/15.bd143bd5.js"><link rel="prefetch" href="/assets/js/150.f0ede764.js"><link rel="prefetch" href="/assets/js/151.b7093623.js"><link rel="prefetch" href="/assets/js/152.a82a6c83.js"><link rel="prefetch" href="/assets/js/153.965e3fb2.js"><link rel="prefetch" href="/assets/js/154.9e49311e.js"><link rel="prefetch" href="/assets/js/155.cef33ba5.js"><link rel="prefetch" href="/assets/js/156.bcc397ae.js"><link rel="prefetch" href="/assets/js/157.90824739.js"><link rel="prefetch" href="/assets/js/158.efd429b9.js"><link rel="prefetch" href="/assets/js/159.122ff5b7.js"><link rel="prefetch" href="/assets/js/16.2449162b.js"><link rel="prefetch" href="/assets/js/160.0b806535.js"><link rel="prefetch" href="/assets/js/161.835052c6.js"><link rel="prefetch" href="/assets/js/162.ca34e2d2.js"><link rel="prefetch" href="/assets/js/163.08000d04.js"><link rel="prefetch" href="/assets/js/164.a1cc0109.js"><link rel="prefetch" href="/assets/js/165.65444686.js"><link rel="prefetch" href="/assets/js/166.7d73c84f.js"><link rel="prefetch" href="/assets/js/167.009d47a3.js"><link rel="prefetch" href="/assets/js/168.0afeae2a.js"><link rel="prefetch" href="/assets/js/169.7654cb31.js"><link rel="prefetch" href="/assets/js/17.eb7f9def.js"><link rel="prefetch" href="/assets/js/170.58569530.js"><link rel="prefetch" href="/assets/js/171.7db9ed40.js"><link rel="prefetch" href="/assets/js/172.3cb50ed4.js"><link rel="prefetch" href="/assets/js/173.0846425f.js"><link rel="prefetch" href="/assets/js/174.9e95f111.js"><link rel="prefetch" href="/assets/js/175.ef2098f2.js"><link rel="prefetch" href="/assets/js/176.c2635fe9.js"><link rel="prefetch" href="/assets/js/177.4fa38e8e.js"><link rel="prefetch" href="/assets/js/178.2be7037f.js"><link rel="prefetch" href="/assets/js/179.bf3bba28.js"><link rel="prefetch" href="/assets/js/18.0455f4d1.js"><link rel="prefetch" href="/assets/js/180.72c5f597.js"><link rel="prefetch" href="/assets/js/181.42287bcc.js"><link rel="prefetch" href="/assets/js/182.6cd4bf1a.js"><link rel="prefetch" href="/assets/js/183.05dbbfd9.js"><link rel="prefetch" href="/assets/js/184.03de7e00.js"><link rel="prefetch" href="/assets/js/185.42dd210e.js"><link rel="prefetch" href="/assets/js/186.28ee0f8a.js"><link rel="prefetch" href="/assets/js/187.bb58697b.js"><link rel="prefetch" href="/assets/js/189.fac747e3.js"><link rel="prefetch" href="/assets/js/19.ae9e35d6.js"><link rel="prefetch" href="/assets/js/190.ea533ac7.js"><link rel="prefetch" href="/assets/js/191.6dc6eb13.js"><link rel="prefetch" href="/assets/js/192.184d249f.js"><link rel="prefetch" href="/assets/js/193.4a06bc12.js"><link rel="prefetch" href="/assets/js/194.8cce60a9.js"><link rel="prefetch" href="/assets/js/195.93231a13.js"><link rel="prefetch" href="/assets/js/196.4a596bde.js"><link rel="prefetch" href="/assets/js/197.96c113cf.js"><link rel="prefetch" href="/assets/js/198.73ba3f67.js"><link rel="prefetch" href="/assets/js/199.74bab595.js"><link rel="prefetch" href="/assets/js/20.b542d0e7.js"><link rel="prefetch" href="/assets/js/200.69a6928a.js"><link rel="prefetch" href="/assets/js/201.9ffa7c5a.js"><link rel="prefetch" href="/assets/js/202.41edb652.js"><link rel="prefetch" href="/assets/js/203.7fabcef3.js"><link rel="prefetch" href="/assets/js/204.b0ae2f62.js"><link rel="prefetch" href="/assets/js/205.add8738b.js"><link rel="prefetch" href="/assets/js/206.f3a712ec.js"><link rel="prefetch" href="/assets/js/207.cd7dd729.js"><link rel="prefetch" href="/assets/js/208.78b33afa.js"><link rel="prefetch" href="/assets/js/209.9d3329ff.js"><link rel="prefetch" href="/assets/js/21.5a050318.js"><link rel="prefetch" href="/assets/js/210.d285d5ac.js"><link rel="prefetch" href="/assets/js/211.8791bb3f.js"><link rel="prefetch" href="/assets/js/212.84ed81a8.js"><link rel="prefetch" href="/assets/js/213.7b990580.js"><link rel="prefetch" href="/assets/js/214.da31f20c.js"><link rel="prefetch" href="/assets/js/215.9eeed659.js"><link rel="prefetch" href="/assets/js/216.9539f0ec.js"><link rel="prefetch" href="/assets/js/217.11b575be.js"><link rel="prefetch" href="/assets/js/218.a67f12f1.js"><link rel="prefetch" href="/assets/js/219.bfbb817a.js"><link rel="prefetch" href="/assets/js/22.2bc6f7e3.js"><link rel="prefetch" href="/assets/js/220.8b01342f.js"><link rel="prefetch" href="/assets/js/221.b450decd.js"><link rel="prefetch" href="/assets/js/222.97468507.js"><link rel="prefetch" href="/assets/js/223.b6dafd73.js"><link rel="prefetch" href="/assets/js/224.c86c18c6.js"><link rel="prefetch" href="/assets/js/225.b0dcf86e.js"><link rel="prefetch" href="/assets/js/226.02cc2999.js"><link rel="prefetch" href="/assets/js/227.8474ef5a.js"><link rel="prefetch" href="/assets/js/228.0298e421.js"><link rel="prefetch" href="/assets/js/229.6aeaf595.js"><link rel="prefetch" href="/assets/js/23.9995fce4.js"><link rel="prefetch" href="/assets/js/230.a5785286.js"><link rel="prefetch" href="/assets/js/231.d791daa4.js"><link rel="prefetch" href="/assets/js/232.97aeeb00.js"><link rel="prefetch" href="/assets/js/233.46e51e28.js"><link rel="prefetch" href="/assets/js/234.2cffe82f.js"><link rel="prefetch" href="/assets/js/235.14965da6.js"><link rel="prefetch" href="/assets/js/236.00a5afc0.js"><link rel="prefetch" href="/assets/js/237.3b73d52f.js"><link rel="prefetch" href="/assets/js/238.6e1db765.js"><link rel="prefetch" href="/assets/js/239.75866c5e.js"><link rel="prefetch" href="/assets/js/24.9141eeb2.js"><link rel="prefetch" href="/assets/js/240.af9c2cc9.js"><link rel="prefetch" href="/assets/js/241.388acab2.js"><link rel="prefetch" href="/assets/js/242.c60f2b48.js"><link rel="prefetch" href="/assets/js/243.d8e81b13.js"><link rel="prefetch" href="/assets/js/244.58b0b21d.js"><link rel="prefetch" href="/assets/js/245.c3768497.js"><link rel="prefetch" href="/assets/js/246.ac8bbe7a.js"><link rel="prefetch" href="/assets/js/247.d095f70a.js"><link rel="prefetch" href="/assets/js/248.e9f210b5.js"><link rel="prefetch" href="/assets/js/249.a9fad023.js"><link rel="prefetch" href="/assets/js/25.98e8593e.js"><link rel="prefetch" href="/assets/js/250.ae7f0ebb.js"><link rel="prefetch" href="/assets/js/251.9a617d55.js"><link rel="prefetch" href="/assets/js/252.ce082446.js"><link rel="prefetch" href="/assets/js/253.4575302d.js"><link rel="prefetch" href="/assets/js/254.5899a61b.js"><link rel="prefetch" href="/assets/js/255.66c69f31.js"><link rel="prefetch" href="/assets/js/256.8fd6c706.js"><link rel="prefetch" href="/assets/js/257.31b77e5e.js"><link rel="prefetch" href="/assets/js/258.eba48891.js"><link rel="prefetch" href="/assets/js/259.edf74b59.js"><link rel="prefetch" href="/assets/js/26.e69924ea.js"><link rel="prefetch" href="/assets/js/260.cf2ed36d.js"><link rel="prefetch" href="/assets/js/261.9e7792d8.js"><link rel="prefetch" href="/assets/js/262.e7b9433e.js"><link rel="prefetch" href="/assets/js/263.1185b25c.js"><link rel="prefetch" href="/assets/js/264.5e0f89cb.js"><link rel="prefetch" href="/assets/js/265.a38d3b94.js"><link rel="prefetch" href="/assets/js/266.2ef170b3.js"><link rel="prefetch" href="/assets/js/267.a7d14651.js"><link rel="prefetch" href="/assets/js/268.05b18748.js"><link rel="prefetch" href="/assets/js/269.dad48d6f.js"><link rel="prefetch" href="/assets/js/27.13612515.js"><link rel="prefetch" href="/assets/js/270.4f5a6b8d.js"><link rel="prefetch" href="/assets/js/271.7ebf6682.js"><link rel="prefetch" href="/assets/js/272.7c2fbfd1.js"><link rel="prefetch" href="/assets/js/273.8ee20732.js"><link rel="prefetch" href="/assets/js/274.d525242a.js"><link rel="prefetch" href="/assets/js/275.a8a19acb.js"><link rel="prefetch" href="/assets/js/276.df3a4eb4.js"><link rel="prefetch" href="/assets/js/277.336debda.js"><link rel="prefetch" href="/assets/js/278.c470625f.js"><link rel="prefetch" href="/assets/js/279.a91e1a64.js"><link rel="prefetch" href="/assets/js/28.ab7ae1df.js"><link rel="prefetch" href="/assets/js/280.87e25c9a.js"><link rel="prefetch" href="/assets/js/281.87c1ba25.js"><link rel="prefetch" href="/assets/js/282.dcd4dce0.js"><link rel="prefetch" href="/assets/js/283.abac2e00.js"><link rel="prefetch" href="/assets/js/284.f6079659.js"><link rel="prefetch" href="/assets/js/285.f1b39879.js"><link rel="prefetch" href="/assets/js/286.f6a79242.js"><link rel="prefetch" href="/assets/js/287.06bebe07.js"><link rel="prefetch" href="/assets/js/288.89e325df.js"><link rel="prefetch" href="/assets/js/289.3aa1bedd.js"><link rel="prefetch" href="/assets/js/29.ebe50f76.js"><link rel="prefetch" href="/assets/js/290.ee059c92.js"><link rel="prefetch" href="/assets/js/291.fa9a921a.js"><link rel="prefetch" href="/assets/js/292.2a8811cd.js"><link rel="prefetch" href="/assets/js/293.eec09cdf.js"><link rel="prefetch" href="/assets/js/294.dfac20dc.js"><link rel="prefetch" href="/assets/js/295.825d2070.js"><link rel="prefetch" href="/assets/js/296.f645861e.js"><link rel="prefetch" href="/assets/js/297.424fdb17.js"><link rel="prefetch" href="/assets/js/298.ebf87cdc.js"><link rel="prefetch" href="/assets/js/299.b8f19cbb.js"><link rel="prefetch" href="/assets/js/30.75237511.js"><link rel="prefetch" href="/assets/js/300.10fb6d4f.js"><link rel="prefetch" href="/assets/js/301.ef77c612.js"><link rel="prefetch" href="/assets/js/302.1b839763.js"><link rel="prefetch" href="/assets/js/303.609f7d98.js"><link rel="prefetch" href="/assets/js/304.1d255f19.js"><link rel="prefetch" href="/assets/js/305.b0234f2c.js"><link rel="prefetch" href="/assets/js/306.48677f64.js"><link rel="prefetch" href="/assets/js/307.14390d4b.js"><link rel="prefetch" href="/assets/js/308.fa730b28.js"><link rel="prefetch" href="/assets/js/309.0496b9e0.js"><link rel="prefetch" href="/assets/js/31.cf3f471a.js"><link rel="prefetch" href="/assets/js/310.a31676dc.js"><link rel="prefetch" href="/assets/js/311.ed53adc5.js"><link rel="prefetch" href="/assets/js/312.1b0ff2f1.js"><link rel="prefetch" href="/assets/js/313.bf123f32.js"><link rel="prefetch" href="/assets/js/314.4e6ce06b.js"><link rel="prefetch" href="/assets/js/315.8eb18560.js"><link rel="prefetch" href="/assets/js/32.74fef842.js"><link rel="prefetch" href="/assets/js/33.bc2d190b.js"><link rel="prefetch" href="/assets/js/34.d23438fc.js"><link rel="prefetch" href="/assets/js/35.7675c4d0.js"><link rel="prefetch" href="/assets/js/36.96a4161b.js"><link rel="prefetch" href="/assets/js/37.d1824f2f.js"><link rel="prefetch" href="/assets/js/38.4effff9e.js"><link rel="prefetch" href="/assets/js/39.6509914b.js"><link rel="prefetch" href="/assets/js/4.4d01750f.js"><link rel="prefetch" href="/assets/js/40.1509d08b.js"><link rel="prefetch" href="/assets/js/41.f2c1124f.js"><link rel="prefetch" href="/assets/js/42.e541d077.js"><link rel="prefetch" href="/assets/js/43.369de999.js"><link rel="prefetch" href="/assets/js/44.43959db0.js"><link rel="prefetch" href="/assets/js/45.282fbd31.js"><link rel="prefetch" href="/assets/js/46.1b83cfe9.js"><link rel="prefetch" href="/assets/js/47.c3a88e41.js"><link rel="prefetch" href="/assets/js/48.bc7c0a1b.js"><link rel="prefetch" href="/assets/js/49.92a4e5ba.js"><link rel="prefetch" href="/assets/js/5.c3991e24.js"><link rel="prefetch" href="/assets/js/50.9c488c6c.js"><link rel="prefetch" href="/assets/js/51.546ea632.js"><link rel="prefetch" href="/assets/js/52.0d2ccee1.js"><link rel="prefetch" href="/assets/js/53.6f52b5b1.js"><link rel="prefetch" href="/assets/js/54.c838b295.js"><link rel="prefetch" href="/assets/js/55.13af99ee.js"><link rel="prefetch" href="/assets/js/56.6be6d1ed.js"><link rel="prefetch" href="/assets/js/57.67c98b39.js"><link rel="prefetch" href="/assets/js/58.107e82ec.js"><link rel="prefetch" href="/assets/js/59.b3e5edc7.js"><link rel="prefetch" href="/assets/js/6.36a535f9.js"><link rel="prefetch" href="/assets/js/60.3b0b4ba5.js"><link rel="prefetch" href="/assets/js/61.3df843df.js"><link rel="prefetch" href="/assets/js/62.1213823d.js"><link rel="prefetch" href="/assets/js/63.e8f3f926.js"><link rel="prefetch" href="/assets/js/64.e1219050.js"><link rel="prefetch" href="/assets/js/65.5bf5bb0b.js"><link rel="prefetch" href="/assets/js/66.a2502afb.js"><link rel="prefetch" href="/assets/js/67.690dd59b.js"><link rel="prefetch" href="/assets/js/68.de7b0915.js"><link rel="prefetch" href="/assets/js/69.ac61dd61.js"><link rel="prefetch" href="/assets/js/7.5d254238.js"><link rel="prefetch" href="/assets/js/70.3edd41b1.js"><link rel="prefetch" href="/assets/js/71.d23407e9.js"><link rel="prefetch" href="/assets/js/72.a5bd01bc.js"><link rel="prefetch" href="/assets/js/73.c9f4dd57.js"><link rel="prefetch" href="/assets/js/74.66323fc1.js"><link rel="prefetch" href="/assets/js/75.e1a72e00.js"><link rel="prefetch" href="/assets/js/76.801268b4.js"><link rel="prefetch" href="/assets/js/77.3a5fda67.js"><link rel="prefetch" href="/assets/js/78.54d84cd4.js"><link rel="prefetch" href="/assets/js/79.fa10f4e3.js"><link rel="prefetch" href="/assets/js/8.e060e47d.js"><link rel="prefetch" href="/assets/js/80.d5b24fea.js"><link rel="prefetch" href="/assets/js/81.0e9da714.js"><link rel="prefetch" href="/assets/js/82.e96ff6d7.js"><link rel="prefetch" href="/assets/js/83.771cced1.js"><link rel="prefetch" href="/assets/js/84.220b69e7.js"><link rel="prefetch" href="/assets/js/85.7dcc5659.js"><link rel="prefetch" href="/assets/js/86.44ba2100.js"><link rel="prefetch" href="/assets/js/87.281da75d.js"><link rel="prefetch" href="/assets/js/88.12d88449.js"><link rel="prefetch" href="/assets/js/89.f28c86d3.js"><link rel="prefetch" href="/assets/js/9.8f9fef32.js"><link rel="prefetch" href="/assets/js/90.715cabb2.js"><link rel="prefetch" href="/assets/js/91.6ced7c82.js"><link rel="prefetch" href="/assets/js/92.c05b33ca.js"><link rel="prefetch" href="/assets/js/93.6bf5fb66.js"><link rel="prefetch" href="/assets/js/94.3561200e.js"><link rel="prefetch" href="/assets/js/95.0f2cf716.js"><link rel="prefetch" href="/assets/js/96.ac8487ea.js"><link rel="prefetch" href="/assets/js/97.48042b5a.js"><link rel="prefetch" href="/assets/js/98.441bb7f8.js"><link rel="prefetch" href="/assets/js/99.4b214d92.js">
    <link rel="stylesheet" href="/assets/css/0.styles.56073ad3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/magic.png" alt="Pangolin Note" class="logo"> <span class="site-name can-hide">Pangolin Note</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">🏡首页</a></div><div class="nav-item"><a href="/basic/" class="nav-link">基础</a></div><div class="nav-item"><a href="/develop/" class="nav-link">开发</a></div><div class="nav-item"><a href="/middleware/" class="nav-link">系统</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">算法</a></div><div class="nav-item"><a href="/books/" class="nav-link">🍀读书笔记</a></div><div class="nav-item"><a href="/work/" class="nav-link">工作</a></div><div class="nav-item"><a href="/pangolin/" class="nav-link">🌸达尔文的猹</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/avatarnew.png"> <div class="blogger-info"><h3>达尔文的猹</h3> <span>大道至简 悟在天成</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">🏡首页</a></div><div class="nav-item"><a href="/basic/" class="nav-link">基础</a></div><div class="nav-item"><a href="/develop/" class="nav-link">开发</a></div><div class="nav-item"><a href="/middleware/" class="nav-link">系统</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">算法</a></div><div class="nav-item"><a href="/books/" class="nav-link">🍀读书笔记</a></div><div class="nav-item"><a href="/work/" class="nav-link">工作</a></div><div class="nav-item"><a href="/pangolin/" class="nav-link">🌸达尔文的猹</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>系统</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>分布式系统理论</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/129626/" class="sidebar-link">分布式系统基础</a></li><li><a href="/pages/fb5d35/" class="sidebar-link">分布式共识算法</a></li><li><a href="/pages/12ac37/" class="sidebar-link">分布式系统组件</a></li><li><a href="/pages/d03ebf/" class="sidebar-link">分布式技术原理与算法解析(极客时间)🌸</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>系统接入层</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/f1b6c4/" class="sidebar-link">Nginx基础</a></li><li><a href="/pages/d4123d/" class="sidebar-link">深入拆解Tomcat与Jetty(极客时间)🌸</a></li><li><a href="/pages/baee2f/" class="sidebar-link">Netty</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>服务治理-注册发现与RPC</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/05077d/" class="sidebar-link">基础</a></li><li><a href="/pages/51b6aa/" class="sidebar-link">RPC实战与核心原理(极客时间)🌸</a></li><li><a href="/pages/0966ee/" class="sidebar-link">Zookeeper</a></li><li><a href="/pages/3b7e05/" class="sidebar-link">Nacos</a></li><li><a href="/pages/7f31f8/" class="sidebar-link">Dubbo</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>服务治理-流量控制</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/44bfa8/" class="sidebar-link">负载均衡</a></li><li><a href="/pages/4d5a6c/" class="sidebar-link">限流</a></li><li><a href="/pages/e0c561/" class="sidebar-link">熔断</a></li><li><a href="/pages/12ae40/" class="sidebar-link">网关路由</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading open"><span>服务治理-系统监控与安全</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/8c9210/" class="sidebar-link">系统安全性</a></li><li><a href="/pages/c9bf40/" class="sidebar-link">系统监控组件</a></li><li><a href="/pages/3f3cf7/" aria-current="page" class="active sidebar-link">运维监控系统实战(极客时间)🌸</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#开篇词" class="sidebar-link">开篇词</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_0-每个关注高可用的人-都应该了解监控知识" class="sidebar-link">0.每个关注高可用的人,都应该了解监控知识</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#哪些人应该学习监控相关的知识" class="sidebar-link">哪些人应该学习监控相关的知识?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控是做好软件架构的重要一环" class="sidebar-link">监控是做好软件架构的重要一环</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#这门课的结构" class="sidebar-link">这门课的结构</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#监控概述" class="sidebar-link">监控概述</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_1-背景信息-监控需求以及开源方案的横评对比" class="sidebar-link">1.背景信息-监控需求以及开源方案的横评对比</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控需求来源" class="sidebar-link">监控需求来源</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#可观测性三大支柱" class="sidebar-link">可观测性三大支柱</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-指标监控" class="sidebar-link">1.指标监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-日志" class="sidebar-link">2.日志</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-链路追踪" class="sidebar-link">3.链路追踪</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#业界方案横评" class="sidebar-link">业界方案横评</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-老一代整体方案的代表zabbix" class="sidebar-link">1.老一代整体方案的代表Zabbix</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-老一代国产代表open-falcon" class="sidebar-link">2.老一代国产代表Open-Falcon</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-新一代整体方案代表prometheus" class="sidebar-link">3.新一代整体方案代表Prometheus</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-新一代国产代表-nightingale" class="sidebar-link">4.新一代国产代表 Nightingale</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-对比" class="sidebar-link">5.对比</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_2-基本概念-监控圈子有哪些行业黑话" class="sidebar-link">2.基本概念-监控圈子有哪些行业黑话?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控指标" class="sidebar-link">监控指标</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-全局唯一字符串作为指标标识" class="sidebar-link">1.全局唯一字符串作为指标标识</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-标签集的组合作为指标标识" class="sidebar-link">2.标签集的组合作为指标标识</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-优雅高效的influx指标格式" class="sidebar-link">3.优雅高效的Influx指标格式</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#指标类型" class="sidebar-link">指标类型</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-gauge" class="sidebar-link">1.Gauge</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-counter" class="sidebar-link">2.Counter</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-histogram" class="sidebar-link">3.Histogram</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-summary" class="sidebar-link">4.Summary</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-类型扩展知识" class="sidebar-link">5.类型扩展知识</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#时序库" class="sidebar-link">时序库</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警收敛" class="sidebar-link">告警收敛</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警闭环" class="sidebar-link">告警闭环</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_3-架构概述-一个监控系统的典型架构是什么样的" class="sidebar-link">3.架构概述-一个监控系统的典型架构是什么样的?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#典型架构" class="sidebar-link">典型架构</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#采集器" class="sidebar-link">采集器</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-telegraf" class="sidebar-link">1.Telegraf</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-exporters" class="sidebar-link">2.Exporters</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-grafana-agent" class="sidebar-link">3.Grafana-Agent</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-categraf" class="sidebar-link">4.Categraf</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#时序库-2" class="sidebar-link">时序库</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-influxdb" class="sidebar-link">1.InfluxDB</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-tdengine" class="sidebar-link">2.TDEngine</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-m3db" class="sidebar-link">3.M3DB</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-victoriametrics" class="sidebar-link">4.VictoriaMetrics</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-timescaledb" class="sidebar-link">5.TimescaleDB</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警引擎" class="sidebar-link">告警引擎</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#数据展示" class="sidebar-link">数据展示</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-2" class="sidebar-link">小结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#搭建并增强prometheus" class="sidebar-link">搭建并增强Prometheus</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_4-如何快速搭建prometheus系统" class="sidebar-link">4.如何快速搭建Prometheus系统?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#通用架构回顾" class="sidebar-link">通用架构回顾</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#部署prometheus" class="sidebar-link">部署Prometheus</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#部署node-exporter" class="sidebar-link">部署Node-Exporter</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#配置告警规则" class="sidebar-link">配置告警规则</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#部署alertmanager" class="sidebar-link">部署Alertmanager</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#部署grafana" class="sidebar-link">部署Grafana</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-3" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_5-prometheus中有哪些关键设计" class="sidebar-link">5.Prometheus中有哪些关键设计?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#标准先行与注重生态" class="sidebar-link">标准先行与注重生态</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#主要使用拉模式与解耦" class="sidebar-link">主要使用拉模式与解耦</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控目标动态发现机制" class="sidebar-link">监控目标动态发现机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#基于配置文件的管理方式" class="sidebar-link">基于配置文件的管理方式</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#灵活的查询语言" class="sidebar-link">灵活的查询语言</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-4" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_6-promql有哪些常见的使用场景" class="sidebar-link">6.PromQL有哪些常见的使用场景?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#时序数据" class="sidebar-link">时序数据</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#promql典型应用场景" class="sidebar-link">PromQL典型应用场景</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-查询选择器" class="sidebar-link">1.查询选择器</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-算术运算符" class="sidebar-link">2.算术运算符</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-比较运算符" class="sidebar-link">3.比较运算符</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-逻辑运算符" class="sidebar-link">4.逻辑运算符</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-向量匹配" class="sidebar-link">5.向量匹配</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_6-聚合运算" class="sidebar-link">6.聚合运算</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#容易误解的函数" class="sidebar-link">容易误解的函数</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-5" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_7-如何解决prometheus的存储容量问题" class="sidebar-link">7.如何解决Prometheus的存储容量问题?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#所有场景都需要扩展容量吗" class="sidebar-link">所有场景都需要扩展容量吗?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#prometheus-联邦机制" class="sidebar-link">Prometheus 联邦机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#远程存储方案" class="sidebar-link">远程存储方案</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-victoriametrics" class="sidebar-link">1.VictoriaMetrics</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-thanos" class="sidebar-link">2.Thanos</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#prometheus自身搭建集群" class="sidebar-link">Prometheus自身搭建集群</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-6" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_8-如何用nightingale解决prometheus的告警管理问题" class="sidebar-link">8.如何用Nightingale解决Prometheus的告警管理问题?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#夜莺简介" class="sidebar-link">夜莺简介</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#部署夜莺" class="sidebar-link">部署夜莺</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警管理" class="sidebar-link">告警管理</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-规则管理" class="sidebar-link">1.规则管理</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-规则配置" class="sidebar-link">2.规则配置</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-告警屏蔽" class="sidebar-link">3.告警屏蔽</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-告警订阅" class="sidebar-link">4.告警订阅</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-历史告警存档" class="sidebar-link">5.历史告警存档</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_6-活跃告警聚合" class="sidebar-link">6.活跃告警聚合</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_7-告警自愈" class="sidebar-link">7.告警自愈</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_8-失联告警" class="sidebar-link">8.失联告警</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-7" class="sidebar-link">小结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#监控实战" class="sidebar-link">监控实战</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_9-监控概论-有哪些方法可以指导监控数据采集" class="sidebar-link">9.监控概论-有哪些方法可以指导监控数据采集?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#google的四个黄金指标" class="sidebar-link">Google的四个黄金指标</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#red方法" class="sidebar-link">RED方法</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#use方法" class="sidebar-link">USE方法</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控分类" class="sidebar-link">监控分类</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-业务监控" class="sidebar-link">1.业务监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-应用监控" class="sidebar-link">2.应用监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-组件监控" class="sidebar-link">3.组件监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-资源监控" class="sidebar-link">4.资源监控</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_1-设备监控" class="sidebar-link">(1)设备监控</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_2-网络监控" class="sidebar-link">(2)网络监控</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-8" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_10-监控概论-监控数据的采集方式及原理" class="sidebar-link">10.监控概论-监控数据的采集方式及原理</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#读取-proc目录" class="sidebar-link">读取/proc目录</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#执行命令行工具" class="sidebar-link">执行命令行工具</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#远程黑盒探测" class="sidebar-link">远程黑盒探测</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#拉取特定协议的数据" class="sidebar-link">拉取特定协议的数据</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#连接到目标对象执行命令" class="sidebar-link">连接到目标对象执行命令</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#代码埋点与日志解析" class="sidebar-link">代码埋点与日志解析</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-9" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_11-机器监控-操作系统有哪些指标需要重点关注" class="sidebar-link">11.机器监控-操作系统有哪些指标需要重点关注?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#机器监控手段" class="sidebar-link">机器监控手段</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#categraf介绍" class="sidebar-link">Categraf介绍</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#categraf配置" class="sidebar-link">Categraf配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#导入配置" class="sidebar-link">导入配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#categraf插件" class="sidebar-link">Categraf插件</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-cpu" class="sidebar-link">1.cpu</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-mem" class="sidebar-link">2.mem</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-disk" class="sidebar-link">3.disk</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-diskio" class="sidebar-link">4.diskio</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-net" class="sidebar-link">5.net</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_6-netstat" class="sidebar-link">6.netstat</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_7-processes" class="sidebar-link">7.processes</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_8-conntrack" class="sidebar-link">8.conntrack</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_9-kernel-vmstat" class="sidebar-link">9.kernel_vmstat</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_10-ntp" class="sidebar-link">10.ntp</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_11-procstat" class="sidebar-link">11.procstat</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_12-exec" class="sidebar-link">12.exec</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-10" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_12-网络监控-如何监控网络链路和网络设备" class="sidebar-link">12.网络监控-如何监控网络链路和网络设备?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#网络链路监控" class="sidebar-link">网络链路监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-icmp探测" class="sidebar-link">1.ICMP探测</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-tcp探测" class="sidebar-link">2.TCP探测</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-http探测" class="sidebar-link">3.HTTP探测</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#网络设备监控" class="sidebar-link">网络设备监控</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-snmp指标获取方式" class="sidebar-link">1.SNMP指标获取方式</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-snmp-trap" class="sidebar-link">2.SNMP Trap</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-11" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_13-组件监控-mysql的关键指标及采集方法有哪些" class="sidebar-link">13.组件监控-MySQL的关键指标及采集方法有哪些?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#整体思路" class="sidebar-link">整体思路</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-延迟" class="sidebar-link">1.延迟</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-流量" class="sidebar-link">2.流量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-错误" class="sidebar-link">3.错误</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-饱和度" class="sidebar-link">4.饱和度</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#采集配置" class="sidebar-link">采集配置</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-中心化探测" class="sidebar-link">1.中心化探测</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-分布式本地采集" class="sidebar-link">2.分布式本地采集</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#业务指标" class="sidebar-link">业务指标</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-12" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_14-组件监控-redis的关键指标及采集方法有哪些" class="sidebar-link">14.组件监控-Redis的关键指标及采集方法有哪些?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#延迟" class="sidebar-link">延迟</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#流量" class="sidebar-link">流量</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#错误" class="sidebar-link">错误</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#饱和度" class="sidebar-link">饱和度</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#采集配置-2" class="sidebar-link">采集配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-13" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_15-组件监控-kafka的关键指标及采集方法有哪些" class="sidebar-link">15.组件监控-Kafka的关键指标及采集方法有哪些?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#kafka架构" class="sidebar-link">Kafka架构</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#jmx简介" class="sidebar-link">JMX简介</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#kafka开启jmx" class="sidebar-link">Kafka开启JMX</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#kafka开启jolokia" class="sidebar-link">Kafka开启Jolokia</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#jvm指标" class="sidebar-link">JVM指标</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#kafka指标" class="sidebar-link">Kafka指标</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-活跃控制器数量" class="sidebar-link">1.活跃控制器数量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-非同步分区数量" class="sidebar-link">2.非同步分区数量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-离线分区数量" class="sidebar-link">3.离线分区数量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-离线日志目录数量" class="sidebar-link">4.离线日志目录数量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-流入流出字节和流入消息" class="sidebar-link">5.流入流出字节和流入消息</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_6-流入字节" class="sidebar-link">6.流入字节</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_7-流出字节" class="sidebar-link">7.流出字节</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_8-流入消息" class="sidebar-link">8.流入消息</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_9-分区数量" class="sidebar-link">9.分区数量</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_10-leader分区数量" class="sidebar-link">10.leader分区数量</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#lag监控" class="sidebar-link">Lag监控</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-14" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_16-组件监控-elasticsearch的关键指标及采集方法有哪些" class="sidebar-link">16.组件监控-Elasticsearch的关键指标及采集方法有哪些?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#elasticsearch-的职能和架构" class="sidebar-link">Elasticsearch 的职能和架构</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#elasticsearch暴露指标的方式" class="sidebar-link">Elasticsearch暴露指标的方式</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#获取节点统计信息" class="sidebar-link">获取节点统计信息</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#节点统计信息解读" class="sidebar-link">节点统计信息解读</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#elasticsearch-指标采集配置" class="sidebar-link">Elasticsearch 指标采集配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-15" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_17-组件监控-kubernetesnode组件的关键指标与数据采集" class="sidebar-link">17.组件监控-KubernetesNode组件的关键指标与数据采集</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#kubernetes架构" class="sidebar-link">Kubernetes架构</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控kube-proxy" class="sidebar-link">监控Kube-Proxy</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-配置采集规则" class="sidebar-link">1.配置采集规则</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-使用daemonset部署采集器" class="sidebar-link">2.使用Daemonset部署采集器</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-kube-proxy指标解释" class="sidebar-link">3.Kube-Proxy指标解释</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#监控kubelet" class="sidebar-link">监控Kubelet</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-引入认证信息" class="sidebar-link">1.引入认证信息</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-升级categraf-daemonset" class="sidebar-link">2.升级Categraf Daemonset</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-kubelet关键指标" class="sidebar-link">3.Kubelet关键指标</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-容器负载指标" class="sidebar-link">4.容器负载指标</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_1-cpu指标" class="sidebar-link">(1)CPU指标</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_2-内存指标" class="sidebar-link">(2)内存指标</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_3-pod网络流量" class="sidebar-link">(3)Pod网络流量</a></li><li class="sidebar-sub-header level6"><a href="/pages/3f3cf7/#_4-pod硬盘io读写流量" class="sidebar-link">(4)Pod硬盘IO读写流量</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-16" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_18-组件监控-kubernetes控制面组件的关键指标与数据采集" class="sidebar-link">18.组件监控-Kubernetes控制面组件的关键指标与数据采集</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#数据采集" class="sidebar-link">数据采集</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-创建认证信息" class="sidebar-link">1.创建认证信息</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-部署采集器" class="sidebar-link">2.部署采集器</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-修复controller-manager和scheduler" class="sidebar-link">3.修复Controller-manager和Scheduler</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-修复etcd" class="sidebar-link">4.修复etcd</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-修复ksm" class="sidebar-link">5.修复KSM</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#关键指标" class="sidebar-link">关键指标</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-apiserver" class="sidebar-link">1.APIServer</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-controller-manager" class="sidebar-link">2.Controller-manager</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_3-scheduler" class="sidebar-link">3.Scheduler</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_4-etcd" class="sidebar-link">4.etcd</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_5-ksm" class="sidebar-link">5.KSM</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-17" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_19-应用监控-如何使用埋点方式对应用监控" class="sidebar-link">19.应用监控-如何使用埋点方式对应用监控?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#埋点方式介绍" class="sidebar-link">埋点方式介绍</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#statsd" class="sidebar-link">StatsD</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#prometheus" class="sidebar-link">Prometheus</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#数据传输通路" class="sidebar-link">数据传输通路</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-18" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_20-应用监控-如何使用日志来监控应用" class="sidebar-link">20.应用监控-如何使用日志来监控应用?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#提取指标的典型做法" class="sidebar-link">提取指标的典型做法</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#快速上手mtail" class="sidebar-link">快速上手mtail</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#快速上手grok-exporter" class="sidebar-link">快速上手grok_exporter</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-19" class="sidebar-link">小结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#监控告警" class="sidebar-link">监控告警</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_21-事件管理-事件降噪的几个典型手段" class="sidebar-link">21.事件管理-事件降噪的几个典型手段</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警太多的常见原因" class="sidebar-link">告警太多的常见原因</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#优化告警规则" class="sidebar-link">优化告警规则</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_1-每个规则都应该对应具体的runbook" class="sidebar-link">1.每个规则都应该对应具体的Runbook</a></li><li class="sidebar-sub-header level5"><a href="/pages/3f3cf7/#_2-每个告警都应该合理分级" class="sidebar-link">2.每个告警都应该合理分级</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警规则支持生效时间的配置" class="sidebar-link">告警规则支持生效时间的配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警规则支持分级和不同的触达渠道" class="sidebar-link">告警规则支持分级和不同的触达渠道</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#重复告警支持最大次数和发送频率" class="sidebar-link">重复告警支持最大次数和发送频率</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警事件支持屏蔽配置" class="sidebar-link">告警事件支持屏蔽配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警事件支持抑制配置" class="sidebar-link">告警事件支持抑制配置</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警事件聚合发送逻辑" class="sidebar-link">告警事件聚合发送逻辑</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-20" class="sidebar-link">小结</a></li><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_22-事件管理-如何保证事件的闭环处理" class="sidebar-link">22.事件管理-如何保证事件的闭环处理?</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#排班-专人做专事" class="sidebar-link">排班,专人做专事</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警升级机制" class="sidebar-link">告警升级机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警收敛逻辑" class="sidebar-link">告警收敛逻辑</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#故障协同处理" class="sidebar-link">故障协同处理</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#告警自动处理" class="sidebar-link">告警自动处理</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#小结-21" class="sidebar-link">小结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/3f3cf7/#结束语" class="sidebar-link">结束语</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/3f3cf7/#_23-弱水三千-只取一瓢饮" class="sidebar-link">23.弱水三千,只取一瓢饮</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#术业有专攻" class="sidebar-link">术业有专攻</a></li><li class="sidebar-sub-header level4"><a href="/pages/3f3cf7/#成长讲求方法" class="sidebar-link">成长讲求方法</a></li></ul></li></ul></li><li><a href="/pages/e20e02/" class="sidebar-link">OAuth2.0实战课(极客时间)🌟</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-消息队列</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/96d94c/" class="sidebar-link">消息队列基础</a></li><li><a href="/pages/abf16c/" class="sidebar-link">RabbitMQ</a></li><li><a href="/pages/4fc3f1/" class="sidebar-link">Kafka</a></li><li><a href="/pages/013cfe/" class="sidebar-link">RocketMQ</a></li><li><a href="/pages/ed8d92/" class="sidebar-link">Disruptor</a></li><li><a href="/pages/249149/" class="sidebar-link">消息队列高手课(极客时间)🌟</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-缓存</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/946847/" class="sidebar-link">缓存基础</a></li><li><a href="/pages/e46d56/" class="sidebar-link">本地缓存</a></li><li><a href="/pages/0abfb9/" class="sidebar-link">Redis基础</a></li><li><a href="/pages/09236a/" class="sidebar-link">Redis持久化</a></li><li><a href="/pages/867f9b/" class="sidebar-link">Redis主从复制</a></li><li><a href="/pages/50cae1/" class="sidebar-link">Redis哨兵</a></li><li><a href="/pages/43b45c/" class="sidebar-link">Redis集群</a></li><li><a href="/pages/a32379/" class="sidebar-link">Redis内存管理与运维</a></li><li><a href="/pages/386037/" class="sidebar-link">Redis核心技术与实战(极客时间)🌸</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-其他</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/23044d/" class="sidebar-link">定时任务-XXLJob</a></li><li><a href="/pages/459117/" class="sidebar-link">ES与检索</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>系统设计与优化</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/41a845/" class="sidebar-link">凤凰架构</a></li><li><a href="/pages/68cc0b/" class="sidebar-link">左耳听风(极客时间)🌟</a></li><li><a href="/pages/e3e99c/" class="sidebar-link">从0开始学微服务(极客时间)🌸</a></li><li><a href="/pages/1e5368/" class="sidebar-link">高并发系统设计40问(极客时间)🌸</a></li><li><a href="/pages/33599f/" class="sidebar-link">系统性能调优必知必会(极客时间)🌸</a></li><li><a href="/pages/c83472/" class="sidebar-link">后端技术面试38讲(极客时间)</a></li><li><a href="/pages/4404b6/" class="sidebar-link">架构实战案例解析(极客时间)🌸</a></li><li><a href="/pages/8f1c1d/" class="sidebar-link">如何设计一个秒杀系统(极客时间)</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>容器</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading open"><span>容器</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/582acf/" class="sidebar-link">部署Minikube</a></li><li><a href="/pages/98e5e4/" class="sidebar-link">容器实战高手课(极客时间)🌸</a></li><li><a href="/pages/c6a42c/" class="sidebar-link">Kubernetes实战🌸</a></li><li><a href="/pages/f35c72/" class="sidebar-link">深入剖析Kubernetes(极客时间)🌸</a></li><li><a href="/pages/caa314/" class="sidebar-link">Istio</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>自动化运维</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/beb97f/" class="sidebar-link">持续集成(CICD)</a></li><li><a href="/pages/a0df2d/" class="sidebar-link">DevOps</a></li><li><a href="/pages/765815/" class="sidebar-link">SRE实战手册(极客时间)</a></li></ul></section></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06970110><div class="articleInfo" data-v-06970110><ul class="breadcrumbs" data-v-06970110><li data-v-06970110><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06970110></a></li> <li data-v-06970110><a href="/middleware/#系统" data-v-06970110>系统</a></li><li data-v-06970110><a href="/middleware/#系统" data-v-06970110>系统</a></li><li data-v-06970110><a href="/middleware/#服务治理-系统监控与安全" data-v-06970110>服务治理-系统监控与安全</a></li></ul> <div class="info" data-v-06970110><div title="作者" class="author iconfont icon-touxiang" data-v-06970110><a href="https://github.com/nanodaemony" target="_blank" title="作者" class="beLink" data-v-06970110>NanoDaemony</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06970110><a href="javascript:;" data-v-06970110>2025-02-26</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">本文目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">运维监控系统实战(极客时间)🌸<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="_411-运维监控系统实战-极客时间-🌸"><a href="#_411-运维监控系统实战-极客时间-🌸" class="header-anchor">#</a> 411.运维监控系统实战(极客时间)🌸</h1> <h2 id="开篇词"><a href="#开篇词" class="header-anchor">#</a> 开篇词</h2> <h3 id="_0-每个关注高可用的人-都应该了解监控知识"><a href="#_0-每个关注高可用的人-都应该了解监控知识" class="header-anchor">#</a> 0.每个关注高可用的人,都应该了解监控知识</h3> <p>现在 ** Prometheus 生态随着 Kubernetes 的流行, 已成为云原生监控事实上的标准**.</p> <p>Categraf 则是一款监控数据采集器, 是类似 Telegraf, Datadog-agent, Grafana-agent 的一个 Agent, 可以采集 metrics, logs, traces, 尝试做一个大一统的采集解决方案, 同时希望在项目里沉淀出各个监控目标的最佳实践, 做到开箱即用.</p> <p>线上经常有各种监控问题. 比如:</p> <ul><li>指标有哪些类型, 哪类指标比较关键?</li> <li>如何部署一套高可用的监控系统, 存储应该如何选型?</li> <li>如何监控 MySQL, Redis, Kafka, ElasticSearch?</li> <li>如何监控 Kubernetes 这么复杂的平台?</li> <li>如何埋点, 如何分析日志?</li> <li>如何做到事件闭环和告警自愈?</li> <li>...</li></ul> <p>提问的这些人当中, 大部分是运维工程师, 业务研发, 还有监控和稳定性系统建设人员, 对他们来说运维监控相关的知识是工作中必不可少的一部分. 那是不是其他领域的人就没必要了解监控相关的知识了呢? 不是的.</p> <h4 id="哪些人应该学习监控相关的知识"><a href="#哪些人应该学习监控相关的知识" class="header-anchor">#</a> 哪些人应该学习监控相关的知识?</h4> <p>应该说每个关注高可用, 关注服务稳定性的技术人员都应该学习监控相关的知识. 在稳定性保障体系中, 核心就是在干一件事, 减少故障. 可以看一下故障的生命周期.</p> <p><img src="/img/5a01b06a48274f14eb39e0e483ee98e2-20230719203435-gyb1raf.png" alt="图片"></p> <p>减少故障有两个层面的意思, 一个是做好常态预防, 不让故障发生; 另一个是如果故障发生, 要能尽快止损, 减少故障时长. 而监控的典型作用, 就是帮助我们<strong>发现及定位故障</strong>, 这两个环节对于减少故障时长至关重要.</p> <p>运维人员和研发人员是典型的关注稳定性的人, 不过侧重点不同. 一般来说, 运维人员负责全公司所有业务的运维工作, 研发人员只负责自己业务线的研发工作, 所以发生故障的时候, 运维人员更希望快速找到问题根因, 及时止损. 而研发人员, 更希望能 &quot;自证清白&quot;. 不管出于何种目的, 监控都是不可或缺的工具.</p> <p>当然监控的作用还有很多, 比如用于日常巡检, 作为性能调优的数据佐证, 提前发现一些设备, 中间件不合理的配置. 之所以能做到这些, 是因为所有优秀的软件, 都内置了监控数据的暴露方法, 让用户可以对其进行观测, 了解其健康状况. **可被监控和观测, 也是开发软件时必须考虑的一环. **</p> <h4 id="监控是做好软件架构的重要一环"><a href="#监控是做好软件架构的重要一环" class="header-anchor">#</a> 监控是做好软件架构的重要一环</h4> <p>好的软件架构, 一定是考虑了高可用的, 一定是考虑了各类故障的发现和应对手段的. 一名合格的架构师, 理应对各种监控手段都熟稔于心.</p> <p><img src="/img/e6273f4cc906de0a1e9f3c62951b2e41-20230719203435-tca9q4t.png" alt=""></p> <p><strong>比如各类开源组件, 有的是直接暴露了 Prometheus metrics 接口, 有的是暴露了 HTTP JSON 接口, 有的是通过 JMX 暴露监控数据, 有的则需要连上去执行命令, 虽然大家的指标暴露方式不一样, 但没有哪个是缺少监控能力的.</strong></p> <p><strong>业务程序也有多种暴露方式</strong>, 比较知名的埋点工具是 StatsD, <strong>Prometheus</strong>. 当然有些语言会有适合自己的更易用的埋点工具, 比如 Java 生态的 Micrometer. 业务程序除了指标埋点监控, 通常还有更丰富的观测手段, 比如引入链路追踪的框架: Zipkin, Jaeger, <strong>Skywalking</strong> 等. 当然所有软件都可以使用日志的方式来暴露健康状况, 不过这种方式最昂贵, 数据非结构化, 适合排查问题, 但不适合作为指标数据的来源.</p> <p><strong>想要在技术这条路上走得更远, 监控相关的知识必不可少</strong>.</p> <h4 id="这门课的结构"><a href="#这门课的结构" class="header-anchor">#</a> 这门课的结构</h4> <p>本课程分成了 4 个部分.</p> <p><img src="/img/4976be7b4ce5737515539f4a3824yycb-20230719203435-ddsglqb.jpg" alt=""></p> <blockquote><p>第一部分: 基础知识</p></blockquote> <p>学习监控知识, 得先了解为什么, 也就是监控是因何产生的, 解决了什么问题, 有哪些典型的方案, 分别有什么优缺点. 最后会给总结通用的监控系统架构, 提前打好铺垫, 为后面的学习奠定理论基础.</p> <blockquote><p>第二部分: 搭建并优化 Prometheus</p></blockquote> <p>了解了基础知识之后, 就需要动手实践. 第二部分会搭建 Prometheus 这个监控系统, 对监控系统有一个感性的认识. 为什么选择 Prometheus 而不是其他监控系统, 最核心的原因是 Prometheus 在当下云原生的环境下真的太流行了, 其次是 Prometheus 搭建简单, 使用灵活, 体现了很多设计哲学, 有助于理解监控系统的相关设计.</p> <p>这个部分还会剖析 Prometheus 的一些关键设计, 就是这些关键设计奠定了它的江湖地位. 但是 Prometheus 也不是尽善尽美的, 真正在生产环境下使用, 还需要解决存储扩展问题, 规则管理的协同问题, 对此社区有一些解决方案, 会一起比较选型.</p> <blockquote><p>第三部分: 监控实战, 搞定常见的监控需求</p></blockquote> <p>操作系统, 网络设备, MySQL, Redis, Kafka, ElasticSearch, Kubernetes, 应用, 日志等等, 所有常见监控的需求统统搞定, 这部分会讲解各个监控目标是如何采集监控数据的, 哪些指标最关键. 中间穿插一些问题排查手段, 并提供配置好的仪表盘, 在开箱即用的同时, 知其然并知其所以然.</p> <blockquote><p>第四部分: 告警实战, 设计良好的告警系统应该具备哪些能力</p></blockquote> <p>监控数据采集上来之后, 下一步就是要甄别异常数据并发出告警了. 这个部分包括<strong>告警规则, 屏蔽规则, 抑制规则, 订阅规则的管理, 还有告警事件的管理以及告警事件触发后的自愈逻辑</strong>. 一般监控系统都支持配置告警规则, 可以产生告警事件, 但是针对告警事件后续的支持偏弱, 没有很好的聚合收敛, 事件闭环的能力.</p> <h2 id="监控概述"><a href="#监控概述" class="header-anchor">#</a> 监控概述</h2> <h3 id="_1-背景信息-监控需求以及开源方案的横评对比"><a href="#_1-背景信息-监控需求以及开源方案的横评对比" class="header-anchor">#</a> 1.背景信息-监控需求以及开源方案的横评对比</h3> <p>本节先了解一下监控相关的背景信息, 对监控系统有一个整体性的了解. 所以这里会先聊一聊监控的需求来源, 也就是说监控系统都可以用来做什么, 然后再跳出监控, 从可观测性来看, 监控与日志, 链路之间的关系以及它们各自的作用. 最后会介绍开源社区几个有代表性的方案以及它们各自的优缺点, 便于做技术选型.</p> <h4 id="监控需求来源"><a href="#监控需求来源" class="header-anchor">#</a> 监控需求来源</h4> <p>监控最初始的需求, 其实就是一句话: <strong>系统出问题了能及时感知到</strong>. 随着时代的发展, 大家对监控系统提出了更多的诉求, 比如:</p> <ul><li>通过监控了解数据趋势, 知道系统在未来的某个时刻可能出问题, 预知问题.</li> <li>通过监控了解系统的水位情况, 为服务扩缩容提供数据支撑.</li> <li>通过监控来给系统把脉, 感知到哪里需要优化, 比如一些中间件参数的调优.</li> <li>通过监控来洞察业务, 提供业务决策的数据依据, 及时感知业务异常.</li></ul> <p>目前监控系统越来越重要, 同时也越来越完备. 不但能够很好地解决上面这几点诉求, 还沉淀出了很多监控系统中的稳定性相关的知识.</p> <h4 id="可观测性三大支柱"><a href="#可观测性三大支柱" class="header-anchor">#</a> 可观测性三大支柱</h4> <h5 id="_1-指标监控"><a href="#_1-指标监控" class="header-anchor">#</a> 1.指标监控</h5> <p>监控系统一般只是<strong>指标监控</strong>, 通常使用折线图形态呈现在图表上, 比如某个机器的 CPU 利用率, 某个数据库实例的流量或者网站的在线人数, 都可以体现为随着时间而变化的趋势图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/44623a474780c33b25b04398a5a4cc3f.png" alt="图片"></p> <p><mark><strong>指标监控</strong></mark> 只能处理数字, 但它的<strong>历史数据存储成本较低, 实时性好, 生态庞大</strong>, 是可观测性领域里最重要的一根支柱. 聚焦在<strong>指标监控</strong>领域的开源产品有 Zabbix, Open-Falcon, <strong>Prometheus</strong>, Nightingale 等.</p> <p>由于指标监控因历史数据存储成本较低, 实时性好, 生态庞大, 是可观测性领域里最重要的一根支柱, 也是我们关注的重点.</p> <h5 id="_2-日志"><a href="#_2-日志" class="header-anchor">#</a> 2.日志</h5> <p>除了指标监控, 另一个重要的可观测性支柱是 <mark><strong>日志</strong></mark>. 从日志中可以得到很多信息, 对于了解软件的运行情况, 业务的运营情况都很关键. 比如操作系统的日志, 接入层的日志, 服务运行日志, 都是重要的数据源.</p> <p>从操作系统的日志中, 可以得知很多系统级事件的发生; 从接入层的日志中, 可以得知有哪些域名, IP, URL 收到了访问, 是否成功以及延迟情况等; 从服务日志中可以查到 Exception 的信息, 调用堆栈等, 对于排查问题来说非常关键. 但是<strong>日志数据通常量比较大, 不够结构化, 存储成本较高</strong>.</p> <p>处理日志这个场景, 也有很多专门的系统, 比如开源产品 ELK 和 Loki, 商业产品 Splunk 和 Datadog, 下面是在 Kibana 中查询日志的一个页面.</p> <p><img src="/img/1ff853edd518a6f1bf5f2a038ff9a99c-20230719203435-zqqxcdi.png" alt="图片"></p> <h5 id="_3-链路追踪"><a href="#_3-链路追踪" class="header-anchor">#</a> 3.链路追踪</h5> <p>可观测性最后一大支柱是 <mark><strong>链路追踪</strong></mark>. 随着微服务的普及, 原本的单体应用被拆分成很多个小的服务, 服务之间有错综复杂的调用关系, 一个问题具体是哪个模块导致的, 排查起来其实非常困难.</p> <p><strong>链路追踪的思路是以请求串联上下游模块, 为每个请求生成一个随机字符串作为请求 ID. 服务之间互相调用的时候, 把这个 ID 逐层往下传递, 每层分别耗费了多长时间, 是否正常处理, 都可以收集起来附到这个请求 ID 上. 后面追查问题时, 拿着请求 ID 就可以把串联的所有信息提取出来</strong>. 链路追踪这个领域也有很多产品, 比如 <strong>Skywalking</strong>, Jaeger, Zipkin 等. 下面是 Zipkin 的一个页面.</p> <p><img src="/img/019923edea67c1363ba080dc129a3594-20230719203435-zarxgto.png" alt="图片"></p> <p>虽然把<strong>可观测性领域划分成了 3 大支柱</strong>, 但实际上它们之间是有很强的关联关系的. 比如经常会从日志中提取指标, 转存到指标监控系统, 或者从日志中提取链路信息来做分析, 这在业界都有很多实践.</p> <p>下面就来一起梳理一下业界常见的开源解决方案.</p> <h4 id="业界方案横评"><a href="#业界方案横评" class="header-anchor">#</a> 业界方案横评</h4> <p>了解业界典型方案的一些优缺点, 对选型有很大帮助. 这里主要是评价开源方案, 商业产品接触的人相对较少, 这里就不点评了.</p> <h5 id="_1-老一代整体方案的代表zabbix"><a href="#_1-老一代整体方案的代表zabbix" class="header-anchor">#</a> 1.老一代整体方案的代表Zabbix</h5> <p>Zabbix 是一个企业级的开源解决方案, 擅长设备, 网络, 中间件的监控. 因为前几年使用的监控系统主要就是用来监控设备和中间件的, 所以 Zabbix 在国内应用非常广泛.</p> <p>Zabbix 核心由两部分构成, Zabbix Server 与可选组件 Zabbix Agent. Zabbix Server 可以通过 SNMP, Zabbix Agent, JMX, IPMI 等多种方式采集数据. Zabbix 还有一些配套组件, Zabbix Proxy, Zabbix Java Gateway, Zabbix Get, Zabbix WEB 等, 共同组成了 Zabbix 整体架构.</p> <p><img src="/img/078c1b5f6d0d0382d742fb4049feff6d-20230719203435-n8frk7p.png" alt=""></p> <p><strong>Zabbix的优点</strong></p> <ul><li>对各种设备的兼容性较好, Agentd 可以在 Windows, Linux上运行.</li> <li>架构简单, 使用数据库做时序数据存储, 易于维护, 备份和转储都比较容易.</li> <li>社区庞大, 资料多.</li></ul> <p><strong>Zabbix的缺点</strong></p> <ul><li><strong>使用数据库做存储</strong>, 无法水平扩展, 容量有限. 如果采集频率较高, 比如 10 秒采集一次, 上限大约可以监控 600 台设备, 还需要把数据库部署在一个很高配的机器上, 比如 SSD 或者 NVMe 的盘才可以.</li> <li>Zabbix 面向资产的管理逻辑, 监控指标的数据结构较为固化, 没有灵活的标签设计, <strong>面对云原生架构下动态多变的环境, 显得力不从心</strong>.</li></ul> <h5 id="_2-老一代国产代表open-falcon"><a href="#_2-老一代国产代表open-falcon" class="header-anchor">#</a> 2.老一代国产代表Open-Falcon</h5> <p>Open-Falcon 出现在 Zabbix 之后, 开发的初衷就是想要解决 Zabbix 的容量问题. Open-Falcon 最初来自小米, Open-Falcon的初衷是想做一套大一统的方案, 来解决这个乱局. 可以看一下Open-Falcon的架构图.</p> <p><img src="/img/faf28d6c6409936a0300a36d914f4f84-20230719203435-23329d2.png" alt="图片"></p> <p>Open-Falcon 基于 RRDtool 做了一个分布式时序存储组件 Graph. 这种做法可以把多台机器组成一个集群, 大幅提升海量数据的处理能力. 前面负责转发的组件是 Transfer, Transfer 对监控数据求取一个唯一 ID, 再对 ID 做哈希, 就可以生成监控数据和 Graph 实例的对应关系, 这就是 Open-Falcon 架构中最核心的分片逻辑.</p> <p>结合给出的架构图来看, 告警部分是使用 Judge 模块来做的, 发送告警事件的是 Alarm 模块, 采集数据的是 Agent, 负责心跳的模块是 HBS, 负责聚合监控数据的模块是 Aggregator, 负责处理数据缺失的模块是 Nodata. 当然还有用于和用户交互的 Portal/Dashboard 模块.</p> <p>Open-Falcon 把组件拆得比较散, 组件比较多, 部署起来相对比较麻烦. 不过每个组件的职能单一, 二次开发会比较容易, 很多互联网公司都是基于 Open-Falcon 做了二次开发, 比如美团, 新浪微博, 爱奇艺等.</p> <p><strong>Open-Falcon的优点</strong></p> <ul><li>可以处理大规模监控场景, 比 Zabbix 的容量要大得多, 不仅可以处理设备, 中间件层面的监控, 也可以处理应用层面的监控.</li> <li>组件拆分得比较散, 大都是用 Go 语言开发的, Web 部分是用 Python, 易于做二次开发.</li></ul> <p><strong>Open-Falcon的缺点</strong></p> <ul><li>生态不够庞大, 有一些贡献者, 但数量相对较少.</li> <li>开源软件的治理架构不够优秀, 小米公司的核心开发人员离职, 项目就停滞不前了, 缺少了生命力.</li></ul> <h5 id="_3-新一代整体方案代表prometheus"><a href="#_3-新一代整体方案代表prometheus" class="header-anchor">#</a> 3.新一代整体方案代表Prometheus</h5> <p>Prometheus 的设计思路来自 Google 的 Borgmon, <strong>而 Prometheus 就是为 Kubernetes 而生的. 它针对 Kubernetes 做了直接的支持, 提供了多种服务发现机制, 大幅简化了 Kubernetes 的监控</strong>.</p> <p>在 Kubernetes 环境下, Pod 创建和销毁非常频繁, 监控指标生命周期大幅缩短, 这导致类似 Zabbix 这种面向资产的监控系统力不从心, 而且云原生环境下大都是微服务设计, 服务数量变多, 指标量也呈爆炸态势, 这就对时序数据存储提出了非常高的要求.</p> <p>Prometheus 1.0 从 2.0 开始重新设计了时序库, 性能, 可靠性都有大幅提升, 另外社区涌现了越来越多的 Exporter 采集器, 非常繁荣. 可以看一下 Prometheus 的架构图.</p> <p><img src="/img/e679ea2310fd68aa7391b018382c3d13-20230719203435-oida9z0.png" alt="图片"></p> <p><strong>Prometheus的优点</strong></p> <ul><li>对 Kubernetes 支持得很好, 目前来看, Prometheus 就是 Kubernetes 监控的标配.</li> <li>生态庞大, 有各种各样的 Exporter, 支持各种各样的时序库作为后端的 Backend 存储, 也有很好的支持多种不同语言的 SDK, 供业务代码嵌入埋点.</li></ul> <p><strong>Prometheus的缺点</strong></p> <ul><li>易用性差一些, 比如告警策略需要修改配置文件, 协同起来比较麻烦. 当然了, 对于 IaC 落地较好的公司, 反而认为这样更好, 不过在国内当下的环境来看, 还无法走得这么靠前, 大家还是更喜欢用 Web 界面来查看监控数据, 管理告警规则.</li> <li>Exporter 参差不齐, 通常是一个监控目标一个 Exporter, 管理起来成本比较高.</li> <li>容量问题, Prometheus 默认只提供单机时序库, 集群方案需要依赖其他的时序库.</li></ul> <h5 id="_4-新一代国产代表-nightingale"><a href="#_4-新一代国产代表-nightingale" class="header-anchor">#</a> 4.新一代国产代表 Nightingale</h5> <p>Nightingale 可以看做是 Open-Falcon 的一个延续, 因为开发人员是一拨人, 不过两个软件的定位截然不同, Open-Falcon 类似 Zabbix, 更多的是面向机器设备, 而 Nightingale 不止解决设备和中间件的监控, 也希望能一并解决<strong>云原生</strong>环境下的监控问题.</p> <p>但是在 Kubernetes 环境下, Prometheus 已经大行其道, 再重复造轮子意义不大, 所以 <strong>Nightingale 的做法是和 Prometheus 做良好的整合, 打造一个更完备的方案</strong>. 当下的架构, 主要是把 Prometheus 当成一个<strong>时序库</strong>, 作为 Nightingale 的一个数据源. 如果不使用 Prometheus 也没问题, 比如使用 VictoriaMetrics 作为时序库, 也是很多公司的选择.</p> <p><img src="/img/c9236a33aba494eb22e9f068efafe791-20230719203435-7fj8xzu.png" alt="图片"></p> <p><strong>Nightingale的优点</strong></p> <ul><li>有比较完备的 UI, 有权限控制, 产品功能比较完备, 可以作为公司级统一的监控产品让所有团队共同使用. Prometheus 一般是每个团队自己用自己的, 比较方便. 如果一个公司用同一套 Prometheus 系统来解决监控需求会比较麻烦, 容易出现上面说的协同问题, 而 Nightingale 在协同方面做得相对好一些.</li> <li>兼容并包, 设计上比较开放, 支持对接 Categraf, Telegraf, Grafana-Agent, Datadog-Agent 等采集器, 还有 Prometheus 生态的各种 Exporter, 时序库支持对接 Prometheus, VictoriaMetrics, M3DB, Thanos 等.</li></ul> <p><strong>Nightingale的缺点</strong></p> <ul><li>考虑到机房网络割裂问题, 告警引擎单独拆出一个模块下沉部署到各个机房, 但是很多中小公司无需这么复杂的架构, 部署维护起来比较麻烦.</li> <li>告警事件发送缺少聚合降噪收敛逻辑, 官方的解释是未来会单独做一个事件中心的产品, 支持 Nightingale, Zabbix, Prometheus 等多种数据源的告警事件, 但目前还没有放出.</li></ul> <p><strong>上面介绍了几种典型方案, 每种方案各有优缺点, 如果主要需求是监控设备, 推荐使用 Zabbix; 如果主要需求是监控 Kubernetes, 可以选择 Prometheus+Grafana; 如果既要兼顾传统设备, 中间件监控场景, 又要兼顾 Kubernetes, 做成公司级方案, 推荐你使用 Nightingale.</strong></p> <h5 id="_5-对比"><a href="#_5-对比" class="header-anchor">#</a> 5.对比</h5> <p>最后对指标监控领域的多个开源解决方案做了横评对比, 帮助你做技术方案的选型. 针对指标监控的几个开源方案的优缺点比较.</p> <p><img src="/img/cb513a55f60ed2c684b06639bafda446-20230719203435-pcy0w1s.jpg" alt=""></p> <h3 id="_2-基本概念-监控圈子有哪些行业黑话"><a href="#_2-基本概念-监控圈子有哪些行业黑话" class="header-anchor">#</a> 2.基本概念-监控圈子有哪些行业黑话?</h3> <p>本节继续学习监控的相关概念, 包括监控, 监控指标, 指标类型, 时序库, 还有告警收敛与闭环等. 理清监控圈子的这些常用术语之后, 学习起来会更轻松一些.</p> <p>监控这个词在不同的上下文中含义会有一些区别, 一般说监控 MySQL, 监控 Redis 的时候, 都是指能够采集到 MySQL, Redis 的监控数据, 并能可视化展示. 这时候监控表示数据采集和可视化, 不包括告警引擎和事件处理. 但当讲监控系统的时候, 因为说的是整个系统, 所以也会包含告警和事件发送等相关功能.</p> <p>监控体系中最基础的是监控指标, <strong>监控系统就是围绕指标的采集, 传输, 存储, 分析, 可视化的一个系统</strong>, 下面就从监控指标这个概念讲起.</p> <h4 id="监控指标"><a href="#监控指标" class="header-anchor">#</a> 监控指标</h4> <p><strong>监控指标是指数值类型的监控数据</strong>, 比如某个机器的内存利用率, 某个 MySQL 实例的当前连接数, 某个 Redis 的最大内存上限等等. 不同的监控系统, 对于监控指标有不同的描述方式, 典型的方式有三种, 下面分别介绍一下.</p> <h5 id="_1-全局唯一字符串作为指标标识"><a href="#_1-全局唯一字符串作为指标标识" class="header-anchor">#</a> 1.全局唯一字符串作为指标标识</h5> <p><strong>监控指标通常是一个全局唯一的字符串</strong>, 比如某机器的内存利用率  host.10.2.3.4.mem_used_percent, 这个字符串中包含了机器的信息, 也包含了指标名, 可以唯一标识一条监控指标. 假设监控数据采集的频率是 30 秒, 2 分钟内采集了 4 个数据点, 一个数据点包含一个时间戳和一个值, 可以用 JSON 表示这个监控指标及其监控数据.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;host.10.2.3.4.mem_used_percent&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;points&quot;</span><span class="token operator">:</span><span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;clock&quot;</span><span class="token operator">:</span><span class="token number">1662449136</span><span class="token punctuation">,</span>
            <span class="token property">&quot;value&quot;</span><span class="token operator">:</span><span class="token number">45.4</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;clock&quot;</span><span class="token operator">:</span><span class="token number">1662449166</span><span class="token punctuation">,</span>
            <span class="token property">&quot;value&quot;</span><span class="token operator">:</span><span class="token number">43.2</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;clock&quot;</span><span class="token operator">:</span><span class="token number">1662449196</span><span class="token punctuation">,</span>
            <span class="token property">&quot;value&quot;</span><span class="token operator">:</span><span class="token number">44.9</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;clock&quot;</span><span class="token operator">:</span><span class="token number">1662449226</span><span class="token punctuation">,</span>
            <span class="token property">&quot;value&quot;</span><span class="token operator">:</span><span class="token number">44.8</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>相对老一些的监控系统, 比如 Graphite, 就是使用这种方式来标识监控指标的. 一些老的监控数据采集器, 比如 Collectd, 也是这样标识监控指标的.</p> <p>虽然这种方式一目了然, 非常清晰, 但是<strong>缺少对维度信息的描述, 不便于做聚合计算</strong>. 比如下面几条用于描述 HTTP 请求状态码的指标.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>myhost.service1.http_request.200.get
myhost.service1.http_request.200.post
myhost.service1.http_request.500.get
myhost.service1.http_request.500.post
myhost.service2.http_request.200.get
myhost.service2.http_request.500.post

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>myhost 这个机器上部署了两个服务, 分别是 service1 和 service2. 有些请求状态码是 200, 有些是 500, 有些 HTTP method 是 get, 有些是 post. <strong>如果想分别统计这些指标的数量, 就要把这些分类维度信息都拼到指标标识中. 但是这样做会产生两个弊端: 一是看起来比较混乱, 二是不方便聚合统计</strong>.</p> <p>举个例子, 比如想计算 service1 这个服务的成功率, 要把 service1 里所有状态码为 200 的请求数量拿到, 除以 service1 所有请求的数量. 如果预先知道所有状态码, 所有 HTTP method, 则可以枚举指标名称, 拉取监控数据. 如果<strong>不知道所有状态码和 HTTP method, 就要先用正则匹配指标标识, 查询出指标列表再拉取监控数据做计算, 处理起来非常麻烦</strong>.</p> <p>其实这是用马后炮视角解释这个问题的, 实际上, 在 Graphite, Collectd, Zabbix 这些软件盛行的时代, 这个问题并不明显. 因为那个时代主要关注的是机器设备, 数据库, 中间件的监控, 不会有很多维度的信息. <strong>直到业界开始关注应用层面监控的时候, 才暴露出这个问题</strong>.</p> <h5 id="_2-标签集的组合作为指标标识"><a href="#_2-标签集的组合作为指标标识" class="header-anchor">#</a> 2.标签集的组合作为指标标识</h5> <p>2010 年左右, 有一款名叫 <a href="http://opentsdb.net/" target="_blank" rel="noopener noreferrer">OpenTSDB<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 的时序数据库诞生了. 虽然现在已经较少使用了, 但是 OpenTSDB 描述指标的方式, 对业界有很大影响. 下面是通过文本协议推给 OpenTSDB 的数据示例, 可以从中看出指标标识的定义方式.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>mysql.bytes_received 1287333217 327810227706 schema=foo host=db1
mysql.bytes_sent 1287333217 6604859181710 schema=foo host=db1
mysql.bytes_received 1287333232 327812421706 schema=foo host=db1
mysql.bytes_sent 1287333232 6604901075387 schema=foo host=db1
mysql.bytes_received 1287333321 340899533915 schema=foo host=db2
mysql.bytes_sent 1287333321 5506469130707 schema=foo host=db2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>上面这 6 条监控指标, <strong>都通过空格把指标分隔成了多个字段. 第一段是指标名, 第二段是时间戳(单位是秒), 第三段是指标值, 剩下的部分是多个标签(tags/labels), 每个标签都是 key=value 的格式, 多个标签之间使用空格分隔</strong>.</p> <p>除了 OpenTSDB, 新时代的时序库大都引入了<mark><strong>标签</strong></mark>的概念, 比如 Prometheus, 它们甚至认为指标名也是一种特殊的标签(其标签 key 是 __name__ ), 所以 <mark><strong>Prometheus 仅仅使用标签集作为指标标识</strong></mark>, 从 Prometheus 的数据结构定义中就可以看出来.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>message Sample {
  double value    = 1;
  int64 timestamp = 2;
}

message Label {
  string name  = 1;
  string value = 2;
}

message TimeSeries {
  repeated Label labels   = 1 [(gogoproto.nullable) = false];
  repeated Sample samples = 2 [(gogoproto.nullable) = false];
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>TimeSeries 这个结构中并没有一个单独的 metric 字段, 指标名的信息实际是放到了  labels 数组中了.</p> <h5 id="_3-优雅高效的influx指标格式"><a href="#_3-优雅高效的influx指标格式" class="header-anchor">#</a> 3.优雅高效的Influx指标格式</h5> <p>InfluxData 公司有一款开源时序库非常有名, 叫 <a href="https://www.influxdata.com/" target="_blank" rel="noopener noreferrer">InfluxDB<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, InfluxDB 在接收监控数据写入时, 设计了一个非常精巧的指标格式, 一行可以传输多个指标.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>mesurement,labelkey1=labelval1,labelkey2=labelval2 field1=1.2,field2=2.3 timestamp
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>总体来看, 分为 4 个部分, <strong>measurement, tag_set field_set timestamp</strong>, 其中 tag_set 是可选的, tag_set 与前面的 measurement 之间用<strong>逗号</strong>分隔, 其他各个部分之间都是用<strong>空格</strong>来分隔的. 可以通过下面的例子来理解.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>weather,location=us-midwest temperature=82 1465839830100400200
  |    -------------------- --------------  |
  |             |             |             |
  |             |             |             |
+-----------+--------+-+---------+-+---------+
|measurement|,tag_set| |field_set| |timestamp|
+-----------+--------+-+---------+-+---------+
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>把上面 OpenTSDB 的指标示例改写成 Influx 格式, 结果是这样的.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>mysql,schema=foo,host=db1 bytes_received=327810227706,bytes_sent=6604859181710 1287333217000000000
mysql,schema=foo,host=db1 bytes_received=327812421706,bytes_sent=6604901075387 1287333232000000000
mysql,schema=foo,host=db2 bytes_received=340899533915,bytes_sent=5506469130707 1287333321000000000
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>注意, 时间戳的单位是纳秒. <strong>这种写法设计很精巧, 标签重复度低, field 越多的情况下它的优势越明显, 网络传输的时候可以节省更多带宽</strong>. 当然了, OpenTSDB 的格式或者 Prometheus 的格式如果做了数据压缩, 节省带宽的效果也是不错的, 因为字符的压缩效果一般比较明显. 现如今机房内部通信动辄万兆网卡, 这个流量的大小区别倒也不用太关注.</p> <p><img src="/img/ee5a62f16cb36b57cf560c1b00e41822-20230719203435-tq4c6ha.png" alt="图片"></p> <p>监控指标的概念非常重要, 可以说监控系统中的一切都是围绕监控指标来的, 所以用了大量篇幅来解释监控指标, 还讲解了几种不同指标的描述方式. 除了这些描述方式之外, <strong>监控指标还分为各种不同的类型</strong>, 下面一起来看一下.</p> <h4 id="指标类型"><a href="#指标类型" class="header-anchor">#</a> 指标类型</h4> <p>有些监控系统是不区分指标类型的, 有些会做区分. 90 年代出现了 <a href="https://oss.oetiker.ch/rrdtool/" target="_blank" rel="noopener noreferrer">RRDtool<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 它是一个环形数据库, 也是一个绘图引擎, 很多监控工具都是使用 RRDtool 来存储或绘制监控趋势图的, 比如 Cacti, MRTG, Zabbix 等等. RRDtool 还提出了数据类型的概念, 支持GAUGE, COUNTER, DERIVE, DCOUNTER, DDERIVE, ABSOLUTE 等多种数据类型.</p> <p><strong>Prometheus 生态也支持数据类型, 分为 Gauge, Counter, Histogram, Summary 4 种, 下面简单了解一下 Prometheus 的这 4 种类型.</strong></p> <h5 id="_1-gauge"><a href="#_1-gauge" class="header-anchor">#</a> 1.Gauge</h5> <p><mark><strong>测量值类型, 可大可小, 可正可负</strong></mark>. 这种类型的数据, 通常关注的是 <mark><strong>当前值</strong></mark>, 比如房间里的人数, 队列积压的消息数, 今年公司的收入和净利润.</p> <h5 id="_2-counter"><a href="#_2-counter" class="header-anchor">#</a> 2.Counter</h5> <p><mark>表示</mark>​<mark><strong>单调递增的值</strong></mark>, 比如操作系统自启动以来网卡接收到的所有流量包的数量. 每接收到一个包, 操作系统就会加 1, 所以这个值是持续递增的. 但是操作系统可能会重启, 导致这个值出现重置, 比如第一次是从 0 一直涨到了 239423423, 然后机器重启, 新采集的数据是一些比 239423423 小很多的值, 这种情况怎么办? 此时 Prometheus 看到值没有递增, 就能感知到重置的情况, 会把新采集的值加上 239423423 再做计算.</p> <h5 id="_3-histogram"><a href="#_3-histogram" class="header-anchor">#</a> 3.Histogram</h5> <p><mark>直方图类型, 用于</mark>​<mark><strong>描述数据分布</strong></mark>​<mark>, 最典型的应用场景就是监控延迟数据</mark>, 计算 90 分位, 99 分位的值. 所谓的分位值, 就是把一批数据从小到大排序, 然后取 X% 位置的数据, 90 分位就是指样本数据第 90% 位置的值.</p> <p>有些服务访问量很高, 每秒几百万次, 如果要把所有请求的延迟数据全部拿到, 排序之后再计算分位值, 这个代价就太高了. 使用 Histogram 类型, 可以用较小的代价计算一个大概值. 当然不是特别准确, 但是在监控场景足够用了, 监控毕竟只是一个采样的系统, 对数据准确性要求没有那么高.</p> <p><strong>Histogram 的做法是根据数据的 value 范围, 规划多个桶(bucket), 把样本数据点放入不同的桶来统计</strong>. 比如有个服务 service1, 它的接口延迟最小的通常在一两百毫秒, 最大的通常在 1 秒, 如果超过 3 秒, 大概率就是系统不正常了. 此时可以规划 4 个桶, 假设有 1000 个请求, 来看下各个桶和对应的样本统计值.</p> <p><img src="/img/f0a3eca509ac8bebcdb07685c4ba3d28-20230719203435-fm80l2y.png" alt=""></p> <ul><li>延迟小于 200 毫秒的, 有 600 个请求落到了这个区间.</li> <li>延迟小于 1 秒的, 有 850 个请求落到了这个区间, 其中大于 200 毫秒的有 250 个请求.</li> <li>延迟小于 3 秒的, 有 1000 个请求落到了这个区间, 其中大于 1 秒的有 150 个请求.</li> <li>延迟小于正无穷的, 也就是总量, 有 1000 个请求落到了这个区间, 说明没有大于 3 秒的请求.</li></ul> <p>现在来计算 90 分位值, 也就是第 900 个请求, 说明这个值落到了第 3 个桶, 延迟小于 3 秒的桶, 于是可以得出结论, 90 分位的延迟大小是 1~3 秒之间.</p> <p>虽然知道了<strong>区间范围</strong>, 但是还无法得出具体的值. **为了计算出具体的值, Prometheus 有个假设, **​<mark><strong>它认为各个桶里的样本数据是均匀分布的</strong></mark>, 即第三个桶的这 150 个请求, 延迟最小的请求恰好延迟了 1 秒, 延迟最大的恰好延迟了 3 秒, 总量的第 900 个请求, 是这个桶里的第 50 个请求, 最终 90 分位的延迟数据计算方法是:</p> <p>$$
(3-1)\times(50\div150)+1=1.67 秒
$$</p> <p><img src="/img/0bb6b97835f11ae512517eb2040df30f-20230719203435-er0mzxj.png" alt=""></p> <p>这就是 <strong>histogram_quantile</strong> 的计算方法. histogram_quantile 是 Prometheus 的一个函数, 这里为了说明 Histogram 类型, 提前讲一下这个函数的计算逻辑.</p> <p>虽然 Histogram 这种做法相比于把所有请求延迟数据都存储起来再计算延迟, 性能有了巨大的提升, 但是要同时计算成千上万个接口的分位值延迟数据, 还是非常耗费资源的, 甚至会造成服务端 OOM. 于是就有了 <strong>Summary</strong> 类型.</p> <h5 id="_4-summary"><a href="#_4-summary" class="header-anchor">#</a> 4.Summary</h5> <p><mark>Summary 这种类型是 </mark>​<mark><strong>在客户端计算分位值</strong></mark>​<mark>, 然后把计算之后的结果推给服务端存储, 展示的时候直接查询即可, 不需要做很重的计算, 性能大幅提升.</mark></p> <p>听起来不错, 但是有个问题, Summary 的计算是在客户端计算的, 也就意味着<strong>不是全局的分位值</strong>, 比如某个服务 service1, 部署在两个机器上, 服务代码里通过内嵌 Prometheus 的 SDK 做了埋点监控, SDK 里会计算 Summary 数据. 也就是说, <strong>分位值延迟数据是进程粒度的, 不是整个服务粒度的</strong>.</p> <p>这个问题很严重吗? 其实也没什么大不了的, 这两个机器前面肯定有负载均衡, 负载均衡会保证把请求均匀地打给后端的两个实例. <strong>一个实例内部计算的分位值, 理论上和全局计算的分位值差别不会很大</strong>. 另外如果某个实例有故障, 比如硬盘问题, 导致落在这个实例的请求延迟大增, 在实例粒度计算的延迟数据反而更容易发现问题.</p> <p>到这里就把 Prometheus 的四种数据类型介绍完了, 现在回顾一下这 4 种类型, 再往上翻一下 Prometheus 的数据传输结构, 就是那个 TimeSeries 的 Proto 结构, 看看能否发现一些问题?</p> <h5 id="_5-类型扩展知识"><a href="#_5-类型扩展知识" class="header-anchor">#</a> 5.类型扩展知识</h5> <p><strong>TimeSeries 数据结构中没有包含类型信息! 现在采集了一些监控数据, 传给 Prometheus(比如通过 remote write 协议), 数据是分了多种类型的, 传输的时候却没有办法告诉 Prometheus这些数据的类型是什么, 难道它不需要知道我的数据类型吗?</strong></p> <p><strong>其实从存储角度还真的不需要知道, 存储的时候只要知道指标标识, 时间戳, 值</strong>, 就足够了. 后续做 <mark><strong>PromQL 查询计算的时候, 不同的函数有不同的行为</strong></mark>, 比如 rate, increase 函数, 就给它传入 Counter 类型的数据作为参数即可. 对于 histogram_quantile 函数, 就传入带有 le 标签的 bucket 指标. 其实给 rate 函数传入一个 Gauge 类型的指标, 也照样可以拿到值, 虽然这个值没有合乎情理的业务语义.</p> <p>那为什么还需要划分这么多类型呢? <mark>最主要的作用是 </mark>​<mark><strong>在采集侧埋点的时候, SDK 会根据数据类型做不同的计算逻辑</strong></mark>, 比如 Histogram 类型, 每次请求进来的时候, 代码里调用一下 SDK 的 Observe 方法通知 SDK, SDK 就会自动计算生成多个指标, 提升埋点便利性.</p> <h4 id="时序库"><a href="#时序库" class="header-anchor">#</a> 时序库</h4> <p>了解了监控系统中指标的采集和传输之后, 接下来就是<strong>如何存储这些数据</strong>了. 监控数据是周期性采集的, 每条数据都关联一个时间戳, 所以<strong>都是时序数据, 使用时序库存储</strong>, 下面就来看看时序库的概念.</p> <p><strong>时序库(Time series database)是一种专门处理时序数据的数据库</strong>. 常见的数据库中, MySQL 是关系型数据库, Redis 是 KV 数据库, MongoDB 是文档数据库, 而 <strong>InfluxDB</strong>, VictoriaMetrics, M3DB 等都是时序库, Prometheus 其实也<strong>内置实现了一个时序存储模块</strong>.</p> <p>那什么是 <strong>时序数据</strong> 呢? <mark><strong>时序数据最大的特点是每一条数据都带有时间戳, 通常是单调顺序, 不会乱序, 流式发给服务端, 通常不会修改, 比如指标数据和日志数据, 都是典型的时序数据</strong></mark>. 存储领域没有银弹, 不同的数据场景侧重点不同, 所以针对时序数据这个特定场景, 产生了时序库这个专门的细分领域. 在 DB-Engines 网站上, 有一个 <a href="https://db-engines.com/en/ranking/time+series+dbms" target="_blank" rel="noopener noreferrer">时序库的流行度排序<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 可以了解到当下哪些时序库比较流行.</p> <h4 id="告警收敛"><a href="#告警收敛" class="header-anchor">#</a> 告警收敛</h4> <p>之前提到监控系统有<strong>两个核心能力, 一个是监控, 一个是告警</strong>. 告警部分也有一些关键概念, 比如告警收敛, 告警闭环, 下面一起来看一下.</p> <p>基础设施层面的故障, 比如基础网络问题, 可能会瞬间产生很多告警事件, 形成<strong>告警风暴</strong>, 导致接收告警的媒介拥塞, 比如手机不停接收到短信和电话呼入, 没办法使用. 这个时候, 就要想办法 <strong>让告警事件变少</strong>, 用的方法就是<strong>告警收敛</strong>.</p> <p><strong>最典型的手段是告警聚合发送, 聚合可以采用不同的维度, 比如时间维度, 策略维度, 监控对象维度等等</strong>. 如果 100 台机器同时报失联, 就可以合并成一条告警通知, 减少打扰.</p> <p><strong>另外一个典型的收敛手段是把多个事件聚合成告警, 把多个告警聚合成故障</strong>. 比如某个机器的 CPU 利用率告警, 监控系统可能每分钟都会产生一条事件, 这多个事件的告警规则, 监控对象, 监控指标都相同, 所以可以收敛为一条告警. 假设有 100 台机器都告警了, 其中 50 台属于业务 A, 另外 50 台属于业务 B, 可以按照业务来做聚合, 聚合之后产生两个故障, 这样就可以起到很好的收敛效果.</p> <h4 id="告警闭环"><a href="#告警闭环" class="header-anchor">#</a> 告警闭环</h4> <p>闭环这个词是个互联网黑话, 表示某个事情有始有终, 告警怎么判断是否闭环了呢? 问题最终被解决, 告警恢复, 就算是闭环了. 产品怎么设计才能保证告警闭环呢? 通常来讲, 没人响应的告警能够升级通知, <strong>告警 oncall 人员可以认领告警</strong>, 基本就有比较好的保障了.</p> <h4 id="小结"><a href="#小结" class="header-anchor">#</a> 小结</h4> <p>这一讲主要讲解一些监控领域的关键概念, 这些基础知识是整个监控体系知识蓝图的根基, 一定要掌握. 下面对这一讲的内容做一个简单总结.</p> <ul><li>**监控: ** 这个词在不同的上下文会有不同的语义, 有的时候表示数据采集和可视化, 有的时候表示整个监控系统. 不过不管怎么理解, 通常都不影响交流.</li> <li>**监控指标: ** 这个概念很关键, 不同的监控产品有不同的描述方式, 不过随着 OpenMetrics 标准的建立, 指标描述方式会渐渐趋于一致. 重点要了解 Prometheus 的指标描述方式 <strong>metric + labels</strong>, 当然 metric 也可以看作一个特殊的 label. Influx 格式也很重要, 建议掌握, 如果使用 Telegraf 作为采集器, 就绕不过去这个格式.</li> <li><strong>指标类型</strong>: 针对时下流行的 Prometheus, 讲解了 4 种指标类型及每个类型的适用场景, 最后明确了<strong>指标类型最核心的作用: 在采集侧埋点时, SDK 会根据数据类型做不同的计算逻辑</strong>.</li> <li>**时序库: ** 存储时序序列数据的数据库, 它已经成为了一个单独的数据库细分方向, 而且随着 IoT 的场景越来越多, 以及微服务的发展, 时序库这个话题也越来越流行.</li> <li>**告警收敛和告警闭环: ** 告警事件层面的话题是所有监控系统都需要处理的. 当然也可以作为一个专门的产品和多种监控系统对接, 专注处理告警事件, 希望国内能有超越  Bigpanda, Pagerduty 的产品出现.</li></ul> <p>本节的重点总结如下:</p> <p><img src="/img/b2a5d68462fa2yy22615720ee10fe2f9-20230719203435-ikwa5na.jpg" alt=""></p> <h3 id="_3-架构概述-一个监控系统的典型架构是什么样的"><a href="#_3-架构概述-一个监控系统的典型架构是什么样的" class="header-anchor">#</a> 3.架构概述-一个监控系统的典型架构是什么样的?</h3> <p>这一讲来聊聊监控系统的典型架构, 看看监控系统由哪些模块组成, 各个模块是如何相互协同的. 业界监控系统数量较多, 如果一上来就陷入某个具体的系统中, 容易一叶障目, 不见泰山. 这里把众多监控系统的架构做了一个统一的抽象和概括, 后面再看到任何一个监控系统, 都能快速理解了.</p> <h4 id="典型架构"><a href="#典型架构" class="header-anchor">#</a> 典型架构</h4> <p><img src="/img/9edcfef623ea9583134533c3b4c477f5-20230719203435-t4yuumu.png" alt="图片"></p> <p>先来看监控系统的典型架构图, 从左往右看, <strong>采集器是负责采集监控数据的, 采集到数据之后传输给服务端, 通常是直接写入时序库</strong>. 然后就是对时序库的数据进行分析和可视化, 分析部分最典型的就是告警规则判断(复杂一些的会引入统计算法和机器学习的能力做预判), 即图上的告警引擎, 告警引擎产生告警事件之后交给告警发送模块做不同媒介的通知. 可视化比较简单, 就是图上的数据展示, 通过各种图表来合理地渲染各类监控数据, 便于用户查看比较, 日常巡检.</p> <p>下面就来逐一分析一下每个模块的职能和设计.</p> <h4 id="采集器"><a href="#采集器" class="header-anchor">#</a> 采集器</h4> <p><strong>采集器负责采集监控数据</strong>, 有两种典型的部署方式, <strong>一种是跟随监控对象部署</strong>, 比如所有的机器上都部署一个采集器, 采集机器的 CPU, 内存, 硬盘, IO, 网络相关的指标; <strong>另一种是远程探针式</strong>, 比如选取一个中心机器做探针, 同时探测很多个机器的 PING 连通性, 或者连到很多 MySQL 实例上去, 执行命令采集数据.</p> <p>业界有多款开源采集器可供选择, 下面做一个简要点评, 便于你做选型.</p> <h5 id="_1-telegraf"><a href="#_1-telegraf" class="header-anchor">#</a> 1.Telegraf</h5> <p><a href="https://github.com/influxdata/telegraf" target="_blank" rel="noopener noreferrer">Telegraf<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 是 InfluxData 公司的产品, 开源协议是 MIT, 非常开放, 有很多外部贡献者, 主要配合 InfluxDB 使用. 当然 Telegraf 也可以把监控数据推给 Prometheus, Graphite, Datadog, OpenTSDB 等很多其他存储, 但和 InfluxDB 的对接是最丝滑的.</p> <p>InfluxDB 支持存储字符串, 而 Telegraf 采集的很多数据都是字符串类型, 但如果把这类数据推给 Prometheus 生态的时序库, 比如 VictoriaMetrics, M3DB, Thanos等, 它就会报错. 因为这些时序库只能存储数值型时序数据. 另外 Telegraf 采集的很多数据在成功和失败的时候会打上不同的标签, 比如成功的时候会打上 <code>result=success</code>​ 标签, 失败的时候打上 <code>result=failed</code>​ 标签.</p> <p>在 InfluxDB 中这种情况是可以的, 但是在 Prometheus 生态里, 标签变化就表示不同的指标, 这种情况可以称为<strong>标签非稳态结构</strong>, 使用 Prometheus 生态的时序库与 Telegraf 对接时需要 <strong>把这类标签丢弃掉</strong>.</p> <p>Telegraf 是指标领域的 All-In-One 采集器, 支持各种采集插件, 只需要使用 Telegraf 这一个采集器, 就能解决绝大部分采集需求.</p> <h5 id="_2-exporters"><a href="#_2-exporters" class="header-anchor">#</a> 2.Exporters</h5> <p><strong>Exporter 是专门用于 Prometheus 生态的组件, Prometheus 生态的采集器比较零散, 每个采集目标都有对应的 Exporter 组件, 比如 MySQL 有 mysqld_exporter, Redis 有 redis_exporter, 交换机有 snmp_exporter, JVM 有 jmx_exporter.</strong></p> <p>这些 Exporter 的核心逻辑, 就是<mark><strong>去这些监控对象里采集数据, 然后暴露为 Prometheus 协议的监控数据</strong></mark>. 比如 mysqld_exporter, 就是连上 MySQL, 执行一些类似于 <code>show global status</code>​, <code>show global variables</code>​, <code>show slave status</code>​ 这样的命令, 拿到输出, 再转换为 Prometheus 协议的数据; 还有 redis_exporter, 它是连上 Redis, 执行一些类似于 <code>info</code>​ 的命令, 拿到输出, 转换为 Prometheus 协议的数据.</p> <p>随着 Prometheus 的影响越来越大, 很多中间件都内置支持了 Prometheus, 直接通过自身的 <code>/metrics</code>​ 接口暴露监控数据, 不用再单独伴生 Exporter, 简化了架构. 比如 Kubernetes 中的各类组件: kube-apiserver, kube-proxy, kube-scheduler 等等, 比如 etcd, 还有新版本的 ZooKeeper, RabbitMQ, HAProxy, 都<strong>可以直接暴露 Prometheus 协议的监控数据, 无需 Exporter</strong>.</p> <p>不管是 Exporter 还是直接内置支持 Prometheus 协议的各类组件, 都提供 HTTP 接口(通常是 <code>/metrics</code>​)来暴露监控数据, <strong>让监控系统来拉, 这叫做 PULL 模型</strong>. 而像 Telegraf 那种则是 PUSH 模型, 采集了数据之后调用服务端的接口来推送数据. 关于PULL 模型和 PUSH 模型还会再详细地讲一下, 这里先有个印象即可.</p> <p>Telegraf 以及后面即将讲到的 Grafana-Agent, 也可以直接抓取 Prometheus 协议的监控数据, 然后统一推给时序库, 这种架构比较清晰, 总之跟数据采集相关的都由采集器来负责.</p> <h5 id="_3-grafana-agent"><a href="#_3-grafana-agent" class="header-anchor">#</a> 3.Grafana-Agent</h5> <p><a href="https://github.com/grafana/agent" target="_blank" rel="noopener noreferrer">Grafana-Agent<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 是 Grafana 公司推出的一款 All-In-One 采集器, 不但可以 <strong>采集指标数据</strong>, 也可以 <strong>采集日志数据和链路数据</strong>. 开源协议是 Apache 2.0, 比较开放.</p> <p>Grafana-Agent 作为后来者, 是如何快速集成各类采集能力的呢? Grafana-Agent 写了个框架, 方便导入各类 Exporter, 把各个 Exporter 当做 <strong>Lib</strong> 使用, 常见的 Node-Exporter, Kafka-Exporter, Elasticsearch-Exporter, Mysqld-Exporter 等, 都已经完成了集成. 这样就不用到处去找各类 Exporter, 只使用 Grafana-Agent 这一个二进制就可以搞定众多采集能力了.</p> <p><strong>Grafana-Agent 这种集成 Exporter 的方式, 完全兼容 Exporter 的指标体系</strong>, 比如 Node-Exporter. 如果场景不方便使用 PULL 的方式来抓取数据, 就可以换成 Grafana-Agent, 采用 <strong>PUSH 的方式推送监控数据</strong>, 完全兼容 Node-Exporter 的指标. 当然, Exporter 种类繁多, Grafana-Agent 不可能全部集成, 对于默认没有集成进去的 Exporter, Grafana-Agent 也支持用 PULL 的方式去抓取其他 Exporter 的数据, 然后再通过 Remote Write 的方式, 将采集到的数据转发给服务端.</p> <p>对于日志采集, Grafana-Agent 集成了 Loki 生态的日志采集器 Promtail. 对于链路数据, Grafana-Agent 集成了 OpenTelemetry Collector. 相当于把可观测性三大支柱的采集能力都建全了. 一个 Agent 搞定所有采集能力有个显而易见的好处, 就是便于附加一些通用标签, 比如某个机器的所有可观测性数据, 都统一打上机器名的标签, 后面就可以使用这种统一的标签做关联查询, 这个关联能力是这类 All-In-One 采集器带来的最大好处.</p> <h5 id="_4-categraf"><a href="#_4-categraf" class="header-anchor">#</a> 4.Categraf</h5> <p><a href="https://github.com/flashcatcloud/categraf" target="_blank" rel="noopener noreferrer">Categraf<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 是快猫团队开源的一款监控采集器, 开源协议是 MIT, 非常开放.</p> <p>你可能会想, 已经有这么多采集器了, 为何还要再造一个轮子呢? Categraf 的定位类似 Grafana-Agent, 支持 metrics, logs, traces 的采集, 未来也会支持事件的采集, 对于同类监控目标的多个实例的场景, 又希望做出 Telegraf 的体验. 同时对于所有的采集插件, 不但会提供采集能力, 也会提供监控大盘, 告警规则, 让社区开箱即用.</p> <p>Categraf 偏重 Prometheus 生态, <strong>标签是稳态结构, 只采集数值型时序数据</strong>, 通过 Remote Write 方式推送数据给后端存储, 所有支持 Remote Write 协议的时序库都可以对接, 比如 Prometheus, VictoriaMetrics, M3DB, Thanos 等等.</p> <p>对于习惯使用 Prometheus 的用户, Categraf 也支持直接读取 prometheus.yml 中的 scrape 配置, 对接各类服务发现机制, 实现上就是把 Prometheus agent mode 的代码引入进来了.</p> <p>机器层面的监控, 推荐 Telegraf 和 Categraf, 内置了监控脚本, 进程/端口监控, CPU, 内存之类的也都很完备; 探针类的监控自由度就很高了, 不同的中间件, 数据库监控, 习惯用哪个采集器就可以用哪个.</p> <p>针对上面我们介绍的几种常见的采集器, 做了一个表格供选型参考.</p> <p><img src="/img/5b1f1aa6b8276c07bd0e2d9bcbbcae24-20230719203435-rt5ejht.png" alt="图片"></p> <p><strong>采集器采集到数据之后, 要推给服务端</strong>. 通常有两种做法, <strong>一个是直接推给时序库, 一个是先推给 Kafka, 再经由 Kafka 写到时序库</strong>. 当然, 一些复杂的情况, 可能会在 Kafka 和时序库之间加一个<strong>流式计算引擎</strong>, 比如 Flink, 做一些<strong>预聚合计算</strong>. 但绝大部分公司都用不到, 所以这里先不管复杂流式计算的问题, 重点来看一下时序库.</p> <h4 id="时序库-2"><a href="#时序库-2" class="header-anchor">#</a> 时序库</h4> <p>监控系统的架构中, 最核心的就是<strong>时序库</strong>. 老一些的监控系统直接复用关系型数据库, 比如 Zabbix 直接使用 MySQL 存储时序数据, MySQL 擅长处理事务场景, 没有针对时序场景做优化, 容量上有明显的瓶颈. Open-Falcon 是用 RRDtool 攒了一个分布式存储组件 Falcon-Graph, 但是 RRDTool 本身的设计就有问题, 散文件很多, 对硬盘的 IO 要求太高, 性能较差. Falcon-Graph 是分布式的, 可以通过堆机器来解决大规模的问题, 但显然不是最优解.</p> <p>后来, 各种专门解决时序存储问题的数据库横空出世, 比较有代表性的有: InfluxDB, TDEngine, M3DB, VictoriaMetrics, TimescaleDB等. 下面逐一介绍一下.</p> <h5 id="_1-influxdb"><a href="#_1-influxdb" class="header-anchor">#</a> 1.InfluxDB</h5> <p>InfluxDB 来自 InfluxData, 是针对时序存储场景专门设计了存储引擎, 数据结构, 存取接口, 国内使用范围比较广泛, 而且 InfluxDB 可以和 Grafana, Telegraf 等良好整合, 生态是非常完备的. 不过 InfluxDB 开源版本是单机的, 没有开源集群版本. 毕竟是商业公司, 需要赚钱实现良性发展, 这个点是需要斟酌的.</p> <h5 id="_2-tdengine"><a href="#_2-tdengine" class="header-anchor">#</a> 2.TDEngine</h5> <p>TDEngine 姑且可以看做是国产版 InfluxDB, GitHub 的 Star 数上万, 针对<strong>物联网设备</strong>的场景做了优化, 性能很好, 也可以和 Grafana, Telegraf 整合, 对于偏设备监控的场景, TDEngine 是个不错的选择.</p> <p>TDEngine 的集群版是开源的, 相比 InfluxDB, TDEngine 这点很有吸引力. TDEngine 不止是做时序数据存储, 还内置支持了流式计算, 可以让用户少部署一些组件.</p> <p><img src="/img/13331964742c055805cd4b1d83547ddb-20230719203435-ne4oisw.png" alt="图片"></p> <p>通过 TDEngine 的官网可以得知, TDEngine 是支持 Prometheus 的 remote_read 和 remote_write 接口的. 不过不支持 Prometheus 的 Query 类接口, 这点需要注意.</p> <p>注: Thanos, M3DB, VictoriaMetrics 都直接兼容 Prometheus 的 Query 类接口, 上层程序可以把这些时序库当做 Prometheus 来使用.</p> <h5 id="_3-m3db"><a href="#_3-m3db" class="header-anchor">#</a> 3.M3DB</h5> <p>M3DB 是来自 Uber 的时序数据库, M3 声称在 Uber 抗住了 66 亿监控指标, 这个量非常庞大. 而且 M3DB 是全开源的, 包括集群版, 不过架构原理比较复杂, CPU 和内存占用较高, 在国内没有大规模推广起来. M3DB 的架构代码中包含很多分布式系统设计的知识, 是个可以拿来学习的好项目.</p> <h5 id="_4-victoriametrics"><a href="#_4-victoriametrics" class="header-anchor">#</a> 4.VictoriaMetrics</h5> <p>VictoriaMetrics, 简称 VM, 架构非常简单清晰, 采用 merge read 方式, 避免了数据迁移问题, 搞一批云上虚拟机, 挂上云硬盘, 部署 VM 集群, 使用单副本, 是非常轻量可靠的集群方式. 可以看一下 VM 架构图.</p> <p><img src="/img/85yy905fa9f7b5d8c16f6019053cbf3e-20230719203435-mkzc8l5.png" alt="图片"></p> <p>VM 实现了 Prometheus 的 Query 类接口, 即 <code>/api/v1/query</code>​, <code>/api/v1/query_range</code>​, <code>/api/v1/label/&lt;label-key&gt;/values</code>​ 相关的接口, 是 Prometheus 一个非常好的 Backend, 甚至可以说是 Prometheus 的一个替代品. 其实 VM 的初衷就是想要替换掉 Prometheus 的.</p> <h5 id="_5-timescaledb"><a href="#_5-timescaledb" class="header-anchor">#</a> 5.TimescaleDB</h5> <p>TimescaleDB 是 timescale.inc 开发的一款时序数据库, 作为一个 PostgreSQL 的扩展提供服务.</p> <p>它是基于 PostgreSQL 设计而成的, 而 PostgreSQL 生态四十年的积累, 就是巨人的肩膀, 很多底层的工作 PostgreSQL 其实已经完成了. 就拿保障数据安全来说吧, 因为程序可能随时会崩溃, 服务器可能会遇到电源问题或硬件故障, 磁盘可能损坏或者夯住, 这些极端场景都需要完善的解决方案来处理. PostgreSQL 社区已经有了现成的高可用特性, 包括完善的流复制和只读副本, 数据库快照功能, 增量备份和任意时间点恢复, wal 支持, 快速导入导出工具等. 而其他时序库, 这些问题都要从头解决.</p> <p>但是传统数据库是基于 btree 做索引的, 数据量到百亿或者千亿行, btree 会大到内存都存不下, 产生频繁的磁盘交换, 数据库性能会显著下降. 另外时序数据的写入量特别大, PostgreSQL 面对大量的插入, 性能也不理想.</p> <p>上面罗列了业界常用的几个时序库, 可以根据需求自行选择. 数据一旦进入时序库, 后面就可以对接告警引擎和可视化了, 这两部分分别解决了什么问题, 架构原理如何? 一起看一下.</p> <h4 id="告警引擎"><a href="#告警引擎" class="header-anchor">#</a> 告警引擎</h4> <p>告警引擎的核心职责就是 <mark><strong>处理告警规则, 生成告警事件</strong></mark>. 通常来讲, 用户会配置数百甚至数千条告警规则, 一些超大型的公司可能要配置数万条告警规则. 每个规则里含有数据过滤条件, 阈值, 执行频率等, 有一些配置丰富的监控系统, 还支持配置规则生效时段, 持续时长, 留观时长等.</p> <p>**告警引擎通常有两种架构, 一种是数据触发式, 一种是周期轮询式. **</p> <p><strong>数据触发式</strong>, 是指服务端接收到监控数据之后, 除了存储到时序库, 还会转发一份数据给告警引擎, 告警引擎每收到一条监控数据, 就要判断是否关联了告警规则, 做告警判断. 因为监控数据量比较大, 告警规则的量也可能比较大, 所以告警引擎是会做分片部署的, 即部署多个实例. 这样的架构, 即时性很好, 但是想要做指标关联计算就很麻烦, 因为不同的指标哈希后可能会落到不同的告警引擎实例.</p> <p>注: 分片的常见做法是根据指标标识做哈希.</p> <p><strong>周期轮询式, 架构简单, 通常是一个规则一个协程, 按照用户配置的执行频率, 周期性查询判断即可, 因为是主动查询的, 做指标关联计算就会很容易</strong>. 像 Prometheus, Nightingale, Grafana 等, 都是这样的架构.</p> <p>生成事件之后, 通常是交给一个单独的模块来做告警发送, 这个模块负责事件聚合, 收敛, 根据不同的条件发送给不同的接收者和不同的通知媒介. 告警事件的处理, 是一个非常通用的需求, 而且非常零碎, 复杂, 每个监控系统都去实现一套, 通常不会做得很完备. 于是就有了专门处理这类需求的产品, 最典型的比如 PagerDuty, 可以接收各类事件源的事件, 用户就只需要在 PagerDuty 做 OnCall 响应即可, 非常方便.</p> <h4 id="数据展示"><a href="#数据展示" class="header-anchor">#</a> 数据展示</h4> <p>监控数据的可视化也是一个非常通用且重要的需求, 业界做得最成功的当数 <strong>Grafana</strong>. <strong>Grafana 采用插件式架构, 可以支持不同类型的数据源, 图表非常丰富, 基本可以看做是开源领域的事实标准</strong>. 很多公司的商业化产品中, 甚至直接内嵌了 Grafana, 可见它是多么流行. 当然, Grafana 新版本已经修改了开源协议, 使用 AGPLv3, 这就意味着如果某公司的产品基于 Grafana 做了二次开发, 就必须公开代码, 有些厂商想要 Fork Grafana, 然后进行闭源商业分发, 就行不通了.</p> <p>监控数据可视化, 通常有两类需求, <strong>一个是即时查询, 一个是监控大盘(Dashboard)</strong> . 即时查询是临时起意, 比如线上有个问题, 需要追查监控数据, 还原现场排查问题, 这就需要有个方便查看的指标浏览功能, 快速找到想要的指标. 监控大盘通常用于日常巡检和问题排查, 由资深工程师创建, 放置了一些特别值得重点关注的指标, 一定程度上可以引发我们思考, 具有很强的知识沉淀效果. 如果想要了解某个组件的原理, 这个组件的监控大盘通常可以带给你一些启发.</p> <h4 id="小结-2"><a href="#小结-2" class="header-anchor">#</a> 小结</h4> <p>本讲围绕监控系统的典型架构, 阐述了各个功能模块的职能.</p> <ul><li><strong>采集器</strong>: <strong>用于收集监控数据</strong>, 业界有不少开源解决方案, 大同小异, 总体分为推拉两种模式, 各有应用场景. Telegraf, Exporters 用得最广泛, Grafana-Agent 和 Categraf 是后来者, 当然还有 Datadog-Agent 这种商业解决方案, 建议是优先考虑 Categraf, 相对而言, 它使用起来更加便捷. 如果有些场景 Categraf 没有覆盖, 可以考虑辅以一些特定的 Exporter.</li> <li><strong>时序库</strong>: <strong>用于存储时序数据</strong>, 是一个非常内卷的行业, 有很多开源方案可供选择. 如果规模比较小, 1000 台机器以下, 通常一个单机版本的 Prometheus 就够用了. 如果规模再大一些, 建议考虑 VictoriaMetrics, 毕竟架构简单, 简单的东西可能不完备, 但是出了问题容易排查, 更加可控.</li> <li><strong>告警引擎</strong>: <strong>用于做告警规则判断, 生成告警事件</strong>. 这是监控系统的一个重要组成部分, 通常是基于固定阈值规则来告警. 当然随着时代的发展, 也有系统支持统计算法和机器学习的方式做告警预判, 也是可以尝试的. AiOps 概念中最容易落地, 或者说落地之后最容易有效果的, 就是告警引擎. 不过 Google SRE 的观点是不希望在告警中使用太多 magic 的手段, 这个就见仁见智了.</li> <li><strong>数据展示</strong>: <strong>用于渲染展示监控数据</strong>. 最常见的图表就是折线图, 可以清晰明了地看到数据变化趋势, 有些人会把监控大盘配置得特别花哨, 各种能用的图表类型都用一下, 其实实用性才是最核心的诉求. 很多监控系统会内置看图功能, 开源领域最成熟的就是 Grafana, 如果某个存储无法和 Grafana 对接, 其流行性都会大打折扣.</li></ul> <p>总结如下:</p> <p><img src="/img/6fc697bd0378f55d42043ef25982b155-20230719203435-5804o6e.jpg" alt="图片"></p> <h2 id="搭建并增强prometheus"><a href="#搭建并增强prometheus" class="header-anchor">#</a> 搭建并增强Prometheus</h2> <h3 id="_4-如何快速搭建prometheus系统"><a href="#_4-如何快速搭建prometheus系统" class="header-anchor">#</a> 4.如何快速搭建Prometheus系统?</h3> <p>前面三讲介绍了监控系统的一些基本概念, 这一讲开始进入实操环节, 部署监控系统. 业界可选的开源方案很多, 随着云原生的流行, 越来越多的公司开始拥抱云原生, 而云原生标配的监控系统显然就是 Prometheus, 而且 Prometheus 的部署非常简单, 所以这一讲就先来自己动手搭建 Prometheus.</p> <h4 id="通用架构回顾"><a href="#通用架构回顾" class="header-anchor">#</a> 通用架构回顾</h4> <p>回顾一下上一讲介绍的监控系统通用架构.</p> <p><img src="/img/9edcfef623ea9583134533c3b4c477f5-20230719203435-kcoq5ye.png" alt="图片"></p> <p>之所以说 Prometheus 比较容易搭建, 是因为<strong>它把服务端组件, 包括时序库, 告警引擎, 数据展示三大块, 整合成了一个进程</strong>, 组件的数量大幅减少. <strong>Prometheus 生态的采集器就是各种 Exporter, 告警发送靠的是 AlertManager 组件</strong>, 下面先来部署  Prometheus 模块.</p> <h4 id="部署prometheus"><a href="#部署prometheus" class="header-anchor">#</a> 部署Prometheus</h4> <p>因为生产环境大概率是 Linux 的, 所以选择 Linux 下的发布包, 把 Prometheus 和 Alertmanager 两个包都下载下来.</p> <p>Prometheus 的下载地址:  <a href="https://prometheus.io/download/" target="_blank" rel="noopener noreferrer">https://prometheus.io/download/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><img src="/img/cf6af0ffc5f3be2867f8a18d0cd254f7-20230719203435-r0scmyn.png" alt="图片"></p> <p>下载之后解压缩, 使用 systemd 托管启动, 可以参考下面的命令.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /opt/prometheus
<span class="token function">wget</span> https://github.com/prometheus/prometheus/releases/download/v2.37.1/prometheus-2.37.1.linux-amd64.tar.gz
<span class="token function">tar</span> xf prometheus-2.37.1.linux-amd64.tar.gz
<span class="token function">cp</span> <span class="token parameter variable">-far</span> prometheus-2.37.1.linux-amd64/*  /opt/prometheus/

<span class="token comment"># service</span>
<span class="token function">cat</span> <span class="token operator">&lt;&lt;</span><span class="token string">EOF<span class="token bash punctuation"> <span class="token operator">&gt;</span>/etc/systemd/system/prometheus.service</span>
[Unit]
Description=&quot;prometheus&quot;
Documentation=https://prometheus.io/
After=network.target

[Service]
Type=simple

ExecStart=/opt/prometheus/prometheus  --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m --web.enable-admin-api

Restart=on-failure
SuccessExitStatus=0
LimitNOFILE=65536
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=prometheus

[Install]
WantedBy=multi-user.target
EOF</span>

systemctl <span class="token builtin class-name">enable</span> prometheus
systemctl start prometheus
systemctl status prometheus
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br></div></div><p>这里需要重点关注的是 Prometheus 进程的启动参数, 这里在每个参数下面都做出了解释.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment">#指定 Prometheus 的配置文件路径</span>
<span class="token parameter variable">--config.file</span><span class="token operator">=</span>/opt/prometheus/prometheus.yml

<span class="token comment"># 指定 Prometheus 时序数据的硬盘存储路径</span>
<span class="token parameter variable">--storage.tsdb.path</span><span class="token operator">=</span>/opt/prometheus/data

<span class="token comment"># 启用生命周期管理相关的 API, 比如调用 /-/reload 接口就需要启用该项</span>
--web.enable-lifecycle

<span class="token comment"># 启用 remote write 接收数据的接口, 启用该项之后, categraf, grafana-agent 等 agent 就可以通过 /api/v1/write 接口推送数据给 Prometheus</span>
--enable-feature<span class="token operator">=</span>remote-write-receiver

<span class="token comment"># 即时查询在查询当前最新值的时候, 只要发现这个参数指定的时间段内有数据, 就取最新的那个点返回, 这个时间段内没数据, 就不返回了</span>
--query.lookback-delta<span class="token operator">=</span>2m

<span class="token comment"># 启用管理性 API, 比如删除时间序列数据的 /api/v1/admin/tsdb/delete_series 接口</span>
--web.enable-admin-api
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>如果正常启动, Prometheus 默认会在 9090 端口监听, 访问这个端口就可以看到 Prometheus 的 Web 页面, 输入下面的  PromQL 可以查到一些监控数据.</p> <p><img src="/img/91652cc17442bcb51df6230624d0a21a-20230719203435-c0fryk6.png" alt="图片"></p> <p>这个数据是从哪里来的呢? 其实是 Prometheus <strong>自己抓取自己</strong>的, Prometheus 会在 <code>/metrics</code>​ 接口暴露监控数据, 可以访问这个接口看一下输出. 同时 Prometheus 在配置文件里配置了<strong>抓取规则</strong>, 打开 <strong>prometheus.yml</strong> 就可以看到了.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>scrape_configs:
  - job_name: <span class="token string">'prometheus'</span>
    static_configs:
    - targets: <span class="token punctuation">[</span><span class="token string">'localhost:9090'</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>localhost:9090 是暴露监控数据的地址, 没有指定接口路径, 默认使用 <code>/metrics</code>​, 没有指定 scheme, 默认使用 HTTP, 所以实际请求的是 <code>http://localhost:9090/metrics</code>​. 了解了 Prometheus 自监控的方式, 下面来看一下机器监控.</p> <h4 id="部署node-exporter"><a href="#部署node-exporter" class="header-anchor">#</a> 部署Node-Exporter</h4> <p>Prometheus 生态的机器监控比较简单, 就是<strong>在所有的目标机器上部署 Node-Exporter, 然后在抓取规则中给出所有 Node-Exporter 的地址</strong>就可以了.</p> <p>首先下载 <a href="https://prometheus.io/download/#node_exporter" target="_blank" rel="noopener noreferrer">Node-Exporter<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 可以选择当下比较稳定的版本 1.3.1, 下载之后解压就可以直接运行了, 比如使用 nohup(生产环境建议使用 systemd 托管) 简单启动的话, 可以输入下面这一行命令.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token function">nohup</span> ./node_exporter <span class="token operator">&amp;&gt;</span> output.log <span class="token operator">&amp;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>Node-Exporter 默认的监听端口是 9100, 可以通过下面的命令看到 Node-Exporter 采集的指标.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token function">curl</span> <span class="token parameter variable">-s</span> localhost:9100/metrics
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>然后<strong>把 Node-Exporter 的地址配置到 prometheus.yml</strong> 中即可. 修改了配置之后, 记得给 Prometheus 发个 HUP 信号, 让 Prometheus 重新读取配置: <code>kill -HUP &lt;prometheus pid&gt;</code>​. 最终 scrape_configs 部分变成下面这段内容.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>scrape_configs:
  - job_name: <span class="token string">'prometheus'</span>
    static_configs:
    - targets: <span class="token punctuation">[</span><span class="token string">'localhost:9090'</span><span class="token punctuation">]</span>

  - job_name: <span class="token string">'node_exporter'</span>
    static_configs:
    - targets: <span class="token punctuation">[</span><span class="token string">'localhost:9100'</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>其中 targets 是个数组, 如果要监控更多机器, 就在 targets 中写上多个 Node-Exporter 的地址, 用逗号隔开. 之后在 Prometheus 的 Web 上(菜单位置Status -&gt; Targets), 就可以看到相关的 Targets 信息了.</p> <p><img src="/img/f572c8cf62d7b52668c6fd71cdb7887c-20230719203435-lhefdo7.png" alt="图片"></p> <p>在查询监控数据的框里输入 node, 就会自动提示很多 node 打头的指标. 这些指标都是 Node-Exporter 采集的, 选择其中某一个就可以查到对应的监控数据, 比如查看不同硬盘分区的余量大小.</p> <p><img src="/img/44d2bc07de0a62299bb38e910010fbfd-20230719203435-t99bakl.png" alt="图片"></p> <p>Node-Exporter 默认内置了很多 collector, 比如 cpu, loadavg, filesystem 等, 可以通过命令行启动参数来控制这些 collector, 比如要关掉某个 collector, 使用 <code>--no-collector.&lt;name&gt;</code>​, 如果要开启某个 collector, 使用 <code>--collector.&lt;name&gt;</code>​. 具体可以参考 Node-Exporter 的 <a href="https://github.com/prometheus/node_exporter#collectors" target="_blank" rel="noopener noreferrer">README<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. Node-Exporter 默认采集几百个指标, 有了这些数据, 我们就可以演示告警规则的配置了.</p> <h4 id="配置告警规则"><a href="#配置告警规则" class="header-anchor">#</a> 配置告警规则</h4> <p>Prometheus 进程内置了告警判断引擎, prometheus.yml 中可以指定告警规则配置文件, 默认配置中有个例子.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">rule_files</span><span class="token punctuation">:</span>
  <span class="token comment"># - &quot;first_rules.yml&quot;</span>
  <span class="token comment"># - &quot;second_rules.yml&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>可以把不同类型的<strong>告警规则</strong>拆分到不同的配置文件中, 然后在 prometheus.yml 中引用. 比如 Node-Exporter 相关的规则, 命名为 node_exporter.yml, 最终这个 rule_files 就变成了如下配置.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">rule_files</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token string">&quot;node_exporter.yml&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这里设计了一个例子, 监控 Node-Exporter 挂掉以及内存使用率超过 1% 这两种情况. 这里故意设置了一个很小的阈值, 确保能够触发告警.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">groups</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> node_exporter
  rules<span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">alert</span><span class="token punctuation">:</span> HostDown
    expr<span class="token punctuation">:</span> up<span class="token punctuation">{</span>job=&quot;node_exporter&quot;<span class="token punctuation">}</span> == 0
    for<span class="token punctuation">:</span> 1m
    labels<span class="token punctuation">:</span>
      severity<span class="token punctuation">:</span> critical
    annotations<span class="token punctuation">:</span>
      summary<span class="token punctuation">:</span> Host down <span class="token punctuation">{</span><span class="token punctuation">{</span> $labels.instance <span class="token punctuation">}</span><span class="token punctuation">}</span>
  <span class="token punctuation">-</span> <span class="token key atrule">alert</span><span class="token punctuation">:</span> MemUtil
    expr<span class="token punctuation">:</span> 100 <span class="token punctuation">-</span> node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 <span class="token punctuation">&gt;</span> 1
    for<span class="token punctuation">:</span> 1m
    labels<span class="token punctuation">:</span>
      severity<span class="token punctuation">:</span> warn
    annotations<span class="token punctuation">:</span>
      summary<span class="token punctuation">:</span> Mem usage larger than 1%<span class="token punctuation">,</span> instance<span class="token punctuation">:</span><span class="token punctuation">{</span><span class="token punctuation">{</span> $labels.instance <span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>最后, 给 Prometheus 进程发个 HUP 信号, 让它重新加载配置文件.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>kill <span class="token punctuation">-</span>HUP `pidof prometheus`
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>之后就可以去 Prometheus 的 Web 上(Alerts菜单)查看告警规则的判定结果了.</p> <p><img src="/img/bfb533fd9a65c0df2872cea67817f0b3-20230719203435-4d9oyev.png" alt="图片"></p> <p>从图中可以看出, 告警分成 3 个状态, <strong>Inactive, Pending, Firing</strong>. HostDown 这个规则当前是 Inactive 状态, 表示没有触发相关的告警事件, MemUtil 这个规则触发了一个事件, 处于 Firing 状态. 那什么是 Pending 状态呢? 触发过阈值但是还没有满足持续时长( for 关键字后面指定的时间段)的要求, 就是 Pending 状态. 比如 for 1m, 就表示触发阈值的时间持续 1 分钟才算满足条件, 如果规则判定执行频率是 10 秒, 就相当于连续 6 次都触发阈值才可以.</p> <p>在页面上<strong>看到告警</strong>了, 就是一个巨大的进步, 如果还希望在告警的时候收到消息通知, 比如邮件, 短信等, 就需要引入  AlertManager 组件了.</p> <h4 id="部署alertmanager"><a href="#部署alertmanager" class="header-anchor">#</a> 部署Alertmanager</h4> <p>部署 Prometheus 的时候, 已经顺便把 Alertmanager 的包下载下来了, 下面就安装一下. 安装过程很简单, 把上面的  prometheus.service 拿过来改一下给 Alertmanager 使用即可, 下面是改好的 alertmanager.service.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>Unit<span class="token punctuation">]</span>
Description=&quot;alertmanager&quot;
After=network.target

<span class="token punctuation">[</span>Service<span class="token punctuation">]</span>
Type=simple

ExecStart=/usr/local/alertmanager/alertmanager
WorkingDirectory=/usr/local/alertmanager

Restart=on<span class="token punctuation">-</span>failure
SuccessExitStatus=0
LimitNOFILE=65536
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=alertmanager

<span class="token punctuation">[</span>Install<span class="token punctuation">]</span>
WantedBy=multi<span class="token punctuation">-</span>user.target
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>把 Alertmanager 解压到 /usr/local/alertmanager 目录, 通过 ExecStart 可以看出, 直接执行二进制就可以, 实际 Alertmanager 会读取二进制同级目录下的 alertmanager.yml 配置文件. 这里使用 163 邮箱作为 SMTP 发件服务器, 下面是具体的配置.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">global</span><span class="token punctuation">:</span>
  <span class="token key atrule">smtp_from</span><span class="token punctuation">:</span> <span class="token string">'username@163.com'</span>
  <span class="token key atrule">smtp_smarthost</span><span class="token punctuation">:</span> <span class="token string">'smtp.163.com:465'</span>
  <span class="token key atrule">smtp_auth_username</span><span class="token punctuation">:</span> <span class="token string">'username@163.com'</span>
  <span class="token key atrule">smtp_auth_password</span><span class="token punctuation">:</span> <span class="token string">'这里填写授权码'</span>
  <span class="token key atrule">smtp_require_tls</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>

<span class="token key atrule">route</span><span class="token punctuation">:</span>
  group_by<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'alertname'</span><span class="token punctuation">]</span>
  group_wait<span class="token punctuation">:</span> 30s
  group_interval<span class="token punctuation">:</span> 1m
  repeat_interval<span class="token punctuation">:</span> 1h
  receiver<span class="token punctuation">:</span> <span class="token string">'email'</span>

<span class="token key atrule">receivers</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">'web.hook'</span>
    webhook_configs<span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">url</span><span class="token punctuation">:</span> <span class="token string">'http://127.0.0.1:5001/'</span>

  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">'email'</span>
    email_configs<span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">to</span><span class="token punctuation">:</span> <span class="token string">'ulricqin@163.com'</span>

<span class="token key atrule">inhibit_rules</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">source_match</span><span class="token punctuation">:</span>
      severity<span class="token punctuation">:</span> <span class="token string">'critical'</span>
    target_match<span class="token punctuation">:</span>
      severity<span class="token punctuation">:</span> <span class="token string">'warning'</span>
    equal<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'alertname'</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> <span class="token string">'instance'</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><p>首先配置一个全局 SMTP, 然后修改 receivers. receivers 是个数组, 默认例子里有个 web.hook, 然后又加了一个 email 的 receiver, 然后配置 route.receiver 字段的值为 email. email_configs 中的 to 表示收件人, 多个人用逗号分隔, 比如 <code>to: 'user1@163.com, user2@163.com'</code>​, 最后收到的邮件内容大概是这样的, 可以看一下样例.</p> <p><img src="/img/bf8a77d0640d97415205c662f50069d2-20230719203435-8pw1d27.png" alt="图片"></p> <p>收到告警邮件, 就说明这整个<strong>告警链路</strong>走通了. 最后再看一下数据可视化的问题. Prometheus 自带的看图工具, 是给专家用的, 需要对指标体系非常了解, 经验没法沉淀, 而且绘图工具单一, 只有折线图. 如果希望有一个更好用的 UI 工具, 可以试试 Grafana.</p> <h4 id="部署grafana"><a href="#部署grafana" class="header-anchor">#</a> 部署Grafana</h4> <p>Grafana 是一个数据可视化工具, 有丰富的图表类型, 视觉效果很棒, 插件式架构, 支持各种数据源, 是开源监控数据可视化的标杆之作. Grafana 可以直接对接 Prometheus, 大部分使用 Prometheus 的用户, 也都会使用 Grafana, 下面就来部署一下.</p> <p>可以先把 <a href="https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1&amp;edition=oss" target="_blank" rel="noopener noreferrer">Grafana<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 下载下来, 它分为两个版本, 企业版和开源版, 开源版本遵照 AGPLV3 协议, 只要不做二次开发商业化分发, 是可以直接使用的. 这里就下载了开源版本, 选择 <a href="https://dl.grafana.com/oss/release/grafana-9.1.5.linux-amd64.tar.gz" target="_blank" rel="noopener noreferrer">tar.gz 包<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 下载之后解压缩, 执行 <code>./bin/grafana-server</code>​ 即可一键启动, Grafana 默认的监听端口是 3000, 访问后就可以看到登录页面了, 默认的用户名和密码都是 admin.</p> <p>要看图首先要<strong>配置数据源</strong>, 在菜单位置: Configuration -&gt; Data sources, 点击 <strong>Add data source</strong> 就能进入数据源类型选择页面, 选择 Prometheus, 填写 Prometheus 的链接信息, 主要是 URL, 点击 <strong>Save &amp; test</strong> 完成数据源配置.</p> <p>Grafana 提供了和 Prometheus 看图页面类似的功能, 叫做 Explore, 可以在这个页面点选指标看图.</p> <p><img src="/img/7dd10e1295567613329a7c06eb873872-20230719203435-e0vf8mq.png" alt="图片"></p> <p>但 Explore 功能不是最核心的, 使用 Grafana, 主要是使用 Dashboard 看图. Grafana 社区有很多人制作了各式各样的大盘, 以 JSON 格式上传保存在了 <a href="https://grafana.com/grafana/dashboards/" target="_blank" rel="noopener noreferrer">grafana.com<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 如果想要某个 Dashboard, 可以先去这个网站搜索一下, 看看是否有人分享过. 因为已经部署了 Node-Exporter, 那这里就可以直接导入 Node-Exporter 的大盘, 大盘 ID 是 1860, 写到图中对应的位置, 点击 Load, 然后选择数据源点击 Import 即可.</p> <p><img src="/img/ed4598ac72020b58e03b84152ea2185e-20230719203435-st0zian.png" alt="图片"></p> <p>导入成功的话会自动打开 Dashboard, Node-Exporter 的大盘长这个样子.</p> <p><img src="/img/24b12129c46b572f84c2f6550cf394b7-20230719203435-2l9xvkl.png" alt="图片"></p> <p>走到这个监控看图的部分, 也走完了整个流程.</p> <h4 id="小结-3"><a href="#小结-3" class="header-anchor">#</a> 小结</h4> <p>本讲的核心内容就是演示 Prometheus 生态相关组件的部署. 学完这些内容再来看一下 Prometheus 的架构图, 和监控系统通用架构图相互做一个印证, 加深理解.</p> <p><img src="/img/8e7bcb19da502cbe4cc811f60be871d6-20230719203435-qn9231m.png" alt="图片"></p> <p>图上有两个部分没有讲到, 一个是 Pushgateway 组件, 另一个是 Service discovery 部分. 这里再做一个简单的补充.</p> <ul><li><strong>Pushgateway</strong>: 用于接收短生命周期任务的指标上报, 是 PUSH 的接收方式. 因为 Prometheus 主要是 PULL 的方式拉取监控数据, 这就要求在拉取的时刻, 监控对象得活着, 但是很多短周期任务, 比如 cronjob, 可能半秒就运行结束了, 就没法拉取了. 为了应对这种情况, 才单独做了 Pushgateway 组件作为整个生态的补充.</li> <li><strong>Service discovery</strong>: 前面演示抓取数据时, 是直接在 prometheus.yml 中配置的多个 Targets. 这种方式虽然简单直观, 但是也有弊端, 典型的问题就是如果 Targets 是<strong>动态变化</strong>的, 而且变化得比较频繁, 那就会造成管理上的灾难. 所以 Prometheus 提供了多种<strong>服务发现机制</strong>, 可以动态获取要监控的目标, 比如 Kubernetes 的服务发现, 可以通过调用 kube-apiserver 动态获取到需要监控的目标对象, 大幅降低了抓取目标的管理成本.</li></ul> <p>总结如下:</p> <p><img src="/img/57d84b93f63dbc1dc5779ba257c48235-20230719203435-wuzvq3m.jpg" alt=""></p> <h3 id="_5-prometheus中有哪些关键设计"><a href="#_5-prometheus中有哪些关键设计" class="header-anchor">#</a> 5.Prometheus中有哪些关键设计?</h3> <p>上一讲介绍了如何搭建 Prometheus 系统, 演示了基本的使用方法, 这一讲深入进去, 梳理一下 Prometheus 的关键设计, 看看这些设计是如何奠定 Prometheus 江湖地位的.</p> <p><img src="/img/c2c67694da6bb16fa0cf7318abd0c5b2-20230719203435-wxj5zcx.jpg" alt=""></p> <h4 id="标准先行与注重生态"><a href="#标准先行与注重生态" class="header-anchor">#</a> 标准先行与注重生态</h4> <p>Prometheus 最重要的规范就是 <mark><strong>指标命名方式</strong></mark>, 数据格式简单易读, 在前面已经聊过了, 它用标签集来标识指标. 有些监控系统会把一些特殊的字段单独提出来, 最典型的就是 hostname 字段, 这种做法在一些特定场景会显得更有效. 但是显然, **统一的标签集表达方式是最通用, 最灵活的. **</p> <p>虽然标签集很灵活, 但是在实际落地时, 强烈建议<strong>在公司推行一个标签定义规范, 标签 Key 不能随便起名, 该有的标签也不能缺失</strong>. 既减少了理解成本, 也保证了数据的规整完备, 便于后续做数据分析. 比如对于应用层面的监控, 可以要求必须具备这几个信息.</p> <ul><li><strong>指标名称 metric</strong></li></ul> <p>Prometheus 内置建立的规范就是叫 metric(即 __name__). 如果是 Counter 类型, 单调递增的值, 指标名称以 _total 结尾.</p> <ul><li><strong>服务名称 service</strong></li></ul> <p>服务名称 service 要全局唯一, 比如 n9e-webapi, p8s-alertmanager, 一般是<strong>系统名称加上模块名称</strong>, 组成最终的服务名称. 如果公司比较大, 就需要一个全局的服务目录做参考, 否则不同的团队可能会起相同的名称, 可以考虑使用 Git 里的 GroupName + RepoName. 系统名称最好也单独做成一个标签, 比如 system=n9e system=p8s.</p> <ul><li><strong>实例名称 instance</strong></li></ul> <p>一个服务一般会部署多个实例, 可以直接使用机器名或 Pod 名作为 instance 名称. 如果在物理机部署, 有实例混部的情况, 就要把端口加上, 比如实例一是 10.1.2.3:3306, 实例二是 10.1.2.3:3307.</p> <ul><li><strong>服务类型 job</strong></li></ul> <p>比如所有的 MySQL 的监控数据, 都统一打上 job=mysql 的标签, Redis 的监控数据, 就打上 job=redis 的标签. 如果是自研的模块, 也可以使用 webserver backend frontend 这种分类方式.</p> <ul><li><strong>地域可用区 zone</strong></li></ul> <p>把地域信息放到标签里, 有个巨大的好处, 比如某个 zone 出问题了, 就比较容易看出来, 带有某个特定的 zone 的指标数据异常, 快速执行切流止损即可. 有了 zone 的信息, region 就可有可无了, zone 的前缀一般就是 region.</p> <ul><li><strong>集群名称 cluster</strong></li></ul> <p>有的时候一个可用区会部署多个集群, 特别是一些中间件, 比如 ElasticSearch, 给每个重要的业务单独部署一个集群, 一个大公司可能有几百套 ElasticSearch 集群, 几千套 ZooKeeper 集群.</p> <ul><li><strong>环境类型 env</strong></li></ul> <p>环境类型 env 用来标识是生产环境还是测试环境. 当然了, 如果监控系统不复用(推荐这么做), 生产用生产的监控系统, 测试用测试的监控系统, 就无需这个标签了.</p> <p>指标的数据格式和传输协议制定好之后, 各种 Exporter, 各种支持 Remote Read/Write 的后端存储就可以接入进来了, 而这些 Exporter, 存储的丰富和繁荣, 又反向推动了 Prometheus 的流行, 形成正向循环.</p> <h4 id="主要使用拉模式与解耦"><a href="#主要使用拉模式与解耦" class="header-anchor">#</a> 主要使用拉模式与解耦</h4> <p><mark><strong>Prometheus 主要使用拉模式获取指标, 辅以推模式(Pushgateway 的职能)</strong></mark> . 很多监控系统都是推模式, 比如 Datadog, Open-Falcon, Telegraf+InfluxDB 组合.</p> <p><img src="/img/dfdb90a4651ba7d88dc878072550357f-20230719203435-jdcgg7t.jpg" alt=""></p> <p>推拉两种方式, 在监控领域讨论也比较多, 它们各有优缺点和适用场景:</p> <p><strong>拉模式有个最重要的优势, 就是解耦</strong>. 你可能之前听很多人说过这个优势, 但未必能体会到解耦解在了哪里, 举一个例子就知道了.</p> <p>对于各类中间件, 特别是非常基础的那些, 很大概率是先于监控系统部署的. 如果是拉模式, 部署好监控系统之后, 再来调用中间件的接口获取数据即可. 如果是推模式, 就需要在中间件里重新配置监控数据上报地址, 然后重启中间件, 这个代价就太高了.</p> <p>但是拉模式需要有很好的服务发现机制, 如果只有少量的几个目标要采集, 怎么搞都可以, 但是有几百个的时候, 手工配置就比较麻烦了. <strong>所以 Prometheus 支持各种服务发现机制, 尤其是基于 Kubernetes 的服务发现机制, 是最常见的</strong>.</p> <p>如果服务没有部署在 Kubernetes 中, 而是部署在传统物理机或虚拟机上, 这个时候就需要使用 Consul 之类的服务发现机制. 但如果在监控体系建设之前, 服务没有接入注册中心, 为了满足监控需求而接入注册中心, 用户会觉得成本太高. 此时推模式就有了用武之地, 这就是很多公司的自研服务都使用推模式发送监控数据的原因.</p> <p>所以结论就来了: <strong>中间件类使用拉模式, 自研的服务使用推模式, 自研的服务如果都接入了注册中心, 则也可以使用拉模式</strong>.</p> <p>当然, 推拉的选择还有一个点比较关键, 就是 <strong>网络通路问题</strong>, 特别是网络 ACL 限制比较严格的环境, 很多都是可出不可进, 比如典型的 NAT 出网, 这种情况下推模式的适配性更好, 也就是说对 ACL 更友好一些. 另一个关键点是 <strong>短周期任务或批处理任务</strong>, 通常不太可能监听 HTTP 端口, 这种大概率也是推模式.</p> <p>推拉模式的选择, 还有一些其他影响因素, 比如推模式服务端通常比较容易处理, 因为数据接收是无状态的. 但是拉模式在数据量大的时候要考虑分片的问题, 还有就是失联告警问题, 拉模式很容易感知到目标失联. 推模式就比较复杂了, 需要对数据缺失做告警, 比如  Prometheus 的 absent 函数, absent 函数需要把指标的每个标签都写全, 才能达到预期效果. 而指标数量何止千万, 几乎不可能完成.</p> <p>最后就是可控性问题, 拉模式, 监控系统是主动的一方, 可以控制频率; 推模式, 客户端是主动的一方, 如果代码写&quot;挫&quot;了, 就会给监控系统造成很大压力.</p> <p>前面我们提到拉模式需要有很好的服务发现机制, Prometheus 采取的就是拉模式, 因此它对监控目标动态发现机制的苛求度很高.</p> <h4 id="监控目标动态发现机制"><a href="#监控目标动态发现机制" class="header-anchor">#</a> 监控目标动态发现机制</h4> <p>监控目标动态发现机制, 这个问题其实很早就有, 老一些的监控系统, 比如 Zabbix, 是资产管理式, 要监控的目标都需要在服务端注册, 配置. 这种方式在监控目标偏静态的场景还是比较好用的, 但是<strong>云原生之后, 基础设施动态化, 监控目标的创建, 销毁都比较频繁, 就需要有一个更自动化的机制来获取监控目标列表</strong>.</p> <p>Prometheus 内置了多种服务发现机制, 最常见的有四种.</p> <ul><li><strong>基于配置文件的发现机制</strong>: 这种方式看起来很低端, 其实非常常用, 因为可以配合配置管理工具一起使用, 非常方便. 使用配置管理工具批量更新配置, 然后让监控系统重新加载一下就可以了, 比较丝滑.</li> <li><strong>基于 Kubernetes 的发现机制</strong>: Kubernetes 中有很多元信息, 通过调用 kube-apiserver, 可以轻易拿到 Pod, Node, Endpoint 等列表, Prometheus 内置支持了 Kubernetes 的服务发现机制, 让这个过程变得更简单, Prometheus 基本成为了 Kubernetes 监控的标配.</li> <li><strong>基于公有云 API 的发现机制</strong>: 比如要监控公有云上所有的 RDS 服务, 一条一条配置比较麻烦, 这个时候就可以基于公有云的 OpenAPI 做一个服务发现机制, 自动拉取相关账号下所有 RDS 实例列表, 大幅降低管理成本.</li> <li><strong>基于注册中心的发现机制</strong>: 社区里最为常用的是 Consul, 典型场景是 PING 监控和 HTTP 监控, 把所有目标注册到 Consul 中, 然后读取 Consul 生成监控对象列表即可.</li></ul> <p>这就是 Prometheus 支持的几个主要的服务发现机制, 当然还有其他方式, 但用得没那么多, 这里就先不介绍了.</p> <h4 id="基于配置文件的管理方式"><a href="#基于配置文件的管理方式" class="header-anchor">#</a> 基于配置文件的管理方式</h4> <p><strong>Prometheus 的告警规则管理, 记录规则管理, 抓取配置管理与发送策略管理, 全部是基于配置文件的</strong>, 这虽然不是一个关键设计, 但确实是一个非常有特色的设计, 这里也简单聊一下.</p> <p>这个方式有两个好处, 一个是简单, 简单到令人发指, 很多监控系统都是使用数据库来存储各类配置的, Prometheus 则直接使用 Yaml 文件, 非常直观. 第二个好处就是便于自动化, 配合配置管理工具, Git, Kubernetes 等, 与 Infrastructure as Code  的管理风潮非常契合.</p> <p>当然这样管理也有一个问题, 就是不便于公司级协作, 比如公司有 30 条业务线, 数百个服务, 上千个研发, 大家都来管理一套配置, 会非常混乱. 所以很多公司的做法是由一个专职的运维团队来管理这套配置, 其他业务线研发有需求了就给这个运维团队提工单, 这种做法也凑合能用, 只是苦了这个运维团队, 团队成员比较容易产生焦躁情绪.</p> <p>另外, Prometheus 默认是<strong>单机时序存储</strong>, 容量有上限, 基于配置管理的问题和容量问题, 非常建议那些推行 DevOps 的团队来使用, 而且是每个团队自己有一套单独的 Prometheus, 互不干扰, 正所谓 &quot;You build it. You Run it. You monitor it. You own it&quot;.</p> <p>当然这样也会带来问题, 最典型的是数据孤岛问题, 不过可以把各个 Prometheus 中的核心关键指标抽取到一个统一的地方来呈现, 比如使用 Prometheus 联邦机制, <strong>只共享核心指标</strong>, 其余指标不需要抽取到中心, 自己团队消化就好.</p> <p>后面也会使用 Nightingale 来增强 Prometheus 的配置管理问题, 算是另一个思路.</p> <h4 id="灵活的查询语言"><a href="#灵活的查询语言" class="header-anchor">#</a> 灵活的查询语言</h4> <p><strong>PromQL</strong>(Prometheus Query Language)是 Prometheus 的查询语言, 非常灵活. 这也是 Prometheus 的一个关键设计.</p> <p>很多老一代监控系统都只能对数据做简单过滤判断阈值, 没有 QL 的支持. 当想要某个数据却发现没有的时候, 就天然倾向于在采集侧处理, 但是 <mark><strong>采集侧是无法穷举所有计算场景的, 采集侧应该采集原始数据, 后续的二次计算还是应该放到中心来搞定</strong></mark>.</p> <p>比如机器的内存指标, 可以从 <code>cat /proc/meminfo</code>​ 中看到很多内存相关的监控指标, 采集器可以轻易拿到 MemAvailable 和 MemTotal 这样的字段, 但是操作系统不会直接暴露内存可用率, 此时就需要使用 PromQL: MemAvailable / MemTotal * 100  做二次计算了. 因为这个场景很常见, 有的采集器就直接自动做了计算, 输出 mem_available_percent 这样的指标. 但是还有很多场景是不好穷举的, 下面再举个例子.</p> <p>有一些监控数据的采集, 是<strong>完全由用户配置</strong>出来的, 比如 SNMP 数据采集, 采集哪些 OID 是用户配置的; JMX 数据采集, 采集哪些 MBean, 哪些 Pattern 也是用户配置的. 监控采集器压根就不知道这些数据的具体语义, 只有配置采集规则的人知道, 这种情况更不可能自动计算, 采集器只能采集原始数据, 如果有二次计算的需求, 最好是设计到服务端, 让服务端来做.</p> <p>PromQL 为二次计算<strong>提供了能力支持, 多个指标的关联计算, 多条件联合告警, 都可以用 PromQL 来实现</strong>, 作为现代监控系统, Query Language 已经是必备要求了.</p> <h4 id="小结-4"><a href="#小结-4" class="header-anchor">#</a> 小结</h4> <p>这一讲介绍了一些 Prometheus 的关键设计, 这些设计成就了 Prometheus. 下面对这一讲的内容做一个简单的回顾.</p> <ul><li>Prometheus 非常注重标准制定和生态建设, 而且标准很稳定, 没有变来变去, 社区有很多人参与其中, 共建整套生态. Prometheus 不期望解决所有问题, 但是影响力巨大, 就是因为标准和生态的强大.</li> <li>Prometheus 主要使用拉模式, 辅以推模式. 这里比较了推拉两种模式, 简单来看, <strong>拉模式便于解耦, 推模式则更简单</strong>. 中间件监控适合拉模式, 自研模块适合推模式. 当然如果注册中心完备, 服务都接入了注册中心, 服务监控的数据采集也可以使用拉模式.</li> <li>拉模式更需要监控目标动态发现机制, 主要使用拉模型的 Prometheus 内置了多种发现机制, 最常用的是基于配置文件,  Kubernetes, 公有云 API, Consul 四种发现机制.</li> <li>Prometheus 的配置管理非常简单, 直接使用 Yaml 文件, 很直观, 便于推行 laC 管理模式, 只是在公司级大规模协同的时候会有些不方便. 当然国内的大部分企业没有践行 IaC, Yaml 配置的方式会相对难搞一些.</li> <li>Prometheus 查询语言就是 PromQL, 这也是它最后一个关键设计, 让采集侧专注采集, 服务端提供灵活的计算能力, 有些偏传统的企业难以接受这种做法, 只想简单过滤指标来配置阈值, 很难把 PromQL 的优势发挥出来, 非常可惜.</li></ul> <p>脑图如下:</p> <p><img src="/img/717634c46dbb97da5484ce6411ef1c4b-20230719203435-8wnrdj6.jpg" alt=""></p> <h3 id="_6-promql有哪些常见的使用场景"><a href="#_6-promql有哪些常见的使用场景" class="header-anchor">#</a> 6.PromQL有哪些常见的使用场景?</h3> <p>上一讲介绍了 Prometheus 中的一些关键设计, 比如注重标准和生态, 监控目标动态发现机制, PromQL 等, 其中 PromQL 是 Prometheus 的查询语言, 使用起来非常灵活方便, 但很多人不知道如何更好地利用它, 发挥不出它的优势. 所以这一讲就来梳理一下 PromQL 的典型应用场景.</p> <p><strong>PromQL 主要用于时序数据的查询和二次计算场景</strong>. 先来回顾一下时序数据, 在脑子里建立起时序数据的具象视图.</p> <h4 id="时序数据"><a href="#时序数据" class="header-anchor">#</a> 时序数据</h4> <p>可以把时序数据理解成一个**以时间为轴的矩阵. ** 如下有三个时间序列, 在时间轴上分别对应不同的值.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>^
│     . . . . . . . . . .   node_load1<span class="token punctuation">{</span>host=&quot;host01&quot;<span class="token punctuation">,</span>zone=&quot;bj&quot;<span class="token punctuation">}</span>
│     . . . . . . . . . .   node_load1<span class="token punctuation">{</span>host=&quot;host02&quot;<span class="token punctuation">,</span>zone=&quot;sh&quot;<span class="token punctuation">}</span>
│     . . . . . . . . . .   node_load1<span class="token punctuation">{</span>host=&quot;host11&quot;<span class="token punctuation">,</span>zone=&quot;sh&quot;<span class="token punctuation">}</span>
v
&lt;<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">-</span> 时间 <span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>每一个点称为一个<strong>样本</strong>(sample), 样本由三部分组成.</p> <ul><li><strong>指标(metric)</strong> : metric name 和描述当前样本特征的 labelsets.</li> <li><strong>时间戳(timestamp)</strong> : 一个精确到毫秒的时间戳.</li> <li><strong>值(value)</strong> : 表示该时间样本的值.</li></ul> <p><strong>PromQL 就是对这样一批样本数据做查询和计算操作.</strong></p> <h4 id="promql典型应用场景"><a href="#promql典型应用场景" class="header-anchor">#</a> PromQL典型应用场景</h4> <p>PromQL 典型的应用场景就是时序数据的查询和二次计算, 这也是 PromQL 的两个核心价值, 其中查询操作靠的就是查询选择器, 下面就来详细地看一下.</p> <h5 id="_1-查询选择器"><a href="#_1-查询选择器" class="header-anchor">#</a> 1.查询选择器</h5> <p>随便一个公司, 时序数据至少都有成千上万条, 而每个监控图表的渲染或者每条告警规则的处理, 都只是针对有限的几条数据, 所以  <strong>PromQL 第一个需求就是过滤</strong>. 假设有两个需求, 一是查询上海所有机器 1 分钟的负载, 二是查询所有以 host0 为前缀的机器 1 分钟的负载. PromQL 的写法是怎样的呢? 可以看一下.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># 通过 = 来做 zone 的匹配过滤</span>
node_load1<span class="token punctuation">{</span>zone=&quot;sh&quot;<span class="token punctuation">}</span>
<span class="token comment"># 通过 =~ 来做 host 的正则过滤</span>
node_load1<span class="token punctuation">{</span>host=~&quot;host0.<span class="token important">*&quot;</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><mark><strong>大括号里写过滤条件, 主要是针对标签过滤</strong></mark>, 操作符除了等于号和正则匹配之外, 还有不等于 <code>!=</code>​ 和正则非 <code>!~</code>​. 需要注意的是, metric name 也是一个非常重要的过滤条件, 可以写到大括号里, 比如想同时查看上海机器的 load1, load5, load15 三个指标, 可以对 <code>__name__</code>​, 也就是 <strong>metric 名字做正则过滤</strong>.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">{</span>__name__=~&quot;node_load.<span class="token important">*&quot;</span><span class="token punctuation">,</span> zone=&quot;sh&quot;<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>上面的例子中, 给出的 3 条 PromQL 都叫做<mark><strong>即时查询</strong></mark>​<mark>(Instant Query)</mark>, 返回的内容叫做<strong>即时向量</strong>(Instant Vector).</p> <p><strong>即时查询返回的是当前的最新值</strong>, 比如 10 点整发起的查询, 返回的就是 10 点整这一时刻对应的数据. 但是监控数据是周期性上报的, 并非每时每刻都有数据上报, 10 点整的时候可能恰恰没有数据进来, 此时 Prometheus 就会往前看, 看看 9 点 59, 9 点 58, 9 点 57 等时间点有没有上报数据. 最多往前看多久呢?</p> <p>这个数据由 Prometheus 的启动参数 <code>--query.lookback-delta</code>​ 控制, 这个参数默认是 5 分钟. 从监控的角度来看, 建议调短一些, 比如改成 1 分钟 <code>--query.lookback-delta=1m</code>​. 为什么呢?</p> <p>举个例子来说明一下, 有个客户使用 Telegraf 做 HTTP 探测, 配置了一个告警规则, 说 response_code 连续 3 分钟都不等于 200 才告警. 实际上只有一个数据点的 response_code 不等于200, 过了 3 分钟还是报警了. 这是为什么?</p> <p>实际上, 主要有两个原因, 一是因为 Telegraf 的 HTTP 探测, 会默认把 status code 放到标签里, 这会导致标签非稳态结构(这个行为不太好, 最好是把这类标签直接丢弃掉, 或者使用 categraf, blackbox_exporter 做采集器), 平时 code=200, 出问题的时候 code=500, 在 Prometheus 生态里, <strong>标签变了就是新的时间序列</strong>了.</p> <p>第二个原因就跟 <code>query.lookback-delta</code>​ 有关了, 虽然只有一个点异常, 也就是说 code=500 的这个时间序列只有一个点, 但是告警规则每次执行查询的时候, 都是查到这个异常点, 连续 5 分钟都是如此. 所以就满足了规则里连续 3 分钟才告警的这个条件, 触发了告警. 这就是建议把 <code>--query.lookback-delta</code>​ 调短的原因.</p> <p>除了即时查询, PromQL 中还有一种查询, 叫做<mark><strong>范围查询</strong></mark>​<mark>(Range Query)</mark>, 返回的内容叫做 Range Vector, 比如下面的 PromQL.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">{</span>__name__=~&quot;node_load.<span class="token important">*&quot;</span><span class="token punctuation">,</span> zone=&quot;sh&quot;<span class="token punctuation">}</span><span class="token punctuation">[</span>1m<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>相比即时查询, 范围查询就是<strong>多加了一个时间范围 1 分钟</strong>. <strong>即时查询每个指标返回一个点, 范围查询会返回多个点</strong>. 假设数据 10 秒钟采集一次, 1 分钟有 6 个点, 都会返回.</p> <p><a href="https://prometheus.io/docs/prometheus/latest/querying/functions/" target="_blank" rel="noopener noreferrer">Prometheus 官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 在介绍各个函数的使用方法的时候, 都会讲解<strong>函数参数</strong>, 标明是 Range Vector 还是 Instant Vector, 这两种查询方式是基础知识, 需要牢牢掌握.</p> <p>上面说的就是 PromQL 第一个核心价值---<mark><strong>筛选</strong></mark>. 接下来看 PromQL 的另一个核心价值---<mark><strong>计算</strong></mark>. 计算部分内容比较多, 有算术, 比较, 逻辑, 聚合运算符等, 下面来一一看下.</p> <h5 id="_2-算术运算符"><a href="#_2-算术运算符" class="header-anchor">#</a> 2.算术运算符</h5> <p>算术运算符比较简单, 就是常用的加减乘除, 取模之类的符号. 这里给出了两个例子, 可以结合这两个例子来了解它的应用场景.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># 计算内存可用率, 就是内存可用量除以内存总量, 又希望按照百分比呈现, 所以最后乘以100</span>
mem_available<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> / mem_total<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> * 100
<span class="token comment"># 计算北京区网口出向的速率, 原始数据的单位是byte, 网络流量单位一般用bit, 所以乘以8</span>
irate(net_sent_bytes_total<span class="token punctuation">{</span>zone=&quot;beijing&quot;<span class="token punctuation">}</span><span class="token punctuation">[</span>1m<span class="token punctuation">]</span>) * 8
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h5 id="_3-比较运算符"><a href="#_3-比较运算符" class="header-anchor">#</a> 3.比较运算符</h5> <p>比较运算符就是大于, 小于, 等于, 不等于之类的, 理解起来也比较简单, 但是意义重大, <mark><strong>告警规则的逻辑就是靠比较运算符来支撑的</strong></mark>. 这里也举两个例子, 结合下面的例子来理解会更容易.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>mem_available<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> / mem_total<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> * 100 &lt; 20
irate(net_sent_bytes_total<span class="token punctuation">{</span>zone=&quot;beijing&quot;<span class="token punctuation">}</span><span class="token punctuation">[</span>1m<span class="token punctuation">]</span>) * 8 / 1024 / 1024 <span class="token punctuation">&gt;</span> 700
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>带有比较运算符的 PromQL 就是告警规则的核心, 比如内存可用率的告警, 在 Prometheus 中可以这样配置</strong>.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">groups</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> host
  rules<span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">alert</span><span class="token punctuation">:</span> MemUtil
    expr<span class="token punctuation">:</span> mem_available<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> / mem_total<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> * 100 &lt; 20
    for<span class="token punctuation">:</span> 1m
    labels<span class="token punctuation">:</span>
      severity<span class="token punctuation">:</span> warn
    annotations<span class="token punctuation">:</span>
      summary<span class="token punctuation">:</span> Mem available less than 20%<span class="token punctuation">,</span> host<span class="token punctuation">:</span><span class="token punctuation">{</span><span class="token punctuation">{</span> $labels.ident <span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>例子中的 <strong>expr 指定了查询用的 PromQL</strong>. 告警引擎会根据用户的配置, 周期性地执行查询. 如果查不到就说明一切正常, 没有机器的内存可用率低于 20%. 如果查到了, 就说明触发了告警, 查到几条就触发几条告警. 当然偶尔一次低于 20% 不是什么大事, 只有连续 1分钟每次查询都低于 20% 才会告警, 这就是 <code>for: 1m</code>​ 存在的意义.</p> <h5 id="_4-逻辑运算符"><a href="#_4-逻辑运算符" class="header-anchor">#</a> 4.逻辑运算符</h5> <p>逻辑运算符有 3 个, <mark><strong>and, or 和 unless</strong></mark>, 用于 instant-vector 之间的运算. <strong>and 是求交集, or 是求并集, unless 是求差集</strong>.</p> <p>来看一个 and 的使用场景.</p> <p>关于磁盘的使用率问题, 有的分区很大, 比如 16T, 有的分区很小, 比如 50G, 像这种情况如果只是用磁盘的使用率做告警就不太合理, 比如 <code>disk_used_percent{app=&quot;clickhouse&quot;} &gt; 70</code>​ 表示磁盘使用率大于 70% 就告警. 对于小盘, 这个策略是合理的, 但对于大盘, 70% 的使用率表示还有非常多的空间, 就不太合理. 这时希望给这个策略加一个限制, 只有小于 200G 的硬盘在使用率超过 70% 的时候, 才需要告警, 这时就可以使用 and 运算符, 可以看一下最终 PromQL.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>disk_used_percent<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span> <span class="token punctuation">&gt;</span> 70 and disk_total<span class="token punctuation">{</span>app=&quot;clickhouse&quot;<span class="token punctuation">}</span>/1024/1024/1024 &lt; 200
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>算术, 比较, 逻辑运算符, 基本的使用方式比较简单, 但如果运算符两侧的向量标签不统一, 就会面临一些更复杂的处理逻辑, 需要在 PromQL 中给出<strong>向量匹配规则</strong>, 下面就来一起看一下.</p> <h5 id="_5-向量匹配"><a href="#_5-向量匹配" class="header-anchor">#</a> 5.向量匹配</h5> <p><strong>向量之间的操作是想要在右侧的向量中, 为左侧向量的每个条目找到一个匹配的元素, 匹配行为分为: one-to-one, many-to-one, one-to-many</strong>. 刚才介绍的磁盘使用率的例子, 就是典型的 one-to-one 类型, 左右两侧的指标, 除了指标名, 其余标签都是一样的, 非常容易找到对应关系. 但是有时候希望用 and 求交集, 但是两侧向量标签不同, 怎么办呢?</p> <p>此时可以使用关键字 <strong>on</strong> 和 <strong>ignoring</strong> 来限制用于做匹配的标签集.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>mysql_slave_status_slave_sql_running == 0
and ON (instance)
mysql_slave_status_master_server_id &gt; 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这个 PromQL 想表达的意思是如果这个 MySQL 实例是个 slave(master_server_id&gt;0), 就检查其 slave_sql_running 的值, 如果 slave_sql_running==0, 就表示 slave sql 线程没有在运行.</p> <p>但 mysql_slave_status_slave_sql_running 和 mysql_slave_status_master_server_id 这两个 metric 的标签, 可能并非完全一致. 不过好在二者都有个 instance 标签, 且相同的 instance 标签的数据从语义上来看就表示一个实例的多个指标数据, 那就可以用关键字 on 来指定只使用 instance 标签做匹配, 忽略其他标签.</p> <p>与 on 相反的是关键字 ignoring, 顾名思义, ignoring 是忽略掉某些标签, 用剩下的标签来做匹配. 拿 Prometheus 文档中的例子来说明.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>## example series
method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;500&quot;}  24
method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;404&quot;}  30
method_code:http_errors:rate5m{method=&quot;put&quot;, code=&quot;501&quot;}  3
method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;500&quot;} 6
method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;404&quot;} 21
method:http_requests:rate5m{method=&quot;get&quot;}  600
method:http_requests:rate5m{method=&quot;del&quot;}  34
method:http_requests:rate5m{method=&quot;post&quot;} 120

## promql
method_code:http_errors:rate5m{code=&quot;500&quot;}
/ ignoring(code)
method:http_requests:rate5m

## result
{method=&quot;get&quot;}  0.04            //  24 / 600
{method=&quot;post&quot;} 0.05            //   6 / 120
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>例子里都是 one-to-one 的对应关系, 这个好理解. 难理解的是 one-to-many 和 many-to-one, 这种情况下, 做指标运算时就要借助关键字 <strong>groupleft 和 groupright</strong> 了. left, right 指向高基数那一侧的向量. 还是用上面method_code:http_errors:rate5m 和 method:http_requests:rate5m 这两个指标来举例, 可以看一下使用 group_left  的 PromQL 和输出的结果.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>## promql
method_code:http_errors:rate5m
/ ignoring(code) group_left
method:http_requests:rate5m

## result
{method=&quot;get&quot;, code=&quot;500&quot;}  0.04            //  24 / 600
{method=&quot;get&quot;, code=&quot;404&quot;}  0.05            //  30 / 600
{method=&quot;post&quot;, code=&quot;500&quot;} 0.05            //   6 / 120
{method=&quot;post&quot;, code=&quot;404&quot;} 0.175           //  21 / 120
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>比如针对 <code>method=&quot;get&quot;</code>​ 的条目, 右侧的向量中只有一个记录, 但是左侧的向量中有两个记录, 所以高基数的一侧是左侧, 故而使用 group_left.</p> <p>这里再举一个例子, 来说明 group_left, group_right 的一个常见用法. 比如使用 kube-state-metrics 来采集 Kubernetes 各个对象的指标数据, 其中针对 pod 有个指标是 kube_pod_labels, 该指标会把 pod 的一些信息放到标签里, 指标值是 1, 相当于一个元信息.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>kube_pod_labels{
[...]
  label_name=&quot;frontdoor&quot;,
  label_version=&quot;1.0.1&quot;,
  label_team=&quot;blue&quot;
  namespace=&quot;default&quot;,
  pod=&quot;frontdoor-xxxxxxxxx-xxxxxx&quot;,
} = 1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>假设某个 Pod 是接入层的, 统计了很多 HTTP 请求相关的指标, 想统计 5xx 的请求数量, 希望能按 Pod 的 version 画一个饼图. 这里有个难点: 接入层的请求类指标没有 version 标签, version 信息只出现在 kube_pod_labels 里, 那怎么让二者联动呢? 如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>sum(
  rate(http_request_count{code=~&quot;^(?:5..)$&quot;}[5m])) by (pod)
*
on (pod) group_left(label_version) kube_pod_labels
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>把这个 PromQL 掰开揉碎, 看一下具体的意思, 乘号前面的部分, 是一个统计每秒 5xx 数量的典型语法, 按照 pod 维度做分组统计.</p> <p>然后乘以 kube_pod_labels, 这个值是 1. 任何值乘以 1 都是原来的值, 所以对整体数值没有影响, 而 kube_pod_labels 有多个标签, 而且和 sum 语句的结果向量的标签不一致, 所以通过 on(pod) 语法来指定只按照 pod 标签来建立对应关系.</p> <p>最后, 利用 group_left(label_version), 把 label_version 附加到了结果向量里, 高基数的部分显然是 sum 的部分, 所以使用 group_left 而非 group_right.</p> <h5 id="_6-聚合运算"><a href="#_6-聚合运算" class="header-anchor">#</a> 6.聚合运算</h5> <p>除了前面说的查询需求外, 针对单个指标的多个 series, 还会有一些<strong>聚合需求</strong>. 比如说想查看 100 台机器的平均内存可用率, 或者想要排个序, 取数值最小的 10 台. 这种需求可以使用 PromQL <strong>内置的聚合函数</strong>来实现.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code># 求取 clickhouse 的机器的平均内存可用率
avg(mem_available_percent{app=&quot;clickhouse&quot;})

# 把 clickhouse 的机器的内存可用率排个序, 取最小的两条记录
bottomk(2, mem_available_percent{app=&quot;clickhouse&quot;})
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>另外, 有时会有<strong>分组统计</strong>的需求, 比如想分别统计 clickhouse 和 canal 的机器内存可用率, 可以<strong>使用关键字 by 指定分组统计的维度(与 by 相反的是 without)</strong> .</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>avg(mem_available_percent{app=~&quot;clickhouse|canal&quot;}) by (app)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>注意: 这些聚合运算, 可以理解为 <mark><strong>纵向拟合</strong></mark>. 可以想象一下, 100 台机器的内存可用率, 在折线图上有 100 条线, 如果想要把这 100 条线拟合成一条线, 就相当于把每个时刻的 100 个点拟合成 1 个点. 那怎么让 100 个点变成 1 个点呢? 求个平均值或最大值之类的, 就可以实现, 所以就有了这些聚合运算符.</p> <p>还有一类聚合运算函数, 可以看作是 <strong>横向拟合</strong>, 也就是 <code>&lt;aggregation&gt;_over_time</code>​ 类的函数. 这些函数接收范围向量, 因为范围向量是一个时段内有多个值, <code>&lt;aggregation&gt;</code>​ 就是对这多个值做运算.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>max_over_time(target_up[2m])
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>target_up 指标后面加了 [2m], 指的就是获取这个指标最近 2 分钟的所有数据点, 如果 15 秒采集一个点, 2 分钟就是 8 个点, max_over_time 就是对这 8 个点求最大值, 相当于对各个时间序列做横向拟合.</p> <h4 id="容易误解的函数"><a href="#容易误解的函数" class="header-anchor">#</a> 容易误解的函数</h4> <p>除了上面说的这些常用的聚合函数外, Prometheus 还内置了很多其他函数, 其中用得最广并且最容易被人误解的是 increase 和 rate 函数, 这里讲一讲这两个函数.</p> <p>先来看 <strong>increase</strong> 函数, 字面意思上表示求取一个增量, 接收一个 range-vector, range-vector 显然是会返回多个 value+timestamp 的组合. 直观地理解就是, 直接把时间范围内的最后一个值减去第一个值, 不就可以得到增量了吗? 非也!</p> <p><img src="/img/5fe64d3408bba9b26b88f556865b2983-20230719203435-laot7e5.png" alt="图片"></p> <p>可以看一下这张图, 图里的一些关键信息, 这里摘录成了文本, 可以看一下.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>promql: net_bytes_recv{interface=&quot;eth0&quot;}[1m] @ 1661570908
965304237246 @1661570850
965307953982 @1661570860
965311949925 @1661570870
965315732812 @1661570880
965319998347 @1661570890
965323899880 @1661570900

promql: increase(net_bytes_recv{interface=&quot;eth0&quot;}[1m]) @1661570909
23595160.8
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>监控数据是 10 秒上报一次, 所以虽然两次 PromQL 查询时间不同, 一次是 1661570908, 一次是 1661570909, 但是所查询的原始数据内容是一样的, 就是 1661570850~1661570900 这几个时间点对应的数据.</p> <p>直观上理解, 在这几个时间点对应的数据上求取 increase, 无非就是最后一个值减去第一个值, 即 965323899880-965304237246=19662634. 不过很遗憾, 实际结果是 23595160.8, 差别有点大, 显然这个直观理解的算法是错的.</p> <p>实际上, <strong>increase 这个 PromQL 发起请求的时间是 1661570909, 时间范围是 [1m], 相当于告诉 Prometheus, 需要查询1661570849(由 1661570909-60 得出)~1661570909 之间的 increase 数值</strong>. 但是原始监控数据并没有 1661570849, 1661570909 这两个时刻的数值, 怎么办呢?</p> <p>Prometheus 只能<strong>基于现有的数据</strong>做外推, 也就是使用最后一个点的数值减去第一个点的数值, 得到的结果除以时间差, 再乘以 60.</p> <p>$$
(965323899880.0-965304237246.0)\div(1661570900.0-1661570850.0)\times60=23595160.8
$$</p> <p>这样最终就得到了 1 分钟的 increase 值, 是个小数.</p> <p>再说一下 rate 函数, increase 函数是求取的时间段内的增量, 而且有数据外推, rate 函数则求取的是每秒变化率, 也有数据外推的逻辑, <strong>increase 的结果除以 range-vector 的时间段的大小</strong>, 就是 rate 的值. 用下面的 PromQL 验证一下.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>rate(net_bytes_recv{interface=&quot;eth0&quot;}[1m])
== bool
increase(net_bytes_recv{interface=&quot;eth0&quot;}[1m])/60.0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这里 == 后面跟了一个 bool 修饰符, 表示希望返回一个 bool 值, 如果是 True 就会返回 1, 如果是 False 就返回 0. 观察结果后发现, 这个表达式永远都会返回 1, 即等号前后的两个 PromQL 语义上是相同的.</p> <p><strong>rate 函数求取的变化率, 相对平滑</strong>. 因为<strong>是拿时间范围内的最后一个值和第一个值做数据外推, 一些毛刺现象就会被平滑掉</strong>. 如果想要得到更敏感的数据, 可以使用 irate 函数. irate 是拿时间范围内的最后两个值来做计算, 变化就会更剧烈, 拿网卡入向流量这个指标来做个对比.</p> <p><img src="/img/68ac7b49091b60970b9a8f8a106500c3-20230719203435-55cibpc.png" alt="图片"></p> <p>蓝色的变化得更剧烈的线是用 irate 函数计算得到的, 而紫色的相对平滑的线是用 rate 函数计算得到的, 对比还是很强烈的.</p> <h4 id="小结-5"><a href="#小结-5" class="header-anchor">#</a> 小结</h4> <p>这一讲以实际场景为出发点, 介绍了不同场景下如何使用 PromQL.</p> <p>重点讲解了 PromQL 的两个核心价值, 一个是筛选, 一个是计算. 筛选是靠查询选择器, 查询分为即时查询和范围查询. 计算部分内容较多, 有算术, 比较, 逻辑, 聚合运算符, 还有向量匹配逻辑, 特别是 group_left 和 group_right, 比较难理解, 需要仔细推敲.</p> <p>函数部分比较重要的是 increase 和 rate, 其实 histogram_quantile 也很常用而且比较难理解, 不过在前面中已经介绍过 histogram_quantile 的计算逻辑了, 这里就不再重复.</p> <p><img src="/img/6075e00c54589543091e7e15yy04a43e-20230719203435-5k5riuc.jpg" alt=""></p> <h3 id="_7-如何解决prometheus的存储容量问题"><a href="#_7-如何解决prometheus的存储容量问题" class="header-anchor">#</a> 7.如何解决Prometheus的存储容量问题?</h3> <p>前几讲介绍了 Prometheus 的关键设计, 这些设计都非常优秀. 在云原生监控领域, 有不可撼动的江湖地位, 那这样说来 Prometheus 是不是就没有缺点了呢? 是否可以满足所有使用场景呢? 显然也不是.</p> <p>一个软件如果什么问题都想解决, 就会导致什么问题都解决不好. 所以 Prometheus 也存在一些不足之处, 其中一个广受诟病的问题就是 <mark><strong>单机存储不好扩展</strong></mark>. 所以这一讲就针对这个问题来聊聊如何扩展 Prometheus 的存储.</p> <h4 id="所有场景都需要扩展容量吗"><a href="#所有场景都需要扩展容量吗" class="header-anchor">#</a> 所有场景都需要扩展容量吗?</h4> <p>虽然聊的是 Prometheus 容量扩展问题, 不过必须先说明一点, 大部分场景其实不需要扩展, 因为一般的数据量压根达不到 Prometheus 的容量上限. <strong>很多中小型公司使用单机版本的 Prometheus 就足够了, 这个时候不要想着去扩展, 容易过度设计, 引入架构上的复杂度问题</strong>.</p> <p>Prometheus 单机容量上限是多少? 根据经验, <strong>每秒接收 80 万个数据点, 算是一个比较健康的上限</strong>, 一开始也无需用一台配置特别高的机器, 随着数据量的增长, 可以再升级硬件的配置. 当然如果想要硬件方便升配, 就需要借助虚拟机或容器, 同时需要使用分布式块存储.</p> <p>每秒接收 80 万个数据点是个什么概念呢? 每台机器每个周期大概采集 200 个系统级指标, 比如 CPU, 内存, 磁盘等相关的指标. 假设采集频率是 10 秒, 平均每秒上报 20 个数据点, 可以支持同时监控的机器量是 4 万台.</p> <p>$$
800000\div20=40000
$$</p> <p>可以看出, 每秒接收 80 万数据点, 其实是一个很大的容量了. 当然如果使用 node-exporter, 指标数量要多于 200, 800 左右, 那也能支持 1 万台机器的监控.</p> <p>不过刚刚只计算了机器监控数据, 如果还要用这个 Prometheus 监控各类中间件, 那就得再做预估计算了. 有些中间件会吐出比较多的指标, 有些指标其实用处不大, 可以丢掉(drop), 当然这就是另一个话题了, 后面监控实战部分会详细讲解, 这里暂不展开.</p> <p>如果单个 Prometheus 实在是扛不住, 也可以<strong>拆成多个 Prometheus, 根据业务或者地域来拆</strong>都是可以的, 这就是下面要介绍的 <strong>Prometheus 联邦机制</strong>.</p> <h4 id="prometheus-联邦机制"><a href="#prometheus-联邦机制" class="header-anchor">#</a> Prometheus 联邦机制</h4> <p>联邦机制可以理解为是 Prometheus <strong>内置支持的一种集群方式</strong>, 核心就是 Prometheus 数据的<strong>级联抓取</strong>. 比如某公司有 8 套 Kubernetes, 每套 Kubernetes 集群都部署了一个 Prometheus, 这 8 个 Prometheus 就形成了 8 个数据孤岛, 没法在一个地方看到 8 个 Prometheus 的数据.</p> <p>当然, 用 Grafana 或 Nightingale, 把这 8 个 Prometheus 作为数据源接入, 然后就可以在一个 Web 上通过<strong>切换数据源</strong>的方式查看不同的数据了, 但本质还是分别查看, <strong>没法做多个 Prometheus 数据的联合运算</strong>.</p> <p>而<strong>联邦机制, 一定程度上就可以解决这个问题, 把不同的 Prometheus 数据聚拢到一个中心的 Prometheus 中,</strong>  架构大体如下.</p> <p><img src="/img/f40db5919edc384c17fc2e148c2ayy53-20230719203435-touh3q5.png" alt="图片"></p> <p>原本一个 Prometheus 解决不了的问题, 拆成了多个, 然后又把多个 Prometheus 的数据聚拢到中心的 Prometheus 中. 但是, 中心的 Prometheus 仍然是个瓶颈. 所以在联邦机制中, 中心端的 Prometheus 去抓取边缘 Prometheus 数据时, 不应该把所有数据都抓取到中心, 而是应该 <mark><strong>只抓取那些需要做聚合计算或其他团队也关注的指标</strong></mark>, 大部分数据还是应该下沉在各个边缘 Prometheus 内部消化掉, 不然中心端的 Prometheus 也顶不住.</p> <p>怎么做到只抓取特定的指标到中心端呢? 通过 <code>match[]</code>​ 参数, 指定过滤条件就可以实现, 下面是中心 Prometheus 的抓取规则.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">scrape_configs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'federate'</span>
    scrape_interval<span class="token punctuation">:</span> 30s
    honor_labels<span class="token punctuation">:</span> <span class="token boolean important">true</span>
    metrics_path<span class="token punctuation">:</span> <span class="token string">'/federate'</span>
    params<span class="token punctuation">:</span>
      'match<span class="token punctuation">[</span><span class="token punctuation">]</span>'<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token string">'{__name__=~&quot;aggr:.*&quot;}'</span>
    static_configs<span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token string">'10.1.2.3:9090'</span>
        <span class="token punctuation">-</span> <span class="token string">'10.1.2.4:9090'</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>边缘 Prometheus 会在 <code>/federate</code>​ 接口暴露监控数据, 所以设置了metrics_path, honor_labels 设置为 true, 意思是在标签重复时, 以源数据的标签为准. 过滤条件中通过正则匹配过滤出所有 <code>aggr:</code>​ 打头的指标, 这类指标都是通过 Recoding Rules 聚合出来的关键指标. 当然, 这是假设的一个规范.</p> <p><mark><strong>联邦这种机制可以落地的核心要求是, 边缘 Prometheus 基本消化了绝大部分指标数据</strong></mark>, 比如告警, 看图等, 都在边缘的 Prometheus 上搞定了. 只有少量数据, 比如需要做聚合计算或其他团队也关注的指标, 被拉到中心, 这样就不会触达中心端 Prometheus 的容量上限. 这就要求公司在使用 Prometheus 之前先做好规划, 建立规范. 说实话可能实施起来会有点儿难, 所以更推荐下面的远程存储方案.</p> <h4 id="远程存储方案"><a href="#远程存储方案" class="header-anchor">#</a> 远程存储方案</h4> <p>默认情况下, Prometheus 收集到监控数据之后是<strong>存储在本地</strong>, 在本地查询计算. 由于单机容量有限, 对于海量数据场景, 需要有其他解决方案. 最直观的想法就是: <strong>既然本地搞不定, 那就在远端做一个集群, 分治处理</strong>.</p> <p>Prometheus 本身不提供集群存储能力, 可以复用其他时序库方案. 时序库挺多的, 如果挨个儿去对接比较费劲, 于是 Prometheus 建立了统一的 <strong>Remote Read</strong>, Remote Write 接口协议, 只要满足这个接口协议的时序库都可以对接进来, 作为 Prometheus remote storage 使用.</p> <p>目前国内使用最广泛的远程存储主要是 <strong>VictoriaMetrics 和 Thanos</strong>. 下面简单介绍一下.</p> <h5 id="_1-victoriametrics"><a href="#_1-victoriametrics" class="header-anchor">#</a> 1.VictoriaMetrics</h5> <p>VM 虽然可以作为 Prometheus 的远程存储, 但它志不在此. VM 是希望成为一个更好的 Prometheus, 所以它不只是时序库, 它还有抓取器, 告警等各个组件, 体系非常完备, 不过现在国内基本上还只是把它当做时序库在用.</p> <p>VM 作为时序库, 核心组件只有 3 个, vmstorage, vminsert 和 vmselect. 其中 vmstorage 用于存储时序数据, vminsert  用于接收时序数据并写入到后端的 vmstorage, Prometheus 使用 Remote Write 对接的就是 vminsert 的地址, vmselect 用于查询时序数据, 它没有实现 Remote Read接口, 反倒实现了 Prometheus 的 Querier 接口. 这是为什么呢?</p> <p>因为 VM 觉得 Remote Read 设计太挫了, 性能不好, 还不如直接实现 Querier 接口. 这样设计的话, Grafana 这类前端应用直接可以和 vmselect 对接, 而不用在中间加一层 Prometheus, 可以看一下 VM 的架构.</p> <p><img src="/img/0056079fe57dde7d00e03355b35765e8-20230719203435-pns7cud.png" alt="图片"></p> <p>n9e-webapi 和 n9e-server 是 Nightingale 的两个模块, 都可以看做 VM 的上层应用. 通过这张图片, 可以比较清楚地看出 VM 的架构以及与上层应用的交互方式.</p> <p>n9e-webapi 通过 vmselect 查询时序数据, vmselect 是无状态模块, 可以水平扩展, 通常部署多个实例, 前面架设负载均衡, 所以 n9e-webapi 通常是对接 vmselect 的负载均衡. n9e-server 也有一些查询VM的需求, 先不用关注, 重点关注 Remote Write 那条线, n9e-server 通过 Remote Write 协议, 把数据转发给 vminsert 的负载均衡, vminsert 也是无状态的, 可以水平扩展.</p> <p>vmstorage 是存储模块, 可以部署多个组成集群, 只要把所有 vmstorage 的地址告诉 vmselect 和 vminsert, 整个集群就跑起来了, 非常简单.</p> <p>问题是数据通过 vminsert 进来之后, 如何分片? vmselect 和 vminsert 之间没有任何关系, vmselect 在查询具体某个指标数据的时候, 怎么知道数据位于哪个 vmstorage 呢? 这个架构虽然看起来简单, 但总感觉跟常见的分布式系统不太一样呢.</p> <p>主要是因为 VM 采用了一种叫做 merge read 的方案, 一个查询请求发给 vmselect 之后, vmselect 会向所有的 vmstorage 发起查询请求. 注意, 是所有的 vmstorage, 然后把结果合并在一起, 返回给前端. 所以 vmselect 压根就不用关心数据位于哪个 vmstorage. 此时 vminsert 用什么分片算法都无所谓了, 数据写到哪个 vmstorage 都行, 反正最后都会 merge read.</p> <p>这个奇葩设计, 看起来还挺有效的. 有没有问题呢? 显然是有的, 就是 vmstorage 集群<strong>不能太大</strong>. 如果有几千个节点, 随便一个查询过来, vmselect 都会向所有 vmstorage 发起查询, 任何一个节点慢了都会拖慢整体速度, 这就让人无法接受了. 一般来讲, 一个 vmstorage 集群, 有一二十个节点还是比较健康的, 这个容量就已经非常大了, 能满足大部分公司的需求, 所以这不是个大问题.</p> <p>个人比较建议在选型远程存储的时候使用 <strong>VictoriaMetrics</strong>, 架构简单, 更有掌控力. 像 M3 虽然容量比 VM 大得多, 但是架构复杂, 出了问题反而无从着手, 不建议使用.</p> <p>在 Prometheus 存储问题的解决方案中, 除了 VM, 还有一个影响力比较大的就是 Thanos, 也就是传说中的灭霸.</p> <h5 id="_2-thanos"><a href="#_2-thanos" class="header-anchor">#</a> 2.Thanos</h5> <p>Thanos 的做法和 VM 不同, Thanos 完全拥抱 Prometheus, 对 Prometheus 做了一个<strong>增强</strong>, 核心特点是使用 <strong>对象存储</strong> 做海量时序存储. 架构图如下.</p> <p><img src="/img/cfbc6d548944f7b169bc469255e1ea4d-20230719203435-y9jq7ak.png" alt="图片"></p> <p>这个架构图初看起来比较复杂, <strong>黄色部分是 Prometheus 自身, 蓝色部分是Thanos, 黑色部分是存储</strong>. 这里边有几个核心点.</p> <ol><li>每个 Prometheus 都要伴生一个 Thanos Sidecar 组件, 这个组件有两个作用, 一是响应 Thanos Query 的查询请求, 二是把 Prometheus 产生的块数据上传到对象存储.</li> <li>Thanos Sidecar 调用 Prometheus 的接口查询数据, 暴露为 StoreAPI, Thanos Store Gateway 调用对象存储的接口查询数据, 也暴露为 StoreAPI. Thanos Query 就可以从这两个地方查询数据了, 相当于近期数据从 Prometheus 获取, 比较久远的数据从对象存储获取.</li></ol> <p>虽然对象存储比较廉价, 但这个架构看起来还是过于复杂了, 没有 VM 看起来干净. 另外这个架构是<strong>和 Prometheus 强绑定</strong>的, 没法用作单独的时序存储, 比较遗憾. 不过好在 Thanos 还有另一种方案, 不用 Sidecar, 使用 Receive 模块, 来接收 Remote Write 协议的数据, 写入本地, 同时上传对象存储, 看一下这个架构.</p> <p><img src="/img/25a79b6dfeeaf07e41810f283057d128-20230719203435-6hbdmz9.png" alt="图片"></p> <p>从存储角度来看, 这个架构和 Prometheus 就没有那么强的绑定关系了, 可以<strong>单独用作时序库</strong>. 关键点还是对象存储, 虽然对象存储是海量, 廉价的, 但是延迟较高, 而且一个请求拆成两部分, 一部分查本地, 一部分查对象存储, 也没有那么可靠.</p> <p>相比日志之类的数据, 指标数据的体量较小, 一般存储 3 个月就够了, 所以对象存储的优势就显得没那么大了. 如果是我来选型, VictoriaMetrics 和 Thanos 之间, 我会选择前者.</p> <p>所谓的远程存储方案, 核心就是 Remote Read/Write, 其实 Prometheus 自身也可以被别的 Prometheus 当做 Remote storage, 只要开启 <code>--enable-feature=remote-write-receiver</code>​ 这个参数即可. 下面来看一下 Prometheus 自身怎么来搭建集群.</p> <h4 id="prometheus自身搭建集群"><a href="#prometheus自身搭建集群" class="header-anchor">#</a> Prometheus自身搭建集群</h4> <p>废话不多说, 直接上架构图.</p> <p><img src="/img/71d8011b147069ac5e477086bd954da0-20230719203435-eu5s8s8.jpg" alt="图片"></p> <p>**图上有三个 Prometheus 进程, 有两个用作存储, 有一个用作查询器, 用作查询器的 Prometheus 通过 Remote Read 的方式读取后端多个 Prometheus 的数据, 通过几行 remote_read 的配置就能实现. **</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">remote_read</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">url</span><span class="token punctuation">:</span> <span class="token string">&quot;http://prometheus01:9090/api/v1/read&quot;</span>
    read_recent<span class="token punctuation">:</span> <span class="token boolean important">true</span>
  <span class="token punctuation">-</span> <span class="token key atrule">url</span><span class="token punctuation">:</span> <span class="token string">&quot;http://prometheus02:9090/api/v1/read&quot;</span>
    read_recent<span class="token punctuation">:</span> <span class="token boolean important">true</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>Prometheus 的 remote_read 也是 merge read, 跟 vmselect 逻辑类似. 不过 VM 集群是有副本机制的, 使用 Prometheus 来做集群, 不太好做副本. 当然可以粗暴地为每个分片数据部署多份采集器和 PromTSDB, 也基本可以解决高可用的问题.</p> <p>在实际生产环境中, 如果所有数据都是通过拉的方式来收集, 这种架构也是可以尝试的, 不过大部分企业都是推拉结合, 甚至推是主流, Remote Write 到一个统一的时序库集群, 是一个更加顺畅的方案.</p> <h4 id="小结-6"><a href="#小结-6" class="header-anchor">#</a> 小结</h4> <p>这一讲重点关注了 Prometheus 生态常见的存储扩展问题, 并给出了 3 种集群解决方案.</p> <ul><li><strong>Prometheus 联邦集群</strong>: 按照业务或者地域, 拆成多个边缘Prometheus, 然后在中心搭建一个 Prometheus, 把一些重要的多团队关注的指标或需要二次计算的指标拉到中心.</li> <li><strong>远程存储方案</strong>: 通过 Remote Read/Write 协议, Prometheus 可以和第三方存储对接, 把存储的难题抛给了第三方来解决, 常用方案是 M3DB, VictoriaMetrics, Thanos. 最推荐的是 <strong>VictoriaMetrics</strong>, 架构简单, 更可控一些.</li> <li><strong>Prometheus 自身搭建集群</strong>: 也是利用了 Remote Read/Write 机制, 只是把存储换成了多个 Prometheus, 对于全部采用拉模型抓取数据的公司, 是可以考虑的方案.</li></ul> <p><mark><strong>这三种方案很好地解决了 Prometheus 的存储问题, 可以根据实际情况来选用. 但还是要注意一点, 不要做过度设计. 如果数据量不大, 就无需搭建时序集群, 徒增维护成本.</strong></mark></p> <p>本节的思维导图:</p> <p><img src="/img/5ae33622ee24e67036ffe9dae1e92594-20230719203435-l4g0t5c.jpg" alt=""></p> <h3 id="_8-如何用nightingale解决prometheus的告警管理问题"><a href="#_8-如何用nightingale解决prometheus的告警管理问题" class="header-anchor">#</a> 8.如何用Nightingale解决Prometheus的告警管理问题?</h3> <p>这一讲继续关注 Prometheus 的另一个问题---<strong>告警管理</strong>.</p> <p><strong>Prometheus 的告警规则, 记录规则都是采用配置文件的方式管理的</strong>, 非常适合奉行 Infrastructure as Code 的公司或团队内部使用. 但如果要把监控能力开放给全公司, 就需要有较好的支持协同操作的 UI, 让各个团队互不干扰的同时共享一些通用的成果.</p> <p>解决这个需求的开源产品, 有两款备选, <strong>一个是 Grafana, 另一个是夜莺(Nightingale)</strong> . Grafana 擅长可视化, 是监控绘图领域事实上的标准, 而夜莺的侧重点是告警管理, 所以这一讲重点来介绍一下夜莺, **可以通过夜莺搭建公司级的监控系统, 把监控告警能力赋予公司所有的团队. **</p> <h4 id="夜莺简介"><a href="#夜莺简介" class="header-anchor">#</a> 夜莺简介</h4> <p>夜莺最初是滴滴开源的, 之后捐赠给了中国计算机学会开源发展委员会(CCF ODC), 目标是整合云原生开源生态的众多能力, 为用户提供开箱即用, 一体化全方位的云原生监控解决方案.</p> <p>注: <a href="https://github.com/ccfos/nightingale" target="_blank" rel="noopener noreferrer">夜莺的GitHub地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://n9e.github.io/" target="_blank" rel="noopener noreferrer">文档地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>先来看一下夜莺的架构, 对夜莺的工作模式有个基本的认识.</p> <p><img src="/img/41a846502810df2e0dyyac2a4yy978f9-20230719203435-mme8eph.png" alt="图片"></p> <p>左下角 Agents 表示监控数据采集器, 夜莺可以对接多种 Agent, 比如 Categraf, Telegraf, Grafana-Agent, Datadog-Agent. 这些 Agent 都是 <strong>PUSH 模型, 周期性采集监控数据, 然后推给 Server 的 HTTP 接口</strong>.</p> <p>Server 接收到数据之后, 会通过 Remote Write 协议把数据转发给<strong>时序库</strong>, 这里时序库使用的是 Prometheus, Prometheus 要想接收 Remote Write 协议的数据, 需要在启动参数中开启 <code>--enable-feature=remote-write-receiver</code>​. 除了Prometheus, 也可以使用 M3DB, VictoriaMetrics, Thanos 等作为时序库.</p> <p>Server 的职能相当于一个 <strong>Pushgateway</strong>, 同时也是一个<strong>告警引擎</strong>, 它会周期性地从 MySQL 中同步告警规则, 做规则判断生成告警事件并发送, 对标 Prometheus 的告警引擎和 Alertmanager 模块. Server 还会往 Redis 发送心跳信息, 不过后面的版本有计划下掉 Redis, 直接使用 MySQL 处理心跳.</p> <p>Webapi 模块提供 HTTP 接口, 与前端 JavaScript 交互, 主要有两个功能, 一个是响应管理请求, 比如告警规则, 屏蔽规则, 监控大盘的增删改查; 一个是响应时序数据查询, 作为一个 Proxy 把请求转发给后面的时序库, 等时序库返回结果之后再转发给前端.</p> <p>如果有些监控数据是使用 Exporter 采集的, 就需要 PULL 模型的采集支持. 通常有 3 种做法, 一种是直接使用 Prometheus 本身, 配置 Scrape 规则; 也可以单独部署一个 agent mode 模式的 Prometheus 作为抓取器, 和时序库的职能做进程级别的拆分; 还可以使用其他支持 PULL 模式的抓取器, 比如 Categraf, Grafana-Agent.</p> <h4 id="部署夜莺"><a href="#部署夜莺" class="header-anchor">#</a> 部署夜莺</h4> <p>了解了夜莺的架构之后, 下面简单聊一下如何部署夜莺, 最简单的方式是使用 <strong>Docker compose</strong>, 一行命令就能搞定.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>git clone https<span class="token punctuation">:</span>//github.com/ccfos/nightingale.git
cd docker
docker<span class="token punctuation">-</span>compose up <span class="token punctuation">-</span>d
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>浏览器访问 nwebapi 提供的 18000 端口就能看到登录页面, 默认用户是 root, 默认密码是 root.2020.</p> <p>如果对 Kubernetes 和 Helm 比较熟悉, 也可以采用 <a href="https://n9e.github.io/docs/install/helm/" target="_blank" rel="noopener noreferrer">Helm 的方式部署<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 当然最常用的实际是 <a href="https://n9e.github.io/docs/install/server/" target="_blank" rel="noopener noreferrer">二进制的方式部署<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>服务端部署完成之后, 可以采集一些监控数据看看真实效果, 推荐 <a href="https://n9e.github.io/docs/agent/categraf/" target="_blank" rel="noopener noreferrer">安装 Categraf<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 当然, 因为夜莺支持多种采集器, 也可以使用其他自己熟悉的采集器. 安装完成之后, 来看一下夜莺具体是如何管理告警的.</p> <h4 id="告警管理"><a href="#告警管理" class="header-anchor">#</a> 告警管理</h4> <p><strong>Prometheus 的告警管理是在 prometheus.yml 中配置告警规则, 在 alertmanager.yml 中配置发送规则, 都是需要修改配置文件的, 上百人使用的话不太好协同管理</strong>. 而夜莺提供了 UI 配置能力(当然也有 API), 并且在一些方面做了增强, 比如更丰富的告警规则配置, 历史事件存档, 活跃事件聚合查看, 对接告警自愈等. 下面一起来看一下夜莺告警管理的思路.</p> <h5 id="_1-规则管理"><a href="#_1-规则管理" class="header-anchor">#</a> 1.规则管理</h5> <p>一个公司可能会有几十上百团队配置成千上万条告警规则, 显然不能用一个扁平化的表格来罗列管理, 夜莺引入了一个 <strong>业务组</strong> 的概念, 每一条规则都要归属于某一个业务组, 只有这个业务组的人可以管理组内的规则.</p> <p><img src="/img/03bcf4b6c36a6229c0ed988d2b2c8db3-20230719203435-v4ja9pw.png" alt=""></p> <p>当然, 业务组下面不仅有<strong>告警规则, 还有监控大盘, 监控对象, 屏蔽规则, 订阅规则, 告警自愈脚本</strong>等等. 业务组是夜莺里最重要的一个管理概念.</p> <h5 id="_2-规则配置"><a href="#_2-规则配置" class="header-anchor">#</a> 2.规则配置</h5> <p>告警规则的配置, 核心还是 <mark><strong>PromQL 和持续时长</strong></mark>. 当然夜莺会有一些额外的增强配置, 比如规则的生效时间段, 是否仅在本业务组生效, 是否启用恢复通知, 留观时长, 最大发送次数等等.</p> <p><img src="/img/745bc53a10935d4b8515a9ayyd999961-20230719203435-eq514mk.png" alt=""></p> <p>夜莺的告警规则是把 PromQL 和发送方式整合到了一条规则中, 这个做法和 Alertmanager 是不同的, Prometheus 的告警规则只有 PromQL, 持续时长, 附加标签, 注解这些基本信息, 至于发给谁, 怎么发, 都是在 Alertmanager 中配置的. 如何评价这两种方式呢?</p> <p>Prometheus+Alertmanager 的方式, 可以看做是订阅式, 告警规则中不指定接收者, 在 Alertmanager 的配置中统一设置过滤条件和对应的接收者. 这种方式非常灵活, 但灵活的东西往往需要定规范, 否则容易混乱, 比如大家统一按照业务线的标签来做订阅, 这就要求时序数据都要打上业务线的标签, 或者把业务线的标签放到告警规则的附加标签中, 需要付出一些额外的心力.</p> <p>Alertmanager 的方式特别适合什么场景呢? 就是所有的告警都统一由某一个团队来负责, 在这种场景下,  Prometheus+Alertmanager 不失为一种最佳实践.</p> <p>夜莺的处理方式和 Datadog 很像, <strong>每个团队配置自己的告警规则, 发给自己这个团队, 即自己管自己的, 不需要把告警规则和接收规则拆到两个地方分别配置</strong>, 而且夜莺也支持订阅方式, 后面会介绍.</p> <h5 id="_3-告警屏蔽"><a href="#_3-告警屏蔽" class="header-anchor">#</a> 3.告警屏蔽</h5> <p>告警屏蔽这个功能比较简单, 是<strong>指对一些告警事件做静默处理</strong>. 对于那些预期内的告警, 处理人不希望被打扰就会短时间做一下屏蔽, 通常是根据标签对事件做过滤.</p> <p>夜莺目前的版本, 只能按照时间段屏蔽, 比如屏蔽凌晨 0 点到早上 7 点的所有告警, 不能做周期性屏蔽, 后面的版本会考虑增加这个功能.</p> <h5 id="_4-告警订阅"><a href="#_4-告警订阅" class="header-anchor">#</a> 4.告警订阅</h5> <p>这个机制和 Alertmanager 有点儿像, <strong>可以根据告警规则或标签做事件订阅, 类似于邮件的抄送功能</strong>.</p> <p>比如我是业务方, 业务跑在 Kubernetes 中, Kubernetes 平台如果发生重大故障, 我是希望能及时知道的, 所以可以订阅 Kubernetes 的所有严重告警. 另外, 虽然我希望得知 Kubernetes 的严重告警, 但我毕竟不是 Kubernetes 的运维人员, 所以我在订阅这类事件的时候, 不希望用电话这种方式接收告警(太重了), 只希望用邮件之类的轻量级方式, 所以订阅规则中通常可以重新定义发送媒介, 重新定义事件级别.</p> <h5 id="_5-历史告警存档"><a href="#_5-历史告警存档" class="header-anchor">#</a> 5.历史告警存档</h5> <p>因为夜莺依赖 MySQL 做数据持久化, 所以<strong>告警事件可以直接存入数据库</strong>, 所有的历史告警都可以追踪查询. 虽然这个功能很简单, 但很多企业都需要, 在自证清白的时候显得尤为重要.</p> <p>当然, 所有历史告警存档, 也可以用于后续分析, 从这些数据中可以轻易得知哪些业务线的告警发送得最多, 消耗电话, 短信费用最多, 哪些业务线的告警解决得最快, 哪些人是接收告警的劳模等等. 其实也能从侧面反映出这个团队的告警策略需要优化, 或者业务稳定性需要优化.</p> <h5 id="_6-活跃告警聚合"><a href="#_6-活跃告警聚合" class="header-anchor">#</a> 6.活跃告警聚合</h5> <p>所谓<strong>活跃告警就是未恢复的告警</strong>, 活跃告警功能很重要, 应该作为日常巡检必须要关注的页面.</p> <p>为了减少查看的心理负担, 便于给告警事件分类, 夜莺支持聚合卡片视图, 而且聚合规则是可以自定义的, 比如当前有 300 条未恢复的告警, 可以根据告警规则聚合查看, 也可以根据地域, 业务线, 服务, 机器等维度聚合查看, 一目了然非常方便.</p> <p><img src="/img/5390bd7d2ba815323acdcbe81d0dee45-20230719203435-ojzp68f.png" alt=""></p> <h5 id="_7-告警自愈"><a href="#_7-告警自愈" class="header-anchor">#</a> 7.告警自愈</h5> <p><strong>当告警事件触发之后, 能自动触发一个恢复动作来止损, 这就是所谓的告警自愈</strong>. 一般监控系统都会支持 Webhook, 告警触发之后自动回调某个接口, 就可以在这个接口里写一些自动化逻辑, 但是这种方式还是要写个 HTTP Server 的, 成本略高. 夜莺除了支持 Webhook 之外, 还可以<strong>在告警时自动执行某个脚本</strong>, 用户就可以直接在脚本里写逻辑了.</p> <p>告警自愈依赖 <a href="https://github.com/flashcatcloud/ibex" target="_blank" rel="noopener noreferrer">ibex<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 模块, 这是一个批量执行脚本的小工具, 可以安装测试一下. 不过有些公司会觉得有安全隐患, 不敢开启这个功能, 如果开放到公网的话确实需要小心.</p> <p>自愈脚本要能够在机器上运行, 需要有较强的权限管控, 这个权限也是依赖业务组的机制, 只有这个业务组的管理人员, 才能去这个组内的机器上跑脚本. 夜莺里有个对象管理, 主要就是管机器的, 设计对象管理功能很重要的一个原因就是为了支持告警自愈.</p> <h5 id="_8-失联告警"><a href="#_8-失联告警" class="header-anchor">#</a> 8.失联告警</h5> <p>夜莺主要是用推模式来接收监控数据, 所以如何感知监控对象失联是个比较麻烦的问题. PromQL 中有 absent 函数, 但是这个函数使用起来非常麻烦, 如果要为 100 台机器配置失联告警, 就要配置 100 条告警规则, 基本无法管理.</p> <p>夜莺在服务端加了一个逻辑, 接收到监控数据之后, 会自动从数据中解析出 ident 标签当做机器标识, 然后为这个机器生成 target_up 指标. 这个机器有监控数据上报, 则 target_up 的值设置为 1; 如果长时间收不到机器的指标上报, 则 target_up 的值设置为 0. 通过这种方式, 只需要配置一条告警规则就可以覆盖所有的监控对象.</p> <p>以上就是夜莺所有告警相关的功能, 有些人了解了夜莺之后觉得不错, 想要去尝试, 但是之前很多规则已经用 Prometheus Yaml 文件管理了, 感觉迁移起来比较麻烦, 怎么搞比较合适?</p> <p>其实 老的 Yaml 文件管理的规则其实可以不用动, 甚至如果 Prometheus 只是给自己团队使用的话也不太需要引入夜莺, 只有那些想要 <strong>把监控能力开放给全公司用的场景</strong> 才需要引入夜莺, 而且新规则可以用夜莺管理, 老的规则不迁移或者慢慢迁移都是可以的. 还是那句话, <mark><strong>技术是为了解决现实问题, 没有什么非黑即白</strong></mark>​ **. **</p> <h4 id="小结-7"><a href="#小结-7" class="header-anchor">#</a> 小结</h4> <p>这一讲要解决的问题是增强 Prometheus 的告警管理能力, 因为 Prometheus 的 Yaml 文件管理方式不太方便做公司级协同管理. <strong>Grafana 和夜莺都可以解决这个问题, 不过 Grafana 更擅长看图, 夜莺更擅长告警管理</strong>, 所以这一讲重点讲解了夜莺的告警功能.</p> <p>夜莺告警管理能力分三类, 一个是规则管理, 包括告警规则, 屏蔽规则, 订阅规则, 一个是事件管理, 包括历史事件, 活跃事件, 最后一个是告警自愈.</p> <p>思维导图如下:</p> <p><img src="/img/07b303cb4458f66d42669953e737c2f2-20230719203435-fpo4a64.jpg" alt=""></p> <h2 id="监控实战"><a href="#监控实战" class="header-anchor">#</a> 监控实战</h2> <h3 id="_9-监控概论-有哪些方法可以指导监控数据采集"><a href="#_9-监控概论-有哪些方法可以指导监控数据采集" class="header-anchor">#</a> 9.监控概论-有哪些方法可以指导监控数据采集?</h3> <p>这一讲开始进入监控实战部分, 看看具体怎么监控不同类型的目标对象. 这里先用两讲讲一下监控方法论和典型的监控数据采集原理.</p> <p>这一讲主要介绍<strong>监控方法论</strong>, 因为要监控的目标五花八门, 怎样才能让监控数据更加完备, 怎样才能知道哪些指标更加重要, 解决这些问题都需要监控方法论的指导. 目前业界比较流行的方法论有 Google 的四个黄金指标, RED 方法, USE 方法, 下面一一介绍一下.</p> <h4 id="google的四个黄金指标"><a href="#google的四个黄金指标" class="header-anchor">#</a> Google的四个黄金指标</h4> <p><mark><strong>Google 的四个黄金指标着眼点在服务监控, 这四个指标分别是延迟, 流量, 错误和饱和度.</strong></mark></p> <ul><li><strong>延迟</strong>: 服务请求所花费的时间, 比如用户获取商品列表页面调用的某个接口, 花费 30 毫秒. 这个指标需要区分成功请求和失败请求, 因为失败的请求可能会立刻返回, 延迟很小, 会扰乱正常的请求延迟数据.</li> <li><strong>流量</strong>: HTTP 服务的话就是每秒 HTTP 请求数, RPC 服务的话就是每秒 RPCCall 的数量, 如果是数据库, 可能用数据库系统的事务量来作为流量指标.</li> <li><strong>错误</strong>: 请求失败的速率, 即每秒有多少请求失败, 比如 HTTP 请求返回了 500 错误码, 说明这个请求是失败的, 或者虽然返回的状态码是 200, 但是返回的内容不符合预期, 也认为是请求失败.</li> <li><strong>饱和度</strong>: 描述应用程序有多&quot;满&quot;, 或者描述受限的资源, 比如 CPU 密集型应用, CPU 使用率就可以作为饱和度指标.</li></ul> <p>有了这个方法论的指导, 就知道服务监控应该重点关注哪些指标了. 如果要为某个服务配置监控大盘, 监控大盘里就要包含上述这几类指标. 如果要配置告警规则, 也要重点照顾这几类指标.</p> <p>可以这么说, 只要上述这些指标都是正常的, 这个服务就是健康的. 反之如果这些指标有问题, 服务就是不健康的, 并且大概率已经影响了上游服务甚至终端用户.</p> <p>Google 的四个黄金指标主要是<strong>针对服务的监控</strong>, Weaveworks 的工程师认为饱和度这个指标比较高级, 延迟, 流量, 错误这三个指标相对更重要, 所以将其简化为 RED 方法, 下面来看一下 RED 方法的定义.</p> <h4 id="red方法"><a href="#red方法" class="header-anchor">#</a> RED方法</h4> <ul><li><strong>(Request)Rate</strong>: 请求速率, 每秒请求数.</li> <li><strong>(Request)Errors</strong>: 错误, 每秒错误请求数.</li> <li><strong>(Request)Duration</strong>: 延迟, 每个请求的延迟分布情况.</li></ul> <p>三个英文单词取首字母组成 RED 方法, 姑且可以看做是 Google 四个黄金指标的简化版, 作者很逗, 说为什么起名为 RED 呢? 因为他们内部普遍应用 USE 方法, 为了和 USE 相呼应, 所以取了 RED 这个自认为响亮的名字. 这个 USE 又是什么方法呢?</p> <h4 id="use方法"><a href="#use方法" class="header-anchor">#</a> USE方法</h4> <p>USE 方法的提出者是大名鼎鼎的 Brendan Gregg, 性能分析用的火焰图就是这位大哥发明的. 可以点开 <a href="https://www.brendangregg.com/usemethod.html" target="_blank" rel="noopener noreferrer">USE 方法<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 的官方介绍看看.</p> <p><img src="/img/8f5c3de1e0d1873bacb68a5748deef73-20230719203435-wayhgj0.jpg" alt="图片"></p> <p><mark><strong>USE 是使用率(Utilization), 饱和度(Saturation), 错误(Error)的缩写, 主要用于分析资源问题</strong></mark>. 什么是资源? 在 Gregg对模型的定义中, 是指传统意义上的物理服务器组件, 比如 CPU, 硬盘等, 但现在很多人已经扩展了资源的范围, 把一些软件资源也包含在内. 下面对使用率, 饱和度, 错误做一个更详细的解释.</p> <ul><li><strong>使用率</strong>: 比如内存使用率, CPU使用率等, 是一个百分比.</li> <li><strong>饱和度</strong>: 资源排队工作的指标, 无法再处理额外的工作. 通常用队列长度表示, 比如在 iostat 里看到的 aqu-sz 就是队列长度.</li> <li><strong>错误</strong>: 资源错误事件的计数. 比如 malloc() 失败次数, 通过 ifconfig 看到的 errors, dropped 包量. 有很多错误是以系统错误日志的方式暴露的, 没法直接拿到某个统计指标, 此时可以进行日志关键字监控.</li></ul> <p><strong>USE 方法和 Google 四个黄金指标配合使用</strong>, 就可以知道不同类别的监控对象应该关注的核心指标是什么了. 那监控对象都有哪些类别呢? 换句话说, 做了哪些方面的监控才算是把监控体系建设完备了? 下面就来梳理一下监控对象的类别.</p> <h4 id="监控分类"><a href="#监控分类" class="header-anchor">#</a> 监控分类</h4> <p>为了方便理解, 下图把监控分成 4 个类别.</p> <p><img src="/img/0f6091c107b263bcd481c278d821ee32-20230719203435-hhm0dfq.jpg" alt=""></p> <h5 id="_1-业务监控"><a href="#_1-业务监控" class="header-anchor">#</a> 1.业务监控</h5> <p>这类指标是<strong>管理层</strong>非常关注的, 代表企业营收, 或者跟客户主流程相关, 类似 BI 数据. 不过相比 BI 数据, 业务监控指标有两点不同.</p> <ul><li><strong>对精确度要求没有那么高</strong>: 因为监控只要发现趋势异常就可以, 至于是从 5000 变成了 1000 还是变成了 1001, 没有什么区别.</li> <li><strong>对实时性要求很高</strong>: 很多 BI 数据可能是小时级别或天级别的, 这个时效性无法满足监控的需求, 监控是希望越早发现问题越好, 要是一个小时才发现问题, 黄花菜都凉了.</li></ul> <p><mark>技术人员应该针对这类指标做高优保障, 如果所有的指标都同等对待, 重要的告警就容易被普通告警淹没, 所以 告警一定要分级对待. </mark></p> <p>很多公司的故障管理比较粗放, 只要有报警事件产生, 就认为是有故障, 这是不对的. 在微服务和云原生技术盛行的当下, 某个机器的 CPU 飙高了, 或者 IO 打满了, 对最终用户的体验可能是没有任何影响的, 但是核心业务指标异常, 一定是故障, 因为这类指标异常代表着最终用户体验受损, 或者造成了直接资损.</p> <p>作为中后台的团队, 做的很多稳定性保障的工作不容易让管理层看到, 业务指标是一个突破口, 如果能够把这类指标梳理清楚, 是很容易让老板看到我的价值的.</p> <h5 id="_2-应用监控"><a href="#_2-应用监控" class="header-anchor">#</a> 2.应用监控</h5> <p><strong>应用监控就是指对应用程序(Application)的监控, Google 的四个黄金指标, RED 方法主要就是针对应用监控的.</strong></p> <p>每个公司都应该有统一的 APM(Application Performance Management), 也就是应用性能管理方案, 从指标着手的话一般使用<strong>埋点机制</strong>来做, 比如 StatsD, Prometheus SDK 等, 或者直接分析接入层日志, 从日志提取指标; 从<strong>链路追踪</strong>着手的话可以使用 Zipkin, SkyWalking 等.</p> <p>像 Java 这种字节码技术的语言, <strong>采用 JavaAgent 技术可以做到代码无侵入埋点</strong>. 但是像 Go, C++这类语言, 一般都是采用埋点机制来做, 由统一的工具团队提供一些框架, 在框架里内置埋点逻辑, 这样普通研发人员也就基本不会有代码侵入的感觉了.</p> <h5 id="_3-组件监控"><a href="#_3-组件监控" class="header-anchor">#</a> 3.组件监控</h5> <p>这里把各类<strong>数据库, 中间件, 云平台, 统称为组件</strong>, 组件监控是非常考验知识广度的. 一般监控系统的研发人员, 很难把每个组件的机理都搞清楚, 所以定义统一的接入数据规范, 让专业的人去采集各个组件的数据是更合理的做法.</p> <p>有个好现象是, 很多组件的研发人员, 已经开始让组件自身直接支持 Prometheus 协议, 吐出 metrics 数据, 除了 etcd, Kubernetes 这些云原生时代的组件, 一些老的组件, 比如 RabbitMQ, ZooKeeper 等, 也在新版本里直接做了支持, 实属行业幸事.</p> <h5 id="_4-资源监控"><a href="#_4-资源监控" class="header-anchor">#</a> 4.资源监控</h5> <p>基础资源的监控, 主要是针对<strong>设备和网络</strong>, 设备又分为服务器, 网络设备, 网络监控又分为连通性监控, 质量监控, 流量监控. 下面分别做个简单介绍.</p> <h6 id="_1-设备监控"><a href="#_1-设备监控" class="header-anchor">#</a> (1)设备监控</h6> <p>一提起设备监控, 可能立马会想到 CPU, 内存使用率监控, 除了这些之外, 如果想获取硬件模块的健康状况, 比如电源电压, 风扇转速, 主板环境温度等, 就需要走 IPMI 协议, 通过带外网络采集.</p> <p>网络设备, 典型的就是交换机, 防火墙, 一般是通过 <strong>SNMP 协议</strong>获取指标, 比如交换机各个网口的流量, 包量. 也可以通过 syslog 的方式, 把交换机的日志转存出来, 到服务器上分析.</p> <h6 id="_2-网络监控"><a href="#_2-网络监控" class="header-anchor">#</a> (2)网络监控</h6> <p><strong>网络连通性监控最为常见, 通过 ICMP 协议</strong>, 部署探针机器, 对目标设备做 PING 探测, 能探通就表示能连通, 探测失败就是连不通. 当然, 有些机器可能是禁 PING 的, 此时就需要用 TCP 或 HTTP 之类的协议去探测了.</p> <p>PING 探测可以拿到丢包率和延迟数据, 可以用这些数据分析网络质量. 比如两个机房之间的专线, 用 A 机房的探针去探测 B 机房的目的设备, 就能轻易知道机房之间的网络质量情况.</p> <p>最后是流量监控, 也会用在多个地方, 比如机器的网卡流量, 交换机的网口流量, 机房出口流量, 也是整个监控体系的重要一环.</p> <p>到这里, 监控的分类就介绍完了, 可以看一下自己公司的监控数据, 查漏补缺. 上面的分类主要是针对服务端的监控, 还有一个大类是端监控, 比如 iOS 应用, 会关注是否卡顿, 有没有崩溃, 白屏之类的, 这算是另一个领域, 这里就不展开介绍了.</p> <h4 id="小结-8"><a href="#小结-8" class="header-anchor">#</a> 小结</h4> <p>这一讲关注的是监控方法论, 因为监控对象很多, 监控指标也很多, 哪些指标比较重要就需要有一个指导性理论. 从大类上来看, 分为针对服务的 Google 四个黄金指标和 RED 方法, 以及针对资源的 USE 方法. 这些方法可以解答哪些指标更为重要这个问题.</p> <p>对于监控覆盖完备性问题, 共有业务, 应用, 组件, 资源四个大类, 当然还有端监控, 如果这些类别的监控都建立起来了, 监控体系就是相对完备的.</p> <p>本节的思维导图如下:</p> <p><img src="/img/2yy1d9787ac328fc1c245f4dae0dfb78-20230719203435-ny9pbx1.png" alt=""></p> <h3 id="_10-监控概论-监控数据的采集方式及原理"><a href="#_10-监控概论-监控数据的采集方式及原理" class="header-anchor">#</a> 10.监控概论-监控数据的采集方式及原理</h3> <p>前面介绍了监控的几个方法论, 知道了哪些指标比较关键, 但是<strong>具体如何采集</strong>呢? 这又是一个非常重要的话题. 这一讲就来剖析一下常见的采集数据的技术手段, 了解了这些, 就可以写自己的采集器, 或者扩展很多采集器的能力了, 对很多监控数据也会拥有原理层面的理解.</p> <p>采集方法是多种多样的, 比如读取 <code>/proc</code>​ 目录, 执行系统调用, 执行命令行工具, 远程黑盒探测, 远程拉取特定协议的数据, 连到目标上去执行指令获取输出, 代码埋点, 日志分析提取等各种各样的方法. 这一讲会从中挑选一些比较典型的手段. 下面就按照<strong>使用频率从高到低</strong>依次看一下, 先来看读取 <code>/proc</code>​ 目录的方式.</p> <h4 id="读取-proc目录"><a href="#读取-proc目录" class="header-anchor">#</a> 读取/proc目录</h4> <p>​<code>/proc</code>​ 是一个位于<strong>内存中的伪文件系统</strong>, 该目录下保存的不是真正的文件和目录, 而是一些&quot;运行时&quot;信息, ** Linux 操作系统层面的很多监控数据, 比如内存数据, 网卡流量, 机器负载等**, 都是从 <code>/proc</code>​ 中获取的信息.</p> <p>先来看一下内存相关的指标.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@nano~<span class="token punctuation">]</span><span class="token comment"># cat /proc/meminfo</span>
MemTotal:        <span class="token number">7954676</span> kB
MemFree:          <span class="token number">211136</span> kB
MemAvailable:    <span class="token number">2486688</span> kB
Buffers:          <span class="token number">115068</span> kB
Cached:          <span class="token number">2309836</span> kB
<span class="token punctuation">..</span>.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>内存总量, 剩余量, 可用量, Buffer, Cached 等数据都可以轻易拿到. 当然, <code>/proc/meminfo</code>​ 没有使用率, 可用率这样的百分比指标, 这类指标需要<strong>二次计算</strong>, 可以在客户端采集器中完成, 也可以在服务端查询时现算.</p> <p><strong>内存相关的指标都是 Gauge 类型</strong>的, 下面再来看一下网卡流量相关的指标, 网卡相关的数据都是 Counter 类型的数据.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># head -n3 /proc/net/dev</span>
Inter-<span class="token operator">|</span>   Receive                                                <span class="token operator">|</span>  Transmit
 face <span class="token operator">|</span>bytes    packets errs drop fifo frame compressed multicast<span class="token operator">|</span>bytes    packets errs drop fifo colls carrier compressed
  eth0: <span class="token number">697407964307</span> <span class="token number">2580235035</span>    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>          <span class="token number">0</span>         <span class="token number">0</span> <span class="token number">1969289573661</span> <span class="token number">3137865547</span>    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>       <span class="token number">0</span>          <span class="token number">0</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>我的机器上网卡比较多, 所以这个文件的内容有很多行, 通过 head 命令只查看前面几行, 可以看到 eth0 网卡的指标值. 整体上分两部分, 前一部分是 Receive, 表示入方向, 后一部分是 Transmit, 表示出方向. 697407964307 这个值表示 eth0 网卡入方向收到的 byte 总量, 2580235035 则表示 eth0 网卡入方向收到的 packet 总量.</p> <p>注意了, 这里所谓的总量, 是指操作系统启动以来的累计值. 从监控角度, 通常不关注这个总量, 而是关注最近一分钟或者最近一秒钟的流量是多少, 所以在服务端看图的时候, 通常要使用 irate 函数做二次计算.</p> <p>到这里你可能会觉得, OS 层面的监控很简单, 不就是读取 <code>/proc</code>​ 目录下的内容吗? 也不是, 有些数据从 <code>/proc</code>​ 下面是拿不到的, 比如硬盘使用率. 可以从 <code>/proc/mounts</code>​ 拿到机器的挂载点列表, 但具体每个挂载点的使用率, 就需要系统调用了.</p> <h4 id="执行命令行工具"><a href="#执行命令行工具" class="header-anchor">#</a> 执行命令行工具</h4> <p>OS 内的数据采集, 除了读取 <code>/proc</code>​ 目录之外, 也经常会通过<strong>执行命令行工具</strong>的方式采集指标, 下面再来看一下这种方式.</p> <p>这种方式非常简单, 就是调用一下系统命令, 解析输出就可以了. 比如想获取 9090 端口的监听状态, 可以使用 ss 命令 <code>ss -tln|grep 9090</code>​, 想要拿到各个分区的使用率可以通过 df 命令 <code>df -k</code>​. 但是这个方式不太通用, 性能也不好.</p> <p>先说通用性问题, 就拿 ss 命令来说吧, 不是所有的机器都安装了这个命令行工具, 而且不同的发行版或不同 ss 版本, 命令输出内容格式可能不同. 性能问题也容易理解, 调用命令行工具是需要 fork 一个进程的, 相比于进程内的逻辑, 效率大打折扣, 不过监控采集频率一般都是 10 秒起步, 不频繁, 所以这个性能问题倒不是什么大事, 关键还是通用性问题.</p> <h4 id="远程黑盒探测"><a href="#远程黑盒探测" class="header-anchor">#</a> 远程黑盒探测</h4> <p>读取本地 <code>/proc</code>​ 目录或执行命令行工具, 都是在目标监控机器上进行的操作. 有的时候, 无法在目标机器上部署客户端程序, 这时候就需要<strong>黑盒探测</strong>手段了.</p> <p><mark><strong>典型的探测手段有三类, ICMP, TCP 和 HTTP</strong></mark>. 有一个软件叫 Blackbox Exporter, 就是专门用来探测的, Categraf, Datadog-Agent 等采集器也都可以做这种探测.</p> <p>基于 ICMP 协议, 可以通过 Ping 工具做测试, 可以看一下这个例子.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@nano ~<span class="token punctuation">]</span><span class="token comment"># ping -c 3 www.baidu.com</span>
PING www.a.shifen.com <span class="token punctuation">(</span><span class="token number">180.101</span>.49.13<span class="token punctuation">)</span> <span class="token number">56</span><span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">)</span> bytes of data.
<span class="token number">64</span> bytes from <span class="token number">180.101</span>.49.13 <span class="token punctuation">(</span><span class="token number">180.101</span>.49.13<span class="token punctuation">)</span>: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">1</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">251</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">1.41</span> ms
<span class="token number">64</span> bytes from <span class="token number">180.101</span>.49.13 <span class="token punctuation">(</span><span class="token number">180.101</span>.49.13<span class="token punctuation">)</span>: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">2</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">251</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">1.39</span> ms
<span class="token number">64</span> bytes from <span class="token number">180.101</span>.49.13 <span class="token punctuation">(</span><span class="token number">180.101</span>.49.13<span class="token punctuation">)</span>: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">3</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">251</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">1.38</span> ms

--- www.a.shifen.com <span class="token function">ping</span> statistics ---
<span class="token number">3</span> packets transmitted, <span class="token number">3</span> received, <span class="token number">0</span>% packet loss, <span class="token function">time</span> 2003ms
rtt min/avg/max/mdev <span class="token operator">=</span> <span class="token number">1.382</span>/1.393/1.405/0.009 ms
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>这里使用 Ping 工具向 Baidu 发了 3 个数据包, 得到了多个指标数据.</p> <ul><li>丢包率: 0%</li> <li>min rtt: 1.382</li> <li>avg rtt: 1.393</li> <li>max rtt: 1.405</li> <li>ttl: 251</li></ul> <p>监控采集器和手工 Ping 测试的原理是一样的, 也是发几个包做统计. 不过有些机器是禁 Ping 的, 这时候就可以通过 TCP 或 HTTP 来探测. 对于 Linux 机器, 一般是会开放 sshd 的 22 端口, 那就可以用类似 telnet 的方式探测机器的 22端口, 如果成功就认为机器存活.</p> <p>对于 HTTP 协议的探测, 除了基本的连通性测试, 还可以检查协议内容, 比如要求返回的 status code 必须是 200, 返回的 response body 必须包含 success 字符串, 如果任何一个条件没有满足, 从监控的角度就认为是异常的.</p> <p>有黑盒监控, 自然就有<strong>白盒监控</strong>. 黑盒监控是把监控对象当成一个黑盒子, 不去了解其内部运行机理, 只是通过几种协议做简单探测. 白盒监控与之相反, 它要收集能够反映监控对象内部运行健康度的指标. 但是监控对象的内部指标, 从外部其实是无法拿到的, 所以白盒监控的指标, 需要监控对象自身想办法暴露出来. 最典型的暴露方式, 就是提供一个 HTTP 接口, 在 response body 中返回监控指标的数据. 下面就来看一下这种采集方式.</p> <h4 id="拉取特定协议的数据"><a href="#拉取特定协议的数据" class="header-anchor">#</a> 拉取特定协议的数据</h4> <p>有很多组件都通过 HTTP 接口的方式, 暴露了自身的监控指标. 这里举几个例子, 比如 Elasticsearch 的 <code>/_cluster/health</code>​ 接口.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@nano ~<span class="token punctuation">]</span><span class="token comment"># curl  -uelastic:Pass1223 http://10.206.0.7:9200/_cluster/health -s | jq .</span>
<span class="token punctuation">{</span>
  <span class="token string">&quot;cluster_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;elasticsearch-cluster&quot;</span>,
  <span class="token string">&quot;status&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;yellow&quot;</span>,
  <span class="token string">&quot;timed_out&quot;</span><span class="token builtin class-name">:</span> false,
  <span class="token string">&quot;number_of_nodes&quot;</span><span class="token builtin class-name">:</span> <span class="token number">3</span>,
  <span class="token string">&quot;number_of_data_nodes&quot;</span><span class="token builtin class-name">:</span> <span class="token number">3</span>,
  <span class="token string">&quot;active_primary_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">430</span>,
  <span class="token string">&quot;active_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">430</span>,
  <span class="token string">&quot;relocating_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;initializing_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;unassigned_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">430</span>,
  <span class="token string">&quot;delayed_unassigned_shards&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;number_of_pending_tasks&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;number_of_in_flight_fetch&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;task_max_waiting_in_queue_millis&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
  <span class="token string">&quot;active_shards_percent_as_number&quot;</span><span class="token builtin class-name">:</span> <span class="token number">50</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>可以看到, 返回的内容大多是<strong>指标数值</strong>, 转换成监控服务端要求的数据格式, 传上去即可.</p> <p>除了 Elasticsearch, 还有很多其他组件也是用这种方式来暴露指标的, 比如 RabbitMQ, 访问 <code>/api/overview</code>​ 可以拿到 Message 数量, Connection 数量等概要信息. 再比如 Kubelet, 访问 <code>/stats/summary</code>​ 可以拿到 Node 和 Pod 等很多概要信息.</p> <p>不同的接口返回的内容虽然都是指标数据, 但是要推给监控服务端, 还是要做一次格式转换, 比如统一转换为 Prometheus 的文本格式. <strong>要是这些组件都直接暴露 Prometheus 的协议数据就好了</strong>, 使用统一的解析器, 就能大大简化监控采集逻辑. 所幸这个趋势正在发生, 前面也提到了, 像 etcd, CoreDNS, 新版 ZooKeeper, 新版 RabbitMQ, nginx-vts 等, 都内置暴露了 Prometheus  协议数据, 可谓行业幸事.</p> <p>这种拉取监控数据的方式虽然需要做一些数据格式的转换, 但并不复杂. 因为目标对象会把需要监控的数据直接通过接口暴露出来, 监控采集器把数据拉到本地做格式转换即可.</p> <h4 id="连接到目标对象执行命令"><a href="#连接到目标对象执行命令" class="header-anchor">#</a> 连接到目标对象执行命令</h4> <p>更复杂的方式是<strong>需要连接到目标对象上执行指令</strong>, MySQL, Redis, MongoDB 等都是这种方式, 下面就来一起看一下这种采集方式的工作原理.</p> <p>目前最常用的数据库就是 MySQL 和 Redis 了, 就拿这两个组件来举例. 先说 MySQL, 经常需要获取一些连接相关的指标数据, 比如当前有多少连接, 总共拒绝了多少连接, 总共接收过多少连接, 登录 MySQL 命令行, 使用下面的命令可以获取.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>mysql<span class="token operator">&gt;</span> show global status like <span class="token string">'%onn%'</span><span class="token punctuation">;</span>
+-----------------------------------------------+---------------------+
<span class="token operator">|</span> Variable_name                                 <span class="token operator">|</span> Value               <span class="token operator">|</span>
+-----------------------------------------------+---------------------+
<span class="token operator">|</span> Aborted_connects                              <span class="token operator">|</span> <span class="token number">3212</span>                <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_accept                      <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_internal                    <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_max_connections             <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_peer_address                <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_select                      <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connection_errors_tcpwrap                     <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Connections                                   <span class="token operator">|</span> <span class="token number">3281</span>                <span class="token operator">|</span>
<span class="token operator">|</span> Locked_connects                               <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Max_used_connections                          <span class="token operator">|</span> <span class="token number">13</span>                  <span class="token operator">|</span>
<span class="token operator">|</span> Max_used_connections_time                     <span class="token operator">|</span> <span class="token number">2022</span>-10-30 <span class="token number">16</span>:41:35 <span class="token operator">|</span>
<span class="token operator">|</span> Performance_schema_session_connect_attrs_lost <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Ssl_client_connects                           <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Ssl_connect_renegotiates                      <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Ssl_finished_connects                         <span class="token operator">|</span> <span class="token number">0</span>                   <span class="token operator">|</span>
<span class="token operator">|</span> Threads_connected                             <span class="token operator">|</span> <span class="token number">1</span>                   <span class="token operator">|</span>
+-----------------------------------------------+---------------------+
<span class="token number">16</span> rows <span class="token keyword">in</span> <span class="token builtin class-name">set</span> <span class="token punctuation">(</span><span class="token number">0.01</span> sec<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>Threads_connected 表示当前有多少连接, Max_used_connections 表示曾经<strong>最多有多少连接</strong>, Connections 表示总计接收过多少连接. 当然除了连接数相关的指标, 通过 <code>show global status</code>​ 还可以获取很多其他的指标, 这些指标用于表示 MySQL 的运行状态, 随着实例运行, 这些数据会动态变化.</p> <p>还有另一个命令 <code>show global variables</code>​ 可以获取一些<strong>全局变量信息</strong>, 比如使用下面的命令可以获取 MySQL 最大连接数.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>mysql<span class="token operator">&gt;</span> show global variables like <span class="token string">'%onn%'</span><span class="token punctuation">;</span>
+-----------------------------------------------+-----------------+
<span class="token operator">|</span> Variable_name                                 <span class="token operator">|</span> Value           <span class="token operator">|</span>
+-----------------------------------------------+-----------------+
<span class="token operator">|</span> character_set_connection                      <span class="token operator">|</span> utf8            <span class="token operator">|</span>
<span class="token operator">|</span> collation_connection                          <span class="token operator">|</span> utf8_general_ci <span class="token operator">|</span>
<span class="token operator">|</span> connect_timeout                               <span class="token operator">|</span> <span class="token number">10</span>              <span class="token operator">|</span>
<span class="token operator">|</span> disconnect_on_expired_password                <span class="token operator">|</span> ON              <span class="token operator">|</span>
<span class="token operator">|</span> init_connect                                  <span class="token operator">|</span>                 <span class="token operator">|</span>
<span class="token operator">|</span> max_connect_errors                            <span class="token operator">|</span> <span class="token number">100</span>             <span class="token operator">|</span>
<span class="token operator">|</span> max_connections                               <span class="token operator">|</span> <span class="token number">5000</span>            <span class="token operator">|</span>
<span class="token operator">|</span> max_user_connections                          <span class="token operator">|</span> <span class="token number">0</span>               <span class="token operator">|</span>
<span class="token operator">|</span> performance_schema_session_connect_attrs_size <span class="token operator">|</span> <span class="token number">512</span>             <span class="token operator">|</span>
+-----------------------------------------------+-----------------+
<span class="token number">9</span> rows <span class="token keyword">in</span> <span class="token builtin class-name">set</span> <span class="token punctuation">(</span><span class="token number">0.01</span> sec<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><strong>其中 max_connections 就是最大连接数, 这个数值默认是 151. 在很多生产环境下, 都应该调大, 所以要把这个指标作为一个告警规则监控起来, 如果发现这个数值太小要及时告警.</strong></p> <p>除了刚才介绍的两个命令, 还可以执行其他命令获取其他数据库指标, 比如 <code>show slave status</code>​ 可以获取 Slave 节点的信息. 总的来看, <mark><strong>MySQL 监控的原理就是, 连上 MySQL 后执行各种 SQL 语句, 解析结果, 转换为监控时序数据</strong></mark>.</p> <p>上面例子中的 SQL 语句都是用来获取 MySQL 实例运行状态的. 实际上, 既然可以执行 SQL 语句, 就可以自定义一些 SQL 来查询业务数据, 获取业务指标. 前面也提到过, 业务指标数据是整个监控体系中价值最大的, 要好好利用这个能力.</p> <p>比如有个 orders 表存储了订单数据, 那就可以使用下面的语句获取订单总量.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token keyword">select</span> count<span class="token punctuation">(</span>*<span class="token punctuation">)</span> as order_total from orders
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>把 order_total 这个返回值作为最终的监控数据上报即可</strong>. 这种方式对于一些比较简单的单表场景还是挺好用的. 但如果业务侧有分库分表, 就需要用一些更复杂的手段来解决了.</p> <p>Redis 也是类似的, 比如通过 redis-cli 登录到命令行, 执行 <code>info memory</code>​ 命令, 就可以看到很多内存相关的指标.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> info memory
<span class="token comment"># Memory</span>
used_memory:1345568
used_memory_human:1.28M
used_memory_rss:3653632
used_memory_rss_human:3.48M
used_memory_peak:1504640
used_memory_peak_human:1.43M
used_memory_peak_perc:89.43%
used_memory_overhead:1103288
used_memory_startup:1095648
used_memory_dataset:242280
used_memory_dataset_perc:96.94%
<span class="token punctuation">..</span>.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>虽然这里把输出截断了, 但也很容易看出所以然, 输出的指标是 <strong>Key:Value</strong> 的格式, Value 部分有的带着单位, 解析的时候需要注意一下, 做一个格式转换.</p> <p>有些业务数据可能是存在 Redis 里的, 所以监控 Redis 不只是获取 Redis 自身的指标, 还应该支持自定义命令, 获取一些业务数据, 比如下面的命令, 用于获取订单总量.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>get /orders/total
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这个例子是假设业务程序会自动更新 <strong>Redis Key: /orders/total</strong>, 用这个 Key 来存放订单总量.</p> <p><img src="/img/0f6091c107b263bcd481c278d821ee32-20230719203435-noophhq.jpg" alt=""></p> <p>讲到这里, 就把常见的 OS 和中间件的监控讲完了, 按照上一讲的监控分层架构图, 接下来就是应用监控和业务监控, <mark><strong>应用监控和业务监控有两种典型的采集手段, 一个是埋点, 一个是日志解析</strong></mark>.</p> <h4 id="代码埋点与日志解析"><a href="#代码埋点与日志解析" class="header-anchor">#</a> 代码埋点与日志解析</h4> <p>所谓的代码埋点方式, 是指应用程序内嵌一些监控相关的 SDK, 在请求的关键链路上调用 SDK 的方法, 告诉 SDK 当前是个什么请求, 耗时多少, 是否成功之类的, SDK 汇总这些数据并二次计算, 最终推给监控服务端.</p> <p>比如一个用 Go 写的 Web 程序, 提供了 10 个 HTTP 接口, 想获取这 10 个接口的成功率和延迟数据, 那就要写程序实现这些逻辑, 包括数据采集, 统计, 转发给服务端等. 这些监控相关的逻辑是典型的横向需求, 这个 Web 程序有需求, 其他的程序也有这个需求, 所以就把这部分<strong>代码抽象成一个统一的 Lib</strong>, 即上面提到的这个 SDK, 每个需要监控逻辑的程序都可以复用这个 SDK, 提升效率.</p> <p><strong>但是每个项目都要调用这个 SDK 的方法仍然显得很冗余, 是否有更简单的办法呢? 有! 每个公司可以建立统一的框架开发团队, 开发统一的 HTTP 框架, 在框架里使用 AOP 的编程方式, 内置采集这些监控数据. 这样一来, 只要某个团队用了这个统一的 HTTP 框架, 就自动具备了监控埋点能力. 同理也可以构建统一的 RPC 调用框架, 统一的 MySQL 调用框架, 这样就逐步构建了统一且完备的应用监控数据收集体系.</strong></p> <p>这种方式需要内嵌 SDK, 对代码有侵入性, 是否有更简单的办法呢? 有! 对于 Java 这种字节码语言, <strong>可以使用 JavaAgent 技术, 动态修改字节码, 自动获取监控数据</strong>.</p> <p>当然现在也<strong>开始流行 eBPF 技术</strong>, 有些厂商在尝试, 也可以关注下. 不过在生产实践中, 大部分厂商还是在用埋点的方式采集监控数据, 后面会专门演示如何做埋点.</p> <p>对于自研的程序, 代码埋点是没问题的, 但是很多程序可能是外采的, 没法修改它的源代码, 这时候就要使用 <strong>日志解析</strong> 的方式了. 一般程序都会打印日志, 可以写日志解析程序, 从日志中提取一些关键信息, 比如从业务日志中很容易拿到 Exception 关键字出现的次数, 从接入层日志中很容易就能拿到某个接口的访问次数. 这部分内容后面会详细演示, 这里就不过多介绍了.</p> <h4 id="小结-9"><a href="#小结-9" class="header-anchor">#</a> 小结</h4> <p>本节介绍了多种监控数据的采集方式, 可以从原理的角度来理解监控数据采集这部分内容, 后面再遇到监控指标获取不到的问题, 也可以从原理上做一些排查.</p> <p><mark>**总的来看, OS 层面的监控需要把 Agent 部署到机器里, 读取一些本地的特殊文件, 执行一些命令来获取监控数据; 数据库, 中间件的监控, 大都是远程采集, 只是协议各异, 需要做一定的适配; 应用监控的话, 典型的采集方式有两种, 一个是代码埋点, 一个是日志解析. **</mark></p> <p>本节的思维导图如下:</p> <p><img src="/img/24f725a7d2cff0e1a0e4e799d68cf54d-20230719203435-him2pce.jpg" alt=""></p> <h3 id="_11-机器监控-操作系统有哪些指标需要重点关注"><a href="#_11-机器监控-操作系统有哪些指标需要重点关注" class="header-anchor">#</a> 11.机器监控-操作系统有哪些指标需要重点关注?</h3> <p>前两讲从方法论和技术实现角度给介绍了监控数据的采集原理及方法, 这些方法论是搞定后面各种监控需求的基础, 这里可以再结合总结图复习一下. 有了这些理论基础之后, 就可以动手实操了.</p> <p><img src="/img/2a99224e4000699bc14fe6d5445a93ef-20230719203435-cokk2lv.png" alt=""></p> <p>监控方向里最耳熟能详的, 就是机器监控, 也就是前面说的设备监控中的一种. 机器是进程运行的基础环境, 在制作中间件, 应用监控仪表盘的时候, 一般会把机器核心指标, 比如 CPU, 内存, 磁盘, 网络, IO 等, 作为仪表盘的一部分, USE 方法论主要就是针对机器监控提出的, 其重要性不言而喻, 所以今天就从机器监控开始聊起.</p> <h4 id="机器监控手段"><a href="#机器监控手段" class="header-anchor">#</a> 机器监控手段</h4> <p>机器层面的监控分为两部分, <strong>带内监控和带外监控</strong>. <strong>带内监控就是通过带内网络来监控, 主要是以在 OS 里部署 Agent 的方式, 来获取 OS 的 CPU, 内存, 磁盘, IO, 网络, 进程等相关监控指标</strong>. 随着云时代的到来, 普通运维研发人员主要关注带内监控即可, IDC运维人员才会关注带外监控.</p> <p>对于带内监控, 常见的 Agent 有 Categraf, Telegraf, Grafana-agent, Datadog-agent, Node-exporter 等, 这一讲除了介绍基本的CPU, 内存, 硬盘相关的监控, 还会介绍一下进程监控和自定义监控脚本, 所以选择 Categraf, 相对比较方便.</p> <h4 id="categraf介绍"><a href="#categraf介绍" class="header-anchor">#</a> Categraf介绍</h4> <p><strong>Categraf 作为一款 Agent 需要部署到所有目标机器上</strong>, 因为采集 CPU, 内存, 进程等指标, 是需要读取 OS 里的一些信息的, 远程读取不了. 采集到数据之后, 转换格式, 传输给监控服务端.</p> <p>**Categraf 推送监控数据到服务端, 走的是 Prometheus 的 RemoteWrite 协议, 是基于 Protobuf 的 HTTP 协议, 所以所有支持 RemoteWrite 的后端, 都可以和 Categraf 对接, 比如 Prometheus, Nightingale, TDEngine 等. **</p> <h4 id="categraf配置"><a href="#categraf配置" class="header-anchor">#</a> Categraf配置</h4> <p>为了方便看到效果, 可以把 Categraf 采集的数据推送给 Nightingale, 即 n9e-server 的 <code>/prometheus/v1/write</code>​ 地址, 可以看一下相关的配置.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>writers<span class="token punctuation">]</span><span class="token punctuation">]</span>
url <span class="token operator">=</span> <span class="token string">&quot;http://127.0.0.1:19000/prometheus/v1/write&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>注: Categraf 的主配置文件是在 conf 目录下的 config.toml, 解压缩发布包就可以看到了.</p> <p>当然, 如果想让 Categraf 把数据推给 Prometheus, 也可以. 但需要把 127.0.0.1:19000 修改为 Prometheus 地址, 还要修改 URL 路径, 因为 Prometheus 的 RemoteWrite 数据接收地址是 /api/v1/write.</p> <p>最后还要注意, Prometheus 进程启动的时候, 需要增加一个启动参数 <code>--enable-feature=remote-write-receiver</code>​, 重启 Prometheus 就能接收 RemoteWrite 数据了.</p> <p>配置完就可以启动了, 不过启动之前, 先来简单测试一下. 通过 <code>./categraf --test</code>​ 看看 Categraf 有没有报错, 正常情况会在命令行输出采集到的监控数据, 下面是运行结果, 可以参考下.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>root@tt-fc-dev01.nj categraf<span class="token punctuation">]</span><span class="token comment"># ./categraf --test --inputs mem:system</span>
<span class="token number">2022</span>/11/05 09:14:31 main.go:110: I<span class="token operator">!</span> runner.binarydir: /home/work/go/src/categraf
<span class="token number">2022</span>/11/05 09:14:31 main.go:111: I<span class="token operator">!</span> runner.hostname: tt-fc-dev01.nj
<span class="token number">2022</span>/11/05 09:14:31 main.go:112: I<span class="token operator">!</span> runner.fd_limits: <span class="token punctuation">(</span>soft<span class="token operator">=</span><span class="token number">655360</span>, <span class="token assign-left variable">hard</span><span class="token operator">=</span><span class="token number">655360</span><span class="token punctuation">)</span>
<span class="token number">2022</span>/11/05 09:14:31 main.go:113: I<span class="token operator">!</span> runner.vm_limits: <span class="token punctuation">(</span>soft<span class="token operator">=</span>unlimited, <span class="token assign-left variable">hard</span><span class="token operator">=</span>unlimited<span class="token punctuation">)</span>
<span class="token number">2022</span>/11/05 09:14:31 config.go:33: I<span class="token operator">!</span> tracing disabled
<span class="token number">2022</span>/11/05 09:14:31 provider.go:63: I<span class="token operator">!</span> use input provider: <span class="token punctuation">[</span>local<span class="token punctuation">]</span>
<span class="token number">2022</span>/11/05 09:14:31 agent.go:85: I<span class="token operator">!</span> agent starting
<span class="token number">2022</span>/11/05 09:14:31 metrics_agent.go:93: I<span class="token operator">!</span> input: local.mem started
<span class="token number">2022</span>/11/05 09:14:31 metrics_agent.go:93: I<span class="token operator">!</span> input: local.system started
<span class="token number">2022</span>/11/05 09:14:31 prometheus_scrape.go:14: I<span class="token operator">!</span> prometheus scraping disabled<span class="token operator">!</span>
<span class="token number">2022</span>/11/05 09:14:31 agent.go:96: I<span class="token operator">!</span> agent started
09:14:31 system_load_norm_5 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0.3</span>
09:14:31 system_load_norm_15 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0.2675</span>
09:14:31 system_uptime <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">7307063</span>
09:14:31 system_load1 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">1.66</span>
09:14:31 system_load5 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">1.2</span>
09:14:31 system_load15 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">1.07</span>
09:14:31 system_n_cpus <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">4</span>
09:14:31 system_load_norm_1 <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0.415</span>
09:14:31 mem_swap_free <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0</span>
09:14:31 mem_used <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">5248593920</span>
09:14:31 mem_high_total <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0</span>
09:14:31 mem_huge_pages_total <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0</span>
09:14:31 mem_low_free <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>tt-fc-dev01.nj <span class="token number">0</span>
<span class="token punctuation">..</span>.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><p>测试没问题, 就可以启动了. 通过 <code>nohup ./categraf &amp;&gt; stdout.log &amp;</code>​ 简单启动即可, 如果是生产环境, 建议使用 systemd 或 supervisor 等托管进程.</p> <h4 id="导入配置"><a href="#导入配置" class="header-anchor">#</a> 导入配置</h4> <p>Categraf 内置 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/system/dashboard.json" target="_blank" rel="noopener noreferrer">Linux 监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 导入 Nightingale 就能看到效果, 当然它也内置了告警规则, 可以看一下规则的 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/system/alerts-linux.json" target="_blank" rel="noopener noreferrer">JSON 文件<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 下面是大盘效果图.</p> <p><img src="/img/b9e1c30f7cce7a92byye0acd1cdc09b7-20230719203435-n2uudm0.png" alt="图片"></p> <p>走完上面的几步, 就可以看到监控效果了. 下面就来看一下这些数据是怎么来的.</p> <h4 id="categraf插件"><a href="#categraf插件" class="header-anchor">#</a> Categraf插件</h4> <p>Categraf 和 Telegraf, Datadog-agent 类似, 都是插件架构, 采集 CPU 指标的是 cpu 插件, 采集内存指标的是 mem 插件, 采集进程指标的是 procstat 插件, <strong>每个插件都有一个配置目录, 在 conf 目录下, 以 input. 打头</strong>.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>$ <span class="token function">ls</span>
categraf.service            input.exec                  input.mem                   input.ntp                   input.redis_sentinel
config.toml                 input.greenplum             input.mongodb               input.nvidia_smi            input.rocketmq_offset
example.input.jolokia_agent input.http_response         input.mtail                 input.oracle                input.snmp
input.arp_packet            input.ipvs                  input.mysql                 input.phpfpm                input.sqlserver
input.conntrack             input.jenkins               input.net                   input.ping                  input.switch_legacy
input.cpu                   input.kafka                 input.net_response          input.postgresql            input.system
input.disk                  input.kernel                input.netstat               input.processes             input.tomcat
input.diskio                input.kernel_vmstat         input.netstat_filter        input.procstat              input.zookeeper
input.dns_query             input.kubernetes            input.nfsclient             input.prometheus            logs.toml
input.docker                input.linux_sysctl_fs       input.nginx                 input.rabbitmq              prometheus.toml
input.elasticsearch         input.logstash              input.nginx_upstream_check  input.redis                 traces.yaml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>OS 的各类指标采集, 大都是读取的 <code>/proc</code>​ 目录, 前面已经介绍过了, 这里不再赘述. 对于常见的插件, Categraf 中有哪些配置可以控制其行为, 下面一起看一下.</p> <h5 id="_1-cpu"><a href="#_1-cpu" class="header-anchor">#</a> 1.cpu</h5> <p>cpu 插件的配置文件在 input.cpu 目录, 只有两个配置项, <strong>interval 和 collect_per_cpu</strong>, 其中 interval 表示采集频率, 所有的插件都有这个配置. 而和 CPU 采集相关的配置实际只有一个, 就是 collect_per_cpu, 它用于控制是否采集每个单核的指标. 默认值是 false, 表示不采集单核的指标, 只采集整机的指标.</p> <p>CPU 相关的指标, 最核心的就是<strong>使用率</strong>. 大型互联网公司, 为了应对突发流量, CPU 的平均利用率一般就是 30% 左右. 如果平时 CPU 利用率总是超过 60%, 就比较危险了.</p> <h5 id="_2-mem"><a href="#_2-mem" class="header-anchor">#</a> 2.mem</h5> <p>mem 插件的配置文件在 input.mem 目录, 核心配置只有一个 <strong>collect_platform_fields</strong>, 它表示是否采集各个平台特有的指标, 什么意思呢? 内存相关的指标, Linux, Windows, BSD, Darwin 都不是完全一样的, 内存总量, 使用量这类指标所有平台都有, 但是其余很多指标都是和平台相关的, 比如 Linux 下特有的 swap, huge_page 相关的指标, 其他平台就是没有的.</p> <p>内存相关的指标, 最核心的是<strong>可用率</strong>, 即 <strong>mem_available_percent</strong>. 新版本的 OS 内置 available 指标, 老版本的姑且可以把 free + cached + buffer 看做 available. 这个值如果小于 30% 就可以发个低级别告警出来了, 然后着手扩容.</p> <h5 id="_3-disk"><a href="#_3-disk" class="header-anchor">#</a> 3.disk</h5> <p>disk 插件的配置文件在 input.disk 目录, 默认不用调整, 如果某个挂载点不想采集, 可以配置到 ignore_mount_points 中, 这样就会自动忽略掉对应的挂载点.</p> <p>硬盘相关的指标, 主要关注<strong>空间使用率和 inode 使用率</strong>. 对于空间使用率, <strong>85% 一刀切的告警规则不合适</strong>, 建议考虑大空间的盘和小空间的盘分别对应不同的告警规则. 比如:</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>disk_used_percent<span class="token punctuation">{</span>app<span class="token operator">=</span><span class="token string">&quot;clickhouse&quot;</span><span class="token punctuation">}</span> <span class="token operator">&gt;</span> <span class="token number">85</span>
and
disk_total<span class="token punctuation">{</span>app<span class="token operator">=</span><span class="token string">&quot;clickhouse&quot;</span><span class="token punctuation">}</span>/1024/1024/1024 <span class="token operator">&lt;</span> <span class="token number">300</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这个规则用了 and 关键字, 除了使用率大于 85 之外, 又加了一个限制条件: 总量小于 300G.</p> <h5 id="_4-diskio"><a href="#_4-diskio" class="header-anchor">#</a> 4.diskio</h5> <p>diskio 插件的配置文件在 input.diskio 目录, 默认不用调整, 如果只想采集某几个盘的 IO 数据, 可以使用 devices 配置进行限制.</p> <p>硬盘 IO 相关的指标, 主要关注读写延迟, 所谓的 IO.UTIL 这种指标基本不用太关注.</p> <h5 id="_5-net"><a href="#_5-net" class="header-anchor">#</a> 5.net</h5> <p>net 插件的配置文件在 input.net 目录, 默认不用调整, 如果只想采集某个特定网卡的数据, 可以修改 interfaces 配置.</p> <p>现在的 IDC 环境, 动辄万兆网卡, 普通业务根本不用担心网卡跑满的问题, 只有专门作为接入层的机器才需要重点关注. 不过网卡丢包是需要关注的, 比如长期每秒几十个丢包, 就有理由怀疑是硬件的问题了.</p> <h5 id="_6-netstat"><a href="#_6-netstat" class="header-anchor">#</a> 6.netstat</h5> <p>netstat 插件的配置文件在 input.netstat 目录, 默认不用调整, tcp_time_wait 指标就是靠这个插件采集的.</p> <h5 id="_7-processes"><a href="#_7-processes" class="header-anchor">#</a> 7.processes</h5> <p>processes 插件的配置文件在 input.processes 目录, 默认不用调整. 最常见的指标是<strong>进程总量</strong>, 如果某个机器进程总量超过600, 大概率是有问题的, 常见的原因比如某个 cron 写挫了, 每分钟 fork 一个进程, 但就是不退出, 时间长了就把机器压垮了.</p> <h5 id="_8-conntrack"><a href="#_8-conntrack" class="header-anchor">#</a> 8.conntrack</h5> <p>conntrack 插件的配置文件在 input.conntrack 目录, 默认不用调整. 如果工作时间比较久, 应该遇到过 conntrack table full 的报错吧. 这个插件就是用来监控 conntrack 的情况的. 可以配置一条这样的告警规则及时发现问题:  <code>conntrack_ip_conntrack_count / ip_conntrack_max &gt; 0.8</code>​ 就可以告警.</p> <h5 id="_9-kernel-vmstat"><a href="#_9-kernel-vmstat" class="header-anchor">#</a> 9.kernel_vmstat</h5> <p>kernel_vmstat 插件的配置文件在 input.kernel_vmstat, 采集的是 <code>/proc/vmstat</code>​ 的指标数据. 这个文件内容比较多, 所以配置文件中给了一个白名单, 可以按需启用, 默认启用了 oom_kill. 这样一来, OS 发生 OOM, 可以及时知道. 不过这需要高版本的内核, 低版本是没有的. 低版本的 OS 可以通过监控内核日志的 &quot;Out of memory&quot; 关键字来实现 OOM 监控.</p> <h5 id="_10-ntp"><a href="#_10-ntp" class="header-anchor">#</a> 10.ntp</h5> <p>ntp 插件的配置文件在 input.ntp 目录, 需要在配置文件中给出 ntp server 的地址. 每个公司都应该有对时机制, 很多分布式程序都是重度依赖时间的. 监控指标是 ntp_offset_ms, 顾名思义, 单位是毫秒, 一般这个值不能超过 1000, 也不能小于 -1000, 需要配置告警规则.</p> <h5 id="_11-procstat"><a href="#_11-procstat" class="header-anchor">#</a> 11.procstat</h5> <p>procstat 插件的配置文件在 input.procstat 目录, 用于<strong>监控进程</strong>. 进程监控主要是两个方面, 一个是进程存活性, 一个是进程占用的 CPU, 内存, 文件句柄等数据.</p> <p>其中特别需要注意的是文件句柄, 也就是 fd 相关的指标. Linux 默认给进程分配的 fd 数量是 1024, 有些人调整了 ulimit 之后发现不好使, 核心原因是进程在 ulimit 调整之前就启动了, 或者是因为 systemd 层面没有调好. 没关系, 通过 fd 这个监控指标, 最终都可以发现问题. procstat_rlimit_num_fds_soft &lt; 2048 就告警, 需要配置这个规则.</p> <h5 id="_12-exec"><a href="#_12-exec" class="header-anchor">#</a> 12.exec</h5> <p>exec 插件的配置文件在 input.exec 目录, 用于自定义监控脚本. 因为 Agent 虽然内置了很多插件, 但有些长尾需求仍然是解决不了的, 此时就需要通过<strong>自定义监控脚本来扩展监控采集能力</strong>.</p> <p>监控脚本可以是 Shell 的, 也可以是 Python, Perl, Ruby 的, 只要机器上有对应的执行环境就可以. Agent 会 fork 一个进程来执行, 截获进程的 stdout(标准输出), 解析成监控数据然后上报. 所以脚本采集到数据之后, 要格式化成某个特定的格式, 打印到 stdout. Categraf 支持三种格式: Prometheus, Influx, Falcon, 默认是 Influx 格式.</p> <p>简单举个例子, 监控某个目录的大小.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token shebang important">#!/bin/sh</span>

<span class="token assign-left variable">data1</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">du</span> <span class="token parameter variable">-sb</span> /data1<span class="token variable">`</span></span>
<span class="token assign-left variable">data2</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">du</span> <span class="token parameter variable">-sb</span> /data2<span class="token variable">`</span></span>

<span class="token builtin class-name">echo</span> <span class="token string">&quot;du,dir=/data1 size=<span class="token variable">$data1</span>&quot;</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;du,dir=/data2 size=<span class="token variable">$data2</span>&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>这个例子使用的就是 <strong>Influx</strong> 输出格式, 这个格式比较简单, 前面已经详细介绍过了, 这里就不再赘述. 当然也可以采用 Prometheus 的格式或 Falcon 的格式. 把这个脚本的路径配置到 exec.toml 中, Categraf 就会周期性地执行这个脚本, 采集这两个目录的大小了.</p> <p><img src="/img/38a4ab67bb925eca00cba12e75794804-20230719203435-ww9059o.png" alt="图片"></p> <p>Categraf 里一些常见的跟机器相关的插件及重点关注的指标就介绍完了, 总结一下如上面的表格所示.</p> <h4 id="小结-10"><a href="#小结-10" class="header-anchor">#</a> 小结</h4> <p>本节重点介绍了机器监控, 机器监控的手段有两种, <strong>基于 Agent 的这种监控手段走的是带内业务网络, 也就是带内监控, 这种方式最为常用</strong>; 另外一种机器监控手段是带外监控, 走的是带外网络. 现在已经是云时代, 就算不了解带外监控, 也没关系.</p> <p><strong>使用 Categraf 作为采集器</strong>, 把 Categraf 里常见的机器监控插件都介绍了一下, 这些插件可以搞定机器常规指标的采集. 比如 cpu 插件可以监控 CPU 的使用率, mem 插件可以用来监控内存的可用率, disk 插件可以用来监控空间使用率, diskio 插件可以采集硬盘 IO 相关的指标, 还有 exec 可以用来自定义监控脚本, 等等. 搞定这些插件, 机器方面的监控也就不成问题了.</p> <p>本节思维导图如下:</p> <p><img src="/img/yyb2dbda85b408350ccc0a57a0ae15cb-20230719203435-q2ib8ko.jpg" alt="图片"></p> <h3 id="_12-网络监控-如何监控网络链路和网络设备"><a href="#_12-网络监控-如何监控网络链路和网络设备" class="header-anchor">#</a> 12.网络监控-如何监控网络链路和网络设备?</h3> <p>前面介绍了机器监控, 机器属于基础设施. 除了机器之外, 还有一个常见的基础设施, 就是<strong>网络</strong>.</p> <p><mark><strong>网络监控主要包括网络链路监控和网络设备监控</strong></mark>, 通常系统运维人员会比较关注. 本节来看看其中涉及了哪些关键技术和实践方法.</p> <h4 id="网络链路监控"><a href="#网络链路监控" class="header-anchor">#</a> 网络链路监控</h4> <p><mark>**网络链路监控主要包含三个部分, 网络连通性, 网络质量, 网络流量. **</mark></p> <p><strong>连通性和质量的监控手段非常简单, 就是在链路一侧部署探针, 去探测链路另一侧的目标, 通过 ICMP, TCP, HTTP 等协议发送探测数据包, 分析回包的结果. 典型的指标有丢包率, 延迟, 回包是否匹配预期条件等.</strong></p> <p>网络流量监控, 则关注流量大小以及流量内容. 流量大小广泛应用于水位管理, 比如机器网卡, 交换机的接口, 外网出口, 专线带宽等, 及时发现网络瓶颈. 分析流量内容, 则可以识别过度耗用带宽的用户和应用程序, 验证网络 QoS 策略等.</p> <p>这一讲使用 Categraf 来演示一下常用<strong>探针的配置方式</strong>, 进行网络连通性和质量监控. 网络流量大小, 可以使用 SNMP 采集数据, 相关方法会在后面介绍网络设备监控时讲解.</p> <h5 id="_1-icmp探测"><a href="#_1-icmp探测" class="header-anchor">#</a> 1.ICMP探测</h5> <p>Categraf 的 ICMP 探测使用 Ping 插件, 相关配置在 <code>conf/input.ping/ping.toml</code>​, 主要是配置要探测的目标地址, 可以看看样例.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
targets <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">&quot;10.4.5.6&quot;</span>, <span class="token string">&quot;10.4.5.7&quot;</span> <span class="token punctuation">]</span>
labels <span class="token operator">=</span> <span class="token punctuation">{</span> <span class="token assign-left variable">region</span><span class="token operator">=</span><span class="token string">&quot;cloud&quot;</span>, <span class="token assign-left variable">product</span><span class="token operator">=</span><span class="token string">&quot;n9e&quot;</span> <span class="token punctuation">}</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
targets <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">&quot;10.4.5.8&quot;</span> <span class="token punctuation">]</span>
labels <span class="token operator">=</span> <span class="token punctuation">{</span> <span class="token assign-left variable">region</span><span class="token operator">=</span><span class="token string">&quot;cloud&quot;</span>, <span class="token assign-left variable">product</span><span class="token operator">=</span><span class="token string">&quot;zbx&quot;</span> <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>例子中是 Ping 3 个地址, 其中有两个机器是 Nightingale 产品使用的, 有一个机器是 Zabbix 产品使用的, 都位于 cloud 这个区域(region)里, 所以打了不同的标签来丰富其维度信息.</p> <p>如果要同时 Ping 很多台机器, 就会占用很多文件句柄, 需要提前调大 Categraf 的文件句柄限制. 如果是用 systemd 来托管, 可以在 categraf.service 文件中添加 LimitNOFILE 配置.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>Service<span class="token punctuation">]</span>
<span class="token assign-left variable">LimitNOFILE</span><span class="token operator">=</span><span class="token number">8192</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>另一个坑是 <strong>CAP</strong> 问题, 如果使用非 root 账号来运行 Categraf, 需要在 categraf.service 文件中添加如下配置.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>Service<span class="token punctuation">]</span>
<span class="token assign-left variable">CapabilityBoundingSet</span><span class="token operator">=</span>CAP_NET_RAW
<span class="token assign-left variable">AmbientCapabilities</span><span class="token operator">=</span>CAP_NET_RAW
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>**Ping 插件可以采集到目标是否连通, 延迟时间, 丢包率等指标, 可以据此做网络链路的监控. 比如机房专线的探测, 只需要在某个机房部署 Categraf, 来探测另一个机房的设备. **</p> <p>最后是 <a href="https://github.com/flashcatcloud/categraf/tree/main/inputs/ping" target="_blank" rel="noopener noreferrer">仪表盘和告警规则<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, dashboard.json 是仪表盘配置, alerts.json 是告警规则配置, 导入夜莺就可以使用. 如果是直接使用的 Prometheus, 也可以参考 JSON 文件中的 PromQL, 并将其改造成 Prometheus yaml 配置.</p> <h5 id="_2-tcp探测"><a href="#_2-tcp探测" class="header-anchor">#</a> 2.TCP探测</h5> <p>很多时候机器是<strong>禁 Ping</strong> 的, 此时 TCP 探测就派上用场了. TCP 探测用的是 Categraf 的 net_response 插件, 配置文件在 <code>conf/input.net_response/net_response.toml</code>​. 实际这个插件既可以探测 TCP 的响应, 也可以探测 UDP 的响应. 配置中最核心的是 targets 部分, 指定探测的目标, 例子如下.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
targets <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">&quot;10.2.3.4:22&quot;</span>,
    <span class="token string">&quot;localhost:6379&quot;</span>,
    <span class="token string">&quot;:9090&quot;</span>
<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><ul><li>​<code>10.2.3.4:22</code>​ 表示探测 10.2.3.4 这个机器的 22 端口是否可以连通.</li> <li>​<code>localhost:6379</code>​ 表示探测本机的 6379 端口是否可以连通.</li> <li>​<code>:9090</code>​ 表示探测本机的 9090 端口是否可以连通, 没有写 IP 或主机名的就默认使用 localhost.</li></ul> <p>原理也很简单, 就是 Categraf 向目标地址发起网络连接. 如果能连通, 就认为是正常的, 指标值上报为 0, 如果失败就是非 0 的值. 监控指标名字是 net_response_result_code.</p> <p>如果是 UDP 的端口, 是无法发起连接探测的. 此时采用内容匹配探测, 即通过 UDP 发个字符串给探测目标, 理论上探测目标很快就会给出回复. 检查回复内容, 如果回复内容包含特定字符串, 就表示探测目标活着. 相关配置是 send 和 expect 字段, 配置样例如下.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment">## The following options are required for UDP checks. For TCP, they are</span>
<span class="token comment">## optional. The plugin will send the given string to the server and then</span>
<span class="token comment">## expect to receive the given 'expect' string back.</span>
<span class="token comment">## string sent to the server</span>
send <span class="token operator">=</span> <span class="token string">&quot;ping&quot;</span>
<span class="token comment">## expected string in answer</span>
<span class="token function">expect</span> <span class="token operator">=</span> <span class="token string">&quot;pong&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>net_response 插件也内置了仪表盘和告警规则, 可以在 <a href="https://github.com/flashcatcloud/categraf/tree/main/inputs/net_response" target="_blank" rel="noopener noreferrer">代码目录<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 中找到, 导入夜莺就可以使用.</p> <h5 id="_3-http探测"><a href="#_3-http探测" class="header-anchor">#</a> 3.HTTP探测</h5> <p>HTTP 探测和 TCP 的探测逻辑几乎完全一致, 只不过 HTTP 是七层协议, Categraf 可以解析到 Status code, Response body 这些更细粒度的信息. 相关配置在 <code>conf/input.http_response/http_response.toml</code>​, 一个配置样例如下.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
targets <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">&quot;http://localhost&quot;</span>,
    <span class="token string">&quot;https://www.baidu.com&quot;</span>
<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>很多公司都会在所有的机器上部署 Agent, Agent 会开一个 HTTP 端口, 这样就可以通过探测这些 HTTP 端口, 知道 Agent 是否存活, 进而反推机器的存活性.</p> <p>HTTP 插件可以对返回的 Response 做规则匹配, 比如判断 Response body 中是否包含特定的字符串, 或者 Status code 是否是指定的值等, 可以看下相关配置.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token comment">## Optional substring match in body of the response (case sensitive)</span>
expect_response_substring <span class="token operator">=</span> <span class="token string">&quot;ok&quot;</span>

<span class="token comment">## Optional expected response status code.</span>
expect_response_status_code <span class="token operator">=</span> <span class="token number">200</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>如果目标地址是 HTTPS 的, Categraf 也会自动检查证书过期时间, 指标名是 cert_expire_timestamp, 证书过期时间一定要记得加个告警规则, 很多公司发生过因为证书过期而导致线上故障.</p> <p>网络链路的几种探测方式就讲到这里, 下面再来看一下网络中的<strong>节点, 网络设备的监控</strong>.</p> <h4 id="网络设备监控"><a href="#网络设备监控" class="header-anchor">#</a> 网络设备监控</h4> <p>网络设备监控的典型手段有三个, <strong>一个是 Ping 监控</strong>, 探测是否存活, 刚刚已经介绍过了. <strong>另一个是通过 SNMP 获取指标</strong>, 比如各个网口的状态, 流量, 包量等. <strong>最后一个是 SNMP Trap</strong>, 一般网络设备有问题, 都会发出 Trap 消息, 这些 Trap 消息很有价值, 分析这些 Trap 消息是常用且有效的监控手段. 先来看一下 SNMP 获取指标的方式.</p> <h5 id="_1-snmp指标获取方式"><a href="#_1-snmp指标获取方式" class="header-anchor">#</a> 1.SNMP指标获取方式</h5> <p>要采集网络设备的监控指标, 一定要了解 SNMP 协议. 这个内容比较多, 可以结合 <a href="https://flashcat.cloud/blog/snmp-introduction/" target="_blank" rel="noopener noreferrer">《SNMP(简单网络管理协议)简介》<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>来理解. 简单来讲, 就是交换机上有个组件叫 SNMP agent(即 snmpd), 监听 UDP 161 端口, 提供查询服务. SNMP manager, 比如 Categraf, 可以向 SNMP agent 发起查询请求, 传入的参数是 OID, SNMP agent 返回 OID 对应的监控数据.</p> <p>Categraf 提供了 SNMP 插件, 配置文件在 <code>conf/input.snmp/snmp.toml</code>​, 核心配置就是 SNMP agent 的连接地址以及要采集的 OID 列表.</p> <p>举个例子.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>interval <span class="token operator">=</span> <span class="token number">60</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
agents <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;udp://172.30.15.189:161&quot;</span><span class="token punctuation">]</span>

<span class="token function">timeout</span> <span class="token operator">=</span> <span class="token string">&quot;5s&quot;</span>
version <span class="token operator">=</span> <span class="token number">2</span>
community <span class="token operator">=</span> <span class="token string">&quot;public&quot;</span>
agent_host_tag <span class="token operator">=</span> <span class="token string">&quot;ident&quot;</span>
retries <span class="token operator">=</span> <span class="token number">1</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.field<span class="token punctuation">]</span><span class="token punctuation">]</span>
oid <span class="token operator">=</span> <span class="token string">&quot;RFC1213-MIB::sysUpTime.0&quot;</span>
name <span class="token operator">=</span> <span class="token string">&quot;uptime&quot;</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.field<span class="token punctuation">]</span><span class="token punctuation">]</span>
oid <span class="token operator">=</span> <span class="token string">&quot;RFC1213-MIB::sysName.0&quot;</span>
name <span class="token operator">=</span> <span class="token string">&quot;source&quot;</span>
is_tag <span class="token operator">=</span> <span class="token boolean">true</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.table<span class="token punctuation">]</span><span class="token punctuation">]</span>
oid <span class="token operator">=</span> <span class="token string">&quot;IF-MIB::ifTable&quot;</span>
name <span class="token operator">=</span> <span class="token string">&quot;interface&quot;</span>
inherit_tags <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;source&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.table.field<span class="token punctuation">]</span><span class="token punctuation">]</span>
oid <span class="token operator">=</span> <span class="token string">&quot;IF-MIB::ifDescr&quot;</span>
name <span class="token operator">=</span> <span class="token string">&quot;ifDescr&quot;</span>
is_tag <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><p>例子中, 配置的交换机地址是 172.30.15.189, 认证版本是 version 2, 认证团体名是 public. 如果是 v3 版本, 可能和下面的认证配置差不多.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>version <span class="token operator">=</span> <span class="token number">3</span>
sec_name <span class="token operator">=</span> <span class="token string">&quot;managev3user&quot;</span>
auth_protocol <span class="token operator">=</span> <span class="token string">&quot;SHA&quot;</span>
auth_password <span class="token operator">=</span> <span class="token string">&quot;example.Demo.c0m&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>要采集哪些指标, 是通过 OID 字段来指定的, instances.field 有两个, 一个是获取系统启动时间(OID 是 RFC1213-MIB::sysUpTime.0), 一个是获取系统名称(OID 是 RFC1213-MIB::sysName.0), 这两个 OID 都是 Scalar 类型, 可以使用 snmpget 进行测试.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>snmpget <span class="token parameter variable">-v2c</span> <span class="token parameter variable">-c</span> public <span class="token number">172.30</span>.15.189 RFC1213-MIB::sysUpTime.0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>因为 name = &quot;uptime&quot; 这个配置, 指标会命名成 snmp_uptime, snmp 是插件前缀, uptime 就是 name 字段指定的. 看起来挺顺畅, 但是为什么 sysName 这个 field 多了一个 is_tag = true 的配置呢? 因为 sysName 是个字符串, 不是要上报的监控数据, 它会作为一个标签 source=$sysName 附到所有时序数据上.</p> <p>instances.table 部分采集的是 Table 类型的数据, Table 的 OID 是 IF-MIB::ifTable, Table 里有多列数据和索引, Categraf 会自动获取 Table 中所有的索引字段, 做成时序数据的标签, 还会自动获取所有的数据列, 作为指标上报. 但是有些列可能不是数值, 比如 ifDescr 就是字符串, 这个列无需作为指标上报, 作为标签上报更合适, 所以有个 is_tag=true 的配置. inherit_tags 表示继承下来的标签, ifTable 收集到的数据就会自动附上 source 标签.</p> <p>ifTable 可以拿到各个网口的出入向流量, 包量等, 对做容量监控很有帮助, 当然也可以拿到错包, 丢包的情况, 这些都是很重要的监控指标. 这里贴几条监控数据, 可以有一个直观的认识.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token number">12</span>:01:36 snmp_interface_ifInNUcastPkts <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>prober01 <span class="token assign-left variable">ident</span><span class="token operator">=</span><span class="token number">172.30</span>.15.189 <span class="token assign-left variable">ifIndex</span><span class="token operator">=</span><span class="token number">5</span> <span class="token assign-left variable">source</span><span class="token operator">=</span>SW01 <span class="token number">0</span>
<span class="token number">12</span>:01:36 snmp_interface_ifInErrors <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>prober01 <span class="token assign-left variable">ident</span><span class="token operator">=</span><span class="token number">172.30</span>.15.189 <span class="token assign-left variable">ifIndex</span><span class="token operator">=</span><span class="token number">5</span> <span class="token assign-left variable">source</span><span class="token operator">=</span>SW01 <span class="token number">0</span>
<span class="token number">12</span>:01:36 snmp_interface_ifOutDiscards <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>prober01 <span class="token assign-left variable">ident</span><span class="token operator">=</span><span class="token number">172.30</span>.15.189 <span class="token assign-left variable">ifIndex</span><span class="token operator">=</span><span class="token number">5</span> <span class="token assign-left variable">source</span><span class="token operator">=</span>SW01 <span class="token number">0</span>
<span class="token number">12</span>:01:36 snmp_interface_ifOutErrors <span class="token assign-left variable">agent_hostname</span><span class="token operator">=</span>prober01 <span class="token assign-left variable">ident</span><span class="token operator">=</span><span class="token number">172.30</span>.15.189 <span class="token assign-left variable">ifIndex</span><span class="token operator">=</span><span class="token number">5</span> <span class="token assign-left variable">source</span><span class="token operator">=</span>SW01 <span class="token number">0</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>除了获取指标之外, SNMP Trap 也是很关键的监控手段, **SNMP 指标监控是轮询式, 定期采集, 而 Trap 是只要有消息就自动通知, 即时性更好. ** 下面来看一下 Trap 的相关技术方案.</p> <h5 id="_2-snmp-trap"><a href="#_2-snmp-trap" class="header-anchor">#</a> 2.SNMP Trap</h5> <p>与 SNMP 采集指标的方式不同, Trap 消息是由交换机里的 SNMP agent 发消息给 SNMP manager(也是走的 UDP 协议), 与指标采集的数据流向相反. 目前 Categraf 尚不支持 Trap 消息接收, 可以先用 Telegraf 的 snmp_trap 插件做测试.</p> <p><img src="/img/76d4a3ccc578339427e36d5f5db03d09-20230719203435-d9cu60r.jpg" alt=""></p> <p>用 Trap 机制做事件监控是比较便捷的方式, 交换机出现关键问题的时候, 都会立刻发出 Trap 消息. 只要在 Trap Receiver 中配置消息匹配规则, 指定什么样的消息应该产生告警即可. 但是, 匹配规则肯定是需要用人类易读的方式, 这就需要借助 MIB 库, 把 Trap 中的 OID 翻译成人类易读的字符串. 不翻译的话, 原始的 Trap 消息可能是这样的, 很难读懂.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;Version&quot;</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token property">&quot;TrapType&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;OID&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Other&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Community&quot;</span><span class="token operator">:</span> <span class="token string">&quot;public&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Username&quot;</span><span class="token operator">:</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Address&quot;</span><span class="token operator">:</span> <span class="token string">&quot;172.16.1.64:49692&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;VarBinds&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;.1.3.6.1.2.1.1.3.0&quot;</span><span class="token operator">:</span> <span class="token number">7908527690000000</span><span class="token punctuation">,</span>
    <span class="token property">&quot;.1.3.6.1.2.1.2.2.1.1.18&quot;</span><span class="token operator">:</span> <span class="token number">18</span><span class="token punctuation">,</span>
    <span class="token property">&quot;.1.3.6.1.2.1.2.2.1.2.18&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Vlanif103&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;.1.3.6.1.2.1.2.2.1.7.18&quot;</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token property">&quot;.1.3.6.1.2.1.2.2.1.8.18&quot;</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token property">&quot;.1.3.6.1.6.3.1.1.4.1.0&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">&quot;VarBindOIDs&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">&quot;.1.3.6.1.2.1.1.3.0&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;.1.3.6.1.6.3.1.1.4.1.0&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;.1.3.6.1.2.1.2.2.1.1.18&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;.1.3.6.1.2.1.2.2.1.7.18&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;.1.3.6.1.2.1.2.2.1.8.18&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;.1.3.6.1.2.1.2.2.1.2.18&quot;</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><h4 id="小结-11"><a href="#小结-11" class="header-anchor">#</a> 小结</h4> <p>本节从网络链路和网络设备两个方面介绍了网络监控的方法.</p> <p><strong>网络链路监控</strong>, 包括连通性和质量监控, 流量和内容监控, 典型的探测协议是 ICMP, TCP, HTTP. Categraf 有对应的采集插件可以使用, Prometheus 生态的 Blackbox-Exporter 也可以做这个事情.</p> <p>网路流量包含多个方面, 比如机器网卡是否跑满, 可以用 Categraf 采集网卡流量数据, 而交换机的网口流量需要用 SNMP 协议获取. 网络内容监控, 可以使用 NetFlow, J-Flow, sFlow, NetStream, IPFIX 等手段, 找出占用带宽最多的用户, 应用程序和协议.</p> <p><strong>网络设备监控</strong>, 用途很广泛, 除了交换机, 路由器外, UPS, 打印机, 存储等都支持 SNMP 协议, 可以通过 SNMP 获取到设备的各种监控指标. 不过要注意, 对于一些老式交换机, SNMP 采集不能太频繁, 不然有可能影响交换机的性能.</p> <p>另一个网络设备监控手段就是 Trap 了, 通过 SNMP agent 主动发消息给 SNMP manager, 即时性很好, 只要写一个 Trap Receiver, 做协议翻译和规则匹配, 就是一个很好的监控手段. 不过这个方向确实是非常细分的领域, 目前还没有看到相关的开源产品.</p> <p>本节的思维导图:</p> <p><img src="/img/78444e966a71be9f7877eb7ef44f5aeb-20230719203435-v92onyt.jpg" alt=""></p> <h3 id="_13-组件监控-mysql的关键指标及采集方法有哪些"><a href="#_13-组件监控-mysql的关键指标及采集方法有哪些" class="header-anchor">#</a> 13.组件监控-MySQL的关键指标及采集方法有哪些?</h3> <p>本节进入数据库中间件监控实战环节. 这些组件里最常用的非 MySQL 莫属, 这一讲就来介绍一下如何监控 MySQL. 学完本节就知道 MySQL 中哪些指标比较关键以及如何采集这些指标了. 通过这些指标能够提早发现问题, 提升数据库的可用性.</p> <p><img src="/img/1c26d8db1e861c007a1a362db13ace61-20230719203435-hk9bqvf.png" alt="图片"></p> <h4 id="整体思路"><a href="#整体思路" class="header-anchor">#</a> 整体思路</h4> <p>首先要先理清两个问题: <strong>监控哪类指标? 如何采集数据?</strong>  前面系统地介绍过监控方法论, 这些方法论应该如何落地呢? 本节就可以在 MySQL 中应用起来. MySQL 是个服务, 所以可以借用 Google 四个黄金指标的思路来解决问题. 下面一起梳理一下.</p> <p><img src="/img/fb5a50e976687376703a0b44c3166344-20230719203435-vdlfzht.jpg" alt=""></p> <h5 id="_1-延迟"><a href="#_1-延迟" class="header-anchor">#</a> 1.延迟</h5> <p>应用程序会向 MySQL 发起 SELECT, UPDATE 等操作, 处理这些请求花费了多久, 是非常关键的, 甚至还想知道具体是哪个 SQL 最慢, 这样就可以有针对性地调优. 应该如何采集这些延迟数据呢? 典型的方法有三种.</p> <ol><li><strong>在客户端埋点</strong>. 即上层业务程序在请求 MySQL 的时候, 记录一下每个 SQL 的请求耗时, 把这些数据统一推给监控系统, 监控系统就可以计算出平均延迟, 95 分位, 99 分位的延迟数据了. 不过因为要埋点, 对业务代码有一定<strong>侵入性</strong>.</li> <li><strong>Slow queries</strong>. MySQL 提供了慢查询数量的统计指标, 通过下面这段命令就可以拿到.</li></ol> <div class="language-json line-numbers-mode"><pre class="language-json"><code>show global status like 'Slow_queries';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| Slow_queries  | <span class="token number">107</span>   |
+---------------+-------+
<span class="token number">1</span> row in set (<span class="token number">0.000</span> sec)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>这个指标是 Counter 类型的, 即单调递增</strong>, 如果想知道最近一分钟有多少慢查询, 需要使用 increase 函数做二次计算.</p> <p>怎么算慢查询呢? 实际是有一个全局变量的 long_query_time, 默认是 10 秒, 不过也可以调整. 每当查询时间超过了  long_query_time 指定的时间, Slow_queries 就会 +1, 可以通过下面这段命令获取 long_query_time 的值.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>SHOW VARIABLES LIKE 'long_query_time';
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| long_query_time | <span class="token number">10.000000</span> |
+-----------------+-----------+
<span class="token number">1</span> row in set (<span class="token number">0.001</span> sec)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><ol start="3"><li><strong>通过 performance schema 和 sys schema 拿到统计数据</strong>. 比如 performance schema 的 events_statements_summary_by_digest 表, 这个表捕获了很多关键信息, 比如<strong>延迟, 错误量, 查询量</strong>. 看下面的例子, SQL 执行了 2 次, 平均执行时间是 325 毫秒, 表里的时间度量指标都是以皮秒为单位.</li></ol> <div class="language-json line-numbers-mode"><pre class="language-json"><code>*************************** <span class="token number">1</span>. row ***************************
                SCHEMA_NAME<span class="token operator">:</span> employees
                     DIGEST<span class="token operator">:</span> 0c6318da9de53353a3a1bacea70b4fce
                DIGEST_TEXT<span class="token operator">:</span> SELECT * FROM `employees` WHERE `emp_no` &gt; ?
                 COUNT_STAR<span class="token operator">:</span> <span class="token number">2</span>
             SUM_TIMER_WAIT<span class="token operator">:</span> <span class="token number">650358383000</span>
             MIN_TIMER_WAIT<span class="token operator">:</span> <span class="token number">292045159000</span>
             AVG_TIMER_WAIT<span class="token operator">:</span> <span class="token number">325179191000</span>
             MAX_TIMER_WAIT<span class="token operator">:</span> <span class="token number">358313224000</span>
              SUM_LOCK_TIME<span class="token operator">:</span> <span class="token number">520000000</span>
                 SUM_ERRORS<span class="token operator">:</span> <span class="token number">0</span>
               SUM_WARNINGS<span class="token operator">:</span> <span class="token number">0</span>
          SUM_ROWS_AFFECTED<span class="token operator">:</span> <span class="token number">0</span>
              SUM_ROWS_SENT<span class="token operator">:</span> <span class="token number">520048</span>
          SUM_ROWS_EXAMINED<span class="token operator">:</span> <span class="token number">520048</span>
...
          SUM_NO_INDEX_USED<span class="token operator">:</span> <span class="token number">0</span>
     SUM_NO_GOOD_INDEX_USED<span class="token operator">:</span> <span class="token number">0</span>
                 FIRST_SEEN<span class="token operator">:</span> <span class="token number">2016</span><span class="token number">-03</span><span class="token number">-24</span> <span class="token number">14</span><span class="token operator">:</span><span class="token number">25</span><span class="token operator">:</span><span class="token number">32</span>
                  LAST_SEEN<span class="token operator">:</span> <span class="token number">2016</span><span class="token number">-03</span><span class="token number">-24</span> <span class="token number">14</span><span class="token operator">:</span><span class="token number">25</span><span class="token operator">:</span><span class="token number">55</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>针对即时查询, 诊断问题的场景, 还可以使用 sys schema, sys schema 提供了一种组织良好, 人类易读的指标查询方式, 查询起来更简单. 比如可以用下面的方法找到最慢的 SQL. 这个数据在 statements_with_runtimes_in_95th_percentile 表中.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>SELECT * FROM sys.statements_with_runtimes_in_95th_percentile;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果想了解更多的例子, 可以查看 <a href="https://github.com/mysql/mysql-sys" target="_blank" rel="noopener noreferrer">sys schema 的文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 不过要注意的是, MySQL 从 5.7.7 版本开始, 才包含了 sys schema.</p> <h5 id="_2-流量"><a href="#_2-流量" class="header-anchor">#</a> 2.流量</h5> <p>关于流量, 最耳熟能详的是统计 SELECT, UPDATE, DELETE, INSERT 等语句执行的数量. 如果流量太高, 超过了硬件承载能力, 显然是需要监控, 需要扩容的. 这些类型的指标在 MySQL 的<strong>全局变量</strong>中都可以拿到. 来看下面这个例子.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>show global status where Variable_name regexp 'Com_insert|Com_update|Com_delete|Com_select|Questions|Queries';
+-------------------------+-----------+
| Variable_name           | Value     |
+-------------------------+-----------+
| Com_delete              | <span class="token number">2091033</span>   |
| Com_delete_multi        | <span class="token number">0</span>         |
| Com_insert              | <span class="token number">8837007</span>   |
| Com_insert_select       | <span class="token number">0</span>         |
| Com_select              | <span class="token number">226099709</span> |
| Com_update              | <span class="token number">24218879</span>  |
| Com_update_multi        | <span class="token number">0</span>         |
| Empty_queries           | <span class="token number">25455182</span>  |
| Qcache_queries_in_cache | <span class="token number">0</span>         |
| Queries                 | <span class="token number">704921835</span> |
| Questions               | <span class="token number">461095549</span> |
| Slow_queries            | <span class="token number">107</span>       |
+-------------------------+-----------+
<span class="token number">12</span> rows in set (<span class="token number">0.001</span> sec)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>例子中的这些指标都是 <strong>Counter 类型, 单调递增</strong>, 另外 Com_ 是 Command 的前缀, 即各类命令的执行次数. <strong>整体吞吐量主要是看 Questions 指标</strong>, 但 Questions 很容易和它上面的 Queries 混淆. 从例子里可以明显看出 Questions 的数量比 Queries 少. Questions 表示客户端发给 MySQL 的语句数量, 而 Queries 还会包含在存储过程中执行的语句, 以及 PREPARE 这种准备语句, 所以监控整体吞吐一般是看 Questions.</p> <p><strong>流量方面的指标, 一般会统计写数量(Com_insert + Com_update + Com_delete), 读数量(Com_select), 语句总量(Questions).</strong></p> <h5 id="_3-错误"><a href="#_3-错误" class="header-anchor">#</a> 3.错误</h5> <p>错误量这类指标有多个应用场景, 比如客户端连接 MySQL 失败了, 或者语句发给 MySQL, 执行的时候失败了, 都需要有失败计数. 典型的采集手段有两种.</p> <ol><li><strong>在客户端采集, 埋点</strong>, 不管是 MySQL 的问题还是网络的问题, 亦或者中间负载均衡的问题或 DNS 解析的问题, 只要连接失败了, 都可以发现. 缺点依然是会有代码侵入性.</li> <li><strong>从 MySQL 中采集相关错误</strong>, 比如连接错误可以通过 Aborted_connects 和 Connection_errors_max_connections 拿到.</li></ol> <div class="language-json line-numbers-mode"><pre class="language-json"><code>show global status where Variable_name regexp 'Connection_errors_max_connections|Aborted_connects';
+-----------------------------------+--------+
| Variable_name                     | Value  |
+-----------------------------------+--------+
| Aborted_connects                  | <span class="token number">785546</span> |
| Connection_errors_max_connections | <span class="token number">0</span>      |
+-----------------------------------+--------+
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>只要连接失败, 不管是什么原因, Aborted_connects 都会 +1, 而更常用的是 Connection_errors_max_connections , 它表示超过了最大连接数, 所以 MySQL 拒绝连接. MySQL 默认的最大连接数只有 151, 在现在这样的硬件条件下, 实在是太小了, 因此出现这种情况的频率比较高, 需要多多关注, 及时发现这一情况.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>SHOW VARIABLES LIKE 'max_connections';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| max_connections | <span class="token number">151</span>   |
+-----------------+-------+
<span class="token number">1</span> row in set (<span class="token number">0.001</span> sec)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>可以通过这个命令来调整最大连接数.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>SET GLOBAL max_connections <span class="token operator">=</span> <span class="token number">2048</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>虽然可以通过命令临时调整最大连接数, 但一旦重启的话就失效了. 为了永久修改这个配置, 需要调整 <strong>my.cnf</strong>, 在里面增加这么一行内容.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>max_connections = <span class="token number">2048</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>刚刚在介绍延迟指标的时候, 提到了 events_statements_summary_by_digest 表, 也可以通过这个表拿到错误数量.</p> <p>举个例子.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>SELECT schema_name
     <span class="token punctuation">,</span> SUM(sum_errors) err_count
  FROM performance_schema.events_statements_summary_by_digest
 WHERE schema_name IS NOT NULL
 GROUP BY schema_name;
+--------------------+-----------+
| schema_name        | err_count |
+--------------------+-----------+
| employees          |         <span class="token number">8</span> |
| performance_schema |         <span class="token number">1</span> |
| sys                |         <span class="token number">3</span> |
+--------------------+-----------+
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h5 id="_4-饱和度"><a href="#_4-饱和度" class="header-anchor">#</a> 4.饱和度</h5> <p>对于 MySQL 而言, 用什么指标来反映资源有多&quot;满&quot;呢? 首先要关注 MySQL 所在机器的 <strong>CPU, 内存, 硬盘I/O, 网络流量</strong>这些基础指标.</p> <p>MySQL 本身也有一些指标来反映饱和度, 比如刚才讲到的连接数, 当前连接数(Threads_connected)除以最大连接数(max_connections)可以得到 <strong>连接数使用率</strong>, 是一个需要重点监控的饱和度指标.</p> <p>另外就是 <strong>InnoDB Buffer pool</strong> 相关的指标, 一个是 Buffer pool 的使用率, 一个是 Buffer pool 的内存命中率. Buffer pool 是一块内存, 专门用来缓存 Table, Index 相关的数据, 提升查询性能. 对 InnoDB 存储引擎而言, Buffer pool 是一个非常关键的设计.</p> <p>下面查看一下 Buffer pool 相关的指标.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>MariaDB <span class="token punctuation">[</span>(none)<span class="token punctuation">]</span>&gt; show global status like '%buffer%';
+---------------------------------------+--------------------------------------------------+
| Variable_name                         | Value                                            |
+---------------------------------------+--------------------------------------------------+
| Innodb_buffer_pool_dump_status        |                                                  |
| Innodb_buffer_pool_load_status        | Buffer pool(s) load completed at <span class="token number">220825</span> <span class="token number">11</span><span class="token operator">:</span><span class="token number">11</span><span class="token operator">:</span><span class="token number">13</span> |
| Innodb_buffer_pool_resize_status      |                                                  |
| Innodb_buffer_pool_load_incomplete    | OFF                                              |
| Innodb_buffer_pool_pages_data         | <span class="token number">5837</span>                                             |
| Innodb_buffer_pool_bytes_data         | <span class="token number">95633408</span>                                         |
| Innodb_buffer_pool_pages_dirty        | <span class="token number">32</span>                                               |
| Innodb_buffer_pool_bytes_dirty        | <span class="token number">524288</span>                                           |
| Innodb_buffer_pool_pages_flushed      | <span class="token number">134640371</span>                                        |
| Innodb_buffer_pool_pages_free         | <span class="token number">1036</span>                                             |
| Innodb_buffer_pool_pages_misc         | <span class="token number">1318</span>                                             |
| Innodb_buffer_pool_pages_total        | <span class="token number">8191</span>                                             |
| Innodb_buffer_pool_read_ahead_rnd     | <span class="token number">0</span>                                                |
| Innodb_buffer_pool_read_ahead         | <span class="token number">93316</span>                                            |
| Innodb_buffer_pool_read_ahead_evicted | <span class="token number">203</span>                                              |
| Innodb_buffer_pool_read_requests      | <span class="token number">8667876784</span>                                       |
| Innodb_buffer_pool_reads              | <span class="token number">236654</span>                                           |
| Innodb_buffer_pool_wait_free          | <span class="token number">5</span>                                                |
| Innodb_buffer_pool_write_requests     | <span class="token number">533520851</span>                                        |
+---------------------------------------+--------------------------------------------------+
<span class="token number">19</span> rows in set (<span class="token number">0.001</span> sec)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>这里有 4 个指标重点讲一下. <strong>Innodbbufferpoolpagestotal</strong> 表示 InnoDB Buffer pool 的<strong>页总量</strong>, 页(page) 是 Buffer pool 的一个分配单位, 默认的 page size 是 16KB, 可以通过 <code>show variables like &quot;innodb_page_size&quot;</code>​ 拿到.</p> <p><strong>Innodbbufferpoolpagesfree</strong> 是剩余页数量, 通过 total 和 free 可以计算出 used, 用 used 除以 total 就可以得到使用率. 当然, 使用率高并不是说有问题, 因为 InnoDB 有 LRU 缓存清理机制, 只要响应得够快, 高使用率也不是问题.</p> <p><strong>Innodbbufferpoolreadrequests</strong> 和 <strong>Innodbbufferpoolreads</strong> 是另外两个关键指标. read_requests 表示向 Buffer pool 发起的查询总量, 如果 Buffer pool 缓存了相关数据直接返回就好, 如果 Buffer pool 没有相关数据, 就要穿透内存去查询硬盘了. 有多少请求满足不了需要去查询硬盘呢?</p> <p>这就要看 <strong>Innodb_buffer_pool_reads</strong> 指标统计的数量. 所以, reads 这个指标除以 read_requests 就得到了穿透比例, 这个<strong>比例越高, 性能越差, 一般可以通过调整 Buffer pool 的大小来解决</strong>.</p> <p>前面根据 Google 四个黄金指标的方法论, 梳理了 MySQL 相关的指标, 这些指标大多是<strong>可以通过 global status 和 variables 拿到</strong>的. performance schema 和 sys schema 相对难搞, 一是 sys schema 需要较高版本才能支持, 二是这两个 schema 的数据不太适合放到 metrics 库里. 常见做法是通过一些偏全局的统计指标, 比如 Slow_queries, 先发现问题, 再通过这两个 schema 的数据分析细节.</p> <p>不同的采集器采集的指标, 命名方式会有差别, 不过大同小异, 关键是理解思路和原理. 下面还是利用 Categraf 来配置采集, 演示一下整个过程.</p> <h4 id="采集配置"><a href="#采集配置" class="header-anchor">#</a> 采集配置</h4> <p>Categraf 针对 MySQL 的采集插件配置, 在 <code>conf/input.mysql/mysql.toml</code>​ 里. 准备了一个配置样例供参考.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
address = <span class="token string">&quot;127.0.0.1:3306&quot;</span>
username = <span class="token string">&quot;root&quot;</span>
password = <span class="token string">&quot;1234&quot;</span>

extra_status_metrics = <span class="token boolean">true</span>
extra_innodb_metrics = <span class="token boolean">true</span>
gather_processlist_processes_by_state = <span class="token boolean">false</span>
gather_processlist_processes_by_user = <span class="token boolean">false</span>
gather_schema_size = <span class="token boolean">false</span>
gather_table_size = <span class="token boolean">false</span>
gather_system_table_size = <span class="token boolean">false</span>
gather_slave_status = <span class="token boolean">true</span>

# # timeout
# timeout_seconds = <span class="token number">3</span>

# labels = <span class="token punctuation">{</span> instance=<span class="token string">&quot;n9e-dev-mysql&quot;</span> <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>最关键的配置是 <strong>数据库连接地址和认证信息</strong>, 具体采集哪些内容由一堆开关来控制. 一般建议把 extra_status_metrics, extra_innodb_metrics, gather_slave_status 设置为 true, 其他的都不太需要采集. labels 部分, 建议加个 instance 标签, 给这个数据库取一个表意性更强的名称, 未来收到告警消息的时候, 可以一眼知道是哪个数据库的问题. instances 部分是个数组, 如果要监控多个数据库, 就配置多个 instances 就可以了.</p> <p>Categraf 作为采集探针, 采集 MySQL 时, 有两种方案, <strong>一个是中心化探测方案, 一个是分布式本地采集的方案</strong>.</p> <h5 id="_1-中心化探测"><a href="#_1-中心化探测" class="header-anchor">#</a> 1.中心化探测</h5> <p>这个方案是专门找一台机器作为探针机器, 部署一个单独的 Categraf, 只用来采集 MySQL 相关的指标, 同时采集所有的 MySQL 实例, 即这个 Categraf 的 mysql.toml 中会有很多 instances 配置段.</p> <p>这种方案对 MySQL 实例数量较少以及云上的 RDS 服务的场景, 都是适用的. 不过相对不太方便做自动化, 比如要新建一个 MySQL, 还需要到这个探针机器里配置相关的采集规则, 有一些麻烦.</p> <h5 id="_2-分布式本地采集"><a href="#_2-分布式本地采集" class="header-anchor">#</a> 2.分布式本地采集</h5> <p>更推荐第二种方案---分布式本地采集. 这个方案是把 Categraf 部署到部署 MySQL 的那台机器上, 让 Categraf 采集 127.0.0.1:3306 的实例. 对于 MySQL 这个服务, 建议不要混部, 一台宿主机就部署一个 MySQL 就可以了, InnoDB Buffer pool 设置得大一些, 80% 物理内存, 性能杠杠的.</p> <p>DBA 管理 MySQL 的时候要经常创建集群, 通常会沉淀出一些自动化工具, 在自动化工具里把部署 Categraf, 配置 Categraf 的 mysql.toml 的逻辑都加上, 一键搞定, 比较方便. 监控只需要读权限, 建议为监控系统创建一个单独的数据库账号, 统一账号, 统一密码, 统一授权, 这样 mysql.toml 的配置也比较一致.</p> <p>采用这种部署方式的话, 一般就用机器名做标识就可以了, 不太需要单独的 instance 标签. Categraf 内置了一个 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/mysql/dashboard-by-ident.json" target="_blank" rel="noopener noreferrer">夜莺监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 大盘变量使用机器名来做过滤. 如果用的是 Grafana, 可以去 Grafana 官网搜一下 <a href="https://grafana.com/grafana/dashboards/" target="_blank" rel="noopener noreferrer">Dashboard<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 大同小异. 注意一下, 刚刚提到的那些关键指标, 最好都要放到 Dashboard 里. 效果图大概是这个样子.</p> <p><img src="/img/5bde0eb16882569f58f10309a9b75a3f-20230719203435-qsf2ssu.png" alt="图片"></p> <h4 id="业务指标"><a href="#业务指标" class="header-anchor">#</a> 业务指标</h4> <p>MySQL 的指标采集, <mark><strong>核心原理其实就是连上 MySQL 执行一些 SQL, 查询性能数据</strong></mark>. Categraf 内置了一些查询 SQL, 那能否自定义一些 SQL, 查询一些业务指标呢? 比如查询一下业务系统的用户量, 把用户量作为指标上报到监控系统, 还是非常有价值的. 前面讲过监控分类, 其中最重要的一个类别, 就是业务监控.</p> <p>这个需求仍然可以使用 Categraf 的 <strong>MySQL 采集插件</strong>实现, 查看 mysql.toml 里的默认配置, 可以看到这样一段内容.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances.queries<span class="token punctuation">]</span><span class="token punctuation">]</span>
mesurement = <span class="token string">&quot;users&quot;</span>
metric_fields = <span class="token punctuation">[</span> <span class="token string">&quot;total&quot;</span> <span class="token punctuation">]</span>
label_fields = <span class="token punctuation">[</span> <span class="token string">&quot;service&quot;</span> <span class="token punctuation">]</span>
field_to_append = <span class="token string">&quot;&quot;</span>
timeout = <span class="token string">&quot;3s&quot;</span>
request = '''
select 'n9e' as service<span class="token punctuation">,</span> count(*) as total from n9e_v5.users
'''
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>这就是自定义 SQL 的配置, 想要查询哪个数据库实例, 就在对应的 [[instances]] 下面增加 [[instances.queries]]. 看下这几个配置参数的解释.</p> <ul><li>mesurement 指标类别, 会作为 metric name 的前缀.</li> <li>metric_fields 查询返回的结果, 可能有多列是数值, 指定哪些列作为指标上报.</li> <li>label_fields 查询返回的结果, 可能有多列是字符串, 指定哪些列作为标签上报.</li> <li>field_to_append 指定某一列的内容作为 metric name 的后缀.</li> <li>timeout 语句执行超时时间.</li> <li>request 查询语句, 连续三个单引号, 和 Python 的三个单引号语义类似, 里边的内容就不用转义了.</li></ul> <p>MySQL 相关的监控实践, 包括性能监控和业务监控, 核心就是上面说的这些内容, 下面做一个总结.</p> <h4 id="小结-12"><a href="#小结-12" class="header-anchor">#</a> 小结</h4> <p>本节根据 Google 四个黄金指标的方法论, 来指导 MySQL 监控数据的采集, 从延迟, 流量, 错误, 饱和度四个方面分别讲解了具体的指标是什么以及如何获取这些指标.</p> <p>本节思维导图如下:</p> <p><img src="/img/992e7988a1e10e9395bd771cf1314327-20230719203435-70hixq7.jpg" alt=""></p> <h3 id="_14-组件监控-redis的关键指标及采集方法有哪些"><a href="#_14-组件监控-redis的关键指标及采集方法有哪些" class="header-anchor">#</a> 14.组件监控-Redis的关键指标及采集方法有哪些?</h3> <p>Redis 也是一个对外服务, 所以 Google 的四个黄金指标同样适用于Redis, 与上一讲一样, 还是从<strong>延迟, 流量, 错误, 饱和度</strong>这些方面, 来分析 Redis 的关键指标.</p> <h4 id="延迟"><a href="#延迟" class="header-anchor">#</a> 延迟</h4> <p>在软件工程架构中, 之所以选择 Redis 作为技术堆栈的一员, 大概率是想要得到更快的响应速度和更高的吞吐量, 所以延迟数据对使用 Redis 的应用程序至关重要. 通常会通过下面这两种方式来监控延迟.</p> <ol><li>客户端应用程序埋点. 比如某个 Java 或 Go 的程序在调用 Redis 的时候, 计算一下各个命令花费了多久, 然后把耗时数据推给监控系统即可. 这种方式好处是非常灵活, 想要按照什么维度统计就按照什么维度统计, 缺点自然是代码<strong>侵入性</strong>, 和客户端埋点监控 MySQL 的原理是一样的.</li> <li>使用 redis-cli 的 <code>--latency</code>​ 命令, 这个原理比较简单, 就是客户端连上 redis-server, 然后不断发送 ping 命令, 统计耗时. 比如远端机器对某个 redis-server 做探测, 可以看一下探测的结果.</li></ol> <div class="language-json line-numbers-mode"><pre class="language-json"><code>redis-cli --latency -h <span class="token number">10.206</span>.<span class="token number">0.16</span> -p <span class="token number">6379</span>
min<span class="token operator">:</span> <span class="token number">33</span><span class="token punctuation">,</span> max<span class="token operator">:</span> <span class="token number">58</span><span class="token punctuation">,</span> avg<span class="token operator">:</span> <span class="token number">35.30</span> (<span class="token number">1013</span> samples)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>然后又跑到 10.206.0.16 这个机器上, 对本机的 redis-server 做探测, 结果是这样的.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>redis-cli --latency -h <span class="token number">127.0</span>.<span class="token number">0.1</span> -p <span class="token number">6379</span>
min<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> max<span class="token operator">:</span> <span class="token number">18</span><span class="token punctuation">,</span> avg<span class="token operator">:</span> <span class="token number">0.19</span> (<span class="token number">1415</span> samples)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>远端机器平均延迟是 35.3 毫秒, 本地探测平均延迟是 0.19 毫秒, 相差巨大, 时间主要是花费在<strong>网络 I/O</strong> 上了, Redis 本身执行效率是很高的.</p> <p><strong>为什么只使用 ping 命令对 redis-server 做探测, 怎么能反映出真实的工作负载呢? 会不会出现 ping 命令执行得很快, 应用发起的真实请求却很慢的情况呢?</strong></p> <p>这个问题很好, 不过 <strong>Redis 是单线程顺序执行的模型, 如果某个请求执行得慢, 其他所有客户端都得等着, 所以使用 ping 命令对 redis-server 做探测, 理论上探测结果是可以反映 redis-server 的真实工况的</strong>.</p> <p>如果发现 Redis 变慢了, 应该怎么找到那些执行得很慢的命令呢? 这就要求助于 <strong>slowlog</strong> 了. 说到慢日志, 首先要定义执行时间超过多久算慢, Redis 默认的配置是 10 毫秒, 比如调整成 5 毫秒.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span>root@~<span class="token punctuation">]</span># grep slower /etc/redis.conf
slowlog-log-slower-than <span class="token number">10000</span>
<span class="token punctuation">[</span>root@~<span class="token punctuation">]</span># redis-cli
<span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; config set slowlog-log-slower-than <span class="token number">5000</span>
OK
<span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; config get slowlog-log-slower-than
<span class="token number">1</span>) <span class="token string">&quot;slowlog-log-slower-than&quot;</span>
<span class="token number">2</span>) <span class="token string">&quot;5000&quot;</span>
<span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; config rewrite
OK
<span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; quit
<span class="token punctuation">[</span>root@tt-fc-dev01.nj ~<span class="token punctuation">]</span># grep slower /etc/redis.conf
slowlog-log-slower-than <span class="token number">5000</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>之后一些执行时间超过 5 毫秒的命令就会被记录下来, 然后使用 <code>slowlog get [count]</code>​ 就能查看 count 出来的 slowlog 条数了. 这里获取 2 条作为样例.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; SLOWLOG get <span class="token number">2</span>
<span class="token number">1</span>) <span class="token number">1</span>) (integer) <span class="token number">47</span>
   <span class="token number">2</span>) (integer) <span class="token number">1668743666</span>
   <span class="token number">3</span>) (integer) <span class="token number">13168</span>
   <span class="token number">4</span>) <span class="token number">1</span>) <span class="token string">&quot;hset&quot;</span>
      <span class="token number">2</span>) <span class="token string">&quot;/idents/Default&quot;</span>
      <span class="token number">3</span>) <span class="token string">&quot;tt-fc-dev01.nj&quot;</span>
      <span class="token number">4</span>) <span class="token string">&quot;1668743666&quot;</span>
   <span class="token number">5</span>) <span class="token string">&quot;127.0.0.1:43172&quot;</span>
   <span class="token number">6</span>) <span class="token string">&quot;&quot;</span>
<span class="token number">2</span>) <span class="token number">1</span>) (integer) <span class="token number">46</span>
   <span class="token number">2</span>) (integer) <span class="token number">1668646906</span>
   <span class="token number">3</span>) (integer) <span class="token number">13873</span>
   <span class="token number">4</span>) <span class="token number">1</span>) <span class="token string">&quot;hset&quot;</span>
      <span class="token number">2</span>) <span class="token string">&quot;/idents/Default&quot;</span>
      <span class="token number">3</span>) <span class="token string">&quot;10.206.16.3&quot;</span>
      <span class="token number">4</span>) <span class="token string">&quot;1668646906&quot;</span>
   <span class="token number">5</span>) <span class="token string">&quot;127.0.0.1:44612&quot;</span>
   <span class="token number">6</span>) <span class="token string">&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>对于每一条 slowlog, 其各个字段的含义是: 序号, 时间戳, 执行时间(单位是微秒), 命令及其参数, 客户端 IP 和端口等.</p> <h4 id="流量"><a href="#流量" class="header-anchor">#</a> 流量</h4> <p>Redis 每秒处理多少请求, 每秒接收多少字节, 返回多少字节, 在 Redis 里都内置了相关指标, 通过 redis-cli 连上 Redis, 执行 <code>info all</code>​ 命令可以看到很多指标, 绝大部分监控系统, 都是从 info 命令的返回内容中提取的指标.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># redis-cli -h <span class="token number">127.0</span>.<span class="token number">0.1</span> -p <span class="token number">6379</span> info all | grep instantaneous
instantaneous_ops_per_sec<span class="token operator">:</span><span class="token number">0</span>
instantaneous_input_kbps<span class="token operator">:</span><span class="token number">0.00</span>
instantaneous_output_kbps<span class="token operator">:</span><span class="token number">0.00</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>ops_per_sec 表示每秒执行多少次操作, input_kbps 表示每秒接收多少 KB, output_kbps 表示每秒返回多少 KB. 因为连接的这个 Redis 几乎没有什么流量, 所以返回的都是 0, 正常来讲, 一个 Redis 实例每秒处理几万个请求都是很正常的.</p> <p>每秒处理的操作如果较为恒定, 是非常健康的. 如果发现 ops_per_sec 变少了, 就要注意了, 有可能是某个耗时操作导致的命令阻塞, 也有可能是客户端出了问题, 不发请求过来了.</p> <p>如果把 Redis 当做缓存来使用, 还需关注 keyspace_hits 和 keyspace_misses 两个指标.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># redis-cli -h <span class="token number">127.0</span>.<span class="token number">0.1</span> -p <span class="token number">6379</span> info all | grep keyspace
keyspace_hits<span class="token operator">:</span><span class="token number">62033897</span>
keyspace_misses<span class="token operator">:</span><span class="token number">10489649</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这两个指标都是 <strong>Counter 类型, 单调递增</strong>, 即 Redis 实例启动以来, 统计的所有命中的数量和未命中的数量. 如果<strong>要统计总体的命中率, 使用 hits 除以总量即可</strong>.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>hit rate = keyspace_hits / (keyspace_hits + keyspace_misses)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果要关注近期的命中率, 比如最近 10 分钟, 就要通过 PromQL increase 函数等做<strong>二次运算</strong>.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>increase(keyspace_hits<span class="token punctuation">[</span>10m<span class="token punctuation">]</span>)
/
(increase(keyspace_hits<span class="token punctuation">[</span>10m<span class="token punctuation">]</span>) + increase(keyspace_misses<span class="token punctuation">[</span>10m<span class="token punctuation">]</span>))
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>如果命中率低于 0.8 就要注意了, 有可能是内存不够用, 很多 Key 被清理了. 当然也可能是数据没有及时填充或过期了. 较低的命中率显然会对应用程序的延迟有影响, 因为通常来讲, 当应用程序无法从 Redis 中获取缓存数据时, 就要穿透到更慢的存储介质去获取数据了.</p> <h4 id="错误"><a href="#错误" class="header-anchor">#</a> 错误</h4> <p>Redis 在响应客户端请求时, 通常不会有什么内部错误产生, 毕竟只是操作内存, 依赖比较少, 出问题的概率就很小了. 如果客户端操作 Redis 返回了错误, 大概率是网络问题或命令写错了导致的. 最好是做客户端埋点监控, 自己发现了然后自己去解决.</p> <p>Redis 对客户端的数量也有一个最大数值的限制, 默认是 10 万, 如果超过了这个数量, rejected_connections 指标就会 +1. 和 MySQ L不一样的是, Redis 使用过程中, 应该很少遇到超过最大连接数(maxclients) 的情况, 不过谨慎起见, 也可以对 rejected_connections 做一下监控.</p> <h4 id="饱和度"><a href="#饱和度" class="header-anchor">#</a> 饱和度</h4> <p><strong>Redis 重度使用内存, 内存的使用率, 碎片率, 以及因为内存不够用而清理的 Key 数量</strong>, 都是需要重点关注的. 通过 <code>info memory</code>​ 命令查看一下这几个关键指标.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># Memory
used_memory<span class="token operator">:</span><span class="token number">26276368</span>
used_memory_human<span class="token operator">:</span><span class="token number">25</span>.06M
used_memory_rss<span class="token operator">:</span><span class="token number">39575552</span>
used_memory_rss_human<span class="token operator">:</span><span class="token number">37</span>.74M
used_memory_peak<span class="token operator">:</span><span class="token number">33979824</span>
used_memory_peak_human<span class="token operator">:</span><span class="token number">32</span>.41M
...
maxmemory<span class="token operator">:</span><span class="token number">0</span>
maxmemory_human<span class="token operator">:</span>0B
...
mem_fragmentation_ratio<span class="token operator">:</span><span class="token number">1.51</span>
...
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>used_memory 顾名思义就是使用了多少内存, 是从 Redis 自身视角来看的, human 后缀表示用人类易读的方式来表示. used_memory_rss 表示从操作系统视角来看分配了多少内存给 Redis. used_memory_rss 除以 used_memory 就是<strong>内存碎片率, 即 mem_fragmentation_ratio</strong>.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>used_memory_rss(<span class="token number">39575552</span>) / used_memory(<span class="token number">26276368</span>) = mem_fragmentation_ratio(<span class="token number">1.51</span>)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果碎片化率比较高, 说明 used_memory_rss 相对更大, used_memory 相对更小, 即 OS 给 Redis 分配了很多内存, 但 Redis 利用得不好. 正常来讲, OS 分配内存的时候因为有分配单位(比如 8byte, 16byte, 32byte, 64byte)大小的限制, 不可能说进程要多大就能准确分配多大, 假设 Redis 来申请 222 个字节, OS 会直接分配 256 个字节, 这就会产生内存碎片, 但是这种内存碎片不会很多, 要不然 OS 会浪费很多内存, 所以多给一些内存算是正常情况, <strong>即 mem_fragmentation_ratio 稍微大于 1 是没问题的</strong>.</p> <p><strong>另外如果执行 Flushdb, Flushdb 会让 Redis 把数据删掉, 而 Redis 不会立马把这部分内存归还给 OS, 碎片化率的指标就会巨高无比, 此时建议重启 Redis. 毕竟, 都已经 Flushdb 了, 说明 Redis 里已经没有数据了.</strong></p> <p>随着应用程序不断删除, 修改 Redis 中的数据, 内存碎片化率也会上升. 有人说 mem_fragmentation_ratio 超过 1.5 了, 就说明碎片率太高, 需要重启 Redis 或使用下面的命令让 Redis 清理碎片(这个命令从 Redis V4 才开始引入), 搞得非常紧张的样子.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>CONFIG SET activedefrag yes
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>其实大可不必, 就像上面这个例子, RSS 才占用 37M, Redis 实际使用 25M, 碎片 12M, 小得可怜, 虽然  mem_fragmentation_ratio 已经 1.51 了, 但是完全不需要处理. used_memory_peak 是 32.41M, 说明曾经用到过这么多, 后来有些 Key 过期了或者删除/修改了, 才导致碎片率高了点.</p> <p>那什么时候需要处理碎片呢? <strong>机器内存不够用了, 碎片化的内存浪费太多, 并且碎片化率很高的时候才需要处理</strong>. 可以通过调整下面的参数来控制碎片处理过程.</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token comment"># 开启自动内存碎片整理(总开关)</span>
activedefrag <span class="token function">yes</span>
<span class="token comment"># 当碎片达到 100mb 时, 开启内存碎片整理</span>
active-defrag-ignore-bytes 100mb
<span class="token comment"># 当碎片超过 10% 时, 开启内存碎片整理</span>
active-defrag-threshold-lower <span class="token number">10</span>
<span class="token comment"># 内存碎片超过 100%, 则尽最大努力整理</span>
active-defrag-threshold-upper <span class="token number">100</span>
<span class="token comment"># 内存自动整理占用资源最小百分比</span>
active-defrag-cycle-min <span class="token number">25</span>
<span class="token comment"># 内存自动整理占用资源最大百分比</span>
active-defrag-cycle-max <span class="token number">75</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>上面讨论的是 mem_fragmentation_ratio 过大的情况, 实际上这个值还有<strong>可能小于 1</strong>, 表示 Redis 使用了超过 RSS 数量的内存, 说明<strong>此时部分内存已经被放到交换分区上</strong>了, 而磁盘的性能相比内存差了大概 5 个数量级, 所以出现这种情况时会严重影响性能.</p> <p>饱和度的度量方面, 还有一个指标是 evicted_keys, 表示当<strong>内存占用超过了 maxmemory 的时候, Redis 清理的 Key 的数量</strong>. 实际上, 内存达到 maxmemory 的时候, 具体是怎么一个处理策略, 是可以配置的, 默认的策略是 noeviction.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span>root@tt-fc-dev01.nj ~<span class="token punctuation">]</span># redis-cli
<span class="token number">127.0</span>.<span class="token number">0.1</span><span class="token operator">:</span><span class="token number">6379</span>&gt; config get maxmemory-policy
<span class="token number">1</span>) <span class="token string">&quot;maxmemory-policy&quot;</span>
<span class="token number">2</span>) <span class="token string">&quot;noeviction&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>其他常见策略有: volatile-lru, 表示从已设置过期时间的内存数据集里, 挑选最近最少使用的数据淘汰掉; volatile-ttl, 表示从已设置过期时间的内存数据集里, 挑选即将过期的数据淘汰.</p> <p>&quot;Google 的四个黄金指标&quot; 重点要关注的指标就描述到这里, 如果这些指标出问题, 上游的服务大概率会受到影响, 还有一些指标虽然短期不会影响上游服务, 但是如果不及时处理未来也会出现大麻烦, 这类指标通常用于衡量 Redis 内部的一些运行工况, 比如:</p> <ul><li>持久化相关的指标: rdb_changes_since_last_save 表示自从上次落盘以来又有多少次变更.</li> <li>主从相关的指标: master_link_down_since_seconds 表示主从连接已经断开的时长.</li></ul> <p>这些都属于见名知义的指标, 就不展开了.</p> <h4 id="采集配置-2"><a href="#采集配置-2" class="header-anchor">#</a> 采集配置</h4> <p>下面看一下 Redis 的监控数据如何采集.</p> <p>Categraf 也提供了 Redis 采集插件, 配置样例在 <code>conf/input.redis/redis.toml</code>​, 看一下.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
# address = <span class="token string">&quot;127.0.0.1:6379&quot;</span>
# username = <span class="token string">&quot;&quot;</span>
# password = <span class="token string">&quot;&quot;</span>
# pool_size = <span class="token number">2</span>

# # Optional. Specify redis commands to retrieve values
# commands = <span class="token punctuation">[</span>
#     <span class="token punctuation">{</span>command = <span class="token punctuation">[</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sample-key1&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> metric = <span class="token string">&quot;custom_metric_name1&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
#     <span class="token punctuation">{</span>command = <span class="token punctuation">[</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;sample-key2&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> metric = <span class="token string">&quot;custom_metric_name2&quot;</span><span class="token punctuation">}</span>
# <span class="token punctuation">]</span>

# labels = <span class="token punctuation">{</span> instance=<span class="token string">&quot;n9e-dev-redis&quot;</span> <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>最核心的配置就是 address, 也就是 Redis 的连接地址, 然后是认证信息, username 字段低版本的 Redis 是不需要的, 如果是 6.0 以上的版本并且启用了 ACL 的才需要.</p> <p>commands 的作用是自定义一些命令来获取指标, 和 MySQL 采集器中的 queries 类似, 在业务指标采集的场景, 通常能发挥奇效.</p> <p>labels 是个通用配置, 所有的 Categraf 的采集器, 都支持在 <code>[[instances]]</code>​ 下面自定义标签. 如果使用机器名来过滤, 这样便于把 Redis 的指标和 Redis 所在机器的指标放到一张大盘里展示. 这里提供了一个 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/redis/dashboard.json" target="_blank" rel="noopener noreferrer">仪表盘样例<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 供参考.</p> <p><img src="/img/429ae1a1c2e6fa1f457b409267ea312f-20230719203435-od4hrl2.png" alt=""></p> <p>Redis 监控的原理, 采集方法, 仪表盘相关的知识就讲解完了, 下面做一个总结.</p> <h4 id="小结-13"><a href="#小结-13" class="header-anchor">#</a> 小结</h4> <p>因为 Redis 也是一个对外服务, 所以这里还是按照 Google 的四个黄金指标的法则来梳理重要指标.</p> <ul><li>延迟方面可以使用 <code>redis-cli --latency</code>​ 来探测, 不过采集器一般不会直接调用这个命令行工具, 而是采集的时候先发个 ping 命令来获取一下延迟.</li> <li>流量方面重点关注每秒处理多少个 command, 每秒收到多少网络流量, 返回多少网络流量.</li> <li>Redis 因为只是操作内存, 所以基本不会遇到错误, 可以使用客户端埋点方式, 来采集网络错误, 命令错误.</li> <li>饱和度方面, 则重点关注内存饱和度, 尤其是内存碎片率, 小于 1 不行, 太大了也不太好.</li></ul> <p>本节思维导图如下:</p> <p><img src="/img/6c59e45ed77817e05003e5888853b228-20230719203435-94ykff4.jpg" alt=""></p> <h3 id="_15-组件监控-kafka的关键指标及采集方法有哪些"><a href="#_15-组件监控-kafka的关键指标及采集方法有哪些" class="header-anchor">#</a> 15.组件监控-Kafka的关键指标及采集方法有哪些?</h3> <p>对于 MySQL 和 Redis 的监控, 核心原理就是连到实例上执行特定语句命令拉取数据, 类似的还有 MongoDB, 这算是一类监控场景. 本节介绍现代分布式系统中非常常用的组件---Kafka, 同时引出 JMX 监控场景.</p> <p>要做好 Kafka 的监控, 首先要了解 Kafka 的 <a href="https://time.geekbang.org/column/article/99318" target="_blank" rel="noopener noreferrer">基础概念<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 比如 Topic(主题), Partition(分区), Replica(副本), AR(Assigned Replicas), ISR(In-Sync Replicas), OSR(Out-of-Sync Replicas), HW(High Watermark), LEO(Log End Offset)等等. 其次是要了解 Kafka 的架构, 通过架构才能知道要重点监控哪些组件.</p> <h4 id="kafka架构"><a href="#kafka架构" class="header-anchor">#</a> Kafka架构</h4> <p>下面看看看一下 Kafka 的架构图</p> <p><img src="/img/d691yye35395bb878227c002dfcc7a84-20230719203435-sll7ep9.png" alt=""></p> <p>上面绿色部分 PRODUCER(生产者)和下面紫色部分 CONSUMER(消费者)是<strong>业务程序</strong>, 通常由研发人员埋点解决监控问题, 如果是 Java 客户端也会暴露 JMX 指标. 组件运维监控层面着重关注蓝色部分的 BROKER(Kafka 节点)和红色部分的 ZOOKEEPER.</p> <p>ZooKeeper 也是 Java 语言写的, 监控相对简单, 可以复用下面介绍的 <strong>JMX 监控方式</strong>, 另外 ZooKeeper 支持 mntr 四字命令, 可以获取 ZooKeeper 内部健康状况. 新版 ZooKeeper 连四字命令都不需要了, <strong>直接内置暴露了 Prometheus 协议的 metrics 接口, 直接抓取即可</strong>.</p> <p>这里重点关注 Broker 节点的监控, 也就是 <strong>Kafka 自身的监控</strong>, 通常从四个方面着手.</p> <ul><li>Kafka 进程所在机器的监控, 这个参考前面的内容, 重点关注 CPU, 硬盘 I/O, 网络 I/O.</li> <li>JVM 监控, Kafka 是个 Java 进程, 所以需要<strong>常规的 JVM 监控, 通过 JMX 方式暴露</strong>.</li> <li>Kafka 自身的指标, 也是通过 JMX 方式暴露, 比如消息数量, 流量, 分区, 副本的数量等.</li> <li>各个 consumer 的 lag 监控, 即消息堆积量, 是各类 MQ 都应该监控的指标.</li></ul> <p>JVM 和 Kafka 相关的指标, 都通过 JMX 方式暴露, 就先来看一下什么是 JMX, 以及 Kafka 如何开启 JMX.</p> <h4 id="jmx简介"><a href="#jmx简介" class="header-anchor">#</a> JMX简介</h4> <p>**JMX(Java Management Extensions)是一个为应用程序植入管理功能的框架. Java 程序接入 JMX 框架之后, 可以把一些类的属性和方法暴露出来, 用户就可以使用 JMX 相关工具来读取或操作这些类. **</p> <p>比如一个类是 Person, 有 Name 和 Age 两个属性, 如果把 Person 做成一个 MBean, 就可以在 JConsole 里直接查到 Person 属性的值, 也可以修改这些属性.</p> <p>注: MBean 被管理的 Java 对象, JConsole 是 JMX 的一个管理工具.</p> <p>可以通过 JConsole 直接操作 JavaBean, 那 JConsole 对 JavaBean 来说是什么?</p> <p>打个比方, 其实就像是 PHPMyAdmin 之于 MySQL, 可以通过 PHPMyAdmin 直接操作数据库, 这样更容易理解. 如果没有理解也没关系, 从监控的角度, 只要知道如何通过 JMX 读取 Kafka 的指标即可. 下面就来看一下 <strong>Kafka 如何开启 JMX 端口</strong>.</p> <h4 id="kafka开启jmx"><a href="#kafka开启jmx" class="header-anchor">#</a> Kafka开启JMX</h4> <p>Kafka 的配置文件在 config 目录, 各种脚本在 bin 目录, 要让 Kafka 开启 JMX, 肯定是要修改某个配置项或者调整某个脚本的, 具体调整哪里呢? 在 Kafka 的部署目录搜索一下看看.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>grep -i jmx -r config
grep -i jmx -r bin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>在 config 目录搜索 jmx 发现什么都找不到, 看来不是通过配置文件来处理的. 在 bin 目录下搜索 jmx, 可以看到有两个脚本出现了这个关键字, 一个是 bin/kafka-run-class.sh, 另一个是 bin/windows/kafka-run-class.bat. 显然 bat 结尾的文件是 Windows 环境的批处理文件, sh 结尾的才是 Linux, Mac 下使用的脚本文件. 打开 kafka-run-class.sh 看一下里边的关键配置.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># JMX settings
if <span class="token punctuation">[</span> -z <span class="token string">&quot;$KAFKA_JMX_OPTS&quot;</span> <span class="token punctuation">]</span>; then
  KAFKA_JMX_OPTS=<span class="token string">&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false &quot;</span>
fi

# JMX port to use
if <span class="token punctuation">[</span>  $JMX_PORT <span class="token punctuation">]</span>; then
  KAFKA_JMX_OPTS=<span class="token string">&quot;$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT &quot;</span>
fi

...

# Launch mode
if <span class="token punctuation">[</span> <span class="token string">&quot;x$DAEMON_MODE&quot;</span> = <span class="token string">&quot;xtrue&quot;</span> <span class="token punctuation">]</span>; then
  nohup <span class="token string">&quot;$JAVA&quot;</span> $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp <span class="token string">&quot;$CLASSPATH&quot;</span> $KAFKA_OPTS <span class="token string">&quot;$@&quot;</span> &gt; <span class="token string">&quot;$CONSOLE_OUTPUT_FILE&quot;</span> <span class="token number">2</span>&gt;&amp;<span class="token number">1</span> &lt; /dev/<span class="token null keyword">null</span> &amp;
else
  exec <span class="token string">&quot;$JAVA&quot;</span> $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp <span class="token string">&quot;$CLASSPATH&quot;</span> $KAFKA_OPTS <span class="token string">&quot;$@&quot;</span>
fi
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p><strong>如果 KAFKA_JMX_OPTS 变量为空, 就给它赋值, 赋值的那一行内容, 实际就是开启 JMX 的关键参数</strong>. 如果 JMX_PORT 变量不为空, 就再加上 -Dcom.sun.management.jmxremote.port 这个参数, 通过某个端口暴露 JMX 数据, 最后把 KAFKA_JMX_OPTS 放到启动命令里.</p> <p>这就很清晰了, 只要启动 Kafka 之前, 在环境变量里嵌入 JMX_PORT 变量, Kafka 就会监听这个端口, 暴露 JMX 数据, 下面试试.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>export JMX_PORT=<span class="token number">3457</span>; ./bin/kafka-server-start.sh config/server.properties
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>启动之后, 检查 Kafka 的端口监听, 就会发现除了原本监听的 9092 端口, 现在也监听了 3457 端口, 使用 JConsole 工具连上来看看.</p> <p><img src="/img/3760f24d0d92d5d5db79edb58d8fbca5-20230719203435-15fxqpc.png" alt=""></p> <p>选择远程进程, 输入 localhost:3457, 然后点击连接, 选择不安全的连接, 就进入了 JConsole 主页面. 默认进来是概览页面, 选择 <strong>MBean</strong>, 左侧就看到了一个树形结构的多个对象. 举个例子, 依次点击 kafka.server, ReplicaManager, OfflineReplicaCount, 右侧会展示 MBeanInfo, 里边尤其要注意的是 ObjectName, 后面获取 JMX 数据的时候, 会频繁用到这个属性.</p> <p><img src="/img/638d5f5c37f17d920e036dd14fcf33a6-20230719203435-ric1968.png" alt="图片"></p> <p><strong>OfflineReplicaCount</strong> 是 Broker 的一个关键指标, 点击下面的属性, 就可以看到具体的值.</p> <p>通过 JConsole 的页面确实可以查到各个监控指标的数据, 但真正和监控系统对接的话, 还是需要使用<strong>编程的方式</strong>来获取. <strong>JMX 的端口走的是 RMI 协议</strong>, 是 Java 独有的 RPC 协议, 其他语言没法调用. 好在有工具可以把它转为 HTTP 协议, 常见的工具有两个, 一个是 Prometheus 生态的 <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener noreferrer">jmxexporterjavaagent<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 一个是 <a href="https://jolokia.org/" target="_blank" rel="noopener noreferrer">Jolokia<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. Jolokia 也是个 JavaAgent, jmx_exporter 可以把 JMX 指标导出为 Prometheus metrics 格式, Jolokia 可以把 JMX 指标导出为 JSON 格式, 差别不大.</p> <p>不过 Kafka 暴露的 JMX 指标实在是太多了, 如果不过滤全部导出, 每个 Broker 轻轻松松就几万个JMX 指标, 大型互联网公司的话, 基本上都有几百个 Broker, 这个量就有点儿大了.</p> <p>过滤方式主要有两种, <strong>一种是过滤 MBean</strong>, 通过白名单的方式指定, 这些 MBean 采集的数据如果有些还不想要, 就做二次过滤, 通过黑名单的方式指定, 比如根据指标名字做过滤. jmx_exporter 指定 MBean 过滤规则是通过一个配置文件实现的, 如果这个配置文件发生变化, 就要重启 Java 进程, 动作有点儿重.</p> <p>而 Jolokia 的过滤规则都可以在采集器 agent 侧实现, 修改过滤规则只需要重启采集器即可, 不需要重启要监控的 Java 进程, 动作相对轻一些. 下面就来看一下如何为 Kafka 引入 Jolokia 支持.</p> <h4 id="kafka开启jolokia"><a href="#kafka开启jolokia" class="header-anchor">#</a> Kafka开启Jolokia</h4> <p>首先下载 Jolokia 的 <a href="https://download.flashcat.cloud/jolokia-jvm-1.6.2-agent.jar.zip" target="_blank" rel="noopener noreferrer">javaagent jar 包<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 解压到 /opt/jolokia 目录下. 然后在 kafka-run-class.sh 找到 JMX 相关的配置, 在 JMX_PORT 相关逻辑下面增加三行.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># JMX settings
if <span class="token punctuation">[</span> -z <span class="token string">&quot;$KAFKA_JMX_OPTS&quot;</span> <span class="token punctuation">]</span>; then
  KAFKA_JMX_OPTS=<span class="token string">&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false &quot;</span>
fi

# JMX port to use
if <span class="token punctuation">[</span>  $JMX_PORT <span class="token punctuation">]</span>; then
  KAFKA_JMX_OPTS=<span class="token string">&quot;$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT &quot;</span>
fi

########## adding lines
if <span class="token punctuation">[</span> <span class="token string">&quot;x$JOLOKIA&quot;</span> != <span class="token string">&quot;x&quot;</span> <span class="token punctuation">]</span>; then
  KAFKA_JMX_OPTS=<span class="token string">&quot;$KAFKA_JMX_OPTS -javaagent:/opt/jolokia/jolokia-jvm-1.6.2-agent.jar=host=0.0.0.0,port=3456&quot;</span>
fi
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>例子里的 3456 是 Jolokia 监听的端口, 可以换成别的, 只要别跟机器上的其他端口冲突就行. 加了一个 JOLOKIA 变量的判断, 如果这个变量不为空, 就开启 Jolokia; 如果变量为空就不开启, 方便在外部控制. 此时可以重新启动 Kafka.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>export JOLOKIA=<span class="token boolean">true</span>; export JMX_PORT=<span class="token number">3457</span>; nohup ./bin/kafka-server-start.sh config/server.properties &amp;&gt; stdout.log &amp;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>验证 Jolokia 是否在正常工作, 请求其 /jolokia/version 接口即可. 下面是请求示例.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code># curl -s <span class="token number">10.206</span>.<span class="token number">16.8</span><span class="token operator">:</span><span class="token number">3456</span>/jolokia/version | jq .
<span class="token punctuation">{</span>
  <span class="token property">&quot;request&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;version&quot;</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">&quot;value&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;agent&quot;</span><span class="token operator">:</span> <span class="token string">&quot;1.6.2&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;protocol&quot;</span><span class="token operator">:</span> <span class="token string">&quot;7.2&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;config&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">&quot;listenForHttpService&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;maxCollectionSize&quot;</span><span class="token operator">:</span> <span class="token string">&quot;0&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;authIgnoreCerts&quot;</span><span class="token operator">:</span> <span class="token string">&quot;false&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;agentId&quot;</span><span class="token operator">:</span> <span class="token string">&quot;10.206.16.8-2012615-50134894-jvm&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;debug&quot;</span><span class="token operator">:</span> <span class="token string">&quot;false&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;agentType&quot;</span><span class="token operator">:</span> <span class="token string">&quot;jvm&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;policyLocation&quot;</span><span class="token operator">:</span> <span class="token string">&quot;classpath:/jolokia-access.xml&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;agentContext&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/jolokia&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;serializeException&quot;</span><span class="token operator">:</span> <span class="token string">&quot;false&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;mimeType&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text/plain&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;maxDepth&quot;</span><span class="token operator">:</span> <span class="token string">&quot;15&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;authMode&quot;</span><span class="token operator">:</span> <span class="token string">&quot;basic&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;authMatch&quot;</span><span class="token operator">:</span> <span class="token string">&quot;any&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;discoveryEnabled&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;streaming&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;canonicalNaming&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;historyMaxEntries&quot;</span><span class="token operator">:</span> <span class="token string">&quot;10&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;allowErrorDetails&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;allowDnsReverseLookup&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;realm&quot;</span><span class="token operator">:</span> <span class="token string">&quot;jolokia&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;includeStackTrace&quot;</span><span class="token operator">:</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;maxObjects&quot;</span><span class="token operator">:</span> <span class="token string">&quot;0&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;useRestrictorService&quot;</span><span class="token operator">:</span> <span class="token string">&quot;false&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;debugMaxEntries&quot;</span><span class="token operator">:</span> <span class="token string">&quot;100&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;info&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">&quot;product&quot;</span><span class="token operator">:</span> <span class="token string">&quot;jetty&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;vendor&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Eclipse&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token string">&quot;9.4.43.v20210629&quot;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">&quot;timestamp&quot;</span><span class="token operator">:</span> <span class="token number">1669277907</span><span class="token punctuation">,</span>
  <span class="token property">&quot;status&quot;</span><span class="token operator">:</span> <span class="token number">200</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br></div></div><p>上面返回的内容表示 Jolokia 在正常工作, 下面就可以<strong>使用监控 agent 来采集 Jolokia 的数据</strong>了. <strong>JMX 数据分两类, 一类是和 JVM 相关的, 一类是和 Kafka 相关</strong>的.</p> <h4 id="jvm指标"><a href="#jvm指标" class="header-anchor">#</a> JVM指标</h4> <p>先来看一下 JVM 相关的采集规则.</p> <p>Categraf 的配置目录 conf 下面, 默认有一个 input.jolokia_agent_kafka 的目录, 放置了 Kafka 的 Jolokia 拉取规则的样例. 把 input.jolokia_agent_kafka 重命名为 input.jolokia_agent, 然后修改此目录下面的 kafka.toml, 重点关注 urls 和 labels 两个配置.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
urls = <span class="token punctuation">[</span><span class="token string">&quot;http://localhost:3456/jolokia&quot;</span><span class="token punctuation">]</span>
labels = <span class="token punctuation">{</span> cluster = <span class="token string">&quot;kafka-cluster-demo&quot;</span> <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这里建议用 Categraf 采集本机的 Kafka, 并为采集的数据附加一个名为 cluster 的标签. 因为一个公司通常有多个 Kafka 集群, 使用 cluster 标签可以做出区分. 通过 test 参数测试一下采集的指标是否正常.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>./categraf --test --inputs jolokia_agent
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果输出大量的指标, 就说明采集逻辑是正常的, 稍等片刻, 重启 Categraf, 再去监控系统查询一下, 看看数据是否正常上报了.</p> <p><img src="/img/6232732758e3d64f9ba42c1d9ce497c4-20230719203435-hk4j0gh.png" alt=""></p> <p>看下图中的指标, ThreadCount 表示 JVM 里的线程数, 类似的还有 DaemonThreadCount, 表示后台线程数, PeakThreadCount 表示历史峰值线程数. JVM 要重点关注 GC 的情况和内存的情况, 看下相关指标.</p> <p>GC 主要看次数和时间, 分为 YongGC 和 FullGC, YongGC 很正常, 频率也比较高, FullGC 正常情况下很少发生, 如果经常发生, FullGC 程序的性能就会受影响. GC 次数的指标是 kafka_java_garbage_collector_CollectionCount, 是一个 Counter 类型单调递增的值. GC 时间的指标是 kafka_java_garbage_collector_CollectionTime, 也是一个 Counter 类型单调递增的值. 这类指标通常使用 increase 或 irate 函数计算增量或速率, 不关心当前值是多少.</p> <p>内存的指标是 kafka_java_memory_pool_Usage_used, 单位是 byte. 有个 name 标签标识了具体是哪个区域的内存大小, 比如 Eden 区, Survivor 区, Old 区. 下面仪表盘的中间部分, 就是这个内存指标, 变化比较剧烈的是 Eden 区, 每隔一段时间就会 GC 一次, Eden 区的内存使用量就会降下来, 过段时间又会随着使用而上升, 然后再次 GC, 量又会降下来, 循环往复.</p> <p><img src="/img/c969cb5166a66c3a6a02f907c9f2fc18-20230719203435-4y6nmgc.png" alt=""></p> <p><strong>所有 Java 类程序, 都需要关注这些 JVM 的指标</strong>, 相关指标的采集方法在 kafka.toml 中有样例, 就是这些 java.lang 打头的 MBean.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name  = <span class="token string">&quot;java_runtime&quot;</span>
  mbean = <span class="token string">&quot;java.lang:type=Runtime&quot;</span>
  paths = <span class="token punctuation">[</span><span class="token string">&quot;Uptime&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name  = <span class="token string">&quot;java_memory&quot;</span>
  mbean = <span class="token string">&quot;java.lang:type=Memory&quot;</span>
  paths = <span class="token punctuation">[</span><span class="token string">&quot;HeapMemoryUsage&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;NonHeapMemoryUsage&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ObjectPendingFinalizationCount&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name     = <span class="token string">&quot;java_garbage_collector&quot;</span>
  mbean    = <span class="token string">&quot;java.lang:name=*,type=GarbageCollector&quot;</span>
  paths    = <span class="token punctuation">[</span><span class="token string">&quot;CollectionTime&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CollectionCount&quot;</span><span class="token punctuation">]</span>
  tag_keys = <span class="token punctuation">[</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name  = <span class="token string">&quot;java_last_garbage_collection&quot;</span>
  mbean = <span class="token string">&quot;java.lang:name=G1 Young Generation,type=GarbageCollector&quot;</span>
  paths = <span class="token punctuation">[</span><span class="token string">&quot;LastGcInfo/duration&quot;</span><span class="token punctuation">]</span>
  # paths = <span class="token punctuation">[</span><span class="token string">&quot;LastGcInfo/duration&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;LastGcInfo/GcThreadCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;LastGcInfo/memoryUsageAfterGc&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name  = <span class="token string">&quot;java_threading&quot;</span>
  mbean = <span class="token string">&quot;java.lang:type=Threading&quot;</span>
  paths = <span class="token punctuation">[</span><span class="token string">&quot;TotalStartedThreadCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ThreadCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;DaemonThreadCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;PeakThreadCount&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name  = <span class="token string">&quot;java_class_loading&quot;</span>
  mbean = <span class="token string">&quot;java.lang:type=ClassLoading&quot;</span>
  paths = <span class="token punctuation">[</span><span class="token string">&quot;LoadedClassCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;UnloadedClassCount&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;TotalLoadedClassCount&quot;</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>instances.metric<span class="token punctuation">]</span><span class="token punctuation">]</span>
  name     = <span class="token string">&quot;java_memory_pool&quot;</span>
  mbean    = <span class="token string">&quot;java.lang:name=*,type=MemoryPool&quot;</span>
  paths    = <span class="token punctuation">[</span><span class="token string">&quot;Usage&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;PeakUsage&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CollectionUsage&quot;</span><span class="token punctuation">]</span>
  tag_keys = <span class="token punctuation">[</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><p>到这里, JVM 的常规指标就讲完了. 如果想采集其他指标, 可以使用 JConsole 连到 JMX 端口, 查看相关 MBean 的信息, 在 Categraf 里新增 <code>[[instances.metric]]</code>​ 的配置即可.</p> <h4 id="kafka指标"><a href="#kafka指标" class="header-anchor">#</a> Kafka指标</h4> <p>kafka.toml 中还有很多 Kafka Broker 的 JMX 指标. 然而 Kafka 的指标实在是太多了, 其中有些指标只是为了调试而设置的. 哪些指标更为关键, 应该配置告警, 哪些应该放到仪表盘里, 哪些压根就无需关注, 比较难梳理, 好在目前这方面的资料比较丰富, 一定程度上是有共识的, 下面就来讲一下这些共识性的关键指标.</p> <h5 id="_1-活跃控制器数量"><a href="#_1-活跃控制器数量" class="header-anchor">#</a> 1.活跃控制器数量</h5> <blockquote><p>MBean: broker kafka.controller:type=KafkaController,name=ActiveControllerCount</p></blockquote> <p>一个 Kafka 集群有多个 Broker, 正常来讲其中一个 Broker 会是活跃控制器, 且只能有一个. 从整个集群角度来看, SUM 所有 Broker 的这个指标, 结果应该为 1. 如果 SUM 的结果为 2, 也就是说, 有两个 Broker 都认为自己是活跃控制器. 这可能是网络分区导致的, 需要重启 Kafka Broker 进程. 如果重启了不好使, 可能是依赖的 ZooKeeper 出现了网络分区, 需要先去解决 ZooKeeper 的问题, 然后重启 Broker 进程.</p> <h5 id="_2-非同步分区数量"><a href="#_2-非同步分区数量" class="header-anchor">#</a> 2.非同步分区数量</h5> <blockquote><p>MBean: kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions</p></blockquote> <p>这个指标是对每个 Topic 的每个分区的统计, 如果某个分区主从同步出现问题, 对应的数值就会大于 0. 常见的原因比如某个 Broker 出问题了, 一般是 Kafka 进程问题或者所在机器的硬件问题, 那么跟这个 Broker 相关的分区就全部都有问题, 这个时候出问题的分区数量大致是恒定的. 如果出问题的分区数量不恒定, 可能是集群性能问题导致的, 需要检查硬盘 I/O, CPU 之类的指标.</p> <h5 id="_3-离线分区数量"><a href="#_3-离线分区数量" class="header-anchor">#</a> 3.离线分区数量</h5> <blockquote><p>MBean: kafka.controller:type=KafkaController,name=OfflinePartitionsCount</p></blockquote> <p>这个指标只有集群控制器才有, 其他 Broker 这个指标的值是 0, 表示集群里没有 leader 的分区数量. Kafka 主要靠 leader 副本提供读写能力, 如果有些分区没有 leader 副本了, 显然就无法读写了, 是一个非常严重的问题.</p> <h5 id="_4-离线日志目录数量"><a href="#_4-离线日志目录数量" class="header-anchor">#</a> 4.离线日志目录数量</h5> <blockquote><p>MBean: kafka.log:type=LogManager,name=OfflineLogDirectoryCount</p></blockquote> <p>Kafka 是把收到的消息存入 log 目录, 如果 log 目录有问题, 比如写满了, 就会被置为 Offline, 及时监控离线日志目录的数量显然非常有必要. 如果这个值大于 0, 想进一步知道具体是哪个目录出问题了, 可以查询 MBean: kafka.log:type=LogManager,name=LogDirectoryOffline,logDirectory=*&quot;, LogDirectory 字段会标明具体是哪个目录.</p> <h5 id="_5-流入流出字节和流入消息"><a href="#_5-流入流出字节和流入消息" class="header-anchor">#</a> 5.流入流出字节和流入消息</h5> <p>这是典型的吞吐指标, 既有 Broker 粒度的, 也有 Topic 粒度的, 名字都一样, Topic 粒度的指标数据 MBean ObjectName 会多一个 topic=xx 的后缀.</p> <h5 id="_6-流入字节"><a href="#_6-流入字节" class="header-anchor">#</a> 6.流入字节</h5> <blockquote><p>MBean: kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec</p></blockquote> <p>这个指标 Kafka 在使用 Yammer Metrics 埋点的时候, 设置为了 Meter 类型, 所以 Yammer 会自动计算出 Count, OneMinuteRate, FiveMinuteRate, FifteenMinuteRate, MeanRate 等指标, 也就是 1 分钟, 5 分钟, 15 分钟内的平均流入速率, 以及整体平均流入速率. 而 Count 表示总量, 如果时序库支持 PromQL, 就只采集 Count, 其他的不用采集, 后面使用 PromQL 对 Count 值做 irate 计算即可.</p> <h5 id="_7-流出字节"><a href="#_7-流出字节" class="header-anchor">#</a> 7.流出字节</h5> <blockquote><p>MBean: kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec</p></blockquote> <p>和 BytesInPerSec 类似, 表示出向流量. 不过需要注意的是, 流出字节除了普通消费者的消费流量, 也包含了副本同步流量.</p> <h5 id="_8-流入消息"><a href="#_8-流入消息" class="header-anchor">#</a> 8.流入消息</h5> <blockquote><p>MBean: kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec</p></blockquote> <p>BytesInPerSec 和 BytesOutPerSec 都是以 byte 为单位统计的, 而 MessagesInPerSec 是以消息个数为单位统计的, 也是 Meter 类型, 相关属性都一样.</p> <p>需要解释一下的是, Kafka 不提供 MessagesOutPerSec, 你可能觉得有点儿奇怪, 有入就得有出才正常嘛. 这是因为消息被拉取的时候, Broker 会把整个&quot;消息批次&quot;发送给消费者, 并不会展开&quot;批次&quot;, 也就没法计算具体有多少条消息了.</p> <h5 id="_9-分区数量"><a href="#_9-分区数量" class="header-anchor">#</a> 9.分区数量</h5> <blockquote><p>MBean: kafka.server:type=ReplicaManager,name=PartitionCount</p></blockquote> <p>这个指标表示某个 Broker 上面总共有多少个分区, 包括 leader 分区和 follower 分区. 如果多个 Broker 分区不均衡, 可能会造成有些 Broker 消耗硬盘空间过快, 这是需要注意的.</p> <h5 id="_10-leader分区数量"><a href="#_10-leader分区数量" class="header-anchor">#</a> 10.leader分区数量</h5> <blockquote><p>MBean: kafka.server:type=ReplicaManager,name=LeaderCount</p></blockquote> <p>这个指标表示某个 Broker 上面总共有多少个 leader 分区, leader 分区负责数据读写, 承接流量, 所以 leader 分区如果不均衡, 会导致某些 Broker 过分繁忙而另一些 Broker 过分空闲, 这种情况也是需要注意的.</p> <p>针对以上关键指标的参考<a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/kafka/dashboard-key-metrics.json" target="_blank" rel="noopener noreferrer">仪表盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>如下.</p> <p><img src="/img/63e093297a9a094fb706e9660a9f0e5a-20230719203435-gfl9nny.png" alt=""></p> <h4 id="lag监控"><a href="#lag监控" class="header-anchor">#</a> Lag监控</h4> <p>最后一个关键点是 <strong>consumer lag 监控</strong>, 俗称<strong>消息队列堆积</strong>, 一起来看一下.</p> <p>每个 Topic 会分成多个 Partition, 每个 Partition 都有一个当前的 offset, 表示生产的消息已经堆积到了什么位置. 每个 Partition 可以被多个 consumergroup 消费, consumergroup 消费的时候, 针对某个 Partition 也会有一个 offset 表示消费位置. 生产者的 offset 减去 consumergroup 的 offset, 就表示滞后量.</p> <p><strong>这个滞后量如果过大, 就表示消费者可能遇到了问题</strong>, 没有及时干活, 这是个很严重的问题. 比如监控数据对即时性要求就很高, 如果通过 Kafka 传输监控数据, 但滞后量很大, 最后呈现给用户的图表可能是几分钟之前的数据, 那意义就不大了.</p> <p>监控 Lag 数据有两个办法, 一个是从 consumer 的 JMX 中获取, 不过只有 Java 的程序才能这么做; 一个是通过网络上的一些  <strong>Exporter 获取</strong>, 因为 Lag 数据太重要了, 所以有人专门写了 Exporter 来采集. 很多 consumer 都是非 Java 语言实现的, 所以这里重点介绍 Exporter 的方案.</p> <p>滞后性, 表示消息差值数量, 这个不太方便设置告警规则, 因为一些消息量巨大的 Topic Lag 值看起来很大, 但是很快就消费完了, 有些消息量很小的 Topic, consumer 可能都挂了, 但是 Lag 值仍然很小. 要是能预估一下队列里的消费时长就好了, 参考历史数据情况进行预估, 如果这个预估的时长变大了, 就表示有问题了. 其实还真有这样的 <a href="https://github.com/davidmparrott/kafka_exporter" target="_blank" rel="noopener noreferrer">Exporter<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, Categraf 就直接集成的这个 Exporter 的代码, 可以直接使用.</p> <p>Categraf 中怎么配置 Kafka 的 Lag 监控呢? 使用 kafka 采集插件, 配置文件在 conf/input.kafka/kafka.toml, 最核心的配置有两个, 一个是 labels, 一个是 kafka_uris, 可以看下配置样例.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
labels = <span class="token punctuation">{</span> cluster=<span class="token string">&quot;tencent-dev&quot;</span> <span class="token punctuation">}</span>
log_level = <span class="token string">&quot;error&quot;</span>
kafka_uris = <span class="token punctuation">[</span><span class="token string">&quot;10.206.16.3:9092&quot;</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>在 labels 中, 建议加一个 cluster 标签. 因为一个公司一般有多个 Kafka 集群, 这样就可以通过这个标签区分, 其次就是 kafka_uris, 一般写一两个就可以了, 不用把所有 Broker 地址全部写上, Categraf 会作为一个 Kafka client 连上集群, 读取 offset 数据. 如果是老集群, offset 信息存在 ZooKeeper 上, 这个时候就要设置 use_zookeeper_lag = true, 并通过 zookeeper_uris 改写 ZooKeeper 的连接地址.</p> <p>Kafka 这个采集插件, 采集的最核心的指标是 kafka_consumer_lag_millis, 可以看一下样例.</p> <p><img src="/img/13e9c573061a675a223131cfd18bd7fb-20230719203435-4jksro8.png" alt=""></p> <p>指标单位是毫秒, 就是一个预估消费时长, 这个指标也放到了 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/kafka/dashboard-key-metrics.json" target="_blank" rel="noopener noreferrer">仪表盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 中, 可以直接导入夜莺使用, 或者参考里边的 PromQL 自己制作 Grafana 大盘.</p> <h4 id="小结-14"><a href="#小结-14" class="header-anchor">#</a> 小结</h4> <p>Kafka 是现代分布式系统架构中非常常见的组件, Kafka 运行是否正常, 消息消费是否正常, 都需要重点关注. 监控可以从 4 个层面着手, 机器, JVM, Kafka Broker, Lag. 当然 ZooKeeper 作为 Kafka 重度依赖组件, 也需要监控, 还有就是 producer 和 consumer 也是需要监控的. 不过那是应用程序层面的监控了, 需要研发人员协同来做, 作为组件平台方来讲, 重点还是放在 Broker 层面.</p> <p>机器监控层面, 应该重点关注 CPU, 硬盘I/O, 网络I/O, 以及 Kafka 进程层面占用的资源, 比如打开了多少文件句柄, 最大可以打开多少句柄等.</p> <p>JVM 监控层面, 重点关注 GC 和内存的情况, 如果频繁发生 Old 区 Full GC, Kafka 性能肯定会受影响. 所有 Java 程序都应该监控 JVM, 比如 Tomcat, JBoss, Hadoop, 走 JMX 这个路径是一个典型的方式.</p> <p>Kafka Broker JMX 指标, 重点关注一些大面上的异常指标, Kafka 暴露了太多的 JMX 指标, 如果无法抓取到关键指标, Kafka 监控绝对是噩梦.</p> <p>Lag 监控, 也就是 Topic Partition 的消费者滞后监控, 是 Queue 类程序需要关注的典型指标. 因为一旦消费者跟不上生产者的速度, 消息就会积压, 数据即时性也就会受很大影响.</p> <p>本节思维导图如下:</p> <p><img src="/img/4yy986291dd9dfe6976d839bcbcc9161-20230719203435-qtci8dx.jpg" alt=""></p> <h3 id="_16-组件监控-elasticsearch的关键指标及采集方法有哪些"><a href="#_16-组件监控-elasticsearch的关键指标及采集方法有哪些" class="header-anchor">#</a> 16.组件监控-Elasticsearch的关键指标及采集方法有哪些?</h3> <p>Kafka 是 Java 组件, 主要使用 JMX 的方式采集指标. 本节介绍另一个 Java 组件: Elasticsearch(简称 ES), Elasticsearch 直接通过 HTTP 接口暴露指标, 相比 Kafka 真是简单太多了.</p> <p>Elasticsearch 的监控同样包含多个方面, 操作系统, JVM 层面的关注点和 Kafka 是一样的, 这里不再赘述. 重点关注 Elasticsearch 本身的指标, 它自身的指标有很多, 哪些相对更关键呢? 这就要从 Elasticsearch 的职能和架构说起了.</p> <h4 id="elasticsearch-的职能和架构"><a href="#elasticsearch-的职能和架构" class="header-anchor">#</a> Elasticsearch 的职能和架构</h4> <p>Elasticsearch 的核心职能就是对外提供搜索服务, 所以 <mark><strong>搜索请求的吞吐和延迟</strong></mark> 是非常关键的, 搜索是靠底层的索引实现的, 所以 <mark><strong>索引的性能指标</strong></mark> 也非常关键, Elasticsearch 由一个或多个节点组成集群, <strong>集群自身是否健康</strong> 也是需要监控的.</p> <p>ElasticSearch 的架构非常简单, 一个节点就可以对外提供服务, 不过单点的集群显然有容灾问题, 如果挂掉了就万事皆休了. 一般生产环境, 至少搭建一个三节点的集群.</p> <p><img src="/img/06dfyy8f73ae4cfe9b2f071ee2646d01-20230719203435-u37npiu.jpg" alt="图片"></p> <p>三个节点分别部署三个 Elasticsearch 进程, 这三个进程把 cluster.name 都设置成相同的值, 就可以组成一个集群. Elasticsearch 会自动选出一个 master 节点, 负责管理集群范围内所有的变更, 整个选主过程是自动的, 不需要操心.</p> <p>架构图里绿色的 P0, P1, P2 表示三个分片, R0, R1, R2 代表分片副本, 每个分片有两个副本, 也就是说 P0 对应两个 R0, P1 对应两个 R1, P2 对应两个 R2. 这些分片和副本是否成功分配到 Node 上并落盘写入, 也是一个重要的监控指标.</p> <p>前面知道 Elasticsearch 哪些方面的指标比较关键了, 下面再来看一下这些指标是怎么获取的.</p> <h4 id="elasticsearch暴露指标的方式"><a href="#elasticsearch暴露指标的方式" class="header-anchor">#</a> Elasticsearch暴露指标的方式</h4> <p><strong>Elasticsearch 通过 HTTP 接口方式暴露指标</strong>, 集群整体的健康状况使用 <code>/_cluster/health</code>​ 获取, 这里使用 curl 测试一下.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>ulric@localhost ~ % curl -s -uelastic<span class="token operator">:</span>Pass1234 'http<span class="token operator">:</span><span class="token comment">//10.206.16.3:9200/_cluster/health?pretty'</span>
<span class="token punctuation">{</span>
  <span class="token property">&quot;cluster_name&quot;</span> <span class="token operator">:</span> <span class="token string">&quot;elasticsearch-cluster&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;status&quot;</span> <span class="token operator">:</span> <span class="token string">&quot;green&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;timed_out&quot;</span> <span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
  <span class="token property">&quot;number_of_nodes&quot;</span> <span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
  <span class="token property">&quot;number_of_data_nodes&quot;</span> <span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
  <span class="token property">&quot;active_primary_shards&quot;</span> <span class="token operator">:</span> <span class="token number">216</span><span class="token punctuation">,</span>
  <span class="token property">&quot;active_shards&quot;</span> <span class="token operator">:</span> <span class="token number">432</span><span class="token punctuation">,</span>
  <span class="token property">&quot;relocating_shards&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;initializing_shards&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;unassigned_shards&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;delayed_unassigned_shards&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;number_of_pending_tasks&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;number_of_in_flight_fetch&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;task_max_waiting_in_queue_millis&quot;</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;active_shards_percent_as_number&quot;</span> <span class="token operator">:</span> <span class="token number">100.0</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>这里最关键的信息是 status 字段, 如果是 green, 表示主分片和副本分片都处于正常状态; 如果 status 是 yellow, 表示主分片处于正常状态, 但副本分片有异常状态; 如果 status 是 red, 则表示有主分片是异常状态.</p> <p>其他字段大都是集群统计数据, 比如 number_of_nodes 表示集群共有 3 个节点, number_of_data_nodes 表示集群共有 3 个数据节点, active_primary_shards 表示共有 216 个活跃主分区, active_shards 表示共有 432 个活跃分区.</p> <p>注意在集群正常的情况下, 对集群里的所有节点请求这个接口, 都会返回相同的信息, 所以要获取集群健康状况只需要请求某一个节点即可, 或者都请求一下也没啥大不了的, 数据量也不大.</p> <p>除了 <code>/_cluster/health</code>​ 之外, 其他常见的接口还有 <code>/_cluster/health?level=indices</code>​, <code>/_nodes/stats</code>​, <code>/_nodes/_local/stats</code>​, <code>/_cluster/stats</code>​, <code>/_all/_stats</code>​, 其中最有用的是 <strong>获取节点统计数据的接口</strong>, 下面重点介绍一下.</p> <h4 id="获取节点统计信息"><a href="#获取节点统计信息" class="header-anchor">#</a> 获取节点统计信息</h4> <p><strong>获取节点统计信息</strong>可以使用两个接口, <code>/_nodes/stats</code>​ 会返回集群中所有节点的信息, <code>/_nodes/_local/stats</code>​ 则只返回请求的那个节点的信息.</p> <p>这样的设计, 从监控角度就有两种采集方式, 一种是<strong>在中心部署监控采集器</strong>, 连上某一台 Elasticsearch 节点, 从这个节点获取所有其他节点的信息, 可以看一下架构图.</p> <p><img src="/img/7c9a200d6bebba9d69705678ea06b799-20230719203435-4yw5lnz.png" alt="图片"></p> <p>另一种方式, 是把<strong>监控采集器部署在所有节点</strong>上, 调用各自节点上 ES 进程的 local 接口, 可以看一下架构图.</p> <p><img src="/img/yy228e4d6378f7ffc7bac3765b5525a9-20230719203435-ku4dihh.png" alt=""></p> <p>​<code>/_nodes/stats</code>​ 接口返回的内容非常丰富, 看一个样例.</p> <p><img src="/img/aa98cf47e4067d8584547d83a6683cfd-20230719203435-31t1ab3.png" alt="图片"></p> <p>nodes 字段是个大 map, map 的 key 是 node_id, map 的 value 就是各类统计指标, 其中最关键的是 <strong>indices</strong>, 也就是索引相关的. 除此之外, 还有 os 操作系统相关的, process 进程相关的, jvm 相关的, thread_pool 线程池相关的, fs 文件系统相关的, transport 网络吞吐相关的, http 各个接口请求相关的各类指标. 我们可以通过在 URL 中传参的方式告诉 ES 只返回某些特定数据, 比如:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>/_nodes/stats/indices<span class="token punctuation">,</span>os
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这种接口调用方式, 只会返回索引和操作系统相关的指标. 这个接口返回的内容非常关键, 下面来挑选一些关键信息进行解读一下.</p> <h4 id="节点统计信息解读"><a href="#节点统计信息解读" class="header-anchor">#</a> 节点统计信息解读</h4> <p>索引部分是最关键的, 先来看索引部分.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>    <span class="token property">&quot;indices&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;docs&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;count&quot;</span><span class="token operator">:</span> <span class="token number">45339548</span><span class="token punctuation">,</span>
            <span class="token property">&quot;deleted&quot;</span><span class="token operator">:</span> <span class="token number">2</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token property">&quot;shard_stats&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;total_count&quot;</span><span class="token operator">:</span> <span class="token number">144</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token property">&quot;store&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;size_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">15882899598</span><span class="token punctuation">,</span>
            <span class="token property">&quot;total_data_set_size_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">15882899598</span><span class="token punctuation">,</span>
            <span class="token property">&quot;reserved_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>docs 统计了<strong>文档的数量</strong>, 包括还没有从段(segments)里清除的已删除文档数量.</li> <li>shard_stats 统计了<strong>分片的数量</strong>.</li> <li>store 统计了<strong>存储的情况</strong>, 包括主分片和副本分片总共耗费了多少物理存储.</li></ul> <p>indexing, get, search, merges, refresh, flush 等, 都是类似的, 统计了 Elasticsearch 各个关键环节的吞吐和耗时, 其中比较关键的是 indexing, search, merge, 下面是数据样例.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>    <span class="token property">&quot;indexing&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;index_total&quot;</span><span class="token operator">:</span> <span class="token number">18595844</span><span class="token punctuation">,</span>
        <span class="token property">&quot;index_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">1868991</span><span class="token punctuation">,</span>
        <span class="token property">&quot;index_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;index_failed&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;delete_total&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;delete_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;delete_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;noop_update_total&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;is_throttled&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
        <span class="token property">&quot;throttle_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;search&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;open_contexts&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;query_total&quot;</span><span class="token operator">:</span> <span class="token number">140847</span><span class="token punctuation">,</span>
        <span class="token property">&quot;query_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">59976</span><span class="token punctuation">,</span>
        <span class="token property">&quot;query_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;fetch_total&quot;</span><span class="token operator">:</span> <span class="token number">1333</span><span class="token punctuation">,</span>
        <span class="token property">&quot;fetch_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">990</span><span class="token punctuation">,</span>
        <span class="token property">&quot;fetch_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;scroll_total&quot;</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
        <span class="token property">&quot;scroll_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">86</span><span class="token punctuation">,</span>
        <span class="token property">&quot;scroll_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;suggest_total&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;suggest_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;suggest_current&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;merges&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;current&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;current_docs&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;current_size_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total&quot;</span><span class="token operator">:</span> <span class="token number">64937</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">7170896</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_docs&quot;</span><span class="token operator">:</span> <span class="token number">1341992706</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_size_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">140455785325</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_stopped_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_throttled_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">160061</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_auto_throttle_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">6707112372</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br></div></div><p><strong>indexing</strong> 是统计索引过程, ES 的架构里, 索引是非常关键的一个东西, 索引的吞吐和耗时都应该密切关注, index_total 和 index_time_in_millis 都是 Counter 类型的指标, 单调递增. 如果要求取最近一分钟的索引数量和平均延迟, 就需要使用 increase 函数求增量. throttle_time_in_millis 表示受限的时间, 索引不能耗费太多资源, 如果占用了太多资源就影响其他的操作, 应该限制一下, 这个指标就表示总计被限制的时间.</p> <p><strong>search</strong> 描述在活跃中的搜索(open_contexts)数量, 查询的总数量, 以及自节点启动以来在查询上消耗的总时间. 用 increase(query_time_in_millis[1m]) / increase(query_total[1m]) 计算出来的比值, 可以用来粗略地评价查询有多高效. 比值越大, 每个查询花费的时间越多, 到一定程度就要考虑调优了.</p> <p><strong>fetch</strong> 统计值展示了查询处理的后一半流程, 也就是 query-then-fetch 里的 fetch 部分. 如果 fetch 耗时比 query 还多, 说明磁盘较慢, 可能是获取了太多文档, 或者搜索请求设置了太大的分页.</p> <p><strong>merges</strong> 包括了 Lucene 段合并相关的信息. 它会告诉你目前在运行几个合并, 合并涉及的文档数量, 正在合并的段的总大小, 以及在合并操作上消耗的总时间. 合并要消耗大量的磁盘 I/O 和 CPU 资源, 如果 merge 操作耗费太多资源, 也会被限制, 即 total_throttled_time_in_millis 指标.</p> <p>除了索引信息之外,  还直接在 HTTP 接口中暴露了操作系统, 进程, JVM 相关的指标, 下面也简单看一下.</p> <p>操作系统层面的指标, 既可以使用 Elasticsearch 自己暴露的数据, 也可以使用监控采集器直接采集的数据, 比如 Categraf 默认会采集 CPU, 内存, 磁盘, IO, 网络, 进程等多种信息. 这里要解决的关键问题是, **如何通过相同的大盘变量过滤 Elasticsearch 的指标和操作系统的指标? **  从 Elasticsearch 接口采集到的指标, 会带有一个 node_host 标签, 放置的是机器的 IP, 一般都是使用这个标签过滤数据, 比如下面这个样例.</p> <p><img src="/img/26395b87fefdba2025068214e666329d-20230719203435-lv06nsw.png" alt="图片"></p> <p>要想使用机器 IP 过滤操作系统的指标, 就需要在采集器上报数据的时候, 同时把机器 IP 作为标签上报. 如果是 Categraf 的话, hostname 要配置为 <code>&quot;$ip&quot;</code>​, 如果是 Telegraf 的话, 就需要手工配置写死本机 IP 了. 当然,如果不使用监控采集器采集的操作系统指标, 直接复用 Elasticsearch 接口中吐出的那些指标, 就没有这个过滤问题了, 因为 Elasticsearch 的数据标签天然就是统一的.</p> <p>JVM 相关的指标, 上一讲 Kafka 监控已经介绍过了, 不过当时是采用 JMX 方式获取的, Elasticsearch 则更为简单, 在 <code>/_nodes/stats</code>​ 接口中直接暴露了 JVM 指标, GC, 内存池等数据都有, 只是最终的指标命名方式和 Kafka 不同. 下面是 JVM 相关指标的样例供参考.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;timestamp&quot;</span><span class="token operator">:</span> <span class="token number">1670041198455</span><span class="token punctuation">,</span>
    <span class="token property">&quot;uptime_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">92165514</span><span class="token punctuation">,</span>
    <span class="token property">&quot;mem&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;heap_used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">752914744</span><span class="token punctuation">,</span>
        <span class="token property">&quot;heap_used_percent&quot;</span><span class="token operator">:</span> <span class="token number">35</span><span class="token punctuation">,</span>
        <span class="token property">&quot;heap_committed_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">2147483648</span><span class="token punctuation">,</span>
        <span class="token property">&quot;heap_max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">2147483648</span><span class="token punctuation">,</span>
        <span class="token property">&quot;non_heap_used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">265504880</span><span class="token punctuation">,</span>
        <span class="token property">&quot;non_heap_committed_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">269877248</span><span class="token punctuation">,</span>
        <span class="token property">&quot;pools&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;young&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">289406976</span><span class="token punctuation">,</span>
                <span class="token property">&quot;max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">1283457024</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token property">&quot;old&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">419899904</span><span class="token punctuation">,</span>
                <span class="token property">&quot;max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">2147483648</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">641861120</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">2147483648</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token property">&quot;survivor&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">43607864</span><span class="token punctuation">,</span>
                <span class="token property">&quot;max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">115343360</span><span class="token punctuation">,</span>
                <span class="token property">&quot;peak_max_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;threads&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;count&quot;</span><span class="token operator">:</span> <span class="token number">150</span><span class="token punctuation">,</span>
        <span class="token property">&quot;peak_count&quot;</span><span class="token operator">:</span> <span class="token number">161</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;gc&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;collectors&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;young&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;collection_count&quot;</span><span class="token operator">:</span> <span class="token number">8501</span><span class="token punctuation">,</span>
                <span class="token property">&quot;collection_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">157112</span>
            <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token property">&quot;old&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
                <span class="token property">&quot;collection_count&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token property">&quot;collection_time_in_millis&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;buffer_pools&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;mapped&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;count&quot;</span><span class="token operator">:</span> <span class="token number">2490</span><span class="token punctuation">,</span>
            <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">9927166600</span><span class="token punctuation">,</span>
            <span class="token property">&quot;total_capacity_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">9927166600</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token property">&quot;direct&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;count&quot;</span><span class="token operator">:</span> <span class="token number">129</span><span class="token punctuation">,</span>
            <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">6017066</span><span class="token punctuation">,</span>
            <span class="token property">&quot;total_capacity_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">6017065</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token property">&quot;mapped - 'non-volatile memory'&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token property">&quot;count&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token property">&quot;used_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token property">&quot;total_capacity_in_bytes&quot;</span><span class="token operator">:</span> <span class="token number">0</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">&quot;classes&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;current_loaded_count&quot;</span><span class="token operator">:</span> <span class="token number">28215</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_loaded_count&quot;</span><span class="token operator">:</span> <span class="token number">28291</span><span class="token punctuation">,</span>
        <span class="token property">&quot;total_unloaded_count&quot;</span><span class="token operator">:</span> <span class="token number">76</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br></div></div><h4 id="elasticsearch-指标采集配置"><a href="#elasticsearch-指标采集配置" class="header-anchor">#</a> Elasticsearch 指标采集配置</h4> <p>下面进入采集环节, 看看怎么通过 Categraf 收集这些指标.</p> <p>Categraf 采集 Elasticsearch 的配置文件在 <code>conf/input.elasticsearch/elasticsearch.toml</code>​, 看里边的一些关键配置.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>labels = <span class="token punctuation">{</span> cluster=<span class="token string">&quot;cloud-n9e-es&quot;</span> <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>先看标签配置, 这里建议手工加一个 cluster 标签, 因为一个公司通常有多个 Elasticsearch 集群, 可以通过这个标签来区分. 实际上, 每个 Elasticsearch 集群都有一个自己的名字, 会放到 cluster_name 标签中, 不过有可能多个集群可能使用了相同的 cluster.name, 这样就没法通过内置的名字区分了, 还是在标签中直接新增一个 cluster 标签比较稳妥.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>servers = <span class="token punctuation">[</span><span class="token string">&quot;http://localhost:9200&quot;</span><span class="token punctuation">]</span>
local = <span class="token boolean">false</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>servers 用来配置 Elasticsearch 节点的地址, 如果后面的 local 配置为 false, 这里就只需要配置一台 Elasticsearch 的地址, 通过这一个地址拉取整个集群的监控指标, 还有其他机器的节点指标. 这种方式虽然简单, 但是可能会对集群性能有些影响, 集群节点数量不多是可以的, 但如果集群有大几十个节点, 就要注意一下了.</p> <p>如果 local 配置为 true, 就表示从 <code>/_nodes/_local/stats</code>​ 获取本地节点的信息, 那就要分别采集所有的节点了. 要么在 servers 中配置所有的 Elasticsearch 节点列表做远程拉取, 要么就是把 Elasticsearch 和 Categraf 做成一对一的关系, 让 Categraf 采集 localhost 上的 Elasticsearch.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>cluster_health = <span class="token boolean">true</span>
## Adjust cluster_health_level when you want to obtain detailed health stats
## The options are
##  - indices (default)
##  - cluster
cluster_health_level = <span class="token string">&quot;cluster&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>cluster_health 用来控制是否采集集群健康指标, 即是否拉取 <code>/_cluster/health</code>​ 接口的数据. 这个接口可以传入 level 参数, 用 cluster_health_level 来控制是拉取 cluster 集群级别的数据, 还是拉取 indices 索引级别的数据. 平时监控 cluster 级别就够了, 如果 cluster 级别是 yellow 或 red 了, 可以再手工查看索引级别的数据, 排查具体是哪个索引的问题.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>cluster_stats = <span class="token boolean">true</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>cluster_stats 用于控制是否采集集群层面的统计指标, 默认采集即可, 这个数量不算大. 这个数据只从主节点拉取, 如果当前节点不是主节点, 会跳过这个采集逻辑.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>## Indices to collect; can be one or more indices names or _all
## Use of wildcards is allowed. Use a wildcard at the end to retrieve index names that end with a changing value<span class="token punctuation">,</span> like a date.
# indices_include = <span class="token punctuation">[</span><span class="token string">&quot;zipkin*&quot;</span><span class="token punctuation">]</span>

## use <span class="token string">&quot;shards&quot;</span> or blank string for indices level
indices_level = <span class="token string">&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>indices_include 支持通配符, 配置要采集哪些索引的 _stats 信息, 如果想采集所有的索引, 设置为 _all 就可以. 索引的 _stats 接口也支持 level 参数, 可以用 indices_level 来控制是获取索引颗粒度的数据, 还是分片颗粒度的数据.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>node_stats = <span class="token punctuation">[</span><span class="token string">&quot;jvm&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;breaker&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;process&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;os&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;fs&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;indices&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;thread_pool&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;transport&quot;</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>node_stats 用来选择拉取节点的哪些信息, 就是 <code>/_nodes/stats/indices,os</code>​ 接口最后面那部分参数. 默认配置就够用了, 里边有个 HTTP 部分, 指标非常多, 不建议采集, 默认配置里也没有.</p> <p>其他的配置不是很关键, 就不过多介绍了, 这里把前面这些关键指标做成了一个 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/elasticsearch/dashboard.json" target="_blank" rel="noopener noreferrer">监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 也可以看一下效果图.</p> <p><img src="/img/d11aaeeaf950179e02026fe4f5915d0b-20230719203435-5mh9esi.png" alt=""><img src="/img/0c34c70a6a2571ea0b3e849f7797088c-20230719203435-kdfu2qd.png" alt=""></p> <h4 id="小结-15"><a href="#小结-15" class="header-anchor">#</a> 小结</h4> <p>Elasticsearch 的核心职能就是提供搜索服务, 搜索的数据要提前建立索引, 为了支持海量数据, Elasticsearch 还能组成集群, 所以 **搜索性能, 索引性能, 集群健康状况以及集群中各个节点的健康状况, 就是我们要监控的核心指标. **</p> <p>Elasticsearch 暴露指标的方式非常简单, 就是<strong>几个 HTTP 接口, 返回 JSON 数据, 直接拉取解析</strong>即可, 比 JMX 方式简单得多. 要关注的核心是 <code>/_cluster/health</code>​ 和 <code>/_nodes/stats</code>​ 这两个接口, 一个用来获取<strong>整个集群的监控数据, 一个用来获取节点粒度的监控数据</strong>. <code>/_nodes/stats</code>​ 接口返回的数据非常丰富, 不但有索引类指标, 还有 OS, JVM, Process, ThreadPool 指标, 重点关注索引相关的指标和 JVM 相关的指标.</p> <p>本节思维导图如下:</p> <p><img src="/img/dd6c9e2770e228674223681470bf02a0-20230719203435-iwmjbot.jpg" alt="图片"></p> <h3 id="_17-组件监控-kubernetesnode组件的关键指标与数据采集"><a href="#_17-组件监控-kubernetesnode组件的关键指标与数据采集" class="header-anchor">#</a> 17.组件监控-KubernetesNode组件的关键指标与数据采集</h3> <p>本节介绍的是云原生时代的扛把子 Kubernetes 的监控, 云原生这个词就是随着 Kubernetes 火起来的. Kubernetes 架构比较复杂, 这里会用两讲的时间来分享.</p> <p>虽然网上可以找到基于 Prometheus 做的 Operator, 一键监控 Kubernetes, 但是很多人仍然不知其所以然, 这两讲会按照组件粒度来讲, 争取让你理解其中的原理, 至于后面用什么工具来落地, 那都是技术的层面了, 好办.</p> <p>要监控 Kubernetes, 得先弄明白 Kubernetes 有哪些模块要监控, 所以先来看一下 Kubernetes 的架构.</p> <h4 id="kubernetes架构"><a href="#kubernetes架构" class="header-anchor">#</a> Kubernetes架构</h4> <p>下面是 Kubernetes 的架构图, 用户交互部分是 UI 和 CLI, 这两个不需要监控, 关键是 <strong>Control plane(控制面)和 Worker node(工作负载节点)</strong> . 控制面的组件提供了管理和调度能力, 如果控制面组件出了问题, 就没法给 Kubernetes 下发指令了. 工作负载节点运行了容器, 以及管理这些容器的运行时引擎(图上的 Docker), 管理 Pod 的 Kubelet, 以及转发规则的 Kube-Proxy. 工作负载节点如果出问题, 可能会直接影响业务流量, 所以对这类节点的监控就显得更为重要了.</p> <p><img src="/img/5b1e70e4d2b006ef451e7689086b2e99-20230719203435-blq7xrg.png" alt="图片"></p> <p>当然, 除了控制面组件和工作负载节点的监控, 整个 Kubernetes 监控体系还应该包含另外三部分, 一个是 Kubernetes 所在<strong>宿主</strong>的监控, 一个是 Kubernetes 上面<strong>运行对象</strong>的监控, 还有一个<strong>是 Pod 内业务</strong>的监控. 宿主的监控就是机器的监控, 前面已经介绍过. Kubernetes 的对象监控, 使用 kube-state-metrics(简称 KSM) 监控. Pod 内的业务的监控, 已经超过了组件监控的范畴, 后面会详细介绍.</p> <p>所以 Kubernetes 组件监控的这两讲, 会重点介绍控制面, 工作负载, KSM 三个方面的监控. 随着越来越多公司选择公有云的 Kubernetes 托管服务, 控制面的组件直接交给云厂商来托管了, 只需要关注工作负载节点, 所以这一讲先来介绍工作负载节点的监控.</p> <p>工作负载节点重点关注两部分, 一个是<strong>容器负载</strong>, 一个是<strong>组件</strong>, 组件又包括 <strong>Kube-Proxy, Kubelet, 容器引擎</strong>. 容器引擎一般不会出问题, 所以重点关注 Kubernetes 的两个组件 <strong>Kube-Proxy 和 Kubelet</strong>. 按照先易后难, 循序渐进的顺序, 先来看一下 Kube-Proxy 的监控方案.</p> <h4 id="监控kube-proxy"><a href="#监控kube-proxy" class="header-anchor">#</a> 监控Kube-Proxy</h4> <p>所有的 Kubernetes 组件, 都提供了 <code>/metrics</code>​ <strong>接口</strong>用来暴露监控数据, Kube-Proxy 也不例外. 通过 <code>ss</code>​ 或者 <code>netstat</code>​ 命令可以看到 Kube-Proxy 监听的端口, 一个是 10249, 用来暴露监控指标, 一个是 10256, 作为健康检查的端口, 一般只关注前一个端口. 下面来测试一下.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span>root@tt-fc-dev01.nj ~<span class="token punctuation">]</span># curl -s localhost<span class="token operator">:</span><span class="token number">10249</span>/metrics | head -n <span class="token number">6</span>
# HELP apiserver_audit_event_total <span class="token punctuation">[</span>ALPHA<span class="token punctuation">]</span> Counter of audit events generated and sent to the audit backend.
# TYPE apiserver_audit_event_total counter
apiserver_audit_event_total <span class="token number">0</span>
# HELP apiserver_audit_requests_rejected_total <span class="token punctuation">[</span>ALPHA<span class="token punctuation">]</span> Counter of apiserver requests rejected due to an error in audit logging backend.
# TYPE apiserver_audit_requests_rejected_total counter
apiserver_audit_requests_rejected_total <span class="token number">0</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>不需要认证直接就可以拿到指标, 很简单, 只要有个<strong>采集器</strong>能够抓取这个数据就可以了. 支持 Prometheus 协议数据抓取的采集器挺多的, 这里还是使用 Categraf 进行演示.</p> <h5 id="_1-配置采集规则"><a href="#_1-配置采集规则" class="header-anchor">#</a> 1.配置采集规则</h5> <p>抓取 Prometheus 协议的数据, 使用 Categraf 的 input.prometheus 插件, 配置文件在 <code>conf/input.prometheus/prometheus.toml</code>​, 要抓取哪个目标地址, 就直接把 URL 配置到抓取地址中, 可以参考下面的样例.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>interval = <span class="token number">15</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span>instances<span class="token punctuation">]</span><span class="token punctuation">]</span>
urls = <span class="token punctuation">[</span>
     <span class="token string">&quot;http://localhost:10249/metrics&quot;</span>
<span class="token punctuation">]</span>
labels = <span class="token punctuation">{</span> job=<span class="token string">&quot;kube-proxy&quot;</span> <span class="token punctuation">}</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>之后我们就可以使用 <code>./categraf --test --inputs prometheus</code>​ 测试了, 如果一切正常, 在控制台就能看到采集到的 Kube-Proxy 相关的指标, 具体哪些指标比较关键呢? 先不急, 后面我会谈到.</p> <p>Kube-Proxy 在 Kubernetes 集群的所有节点上部署, 如果使用上面的采集规则配置方式, 就需要在所有 Kubernetes 节点的 Categraf 上配置采集规则, 未来扩容节点的时候, 也要记得在新节点配置采集规则. 如果机器初始化流程做得不错, 也还好, 否则的话就会比较麻烦. 我更推荐的方式, 是把 Categraf 作为 Daemonset 部署, 这样每次新节点扩容, Kubernetes 会自动调度, 省事不少. 下面我来演示一下如何部署 Categraf Daemonset.</p> <h5 id="_2-使用daemonset部署采集器"><a href="#_2-使用daemonset部署采集器" class="header-anchor">#</a> 2.使用Daemonset部署采集器</h5> <p>要把 Categraf 部署为 Daemonset, 需要先创建一个 namespace, 然后把相关的配置做成 ConfigMap, 下面做一个演示, 先创建 namespace.</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token comment"># 创建 namespace</span>
<span class="token punctuation">[</span>work@tt-fc-dev01.nj categraf<span class="token punctuation">]</span>$ kubectl create namespace flashcat
namespace/flashcat created

<span class="token comment"># 查询刚刚创建的namespace, 看是否创建成功</span>
<span class="token punctuation">[</span>work@tt-fc-dev01.nj categraf<span class="token punctuation">]</span>$ kubectl get ns <span class="token operator">|</span> <span class="token function">grep</span> flashcat
flashcat                                 Active   29s
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>然后创建 ConfigMap, ConfigMap 用来放置 Categraf 的主配置 config.toml, 以及 input.prometheus 插件的配置 prometheus.toml, 可以看一下相关的 YAML 内容.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>config
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">config.toml</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    [global]
    hostname = &quot;$HOSTNAME&quot;
    interval = 15
    providers = [&quot;local&quot;]
    [writer_opt]
    batch = 2000
    chan_size = 10000
    [[writers]]
    url = &quot;http://10.206.0.16:19000/prometheus/v1/write&quot;
    timeout = 5000
    dial_timeout = 2500
    max_idle_conns_per_host = 100</span>
<span class="token punctuation">---</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>input<span class="token punctuation">-</span>prometheus
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">prometheus.toml</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    [[instances]]
    urls = [&quot;http://127.0.0.1:10249/metrics&quot;]
    labels = { job=&quot;kube-proxy&quot; }</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><p>上例中的 <code>http://10.206.0.16:19000/prometheus/v1/write</code>​ 是一个支持 Prometheus Remote Write 协议的数据接收地址, 可以使用你的 n9e-server, 也可以使用 vminsert, prometheus 等其他支持 RemoteWrite 协议的地址. <code>hostname = &quot;$HOSTNAME&quot;</code>​ 这个配置用了 <code>$</code>​ 符号, 后面创建 Daemonset 的时候会注入 HOSTNAME 这个环境变量, 让 Categraf 自动拿到.</p> <p>prometheus.toml 的配置中, 除了给出 Kube-Proxy 的抓取地址, 还手工指定了一个 <strong>job 标签</strong>, 用来标识这个数据来自哪个组件. 如果公司有多套 Kubernetes 集群, 所有监控数据都会进到一个时序库, <strong>为了区分不同的集群, 建议在标签里再加一个 cluster 的标签</strong>.</p> <p>比如:</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>labels = <span class="token punctuation">{</span> job=&quot;kube<span class="token punctuation">-</span>proxy&quot;<span class="token punctuation">,</span> cluster=&quot;beijing01&quot; <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>下面把 ConfigMap 创建出来.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>work@tt-fc<span class="token punctuation">]</span>$ kubectl apply <span class="token parameter variable">-f</span> categraf-configmap-v1.yaml <span class="token parameter variable">-n</span> flashcat
configmap/categraf-config created
configmap/categraf-input-prometheus created

<span class="token punctuation">[</span>work@tt-fc<span class="token punctuation">]</span>$ kubectl get configmap <span class="token parameter variable">-n</span> flashcat
NAME                        DATA   AGE
categraf-config             <span class="token number">1</span>      19s
categraf-input-prometheus   <span class="token number">1</span>      19s
kube-root-ca.crt            <span class="token number">1</span>      22m
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>配置文件准备好了, 接下来就可以创建 Daemonset 了. 这里要注意, 把 HOSTNAME 作为环境变量注入进去, 可以参考下面 Daemonset 的 YAML 文件.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> DaemonSet
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">labels</span><span class="token punctuation">:</span>
    <span class="token key atrule">app</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">selector</span><span class="token punctuation">:</span>
    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>
      <span class="token key atrule">app</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
  <span class="token key atrule">template</span><span class="token punctuation">:</span>
    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>
      <span class="token key atrule">labels</span><span class="token punctuation">:</span>
        <span class="token key atrule">app</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
    <span class="token key atrule">spec</span><span class="token punctuation">:</span>
      <span class="token key atrule">containers</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">env</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> TZ
          <span class="token key atrule">value</span><span class="token punctuation">:</span> Asia/Shanghai
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> HOSTNAME
          <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>
            <span class="token key atrule">fieldRef</span><span class="token punctuation">:</span>
              <span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
              <span class="token key atrule">fieldPath</span><span class="token punctuation">:</span> spec.nodeName
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> HOSTIP
          <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>
            <span class="token key atrule">fieldRef</span><span class="token punctuation">:</span>
              <span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
              <span class="token key atrule">fieldPath</span><span class="token punctuation">:</span> status.hostIP
        <span class="token key atrule">image</span><span class="token punctuation">:</span> flashcatcloud/categraf<span class="token punctuation">:</span>v0.2.18
        <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent
        <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
        <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /etc/categraf/conf
          <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>config
        <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /etc/categraf/conf/input.prometheus
          <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>input<span class="token punctuation">-</span>prometheus
      <span class="token key atrule">hostNetwork</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
      <span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span> Always
      <span class="token key atrule">tolerations</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">effect</span><span class="token punctuation">:</span> NoSchedule
        <span class="token key atrule">operator</span><span class="token punctuation">:</span> Exists
      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">configMap</span><span class="token punctuation">:</span>
          <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>config
        <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>config
      <span class="token punctuation">-</span> <span class="token key atrule">configMap</span><span class="token punctuation">:</span>
          <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>input<span class="token punctuation">-</span>prometheus
        <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>input<span class="token punctuation">-</span>prometheus
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br></div></div><p>最后一步, apply 一下这个 Daemonset 的 YAML 文件.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>work@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj yamls<span class="token punctuation">]</span>$ kubectl apply <span class="token punctuation">-</span>f categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>v1.yaml <span class="token punctuation">-</span>n flashcat
daemonset.apps/categraf<span class="token punctuation">-</span>daemonset created

<span class="token punctuation">[</span>work@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj yamls<span class="token punctuation">]</span>$ kubectl get ds <span class="token punctuation">-</span>o wide <span class="token punctuation">-</span>n flashcat
NAME                 DESIRED   CURRENT   READY   UP<span class="token punctuation">-</span>TO<span class="token punctuation">-</span>DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES                           SELECTOR
categraf<span class="token punctuation">-</span>daemonset   6         6         6       6            6           &lt;none<span class="token punctuation">&gt;</span>          2m20s   categraf     flashcatcloud/categraf<span class="token punctuation">:</span>v0.2.17   app=categraf<span class="token punctuation">-</span>daemonset

<span class="token punctuation">[</span>work@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj yamls<span class="token punctuation">]</span>$ kubectl get pods <span class="token punctuation">-</span>o wide <span class="token punctuation">-</span>n flashcat
NAME                       READY   STATUS    RESTARTS   AGE     IP            NODE          NOMINATED NODE   READINESS GATES
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>4qlt9   1/1     Running   0          2m10s   10.206.0.7    10.206.0.7    &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>s9bk2   1/1     Running   0          2m10s   10.206.0.11   10.206.0.11   &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>w77lt   1/1     Running   0          2m10s   10.206.16.3   10.206.16.3   &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>xgwf5   1/1     Running   0          2m10s   10.206.0.16   10.206.0.16   &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>z9rk5   1/1     Running   0          2m10s   10.206.16.8   10.206.16.8   &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>zdp8v   1/1     Running   0          2m10s   10.206.0.17   10.206.0.17   &lt;none<span class="token punctuation">&gt;</span>           &lt;none<span class="token punctuation">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>看起来一切正常, 去监控服务端查询一下 kubeproxy 打头的指标, 理论上就能看到采集到的数据了. Kube-Proxy 暴露了不少指标, 下面挑选一些关键指标稍作解释.</p> <h5 id="_3-kube-proxy指标解释"><a href="#_3-kube-proxy指标解释" class="header-anchor">#</a> 3.Kube-Proxy指标解释</h5> <blockquote><p>通用的Go程序相关的指标</p></blockquote> <p><img src="/img/50c462b926b60257743242d6e425801c-20230719203435-jpyabej.png" alt="图片"></p> <p>以上指标, 只要是通过 Prometheus Go SDK 埋点的程序都会有, 除了 Kube-Proxy, 后面介绍的 Kubelet, APIServer, Scheduler 等, 也全部都有, 这里需要记住.</p> <blockquote><p>请求APIServer的指标</p></blockquote> <p>Kubernetes 中多个组件都要调用 APIServer 的接口, 每秒调用多少次, 有多少成功多少失败, 耗时情况如何, 这些指标也比较关键.</p> <p>比如:</p> <ul><li>rest_client_request_duration_seconds: 请求 APIServer 的耗时统计</li> <li>rest_client_requests_total: 请求 APIServer 的调用量统计</li></ul> <blockquote><p>规则同步类指标</p></blockquote> <p>Kube-Proxy 的核心职能, 就是去 APIServer 获取转发规则, 修改本地的 iptables 或者 ipvs 的规则, 所以这些规则同步相关的指标, 就至关重要了. 这里列出几个核心指标.</p> <p><img src="/img/d8d8db1e76df059c540c67f6928bf030-20230719203435-pg230x7.png" alt="图片"></p> <p>Categraf 内置了 Kube-Proxy 的 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/kube_proxy/dashboard-by-ident.json" target="_blank" rel="noopener noreferrer">监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 关键的核心指标都已经做到监控大盘里了, 导入夜莺就能使用.</p> <h4 id="监控kubelet"><a href="#监控kubelet" class="header-anchor">#</a> 监控Kubelet</h4> <p>下面继续看工作负载节点的第二个组件 Kubelet 应该如何监控.</p> <p>Kubelet 也是在所有 Kubernetes 节点上部署的, 理论上可以采用和 Kube-Proxy 完全一样的监控方法, 但是 Kubelet 的接口需要认证, 来测试一下.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># ps aux|grep kubelet</span>
root      163490  0.0  0.0  12136  1064 pts/1    S+   13<span class="token punctuation">:</span>34   0<span class="token punctuation">:</span>00 grep <span class="token punctuation">-</span><span class="token punctuation">-</span>color=auto kubelet
root      166673  3.2  1.0 3517060 81336 <span class="token punctuation">?</span>       Ssl  Aug16 4176<span class="token punctuation">:</span>52 /usr/bin/kubelet <span class="token punctuation">-</span><span class="token punctuation">-</span>bootstrap<span class="token punctuation">-</span>kubeconfig=/etc/kubernetes/bootstrap<span class="token punctuation">-</span>kubelet.conf <span class="token punctuation">-</span><span class="token punctuation">-</span>kubeconfig=/etc/kubernetes/kubelet.conf <span class="token punctuation">-</span><span class="token punctuation">-</span>config=/var/lib/kubelet/config.yaml <span class="token punctuation">-</span><span class="token punctuation">-</span>hostname<span class="token punctuation">-</span>override=10.206.0.16 <span class="token punctuation">-</span><span class="token punctuation">-</span>network<span class="token punctuation">-</span>plugin=cni <span class="token punctuation">-</span><span class="token punctuation">-</span>pod<span class="token punctuation">-</span>infra<span class="token punctuation">-</span>container<span class="token punctuation">-</span>image=registry.aliyuncs.com/google_containers/pause<span class="token punctuation">:</span><span class="token number">3.6</span>

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># cat /var/lib/kubelet/config.yaml | grep 102</span>
<span class="token key atrule">healthzPort</span><span class="token punctuation">:</span> <span class="token number">10248</span>

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># curl localhost:10248/healthz</span>
ok

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># curl localhost:10250/metrics</span>
Client sent an HTTP request to an HTTPS server.

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># curl https://localhost:10250/metrics</span>
<span class="token key atrule">curl</span><span class="token punctuation">:</span> <span class="token key atrule">(60) SSL certificate problem</span><span class="token punctuation">:</span> self signed certificate in certificate chain
<span class="token key atrule">More details here</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//curl.haxx.se/docs/sslcerts.html

curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it<span class="token punctuation">,</span> please visit the web page mentioned above.
<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj ~<span class="token punctuation">]</span><span class="token comment"># curl -k https://localhost:10250/metrics</span>
Unauthorized
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>这几条测试命令可以说明很多问题, 首先是 Kubelet 监听了两个端口, 一个是 10248, 是个健康检查端口, 另一个是 10250, 暴露 metrics 指标, 但是访问这个接口需要传入 Authorization 的 Token, 下面就来创建 ServiceAccount. Kubernetes 会为 ServiceAccount 自动分配 Token.</p> <h5 id="_1-引入认证信息"><a href="#_1-引入认证信息" class="header-anchor">#</a> 1.引入认证信息</h5> <p>只创建 ServiceAccount 没什么用, 还需要为这个账号绑定权限, Kubernetes 中使用 ClusterRole 来定义权限, 使用 ClusterRoleBinding 来绑定 ClusterRole 和 ServiceAccount, 下面是相关 YAML 定义.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
<span class="token key atrule">rules</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token string">&quot;&quot;</span>
  <span class="token key atrule">resources</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> nodes/metrics
  <span class="token punctuation">-</span> nodes/stats
  <span class="token punctuation">-</span> nodes/proxy
  <span class="token key atrule">verbs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> get
<span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> flashcat
<span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRoleBinding
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
<span class="token key atrule">roleRef</span><span class="token punctuation">:</span>
  <span class="token key atrule">apiGroup</span><span class="token punctuation">:</span> rbac.authorization.k8s.io
  <span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
<span class="token key atrule">subjects</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> flashcat
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><p>把上面的内容保存为 auth.yaml, apply 一下, 然后从 ServiceAccount 中提取 Token, 做一下 metrics 接口的请求测试.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>work@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj yamls<span class="token punctuation">]</span>$ kubectl apply <span class="token punctuation">-</span>f auth.yaml
clusterrole.rbac.authorization.k8s.io/categraf<span class="token punctuation">-</span>daemonset created
serviceaccount/categraf<span class="token punctuation">-</span>daemonset created
clusterrolebinding.rbac.authorization.k8s.io/categraf<span class="token punctuation">-</span>daemonset created

<span class="token punctuation">[</span>work@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj yamls<span class="token punctuation">]</span>$ kubectl get sa <span class="token punctuation">-</span>n flashcat
NAME                 SECRETS   AGE
categraf<span class="token punctuation">-</span>daemonset   1         90m
default              1         4d23h

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj qinxiaohui<span class="token punctuation">]</span><span class="token comment"># kubectl get sa categraf-daemonset -n flashcat -o yaml</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>
    <span class="token key atrule">kubectl.kubernetes.io/last-applied-configuration</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
      {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;ServiceAccount&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;categraf-daemonset&quot;,&quot;namespace&quot;:&quot;flashcat&quot;}}</span>
  <span class="token key atrule">creationTimestamp</span><span class="token punctuation">:</span> <span class="token string">&quot;2022-11-14T03:53:54Z&quot;</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> flashcat
  <span class="token key atrule">resourceVersion</span><span class="token punctuation">:</span> <span class="token string">&quot;120570510&quot;</span>
  <span class="token key atrule">uid</span><span class="token punctuation">:</span> 22f5a785<span class="token punctuation">-</span>871c<span class="token punctuation">-</span>4454<span class="token punctuation">-</span>b82e<span class="token punctuation">-</span>12bf104450a0
<span class="token key atrule">secrets</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset<span class="token punctuation">-</span>token<span class="token punctuation">-</span>7mccq

<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj qinxiaohui<span class="token punctuation">]</span><span class="token comment"># token=`kubectl get secret categraf-daemonset-token-7mccq -n flashcat -o jsonpath={.data.token} | base64 -d`</span>
<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj qinxiaohui<span class="token punctuation">]</span><span class="token comment"># curl -s -k -H &quot;Authorization: Bearer $token&quot; https://localhost:10250/metrics &gt; aaaa</span>
<span class="token punctuation">[</span>root@tt<span class="token punctuation">-</span>fc<span class="token punctuation">-</span>dev01.nj qinxiaohui<span class="token punctuation">]</span><span class="token comment"># head -n 5 aaaa</span>
<span class="token comment"># HELP apiserver_audit_event_total [ALPHA] Counter of audit events generated and sent to the audit backend.</span>
<span class="token comment"># TYPE apiserver_audit_event_total counter</span>
apiserver_audit_event_total 0
<span class="token comment"># HELP apiserver_audit_requests_rejected_total [ALPHA] Counter of apiserver requests rejected due to an error in audit logging backend.</span>
<span class="token comment"># TYPE apiserver_audit_requests_rejected_total counter</span>
apiserver_audit_requests_rejected_total 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br></div></div><p>这几个命令看起来比较清晰了, 创建的 ServiceAccount 名为 categraf-daemonset, 导出为 YAML 之后, 看到 secret 的 name 是 categraf-daemonset-token-7mccq, 然后从这个 secret 中解出 Token, 放到 Header 里, 请求 Kubelet 的 metrics 接口, 最终拿到了数据, 搞定收工.</p> <p>后面把 Categraf 作为采集器做成 Daemonset, 再为 Categraf 这个 Daemonset 指定 ServiceAccountName, Kubernetes就会自动把 Token 的内容挂到 Daemonset 的目录里, 下面开始实操.</p> <h5 id="_2-升级categraf-daemonset"><a href="#_2-升级categraf-daemonset" class="header-anchor">#</a> 2.升级Categraf Daemonset</h5> <p>采集 Kube-Proxy 的时候, 已经准备好了 Categraf Daemonset 用到的 ConfigMap, 当时只是抓取了 Kube-Proxy 的 metrics 数据, 下面升级一下这个 ConfigMap 的内容, 加上对 Kubelet 的数据抓取规则.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>config
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">config.toml</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    [global]
    hostname = &quot;$HOSTNAME&quot;
    interval = 15
    providers = [&quot;local&quot;]
    [writer_opt]
    batch = 2000
    chan_size = 10000
    [[writers]]
    url = &quot;http://10.206.0.16:19000/prometheus/v1/write&quot;
    timeout = 5000
    dial_timeout = 2500
    max_idle_conns_per_host = 100</span>
<span class="token punctuation">---</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>input<span class="token punctuation">-</span>prometheus
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">prometheus.toml</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    [[instances]]
    urls = [&quot;http://127.0.0.1:10249/metrics&quot;]
    labels = { job=&quot;kube-proxy&quot; }
    [[instances]]
    urls = [&quot;https://127.0.0.1:10250/metrics&quot;]
    bearer_token_file = &quot;/var/run/secrets/kubernetes.io/serviceaccount/token&quot;
    use_tls = true
    insecure_skip_verify = true
    labels = { job=&quot;kubelet&quot; }
    [[instances]]
    urls = [&quot;https://127.0.0.1:10250/metrics/cadvisor&quot;]
    bearer_token_file = &quot;/var/run/secrets/kubernetes.io/serviceaccount/token&quot;
    use_tls = true
    insecure_skip_verify = true
    labels = { job=&quot;cadvisor&quot; }</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br></div></div><p>Kubelet 在 10250 端口暴露了两类 metrics 数据, 一个是 <code>/metrics</code>​, 暴露的是 Kubelet 自身的监控数据, 另一个是 <code>/metrics/cadvisor</code>​, 暴露的是容器的监控数据.</p> <p>然后修改一下之前的 Daemonset 的 yaml 文件, 在 hostNetwork 这一行下面增加 ServiceAccountName 配置, 可以看下示例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">hostNetwork</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
<span class="token key atrule">serviceAccountName</span><span class="token punctuation">:</span> categraf<span class="token punctuation">-</span>daemonset
<span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span> Always
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>可以把之前的 Daemonset 直接删除, 使用新的 yaml 重新创建, 稍等片刻, 就能在服务端查询到 Kubelet 和容器的监控数据了.</p> <p><img src="/img/6a51byye73ef6ae2bdc1888d0df8d5ac-20230719203435-5v1tqpt.png" alt="图片"></p> <h5 id="_3-kubelet关键指标"><a href="#_3-kubelet关键指标" class="header-anchor">#</a> 3.Kubelet关键指标</h5> <p>Kubelet 也会吐出 <strong>Go 进程</strong>相关的通用指标以及和 APIServer 通信相关的度量指标, 和 Kube-Proxy 类似. Kubelet 核心职能是管理 Pod, 操作各种 CNI, CSI 相关的接口, 和容器引擎打交道, 度量这类操作的指标就显得尤为关键.</p> <p>比如:</p> <p><img src="/img/ab350235163ca9f4b0b0af717765fe85-20230719203435-ukgee4v.png" alt="图片"></p> <p>Categraf 内置了 Kubelet 的 <a href="https://github.com/flashcatcloud/categraf/blob/main/inputs/kubelet/dashboard-by-ident.json" target="_blank" rel="noopener noreferrer">监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 关键的核心指标都已经做到监控大盘里了, 导入夜莺就能使用.</p> <p>刚才在升级 Categraf Daemonset 的 ConfigMap 的时候, 不只采集了 Kubelet 的指标, 还一并采集了容器的指标, Categraf 也提供了容器的 <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/pod-dash.json" target="_blank" rel="noopener noreferrer">监控大盘<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h5 id="_4-容器负载指标"><a href="#_4-容器负载指标" class="header-anchor">#</a> 4.容器负载指标</h5> <p>关于容器, 这里也选几个核心的指标解释一下. <strong>容器负载主要是关心 CPU, 内存, 网络, IO, 尤其是 CPU 和内存</strong>, 一起看一下相关指标的说明.</p> <h6 id="_1-cpu指标"><a href="#_1-cpu指标" class="header-anchor">#</a> (1)CPU指标</h6> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>sum(
irate(container_cpu_usage_seconds_total<span class="token punctuation">[</span>3m<span class="token punctuation">]</span>)
) by (pod<span class="token punctuation">,</span>id<span class="token punctuation">,</span>namespace<span class="token punctuation">,</span>container<span class="token punctuation">,</span>ident<span class="token punctuation">,</span>image)
/
sum(
container_spec_cpu_quota/container_spec_cpu_period
) by (pod<span class="token punctuation">,</span>id<span class="token punctuation">,</span>namespace<span class="token punctuation">,</span>container<span class="token punctuation">,</span>ident<span class="token punctuation">,</span>image)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>这是计算 CPU 使用率, 整体是一个除法运算, 分子部分是容器每秒耗费的 CPU 时间, 分母部分是每秒分配给容器的 CPU 时间. 里边的 ident 标签是 Categraf 采集时自动加的, 如果采集方式不同, 可能要适当调整 by 后面的标签集.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>increase(container_cpu_cfs_throttled_periods_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>)
/
increase(container_cpu_cfs_periods_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>) * 100
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这是在计算 CPU 被限制的时间比例, 如果这个值很高, 说明容器在使用 CPU 资源的时候经常被限制, 需要提高这个容器的 CPU Quota. 延迟敏感型的应用, 需要特别关注这个指标.</p> <h6 id="_2-内存指标"><a href="#_2-内存指标" class="header-anchor">#</a> (2)内存指标</h6> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>container_memory_working_set_bytes
/
container_spec_memory_limit_bytes
and
container_spec_memory_limit_bytes <span class="token tag">!=</span> 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>计算内存使用率的时候, 核心也是一个除法运算, 分子是容器的内存占用, 分母是内存 Limit 大小. 当然, 有些容器没有指定内存Limit, 所以还需要有个 and 语句来做限制, 只有 limit_bytes 不等于 0, 这个除法运算才有意义.</p> <h6 id="_3-pod网络流量"><a href="#_3-pod网络流量" class="header-anchor">#</a> (3)Pod网络流量</h6> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>irate(container_network_transmit_bytes_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>) * 8
irate(container_network_receive_bytes_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>) * 8
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这个指标名字非常清晰, transmit 是出向, receive 是入向, 这两个指标都是 Counter 类型的值, 单调递增, 所以使用 irate 计算每秒速率. 因为网络流量一般都是用 bit 作为单位, 所以最后乘以 8, 把 byte 换算成 bit.</p> <h6 id="_4-pod硬盘io读写流量"><a href="#_4-pod硬盘io读写流量" class="header-anchor">#</a> (4)Pod硬盘IO读写流量</h6> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>irate(container_fs_reads_bytes_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>)
irate(container_fs_writes_bytes_total<span class="token punctuation">[</span>1m<span class="token punctuation">]</span>)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这个指标名字一看就知道是 Counter 类型, 不关心当前值是多少, 而是关心<strong>最近一段时间</strong>每秒的速率是多少, 所以使用 irate 做了二次计算.</p> <h4 id="小结-16"><a href="#小结-16" class="header-anchor">#</a> 小结</h4> <p>本节介绍了 Kubernetes 的监控, Kubernetes 组件众多, 通过架构图可以看出, 大体上可以分为两部分, 一个是控制面组件, 一个是工作负载节点相关组件. 本节重点介绍了工作负载节点相关的组件, 包括 Kube-Proxy, Kubelet, 容器负载. 当然, 容器引擎是否存活也是需要关注的, 不过容器引擎一般都通过 systemd 托管, 挂掉之后会自动拉起, 出问题的概率很小.</p> <p><strong>Kube-Proxy 的监控比较简单, 通过 metrics 接口直接暴露监控指标, 没有认证鉴权, 使用 Categraf 直接拉取就可以了</strong>. 为了便于管理, 建议把 Categraf 做成 Daemonset. Kube-Proxy 的关键指标分三类: <strong>一是通用的 Go 程序相关的指标, 所有的 Kubernetes 组件都有这类指标; 二是请求 APIServer 相关的指标, 所有请求 APIServer 的模块都有这类指标; 三是规则同步类指标, 因为 Kube-Proxy 核心职能就是要做好规则同步, 所以这类指标是最关键的</strong>.</p> <p>Kubelet 的监控, 相对更复杂, 因为有认证鉴权的要求, 需要创建 ServiceAccount, ClusterRole, ClusterRoleBinding 等对象. 因为 Kubelet 也是在所有宿主上的, 所以采集器也可以部署为 Daemonset. Kubelet 的关键指标是跟操作相关的, 比如操作 Docker 引擎, 操作网络插件等, 这些操作的次数, 成功与否, 都非常关键.</p> <p>Kubelet 的接口还暴露了容器负载指标, 通过 /metrics/cadvisor 来抓取, 重点关注 CPU, 内存, 网络, 硬盘 IO 等指标. CPU 方面尤其要注意容器被限制的时间比例, 对于延迟敏感型业务有较大影响.</p> <p>本节思维导图如下:</p> <p><img src="/img/bcd9aa98db0acb107db94c63db1yy3f1-20230719203435-fvzwy7g.jpg" alt=""></p> <h3 id="_18-组件监控-kubernetes控制面组件的关键指标与数据采集"><a href="#_18-组件监控-kubernetes控制面组件的关键指标与数据采集" class="header-anchor">#</a> 18.组件监控-Kubernetes控制面组件的关键指标与数据采集</h3> <p>前面介绍了 Kubernetes <strong>工作负载节点</strong> 的监控, 了解了 Kube-Proxy, Kubelet, 容器负载监控的方法. 本节介绍 <strong>控制面组件</strong> 的监控, 包括 <strong>APIServer, Controller-manager(简称CM), Scheduler, etcd</strong> 四个组件, 本节会讲解这几个组件监控数据的采集方法和关键指标, 并给出监控大盘. 此外还会学习如何使用 kube-state-metrics(简称 KSM)来监控 Kubernetes 的各类对象.</p> <h4 id="数据采集"><a href="#数据采集" class="header-anchor">#</a> 数据采集</h4> <p>自行搭建 Kubernetes 控制面的朋友, 大都是选择 <strong>Kubeadm</strong> 这样的工具, Kubeadm 会把控制面的组件以静态容器的方式放到容器里运行, 之后会重点演示在这种部署方式下如何采集监控数据.</p> <p>不过很多大一些的互联网公司会选择直接使用<strong>二进制</strong>的方式来部署, 因为二进制的方式对于监控数据采集来说其实更简单, 直接在采集器里配置要抓取的这几个组件的目标地址就可以了.</p> <p>如果想要调用 Kubernetes 服务端 APIServer, Controller-manager, Scheduler 这三个组件的 <code>/metrics</code>​ 接口, 需要有 Token 做鉴权, 因此还是通过创建 ServiceAccount 的方式拿到 Token, 后面也会把采集器直接部署到 Kubernetes 容器里, 这样 Token 信息就可以自动 mount 到容器里, 比较方便.</p> <h5 id="_1-创建认证信息"><a href="#_1-创建认证信息" class="header-anchor">#</a> 1.创建认证信息</h5> <p>相比前面为 Categraf 准备的 <strong>ServiceAccount</strong>, 用于访问控制面组件的 ServiceAccount 会要求更多权限, 这里重新给出一个升级后的 YAML 文件供参考.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
<span class="token key atrule">rules</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;&quot;</span><span class="token punctuation">]</span>
    <span class="token key atrule">resources</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> nodes
      <span class="token punctuation">-</span> nodes/metrics
      <span class="token punctuation">-</span> nodes/stats
      <span class="token punctuation">-</span> nodes/proxy
      <span class="token punctuation">-</span> services
      <span class="token punctuation">-</span> endpoints
      <span class="token punctuation">-</span> pods
    <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;list&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;watch&quot;</span><span class="token punctuation">]</span>
  <span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> extensions
      <span class="token punctuation">-</span> networking.k8s.io
    <span class="token key atrule">resources</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> ingresses
    <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;list&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;watch&quot;</span><span class="token punctuation">]</span>
  <span class="token punctuation">-</span> <span class="token key atrule">nonResourceURLs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;/metrics&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;/metrics/cadvisor&quot;</span><span class="token punctuation">]</span>
    <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">]</span>
<span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> flashcat
<span class="token punctuation">---</span>
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRoleBinding
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
<span class="token key atrule">roleRef</span><span class="token punctuation">:</span>
  <span class="token key atrule">apiGroup</span><span class="token punctuation">:</span> rbac.authorization.k8s.io
  <span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
<span class="token key atrule">subjects</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
  <span class="token key atrule">name</span><span class="token punctuation">:</span> categraf
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> flashcat
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br></div></div><p>使用 <code>kubectl apply</code>​ 一下这个YAML 文件即可. 有了认证信息, 后面就是选型并部署采集器了.</p> <h5 id="_2-部署采集器"><a href="#_2-部署采集器" class="header-anchor">#</a> 2.部署采集器</h5> <p>我们希望能够自动感知到组件实例的变化, 也就是要抓取的目标地址的变化. 毫无疑问要读取 Kubernetes 的元信息, 就需要具备类似 Prometheus 的 Kubernetes 服务发现能力. <strong>支持这个服务发现能力的采集器, 比较常用的是 Telegraf, Prometheus, Categraf, Grafana-agent, vmagent 等, 这里最原汁原味的显然是 Prometheus 自身</strong>.</p> <p>Prometheus 从 v2.32.0 开始支持 agent mode 模式, <strong>相当于把 Prometheus 当做一个采集 agent 来使用, 只负责采集数据</strong>, 这里就使用这个方式来采集数据.</p> <p>agent mode 模式的 Prometheus, 重点要配置 scrape 规则和 remote write 地址, 这里把配置文件做成 ConfigMap, 参考的 YAML 文件如下.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  name<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent<span class="token punctuation">-</span>conf
  labels<span class="token punctuation">:</span>
    name<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent<span class="token punctuation">-</span>conf
  namespace<span class="token punctuation">:</span> flashcat
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  prometheus.yml<span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token punctuation">-</span>
    global<span class="token punctuation">:</span>
      scrape_interval<span class="token punctuation">:</span> 15s
      evaluation_interval<span class="token punctuation">:</span> 15s

    scrape_configs<span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'apiserver'</span>
        kubernetes_sd_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> endpoints
        scheme<span class="token punctuation">:</span> https
        tls_config<span class="token punctuation">:</span>
          insecure_skip_verify<span class="token punctuation">:</span> <span class="token boolean important">true</span>
        authorization<span class="token punctuation">:</span>
          credentials_file<span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">,</span> __meta_kubernetes_service_name<span class="token punctuation">,</span> __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
          action<span class="token punctuation">:</span> keep
          regex<span class="token punctuation">:</span> default;kubernetes;https

      <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'controller-manager'</span>
        kubernetes_sd_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> endpoints
        scheme<span class="token punctuation">:</span> https
        tls_config<span class="token punctuation">:</span>
          insecure_skip_verify<span class="token punctuation">:</span> <span class="token boolean important">true</span>
        authorization<span class="token punctuation">:</span>
          credentials_file<span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">,</span> __meta_kubernetes_service_name<span class="token punctuation">,</span> __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
          action<span class="token punctuation">:</span> keep
          regex<span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system;kube<span class="token punctuation">-</span>controller<span class="token punctuation">-</span>manager;https

      <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'scheduler'</span>
        kubernetes_sd_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> endpoints
        scheme<span class="token punctuation">:</span> https
        tls_config<span class="token punctuation">:</span>
          insecure_skip_verify<span class="token punctuation">:</span> <span class="token boolean important">true</span>
        authorization<span class="token punctuation">:</span>
          credentials_file<span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">,</span> __meta_kubernetes_service_name<span class="token punctuation">,</span> __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
          action<span class="token punctuation">:</span> keep
          regex<span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system;kube<span class="token punctuation">-</span>scheduler;https

      <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'etcd'</span>
        kubernetes_sd_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> endpoints
        scheme<span class="token punctuation">:</span> http
        relabel_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">,</span> __meta_kubernetes_service_name<span class="token punctuation">,</span> __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
          action<span class="token punctuation">:</span> keep
          regex<span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system;etcd;http

      <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'kube-state-metrics'</span>
        kubernetes_sd_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> endpoints
        scheme<span class="token punctuation">:</span> http
        relabel_configs<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">,</span> __meta_kubernetes_service_name<span class="token punctuation">,</span> __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
          action<span class="token punctuation">:</span> keep
          regex<span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics;http<span class="token punctuation">-</span>metrics

    remote_write<span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">url</span><span class="token punctuation">:</span> <span class="token string">'http://10.206.0.16:19000/prometheus/v1/write'</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br></div></div><p>说明一下, 这段代码中包含了 5 个抓取 job, 分别是 <strong>APIServer, Controller-manager, Scheduler, ectd, KSM</strong>. 前面 3 个走的是 HTTPS , 后面两个走的是 HTTP, 重点关注 relabel 规则. keep 的规则实际就是在做过滤, 只过滤自己 job 感兴趣的那些 endpoint. 最后两行配置了 remote write 地址, 采集到的数据通过 remote write 协议推给远端, 这里是推给了 n9e-server, n9e-server 后面是 VictoriaMetrics 集群.</p> <p>准备好配置文件之后, 接下来部署 Prometheus. 因为只是抓取几个服务端组件, 抓取量不大, 不用做分片, 这里把 Prometheus agent mode 做成单副本的 Deployment, 可以看一下 YAML 文件.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  name<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent
  namespace<span class="token punctuation">:</span> flashcat
  labels<span class="token punctuation">:</span>
    app<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  replicas<span class="token punctuation">:</span> <span class="token number">1</span>
  selector<span class="token punctuation">:</span>
    matchLabels<span class="token punctuation">:</span>
      app<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent
  template<span class="token punctuation">:</span>
    metadata<span class="token punctuation">:</span>
      labels<span class="token punctuation">:</span>
        app<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent
    spec<span class="token punctuation">:</span>
      serviceAccountName<span class="token punctuation">:</span> categraf
      containers<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus
          image<span class="token punctuation">:</span> prom/prometheus
          args<span class="token punctuation">:</span>
            <span class="token punctuation">-</span> <span class="token string">&quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span>
            <span class="token punctuation">-</span> <span class="token string">&quot;--web.enable-lifecycle&quot;</span>
            <span class="token punctuation">-</span> <span class="token string">&quot;--enable-feature=agent&quot;</span>
          ports<span class="token punctuation">:</span>
            <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">9090</span>
          resources<span class="token punctuation">:</span>
            requests<span class="token punctuation">:</span>
              cpu<span class="token punctuation">:</span> 500m
              memory<span class="token punctuation">:</span> 500M
            limits<span class="token punctuation">:</span>
              cpu<span class="token punctuation">:</span> <span class="token number">1</span>
              memory<span class="token punctuation">:</span> 1Gi
          volumeMounts<span class="token punctuation">:</span>
            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>config<span class="token punctuation">-</span>volume
              mountPath<span class="token punctuation">:</span> /etc/prometheus/
            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>storage<span class="token punctuation">-</span>volume
              mountPath<span class="token punctuation">:</span> /prometheus/
      volumes<span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>config<span class="token punctuation">-</span>volume
          configMap<span class="token punctuation">:</span>
            defaultMode<span class="token punctuation">:</span> <span class="token number">420</span>
            name<span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>agent<span class="token punctuation">-</span>conf
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>storage<span class="token punctuation">-</span>volume
          emptyDir<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br></div></div><p>这里要注意的关键点, 一个是 serviceAccountName, 配置是 categraf, 和前面创建的 ServiceAccount 对应, 另一个是 args 部分, 给出了相关的启动参数, <code>--enable-feature=agent</code>​ 就是作为 agent mode 模式运行.</p> <p>最后执行 <code>kubectl apply -f prometheus-agent-deployment.yaml</code>​, 让 Kubernetes 把 Deployment 拉起来就可以了. 稍等片刻, 去页面上查询一下 APIServer 的监控数据, 理论上是可以查到的, 但是其他组件的监控数据, 大概率是没有的, 下面来一一修复.</p> <h5 id="_3-修复controller-manager和scheduler"><a href="#_3-修复controller-manager和scheduler" class="header-anchor">#</a> 3.修复Controller-manager和Scheduler</h5> <p>上面的抓取规则走的都是 Kubernetes 服务发现机制, 发现 endpoint, 然后过滤. 先通过下面的命令查看一下 kube-system 这个 namespace 下有哪些 endpoint.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>kubectl get endpoints <span class="token punctuation">-</span>n kube<span class="token punctuation">-</span>system
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果有 kube-controller-manager, kube-scheduler 这两个 endpoint, 理论上通过上面的抓取规则就可以抓到数据, 如果没有的话, 可以创建相关的 service.</p> <p>可以参考我给出的这两个 YAML 文件来创建 service.</p> <ul><li><a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/controller-service.yaml" target="_blank" rel="noopener noreferrer">https://github.com/flashcatcloud/categraf/blob/main/k8s/controller-service.yaml<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/scheduler-service.yaml" target="_blank" rel="noopener noreferrer">https://github.com/flashcatcloud/categraf/blob/main/k8s/scheduler-service.yaml<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>另外就是得确保 Controller-manager 和 Scheduler 没有监听在 127.0.0.1, 否则采集器落在其他机器上就访问不通了. 具体怎么做呢?</p> <p>在这两个组件的启动参数里加上 <code>--bind-address=0.0.0.0</code>​ 就可以了. 如果是 Kubeadm 安装的, 可以在 /etc/kubernetes/manifests/kube-controller-manager.yaml 和 /etc/kubernetes/manifests/kube-scheduler.yaml 里调整参数. 调整完之后, 理论上就可以抓到数据了.</p> <h5 id="_4-修复etcd"><a href="#_4-修复etcd" class="header-anchor">#</a> 4.修复etcd</h5> <p>etcd 默认端口是 2379, 如果从这个端口获取监控数据, 就需要有比较复杂的认证鉴权. 但其实 etcd 的监控数据也不是什么太关键的信息, 而且是内网, 直接开放就可以了. etcd 提供了一个启动参数, 可以为暴露监控指标单独监听一个地址.</p> <p>具体参数是:</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">-</span><span class="token punctuation">-</span>listen<span class="token punctuation">-</span>metrics<span class="token punctuation">-</span>urls=http<span class="token punctuation">:</span>//0.0.0.0<span class="token punctuation">:</span><span class="token number">2381</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>之后创建相关的 <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/etcd-service-http.yaml" target="_blank" rel="noopener noreferrer">service<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, prometheus agent 就可以发现这个 HTTP 的 endpoint 了.</p> <h5 id="_5-修复ksm"><a href="#_5-修复ksm" class="header-anchor">#</a> 5.修复KSM</h5> <p>KSM 是监控各类 Kubernetes 对象的组件, 通过 KSM 可以知道 Service, Deployment, Statefulset, Node 等组件的各类元信息, 比如某个 Deployment 期望有几个副本, 实际有几个 Pod 在运行这种问题, 就是靠 KSM 来回答的. KSM 是如何知道这些信息的呢? 它需要跟 APIServer 通信, 订阅各类资源对象的变更. 下面安装一下 KSM, 相关指标就有了.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>git clone https<span class="token punctuation">:</span>//github.com/kubernetes/kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics
kubectl apply <span class="token punctuation">-</span>f kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics/examples/standard/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>KSM 在代码仓库里提供了相关的 YAML 文件, 可以 clone 下来直接 apply 就可以. KSM 默认暴露了两个端口, 8080 用于返回各类 Kubernetes 对象信息, 8081 用于返回 KSM 自身的指标, 在抓取规则里重点抓取的是 8080 的数据.</p> <p>KSM 要返回所有 Kubernetes 对象的指标, 数据量比较大, 从 8080 拉取监控数据可能会拉取十几秒甚至几十秒, KSM 为此支持了分片逻辑, examples/standard 下面提供的 YAML 文件是把 KSM 部署为单副本的 Deployment, 分片的话使用 Daemonset, 每个 Node 上都跑一个 KSM, 这个 KSM 只同步与自身节点相关的数据, KSM 的官方 README 里说得很清楚了, 可以看一下Daemonset 样例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> DaemonSet
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">template</span><span class="token punctuation">:</span>
    <span class="token key atrule">spec</span><span class="token punctuation">:</span>
      <span class="token key atrule">containers</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> registry.k8s.io/kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics/kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics<span class="token punctuation">:</span>IMAGE_TAG
        <span class="token key atrule">name</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics
        <span class="token key atrule">args</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>resource=pods
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>node=$(NODE_NAME)
        <span class="token key atrule">env</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> NODE_NAME
          <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>
            <span class="token key atrule">fieldRef</span><span class="token punctuation">:</span>
              <span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
              <span class="token key atrule">fieldPath</span><span class="token punctuation">:</span> spec.nodeName
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>另外, KSM 提供了两种方式来过滤要 watch 的对象类型, 一个是通过白名单的方式指定具体要 watch 哪类对象, 通过命令行启动参数中的 <code>--resources=daemonsets,deployments</code>​, 表示只 watch daemonsets 和 deployments. 虽然已经限制了对象资源类型, 但如果采集的某些指标仍然不想要, 可以采用黑名单的方式来过滤指标:  <code>--metric-denylist=kube_deployment_spec_.*</code>​. 这个过滤规则支持正则写法, 多个正则之间可以使用逗号分隔.</p> <p>做完这些操作之后, 就可以采集到这些组件的监控数据了, 下面继续看哪些指标更为关键.</p> <h4 id="关键指标"><a href="#关键指标" class="header-anchor">#</a> 关键指标</h4> <p>Categraf 的代码仓库里已经内置了 Kubernetes 各个组件的监控大盘, 只要是出现在监控大盘上的指标, 理论上就是相对比较重要的, 要不然也没有必要放到大盘上了. 可以看一下 <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/apiserver-dash.json" target="_blank" rel="noopener noreferrer">APIServer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/cm-dash.json" target="_blank" rel="noopener noreferrer">Controller-manager<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/scheduler-dash.json" target="_blank" rel="noopener noreferrer">Scheduler<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://github.com/flashcatcloud/categraf/blob/main/k8s/etcd-dash.json" target="_blank" rel="noopener noreferrer">etcd<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://github.com/flashcatcloud/categraf/tree/main/inputs/kube_state_metrics" target="_blank" rel="noopener noreferrer">KSM<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 的大盘.</p> <p>如果使用 Grafana 来做可视化, 可以参考下面两个项目中提供的 Dashboard.</p> <ul><li><a href="https://github.com/kubernetes-monitoring/kubernetes-mixin" target="_blank" rel="noopener noreferrer">https://github.com/kubernetes-monitoring/kubernetes-mixin<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://github.com/dotdc/grafana-dashboards-kubernetes" target="_blank" rel="noopener noreferrer">https://github.com/dotdc/grafana-dashboards-kubernetes<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>因为所有组件都是 Go 实现的, 都暴露了 Go 程序通用的那些 CPU, 内存, Goroutine, 句柄等指标, 这一部分内容在上一讲已经介绍过, 这里不再赘述. 下面分别看一下这几个组件一些其他类型的关键指标.</p> <h5 id="_1-apiserver"><a href="#_1-apiserver" class="header-anchor">#</a> 1.APIServer</h5> <p>**APIServer 的核心职能是 Kubernetes 集群的 API 总入口, Kube-Proxy, Kubelet, Controller-Manager, Scheduler 等都需要调用 APIServer, 所以 APIServer 的监控, 完全按照 RED 方法论来梳理即可, 最核心的就是请求吞吐和延迟. **</p> <ul><li><strong>apiserver_request_total</strong>: 请求量的指标, 可以统计每秒请求数, 成功率.</li> <li><strong>apiserver_request_duration_seconds</strong>: 请求耗时的指标.</li> <li><strong>apiserver_current_inflight_requests</strong>: APIServer 当前处理的请求数, 分为 mutating(非 get, list, watch的请求)和 readOnly(get, list, watch请求)两种, 请求量过大就会被限流, 所以这个指标对观察容量水位很有帮助.</li></ul> <h5 id="_2-controller-manager"><a href="#_2-controller-manager" class="header-anchor">#</a> 2.Controller-manager</h5> <p>Controller-manager 负责监听对象状态, 并与期望状态做对比. 如果状态不一致则进行调谐, 重点关注的是<strong>任务数量, 队列深度</strong> 等.</p> <ul><li><strong>workqueue_adds_total</strong>: 各个 controller 接收到的任务总数.</li> <li><strong>workqueue_depth</strong>: 各个 controller 的队列深度, 表示各个 controller 中的任务的数量, 数量越大表示越繁忙.</li> <li><strong>workqueue_queue_duration_seconds</strong>: 任务在队列中的等待耗时, 按照控制器分别统计.</li> <li><strong>workqueue_work_duration_seconds</strong>: 任务出队到被处理完成的时间, 按照控制器分别统计.</li> <li><strong>workqueue_retries_total</strong>: 任务进入队列的重试次数.</li></ul> <h5 id="_3-scheduler"><a href="#_3-scheduler" class="header-anchor">#</a> 3.Scheduler</h5> <p>Scheduler 在 Kubernetes 架构中负责把对象调度到合适的 Node 上, 在这个过程中会有一系列的规则计算和筛选, 重点关注 <strong>调度</strong> 这个动作的相关指标.</p> <ul><li><strong>leader_election_master_status</strong>: 调度器的选主状态, 1 表示 master, 0 表示 backup.</li> <li><strong>scheduler_queue_incoming_pods_total</strong>: 进入调度队列的 Pod 数量.</li> <li><strong>scheduler_pending_pods</strong>: Pending 的 Pod 数量.</li> <li><strong>scheduler_pod_scheduling_attempts</strong>: Pod 调度成功前, 调度重试的次数分布.</li> <li><strong>scheduler_framework_extension_point_duration_seconds</strong>: 调度框架的扩展点延迟分布, 按 extension_point 统计.</li> <li><strong>scheduler_schedule_attempts_total</strong>: 按照调度结果统计的尝试次数, &quot;unschedulable&quot; 表示无法调度, &quot;error&quot; 表示调度器内部错误.</li></ul> <h5 id="_4-etcd"><a href="#_4-etcd" class="header-anchor">#</a> 4.etcd</h5> <p>etcd在 Kubernetes 的架构中作用巨大, 相对也比较稳定, 不过 etcd 对硬盘 IO 要求较高, 因此需要着重关注 IO 相关的指标, 生产环境建议至少使用 SSD 的盘做存储.</p> <ul><li><strong>etcd_server_has_leader</strong>: etcd 是否有 leader.</li> <li><strong>etcd_server_leader_changes_seen_total</strong>: 偶尔切主问题不大, 频繁切主就要关注了.</li> <li><strong>etcd_server_proposals_failed_total</strong>: 提案失败次数.</li> <li><strong>etcd_disk_backend_commit_duration_seconds</strong>: 提交花费的耗时.</li> <li><strong>etcd_disk_wal_fsync_duration_seconds</strong>: wal 日志同步耗时.</li></ul> <h5 id="_5-ksm"><a href="#_5-ksm" class="header-anchor">#</a> 5.KSM</h5> <p>Kube-state-metrics 这个组件, 采集的很多指标都只是充当元信息, 单独拿出来未必那么有用, 但是和其他指标做 group_left, group_right 连接的时候可能又会很有用. 下面挑选一些相对常用的指标解释一下.</p> <ul><li><strong>kube_node_status_condition</strong>: Node 节点状态, 状态不正常, 有磁盘压力等都可以通过这个指标发现.</li> <li><strong>kube_pod_container_status_last_terminated_reason</strong>: 容器停止原因.</li> <li><strong>kube_pod_container_status_waiting_reason</strong>: 容器处于 waiting 状态的原因.</li> <li><strong>kube_pod_container_status_restarts_total</strong>: 容器重启次数.</li> <li><strong>kube_deployment_spec_replicas</strong>: deployment配置期望的副本数.</li> <li><strong>kube_deployment_status_replicas_available</strong>: deployment 实际可用的副本数.</li></ul> <p>基于 KSM 数据的比较典型的告警规则, 也举个例子.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># 长时间版本不一致需要告警</span>
kube_deployment_status_observed_generation<span class="token punctuation">{</span>job=&quot;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics&quot;<span class="token punctuation">}</span>
<span class="token tag">!=</span>
kube_deployment_metadata_generation<span class="token punctuation">{</span>job=&quot;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics&quot;<span class="token punctuation">}</span>

<span class="token comment"># deployment 副本数不一致</span>
(
kube_deployment_spec_replicas<span class="token punctuation">{</span>job=&quot;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics&quot;<span class="token punctuation">}</span>
<span class="token tag">!=</span>
kube_deployment_status_replicas_available<span class="token punctuation">{</span>job=&quot;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics&quot;<span class="token punctuation">}</span>
)
and
(
changes(kube_deployment_status_replicas_updated<span class="token punctuation">{</span>job=&quot;kube<span class="token punctuation">-</span>state<span class="token punctuation">-</span>metrics&quot;<span class="token punctuation">}</span><span class="token punctuation">[</span>5m<span class="token punctuation">]</span>) == 0
)

<span class="token comment"># 容器有 Error 或者 OOM 导致的退出</span>
(sum(kube_pod_container_status_last_terminated_reason<span class="token punctuation">{</span>reason=~&quot;Error<span class="token punctuation">|</span>OOMKilled&quot;<span class="token punctuation">}</span>) by (namespace<span class="token punctuation">,</span>pod<span class="token punctuation">,</span>container) <span class="token punctuation">&gt;</span> 0)
* on(namespace<span class="token punctuation">,</span>pod<span class="token punctuation">,</span>container)
sum(increase(kube_pod_container_status_restarts_total<span class="token punctuation">[</span>10m<span class="token punctuation">]</span>) <span class="token punctuation">&gt;</span> 0) by(namespace<span class="token punctuation">,</span>pod<span class="token punctuation">,</span>container)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>上面只是举了 Deployment 的例子, Statefulset 也是类似的.</p> <h4 id="小结-17"><a href="#小结-17" class="header-anchor">#</a> 小结</h4> <p>Kubernetes 体系确实非常庞大, 这一讲重点介绍控制面的组件监控, 包括 APIServer, Controller-manager, Scheduler, etcd等. 当然, Kubernetes 对象的监控也很关键, 可以使用 KSM 完成.</p> <p><strong>核心内容主要是两部分, 一个是数据采集, 一个是关键指标</strong>. 数据采集引入了 prometheus agent mode, 支持 Kubernetes 服务发现, 非常轻量, 通过 remote write 协议把数据推给后端存储. 关键指标的话需要看各个模块的核心职能以及重点依赖, 比如 Scheduler 是做调度的, 那就要看调度相关的指标, etcd 强依赖硬盘, 就要多关注硬盘 IO 相关的指标.</p> <p>Kubernetes 控制面的组件全部都要<strong>认证鉴权</strong>, 相比之前演示的 Kubelet 数据采集, 需要给更多的权限. Controller-manager, Scheduler 可能默认没有创建 Service, 需要手工创建并且修改监听地址, etcd 要开启 HTTP 协议的指标暴露端口, 这些都是坑, 需要依次修复.</p> <p>本节思维导图如下:</p> <p><img src="/img/c183a43526b4bea24c42d6fec3774ccd-20230719203435-mb8h5ht.jpg" alt=""></p> <h3 id="_19-应用监控-如何使用埋点方式对应用监控"><a href="#_19-应用监控-如何使用埋点方式对应用监控" class="header-anchor">#</a> 19.应用监控-如何使用埋点方式对应用监控?</h3> <p>前面几讲主要是介绍了常见的中间件, 数据库的监控, 统称为组件监控, 根据前面对监控做的分类, 还有<strong>应用和业务层面</strong>的监控没有介绍, 接下来会用两讲来介绍这部分内容.</p> <blockquote><p>💡因为业务指标的生成也需要应用程序侧来实现, 所以这两个层面的监控可以统称为应用监控.</p></blockquote> <p>在指标监控的世界里, <mark><strong>应用和业务层面的监控有两种典型手段, 一种是在应用程序里埋点, 另一种是分析日志, 从日志中提取指标</strong></mark>. 埋点的方式性能更好, 也更灵活, 只是对应用程序有一定侵入性, 而分析日志的话对应用程序侵入性较小, 但由于链路较长, 需要做文本分析处理, 性能较差, 需要更多算力支持. 这一讲先来介绍第一种方式, 使用埋点的方式做应用和业务监控.</p> <h4 id="埋点方式介绍"><a href="#埋点方式介绍" class="header-anchor">#</a> 埋点方式介绍</h4> <p>所谓的埋点, 就是指应用程序<strong>内嵌了埋点的 SDK</strong>(一个 lib 库), 然后在一些关键代码流程里调用 SDK 提供的方法, 记录下各种关键指标. 比如某个 HTTP 服务, 提供了 10 个接口, 每个接口的处理花费了多少毫秒, 就可以作为指标记录下来.</p> <p>你可能会疑惑, 如果监控系统已经提供了 PUSH 接口了, 比如 Prometheus 的 Pushgateway 组件, 在应用程序里直接调用 Pushgateway 接口推数据不就行了吗? 为什么还需要 SDK 呢?</p> <p><strong>核心原因是 SDK 可以封装一些通用的计算逻辑</strong>. 比如有个指标是 Summary 类型, 可以提供某个接口 99 分位的延迟数据. 如果没有 SDK, 需要怎么做呢? 每当这个接口响应一次请求, 就记录一个延迟时间, 然后存入一个内存数据结构, 等到一个时间间隔, 比如 10 秒钟, 就把这段时间内所有的延迟数据排个序, 然后取 99 分位的值, 最后调用 Pushgateway 的接口推过去. 很麻烦是不是?</p> <p>这里需要准备这个数据结构, 这个数据结构还需要线程安全. 如果请求非常频繁, 耗时数据很多, 还得进行限制, 比如这个数据结构只保存 1000 个耗时数据. 然后到了时间间隔之后需要排序, 还要组织成监控系统需要的数据格式, 还需要调用 HTTP 接口推送数据.</p> <p><strong>而 SDK 就是做这些通用逻辑的</strong>, 应用程序要做的, 就是拿到延迟数据之后, 调用 SDK 的方法告知 SDK, 说又有一次新的接口调用, 延迟数据是多少, 哥们后续就交给你了, SDK 就能完成剩余所有的事情.</p> <p>业界比较知名的<strong>跨语言埋点工具</strong>是 <a href="https://github.com/statsd/statsd" target="_blank" rel="noopener noreferrer">StatsD<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://prometheus.io/docs/instrumenting/clientlibs/" target="_blank" rel="noopener noreferrer">Prometheus<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 当然有些语言有自己生态的常用工具, 比如 Java 生态的 Micrometer, 不过一般公司都会使用多种语言, 这些跨语言的埋点方案通常使用频率会更高. 所以这里分别介绍这两个方式.</p> <h4 id="statsd"><a href="#statsd" class="header-anchor">#</a> StatsD</h4> <p>StatsD 有个很大的特点是使用 <strong>UDP 传输协议</strong>, 大部分计算逻辑都挪到了 StatsD 的 Server, SDK 层面的工作非常轻量.</p> <p><img src="/img/94e9f7d2251d6241bb0f83308810230d-20230719203435-bfmdxcf.png" alt=""></p> <p>StatsD SDK 与 StatsD Server 之间通信使用的是 UDP 协议, UDP 协议无需建立连接, 即使 StatsD Server 挂了, 也不影响应用程序, 而对于延迟分布区间这样的计算逻辑, 是在 StatsD Server 里计算的, 也不会影响应用程序, 所以整个 StatsD 的设计是非常轻量的, 对应用程序基本没有影响.</p> <p>由于 StatsD 相当知名, 所以很多采集器都实现了 StatsD 的协议, 比如 Telegraf, Datadog-agent, 也就是说, 图上的 StatsD Server 是可以换成 Telegraf 或 Datadog-agent 的. 这样就不用部署太多进程, 一个采集器包打天下, 就拿 Telegraf 来说吧, 替换后架构就变成了这样.</p> <p><img src="/img/e45a7a5926bb491c5560bc16a5189cfb-20230719203435-17j46y9.png" alt=""></p> <p>下面来演示一下, 用一个小程序做个埋点. 就把 Telegraf 当做 StatsD Server 来接收埋点数据, Telegraf 是 InfluxData 主导开源的监控采集器.</p> <p>Telegraf 提供 StatsD 的 input 插件, 在配置文件中搜索 inputs.statsd 就能找到相关的配置段了, 里边有详尽的注释, 直接上配置样例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>inputs.statsd<span class="token punctuation">]</span><span class="token punctuation">]</span>
protocol = &quot;udp&quot;
service_address = &quot;<span class="token punctuation">:</span>8125&quot;
percentiles = <span class="token punctuation">[</span><span class="token number">50.0</span><span class="token punctuation">,</span> <span class="token number">90.0</span><span class="token punctuation">,</span> <span class="token number">99.0</span><span class="token punctuation">,</span> <span class="token number">99.9</span><span class="token punctuation">,</span> <span class="token number">99.95</span><span class="token punctuation">,</span> <span class="token number">100.0</span><span class="token punctuation">]</span>
metric_separator = &quot;_&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>Telegraf 重启之后就会在 8125 开启 UDP 监听, 应用程序就可以往这个地址推送监控数据了. 这里提供一个 Go 埋点的例子.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token keyword">package</span> main
<span class="token keyword">import</span> <span class="token punctuation">(</span>
    <span class="token string">&quot;fmt&quot;</span>
    <span class="token string">&quot;math/rand&quot;</span>
    <span class="token string">&quot;net/http&quot;</span>
    <span class="token string">&quot;time&quot;</span>
    <span class="token string">&quot;github.com/smira/go-statsd&quot;</span>
<span class="token punctuation">)</span>
<span class="token keyword">var</span> client <span class="token operator">*</span>statsd<span class="token punctuation">.</span>Client
<span class="token keyword">func</span> <span class="token function">homeHandler</span><span class="token punctuation">(</span>w http<span class="token punctuation">.</span>ResponseWriter<span class="token punctuation">,</span> r <span class="token operator">*</span>http<span class="token punctuation">.</span>Request<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    start <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// random sleep</span>
    num <span class="token operator">:=</span> rand<span class="token punctuation">.</span><span class="token function">Int31n</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
    time<span class="token punctuation">.</span><span class="token function">Sleep</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Duration</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Millisecond<span class="token punctuation">)</span>
    fmt<span class="token punctuation">.</span><span class="token function">Fprintf</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> <span class="token string">&quot;duration: %d&quot;</span><span class="token punctuation">,</span> num<span class="token punctuation">)</span>
    client<span class="token punctuation">.</span><span class="token function">Incr</span><span class="token punctuation">(</span><span class="token string">&quot;requests.counter,page=home&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    client<span class="token punctuation">.</span><span class="token function">PrecisionTiming</span><span class="token punctuation">(</span><span class="token string">&quot;requests.latency,page=home&quot;</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span><span class="token function">Since</span><span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// init client</span>
    client <span class="token operator">=</span> statsd<span class="token punctuation">.</span><span class="token function">NewClient</span><span class="token punctuation">(</span><span class="token string">&quot;localhost:8125&quot;</span><span class="token punctuation">,</span>
        statsd<span class="token punctuation">.</span><span class="token function">TagStyle</span><span class="token punctuation">(</span>statsd<span class="token punctuation">.</span>TagFormatInfluxDB<span class="token punctuation">)</span><span class="token punctuation">,</span>
        statsd<span class="token punctuation">.</span><span class="token function">MaxPacketSize</span><span class="token punctuation">(</span><span class="token number">1400</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        statsd<span class="token punctuation">.</span><span class="token function">MetricPrefix</span><span class="token punctuation">(</span><span class="token string">&quot;http.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        statsd<span class="token punctuation">.</span><span class="token function">DefaultTags</span><span class="token punctuation">(</span>statsd<span class="token punctuation">.</span><span class="token function">StringTag</span><span class="token punctuation">(</span><span class="token string">&quot;service&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;n9e-webapi&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> statsd<span class="token punctuation">.</span><span class="token function">StringTag</span><span class="token punctuation">(</span><span class="token string">&quot;region&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;bj&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">defer</span> client<span class="token punctuation">.</span><span class="token function">Close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    http<span class="token punctuation">.</span><span class="token function">HandleFunc</span><span class="token punctuation">(</span><span class="token string">&quot;/&quot;</span><span class="token punctuation">,</span> homeHandler<span class="token punctuation">)</span>
    http<span class="token punctuation">.</span><span class="token function">ListenAndServe</span><span class="token punctuation">(</span><span class="token string">&quot;:8000&quot;</span><span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>这个 Web 服务只有一个根路径, 逻辑也很简单, 就是随机 sleep 几十个毫秒当做业务处理时间. 整体逻辑是这样的: 首先, 要通过 statsd.NewClient 初始化一个 StatsD 的客户端, 参数中指定了 StatsD 的 Server 地址(在这个例子里就是 Telegraf 的 8125), 指定了所有监控指标的前缀是 <code>http.</code>​, 还指定了两个全局 Tag, 一个是 <code>service=n9e-webapi</code>​, 另一个是 <code>region=bj</code>​. 通过 TagStyle 指定要发送的是 InfluxDB 样式的标签.</p> <p>然后, 在请求的具体处理逻辑里上报了两个监控指标, 一个是 <code>requests.counter</code>​, 另一个是 <code>requests.latency</code>​, 并为它们指定了一个指标级别的标签 <code>page=home</code>​, 整体看起来还是比较简单的.</p> <p>Telegraf 支持多种 output 插件, 可以使用比较快捷的 outputs.file 插件, 把生成的指标写到 stdout, 来验证效果.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token punctuation">[</span><span class="token punctuation">[</span>outputs<span class="token punctuation">.</span>file<span class="token punctuation">]</span><span class="token punctuation">]</span>
files <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;stdout&quot;</span><span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>请求数量和请求延时都是典型的应用层面的监控指标</strong>, 如果想要做业务指标监控, 比如订单量监控, 应该怎么做呢? 其实逻辑是完全一样的, 仿照 <code>requests.counter</code>​ 的写法, 做一个订单量的指标, 每次创建一个新订单的时候, 就给订单量指标 <code>+1</code>​. 一般一个服务会部署多个实例, 每个实例都统计了自己的订单量, 要计算最近一分钟的订单数量的话, 只需要在服务端使用 PromQL 做二次汇总计算.</p> <h4 id="prometheus"><a href="#prometheus" class="header-anchor">#</a> Prometheus</h4> <p>Prometheus 的埋点方式跟 StatsD 很像, <strong>对于请求数量和延迟这样的监控指标, 也是在请求处理完成之后, 调用 SDK 的方法进行记录的</strong>. 不过, 如果每个方法都要加这么几行代码就显得太冗余了, 最好还是通过 AOP 的方式做一些切面逻辑, Nightingale 的 Webapi 模块就是这么干的, 直接用这个 <a href="https://github.com/ccfos/nightingale" target="_blank" rel="noopener noreferrer">代码<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 进行讲解.</p> <p>Webapi 的职能是提供一系列 HTTP 接口给 JavaScript 调用, 需要监控这些接口的调用量, 成功率, 延迟数据. 埋点之前先规划一下标签, 给每个 HTTP 接口规划 4 个标签.</p> <ul><li>service: 服务名称, 要求全局唯一, 可以和其他服务区分开.</li> <li>code: HTTP 返回状态码, 可以根据这个信息得知 4xx 的比例是多少, 5xx 的比例是多少, 计算成功率.</li> <li>path: 接口路径, 比如 <code>/api/v1/users</code>​, 有时候会在接口路径中放置 URL 参数, 比如 <code>/api/v1/user/23</code>​,  <code>/api/v1/user/12</code>​ 是请求 id 为 23 和 12 的用户信息. 这个时候不能直接把这个 URL 作为接口路径的标签值, 否则这个指标颗粒度就太细了, 应该把接口路径的标签值设置成 <code>/api/v1/user/:id</code>​.</li> <li>method: HTTP 方法, GET, POST, DELETE, PUT 等.</li></ul> <p><strong>Prometheus 埋点需要提前把指标变量定义出来</strong>, 使用一个单独的包来放置, 可以看一下 <a href="https://github.com/ccfos/nightingale/blob/main/src/webapi/stat/stat.go" target="_blank" rel="noopener noreferrer">相关代码<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token keyword">package</span> stat

<span class="token keyword">import</span> <span class="token punctuation">(</span>
    <span class="token string">&quot;time&quot;</span>
    <span class="token string">&quot;github.com/prometheus/client_golang/prometheus&quot;</span>
<span class="token punctuation">)</span>

<span class="token keyword">const</span> Service <span class="token operator">=</span> <span class="token string">&quot;n9e-webapi&quot;</span>

<span class="token keyword">var</span> <span class="token punctuation">(</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">{</span><span class="token string">&quot;service&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;code&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;path&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;method&quot;</span><span class="token punctuation">}</span>

    uptime <span class="token operator">=</span> prometheus<span class="token punctuation">.</span><span class="token function">NewCounterVec</span><span class="token punctuation">(</span>
    prometheus<span class="token punctuation">.</span>CounterOpts<span class="token punctuation">{</span>
        		Name<span class="token punctuation">:</span> <span class="token string">&quot;uptime&quot;</span><span class="token punctuation">,</span>
			Help<span class="token punctuation">:</span> <span class="token string">&quot;HTTP service uptime.&quot;</span><span class="token punctuation">,</span>
		<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">{</span><span class="token string">&quot;service&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    RequestCounter <span class="token operator">=</span> prometheus<span class="token punctuation">.</span><span class="token function">NewCounterVec</span><span class="token punctuation">(</span>
    	prometheus<span class="token punctuation">.</span>CounterOpts<span class="token punctuation">{</span>
		Name<span class="token punctuation">:</span> <span class="token string">&quot;http_request_count_total&quot;</span><span class="token punctuation">,</span>
		Help<span class="token punctuation">:</span> <span class="token string">&quot;Total number of HTTP requests made.&quot;</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    RequestDuration <span class="token operator">=</span> prometheus<span class="token punctuation">.</span><span class="token function">NewHistogramVec</span><span class="token punctuation">(</span>
	prometheus<span class="token punctuation">.</span>HistogramOpts<span class="token punctuation">{</span>
        		Buckets<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">float64</span><span class="token punctuation">{</span><span class="token number">.01</span><span class="token punctuation">,</span> <span class="token number">.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
			Name<span class="token punctuation">:</span>    <span class="token string">&quot;http_request_duration_seconds&quot;</span><span class="token punctuation">,</span>
			Help<span class="token punctuation">:</span>    <span class="token string">&quot;HTTP request latencies in seconds.&quot;</span><span class="token punctuation">,</span>
		<span class="token punctuation">}</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span>
	<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

<span class="token keyword">func</span> <span class="token function">Init</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// Register the summary and the histogram with Prometheus's default registry.</span>
    prometheus<span class="token punctuation">.</span><span class="token function">MustRegister</span><span class="token punctuation">(</span>
    	uptime<span class="token punctuation">,</span>
	RequestCounter<span class="token punctuation">,</span>
	RequestDuration<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">go</span> <span class="token function">recordUptime</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>

<span class="token comment">// recordUptime increases service uptime per second.</span>
<span class="token keyword">func</span> <span class="token function">recordUptime</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">for</span> <span class="token keyword">range</span> time<span class="token punctuation">.</span><span class="token function">Tick</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">)</span> <span class="token punctuation">{</span>
	uptime<span class="token punctuation">.</span><span class="token function">WithLabelValues</span><span class="token punctuation">(</span>Service<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Inc</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br></div></div><p>uptime 变量是顺手为之, 统计进程启动了多长时间, 不用太关注, RequestCounter 和 RequestDuration, 分别统计请求流量和请求延迟. Init 方法是在 Webapi 模块进程初始化的时候调用, 所以进程一起, 就会自动注册好.</p> <p>然后写一个 middleware, <strong>在请求进来的时候拦截一下, 省得每个请求都要去统计</strong>, 可以看一下 middleware 方法的 <a href="https://github.com/ccfos/nightingale/blob/main/src/webapi/router/router.go#L20" target="_blank" rel="noopener noreferrer">代码<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token keyword">func</span> <span class="token function">stat</span><span class="token punctuation">(</span><span class="token punctuation">)</span> gin<span class="token punctuation">.</span>HandlerFunc <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token keyword">func</span><span class="token punctuation">(</span>c <span class="token operator">*</span>gin<span class="token punctuation">.</span>Context<span class="token punctuation">)</span> <span class="token punctuation">{</span>
	start <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	c<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

	code <span class="token operator">:=</span> fmt<span class="token punctuation">.</span><span class="token function">Sprintf</span><span class="token punctuation">(</span><span class="token string">&quot;%d&quot;</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>Writer<span class="token punctuation">.</span><span class="token function">Status</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	method <span class="token operator">:=</span> c<span class="token punctuation">.</span>Request<span class="token punctuation">.</span>Method
	labels <span class="token operator">:=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">{</span>promstat<span class="token punctuation">.</span>Service<span class="token punctuation">,</span> code<span class="token punctuation">,</span> c<span class="token punctuation">.</span><span class="token function">FullPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> method<span class="token punctuation">}</span>

	promstat<span class="token punctuation">.</span>RequestCounter<span class="token punctuation">.</span><span class="token function">WithLabelValues</span><span class="token punctuation">(</span>labels<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Inc</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	promstat<span class="token punctuation">.</span>RequestDuration<span class="token punctuation">.</span><span class="token function">WithLabelValues</span><span class="token punctuation">(</span>labels<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Observe</span><span class="token punctuation">(</span><span class="token function">float64</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Since</span><span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Seconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>有了这个 middleware 之后, new 出 gin 的 engine 的时候, 就立马 Use 一下.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token operator">...</span>
r <span class="token operator">:=</span> gin<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
r<span class="token punctuation">.</span><span class="token function">Use</span><span class="token punctuation">(</span><span class="token function">stat</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">...</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>最后, 监控数据要通过/metrics接口暴露出去, 要暴露这个请求端点.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code><span class="token keyword">import</span> <span class="token punctuation">(</span>
    <span class="token operator">...</span>
    <span class="token string">&quot;github.com/prometheus/client_golang/prometheus/promhttp&quot;</span>
<span class="token punctuation">)</span>
<span class="token keyword">func</span> <span class="token function">configRoute</span><span class="token punctuation">(</span>r <span class="token operator">*</span>gin<span class="token punctuation">.</span>Engine<span class="token punctuation">,</span> version <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token operator">...</span>
    r<span class="token punctuation">.</span><span class="token function">GET</span><span class="token punctuation">(</span><span class="token string">&quot;/metrics&quot;</span><span class="token punctuation">,</span> gin<span class="token punctuation">.</span><span class="token function">WrapH</span><span class="token punctuation">(</span>promhttp<span class="token punctuation">.</span><span class="token function">Handler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>这样, 每个 Webapi 接口的流量和成功率都可以监控到了. 如果你也部署了 Nightingale, 请求 Webapi(默认是18000)的 /metrics 接口看看返回的内容吧.</p> <h4 id="数据传输通路"><a href="#数据传输通路" class="header-anchor">#</a> 数据传输通路</h4> <p>无论是 StatsD, 还是使用 Prometheus, 总之通过埋点采集到了监控指标. 接下来这些数据<strong>如何进入监控服务端</strong>呢? 看一下这个通路典型的构建方式.</p> <p>使用 StatsD 的埋点方式, 数据通过 UDP 推给 Telegraf, Telegraf 推给后端监控系统. 如果是通过 Prometheus 的方式来埋点, 就是暴露 <code>/metrics</code>​ 接口, <strong>等待监控系统来拉</strong>. 如果应用是部署在物理机或虚拟机上, 直接通过本地的监控 agent 来拉取即可. 如果应用是部署在 Kubernetes 的 Pod 里, 则有两种办法来拉取数据, 一个是 Sidecar 模式, 一个是中心端服务发现的模式. 下面这个示意图展示的是 Sidecar 模式.</p> <p><img src="/img/1309313e94e9a9f8a88344d74d3762d1-20230719203435-5qjvn16.png" alt=""></p> <p>左侧 Pod1 里有两个容器, App 通过 StatsD 埋点, 然后通过 UDP 推给 Telegraf, Telegraf 接收到数据之后做二次计算, 把结果推给监控服务端; 右侧 Pod2 里也有两个容器, App 通过 Prometheus SDK 埋点, 暴露 <code>/metrics</code>​ 接口, Categraf 通过这个接口拉取数据, 然后推给监控服务端.</p> <p>这种方式的优点是比较灵活, Pod 内怎么做应用自己说了算. 即使给 <code>/metrics</code>​ 接口增加一些认证鉴权, 指标过滤, 扩展标签的逻辑, 都不影响其他的 Pod. 数据是推给监控服务端的, 监控服务端接收数据的组件可以做成无状态集群, 前面架设负载均衡, 整个架构非常简单, 扩展性也很好. 当然缺点也很明显, 每个 Pod 里都伴生 Sidecar agent, 浪费资源.</p> <p>StatsD 埋点的方式只能使用 Sidecar 模式传输数据, 而 Prometheus SDK 埋点还有第二种数据抓取方式: <strong>中心端服务发现模式</strong>.</p> <p><img src="/img/a4e052ddd462710c05d2c21db88388d8-20230719203435-2emyvcq.png" alt="图片"></p> <p>每个应用容器都统一暴露 <code>/metrics</code>​ 接口, <strong>监控抓取器通过 Kubernetes 服务发现机制, 找到所有的 Pod, 分别抓取</strong>即可. 不过并不是所有的 Pod 都暴露指标数据, 即使暴露了, 接口路径也未必一定是 <code>/metrics</code>​, 这就需要有一个机制和规范, 通过这个机制告诉指标抓取器, 选择哪个类型的 Pod 抓数据, 抓数据的时候使用哪个端口, 哪个接口路径来抓.</p> <p>一般<strong>使用 Pod 注解</strong>来承接这个规范, 比如制定标准: 所有想要被抓取监控数据的 Pod 都统一暴露如下注解.</p> <div class="language-go line-numbers-mode"><pre class="language-go"><code>prometheus<span class="token punctuation">.</span>io<span class="token operator">/</span>scrape<span class="token operator">=</span><span class="token boolean">true</span>
prometheus<span class="token punctuation">.</span>io<span class="token operator">/</span>metric_path<span class="token operator">=</span><span class="token operator">&lt;</span>path<span class="token operator">&gt;</span>
prometheus<span class="token punctuation">.</span>io<span class="token operator">/</span>scrape_port<span class="token operator">=</span><span class="token operator">&lt;</span>port<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>然后就可以写抓取 Job 来抓取这类数据了, 下面给出一个样例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">&quot;kubernetes-pods&quot;</span>
  <span class="token key atrule">kubernetes_sd_configs</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> pod
  <span class="token key atrule">relabel_configs</span><span class="token punctuation">:</span>
    <span class="token comment"># &quot;prometheus.io/scrape = true&quot; annotation.</span>
    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_pod_annotation_prometheus_io_scrape<span class="token punctuation">]</span>
      <span class="token key atrule">action</span><span class="token punctuation">:</span> keep
      <span class="token key atrule">regex</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
    <span class="token comment"># &quot;prometheus.io/metric_path = &lt;metric path&gt;&quot; annotation.</span>
    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_pod_annotation_prometheus_io_metric_path<span class="token punctuation">]</span>
      <span class="token key atrule">action</span><span class="token punctuation">:</span> replace
      <span class="token key atrule">target_label</span><span class="token punctuation">:</span> __metrics_path__
      <span class="token key atrule">regex</span><span class="token punctuation">:</span> (.+)
    <span class="token comment"># &quot;prometheus.io/scrape_port = &lt;port&gt;&quot; annotation.</span>
    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__address__<span class="token punctuation">,</span> __meta_kubernetes_pod_annotation_prometheus_io_scrape_port<span class="token punctuation">]</span>
      <span class="token key atrule">action</span><span class="token punctuation">:</span> replace
      <span class="token key atrule">regex</span><span class="token punctuation">:</span> (<span class="token punctuation">[</span>^<span class="token punctuation">:</span><span class="token punctuation">]</span>+)(<span class="token punctuation">?</span><span class="token punctuation">:</span><span class="token punctuation">:</span>\d+)<span class="token punctuation">?</span>;(\d+)
      <span class="token key atrule">replacement</span><span class="token punctuation">:</span> $1<span class="token punctuation">:</span>$2
      <span class="token key atrule">target_label</span><span class="token punctuation">:</span> __address__
    <span class="token punctuation">-</span> <span class="token key atrule">action</span><span class="token punctuation">:</span> labelmap
      <span class="token key atrule">regex</span><span class="token punctuation">:</span> __meta_kubernetes_pod_label_(.+)
    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">]</span>
      <span class="token key atrule">action</span><span class="token punctuation">:</span> replace
      <span class="token key atrule">target_label</span><span class="token punctuation">:</span> namespace
    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__meta_kubernetes_pod_name<span class="token punctuation">]</span>
      <span class="token key atrule">action</span><span class="token punctuation">:</span> replace
      <span class="token key atrule">target_label</span><span class="token punctuation">:</span> pod
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>分析一下中心端服务发现机制的优缺点. 优点很明显, 不需要 sidecar 的 agent 了, 大幅节省资源, 缺点是所有的抓取规则都是统一的, 不好为每个 Pod 单独指定一些认证机制, 过滤规则等. 不是说不能干, 而是要做的话就得修改中心端这个统一的抓取规则, 非常不方便, 稍有不慎还容易改错, 影响到别的 Pod.</p> <p>当然了, 一般来说不提供这个灵活性也不是太大的问题, 大家遵照一个统一的规范也挺好的, 如果真的有某个 Pod 需要额外做一些灵活配置, 大不了就不开那些注解, 仍使用 sidecar 模式就好. 这两种方式并不一定要二选一, 同时并用也没有任何问题.</p> <h4 id="小结-18"><a href="#小结-18" class="header-anchor">#</a> 小结</h4> <p><strong>本节介绍了两种埋点监控应用的方式, 一个是 StatsD, 一个是 Prometheus, 这两种方式都是跨语言的埋点方案, 业界应用广泛</strong>. StatsD 是推模式, 采用 UDP 协议, 各类计算逻辑挪到了 StatsD Server 中, 对应用本身不会造成影响. Prometheus 是拉模式, SDK 的逻辑跑在应用进程里, 可能对应用造成一定影响, 不过已经有很多公司做了生产验证, Prometheus 的 SDK 还是很稳定的, 大可放心使用.</p> <p>**对于 Prometheus SDK 的埋点方案, 有两种数据抓取方式, 一个是 Sidecar 模式, 灵活但是占用资源多; 一个是中心端服务发现模式, 不那么灵活但是资源占用得少, 技术上没有非黑即白, 建议根据具体场景灵活选择. **</p> <p>本节思维导图如下:</p> <p><img src="/img/8f8c77346f64b8f850798a08238c0a6c-20230719203435-o1tg85o.jpg" alt=""></p> <h3 id="_20-应用监控-如何使用日志来监控应用"><a href="#_20-应用监控-如何使用日志来监控应用" class="header-anchor">#</a> 20.应用监控-如何使用日志来监控应用?</h3> <p>上一讲介绍了应用埋点监控, 对于自研的软件, 在一开始就建立可观测能力是非常好的选择, 但是很多软件可能无法修改源代码, 比如一些外采的软件, 那就只能用一些外挂式的手段, 比如在请求链路上插入一些代理逻辑, 或者读取分析应用日志.</p> <p>典型的代理方式是 Nginx, 如果是 HTTP 服务, 从 Nginx 的 Access 日志中可以获取很多信息, 比如访问的是哪个接口, 用的什么 HTTP 方法, 返回的状态码是什么, 耗时多久等等. 这些信息对应用的监控很有帮助.</p> <p>除此之外, 也可以使用 eBPF 技术为网络包增加一些过滤分析逻辑, 不过 eBPF 要求的内核版本较高. 而通过日志对应用做监控, 显然是相对直观和廉价的方式, 这一讲就来看看<strong>怎么从日志中提取指标</strong>.</p> <h4 id="提取指标的典型做法"><a href="#提取指标的典型做法" class="header-anchor">#</a> 提取指标的典型做法</h4> <p>根据提取规则运行的位置可以分为两类做法, 一个是在中心端, 一个是在日志端.</p> <ul><li><strong>中心端</strong> 就是<strong>把要处理的所有机器的日志都统一传到中心</strong>, 比如通过 Kafka 传输, 最终落到 Elasticsearch, 指标提取规则可以作为流计算任务插到 Kafka 通道上, 性能和实时性都相对更好. 或者直接写个定时任务, 调用 Elasticsearch 的接口查询日志, 同时给出聚合计算函数, 让 Elasticsearch 返回指标数据, 然后写入时序库, 实时性会差一些, 但也基本够用.</li> <li><strong>日志端</strong> 处理是指<strong>提取规则直接运行在产生日志的机器上</strong>, 流式读取日志, 匹配正则表达式. 对于命中的日志, 提取其中的数字部分作为指标上报, 或者不提取任何数字, 只统计一下命中的日志行数有时也很有价值, 比如统计一下 <code>Error</code>​ 或 <code>Exception</code>​ 关键字出现的次数, 就知道系统是不是报错了.</li></ul> <p>中心端处理的方式, 开源解决方案比较少. 日志端处理的方式, 倒是有很多开源方案, 比较有名的是 <a href="https://github.com/google/mtail" target="_blank" rel="noopener noreferrer">mtail<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://github.com/fstab/grok_exporter" target="_blank" rel="noopener noreferrer">grokexporter<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, mtail 发布时间更久, 不过它们原理上是类似的, 这里重点介绍 mtail 的用法.</p> <h4 id="快速上手mtail"><a href="#快速上手mtail" class="header-anchor">#</a> 快速上手mtail</h4> <p>类似于 Linux 下的 tail 命令, mtail, grok_exporter 等工具就像是对日志文件执行 <code>tail -f</code>​, 然后每收到一条日志, 就去匹配预定义的正则表达式, 如果匹配成功, 就执行某些动作, 否则跳过等待下一条日志.</p> <p>下面使用 mtail 统计一下 /var/log/messages 中 Out of memory 关键字出现的次数, 作为一个重要的监控指标上报.</p> <p>如果想统计 /var/log/messages 中 Out of memory 关键字出现的次数, 那就得通过某种机制告诉 mtail 正则表达式是什么, 提取规则是什么, 这个规则文件叫做 program, 一般命名为 xyz.mtail, 下面是一个样例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># 在 mtail 二进制同级目录下创建 progs 目录, 下面放置 syslogs 子目录</span>
<span class="token comment"># syslogs 子目录用于放置系统日志文件对应的提取规则</span>
mkdir <span class="token punctuation">-</span>p progs/syslogs

<span class="token comment"># 用于统计 Out of memory 关键字的 mtail 规则文件内容如下(我命名为</span>
<span class="token comment"># syslogs.mtail): </span>
counter oom_total
/Out of memory/ <span class="token punctuation">{</span>
  oom_total++
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>文件内容看起来很简单, 只有 4 行, 第一行是声明了一个变量, 类型是 counter, 变量名是 oom_total, 第二行是在 <code>//</code>​ 之间定义了一个正则表达式, 用来匹配 Out of memory, 如果匹配成功, 就执行大括号里的内容, 对 oom_total 变量加 1.</p> <p>接下来把 mtail 运行起来, 看看效果如何.</p> <p>启动命令:</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>./mtail <span class="token punctuation">-</span>progs ./progs/syslogs/ <span class="token punctuation">-</span>logs /var/log/messages
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>通过 -progs 参数指定 mtail 文件所在目录, 当然指定具体的文件也可以, 通过 -logs 参数指定要提取的日志文件是哪个, 支持 glob 匹配, 也支持传入多次 -logs 参数. mtail 启动之后会默认监听在 3903 端口, 请求 3903 的 <code>/metrics</code>​ 接口就能拿到 Prometheus 协议的监控数据.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>root@fc<span class="token punctuation">-</span>demo<span class="token punctuation">-</span>02 qinxiaohui<span class="token punctuation">]</span><span class="token comment"># ss -tlnp|grep mtail</span>
LISTEN     0      128       <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>3903                  <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>*                   users<span class="token punctuation">:</span>((&quot;mtail&quot;<span class="token punctuation">,</span>pid=18972<span class="token punctuation">,</span>fd=7))
<span class="token punctuation">[</span>root@fc<span class="token punctuation">-</span>demo<span class="token punctuation">-</span>02 qinxiaohui<span class="token punctuation">]</span><span class="token comment"># curl -s localhost:3903/metrics | grep oom_total</span>
<span class="token comment"># HELP oom_total defined at syslogs.mtail:1:9-17</span>
<span class="token comment"># TYPE oom_total counter</span>
oom_total<span class="token punctuation">{</span>prog=&quot;syslogs.mtail&quot;<span class="token punctuation">}</span> 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>上面的例子使用 grep 命令做了过滤, 只展示了 oom_total 相关的内容, 实际上 mtail 会输出很多指标. 有了这个 /metrics 接口, 怎么和监控系统对接就很明显了, 直接由抓取器来这个地址抓取数据就可以了.</p> <p>下面继续讲解 mtail 本身的用法.</p> <p>例子里 mtail 自动加了一个 prog 标签, 把 mtail 文件名作为标签加上了, 对于一些 access.log 类型的日志, 经常用于统计接口的吞吐, 延迟等, 需要把接口路径, method, statuscode 等作为标签, 应该如何配置呢? 这里以 Nginx 的 access 日志作为样例来演示, 可以看一下 Nginx 的 logformat.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>    log_format  main  '$remote_addr <span class="token punctuation">-</span> $remote_user <span class="token punctuation">[</span>$time_local<span class="token punctuation">]</span> &quot;$request&quot; '
                      '$status $body_bytes_sent &quot;$http_referer&quot; '
                      '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>对应的几条样例日志如下:</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># tail -n 5 /var/log/nginx/access.log</span>
119.45.249.92 <span class="token punctuation">-</span> <span class="token punctuation">-</span> <span class="token punctuation">[</span>17/Dec/2022<span class="token punctuation">:</span>22<span class="token punctuation">:</span>35<span class="token punctuation">:</span>39 +0800<span class="token punctuation">]</span> &quot;GET / HTTP/1.1&quot; 200 14849 &quot;<span class="token punctuation">-</span>&quot; &quot;clb<span class="token punctuation">-</span>healthcheck&quot; &quot;<span class="token punctuation">-</span>&quot;
119.45.249.92 <span class="token punctuation">-</span> <span class="token punctuation">-</span> <span class="token punctuation">[</span>17/Dec/2022<span class="token punctuation">:</span>22<span class="token punctuation">:</span>35<span class="token punctuation">:</span>40 +0800<span class="token punctuation">]</span> &quot;GET / HTTP/1.1&quot; 200 14849 &quot;<span class="token punctuation">-</span>&quot; &quot;clb<span class="token punctuation">-</span>healthcheck&quot; &quot;<span class="token punctuation">-</span>&quot;
119.45.249.92 <span class="token punctuation">-</span> <span class="token punctuation">-</span> <span class="token punctuation">[</span>17/Dec/2022<span class="token punctuation">:</span>22<span class="token punctuation">:</span>35<span class="token punctuation">:</span>40 +0800<span class="token punctuation">]</span> &quot;GET / HTTP/1.1&quot; 200 14849 &quot;<span class="token punctuation">-</span>&quot; &quot;clb<span class="token punctuation">-</span>healthcheck&quot; &quot;<span class="token punctuation">-</span>&quot;
119.45.249.92 <span class="token punctuation">-</span> <span class="token punctuation">-</span> <span class="token punctuation">[</span>17/Dec/2022<span class="token punctuation">:</span>22<span class="token punctuation">:</span>35<span class="token punctuation">:</span>41 +0800<span class="token punctuation">]</span> &quot;GET / HTTP/1.1&quot; 200 14849 &quot;<span class="token punctuation">-</span>&quot; &quot;clb<span class="token punctuation">-</span>healthcheck&quot; &quot;<span class="token punctuation">-</span>&quot;
119.45.249.92 <span class="token punctuation">-</span> <span class="token punctuation">-</span> <span class="token punctuation">[</span>17/Dec/2022<span class="token punctuation">:</span>22<span class="token punctuation">:</span>35<span class="token punctuation">:</span>41 +0800<span class="token punctuation">]</span> &quot;GET / HTTP/1.1&quot; 200 14849 &quot;<span class="token punctuation">-</span>&quot; &quot;clb<span class="token punctuation">-</span>healthcheck&quot; &quot;<span class="token punctuation">-</span>&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>这个 logformat 着实简单, 连响应延迟都没有打印, 这是 Nginx 默认的 logformat, 也先维持现状, 统计一下请求数量以及响应体的大小, 下面是具体的 mtail 文件内容.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>counter request_total by method<span class="token punctuation">,</span> url<span class="token punctuation">,</span> code
counter body_bytes_sent_total by method<span class="token punctuation">,</span> url<span class="token punctuation">,</span> code

/&quot;(<span class="token punctuation">?</span>P&lt;method<span class="token punctuation">&gt;</span>\S+) (<span class="token punctuation">?</span>P&lt;url<span class="token punctuation">&gt;</span>\S+) HTTP\/1.1&quot; (<span class="token punctuation">?</span>P&lt;code<span class="token punctuation">&gt;</span>\d+) (<span class="token punctuation">?</span>P&lt;body_bytes_sent<span class="token punctuation">&gt;</span>\d+)/ <span class="token punctuation">{</span>
	request_total<span class="token punctuation">[</span>$method<span class="token punctuation">]</span><span class="token punctuation">[</span>$url<span class="token punctuation">]</span><span class="token punctuation">[</span>$code<span class="token punctuation">]</span>++
	body_bytes_sent_total<span class="token punctuation">[</span>$method<span class="token punctuation">]</span><span class="token punctuation">[</span>$url<span class="token punctuation">]</span><span class="token punctuation">[</span>$code<span class="token punctuation">]</span> += $body_bytes_sent
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>这个正则看起来就复杂多了, 比如获取 statuscode 的地方写的正则是 <code>(?P&lt;code&gt;\d+)</code>​, 这个叫做 <strong>命名捕获</strong>, 核心的正则就是 <code>\d+</code>​, 但是后面想用这个内容, 就给它设置了一个变量叫 code, 而 method, url, body_bytes_sent 都是同样的道理.</p> <p>匹配了正则之后, 做了两个动作, request_total 变量加一, 相当于在统计请求次数, body_bytes_sent_total 变量加上日志这行提取的 $body_bytes_sent 变量的值, 是在统计响应总大小.</p> <p>这里 request_total 和 body_bytes_sent_total 这两个指标都是带有标签的, 且都是 3 个标签: method, url, code, 声明之后就可以使用, 通过命名捕获的方式给的变量名也可以在后面使用, 非常灵活. 下面是测试输出.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># 通过下面的命令加载 nginx 的 mtail, 指定 nginx 的 access.log</span>
./mtail <span class="token punctuation">-</span>progs ./progs/nginx/ <span class="token punctuation">-</span>logs /var/log/nginx/access.log

<span class="token comment"># 下面请求一下 /metrics 接口, 看看是否采集成功</span>
<span class="token punctuation">[</span>root@fc<span class="token punctuation">-</span>demo<span class="token punctuation">-</span>02 qinxiaohui<span class="token punctuation">]</span><span class="token comment"># curl -s localhost:3903/metrics | grep -P 'request_total|body_bytes_sent_total'</span>
<span class="token comment"># HELP body_bytes_sent_total defined at nginx.mtail:2:9-29</span>
<span class="token comment"># TYPE body_bytes_sent_total counter</span>
body_bytes_sent_total<span class="token punctuation">{</span>code=&quot;200&quot;<span class="token punctuation">,</span>method=&quot;GET&quot;<span class="token punctuation">,</span>prog=&quot;nginx.mtail&quot;<span class="token punctuation">,</span>url=&quot;/&quot;<span class="token punctuation">}</span> 1.143373e+06
<span class="token comment"># HELP request_total defined at nginx.mtail:1:9-21</span>
<span class="token comment"># TYPE request_total counter</span>
request_total<span class="token punctuation">{</span>code=&quot;200&quot;<span class="token punctuation">,</span>method=&quot;GET&quot;<span class="token punctuation">,</span>prog=&quot;nginx.mtail&quot;<span class="token punctuation">,</span>url=&quot;/&quot;<span class="token punctuation">}</span> 77
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>看起来一切正常, 上面这些标签都是从日志中直接提取的, 如果想附加一些静态标签应该怎么做呢? 比如把机房信息作为标签附到时序数据上, 可以看一下样例.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>hidden text zone
zone = &quot;beijing&quot;

counter request_total by method<span class="token punctuation">,</span> url<span class="token punctuation">,</span> code<span class="token punctuation">,</span> zone
counter body_bytes_sent_total by method<span class="token punctuation">,</span> url<span class="token punctuation">,</span> code<span class="token punctuation">,</span> zone

/&quot;(<span class="token punctuation">?</span>P&lt;method<span class="token punctuation">&gt;</span>\S+) (<span class="token punctuation">?</span>P&lt;url<span class="token punctuation">&gt;</span>\S+) HTTP\/1.1&quot; (<span class="token punctuation">?</span>P&lt;code<span class="token punctuation">&gt;</span>\d+) (<span class="token punctuation">?</span>P&lt;body_bytes_sent<span class="token punctuation">&gt;</span>\d+)/ <span class="token punctuation">{</span>
	request_total<span class="token punctuation">[</span>$method<span class="token punctuation">]</span><span class="token punctuation">[</span>$url<span class="token punctuation">]</span><span class="token punctuation">[</span>$code<span class="token punctuation">]</span><span class="token punctuation">[</span>zone<span class="token punctuation">]</span>++
	body_bytes_sent_total<span class="token punctuation">[</span>$method<span class="token punctuation">]</span><span class="token punctuation">[</span>$url<span class="token punctuation">]</span><span class="token punctuation">[</span>$code<span class="token punctuation">]</span><span class="token punctuation">[</span>zone<span class="token punctuation">]</span> += $body_bytes_sent
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>这里加了一个全局的 zone=&quot;beijing&quot; 的标签, 写法一目了然, 不过多解释. 唯一需要注意的是在引用 zone 变量的时候, 前面不要加 <code>$</code>​ 符号. 这里千万别写顺手了, 看到其他变量都加 <code>$</code>​ 就把 zone 也加上了, 加上就识别不了了.</p> <p>上面两个例子演示的都是 Counter 类型的变量, 其实 mtail 还支持 Gauge 和 Histogram 类型, 并且在仓库的 <a href="https://github.com/google/mtail/tree/main/examples" target="_blank" rel="noopener noreferrer">examples<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 目录下提供了很多样例, 可以直接拿来使用, 注意 Histogram 类型在定义的时候要给出 Bucket 的分布范围, 要不然 mtail 不知道如何放置统计数据.</p> <p>下面来看一个生产级的例子, 用于分析 lighttpd 的访问日志, 从中可以学到更多生产级的写法.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token comment"># Copyright 2010 Google Inc. All Rights Reserved.</span>
<span class="token comment"># This file is available under the Apache license.</span>

<span class="token comment"># mtail module for a lighttpd server</span>

counter request by status
counter time_taken by status
counter bytes_out by subtotal<span class="token punctuation">,</span> status
counter bytes_in by status
counter requests by proxy_cache

const ACCESSLOG_RE // +
    /(<span class="token punctuation">?</span>P&lt;proxied_for<span class="token punctuation">&gt;</span>\S+) (<span class="token punctuation">?</span>P&lt;request_ip<span class="token punctuation">&gt;</span>\S+) (<span class="token punctuation">?</span>P&lt;authuser<span class="token punctuation">&gt;</span>\S+)/ +
    / \<span class="token punctuation">[</span>(<span class="token punctuation">?</span>P&lt;access_time<span class="token punctuation">&gt;</span><span class="token punctuation">[</span>^\<span class="token punctuation">]</span><span class="token punctuation">]</span>+)\<span class="token punctuation">]</span> &quot;(<span class="token punctuation">?</span>P&lt;http_method<span class="token punctuation">&gt;</span>\S+) (<span class="token punctuation">?</span>P&lt;url<span class="token punctuation">&gt;</span>.+<span class="token punctuation">?</span>) / +
    /(<span class="token punctuation">?</span>P&lt;protocol<span class="token punctuation">&gt;</span>\S+)&quot; (<span class="token punctuation">?</span>P&lt;status<span class="token punctuation">&gt;</span>\d+) (<span class="token punctuation">?</span>P&lt;bytes_body<span class="token punctuation">&gt;</span>\d+) (<span class="token punctuation">?</span>P&lt;bytes_in<span class="token punctuation">&gt;</span>\d+)/ +
    / (<span class="token punctuation">?</span>P&lt;bytes_out<span class="token punctuation">&gt;</span>\d+) (<span class="token punctuation">?</span>P&lt;time_taken<span class="token punctuation">&gt;</span>\d+) &quot;(<span class="token punctuation">?</span>P&lt;referer<span class="token punctuation">&gt;</span><span class="token punctuation">[</span>^&quot;<span class="token punctuation">]</span>+)&quot; / +
    /&quot;(<span class="token punctuation">?</span>P&lt;agent<span class="token punctuation">&gt;</span><span class="token punctuation">[</span>^&quot;<span class="token punctuation">]</span>+)&quot;/

<span class="token comment"># /var/log/lighttpd/access.log</span>
getfilename() =~ /lighttpd.access.log/ <span class="token punctuation">{</span>
  // + ACCESSLOG_RE <span class="token punctuation">{</span>
    <span class="token comment"># Parse an accesslog entry.</span>
    $url == &quot;/healthz&quot; <span class="token punctuation">{</span>
      <span class="token comment"># nothing</span>
    <span class="token punctuation">}</span>
    otherwise <span class="token punctuation">{</span>
      strptime($access_time<span class="token punctuation">,</span> &quot;02/Jan/2006<span class="token punctuation">:</span>15<span class="token punctuation">:</span>04<span class="token punctuation">:</span>05 <span class="token punctuation">-</span>0700&quot;)

      request<span class="token punctuation">[</span>$status<span class="token punctuation">]</span>++
      time_taken<span class="token punctuation">[</span>$status<span class="token punctuation">]</span> += $time_taken
      bytes_out<span class="token punctuation">[</span><span class="token string">&quot;resp_body&quot;</span><span class="token punctuation">,</span> $status<span class="token punctuation">]</span> += $bytes_body
      bytes_out<span class="token punctuation">[</span><span class="token string">&quot;resp_header&quot;</span><span class="token punctuation">,</span> $status<span class="token punctuation">]</span> += $bytes_out <span class="token punctuation">-</span> $bytes_body
      bytes_in<span class="token punctuation">[</span>$status<span class="token punctuation">]</span> += $bytes_in

      $proxied_for <span class="token tag">!=</span> &quot;<span class="token punctuation">-</span>&quot; <span class="token punctuation">{</span>
        requests<span class="token punctuation">[</span>$request_ip<span class="token punctuation">]</span>++
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br></div></div><p>这个 program 一开始, 定义了很多 counter 类型的变量, 这里没有什么新知识, 略过. 然后定义了一个常量 ACCESSLOG_RE, 这个正则很复杂, 对于这类复杂的正则, 可以拆成很多个小的部分, 相互之间用 + 连接, 这种做法既容易阅读, 又容易为每个片段增加注释, 便于后期维护, 后面介绍的 grok_exporter 则更进一步, 把这些正则片段直接做成 pattern 单独维护了.</p> <p>继续往下看, getfilename() 是个内置函数, 获取日志文件的路径, 对这个内容做了一个正则判断, 如果匹配才去走核心逻辑, 这里是不是有些多此一举了呢? 我猜测, 这个写法的初衷是觉得这段内容可能会和其他的提取规则混在一起, 同时提取多个日志文件时, 为了避免这段逻辑跑在一些无关的日志上, 就加了这么一句判断, 考虑得很周全. 不过, 如果在使用的时候, 可以保证这段逻辑只用于处理 lighttpd 的访问日志, 这个判断就是可以去掉的.</p> <p>getfilename() 的判断通过之后, 就开始校验主正则了. 主正则匹配就开始判断请求的 url 是不是 <code>/healthz</code>​, 如果是就什么都不干(空逻辑), 因为这个是健康检查的接口, 没必要提取指标. 否则进行主逻辑处理, &quot;否则&quot;的关键词是 otherwise, 相当于 else. 主逻辑部分你应该一眼就能明白是什么意思, 核心点是这个 strptime 函数, 它其实是在告诉 mtail 用什么时间格式来转换时间戳, 第二个参数是 Go 写法的 format pattern, 这些其实都好理解, 比较容易掉坑里的是 <strong>时区问题</strong>.</p> <p>如果日志里的时间戳没有打印时区信息, mtail 在处理的时候会把它们统一当做 UTC 时间来对待, 这在其他时区的场景显然是错误的, 这个时候就要手工指定时区, 比如通过 <code>-override_timezone=Asia/Shanghai</code>​ 启动参数可以让 mtail 使用东八区.</p> <p>当然, 如果压根就不在 <code>/metrics</code>​ 接口中暴露时间戳信息, 那抓取器抓取数据的时候只能使用抓取的时间, 时区这个参数有没有都无所谓了, 但如果在 <code>/metrics</code>​ 接口中返回时间戳信息, 就一定要在启动参数中控制时区, 是否在 <code>/metrics</code>​ 接口中返回时间戳信息, 也是通过一个启动参数来控制的,  <code>emit_metric_timestamp</code>​ 设置为 true 的时候才会返回时间戳.</p> <p>最后说一下 mtail 的<strong>部署</strong>, 如果一个机器上有 5 个应用程序都要用 mtail 来提取指标, 各个应用的日志格式又不一样, 建议启动 5 个 mtail 进程分别来处理. 虽然管理起来麻烦, 但是性能好, 相互之间没有影响.</p> <p>如果把所有提取规则都放到一个目录下, 然后通过多次 -logs 参数的方式同时指定这多个应用的日志路径, 一个 mtail 进程也能处理, 但是对于每一行日志, mtail 要把所有提取规则都跑一遍, 十分浪费性能, 而且正则提取, 速度本来就不快. 另外有些指标可能是所有应用都可以复用的, 如果放在一起处理, 还容易相互干扰, 导致统计数据不准. 从这两点来看, 尽量还是要拆开分别处理, 虽然管理起来麻烦一些, 但也是值得的.</p> <p>在容器场景中就没有这个问题, 容器场景直接使用 sidecar 部署就好了, 每个 Pod 必然只有一个应用, 伴生的 mtail 就专注去处理这个应用的日志就好了.</p> <h4 id="快速上手grok-exporter"><a href="#快速上手grok-exporter" class="header-anchor">#</a> 快速上手grok_exporter</h4> <p>mtail 基本用法就介绍这么多, 不知道你有没有感受到, 得写这么多正则, 太麻烦了. 有没有一些工具可以复用这些正则表达式呢? 毕竟有很多相同的正则需求, 没必要重复造轮子. 的确有, 除了刚才介绍的 mtail 自带的 <a href="https://github.com/google/mtail/tree/main/examples" target="_blank" rel="noopener noreferrer">examples<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 之外, grok_exporter 把每个正则都拆散了, 复用性更好, 下面看一下 grok_exporter 是如何使用的.</p> <p><strong>grok_exporter 的核心逻辑和 mtail 一样, 就是通过正则从日志中提取指标</strong>, 之前已经介绍过 mtail 的核心逻辑了, 所以关于 grok_exporter 的介绍会相对简明一些.</p> <p>grok_exporter 显然是用到了 Grok, Grok 在 logstash 中被重度使用, 内置了 100 多个预定义的正则(叫做 pattern), 在 grok_exporter 的代码仓库里直接作为 submodule 的方式引用了 <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/6d25c13c15f98843513f7cdc07f0fb41fbd404ef" target="_blank" rel="noopener noreferrer">logstash-patterns-core<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 预定义的正则放在了 <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/6d25c13c15f98843513f7cdc07f0fb41fbd404ef/patterns" target="_blank" rel="noopener noreferrer">patterns<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 目录下, 可以点击查阅.</p> <p>从 grok_exporter 的 <a href="https://github.com/fstab/grok_exporter/releases" target="_blank" rel="noopener noreferrer">releases<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 页面下载发布包, 解压缩, 直接运行就可以.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>./grok_exporter <span class="token punctuation">-</span>config ./example/config.yml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>grok_exporter 默认监听在 9144 端口, 看下访问测试效果.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>flashcat@fc<span class="token punctuation">-</span>demo<span class="token punctuation">-</span>02 ~<span class="token punctuation">]</span>$ curl <span class="token punctuation">-</span>s 10.100.0.7<span class="token punctuation">:</span>9144/metrics <span class="token punctuation">|</span> head <span class="token punctuation">-</span>n 6
<span class="token comment"># HELP exim_rejected_rcpt_total Total number of rejected recipients, partitioned by error message.</span>
<span class="token comment"># TYPE exim_rejected_rcpt_total counter</span>
exim_rejected_rcpt_total<span class="token punctuation">{</span>error_message=&quot;Sender verify failed&quot;<span class="token punctuation">,</span>logfile=&quot;exim<span class="token punctuation">-</span>rejected<span class="token punctuation">-</span>RCPT<span class="token punctuation">-</span>examples.log&quot;<span class="token punctuation">}</span> 2000
exim_rejected_rcpt_total<span class="token punctuation">{</span>error_message=&quot;Unrouteable address&quot;<span class="token punctuation">,</span>logfile=&quot;exim<span class="token punctuation">-</span>rejected<span class="token punctuation">-</span>RCPT<span class="token punctuation">-</span>examples.log&quot;<span class="token punctuation">}</span> 32
exim_rejected_rcpt_total<span class="token punctuation">{</span>error_message=&quot;relay not permitted&quot;<span class="token punctuation">,</span>logfile=&quot;exim<span class="token punctuation">-</span>rejected<span class="token punctuation">-</span>RCPT<span class="token punctuation">-</span>examples.log&quot;<span class="token punctuation">}</span> 165
<span class="token comment"># HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>通过代码, 可以看到 grok_exporter 可以正常拿到监控数据了. 下面搞一下测试数据, 把它放到 example 目录下, 保存为 login.log.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>12.12.2022 04<span class="token punctuation">:</span>33<span class="token punctuation">:</span>03 10.1.2.1 user=Ulric message=&quot;logged in&quot;
12.12.2022 06<span class="token punctuation">:</span>47<span class="token punctuation">:</span>03 10.1.2.2 user=Qin message=&quot;logged failed&quot;
12.12.2022 06<span class="token punctuation">:</span>55<span class="token punctuation">:</span>03 10.1.2.2 user=Qin message=&quot;logged in&quot;
12.12.2022 07<span class="token punctuation">:</span>03<span class="token punctuation">:</span>03 10.1.2.3 user=Sofia message=&quot;logged in&quot;
12.12.2022 07<span class="token punctuation">:</span>37<span class="token punctuation">:</span>03 10.1.2.1 user=Ulric message=&quot;logged out&quot;
12.12.2022 08<span class="token punctuation">:</span>47<span class="token punctuation">:</span>03 10.1.2.2 user=Qin message=&quot;logged out&quot;
12.12.2022 14<span class="token punctuation">:</span>34<span class="token punctuation">:</span>03 10.1.2.3 user=Sofia message=&quot;logged out&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>之后修改 config.yml 来解析login.log.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">global</span><span class="token punctuation">:</span>
  config_version<span class="token punctuation">:</span> <span class="token number">3</span>
<span class="token key atrule">input</span><span class="token punctuation">:</span>
  type<span class="token punctuation">:</span> file
  path<span class="token punctuation">:</span> ./example/login.log
  readall<span class="token punctuation">:</span> <span class="token boolean important">true</span> <span class="token comment"># Read from the beginning of the file? False means we start at the end of the file and read only new lines.</span>
<span class="token key atrule">imports</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> grok_patterns
  dir<span class="token punctuation">:</span> ./patterns
<span class="token key atrule">metrics</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> counter
  name<span class="token punctuation">:</span> user_activity
  help<span class="token punctuation">:</span> Counter metric example with labels.
  match<span class="token punctuation">:</span> <span class="token string">'%{DATE} %{TIME} %{HOSTNAME:instance} user=%{USER:user} message=&quot;%{GREEDYDATA:data}&quot;'</span>
  labels<span class="token punctuation">:</span>
    user<span class="token punctuation">:</span> <span class="token string">'{{.user}}'</span>
    logfile<span class="token punctuation">:</span> <span class="token string">'{{base .logfile}}'</span>
<span class="token key atrule">server</span><span class="token punctuation">:</span>
  protocol<span class="token punctuation">:</span> http
  port<span class="token punctuation">:</span> <span class="token number">9144</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>使用这个新的配置文件做个测试, 下面是返回内容.</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token punctuation">[</span>flashcat@fc<span class="token punctuation">-</span>demo<span class="token punctuation">-</span>02 ~<span class="token punctuation">]</span>$ curl <span class="token punctuation">-</span>s 10.100.0.7<span class="token punctuation">:</span>9144/metrics <span class="token punctuation">|</span> grep user_activity
grok_exporter_line_processing_errors_total<span class="token punctuation">{</span>metric=&quot;user_activity&quot;<span class="token punctuation">}</span> 0
grok_exporter_lines_matching_total<span class="token punctuation">{</span>metric=&quot;user_activity&quot;<span class="token punctuation">}</span> 7
grok_exporter_lines_processing_time_microseconds_total<span class="token punctuation">{</span>metric=&quot;user_activity&quot;<span class="token punctuation">}</span> 106
<span class="token comment"># HELP user_activity Counter metric example with labels.</span>
<span class="token comment"># TYPE user_activity counter</span>
user_activity<span class="token punctuation">{</span>logfile=&quot;login.log&quot;<span class="token punctuation">,</span>user=&quot;Qin&quot;<span class="token punctuation">}</span> 3
user_activity<span class="token punctuation">{</span>logfile=&quot;login.log&quot;<span class="token punctuation">,</span>user=&quot;Sofia&quot;<span class="token punctuation">}</span> 2
user_activity<span class="token punctuation">{</span>logfile=&quot;login.log&quot;<span class="token punctuation">,</span>user=&quot;Ulric&quot;<span class="token punctuation">}</span> 2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>看起来 grok_exporter 要比 mtail 的方式更易用, 不过和 mtail 一样, 如果要对多个应用程序分别进行日志分析处理, 就要启动多个 grok_exporter 实例, 这点还是不太方便</strong>. 当然, 在运算方面, grok_exporter 没有 mtail 这种类语言式的处理来得灵活方便. 至于选用哪个, 尺有所短寸有所长, 都学会, 具体使用场景具体决策.</p> <h4 id="小结-19"><a href="#小结-19" class="header-anchor">#</a> 小结</h4> <p>本讲介绍的手段, 从标题上来看是服务于应用监控, 不过实际上也可以用于操作系统, 中间件, 数据库等其他监控场景, 而应用监控本身, 反倒不推荐日志监控方式, 而是更推荐上一讲介绍的埋点监控方式. 这一点一定要注意, <strong>毕竟相比埋点方式, 日志方式链路又长, 性能又差, 算是一个不得已而为之的方式</strong>.</p> <p>指标提取的几种方式, 总体上来看就是<strong>中心端和日志端</strong>两种, 由于中心端的处理方式多见于商业软件, 没有看到开源解决方案, 所以重点介绍的是日志端的处理方式, 日志端的处理核心逻辑都是一样的, 通过类似 <code>tail -f</code>​ 的方式不断读取日志内容, <strong>然后对每行日志做正则匹配提取, 由于日志格式不固定, 很难有结构化的处理手段, 所以这些工具都是选择使用正则的方式来提取过滤指标</strong>.</p> <p>mtail 和 grok_exporter 是日志端处理工具的佼佼者, mtail 直接写正则, 虽然可阅读性上稍微差了点儿, 但是胜在逻辑处理能力, 可以对提取的变量做运算, 就像一门小语言, 所以 mtail 把这些提取规则的文件叫做 program. grok_exporter 可以使用预定义的 pattern 名称配置匹配规则, 更易读, 易维护, 运算方面则显得稍弱.</p> <p>本节的思维导图如下:</p> <p><img src="/img/4704d08fdbdb7a7af28a13d906yybeaf-20230719203435-lafdp75.jpg" alt=""></p> <h2 id="监控告警"><a href="#监控告警" class="header-anchor">#</a> 监控告警</h2> <h3 id="_21-事件管理-事件降噪的几个典型手段"><a href="#_21-事件管理-事件降噪的几个典型手段" class="header-anchor">#</a> 21.事件管理-事件降噪的几个典型手段</h3> <p>前面一章介绍了各个部分的监控实战, 偏重如何采集数据, 如何构建仪表盘. 有了这些监控数据之后, 下一步就是告警了, 几乎所有的监控系统都具备生成告警事件的能力, 但通常都不具有完备的事件后续处理能力. 这里说的后续处理主要包括: <strong>多渠道分级通知, 告警静默, 抑制, 收敛聚合, 降噪, 排班, 认领升级, 协同闭环处理</strong>等等. 监控系统或多或少都有一些这方面的能力, 但是通常都不完备, 而这正是 <a href="https://www.pagerduty.com/" target="_blank" rel="noopener noreferrer">PagerDuty<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 这种产品存在的价值.</p> <p><strong>在事件处理方面, 一般会遇到两个痛点, 一个是告警事件太多, 被过度打扰, 另一个是重要告警疏漏, 无法闭环处理</strong>. 这个部分会用两讲内容来介绍这两个痛点的解法.</p> <p>下面先来聊一聊告警事件太多的问题, 看看通常是什么原因导致的.</p> <h4 id="告警太多的常见原因"><a href="#告警太多的常见原因" class="header-anchor">#</a> 告警太多的常见原因</h4> <p>最常见的原因, 是 <strong>告警规则设置得不合理</strong>. 比如很多规则触发了告警之后, 实际没有后续动作, 只是起到常态化通知的效果, 不需要排查, 也不需要止损, 甚至连个长线的 TODO 都没有. 这类告警多了人就疲了, 当重要的告警来临的时候, 也容易忽略. 这样的规则如果不经过治理, 日积月累, 就会产生很多无用的告警.</p> <p>第二个常见的原因是 <strong>底层出问题导致所有的上层依赖都告警</strong>, 越是底层影响越大, 比如基础网络如果出问题, 发出几万条告警都是正常的.</p> <p>第三个原因是 <strong>渠道错配</strong>. 一些不重要的告警也使用打扰性很高的渠道发出, 用户可能会觉得单一渠道不可靠, 想用多个渠道同时发送的方式来保障告警触达率, 这也属于告警规则配置不合理的范畴.</p> <p>第四个原因是 <strong>预期内的维护动作</strong> 导致的. 比如程序升级变更, 如果进程重启时间过长, 可能会导致关联的服务告警, 或者某个机器重启, 忘记提前屏蔽了, 也会产生一堆关联告警.</p> <p>了解了常见原因, 下面来看一下有哪些常见解法.</p> <h4 id="优化告警规则"><a href="#优化告警规则" class="header-anchor">#</a> 优化告警规则</h4> <p>类似 PagerDuty 这样的告警事件中心的产品, 一定程度上是可以解决一些告警过多的问题, 但如果能<strong>从告警规则的源头做好优化</strong>, 自然是事半功倍. 很多公司的告警规则配置没有原则可循, 每次故障复盘先看告警是否漏报, 一线工程师为了不背锅, 自然是尽量多地提高告警覆盖面, 但这么做的后果, 就是告警过多, 无效告警占多数, 长此以往, 工程师疲惫不堪.</p> <p>那么告警规则的配置应该遵照一个什么原则呢? 虽然每个公司业务不同, 总有一些通用的原则可循吧? 的确如此, 这里我分享一下经验做法.</p> <h5 id="_1-每个规则都应该对应具体的runbook"><a href="#_1-每个规则都应该对应具体的runbook" class="header-anchor">#</a> 1.每个规则都应该对应具体的Runbook</h5> <p>Runbook 就是<strong>告警处理手册</strong>, 也就是告警触发之后, 应该细化排查哪些方面, 按照一个什么方式执行动作, 应该有一个手册参考. 如果告警发生之后没有后续动作, 那这个告警的意义就不大了. 在 Nightingale 的告警规则配置页面, 可以看到一个专门的 Runbook 配置, Grafana 的告警配置页面, 也有一个 Runbook 的选项, 就能看出他们对它的重视程度.</p> <p>这个原则看起来是不是很合理? 但是真要落地的时候, 又会发现紧急需要处理的告警事件通常容易对应 Runbook, 但是有些告警规则产生的告警确实没有那么紧急, 有些只是想作为一个通知, 好像又确实难以对应一个固定的 Runbook.</p> <p>针对这两种情况, 一般的做法是: <strong>不紧急的告警, 也必须要有动作, 虽然这个动作可能不是立马执行处理, 但至少要创建个低优先级的工单之类的, 或者提高告警阈值, 等问题严重一些再告警</strong>. 对于只是想通知一下的告警, 其实都不算告警, 只能看做是一种另类的报表和巡检手段, 这样的 &quot;告警&quot; 就按照报表和巡检的逻辑来处理, 比如把这类 &quot;告警&quot; 发到一个单独的邮件组或者单独的聊天群组, 平时都不用关注, 只要每天早上上班或晚上下班之前稍微看一眼就行, 这样就可以减少打扰.</p> <p>制定了这个原则之后, 如果大家不遵守怎么办呢? 还是有很多告警没有对应的 Runbook, 作为管理人员应该怎么处理? 建议是分产品线统计一个指标: &quot;Runbook 预置率&quot;, 就是各个产品线有多少告警规则配置了 Runbook, 有多少没有配置, 这个比例要统计出来, 然后做成红黑榜, 让大家去治理, 治理一段时间之后有经验了, 知道预置率大概在一个什么范围是合理的, 然后就可以要求大家至少达到预置率下限的值. 否则, 就一定是有问题的.</p> <p><strong>Runbook 这个配置原则, 是最为推荐的原则, 效果非常明显, 其次就是告警分级原则.</strong></p> <h5 id="_2-每个告警都应该合理分级"><a href="#_2-每个告警都应该合理分级" class="header-anchor">#</a> 2.每个告警都应该合理分级</h5> <p><strong>基本每个监控系统都支持为告警规则配置不同的级别, 基本上每个监控系统的用户也都知道应该做分级告警</strong>. 但是具体怎么分级, 却没有一个行业共识, 大家各做各的. 这里分享一下个人理解, 可以参考借鉴.</p> <p><strong>首先, 不同级别的告警应该对应不同的处理逻辑, 这样分级才有意义</strong>, 比如通知渠道不同, 通知范围不同, 或者介入处理的人的范围不同, 处理时效不同, 如果某两个级别对应完全一样的处理逻辑, 就可以合并成一个级别.</p> <p>通常的做法是把告警分成 3 个级别.</p> <p><img src="/img/5eabb0b2bb8bedeaa32cb18eb3935963-20230719203435-d80jp1w.png" alt="图片"></p> <p>另外, 如果 Critical 的告警规则很多, 大概率也有问题, 说明系统架构不够鲁棒, 出点什么事都要立刻介入, 系统没有自愈能力. 这样的系统, 需要配备更多运维人员, 而且还很难跟老板讲清楚价值. 怎么办? 这就需要<strong>制定运维准入规则</strong>, 哪个系统要交给运维人员来运维, 首先要提供一些信息.</p> <ul><li>相关联系人, 出了问题能够及时找到人, 联系不上的话得能直接联系研发领导.</li> <li>服务相关信息, 比如代码仓库, 系统架构, 依赖哪些服务, 依赖哪些系统参数, 哪些 JVM 参数, 常见问题还有处理办法等等.</li></ul> <p>然后进行准入评审, 如果系统架构有明显问题, 就没办法通过准入要求, 不接受运维, 如果老板要求必须接, 那就只能加人了, 或者明确说明在架构调整好之前, 不负责 SLA. 如果老板不接受沟通, 那就跳槽吧, 老板根本不懂运维, 不懂稳定性还不信任你.</p> <p>上面介绍的两个告警规则优化原则, 是最重要的两个原则. 照做的话, 可以搞定大部分无效告警, 下面再<strong>从告警产品的角度</strong>来看, 有哪些手段可以解决告警太多的问题.</p> <h4 id="告警规则支持生效时间的配置"><a href="#告警规则支持生效时间的配置" class="header-anchor">#</a> 告警规则支持生效时间的配置</h4> <p>不同公司的业务相差很大, 比如券商, 交易时间段内需要高优保障稳定性, 但是非交易时段, 有些进程直接停掉也无所谓. 但如果是监控系统, 数据是时时刻刻都在上报的, 没有高峰低谷, 需要时刻保证高可用. 可以看下典型的生效时间配置, 可以配置一周当中哪些天生效, 哪些时间段生效. 当然整体是否启用的开关也必不可少.</p> <p><img src="/img/aca64e9cb797f790d41666eb53903183-20230719203435-unhnkrk.png" alt="图片"></p> <p>图片中的配置其实可以继续优化, 现在是只能配置一个时间段, 如果能够配置多个时间段就更好了.</p> <h4 id="告警规则支持分级和不同的触达渠道"><a href="#告警规则支持分级和不同的触达渠道" class="header-anchor">#</a> 告警规则支持分级和不同的触达渠道</h4> <p><strong>有的系统会把触达渠道和告警级别强绑定</strong>, 用户只需要选择级别, 就自动使用对应的通知媒介, 有的系统会把二者拆开, 个人对这个没有倾向性, Open-Falcon 是绑定的, Nightingale 是分别配置的, 分别配置的方式会相对灵活一点.</p> <p><strong>一些低优先级的告警就用打扰性低的通知媒介来通知</strong>, 比如邮件, 不要什么都打电话发短信, 如果某个通知渠道经常用来通知一些低优先级的告警, 时间久了这个通知媒介发出的告警就不被重视了.</p> <h4 id="重复告警支持最大次数和发送频率"><a href="#重复告警支持最大次数和发送频率" class="header-anchor">#</a> 重复告警支持最大次数和发送频率</h4> <p>有些告警短时间没法恢复, 可能会重复发送. 比如一分钟检查一下某个指标, 如果超过阈值就告警, 从某个时刻开始, 触发了阈值, 一分钟之后发出第一条告警, 但是短时间没有恢复, 持续了 10 分钟, 监控系统在第二分钟检查的时候发现还是告警状态, 可能还会发出一条告警, 但是这个告警的重要性就远不如第一条, 完全可以不用通知. 通过设置发送频率, 可以做到比如 1 小时之后再检查, 如果 1 小时之后还是没有恢复, 再发出第二条告警, 这样告警数量就大幅减少了. 当然, 如果好几天没有恢复, 也没有必要每个小时发一次, 应该支持最大发送次数, 限制一下未恢复之前的通知总次数. 比如 Nightingale 对这两项的配置.</p> <p><img src="/img/2f0d3e38edb15c6606ee25b696b9b669-20230719203435-bty60r4.png" alt="图片"></p> <p>看图片里还有一个启用恢复通知和留观时长, 这里也解释一下, 这也是减少通知次数的典型手段. 告警之后一般会发一条 &quot;Triggered&quot; 的消息, 如果恢复了, 有些用户也希望得到通知, 这个时候会收到一条 &quot;Resolved&quot; 消息. 但是重要的告警只要收到了, 一般就会立马到平台上去排查, 既然用户已经登录平台了, 告警是否恢复其实已经可以在平台上看到了, 不用再通知, 所以有些用户就把 &quot;启用恢复通知&quot; 给关闭了, 这种方式也可以减少消息通知次数.</p> <p>留观时长有点儿像是去看病, 告警了就相当于得病了, 比如高烧 39 度, 触发了告警, 这个时候像医生一样进行一系列诊断和修复的动作, 发现体温退到 37 度, 这个时候应该出院吗? 有的时候是不行的, 需要观察一段时间, 一段时间内没有再次高烧再出院, 这就是留观时长的设计逻辑.</p> <h4 id="告警事件支持屏蔽配置"><a href="#告警事件支持屏蔽配置" class="header-anchor">#</a> 告警事件支持屏蔽配置</h4> <p>告警屏蔽一般就是在做一个预期的维护动作之前, 提前把相关告警屏蔽掉, 免得在维护期间又收到告警.</p> <p>告警屏蔽一般有两种配置方式, 一个是配置成未来的一个时间段, 一个是配置成周期性时间段. 未来的一个时间段, 就是用来应对刚才介绍的预期内维护行为的, 周期性时间段比较特殊, 比如每天凌晨 1 点到 5 点不需要告警, 或者周末不需要告警, 就可以配置成周期性屏蔽规则.</p> <h4 id="告警事件支持抑制配置"><a href="#告警事件支持抑制配置" class="header-anchor">#</a> 告警事件支持抑制配置</h4> <p>告警抑制的典型使用场景是一个指标配置两条策略, 不同的优先级和阈值, 如果高优先级的告警触发了, 低优先级的告警就被抑制, 不再重复发送了.</p> <p>比如磁盘使用率大于 88% 就发一个 Warning 级别的告警, 大于 99% 则发一个 Critical 级别的告警, 现在磁盘使用率在 85%, 突然一下子写到了 99.1%, 理论上这个时候两个告警都会触发, 但是只希望收到 Critical 级别的告警. 这就需要告警抑制规则的支持了.</p> <p>有些监控用户会表达这种需求: 某个核心数据库告警了, 依赖这个核心数据库的告警都会发出来, 希望这个场景也做个抑制, 只收到数据库那条告警, 上游服务告警就不要再发出来了. 这个需求合理吗?</p> <p>我觉得有待商榷. 所有的上游服务都发出告警, 虽然告警消息变多了, 但是可以通过聚合发送的方式减少打扰, 众多服务告警, 也正好可以让我们知道影响范围. 另外, 服务之间的依赖关系错综复杂, 依赖这个数据库的服务出了问题, 确实可能是数据库导致的, 但也可能是其他依赖导致的, 如果这个时候通过抑制规则只发出数据库告警, 可能就会忽略一些问题.</p> <h4 id="告警事件聚合发送逻辑"><a href="#告警事件聚合发送逻辑" class="header-anchor">#</a> 告警事件聚合发送逻辑</h4> <p>事件降噪发送最有效的技术手段, 其实就是<strong>聚合发送</strong>, 能够起到立竿见影的效果. 用户的告警规则配置得太乱, 系统是没办法左右的, 但是短时间触发很多告警, 系统是可以通过技术手段聚合之后再发送的.</p> <p>事件聚合一般是根据两三个维度的信息进行聚合运算, 比如告警接收者的维度, 时间的维度, 指定的某个标签的维度(比如产品线), 也可能不指定聚合标签, 只使用接收者维度和时间维度, 这样聚合率会更高. 什么意思呢, 举个例子.</p> <p>张三同学, 在一分钟内, 收到 10 条 Kafka 告警, 10 条 Elasticsearch 告警. 如果只按照接收者维度和时间维度聚合, 就可以把这 20 条告警聚合成 1 条通知张三, 通知消息可能是这么写的.</p> <blockquote><p>张三您好, 最近一分钟您有 20 条告警, 最高级别是 Warning, 相关告警举例:</p> <p>10.2.3.4 Kafka 有目录 Offline</p> <p>10.2.3.5 Kafka 有目录 Offline</p> <p>10.2.3.6 ElasticSearch 流量过大</p> <p>更多详细告警信息, 请点击这里查看</p></blockquote> <p>如果把产品维度也加上, 这 20 条告警就会聚合成 2 条, 1 条报的是 Kafka, 1 条报的是 Elasticsearch. 所有聚合发送的事件中心大都是类似的逻辑, 当然也可以根据文本相似性之类的做聚合.</p> <p>另外也可以增加更多维度来聚合. 那怎么做才是最佳实践呢?</p> <p>分享一下个人看法: 从告警聚合通知角度来看, 只根据<strong>接收人和时间</strong>两个维度做聚合就够了, 这样的聚合率最高, 被打扰的次数最少. 虽然会把多种告警消息混杂在一起通知给用户, 显得有些混乱, 但是用户一般也不会在短信, 邮件, 即时通信软件里期待分门别类的事件查看效果. 想要更好的查看效果, 可以去页面上看, 页面上有更大的操作区, 想怎么聚合就怎么聚合, 想怎么看就怎么看. 告警都已经发生了, 大概率是要打开电脑处理的, 都已经打开电脑了, 在页面上查看一下也是顺其自然的.</p> <p>针对告警事件太多的问题, 主要就是上面这些解决办法. 市面上的开源产品, 只有 Prometheus 生态的 Alertmanager 做得相对完备一点, 但是也不具备上面说的所有的能力. 主要是监控系统的重心, 大都放到了数据采集, 数据存储, 告警触发引擎上面了, 对于告警发送这块, 关注相对比较少. 而且, 告警发送是个通用需求, Zabbix 需要, Prometheus 需要, Open-Falcon, Nightingale, 各类云监控其实都需要, 做一个统一的产品对接所有这些事件源, 是个更合理的做法.</p> <h4 id="小结-20"><a href="#小结-20" class="header-anchor">#</a> 小结</h4> <p>告警事件太多的常见原因, 包括告警规则设置不合理, 底层服务告警导致上游大量告警, 渠道错配, 预期内维护等几类. 对于怎么改进这些问题, 最推荐的方式是优化告警规则, 搞定问题源头, 这需要依赖一些原则, 典型的原则有两个, 一是要求所有的告警都有 Runbook, 二是要求分级合理. 对于告警规则, 还要注意生效时间的配置, 发送频率, 最大发送次数的配置. 对于告警事件, 要做好预先屏蔽, 抑制, 对于最后产生的告警, 要做到聚合发送, 减少打扰.</p> <p>另外所有的告警事件, 建议都要持久化保存, 至少保存几个月. 通过这些历史资料, 可以分析出很多信息, 比如哪个团队接收告警最多, 哪个告警规则发出的告警最多, 哪些告警长时间都没有恢复, 平均告警恢复时长是多少, 可以根据这些数据做告警优化.</p> <p>本节的思维导图如下:</p> <p>​<img src="/img/b61c5f7e372e5bc4fd0833de5ba06d35-20230719203435-s8edbw2.jpg" alt="">​</p> <h3 id="_22-事件管理-如何保证事件的闭环处理"><a href="#_22-事件管理-如何保证事件的闭环处理" class="header-anchor">#</a> 22.事件管理-如何保证事件的闭环处理?</h3> <p>上一讲介绍了事件降噪的几个典型手段, 其实就是怎么让告警发得少点儿. 本节介绍事件闭环管理, 就是告警发出来得有人处理, 所谓的闭环, 就是指<strong>告警发出, 认领, 协作处理, 问题恢复, 复盘改进</strong>的整个过程.</p> <p>虽然事件降噪的几个手段落实之后, 事件数量确实变少了, 但是处理告警事件显然不是一个让人愉快的事情, 不愉快的事情就要团队共担, 所以第一个手段就是排班, 专人做专事.</p> <h4 id="排班-专人做专事"><a href="#排班-专人做专事" class="header-anchor">#</a> 排班,专人做专事</h4> <p>这个手段听起来并不高大上, 但确实非常有效. 值班期间虽然提心吊胆的, 生怕背锅, 但因为是轮班制, 心里总有个盼头, 挺过这个周期就好了.</p> <p>轮班的人在值班期间是第一责任人, 会拿出 120% 的精力来处理问题, 责任到人显然更容易推进问题解决, 其他不值班的人则可以心无旁骛地做一些长线的事情, 不至于总是被告警打断.</p> <p>排班系统通常不开源, 通常是作为事件中心的一个功能, PagerDuty 就提供了排班能力, 即使没有系统支持, 也建议人为制定一个排班表, 把这个制度落实下去, 对告警闭环处理也会有很大帮助.</p> <p>值班人员在值班期间, 虽然已经高度重视了, 但也难免疏漏, 这就需要告警升级机制了.</p> <h4 id="告警升级机制"><a href="#告警升级机制" class="header-anchor">#</a> 告警升级机制</h4> <p>告警升级是指在第一责任人收到告警之后没有及时响应, 然后系统自动通知二线, 三线人员的一种机制. 一线人员没有及时响应的原因可能有很多, 比如手机静音了没有听到, 晚上睡着了, 或者临时出去有事忘带手机了等等. 这个时候系统发现某个告警一直没有恢复, 也没有被认领, 一段时间之后, 就应该通知值班人员的领导或者二线备份人员, 如果二线人员也迟迟没有响应, 就应该继续往上升级.</p> <p>告警升级机制需要认领功能的配合, 也就是一线人员收到告警之后要通过某种机制告诉系统: &quot;我已知晓告警, 现在我开始处理了, 你不要升级了&quot;. 典型的认领功能一般是做在页面上的, 告警后打开告警事件管理中心, 选中相关告警一键认领, 也可以通过上行短信或即时通讯工具中的上行回调机制来完成.</p> <p>升级机制会给值班人员很大的压力, 毕竟谁也不想稍不留神就把电话打到老板那里, 所以一般只有严重的告警才会启用升级机制, 警告或者通知性质的告警都不用启用升级机制. 当然, 这个规范怎么定, 各个团队可以自行商定.</p> <p>通过排班, 认领, 升级这些机制, 可以确保告警递达指定的人, 但要处理告警的话, 只有值班人员自己就未必搞得定了, 需要有协同机制把相关人都拉进来一起处理才可以. 对于某个故障, 可能同时有多个告警事件产生, 大家基于一个统一的故障协同, 而不是基于一堆事件分别协同, 这就需要把这多个事件收敛成一个故障, 下面我们来聊一下这个收敛逻辑.</p> <h4 id="告警收敛逻辑"><a href="#告警收敛逻辑" class="header-anchor">#</a> 告警收敛逻辑</h4> <p>一般收敛逻辑是三级收敛, event -&gt; alert -&gt; incident. 举个例子, 最原始的告警事件, 比如 host1 在 timestamp1 产生了一条 cpu_usage_idle 的告警, 我们称为一个 event. 如果没有恢复, 一段时间之后, 比如 timestamp1 + 60min, 一般会再发出一个告警, 还是 host1, 还是 cpu_usage_idle 这个指标. 很明显, 这两个告警事件是有关联关系的, 指代的是一个问题, 只是时间戳不同, 这样的两个 event, 就可以收敛为一个 alert.</p> <p>从实现上来说, <strong>告警策略(也称告警规则) + 指标标签集的哈希值</strong>, 可以作为 alert 的唯一标识. 比如刚才的例子, 告警策略的 ID 假设为 32, 标签集是: [&quot;name =cpu_usage_idle&quot;, &quot;host=host1&quot;], 这两个时间戳产生的告警事件, 哈希值都是一样的.</p> <p>计算方法是:</p> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code>hash(32 + <span class="token punctuation">[</span><span class="token string">&quot;__name__=cpu_usage_idle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;host=host1&quot;</span><span class="token punctuation">]</span>)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>从 event 到 alert 的这个收敛逻辑, 叫做一级收敛. 只有这个收敛逻辑还不够, 告警信息还是比较散, 不好基于这些散乱的告警分别做协同, 把多个 alert 收敛成一个 incident(故障), 基于 incident 做协同才比较方便. 但是, event 到 alert 是有一个固定的收敛逻辑的, 可以通过程序自动收敛, 而 alert 到 incident 却很难自动收敛. 不过业界也会有一些常见的做法, 下面举几个例子.</p> <blockquote><p>根据时间做收敛</p></blockquote> <p>把告警中心收到的所有告警, 按照时间维度做收敛, 比如按照分钟颗粒度, 一分钟内所有告警收敛成一个故障, 下一分钟所有告警收敛成另一个故障. 显然, 一个故障内的多个告警相互之间可能没有关联关系, 所以这种收敛方法不是太好.</p> <blockquote><p>根据时间+标签做收敛</p></blockquote> <p>除了时间维度, 再加上某个标签作为收敛维度, 比如机器标签, 某个时间段内所有 A 机器的告警收敛成一个故障, 所有 B 机器的告警收敛成另一个故障. 或者按照服务维度, 某个时间段内所有 A 服务的告警收敛成一个故障, 所有 B 服务的告警收敛成另一个故障. 看起来效果好多了, 不过还是没办法和现实中的告警和故障建立完美的对应关系.</p> <blockquote><p>根据时间+文本相似度做收敛</p></blockquote> <p>文本相似度需要引入算法, 但是算法总得有个规律, 很想把某个故障相关的告警聚拢到一起, 但是显然, 很难有个行之有效的规律, 没有规律的算法效果自然好不到哪儿去.</p> <p>既然没办法把告警自动收敛成故障, 那就手工来做. 一个故障关联的关键告警, 还是相对容易区分的, 只要把关键告警关联到故障, 后续基于这个故障做协同就可以了. 所谓协同, 一个是信息同步, 协同处理, 一个是共同复盘, 管理跟进项.</p> <h4 id="故障协同处理"><a href="#故障协同处理" class="header-anchor">#</a> 故障协同处理</h4> <p>首先, 并不是所有的告警都需要升级成故障协同处理. 一般来讲, 如果告警可以被值班人员直接处理掉, 对别的团队负责的服务没有影响, 不需要通知别的团队, 通常是不需要升级成故障的, 在告警层面来协同就可以了, 自己团队内部消化掉; 如果值班人员和他所在的团队没办法独自处理告警, 才需要升级成故障, 拉其他团队的人进来一起处理.</p> <p>多个团队共同处理一个故障, 不同团队的人会发现一些不同的线索, 需要及时同步给所有相关的人, 这个时候就可以在故障下面添加评论, 其他人就可以及时看到. 等到止损之后, 大家还要根据故障时间线复盘, 产出一系列跟进项, 这个时候就需要这个故障管理模块具备跟进项管理的功能, 或者至少能够跟任务管理系统良好打通.</p> <p>有了这样一个故障协同的机制之后, 故障被处理掉的概率就大幅提升了, 后续再配合一些运营统计手段, 统计各个团队的平均故障止损时间, 建立红黑榜, 大家就会有更高的热情来处理故障. 当然, 人的热情再高, 也不如机器来得快, 如果有些告警能够直接关联自动化处理逻辑, 无疑可以大大增加事件闭环率.</p> <h4 id="告警自动处理"><a href="#告警自动处理" class="header-anchor">#</a> 告警自动处理</h4> <p>很多监控系统都可以配置 Webhook, 当告警触发之后自动回调某个 HTTP 接口, 来串联一些自动化的逻辑, 让告警事件无人值守自动处理. 比如某个机房的某个服务挂掉了, Webhook 的逻辑是自动调用切流的接口, 把服务流量切走, 这样来达到止损的目的.</p> <p>不过对于很多运维工程师来说, 写一个 HTTP 接口还是有点儿麻烦, 如果可以在告警之后直接调用一个脚本, 在这个脚本里写自愈逻辑就好了. Nightingale 就可以这么干, 配合 ibex 模块, 可以在告警的时候自动去告警的机器上跑个脚本, 比如磁盘满了自动跑个脚本清理一下无用的日志, 只要在告警规则的回调地址里配置类似 <code>${ibex}/35</code>​ 的信息就可以了.</p> <p>​<code>${ibex}/35</code>​ 就表示告警触发之后自动执行 ID 为 35 的自愈脚本, 默认在告警的机器上执行. 如果想到固定的机器上执行, 比如去某个中控机上执行, 只需要把机器标识信息拼接到 URL 后面, 比如 <code>${ibex}/35/cloud-center01.bj</code>​.</p> <p>新版本的 Categraf 已经内置了 ibex-agent, 不用再单独安装任务执行的 agent 了, 只要在服务端单独部署 ibex-server 模块, 和 n9e-server 协同打通即可, 非常简单.</p> <p>另外, 告警自动处理的这段逻辑, 未必一定能够做到告警自愈, 有的时候只是使用这个机制来抓现场, 也是非常有价值的. 比如某个进程挂掉了, 在挂掉的时候我想知道当时机器的一些运行情况, 比如各项资源的占用情况, 系统日志的信息等等, 我们就可以借助告警自动处理的这个方式, 来自动跑个脚本抓取当时机器上的一些现场信息, 相比收到告警之后手工登录机器查看要高效得多.</p> <h4 id="小结-21"><a href="#小结-21" class="header-anchor">#</a> 小结</h4> <p>本节主要想解决一个问题, 就是告警事件发出之后, 怎么保证一定有人跟进处理, 而且是很快地跟进. 首先是通过排班这个偏管理的手段让大家共同承担一个不那么让人愉快的事情, 为了保证值班人员能及时响应, 引入了 <strong>告警升级通知机制</strong>. 确保事件有人认领之后, 就相当于确立了事件的跟进负责人, 包产到户了, 那后面的事情推进起来就快得多了.</p> <p>告警事件的跟进负责人如果可以处理消化掉相关的告警, 那是再好不过. 如果他个人和团队没办法独自处理, 就需要拉更多的人进来了. 大家基于一个统一的故障协同机制一起排查, 故障是一个包含了多条告警的实体, 大家在这个故障下通过评论的方式发表看法, 提供线索, 止损之后还要复盘, 产出故障对应的未来改进项.</p> <p>此外, 还有一个有效的策略—— <strong>告警自动处理机制</strong>, 一般通过 Webhook 来实现, Nightingale 则更进一步, 内置告警自愈脚本的管理, 可以和 ibex 打通做到告警的时候自动去机器上跑个脚本.</p> <p>本节的思维导图如下:</p> <p>​<img src="/img/1289b2583a4d718b064d1f746a98857e-20230719203435-wzmexl1.jpg" alt="">​</p> <h2 id="结束语"><a href="#结束语" class="header-anchor">#</a> 结束语</h2> <h3 id="_23-弱水三千-只取一瓢饮"><a href="#_23-弱水三千-只取一瓢饮" class="header-anchor">#</a> 23.弱水三千,只取一瓢饮</h3> <h4 id="术业有专攻"><a href="#术业有专攻" class="header-anchor">#</a> 术业有专攻</h4> <p>不要想着这也要学好那也要搞定, 去看一下大厂的招聘要求, <strong>全都是要专才, 而不是什么都稀松平常的通才</strong>. 试想一下, 一个对 Kafka 有源码级掌控力的技术专家, 和一个声称自己既懂 Java, Python, 又懂 Kafka, Elasticsearch, 还懂 Kubernetes, H5, Android 开发的全才, 哪一个会更值钱?</p> <p>回想我大学的第一个寒假, 去图书馆借了很多书, Java 开发相关的, .NET 开发相关的, 甚至还有计算机硬件, Photoshop, Word 的书, 但贪多嚼不烂, 很多我都只是泛泛地读了读, 最后脑子里什么都没有剩下, 想来当时确实是有些天真.</p> <p>技术细分领域太多了, 到底选择哪个方向深耕呢? 一句话概括:  <strong>要选择有复利效应且天花板高的领域</strong>. 复利效应是说你在这个领域里经验越丰富, 就越能拿到好的结果, 而天花板高, 是说这个领域里的经验少的新人很难在短短几年之内就取代经验丰富的老人, 俗称越老越吃香.</p> <p>选好方向之后, 如何更快地成长就是接下来要重点思考的问题了. 你应该见过同样工作 6 年的人, 一个P9, 而另一个却是 P6 吧?</p> <h4 id="成长讲求方法"><a href="#成长讲求方法" class="header-anchor">#</a> 成长讲求方法</h4> <p><strong>有些人声称有 5 年的经验, 其实只有 1 年的经验, 重复用了 5 年; 有些人每天忙忙碌碌解决生产问题, 阅读, 编写大量代码, 学习领域大咖的各种布道分享, 经验蹭蹭地涨, 工作 2 年可能就能达到普通人工作 5 年才有的水平.</strong></p> <p>所在的团队不同, 项目不同, 一定程度上会影响个人的成长, 不过这些外部因素大概只能决定 20%, 80% 都是由个人的努力程度和学习方法决定的. 正所谓方向不对, 努力白费, 方法不行, 啥都不灵. 这里总结了几条行之有效的方法, 分享给你, 希望对你有些启发.</p> <blockquote><p>优先打磨工作中用得到的技术, 用不到的技术学了也容易忘记</p></blockquote> <p>计算机实际是一门工科, 所谓好记性不如烂笔头, 烂笔头不如动手实操. 你熟悉的那个语言的条件语句和循环语句, 应该都写得很溜吧? 但你 N 年前学习的 PL/SQL 的存储过程, 不知道是否还能写出 hello world. 这些淡忘的技术大都是工作中用不到的技术, 抛却了也挺好, 重点学习工作中用得到的技术, 以及这些技术的延展知识, 既能解决工作中的问题, 又能快速提升技术能力, 而且还记得牢, 一举多得!</p> <blockquote><p>免费的才是最贵的, 节省时间的才是最便宜的</p></blockquote> <p>看到这句话, 你可能会想: “你出课程肯定会推荐知识付费啦! ”本来我不想写这一条, 就是担心引起不必要的口水战. 不过在我实际的写作过程中, 这一点让我深有体会, 所以不吐不快. 因为我写文章要查阅大量知识, 在搜集资料的过程中, 我发现付费知识的水准普遍比免费的高出一大截. 很多知识查一周查不出个所以然, 花一天时间查查电子书, 查查专栏, 就能用更少的时间得到更体系化的知识, 其实这才是我们需要的.</p> <p>人生短短三万天, 学习这个事, 还是要讲究效率的. 相比付出的时间成本, 那几百块知识的费用, 真的是毛毛雨.</p> <blockquote><p>自以为会的不一定真会, 能讲出来的知识才是自己的</p></blockquote> <p>所谓台上一分钟台下十年功, 懂得 10 分可能只能讲清楚 2 分, 只懂 2 分则 1 分都讲不清楚. 所以如果有人向你提问, 那就是一个非常好的输出机会, 即使你答不上来也没有关系, 因为这些问题是你自己的知识盲区, 解决这些问题能够让你成长得更快.</p> <blockquote><p>时间一定是有的, 关键看你有多少热情</p></blockquote> <p>虽然我们已经敲定了一个细分领域, 但是仍然有很多知识要学, 是不是感觉学不过来? 如果你确实有这种感受, 说明你的热情还没有完全激发出发. 打游戏, 看小说可以到凌晨 1 点而不觉得累, 学习怎么就不行呢? 14 年我们写 Open-Falcon 那会儿, 经常是工作 5 天, 周末 2 天拿来重构代码, 下周继续写新功能, 完全不觉得累, 那种巨大的热情, 让一切皆有可能.</p> <blockquote><p>站在高一个层级思考问题, 把自己当作项目负责人</p></blockquote> <p><strong>这也是一个奇招, 非常有用. 当把自己的位置摆高, 视野自然就不一样了, 站在全局思考, 就是会考虑得更全面</strong>. 比如一个前后端合作开发的项目, 一般是后端人员出接口文档, 然后给前端人员讲解产品设计和接口设计, 可以统计这类项目的 Bug 率, 一般前端 Bug 率会更高, 原因很容易理解, 后端人员心里装着全局, 考虑得会更周全, 而这个周全的思考不可能 100% 传达给前端, 所以前端如果不能主动思考, 就容易出纰漏.</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p> <p>‍</p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/xugaoyi/vuepress-theme-vdoing/edit/main/docs/30.系统/3000.系统/400.服务治理-系统监控与安全/411.运维监控系统实战(极客时间)🌸.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <!----></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/c9bf40/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">系统监控组件</div></a> <a href="/pages/e20e02/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">OAuth2.0实战课(极客时间)🌟</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/c9bf40/" class="prev">系统监控组件</a></span> <span class="next"><a href="/pages/e20e02/">OAuth2.0实战课(极客时间)🌟</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="mailto:1174520425@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/nanodaemony" title="GitHub" target="_blank" class="iconfont icon-github"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2025
    <span>达尔文的猹 | MIT License</span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.3f3e0e10.js" defer></script><script src="/assets/js/2.e9fcb30c.js" defer></script><script src="/assets/js/3.1998f389.js" defer></script><script src="/assets/js/188.1bc8be96.js" defer></script>
  </body>
</html>
