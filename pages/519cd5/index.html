<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>20-深入拆解消息队列(极客时间) | Pangolin Note</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="大道至简">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.56073ad3.css" as="style"><link rel="preload" href="/assets/js/app.3f3e0e10.js" as="script"><link rel="preload" href="/assets/js/2.e9fcb30c.js" as="script"><link rel="preload" href="/assets/js/3.1998f389.js" as="script"><link rel="preload" href="/assets/js/149.95017f0a.js" as="script"><link rel="prefetch" href="/assets/js/10.0b55747f.js"><link rel="prefetch" href="/assets/js/100.b8912a99.js"><link rel="prefetch" href="/assets/js/101.a6740c8a.js"><link rel="prefetch" href="/assets/js/102.e31e89b2.js"><link rel="prefetch" href="/assets/js/103.2c5dbdae.js"><link rel="prefetch" href="/assets/js/104.0e9c02f6.js"><link rel="prefetch" href="/assets/js/105.8288396c.js"><link rel="prefetch" href="/assets/js/106.62f43c11.js"><link rel="prefetch" href="/assets/js/107.70c90211.js"><link rel="prefetch" href="/assets/js/108.b488ce56.js"><link rel="prefetch" href="/assets/js/109.12942650.js"><link rel="prefetch" href="/assets/js/11.ac3fd1ca.js"><link rel="prefetch" href="/assets/js/110.1e57ecba.js"><link rel="prefetch" href="/assets/js/111.6e33b4ea.js"><link rel="prefetch" href="/assets/js/112.bd52831b.js"><link rel="prefetch" href="/assets/js/113.868c1ac9.js"><link rel="prefetch" href="/assets/js/114.090549d1.js"><link rel="prefetch" href="/assets/js/115.d97f6c2b.js"><link rel="prefetch" href="/assets/js/116.097c4b4e.js"><link rel="prefetch" href="/assets/js/117.4024cfe2.js"><link rel="prefetch" href="/assets/js/118.e3057cba.js"><link rel="prefetch" href="/assets/js/119.4ef1fa3b.js"><link rel="prefetch" href="/assets/js/12.863eaabe.js"><link rel="prefetch" href="/assets/js/120.78f9df50.js"><link rel="prefetch" href="/assets/js/121.8e16df87.js"><link rel="prefetch" href="/assets/js/122.f21c0107.js"><link rel="prefetch" href="/assets/js/123.ea1cb375.js"><link rel="prefetch" href="/assets/js/124.01c04c6e.js"><link rel="prefetch" href="/assets/js/125.d383e301.js"><link rel="prefetch" href="/assets/js/126.3162cb47.js"><link rel="prefetch" href="/assets/js/127.c6bebae6.js"><link rel="prefetch" href="/assets/js/128.d659db60.js"><link rel="prefetch" href="/assets/js/129.2afdcf48.js"><link rel="prefetch" href="/assets/js/13.4f59ce35.js"><link rel="prefetch" href="/assets/js/130.beb9ed9d.js"><link rel="prefetch" href="/assets/js/131.35b05f8a.js"><link rel="prefetch" href="/assets/js/132.d77f4f93.js"><link rel="prefetch" href="/assets/js/133.4ceda6e5.js"><link rel="prefetch" href="/assets/js/134.11390c5f.js"><link rel="prefetch" href="/assets/js/135.32f9e38f.js"><link rel="prefetch" href="/assets/js/136.6d8bb0f2.js"><link rel="prefetch" href="/assets/js/137.9c0ffeef.js"><link rel="prefetch" href="/assets/js/138.88d86e5f.js"><link rel="prefetch" href="/assets/js/139.8c2c3d6c.js"><link rel="prefetch" href="/assets/js/14.11c82d35.js"><link rel="prefetch" href="/assets/js/140.c5c375d3.js"><link rel="prefetch" href="/assets/js/141.d703f30b.js"><link rel="prefetch" href="/assets/js/142.6a005a44.js"><link rel="prefetch" href="/assets/js/143.9b2edf6f.js"><link rel="prefetch" href="/assets/js/144.3fd013c9.js"><link rel="prefetch" href="/assets/js/145.b05079c5.js"><link rel="prefetch" href="/assets/js/146.ed5360a6.js"><link rel="prefetch" href="/assets/js/147.7408d86f.js"><link rel="prefetch" href="/assets/js/148.f390b370.js"><link rel="prefetch" href="/assets/js/15.bd143bd5.js"><link rel="prefetch" href="/assets/js/150.f0ede764.js"><link rel="prefetch" href="/assets/js/151.b7093623.js"><link rel="prefetch" href="/assets/js/152.a82a6c83.js"><link rel="prefetch" href="/assets/js/153.965e3fb2.js"><link rel="prefetch" href="/assets/js/154.9e49311e.js"><link rel="prefetch" href="/assets/js/155.cef33ba5.js"><link rel="prefetch" href="/assets/js/156.bcc397ae.js"><link rel="prefetch" href="/assets/js/157.90824739.js"><link rel="prefetch" href="/assets/js/158.efd429b9.js"><link rel="prefetch" href="/assets/js/159.122ff5b7.js"><link rel="prefetch" href="/assets/js/16.2449162b.js"><link rel="prefetch" href="/assets/js/160.0b806535.js"><link rel="prefetch" href="/assets/js/161.835052c6.js"><link rel="prefetch" href="/assets/js/162.ca34e2d2.js"><link rel="prefetch" href="/assets/js/163.08000d04.js"><link rel="prefetch" href="/assets/js/164.a1cc0109.js"><link rel="prefetch" href="/assets/js/165.65444686.js"><link rel="prefetch" href="/assets/js/166.7d73c84f.js"><link rel="prefetch" href="/assets/js/167.009d47a3.js"><link rel="prefetch" href="/assets/js/168.0afeae2a.js"><link rel="prefetch" href="/assets/js/169.7654cb31.js"><link rel="prefetch" href="/assets/js/17.eb7f9def.js"><link rel="prefetch" href="/assets/js/170.58569530.js"><link rel="prefetch" href="/assets/js/171.7db9ed40.js"><link rel="prefetch" href="/assets/js/172.3cb50ed4.js"><link rel="prefetch" href="/assets/js/173.0846425f.js"><link rel="prefetch" href="/assets/js/174.9e95f111.js"><link rel="prefetch" href="/assets/js/175.ef2098f2.js"><link rel="prefetch" href="/assets/js/176.c2635fe9.js"><link rel="prefetch" href="/assets/js/177.4fa38e8e.js"><link rel="prefetch" href="/assets/js/178.2be7037f.js"><link rel="prefetch" href="/assets/js/179.bf3bba28.js"><link rel="prefetch" href="/assets/js/18.0455f4d1.js"><link rel="prefetch" href="/assets/js/180.72c5f597.js"><link rel="prefetch" href="/assets/js/181.42287bcc.js"><link rel="prefetch" href="/assets/js/182.6cd4bf1a.js"><link rel="prefetch" href="/assets/js/183.05dbbfd9.js"><link rel="prefetch" href="/assets/js/184.03de7e00.js"><link rel="prefetch" href="/assets/js/185.42dd210e.js"><link rel="prefetch" href="/assets/js/186.28ee0f8a.js"><link rel="prefetch" href="/assets/js/187.bb58697b.js"><link rel="prefetch" href="/assets/js/188.1bc8be96.js"><link rel="prefetch" href="/assets/js/189.fac747e3.js"><link rel="prefetch" href="/assets/js/19.ae9e35d6.js"><link rel="prefetch" href="/assets/js/190.ea533ac7.js"><link rel="prefetch" href="/assets/js/191.6dc6eb13.js"><link rel="prefetch" href="/assets/js/192.184d249f.js"><link rel="prefetch" href="/assets/js/193.4a06bc12.js"><link rel="prefetch" href="/assets/js/194.8cce60a9.js"><link rel="prefetch" href="/assets/js/195.93231a13.js"><link rel="prefetch" href="/assets/js/196.4a596bde.js"><link rel="prefetch" href="/assets/js/197.96c113cf.js"><link rel="prefetch" href="/assets/js/198.73ba3f67.js"><link rel="prefetch" href="/assets/js/199.74bab595.js"><link rel="prefetch" href="/assets/js/20.b542d0e7.js"><link rel="prefetch" href="/assets/js/200.69a6928a.js"><link rel="prefetch" href="/assets/js/201.9ffa7c5a.js"><link rel="prefetch" href="/assets/js/202.41edb652.js"><link rel="prefetch" href="/assets/js/203.7fabcef3.js"><link rel="prefetch" href="/assets/js/204.b0ae2f62.js"><link rel="prefetch" href="/assets/js/205.add8738b.js"><link rel="prefetch" href="/assets/js/206.f3a712ec.js"><link rel="prefetch" href="/assets/js/207.cd7dd729.js"><link rel="prefetch" href="/assets/js/208.78b33afa.js"><link rel="prefetch" href="/assets/js/209.9d3329ff.js"><link rel="prefetch" href="/assets/js/21.5a050318.js"><link rel="prefetch" href="/assets/js/210.d285d5ac.js"><link rel="prefetch" href="/assets/js/211.8791bb3f.js"><link rel="prefetch" href="/assets/js/212.84ed81a8.js"><link rel="prefetch" href="/assets/js/213.7b990580.js"><link rel="prefetch" href="/assets/js/214.da31f20c.js"><link rel="prefetch" href="/assets/js/215.9eeed659.js"><link rel="prefetch" href="/assets/js/216.9539f0ec.js"><link rel="prefetch" href="/assets/js/217.11b575be.js"><link rel="prefetch" href="/assets/js/218.a67f12f1.js"><link rel="prefetch" href="/assets/js/219.bfbb817a.js"><link rel="prefetch" href="/assets/js/22.2bc6f7e3.js"><link rel="prefetch" href="/assets/js/220.8b01342f.js"><link rel="prefetch" href="/assets/js/221.b450decd.js"><link rel="prefetch" href="/assets/js/222.97468507.js"><link rel="prefetch" href="/assets/js/223.b6dafd73.js"><link rel="prefetch" href="/assets/js/224.c86c18c6.js"><link rel="prefetch" href="/assets/js/225.b0dcf86e.js"><link rel="prefetch" href="/assets/js/226.02cc2999.js"><link rel="prefetch" href="/assets/js/227.8474ef5a.js"><link rel="prefetch" href="/assets/js/228.0298e421.js"><link rel="prefetch" href="/assets/js/229.6aeaf595.js"><link rel="prefetch" href="/assets/js/23.9995fce4.js"><link rel="prefetch" href="/assets/js/230.a5785286.js"><link rel="prefetch" href="/assets/js/231.d791daa4.js"><link rel="prefetch" href="/assets/js/232.97aeeb00.js"><link rel="prefetch" href="/assets/js/233.46e51e28.js"><link rel="prefetch" href="/assets/js/234.2cffe82f.js"><link rel="prefetch" href="/assets/js/235.14965da6.js"><link rel="prefetch" href="/assets/js/236.00a5afc0.js"><link rel="prefetch" href="/assets/js/237.3b73d52f.js"><link rel="prefetch" href="/assets/js/238.6e1db765.js"><link rel="prefetch" href="/assets/js/239.75866c5e.js"><link rel="prefetch" href="/assets/js/24.9141eeb2.js"><link rel="prefetch" href="/assets/js/240.af9c2cc9.js"><link rel="prefetch" href="/assets/js/241.388acab2.js"><link rel="prefetch" href="/assets/js/242.c60f2b48.js"><link rel="prefetch" href="/assets/js/243.d8e81b13.js"><link rel="prefetch" href="/assets/js/244.58b0b21d.js"><link rel="prefetch" href="/assets/js/245.c3768497.js"><link rel="prefetch" href="/assets/js/246.ac8bbe7a.js"><link rel="prefetch" href="/assets/js/247.d095f70a.js"><link rel="prefetch" href="/assets/js/248.e9f210b5.js"><link rel="prefetch" href="/assets/js/249.a9fad023.js"><link rel="prefetch" href="/assets/js/25.98e8593e.js"><link rel="prefetch" href="/assets/js/250.ae7f0ebb.js"><link rel="prefetch" href="/assets/js/251.9a617d55.js"><link rel="prefetch" href="/assets/js/252.ce082446.js"><link rel="prefetch" href="/assets/js/253.4575302d.js"><link rel="prefetch" href="/assets/js/254.5899a61b.js"><link rel="prefetch" href="/assets/js/255.66c69f31.js"><link rel="prefetch" href="/assets/js/256.8fd6c706.js"><link rel="prefetch" href="/assets/js/257.31b77e5e.js"><link rel="prefetch" href="/assets/js/258.eba48891.js"><link rel="prefetch" href="/assets/js/259.edf74b59.js"><link rel="prefetch" href="/assets/js/26.e69924ea.js"><link rel="prefetch" href="/assets/js/260.cf2ed36d.js"><link rel="prefetch" href="/assets/js/261.9e7792d8.js"><link rel="prefetch" href="/assets/js/262.e7b9433e.js"><link rel="prefetch" href="/assets/js/263.1185b25c.js"><link rel="prefetch" href="/assets/js/264.5e0f89cb.js"><link rel="prefetch" href="/assets/js/265.a38d3b94.js"><link rel="prefetch" href="/assets/js/266.2ef170b3.js"><link rel="prefetch" href="/assets/js/267.a7d14651.js"><link rel="prefetch" href="/assets/js/268.05b18748.js"><link rel="prefetch" href="/assets/js/269.dad48d6f.js"><link rel="prefetch" href="/assets/js/27.13612515.js"><link rel="prefetch" href="/assets/js/270.4f5a6b8d.js"><link rel="prefetch" href="/assets/js/271.7ebf6682.js"><link rel="prefetch" href="/assets/js/272.7c2fbfd1.js"><link rel="prefetch" href="/assets/js/273.8ee20732.js"><link rel="prefetch" href="/assets/js/274.d525242a.js"><link rel="prefetch" href="/assets/js/275.a8a19acb.js"><link rel="prefetch" href="/assets/js/276.df3a4eb4.js"><link rel="prefetch" href="/assets/js/277.336debda.js"><link rel="prefetch" href="/assets/js/278.c470625f.js"><link rel="prefetch" href="/assets/js/279.a91e1a64.js"><link rel="prefetch" href="/assets/js/28.ab7ae1df.js"><link rel="prefetch" href="/assets/js/280.87e25c9a.js"><link rel="prefetch" href="/assets/js/281.87c1ba25.js"><link rel="prefetch" href="/assets/js/282.dcd4dce0.js"><link rel="prefetch" href="/assets/js/283.abac2e00.js"><link rel="prefetch" href="/assets/js/284.f6079659.js"><link rel="prefetch" href="/assets/js/285.f1b39879.js"><link rel="prefetch" href="/assets/js/286.f6a79242.js"><link rel="prefetch" href="/assets/js/287.06bebe07.js"><link rel="prefetch" href="/assets/js/288.89e325df.js"><link rel="prefetch" href="/assets/js/289.3aa1bedd.js"><link rel="prefetch" href="/assets/js/29.ebe50f76.js"><link rel="prefetch" href="/assets/js/290.ee059c92.js"><link rel="prefetch" href="/assets/js/291.fa9a921a.js"><link rel="prefetch" href="/assets/js/292.2a8811cd.js"><link rel="prefetch" href="/assets/js/293.eec09cdf.js"><link rel="prefetch" href="/assets/js/294.dfac20dc.js"><link rel="prefetch" href="/assets/js/295.825d2070.js"><link rel="prefetch" href="/assets/js/296.f645861e.js"><link rel="prefetch" href="/assets/js/297.424fdb17.js"><link rel="prefetch" href="/assets/js/298.ebf87cdc.js"><link rel="prefetch" href="/assets/js/299.b8f19cbb.js"><link rel="prefetch" href="/assets/js/30.75237511.js"><link rel="prefetch" href="/assets/js/300.10fb6d4f.js"><link rel="prefetch" href="/assets/js/301.ef77c612.js"><link rel="prefetch" href="/assets/js/302.1b839763.js"><link rel="prefetch" href="/assets/js/303.609f7d98.js"><link rel="prefetch" href="/assets/js/304.1d255f19.js"><link rel="prefetch" href="/assets/js/305.b0234f2c.js"><link rel="prefetch" href="/assets/js/306.48677f64.js"><link rel="prefetch" href="/assets/js/307.14390d4b.js"><link rel="prefetch" href="/assets/js/308.fa730b28.js"><link rel="prefetch" href="/assets/js/309.0496b9e0.js"><link rel="prefetch" href="/assets/js/31.cf3f471a.js"><link rel="prefetch" href="/assets/js/310.a31676dc.js"><link rel="prefetch" href="/assets/js/311.ed53adc5.js"><link rel="prefetch" href="/assets/js/312.1b0ff2f1.js"><link rel="prefetch" href="/assets/js/313.bf123f32.js"><link rel="prefetch" href="/assets/js/314.4e6ce06b.js"><link rel="prefetch" href="/assets/js/315.8eb18560.js"><link rel="prefetch" href="/assets/js/32.74fef842.js"><link rel="prefetch" href="/assets/js/33.bc2d190b.js"><link rel="prefetch" href="/assets/js/34.d23438fc.js"><link rel="prefetch" href="/assets/js/35.7675c4d0.js"><link rel="prefetch" href="/assets/js/36.96a4161b.js"><link rel="prefetch" href="/assets/js/37.d1824f2f.js"><link rel="prefetch" href="/assets/js/38.4effff9e.js"><link rel="prefetch" href="/assets/js/39.6509914b.js"><link rel="prefetch" href="/assets/js/4.4d01750f.js"><link rel="prefetch" href="/assets/js/40.1509d08b.js"><link rel="prefetch" href="/assets/js/41.f2c1124f.js"><link rel="prefetch" href="/assets/js/42.e541d077.js"><link rel="prefetch" href="/assets/js/43.369de999.js"><link rel="prefetch" href="/assets/js/44.43959db0.js"><link rel="prefetch" href="/assets/js/45.282fbd31.js"><link rel="prefetch" href="/assets/js/46.1b83cfe9.js"><link rel="prefetch" href="/assets/js/47.c3a88e41.js"><link rel="prefetch" href="/assets/js/48.bc7c0a1b.js"><link rel="prefetch" href="/assets/js/49.92a4e5ba.js"><link rel="prefetch" href="/assets/js/5.c3991e24.js"><link rel="prefetch" href="/assets/js/50.9c488c6c.js"><link rel="prefetch" href="/assets/js/51.546ea632.js"><link rel="prefetch" href="/assets/js/52.0d2ccee1.js"><link rel="prefetch" href="/assets/js/53.6f52b5b1.js"><link rel="prefetch" href="/assets/js/54.c838b295.js"><link rel="prefetch" href="/assets/js/55.13af99ee.js"><link rel="prefetch" href="/assets/js/56.6be6d1ed.js"><link rel="prefetch" href="/assets/js/57.67c98b39.js"><link rel="prefetch" href="/assets/js/58.107e82ec.js"><link rel="prefetch" href="/assets/js/59.b3e5edc7.js"><link rel="prefetch" href="/assets/js/6.36a535f9.js"><link rel="prefetch" href="/assets/js/60.3b0b4ba5.js"><link rel="prefetch" href="/assets/js/61.3df843df.js"><link rel="prefetch" href="/assets/js/62.1213823d.js"><link rel="prefetch" href="/assets/js/63.e8f3f926.js"><link rel="prefetch" href="/assets/js/64.e1219050.js"><link rel="prefetch" href="/assets/js/65.5bf5bb0b.js"><link rel="prefetch" href="/assets/js/66.a2502afb.js"><link rel="prefetch" href="/assets/js/67.690dd59b.js"><link rel="prefetch" href="/assets/js/68.de7b0915.js"><link rel="prefetch" href="/assets/js/69.ac61dd61.js"><link rel="prefetch" href="/assets/js/7.5d254238.js"><link rel="prefetch" href="/assets/js/70.3edd41b1.js"><link rel="prefetch" href="/assets/js/71.d23407e9.js"><link rel="prefetch" href="/assets/js/72.a5bd01bc.js"><link rel="prefetch" href="/assets/js/73.c9f4dd57.js"><link rel="prefetch" href="/assets/js/74.66323fc1.js"><link rel="prefetch" href="/assets/js/75.e1a72e00.js"><link rel="prefetch" href="/assets/js/76.801268b4.js"><link rel="prefetch" href="/assets/js/77.3a5fda67.js"><link rel="prefetch" href="/assets/js/78.54d84cd4.js"><link rel="prefetch" href="/assets/js/79.fa10f4e3.js"><link rel="prefetch" href="/assets/js/8.e060e47d.js"><link rel="prefetch" href="/assets/js/80.d5b24fea.js"><link rel="prefetch" href="/assets/js/81.0e9da714.js"><link rel="prefetch" href="/assets/js/82.e96ff6d7.js"><link rel="prefetch" href="/assets/js/83.771cced1.js"><link rel="prefetch" href="/assets/js/84.220b69e7.js"><link rel="prefetch" href="/assets/js/85.7dcc5659.js"><link rel="prefetch" href="/assets/js/86.44ba2100.js"><link rel="prefetch" href="/assets/js/87.281da75d.js"><link rel="prefetch" href="/assets/js/88.12d88449.js"><link rel="prefetch" href="/assets/js/89.f28c86d3.js"><link rel="prefetch" href="/assets/js/9.8f9fef32.js"><link rel="prefetch" href="/assets/js/90.715cabb2.js"><link rel="prefetch" href="/assets/js/91.6ced7c82.js"><link rel="prefetch" href="/assets/js/92.c05b33ca.js"><link rel="prefetch" href="/assets/js/93.6bf5fb66.js"><link rel="prefetch" href="/assets/js/94.3561200e.js"><link rel="prefetch" href="/assets/js/95.0f2cf716.js"><link rel="prefetch" href="/assets/js/96.ac8487ea.js"><link rel="prefetch" href="/assets/js/97.48042b5a.js"><link rel="prefetch" href="/assets/js/98.441bb7f8.js"><link rel="prefetch" href="/assets/js/99.4b214d92.js">
    <link rel="stylesheet" href="/assets/css/0.styles.56073ad3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/magic.png" alt="Pangolin Note" class="logo"> <span class="site-name can-hide">Pangolin Note</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">🏡首页</a></div><div class="nav-item"><a href="/basic/" class="nav-link">基础</a></div><div class="nav-item"><a href="/develop/" class="nav-link">开发</a></div><div class="nav-item"><a href="/middleware/" class="nav-link">系统</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">算法</a></div><div class="nav-item"><a href="/books/" class="nav-link">🍀读书笔记</a></div><div class="nav-item"><a href="/work/" class="nav-link">工作</a></div><div class="nav-item"><a href="/pangolin/" class="nav-link">🌸达尔文的猹</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/avatarnew.png"> <div class="blogger-info"><h3>达尔文的猹</h3> <span>大道至简 悟在天成</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">🏡首页</a></div><div class="nav-item"><a href="/basic/" class="nav-link">基础</a></div><div class="nav-item"><a href="/develop/" class="nav-link">开发</a></div><div class="nav-item"><a href="/middleware/" class="nav-link">系统</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">算法</a></div><div class="nav-item"><a href="/books/" class="nav-link">🍀读书笔记</a></div><div class="nav-item"><a href="/work/" class="nav-link">工作</a></div><div class="nav-item"><a href="/pangolin/" class="nav-link">🌸达尔文的猹</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>系统</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading open"><span>分布式系统理论</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/129626/" class="sidebar-link">分布式系统基础</a></li><li><a href="/pages/fb5d35/" class="sidebar-link">分布式共识算法</a></li><li><a href="/pages/12ac37/" class="sidebar-link">分布式系统组件</a></li><li><a href="/pages/d03ebf/" class="sidebar-link">分布式技术原理与算法解析(极客时间)🌸</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>系统接入层</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/f1b6c4/" class="sidebar-link">Nginx基础</a></li><li><a href="/pages/d4123d/" class="sidebar-link">深入拆解Tomcat与Jetty(极客时间)🌸</a></li><li><a href="/pages/baee2f/" class="sidebar-link">Netty</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>服务治理-注册发现与RPC</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/05077d/" class="sidebar-link">基础</a></li><li><a href="/pages/51b6aa/" class="sidebar-link">RPC实战与核心原理(极客时间)🌸</a></li><li><a href="/pages/0966ee/" class="sidebar-link">Zookeeper</a></li><li><a href="/pages/3b7e05/" class="sidebar-link">Nacos</a></li><li><a href="/pages/7f31f8/" class="sidebar-link">Dubbo</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>服务治理-流量控制</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/44bfa8/" class="sidebar-link">负载均衡</a></li><li><a href="/pages/4d5a6c/" class="sidebar-link">限流</a></li><li><a href="/pages/e0c561/" class="sidebar-link">熔断</a></li><li><a href="/pages/12ae40/" class="sidebar-link">网关路由</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>服务治理-系统监控与安全</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/8c9210/" class="sidebar-link">系统安全性</a></li><li><a href="/pages/c9bf40/" class="sidebar-link">系统监控组件</a></li><li><a href="/pages/3f3cf7/" class="sidebar-link">运维监控系统实战(极客时间)🌸</a></li><li><a href="/pages/e20e02/" class="sidebar-link">OAuth2.0实战课(极客时间)🌟</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-消息队列</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/96d94c/" class="sidebar-link">消息队列基础</a></li><li><a href="/pages/abf16c/" class="sidebar-link">RabbitMQ</a></li><li><a href="/pages/4fc3f1/" class="sidebar-link">Kafka</a></li><li><a href="/pages/013cfe/" class="sidebar-link">RocketMQ</a></li><li><a href="/pages/ed8d92/" class="sidebar-link">Disruptor</a></li><li><a href="/pages/249149/" class="sidebar-link">消息队列高手课(极客时间)🌟</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-缓存</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/946847/" class="sidebar-link">缓存基础</a></li><li><a href="/pages/e46d56/" class="sidebar-link">本地缓存</a></li><li><a href="/pages/0abfb9/" class="sidebar-link">Redis基础</a></li><li><a href="/pages/09236a/" class="sidebar-link">Redis持久化</a></li><li><a href="/pages/867f9b/" class="sidebar-link">Redis主从复制</a></li><li><a href="/pages/50cae1/" class="sidebar-link">Redis哨兵</a></li><li><a href="/pages/43b45c/" class="sidebar-link">Redis集群</a></li><li><a href="/pages/a32379/" class="sidebar-link">Redis内存管理与运维</a></li><li><a href="/pages/386037/" class="sidebar-link">Redis核心技术与实战(极客时间)🌸</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>中间件-其他</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/23044d/" class="sidebar-link">定时任务-XXLJob</a></li><li><a href="/pages/459117/" class="sidebar-link">ES与检索</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>系统设计与优化</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/41a845/" class="sidebar-link">凤凰架构</a></li><li><a href="/pages/68cc0b/" class="sidebar-link">左耳听风(极客时间)🌟</a></li><li><a href="/pages/e3e99c/" class="sidebar-link">从0开始学微服务(极客时间)🌸</a></li><li><a href="/pages/1e5368/" class="sidebar-link">高并发系统设计40问(极客时间)🌸</a></li><li><a href="/pages/33599f/" class="sidebar-link">系统性能调优必知必会(极客时间)🌸</a></li><li><a href="/pages/c83472/" class="sidebar-link">后端技术面试38讲(极客时间)</a></li><li><a href="/pages/4404b6/" class="sidebar-link">架构实战案例解析(极客时间)🌸</a></li><li><a href="/pages/8f1c1d/" class="sidebar-link">如何设计一个秒杀系统(极客时间)</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>容器</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading open"><span>容器</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/582acf/" class="sidebar-link">部署Minikube</a></li><li><a href="/pages/98e5e4/" class="sidebar-link">容器实战高手课(极客时间)🌸</a></li><li><a href="/pages/c6a42c/" class="sidebar-link">Kubernetes实战🌸</a></li><li><a href="/pages/f35c72/" class="sidebar-link">深入剖析Kubernetes(极客时间)🌸</a></li><li><a href="/pages/caa314/" class="sidebar-link">Istio</a></li></ul></section></li><li><section class="sidebar-group is-sub-group depth-1"><p class="sidebar-heading"><span>自动化运维</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/beb97f/" class="sidebar-link">持续集成(CICD)</a></li><li><a href="/pages/a0df2d/" class="sidebar-link">DevOps</a></li><li><a href="/pages/765815/" class="sidebar-link">SRE实战手册(极客时间)</a></li></ul></section></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06970110><div class="articleInfo" data-v-06970110><ul class="breadcrumbs" data-v-06970110><li data-v-06970110><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06970110></a></li> <li data-v-06970110><a href="/middleware/#系统" data-v-06970110>系统</a></li><li data-v-06970110><a href="/middleware/#系统" data-v-06970110>系统</a></li><li data-v-06970110><a href="/middleware/#中间件-消息队列" data-v-06970110>中间件-消息队列</a></li></ul> <div class="info" data-v-06970110><div title="作者" class="author iconfont icon-touxiang" data-v-06970110><a href="https://github.com/nanodaemony" target="_blank" title="作者" class="beLink" data-v-06970110>NanoDaemony</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06970110><a href="javascript:;" data-v-06970110>2025-02-26</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">本文目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">20-深入拆解消息队列(极客时间)<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="_20-深入拆解消息队列-极客时间"><a href="#_20-深入拆解消息队列-极客时间" class="header-anchor">#</a> 20-深入拆解消息队列(极客时间)</h1> <blockquote><p>这个真的牛.</p> <p>适合反复阅读.</p> <p>评分: 4.7分</p></blockquote> <h3 id="预习篇"><a href="#预习篇" class="header-anchor">#</a> 预习篇</h3> <h4 id="开篇词-深度拆解核心原理-轻松掌握所有消息队列"><a href="#开篇词-深度拆解核心原理-轻松掌握所有消息队列" class="header-anchor">#</a> 开篇词-深度拆解核心原理,轻松掌握所有消息队列</h4> <p>你好, 我是文强. 一名在消息队列领域一线摸爬滚打很多年的开发者, 很高兴在这里遇见你!</p> <p>跟大多数人一样, 在职业生涯前期, 我是一个纯粹的消息队列使用者, 在日常开发过程中大量使用 Kafka 和 RabbitMQ. 后来我到了腾讯云消息队列的团队, 主要负责多款消息队列产品的商业化, 内核优化, 架构升级, 运维运营体系建设, 成本优化, 大规模集群稳定性等工作. 这段经历让我对消息队列这个领域有了非常深刻的理解, 同时也打磨了我的技术能力和解决问题的能力, 积累了大量的实战经验.</p> <p>从而我也理解作为消息队列的使用者, 研发人员, 运维人员, 架构师, 他们希望获得什么, 解决什么问题.</p> <p>作为使用者, 会希望针对业务场景来更好地完成技术选型, 从而选出符合业务需求, 系统架构的最优组件. 我们一般会从功能特性, 性能, 稳定性出发, 查阅资料, 横向对比多款消息队列, 从而做出选择.</p> <p>作为研发人员, 我们希望了解消息队列的底层原理, 设计思考, 实现方案, 从而来提升我们自己的技术能力, 技术视野, 提升竞争力.</p> <p>作为运维人员, 我们希望能够理解用到的消息队列的系统架构, 设计原理等, 从而判断这款产品是否足够稳定, 是否有隐藏的风险, 长期的运维成本是否合理, 监控体系是否完善等等. 从而评估系统的风险点, 以及时规避.</p> <p>作为架构师, 我们希望自己有足够的技术视野, 能够了解到每款消息队列的功能清单, 系统架构的优劣势, 潜在的风险, 成本结构, 社区活跃度等等信息. 让我们在设计架构的过程中可以有足够的理论依据辅助我们做出合理的决策.</p> <p>但不管什么角色, 都会遇到一个关键问题, 那就是:  <strong>消息队列那么多, 看起来那么复杂, 我们是否做出了最优选择</strong>?</p> <p>而要解决这个问题, 是不是要把业界那么多的主流消息队列都学一遍, 从原理到源码, 这样的成本会不会太高了呢? 答案是不用, 有更简单的方法能达成这个目的.</p> <h5 id="消息队列那么多-我该怎么学习"><a href="#消息队列那么多-我该怎么学习" class="header-anchor">#</a> 消息队列那么多, 我该怎么学习?</h5> <p>我们知道, 中间件作为三大基础软件之一, 消息队列是其中重要的组成部分.</p> <p>早年业界消息队列演进的主要推动力在于功能(如延迟消息, 事务消息, 顺序消息等), 场景(实时场景, 大数据场景等), 分布式集群的支持等等. 近几年, 随着云原生架构和 Serverless 的普及, 业界 MQ 主要向实时消息和流消息的融合架构, Serverless, Event, 协议兼容等方面演进. 从而实现计算, 存储的弹性, 实现集群的 Serverless 化.</p> <p>从架构设计角度来看, 消息队列在设计思想上基本是一致的, 在架构演进过程中存在相互借鉴. 这也给我们学习消息队列提供了一个便捷的路径, 即只要我们 <strong>从需求出发, 理解设计原理, 主流技术方案, 方案之间的优劣, 选型过程主要的思考点</strong>, 那么我们再往下学习具体某一款消息队列就会变得非常简单.</p> <p>举个简单的例子, 我们在选型时经常会问, 哪款消息队列性能最高?</p> <p>此时如果我们知道了通信协议, 网络模型, 存储结构, 生产消费原理, 集群部署, 分片副本等因素是跟性能密切相关的, 如果我们还进一步知道了哪种网络模型性能最高, 哪种存储结构在哪种场景下性能最高, 然后你再结合具体某个消息队列的实现机制, 回答这个问题就非常简单了.</p> <p>那我们具体该怎么做呢? 掌握的关键是什么?</p> <h5 id="掌握消息队列的关键路径是什么"><a href="#掌握消息队列的关键路径是什么" class="header-anchor">#</a> 掌握消息队列的关键路径是什么?</h5> <p>在我看来, 掌握的核心关键点是成<strong>体系, 系统, 全面的知识结构</strong>. 只要掌握了核心和顶层设计原理, 不管有多少消息队列都能轻松驾驭.</p> <p>以最近消息队列领域最火的 Apache Pulsar 举例. 从它的设计思想中会看到 Kafka, RocketMQ, RabbitMQ 的影子. 从架构的角度, Pulsar Broker 和 Kafka 的设计几乎是一模一样的. 所以只要<strong>理解了 Kakfa, RocketMQ, RabbitMQ, 再来理解 Pulsar, 就是事半功倍的</strong>.</p> <p>另外, 为了深入理解某款消息队列, 我们经常会去研究源码. 不过这又会碰到一个老大难问题, 源码太多, 甚至看不懂. 其实<strong>源码能不能看懂是依赖于对原理的理解程度, 而原理又依赖于体系化学习和梳理</strong>, 简单来说就是 &quot;知其然才知所以然&quot;. 总之会绕回来.</p> <p>那么在源码学习上, 其实是可以变被动为主动的. 这里非常建议掌握了原理后尝试去开源社区成为 Contributer, 贡献代码, 文档等等, 我自己是参与了 Apache Kakfa, Apache RocketMQ, Apache Pulsar 社区的一些工作, 对我的帮助很大.</p> <p>这时你还会收获一个惊喜! 因为在实际的软件开发中, 消息队列作为基础软件, 它可以串联起分布式系统设计, 网络编程, 操作系统, 存储原理, 计算机硬件, 数据结构, 数据一致性等等多个技术点. 在学习的过程中, 会不知不觉地复习, 串联起这些知识点. 这不仅会让你对消息队列的使用更加得心应手, 还会让你在日常面试中有不错的表现.</p> <h5 id="这门课能为你带来什么"><a href="#这门课能为你带来什么" class="header-anchor">#</a> 这门课能为你带来什么?</h5> <p>我会带你深入拆解消息队列的各个模块的<strong>主流技术方案, 选型思考, 技术实现</strong>, 从而让你对消息队列的技术架构设计有一个清晰, 整体, 全面的认识.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9df4c7bfcdcfe2b0d7281205ccef1060-20240421231949-xv34oq5.jpg" alt="">​</p> <p>这门课设置了六个模块, 分为预习篇, 基础篇, 进阶篇, 功能篇, 架构升级篇, 经验总结篇.</p> <p><strong>预习篇:</strong>  我将结合自己的实践经历, 带你了解主流 MQ 的发展脉络, 从中明确未来发展方向, 并就后续课程频繁提及的基础概念做一个对齐.</p> <p><strong>基础篇:</strong>  从功能上来看一个最基础的消息队列应该具备生产, 存储, 消费的能力. 将从通信协议, 网络模块, 存储模块, 生产者, 消费者五个部分, 来分析一个最基础的消息队列应该考虑什么, 如何选型以及如何设计实现. 最后会围绕着这五个部分分析 4 款主流消息队列的设计实现.</p> <p><strong>进阶篇:</strong>  将在最基础的消息队列之上, 从集群瓶颈和可靠性风险分析, 如何构建集群, 如何确保数据一致性, 集群的安全控制, 集群的可观测性, 编码技巧, 集群优化等七个方面, 来分析实现一个分布式的消息队列集群应该考虑什么, 要怎么做, 有哪些方案可以选择以及各种方案的优劣. 最后还是会围绕着这七个方面分析 4 款主流消息队列的设计实现.</p> <p><strong>功能篇:</strong>  在集群化的消息队列的基础上, 将探讨在集群上如何实现顺序消息, 幂等消息, 延时消息, 事务消息, 死信队列, 优先级队列, 消息查询, 支持 Schema, 支持 WebSocket 等功能. 将详细分析实现这些功能要考虑什么, 如何做方案设计, 技术选型, 以及最后是怎样实现这些功能的.</p> <p><strong>架构升级篇:</strong>  在前面四个模块, 已经实现了一个集群化, 功能丰富的消息队列. 接下来将探讨在云原生架构演进, 降本增效诉求增大, Serverless/Event 概念兴起等背景下, 消息队列是如何跟进业界最新设计理念, 做架构升级以满足系统弹性和降本诉求的. 将从存算分离架构, 分层存储, Severless/Event 架构, 集群容灾, 数据连接, 消息中台等六个方面来展开讲解技术上如何实现, 如何考虑, 能达到什么效果, 有哪些风险, 能满足哪些场景等等.</p> <p><strong>经验总结篇:</strong>  这个模块比较特别, 是基于我自己多年的观察所产出的分享.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c63a563953e2966406e68c55d9f883db-20240421231949-gzj4bdf.jpg" alt=""></p> <h5 id="做最好的自己"><a href="#做最好的自己" class="header-anchor">#</a> 做最好的自己</h5> <p>消息队列是一个复杂的基础软件, 但我希望从庖丁解牛的角度出发, 跟你一起从设计一个最简单的消息队列开始, 将其扩展为一个集群, 再往集群添加各种功能, 最后会结合云原生, Serverless 的架构理念, 对架构做一个全面升级.</p> <p><strong>知识最怕孤岛, 无法串联就容易忘记.</strong>  在学习期间, 你还会发现我们几乎会用到计算机领域的所有基础知识点, 包括但不限于分布式, 操作系统, 网络, 存储等等. 所以这门课程并不只是一门消息队列的原理课, 也可以是一门分布式系统的原理课. 不仅能在工作中帮到你, 也能在面试中帮到你.</p> <h4 id="_01-业界的主流消息队列是如何发展起来的"><a href="#_01-业界的主流消息队列是如何发展起来的" class="header-anchor">#</a> 01-业界的主流消息队列是如何发展起来的?</h4> <p>作为一个消息队列的老兵, 我经常被团队的新同学或者客户的研发人员问: 我希望在业务中引入消息队列, 应该选择哪一款合适? 是不是用最近很火的 Pulsar 就好了, 但是业务团队推荐用 RocketMQ 或 RabbitMQ, 而大数据团队推荐用 Kafka, 有没有什么选择的标准可以参考呢?</p> <p>这个问题你之前一定疑惑过, 可能也有了一套自己的选择标准, 不过遇到这种情况, 我都会先反问: 你觉得消息队列是做什么的?</p> <p>自从负责消息队列云服务之后, 我接触了很多客户, 发现基本 90% 以上的用户(大概率你也在其中), 业务的数据量都不大, 场景也不复杂. 只用到了消息队列最基本的生产和消费功能, 把消息队列当做缓冲分发的管道, 基本不会用到消息队列的高级功能, 比如死信队列, 事务消息, 延时消息等等.</p> <p>所以, 很多情况下不需要很复杂的消息队列, 有些时候甚至都不需要引入业界标准的消息队列产品. 是不是和你之前的想法不太一致? 今天就从这个有点反常识的观点开始讨论.</p> <h5 id="你真的需要标准消息队列吗"><a href="#你真的需要标准消息队列吗" class="header-anchor">#</a> 你真的需要标准消息队列吗?</h5> <p>我第一次用消息队列是在我负责游戏论坛开发的时候, 有一个功能是需要把用户对帖子的评论和点赞数据发给下游分析. 可以想一下, 如果你接到这个需求会怎么做呢?</p> <p>我的第一个想法就是在流程里面加一个函数, 封装一下, 再把数据通过 HTTP API 发送给下游, 就完成了.</p> <p>不过我上级选择了另外一套方案, 引入 Kafka, 在<strong>主流程里面先把数据发送到 Kafka, 再让下游去消费数据</strong>.</p> <p>Apache Kafka 是 LinkedIn 在 2011 年贡献给了 Apache 软件基金会的分布式消息队列. 主要满足<strong>大数据领域中的高吞吐量, 低延迟场景. 核心功能较为简单, 只提供生产和消费, 后来加了幂等和事务. 采用通用分布式架构实现发布-订阅模型, 能高效地处理海量数据</strong>.</p> <p>当时我不太理解加 Kafka 的意义是什么. 因为我们的需求非常简单, 只涉及生产和消费两个动作, 而且现网一直在用 Redis. 当时我认为使用 Redis 的 List 实现 Push/Pop 就可以满足需求, 效果是一样的, 还省去 Kafka 的维护和学习成本. 进一步, 如果担心 Redis 的数据没做持久化丢失了, 也可以通过 MySQL 的表, 把数据 insert 进去, 下游去 select 出来, 也能实现 Push/Pop 的效果.</p> <p><strong>那为什么还是用 Kafka 呢?</strong></p> <p>当时有个业务背景: 用户的回复会包含图片和表情等复杂结构数据, 导致内容可能会特别长. 另外遇到高峰时, 回帖数量会特别多, 短时间内可能有几千万的回帖, 回帖的总内容很大.</p> <p>Redis 的问题在于数据都存在内存里, 如果数据没有及时消费, 就会打爆内存. 而且因为回帖内容可能很大, 在 Redis 的 Value 里存大的数据会有性能和稳定性问题. 而 MySQL 在 insert 上是有性能瓶颈的, 短时间内大量回帖, 插入会特别频繁, 性能就扛不住. 而 Kafka 就没有这个问题, 作为一个消息队列, 它的特点就是高吞吐, 大消息, 高并发, 持久化, 不会存在性能, 功能, 稳定性方面的问题. 这就是选择 Kafka 的理由.</p> <p>其实如果没有大消息和大流量等复杂场景, 是可以选用非标准消息队列产品的. 比如在用户状态审核的场景中, 只需要向下游传递用户 ID 和审核结果, 结构简单, 数量有限. 这时候选择非标准消息队列比如 Redis 和 MySQL 也是可以的.</p> <p><strong>所以, 是否选择使用标准消息队列产品, 取决于数据和业务场景的需求</strong>. 当数据量大, 场景复杂后, 才必须引入标准消息队列, 因为它有高吞吐, 持久化, 长久堆积的特性.</p> <p>既然用非标准消息队列也可以满足相应需求, 那到底什么是消息队列呢?</p> <p>从宏观上来讲, 我会认为具有<strong>缓冲作用, 具备类发布和订阅能力的存储引擎都可以称做消息队列</strong>. 因为消息队列的最基本功能就是生产和消费, 在发布订阅之上, 扩展如死信队列, 顺序消息, 延时消息等高阶能力, 并实现高吞吐, 低延时, 高可靠等特性, 就成为了功能齐全的标准消息队列.</p> <p>现在业界都有哪些标准的消息队列呢? 一起来梳理下.</p> <h5 id="业界都有哪些消息队列"><a href="#业界都有哪些消息队列" class="header-anchor">#</a> 业界都有哪些消息队列?</h5> <p>还是跟随我的时间线来看. 后来我负责的广告业务用到了另一款消息队列 RabbitMQ, 当时我最直观的感觉就是: 它功能比 Kafka 多好多, 支持延时消息, 死信队列, 优先级队列, 事务消息等等, 业务上也是因为要用到这些功能才选择的 RabbitMQ.</p> <p>RabbitMQ 是用 Erlang 写成的消息队列. 主要满足业务中<strong>消息总线</strong>的场景. 特点是功能丰富, 低流量下稳定性较高, 基本具备消息队列所应该具备的所有功能. 缺点是在大流量的情况下会有明显的瓶颈和稳定性风险.</p> <p>当时开源的消息队列并不丰富. 基于 JMS 协议发展出来的 ActiveMQ 因为功能和稳定性问题, 用的人比较少. Kafka 刚开源不久, 功能只有生产和消费. AMQP 协议的 Erlang 实现 RabbitMQ, 因为功能丰富, 稳定性较高, 成为主流选择. ActiveMQ 项目最初是由 LogicBlaze 的创始人于 2004 年创建的, 支持完成 JMS 规范的消息队列. 因为生态, 功能定位方面的原因, 在国内用的人并不多.</p> <p><strong>AMQP 是一个消息队列协议规范, 它不是一款具体的消息队列</strong>. 因为不同消息队列的访问协议是不一样的, 导致不同的消息队列需要用不同的 SDK 访问, 客户的切换成本很高. 2003 年, 多个金融服务机构希望制定一个消息队列的协议规范, 希望不同的消息队列的协议都根据这个标准实现, 这样就可以不需要重复开发 SDK, 不同的应用程序之间的交互和切换可以更简单, 更方便. 这就是 AMQP 的由来.</p> <p>后来开源社区逐渐完善, 阿里的 RocketMQ 在 2017 年从 Apache 基金会毕业, Pulsar 也在 2018 成为了 Apache 的顶级项目, 开源社区生态逐渐繁荣, 选择慢慢变多.</p> <p>RocketMQ 是 2013 年阿里研发, 2016 年开源, 可满足大规模微服务场景的消息队列产品. 可以理解为是 RabbitMQ 的高可用, 分布式升级版. 功能丰富, 基本可以满足业务消息场景下的所有需求. 稳定性, 数据可靠性方面的表现都较好. 性能介于 RabbitMQ 和 Kafka 之间.</p> <p><strong>RocketMQ 在定位上和 RabbitMQ 很像, 功能丰富, 在业务消息中经常会用到</strong>. 不过 RocketMQ 是在移动互联网浪潮下发展起来的, 业务场景更加复杂, 也支持更多功能, 比如消息 Tag, 消息轨迹, 消息查询等等.</p> <p>除了功能层面, 在架构和性能层面, RabbitMQ 开发设计早, 当时分布式的设计理念还不成熟, 导致它在架构层面的设计存在较大的缺陷, 遇到大流量, 高并发的时候, 容易出现集群不可用, 网络分区等情况无法解决. 而 RocketMQ 在分布式架构上实现得更合理优雅, 在大流量, 高并发的场景下表现优秀稳定.</p> <p>Pulsar 2017 年由 Yahoo 开发的消息队列系统. 一开始定位是<strong>流计算领域</strong>, 可以<strong>理解为 Kafka 的升级版</strong>, 近期希望同时发展消息和流两个方向. 其架构上的设计理念较为优秀, 比如计算存储分离, 弹性, 多租户. 在功能上目前正在追赶 RabbitMQ/RocketMQ. 性能层面, 和 Kafka 没有明显的差异. 但当前阶段的稳定性还需要提升.</p> <p><strong>Pulsar 和 Kafka 很像, 主要定位在流领域, 主打大吞吐的流式计算</strong>. 但 Kafka 的功能比较简单, 支持基本的发布订阅, 幂等, 事务消息. Pulsar 在满足这些功能的基础上, 也希望支持 RocketMQ 和 RabbitMQ 的功能, 所以功能最丰富.</p> <p>除了功能层面, 在架构和性能层面上, <strong>Pulsar 的架构设计比 Kafka 更符合当前云原生架构, 它的定位是 Kafka 的升级版, 主要解决 Kafka 当前的一些痛点问题, 比如集群扩缩容慢, 分区迁移需要 Rebalance, 无法支持超多分区等. 性能目前没有特别大的差距</strong>. 不过 Pulsar 发展时间较短, 架构较复杂, 功能支持较多, 当前阶段在稳定性上 Kafka 会比 Pulsar 好非常多.</p> <p>这里总结一下, 当前开源社区用的较多的消息队列主要有 <strong>RabbitMQ, Kafka, RocketMQ 和 Pulsar 四款</strong>. 下面整理了一张消息队列发展的时间脉络图, 供你参考.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2a40cdcf45f4a1ffea4ca87dc67c0f50-20240421231949-4rh8yjp.jpg" alt=""></p> <p>在开源社区发展的这段时间, 国内大厂也一直在自研消息队列, 比如阿里的 RocketMQ, 腾讯的 CMQ 和 TubeMQ, 京东的 JMQ, 字节的 BMQ. 只是发展程度不一样, 有的开源了成为顶级项目, 有的慢慢消亡了, 有的仅限在公司内部使用.</p> <p>虽然有这么多的消息队列, 但它们<strong>发展的方向其实是一致的</strong>.</p> <h5 id="消息队列的发展脉络"><a href="#消息队列的发展脉络" class="header-anchor">#</a> 消息队列的发展脉络</h5> <p>结合我的个人经历, 可以从消息队列的历史中抽象出两条交织的发展脉络: 上层的需求变化和下层的架构演进.</p> <ul><li>从需求发展路径上看, 消息队列的发展趋势是: <strong>消息 -&gt; 流 -&gt;</strong>  ​<strong>消息和流融合</strong>.</li> <li>从架构发展的角度来看, 消息队列的发展趋势是: <strong>单机 -&gt; 分布式 -&gt;</strong> <strong>云原生/Serverless</strong>.</li></ul> <p>在 90 年代到 21 世纪初, 以 IBM MQ 和 AMQP 为代表的消息队列主要满足业务上对消息的需求, 即异步通讯, 架构解耦. 2010 年左右, 移动互联网发展, 大数据兴起, 传统的消息队列在架构上无法满足大流量的吞吐需求, 就发展出了以 Kafka 为代表的消息队列, 主打<strong>大吞吐, 大流量</strong>. 后面进入了分布式的时代, 现在大家熟知的消息队列都是分布式的架构, 所以会有分区, 副本, 一致性概念.</p> <p>随着业务场景越来越复杂, 业务消息的数据量也越来越大. 基于开源 AMQP 的 RabbitMQ 在<strong>性能和架构</strong>上已经无法满足消息场景的需求, 从而发展出了 RocketMQ.</p> <p>近几年随着云计算的发展, 云原生和 Serverless 的理念兴起, 在弹性, 成本的驱动下, 消息队列的架构往<strong>云原生/Serverless</strong> 方向演变, 简单来说就是利用云上的弹性计算, 存储等基础设施去实现架构的 Serverless, 按需使用, 按量付费, 最终达到使用端感受到的免运维, 低成本.</p> <p>基于云原生架构设计的 Pulsar 开始走向成熟, 业界的 MQ 也出现了 <strong>计算存储分离, 分层存储, 多租户, 弹性计算等概念</strong>.</p> <p>云原生/Serverless 的发展趋势, 你应该听得比较多了, &quot;消息和流融合&quot; 的趋势可能有些陌生, 下面稍微解释一下.</p> <h5 id="什么是消息和流"><a href="#什么是消息和流" class="header-anchor">#</a> 什么是消息和流?</h5> <p>消息, 流分开来看都比较好理解.</p> <ul><li><strong>消息就是业务消息</strong>, 在业务架构(比如微服务架构)中用来作消息传递, 做系统的消息总线, 比如用户提交订单的流程.</li> <li><strong>流, 就是在大数据架构中用来做大流量时的数据削峰</strong>, 比如日志的投递流转.</li></ul> <p><mark><strong>消息和流融合就是这两个事情都能做. 不过为什么会有消息和流融合的这个趋势呢</strong></mark>?</p> <p>其实都是钱的原因. 虽然消息队列是基础组件, 但是功能比较单一, 主要是缓冲作用, 在消息, 流的方向上, 功能需求一直是相对固定的, 细分的市场也都有领头组件, 流领域目前是 Kafka 一家独大, 消息领域的头部玩家, 国外是 RabbitMQ, 国内是 RocketMQ.</p> <p>对 MQ 厂商来说, 如果希望扩大产品份额或者新品抢占市场, 就需要有<strong>独特竞争力, 核心就是自己产品的功能和成本</strong>, 即功能更多更丰富, 成本更低. 这里的成本指的是能为客户, 也就是消息队列使用者, 节省多少资源, 人力成本.</p> <p>因为对使用者来说, 业务和大数据都不陌生, 日常工作都需要进行业务和数据系统的开发. 但是麻烦的问题是: 在业务消息中, 经常需要使用 RocketMQ 或 RabbitMQ, 在大数据系统中又需要使用 Kafka 或 Pulsar.</p> <p>所以, <strong>运维侧需要运维多款 MQ, 研发侧需要学习使用多款 MQ</strong>, 这在一定程度上拉升了研发和运维的成本. 如果<mark><strong>有一款消息队列满足所有场景, 只需要部署一款消息队列, 就能满足所有业务的需求, 这种设计思想是非常有商业价值的</strong></mark>.</p> <p>现在也可以看到业界主流的 4 款消息队列, 在<mark><strong>消息和流的融合</strong></mark>上各有动作.</p> <ul><li>RabbitMQ 因为开发语言, 架构和社区的活跃度, 定位的原因, 基本不会走这条路.</li> <li>Kafka 虽然也强调云原生, 但目前主要工作在自身的架构优化上, 比如去 ZooKeeper, 暂时在消息方向没有提出明确概念. 但在我看来, 未来 Kafka 应该会往这个方向转变, 因为流的场景始终会有瓶颈, 打通一个新方向在商业上肯定是有价值的.</li> <li>RocketMQ 在消息领域已经非常成熟, 社区也希望打通流的场景, 扩展使用范围, 提升竞争力, 抢占市场, 也在往这个方向努力.</li> <li>Pulsar 是一个<strong>新兴架构</strong>, 没有历史包袱, 主打的就是云原生的消息和流的融合架构, 希望满足更多场景, 解决更多业务需求.</li></ul> <h5 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h5> <p>现在应该能解答开头提出的问题了, 广义上讲, 消息队列是有缓冲作用, 具备类发布和订阅能力的存储引擎.</p> <p>技术方案如何选择消息队列, 来源于业务场景和数据量. 如果只需要最基本的生产和消费功能, 可以不用标准消息队列产品, 大部分公司或业务的场景下, 一款消息队列就能满足所有需求了.</p> <p>技术的演进都是商业驱动的, 消息队列的演进, 无论是从需求发展路径上看是<strong>消息 -&gt; 流 -&gt; 消息和流融合</strong>, 还是从架构发展角度的<strong>单机 -&gt; 分布式 -&gt; 云原生/Serverless</strong>, <mark><strong>本质其实都是在思考如何降低成本和吸引客户</strong></mark>.</p> <p>为了降低成本, 弹性是最基础的要求. 所以消息队列在技术上, 对计算弹性的需求提出了计算存储分离架构, 对低存储成本的需求提出了分层存储的概念, 对资源复用的需求提出了多租户的概念. 为了吸引客户, 各个消息队列都在尽量提高自己的竞争力, 围绕着功能, 容灾, 多架构, 生态建设展开.</p> <p>不过要注意, 消息和流只是业界的趋势, 不是作为使用者必然的非此即彼的选择. 在开发者实际使用的时候, 我也发现很多人会将 Kafka 当做一个业务消息总线在用, 也有人使用 RocketMQ 传递大流量的日志, 当做大数据架构中的管道在用.</p> <h4 id="_02-消息队列在架构和功能层面都包含哪些概念"><a href="#_02-消息队列在架构和功能层面都包含哪些概念" class="header-anchor">#</a> 02-消息队列在架构和功能层面都包含哪些概念?</h4> <p>这节课来了解一下消息队列在架构和功能层面的基本概念, 也是想有针对性地对齐一些通用基础概念, 同时让你对消息队列有一个整体认识, 从而让后面的学习过程更加顺利.</p> <h5 id="什么时候会用到消息队列"><a href="#什么时候会用到消息队列" class="header-anchor">#</a> 什么时候会用到消息队列?</h5> <p>首先从使用者的角度, 来聊聊什么情况下会用到消息队列.</p> <p>在系统架构中, 消息队列的定位就是 <strong>总线和管道</strong>, 主要起到解耦上下游系统, 数据缓存的作用. 它不像数据库, 会有很多计算, 聚合, 查询的逻辑, 它的主要操作就是 <strong>生产和消费</strong>. 所以在业务中不管是使用哪款消息队列, 核心操作永远是<strong>生产和消费数据</strong>.</p> <p>一般情况下, 会在<mark><strong>需要解耦上下游系统, 对数据有缓冲缓存需求或者需要用到消息队列的某些功能(比如延时消息, 优先级消息)的时候选择使用消息队列, 然后再根据实际需求选型</strong></mark>.</p> <p>下面就用经典的订单下单流程, 来简要概括下对消息队列的使用情况.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2cb1c8245c15f3df28228af3c8b8bd8c-20240421231949-170p1tc.jpg" alt="">​</p> <p>下单流程是一个典型的 <strong>系统解耦, 消息分发</strong> 的场景, 一份数据需要被多个下游系统处理. 另外一个经典场景就是<strong>日志采集流程</strong>, 一般日志数据都很大, 直接发到下游, 下游系统可能会扛不住崩溃, 所以会把数据先缓存到消息队列中. 所以消息队列的基本特性就是<strong>高性能, 高吞吐, 低延时</strong>.</p> <h5 id="架构层面的基本概念"><a href="#架构层面的基本概念" class="header-anchor">#</a> 架构层面的基本概念</h5> <p>接下来通过一张图示, 来了解一下消息队列架构层面常见的一些<strong>基本概念</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/845c85d7f3d55cd47c894f0b8eb7ab06-20240421231949-09orljp.jpg" alt="">​</p> <ol><li><strong>Broker</strong>: Broker 本质上是一个<strong>进程</strong>, 比如 RocketMQ 的 Broker 就是指 RocketMQ Server 启动成功后的一个进程. 在实际部署过程中, 通常一个物理节点只会起一个进程, 所以大部分情况下认为 Broker 就表示<strong>一个节点</strong>, 但是在一些特殊场景下, 一个物理节点中也可以起多个进程, 就表示一台节点有多个 Broker.</li> <li><strong>Topic(主题)</strong> : 在大部分消息队列中, Topic 都是指用来<strong>组织分区关系的一个逻辑概念</strong>. 通常情况下, 一个 Topic 会包含多个分区. 但 RabbitMQ 是一个例外, Topic 是指具体某一种主题模式.</li> <li><strong>Partition/Queue/MessageQueue(分区/分片)</strong> : 在消息队列中, <mark><strong>分区, 分片, Partiton, Queue, MessageQueue 是一个概念, 后面统一用分区来称呼, 都是用来表示数据存储的最小单位</strong></mark>. 一般可以直接将消息写入到一个分区中, 也可以将消息写入到 Topic, 再分发到具体某个分区. <strong>一个 Topic 通常会包含一个或多个分区</strong>.</li> <li><strong>Producer(生产者)</strong> : 生产者指消息的发送方, 即发送消息的客户端, 也叫生产端.</li> <li><strong>Consumer(消费者)</strong> : 消费者指消息的接收方, 即接收消息的客户端, 也叫消费端.</li> <li><strong>ConsumerGroup/Subscription(消费分组/订阅)</strong> : 一般情况下, 消息队列中<mark><strong>消费分组和订阅是同一个概念</strong></mark>, 后面统一用消费分组来称呼. 它是用来组织消费者和分区关系的逻辑概念, 也有保存消费进度的作用.</li> <li><strong>Message(消息)</strong> : 指一条真实的业务数据, 消息队列的每条数据一般都叫做一条消息.</li> <li><strong>Offset/ConsumerOffset/Cursor(位点/消费位点/游标):</strong>  指消费者<strong>消费分区的进度</strong>, 即每个消费者都会去消费分区, 为了避免重复消费进度, 都会保存消费者消费分区的进度信息.</li> <li><strong>ACK/OffsetCommit(确认/位点提交)</strong> : 确认和位点提交一般都是指提交消费进度的操作, 即数据消费成功后, <strong>提交当前的消费位点, 确保不重复消费</strong>.</li> <li><strong>Leader/Follower(领导者/追随者, 主副本/从副本)</strong> : Leader 和 Follower 一般是分区维度副本的概念, 即集群中的分区一般会有多个副本. 此时就会有主从副本的概念, 一般是一个主副本配上一个或多个从副本.</li> <li><strong>Segment(段/数据分段)</strong> : 段是指消息数据在底层具体<strong>存储时, 分为多个文件存储时的文件</strong>, 这个文件就叫做分区的数据段. 即比如每超过 1G 的文件就新起一个文件来存储, 这个文件就是 Segment. 基本所有的消息队列都有段的概念, 比如 Kakfa 的 Segment, Pulsar 的 Ledger 等等.</li> <li><strong>StartOffset/EndOffset(起始位点/结束位点)</strong> : 起始位点和结束位点是<strong>分区维度</strong>的概念. 即数据是顺序写入到分区的, 一般从 0 的位置开始往后写, 此时起始位点就是 0. 因为数据有过期的概念, 分区维度较早的数据会被清理. 此时起始位点就会往后移, 表示当前阶段最早那条有效消息的位点. 结束位点是指最新的那条数据的写入位置. 因为数据一直在写入分区, 所以起始位点和结束位点是一直动态变化的.</li> <li><strong>ACL(访问控制技术)</strong> : ACL 全称是 Access Control List, 用来对集群中的资源进行权限控制, 比如控制分区或 Topic 的读和写等.</li></ol> <h5 id="功能层面的基本概念"><a href="#功能层面的基本概念" class="header-anchor">#</a> 功能层面的基本概念</h5> <p>讲完了架构层面的基本概念, 来看看功能层面的基本概念.</p> <p>相比于数据库的基本操作是增删改查, 消息队列的基本操作就是<strong>生产和消费, 即读和写</strong>. 消息队列一般是不支持客户端修改和删除单条数据的. 接下来就从功能的角度, 来了解一些常见的基本概念.</p> <ol><li><strong>顺序消息</strong>: 是指从生产者和消费者的视角来看, 生产者按顺序写入 Topic 的消息, 在消费者这边能不能按生产者写入的顺序消费到消息, 如果能就是顺序消息.</li> <li><strong>延时消息/定时消息</strong>: 都是指生产者发送消息到 Broker 时, 可以设置这条消息在多久后能被消费到, 当时间到了后, 消息就会被消费到. 延时的意思就是指以 Broker 收到消息的时间为准, 多久后消息能被消费者消费, 比如消息发送成功后的 30 分钟才能被消费. 定时是指可以指定消息在设置的时间才能被看到, 比如设置明天的 20:00 才能被消费. 从技术上来看, 两者是一样的; 从客户端的角度, 功能上稍微有细微的差别; 从内核的角度, 一般两种消息是以同一个概念出现的.</li> <li><strong>事务消息</strong>: 消息队列的事务因为在不同的消息队列中的实现方式不一样, 所以定义也不太一样. 正常情况下, 事务表示<strong>多个操作的原子性</strong>, 即一批操作要么一起成功, 要么一起失败. 在消息队列中, 一般指发送一批消息, 要么同时成功, 要么同时失败.</li> <li><strong>消息重试</strong>: 消息重试分为生产者重试和消费者重试. <strong>生产者重试是指当消息发送失败后, 可以设置重试逻辑, 比如重试几次, 多久后重试, 重试间隔多少. 消费者重试是指当消费的消息处理失败后, 会自动重试消费消息</strong>.</li> <li><strong>消息回溯</strong>: 是指当允许消息被多次消费, 即某条消息消费成功后, 这条消息不会被删除, 还能再重复消费到这条消息.</li> <li><strong>广播消费</strong>: 广播听起来是一个主动的, 即 Broker 将一条消息广播发送给多个消费者. 但是在消息队列中, 广播本质上是指一条消息能不能被很多个消费者消费到. 只要能被多个消费者消费到, 就能起到广播消费的效果, 就可以叫做广播消费.</li> <li><strong>死信队列</strong>: 死信队列是一个功能, 不是一个像分区一样的实体概念. 它是指<strong>当某条消息无法处理成功时, 则把这条消息写入到死信队列, 将这条消息保存起来, 从而可以处理后续的消息的功能</strong>. 大部分情况下, 死信队列在消费端使用得比较多, 即消费到的消息无法处理成功, 则将数据先保存到死信队列, 然后可以继续处理其他消息. 当然, 在生产的时候也会有死信队列的概念, 即某条消息无法写入 Topic, 则可以先写入到死信队列. 从功能上来看, 死信队列的功能业务也可以自己去实现. 消息队列中死信队列的意思是, 消息队列的 SDK 已经集成了这部分功能, 从而让业务使用起来就很简单.</li> <li><strong>优先级队列</strong>: 优先级队列是指可以给在一个分区或队列中的消息设置权重, 权重大的消息能够被优先消费到. 大部分情况下, 消息队列的消息处理是 FIFO 先进先出的规则. 此时如果某些消息需要被优先处理, 基于这个规则就无法实现. 所以就有了优先级队列的概念, 优先级是消息维度设置的.</li> <li><strong>消息过滤</strong>: 是指可以给每条<strong>消息打上标签</strong>, 在消费的时候可以根据标签信息去消费消息. 可以理解为一个简单的<strong>查询消息的功能, 即通过标签去查询过滤消息. 消息过滤主要在消费端生效</strong>.</li> <li><strong>消息过期/删除(TTL)</strong> : 是指消息队列中的消息会在一定时间或者超过一定大小后会被删除. 因为消息队列主要是缓冲作用, 所以一般会要求消息在一定的策略后会自动被清理.</li> <li><strong>消息轨迹</strong>: 是指记录<strong>一条消息从生产端发送, 服务端保存, 消费端消费的全生命周期的流程信息</strong>. 用来追溯消息什么时候被发送, 是否发送成功, 什么时候发送成功, 服务端是否保存成功, 什么时候保存成功, 被哪些消费者消费, 是否消费成功, 什么时候被消费等等信息.</li> <li><strong>消息查询</strong>: 是指能够根据某些信息查询到消息队列中的信息. 比如根据消息 ID 或根据消费位点来查询消息, 可以理解为数据库里面的固定条件的 select 操作.</li> <li><strong>消息压缩</strong>: 是指生产端发送消息的时候, 是否支持将消息进行压缩, 以节省物理资源(比如网卡, 硬盘). 压缩可以在 SDK 完成, 也可以在 Broker 完成, 并没有严格限制. 通常来看, 压缩在客户端完成会比较合理.</li> <li><strong>多租户</strong>: 是指同一个集群是否有逻辑隔离, 比如一个物理集群能否创建两个名称都为 test 的主题. 此时一般会有一个逻辑概念 Namespace(命名空间)和 Tenant(租户)来做隔离, 一般有这两个概念的就是支持多租户.</li> <li><strong>消息持久化</strong>: 是指消息发送到 Broker 后, 会不会<strong>持久化存储</strong>, 比如存储到硬盘. 有些消息队列为了保证性能, 只会把消息存储在内存, 此时节点重启后数据就会丢失.</li> <li><strong>消息流控</strong>: 是指能否对<strong>写入集群的消息进行限制</strong>. 一般会支持 Topic, 分区, 消费分组, 集群等维度的限流.</li></ol> <h5 id="总结-2"><a href="#总结-2" class="header-anchor">#</a> 总结</h5> <p>到这儿预习篇的内容就结束了, 这个起步是不是非常简单. 概念就不过多总结了, 最后来总结一下 4 款主流消息队列的区别以及选型建议, 前面也提到过, 它们分别是 RabbitMQ, RocketMQ, Kafka, Pulsar.</p> <ol><li><strong>RabbitMQ 和 RocektMQ 属于业务消息类的消息队列, 它们的特点是功能丰富, 低延时, 数据高可靠性, 消息可追踪等等, 同时也支持延时消息, 优先级队列, 消息过滤等功能特性</strong>. RabbitMQ 发展较早, RocketMQ 则是新生的消息类的消息队列, 从功能, 集群化, 稳定性, 性能来看, RocketMQ 都是比 RabbitMQ 表现要好的. 所以从某种意义上说, RocketMQ 是可以替代 RabbitMQ 的, 但是因为 RabbitMQ 发展悠久, 内核稳定以及能满足大部分的业务消息场景, 所以目前用户群体也很大. 国内的业务消息类的选型一般以 RocketMQ 优先, 然后才是 RabbitMQ, 而国外的业务消息类选型一般优先的是 RabbitMQ.</li> <li><strong>Kakfa 属于主打流场景的消息队列</strong>. 它的特点是追求高吞吐, 大流量, 在功能上相对简单. 不支持太多消息队列的功能, 比如死信队列, 延时消息, 消息过滤等等. 但它的核心竞争力就是非常稳定, 吞吐性能非常高, 能承担超大流量的业务场景. 所以它是<strong>流场景</strong>下的消息管道的不二选择.</li> <li><strong>Pulsar 从定位上是消息和流一体的. 目标就是满足所有消息和流的场景, 希望同时满足功能和性能两方面的需求</strong>. 所以 Pulsar 的内核会支持很多功能, 在性能和吞吐方面也经常拿来与 Kakfa 做比较. 但是因为其发展时间较短, 目前还不是那么稳定, 正处于快速发展阶段.</li></ol> <p>从个人选择来看, 也给你一些建议.</p> <ol><li><strong>业务消息类的场景, 推荐优先选择 RocketMQ</strong>. 主要原因是 RocketMQ 的性能高, 社区活跃, 集群化架构稳定, 功能也非常丰富. 而 RabbitMQ 当前架构存在缺点, 单机存在瓶颈, 在高 QPS 场景表现不是那么好, 并且可能出现网络分区. 所以从功能, 性能, 稳定性出发, 会优先推荐使用 RocketMQ.</li> <li><strong>流方向的场景, 推荐优先选择 Kafka</strong>. 主要原因是 Kafka 本身的性能和吞吐表现非常优越, 延时和可靠性表现也不错. 而 Pulsar 虽然主打的是替换 Kafka, 并且功能丰富, 架构设计理念先进, 但是因为发展周期较短, 很多功能还不稳定, 当前阶段的现网运营表现并不是那么好. 所以虽然 Kafka 存在扩容, Rebalance 方面的缺陷, 但是从稳定性, 性能出发, 还是会优先推荐使用 Kafka.</li> <li>在日常使用中, 也可能会根据业务需求同时运营多款消息队列, 比如 RocketMQ/RabbitMQ+Kafka.</li></ol> <p>更多细节总结如下, 可以再详细看看.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fcd8ca1618bb823a675668d61e765e7f-20240421231949-7otr6xe.jpg" alt=""><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f7d38df79c7d41630f64c54a16e16b2c-20240421231949-l35296p.jpg" alt=""></p> <h3 id="基础篇"><a href="#基础篇" class="header-anchor">#</a> 基础篇</h3> <h4 id="_03-通信协议-如何设计一个好的通信协议"><a href="#_03-通信协议-如何设计一个好的通信协议" class="header-anchor">#</a> 03-通信协议:如何设计一个好的通信协议?</h4> <p>今天正式进入基础篇的学习, 会带你构建最基础的消息队列.</p> <p>从功能上来看, 一个最基础的消息队列应该具备<strong>生产, 存储, 消费</strong>的能力, 也就是能完成 &quot;生产者把数据发送到 Broker, Broker 收到数据后, 持久化存储数据, 最后消费者从 Broker 消费数据&quot; 的整个流程.</p> <p>从这个流程来拆解技术架构, 如下图所示, 最基础的消息队列应该具备五个模块.</p> <ul><li><mark><strong>通信协议</strong></mark>: 用来完成客户端(生产者和消费者)和 Broker 之间的通信, 比如生产或消费.</li> <li><mark><strong>网络模块</strong></mark>: 客户端用来发送数据, 服务端用来接收数据.</li> <li><mark><strong>存储模块</strong></mark>: 服务端用来完成持久化数据存储.</li> <li><mark><strong>生产者</strong></mark>: 完成生产相关的功能.</li> <li><mark><strong>消费者</strong></mark>: 完成消费相关的功能.</li></ul> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a831a39cd1bf783665eb844257c69898-20240421231949-vdlduzi.jpg" alt="">​</p> <p>其实消息队列本质上讲是个 CS 模型, 通过客户端和服务端之间的交互完成生产, 消费等行为. <strong>不知道你在日常的开发过程中, 是否会好奇客户端和服务端之间的通信流程是怎么实现的呢?</strong></p> <p>那今天就开始学习基础篇的第一讲--通信协议. 为了完成交互, 第一步就需要<strong>确定服务端和客户端是如何通信</strong>的. 而通信的第一步就是确定<strong>使用哪种通信协议进行通信</strong>.</p> <p>大家最熟悉的可能就是 HTTP 协议了, HTTP 作为一个标准协议, 有很多优点. 那能否用 HTTP 协议作为消息队列的通信协议呢?</p> <h5 id="通信协议基础"><a href="#通信协议基础" class="header-anchor">#</a> 通信协议基础</h5> <p>所有协议的选择和设计都是根据需求来的, 消息队列的核心特性是<strong>高吞吐, 低延时, 高可靠</strong>, 所以在协议上至少需要满足:</p> <ul><li>协议可靠性要高, 不能丢数据.</li> <li>协议的性能要高, 通信的延时要低.</li> <li>协议的内容要精简, 带宽的利用率要高.</li> <li>协议需要具备可扩展能力, 方便功能的增减.</li></ul> <p>那有没有现成的满足这四个要求的协议呢?</p> <p>目前业界的通信协议可以分为 <strong>公有协议和私有协议</strong> 两种. 公有协议指公开的受到认可的具有规范的协议, 比如 JMS, HTTP, STOMP 等. 私有协议是指根据自身的功能和需求设计的协议, 一般不具备通用性, 比如 Kafka, RocketMQ, Puslar 的协议都是私有协议.</p> <p>其实消息队列领域是存在公有的, 可直接使用的标准协议的, 比如 AMQP, MQTT, OpenMessaging, 它们设计的初衷就是为了解决因各个消息队列的协议不一样导致的组件互通, 用户使用成本高, 重复设计, 重复开发成本等问题. 但是, 公有的标准协议讨论制定需要较长时间, 往往无法及时赶上需求的变化, 灵活性不足.</p> <p><strong>因此大多数消息队列为了自身的功能支持, 迭代速度, 灵活性考虑, 在核心通信协议的选择上不会选择公有协议, 都会选择自定义私有协议</strong>.</p> <p>那私有协议要怎么设计实现呢? 从技术上来看, 私有协议设计一般需要包含三个步骤.</p> <ol><li><mark><strong>网络通信协议选型</strong></mark>, 指计算机七层网络模型中的协议选择. 比如传输层的 TCP/UDP, 应用层的 HTTP/WebSocket 等.</li> <li><mark><strong>应用通信协议设计</strong></mark>, 指如何约定客户端和服务端之间的通信规则. 比如如何识别请求内容, 如何确定请求字段信息等.</li> <li><mark><strong>编解码(序列化/反序列化)实现</strong></mark>, 用于将二进制的消息内容解析为程序可识别的数据格式.</li></ol> <p>每一步具体如何选择和实现呢? 先看网络通信协议.</p> <h5 id="网络通信协议选型"><a href="#网络通信协议选型" class="header-anchor">#</a> 网络通信协议选型</h5> <p>从功能需求出发, 为了保证性能和可靠性, 几乎所有主流消息队列在核心生产, 消费链路的协议选择上, <strong>都是基于可靠性高, 长连接的 TCP 协议</strong>.</p> <p>下面是一张当前业界主要的协议类型图:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/80340d224f5b555c49a7c62368582739-20240421231949-9k10sbn.jpeg" alt="">​</p> <p>四层的 UDP 虽然也是长连接, 性能更高, 但是因为其不可靠传输的特性, 业界几乎没有消息队列用它通信.</p> <p>七层的 HTTP 协议每次通信都需要经历三次握手, 四次关闭等步骤, 并且协议结构也不够精简. 从而在性能(比如耗时)上的表现较差, 不适合高吞吐, 大流量, 低延时的场景. 所以<strong>主流协议在核心链路上很少使用 HTTP</strong>.</p> <p>但很少并不代表没有, HTTP 协议的优点是客户端库非常丰富, 协议成熟, 非常容易和第三方集成, 用户使用起来成本非常低. 所以一些主打轻量, 简单的消息队列, 比如 AWS SQS, Tencent CMQ, 它们主链路的协议就是用的 HTTP 协议. 核心考虑是满足 <strong>多场景的需求</strong>, 即支持多种接入方式并降低接入门槛. 七层协议虽然在性能上有一些降低, 但是在一些特殊场景或者某些对耗时不敏感的业务中, 降低接入成本是收益很高的事情.</p> <p>接下来看应用通信协议的设计, 如何构成? 设计的时候应该关注什么呢?</p> <h5 id="应用通信协议设计"><a href="#应用通信协议设计" class="header-anchor">#</a> 应用通信协议设计</h5> <p>从应用通信协议构成的角度, 协议一般会包含<strong>协议头和协议体</strong>两部分.</p> <ul><li><strong>协议头</strong> 包含一些<strong>通用信息和数据源信息</strong>, 比如<strong>协议版本, 请求标识, 请求的 ID, 客户端 ID</strong> 等等.</li> <li><strong>协议体</strong> 主要包含本次通信的<strong>业务数据</strong>, 比如一串字符串, 一段 JSON 格式的数据或者原始二进制数据等等.</li></ul> <p>从编解码协议的设计角度来看, 需要分别针对 &quot;请求&quot; 和 &quot;返回&quot; 设计协议, 请求协议结构和返回协议结构一般长这样.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/31e7b41befb65127997dd1c147c7b317-20240421231949-q37ko2y.jpg" alt="">​</p> <p>设计的原则是: <strong>请求维度的通用信息放在协议头, 消息维度的信息就放在协议体</strong>. 那具体怎么设计呢? 下面结合 Kafka 协议来分析.</p> <h6 id="协议头的设计"><a href="#协议头的设计" class="header-anchor">#</a> 协议头的设计</h6> <p>协议头的设计, 首先要确认协议中需要携带哪些通用的信息. 一般情况下, 请求头要携带本次请求以及源端的一些信息, 返回头要携带请求唯一标识来表示对应哪个请求, 这样就可以了.</p> <p>所以, <strong>请求头一般需要携带协议版本, 请求标识, 请求的 ID, 客户端 ID 等信息. 而返回头, 一般只需要携带本次请求的 ID, 本次请求的处理结果(成功或失败)等几个信息</strong>.</p> <p>接下来, 分析一下 Kafka 协议的请求头和返回头的内容, 让你对协议头的设计有个更直观认识. 如下图所示, Kafka V2 协议的请求头中携带了四个信息.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ef24e0d797c5c361605e30405e1cffb4-20240421231949-wjtavjb.jpg" alt="">​</p> <ul><li>用来<strong>标识请求类型</strong>的 api_key, 如生产, 消费, 获取元数据.</li> <li>用来<strong>标识请求协议版本</strong>的 api_version, 如 V0, V1, V2.</li> <li>用来<strong>唯一标识该请求</strong> correlation_id, 可以理解为请求 ID.</li> <li>用来<strong>标识客户端</strong>的 client_id.</li></ul> <p>Kafka V0 协议的返回头中只携带了一个信息, 即该请求的 correlation_id, 用来标识这个返回是哪个请求的.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e45b0f0dfb420d6ae92a97b889756e1e-20240421231949-rb2e4vy.jpg" alt="">​</p> <p>这里有个细节你可能注意到了, 请求协议头是 V2 版本, 返回协议头是 V0 版本, 会不会有点问题呢?</p> <p>其实是没有的. 因为从协议的角度, 一般业务需求的变化(增加或删除)都会涉及请求内容的修改, 所以请求的协议变化是比较频繁的, 而返回头只要能标识本次对应的请求即可, 所以协议的变化比较少. 所以<strong>请求头和返回头的协议版本制定, 是建议分开定义的</strong>, 这样在后期的维护升级中会更加灵活.</p> <h6 id="协议体的设计"><a href="#协议体的设计" class="header-anchor">#</a> 协议体的设计</h6> <p>协议体的设计就和业务功能密切相关了. 因为协议体是携带本次请求/返回的具体内容的, 不同接口是不一样的, 比如生产, 消费, 确认, 每个接口的功能不一样, 结构基本千差万别.</p> <p>不过设计上还是有共性的, 注意三个点: <mark><strong>极简, 向后兼容, 协议版本管理</strong></mark>. 如何理解呢?</p> <p>协议在实现上首先需要具备<strong>向后兼容的能力</strong>, 后续的变更(如增加或删除)不会影响新老客户端的使用; 然后协议内容上要<strong>尽量精简</strong>(比如字段和数据类型), 这样可以降低编解码和传输过程中的带宽的开销, 以及其他物理资源的开销; 最后需要<strong>协议版本管理</strong>, 方便后续的变更.</p> <p>同样为了让你直观感受协议体的设计, 下面看看 Kafka 生产请求和返回的协议内容, 可以先自己分析一下.</p> <p>Kafka 生产请求协议体如下:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/b4b4b2822dbfcf349da7eef311d6e11f-20240421231949-imizc4j.jpg" alt="">​</p> <p>Kafka 生产返回协议体如下:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a199d630cc2d2ebb149d0da1442605fa-20240421231949-k3jga4v.jpg" alt="">​</p> <p>Kafka 生产请求的协议体包含了事务 ID, acks 信息, 请求超时时间, Topic 相关的数据, 都是和生产操作相关的. 生产返回的协议体包含了限流信息, 分区维度的范围信息等. 这些字段中的每个字段都是经过多轮迭代, 重复设计定下来的, 每个字段都有用处.</p> <p>所以在协议体的设计上, <strong>最核心的就是要遵循 &quot;极简&quot; 原则, 在满足业务要求的基础上, 尽量压缩协议的大小</strong>.</p> <p>接下来想讨论一下数据类型, 在协议设计里, 很容易忽略的一个事就是<strong>数据类型</strong>, 比如上面 throttle_time_ms 是 INT32, error_code 是 INT16.</p> <p>数据类型很简单, 用来标识每个字段的类型, 不过为什么会有这个东西呢, 不能直接用 int, string, char 等基础类型吗? 这里有两个原因.</p> <ul><li><strong>消息队列是多语言通信的</strong>. 不同语言对于同一类型的定义和实现是不一样的, 如果使用同一种基础类型在不同的语言进行解析, 可能会出现解析错乱等错误.</li> <li><strong>需要尽量精简消息的长度</strong>. 比如只需要 1 个 byte 就可以表示的内容, 如果用 4 个 byte 来表示, 就会导致消息的内容更长, 消耗更多的物理带宽.</li></ul> <p>所以一般在协议设计的时候, 也需要设计相关的基础数据类型(如何设计可以参考 Kafka 的协议数据类型 或者 <a href="https://protobuf.dev/programming-guides/proto3/#scalar" target="_blank" rel="noopener noreferrer">Protobuf 的数据类型<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>).</p> <h5 id="编解码实现"><a href="#编解码实现" class="header-anchor">#</a> 编解码实现</h5> <p>接下来看看编解码的实现. <strong>编解码也称为序列化和反序列, 就是数据发送的时候编码, 收到数据的时候解码</strong>.</p> <p>为什么要编解码呢? 如下图所示, 因为数据在网络中传输时是二进制的形式, 所以在客户端发送数据的时候就要将原始的格式数据编码为二进制数据, 以便在 TCP 协议中传输, 这一步就是<strong>序列化</strong>. 然后在服务端将收到的二进制数据根据约定好的规范解析成为原始的格式数据, 这就是<strong>反序列化</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bbf19c9ea186a064db193f7fyydd47d1-20240421231949-v8a1otk.jpg" alt="">​</p> <p>在序列化和反序列化中, 最重要的就是 <strong>TCP 的粘包和拆包</strong>. TCP 是一个 &quot;流&quot; 协议, 是一串数据, 没有明显的界限, TCP 层面不知道这段流数据的意义, 只负责传输. 所以<strong>应用层就要根据某个规则从流数据中拆出完整的包, 解析出有意义的数据, 这就是粘包和拆包的作用</strong>.</p> <p><strong>粘包/拆包的几个思路就是</strong>:</p> <ul><li><strong>消息定长</strong>.</li> <li>在包尾增加回车换行符进行<strong>分割</strong>, 例如 FTP 协议.</li> <li><strong>将消息分为消息头和消息体, 消息头中包含消息总长度, 然后根据长度从流中解析出数据</strong>.</li> <li>更加复杂的应用层协议, 比如 HTTP, WebSocket 等.</li></ul> <p>早期, 消息队列的协议设计几乎都是自定义实现编解码, 如 RabbitMQ, RocektMQ 4.0, Kafka 等.</p> <p>但从 0 实现编解码器比较复杂, 随着业界主流编解码框架和编解码协议的成熟, 一些消息队列(如 Pulsar 和 RocketMQ 5.0)开始使用业界成熟的编解码框架, 如 Google 的 <strong>Protobuf</strong>.</p> <p>Protobuf 是一个灵活, 高效, 结构化的编解码框架, 业界非常流行, 很多商业产品都会用, 它支持多语言, 编解码性能较高, 可扩展性强, 产品成熟度高. 这些优点, 都是在设计协议的时候需要重点考虑和实现的, 并且自定义实现编解码的效果不一定有 Protobuf 好. 所以<strong>新的消息队列产品或者新架构可以考虑选择 Protobuf 作为编解码框架</strong>.</p> <p>为了加深你对 &quot;自定义实现编解码&quot; 和 &quot;使用现成的编解码框架&quot; 两个路径的选择判断, 下面来结合 RocketMQ 的通信协议分析一下.</p> <h6 id="从rocketmq看编解码的实现"><a href="#从rocketmq看编解码的实现" class="header-anchor">#</a> 从RocketMQ看编解码的实现</h6> <p>RocketMQ 是业界唯一一个既支持自定义编解码, 又支持成熟编解码框架的消息队列产品. <strong>RocketMQ 5.0 之前支持的 Remoting 协议是自定义编解码, 5.0 之后支持的</strong> <mark><strong>gRPC 协议是基于 Protobuf 编解码框架</strong></mark>.</p> <p><strong>用 Protobuf 的主要原因是它选择 gRPC 框架作为通信框架</strong>. 而 gRPC 框架中默认编解码器为 Protobuf, 编解码操作已经在 gRPC 的库中正确地定义和实现了, 不需要单独开发. 所以 RocketMQ 可以把重点放在 Rocket 消息队列本身的逻辑上, 不需要在协议方面上花费太多精力.</p> <p>接下来看一下 RocketMQ 的 &quot;生产请求&quot; 在 Remoting 协议和 gRPC 协议中的协议结构.</p> <p>如下图所示, <strong>自定义的 Remoting 协议的整体结构, 包括协议头(消息头)和协议体(消息体)两部分</strong>. 消息头包含请求操作码, 版本, 标记, 扩展信息等通用信息. 消息体包含的就是各个请求的具体内容, 比如生产请求就是包含生产请求的请求数据, 是一个复合的结构.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/7f5271c6a64yy95fbbee48c016a205e6-20240421231949-rdhzsuy.png" alt="">​</p> <p>生产请求接口的消息体中的具体内容, 包含生产组, Topic, 标记等生产请求需要携带的信息, 服务端需要根据这些信息完成对应操作.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SendMessageRequestHeader</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">{</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> producerGroup<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> topic<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> defaultTopic<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> defaultTopicQueueNums<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> queueId<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> sysFlag<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Long</span> bornTimestamp<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> flag<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">String</span> properties<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> reconsumeTimes<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">boolean</span> unitMode <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">boolean</span> batch <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token class-name">Integer</span> maxReconsumeTimes<span class="token punctuation">;</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p><strong>gRPC 的生产消息的请求结构, 内容简单, 只需要定义生产请求需要携带的相关信息</strong>, 比如 Topic, 用户属性, 系统属性等.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code>message <span class="token class-name">Message</span> <span class="token punctuation">{</span>
  <span class="token class-name">Resource</span> topic <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
  map<span class="token generics"><span class="token punctuation">&lt;</span>string<span class="token punctuation">,</span> string<span class="token punctuation">&gt;</span></span> user_properties <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>
  <span class="token class-name">SystemProperties</span> system_properties <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>
  bytes body <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

message <span class="token class-name">SendMessageRequest</span> <span class="token punctuation">{</span>
  repeated <span class="token class-name">Message</span> messages <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

service <span class="token class-name">MessagingService</span> <span class="token punctuation">{</span>
  rpc <span class="token class-name">SendMessage</span><span class="token punctuation">(</span><span class="token class-name">SendMessageRequest</span><span class="token punctuation">)</span> returns <span class="token punctuation">(</span><span class="token class-name">SendMessageResponse</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>对比上面两段代码, 可以很直观地看到区别, gRPC 的协议结构比 Remoting 的协议结构简单很多, 比如不需要定义消息头, 定义方式也更加简单.</p> <p>有这样的区别主要有以下两点原因:</p> <ul><li>Remoting 需要先设计协议的整体结构, 协议头和协议体, 而 gRPC 只需要关注协议体. 因为 gRPC 已经完成了整体结构和协议体的设计.</li> <li>Remoting 需要在各个语言自定义实现相关代码, 而 gRPC 基于 Protobuf 编解码框架, 只要根据 Protobuf 语法定义好协议体的内容, 就可以使用工具生成各语言的代码.</li></ul> <p>这也佐证了我们的看法, <strong>使用现成的编解码框架比自定义编解码更加方便和高效</strong>.</p> <h5 id="总结-3"><a href="#总结-3" class="header-anchor">#</a> 总结</h5> <p>到这里, 今天的主要内容--消息队列的通信协议设计就学完了.</p> <p>从功能支持, 迭代速度, 灵活性上考虑, 大多数消息队列的核心通信协议都会优先考虑自定义的私有协议. 私有协议的设计主要考虑网络通信协议选择, 应用通信协议设计, 编解码实现三个方面.</p> <ul><li><strong>网络通信协议选型, 基于可靠, 低延时的需求</strong>, 大部分情况下应该选择 TCP.</li> <li><strong>应用通信协议设计, 分为请求协议和返回协议两方面</strong>. 协议应该包含协议头和协议体两部分. 协议头主要包含一些通用的信息, 协议体包含请求维度的信息.</li> <li><strong>编解码, 也叫序列化和反序列化</strong>. 在实现上分为<strong>自定义实现和使用现成的编解码框架两个路径</strong>.</li></ul> <p>其中最重要的是应用通信协议部分的设计选型, 这部分需要设计协议头和协议体. 重要的是要思考协议头和协议体里面分别要放什么, 放多了浪费带宽影响传输性能, 放少了无法满足业务需求, 需要频繁修改协议内容. 另外, 每个字段的类型也有讲究, 需要尽量降低每次通信的数据大小.</p> <p>所以应用通信协议的内容设计是非常考验技术功底或者经验的. 有一个技巧是, <strong>如果需要实现自定义的协议, 可以去参考一下业界主流的协议实现, 看看都包含哪些元素, 各自踩过什么坑</strong>. 总结分析后, 这样一般能设计出一个相对较好的消息队列.</p> <p>另外, 不可能一下子设计出完美的协议, 所以<strong>核心是保证协议的向前兼容和向后兼容的能力, 以便后续的升级和改造</strong>. 因为历史发展原因, 业界大部分的消息队列的编解码都是自己实现的, 只有近年兴起的 Pulsar 和 RocketMQ 的新版本选择了 Protobuf 作为编解码框架. 从编解码框架的选择来看, 如果是一个全新的项目或架构, 使用现成的编解码框架比如 Protobuf, 是比较好的选择.</p> <h5 id="思考题"><a href="#思考题" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为什么业界的消息队列有多种标准的协议呢?</p></blockquote> <p>业界的消息队列有多种标准的协议, 如 MQTT, AMQP, OpenMessaging. 主要是因为<strong>业务场景不一样, 一套协议标准无法满足多种场景需要</strong>.</p> <p>MQTT 是为了满足<strong>物联网领域</strong>的通信而设计的, 背景是网络环境不稳定, 网络带宽小, 从而需要极精简的协议结构, 并允许可能的数据丢失.</p> <p>AMQP 是主要面向<strong>业务消息</strong>的协议, 因为要承载复杂的业务逻辑, 所以协议设计上要尽可能丰富, 包含多种场景, 并且在传输过程中不允许出现数据丢失. 因为 AMQP 协议本身的设计具有很多局限, 比如功能太简单, 所以不太符合移动互联网, 云原生架构下的消息需求.</p> <p>OpenMessaging 的设计初衷是设计一个符合更多场景的消息队列协议.</p> <h4 id="_04-网络-如何设计高性能的网络模块"><a href="#_04-网络-如何设计高性能的网络模块" class="header-anchor">#</a> 04-网络:如何设计高性能的网络模块?</h4> <p>今天讲消息队列的第二个基础知识点--网络模块. 对消息队列来说, 网络模块是核心组件之一, 网络模块的性能很大程度上决定了消息传输的能力和整体性能.</p> <p>如果你是 Java 技术栈的开发人员, 讲到网络模块的开发, 大概率第一反应就是 Netty. Netty 作为 Java 网络编程中最出名的类库, 几乎主宰了 Java 的网络编程. <strong>那消息队列网络模块的选型,</strong> <strong>是不是直接用</strong> <strong>Netty</strong> <strong>就可以了呢?</strong></p> <p>选型之前, 得先知道要解决什么问题. 消息队列是需要满足高吞吐, 高可靠, 低延时, 并支持多语言访问的基础软件, 网络模块最需要解决的是 <strong>性能</strong>, <strong>稳定性, 开发成本</strong> 三个问题. 接下来就围绕这三点来思考消息队列网络模块应该怎样设计. 首先先来分析一下<strong>网络模块的性能瓶颈可能在哪里</strong>.</p> <h5 id="网络模块的性能瓶颈分析"><a href="#网络模块的性能瓶颈分析" class="header-anchor">#</a> 网络模块的性能瓶颈分析</h5> <p>下面基于最基础的消息队列访问链路图分析.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a831a39cd1bf783665eb844257c69898-20240421231949-l27fzk0.jpg" alt="">​</p> <p>对于 <strong>单个请求</strong> 来说, 请求流程是: 客户端(生产者/消费者)构建请求后, 向服务端发送请求包 -&gt; 服务端接收包后, 将包交给业务线程处理 -&gt; 业务线程处理完成后, 将结果返回给客户端. 其中可能消耗性能的有三个点.</p> <ul><li><strong>编解码的速度</strong>. 上节详细讲过.</li> <li><strong>网络延迟</strong>. 也就是客户端到服务端的网络延迟, 这一点在软件层面几乎无法优化, 取决于网络链路的性能, 跟网络模块无关.</li> <li><strong>服务端/客户端网络模块的处理速度</strong>. 发送/接收请求包后, 包是否能及时被处理, 比如当逻辑线程处理完成后, 网络模块是否及时回包. 这一点属于<strong>性能优化, 是网络模块设计的核心工作</strong>, 后续会细讲.</li></ul> <p>对于 <strong>并发请求</strong> 来说, 在单个请求维度的问题的基础上, 还需要处理高并发, 高 QPS, 高流量等场景带来的性能问题. 主要包含三个方面.</p> <ul><li><strong>高效的连接管理</strong>: 当客户端和服务端之间的 TCP 连接数很多, 如何高效处理, 管理连接.</li> <li><strong>快速处理高并发请求</strong>: 当客户端和服务端之间的 QPS 很高, 如何快速处理(接收, 返回)请求.</li> <li><strong>大流量场景</strong>: 当客户端和服务端之间的流量很高, 如何快速吞吐(读, 写)数据.</li></ul> <p>大流量场景某种意义上是高并发处理的一种子场景. 因为大流量分为单个请求包大并发小, 单个请求包小并发大两种场景. 第一种的瓶颈主要在于数据拷贝, 垃圾回收, CPU 占用等方面, 主要依赖语言层面的编码技巧来解决, 一般问题不大. 第二种场景是需要主要解决的.</p> <p>知道了瓶颈在哪里, 接下来来具体看一下<strong>如何设计出一个高性能的网络模块</strong>.</p> <h5 id="高性能网络模块的设计实现"><a href="#高性能网络模块的设计实现" class="header-anchor">#</a> 高性能网络模块的设计实现</h5> <p>从技术上来看, <mark><strong>高性能网络模块的设计可以分为如何高效管理大量的 TCP 连接, 如何快速处理高并发的请求, 如何提高稳定性和降低开发成本等三个方面</strong></mark>.</p> <h6 id="基于多路复用技术管理tcp连接"><a href="#基于多路复用技术管理tcp连接" class="header-anchor">#</a> 基于多路复用技术管理TCP连接</h6> <p>从技术原理来看, 高效处理大量 TCP 连接, 在消息队列中主要有<strong>单条 TCP 连接的复用和多路复用两种技术思路</strong>.</p> <blockquote><p>1.单条TCP连接的复用</p></blockquote> <p>这是在一条真实的 TCP 连接中, 创建信道(channel, 可以理解为虚拟连接)的概念. 通过编程手段, 把信道当做一条 TCP 连接使用, 做到 TCP 连接的复用, 避免创建大量 TCP 连接导致系统资源消耗过多. 缺点是在协议设计和编码实现的时候有额外开发工作量, 而且近年随着异步 IO, IO 多路复用技术的发展, 这种方案<strong>有点多余</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/159cca23dd9f28f00bbb55d53e323be6-20240421231949-7ejsccg.jpg" alt="">​</p> <p>因为语言特性, 历史背景原因, RabbitMQ 用的就是这种方案.</p> <blockquote><p>2.IO多路复用技术</p></blockquote> <p>主流的消息队列 Kakfa, RocketMQ, Pulsar 的网络模块都是<strong>基于 IO 多路复用</strong>的思路开发的.</p> <p><mark><strong>IO 多路复用技术, 是指通过把多个 IO 的阻塞复用到同一个 selector 的阻塞上, 让系统在单线程的情况下可以同时处理多个客户端请求</strong></mark>. 最大的优势是系统开销小, 系统不需要创建额外的进程或者线程, 降低了维护的工作量, 也节省了资源.</p> <p>目前支持 IO 多路复用的系统调用有 Select, Poll, Epoll 等, Java NIO 库底层就是基于 Epoll 机制实现的.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d30334cf82400efcf1761a439aaab875-20240421231949-j0prmat.jpg" alt="">​</p> <p>不过, 即使使用了这两种技术, <strong>单机能处理的连接数还是有上限的</strong>.</p> <p><mark><strong>第一个上限是操作系统的 FD 上限, 如果连接数超过了 FD 的数量, 连接会创建失败. 第二个限制是系统资源的限制, 主要是 CPU 和内存. 频繁创建, 删除或者创建过多连接会消耗大量的物理资源, 导致系统负载过高</strong></mark>.</p> <p>所以你会发现, <strong>每个消息队列的配置中都会提到连接数的限制和系统</strong> <strong>FD</strong> <strong>上限调整</strong>. Linux 中可以通过命令查看系统的 FD 信息.</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token comment"># 查看能打开 FD 的数量</span>
<span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-n</span>  <span class="token comment"># 用户级限制</span>
<span class="token function">cat</span> /proc/sys/fs/file-max  <span class="token comment"># 系统级限制</span>

<span class="token comment"># 临时修改最大数量</span>
<span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-n</span> <span class="token number">100000</span>   <span class="token comment"># 将最大值改为100000</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>解决了第一个问题连接处理, 看第二个问题: 如何快速处理高并发请求.</p> <h6 id="基于reactor模型处理高并发请求"><a href="#基于reactor模型处理高并发请求" class="header-anchor">#</a> 基于Reactor模型处理高并发请求</h6> <p>先看单个请求的处理.</p> <p>我们知道, 两点之间直线最短. 对于单个请求来说, 最快的处理方式就是客户端直接发出请求, 服务端接收到包后, 直接丢给后面的业务线程处理, 当业务线程处理成功后, 直接返回给客户端.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/31ac43088fd290fe9b167cb6f8b35b8b-20240421231949-6r0cypo.jpg" alt="">​</p> <p>这种处理模式是最快的, 但是这里有两个问题需要解决.</p> <ul><li><strong>如何第一时间拿到包交给后端的业务逻辑处理</strong>?</li> <li><strong>当业务逻辑处理完成后, 如何立即拿到返回值返回给客户端</strong>?</li></ul> <p>最直观的思路就是<strong>阻塞等待模型</strong>, 不断轮询等待请求拿到包, 业务逻辑处理完, 直接返回结果给客户端. 这种处理是最快的. 但是阻塞等待模型因为是串行的处理机制, 每个请求需要等待上一个请求处理完才能处理, 处理效率会很低. 所以, 单个请求, 最合理的方式就是 <strong>异步的事件驱动模型</strong>, 可以通过 Epoll 和异步编程来解决.</p> <p>再看<strong>高并发请求</strong>的情况.</p> <p>在高并发的情况下会有很多连接, 请求需要处理, <strong>核心思路就是并行, 多线程处理</strong>. 那如何并行处理呢? 这时候就需要用到 Reactor 模型了.</p> <p><strong>Reactor 模型是一种处理并发服务请求的事件设计模式, 当主流程收到请求后, 通过多路分离处理的方式, 把请求分发给相应的请求处理器处理</strong>. 如下图所示, Reactor 模式包含 Reactor, Acceptor, Handler 三个角色.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ef7e60fdc7353e58bd39b522628d96d5-20240421231949-68rjzrb.jpg" alt="">​</p> <ul><li>Reactor: 负责监听和分配事件. 收到事件后分派给对应的 Handler 处理, 事件包括连接建立就绪, 读就绪, 写就绪等.</li> <li>Acceptor: 负责处理客户端新连接. Reactor 接收到客户端的连接事件后, 会转发给 Acceptor, Acceptor 接收客户端的连接, 然后创建对应的 Handler, 并向 Reactor 注册此 Handler.</li> <li>Handler: 请求处理器, 负责业务逻辑的处理, 即业务处理线程.</li></ul> <p><strong>从技术上看, Reactor 模型一般有三种实现模式</strong>.</p> <ul><li>单 Reactor 单线程模型(单 Reactor 单线程)</li> <li>单 Reactor 多线程模型 (单 Reactor 多线程)</li> <li>主从 Reactor 多线程模型 (多 Reactor 多线程)</li></ul> <p>具体分析一下, 看<strong>消息队列更适合哪一种</strong>.</p> <p>单 Reactor 单线程模型, <strong>特点是 Reactor 和 Handler 都是单线程的串行处理</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d17de8f24bfaa4ea4278499f8436a04f-20240421231949-icxc4hu.jpg" alt="">​</p> <p>优点是所有处理逻辑放在单线程中实现, 没有上下文切换, 线程竞争, 进程通信等问题. 缺点是在性能与可靠性方面存在比较严重的问题. 性能上, 因为是单线程处理, 无法充分利用 CPU 资源, 并且业务逻辑 Handler 的处理是同步的, 容易造成阻塞, 出现性能瓶颈. 可靠性主要是因为单 Reactor 是单线程的, 如果出现异常不能处理请求, 会导致整个系统通信模块不可用.</p> <p><strong>所以单</strong> <strong>Reactor</strong> <strong>单进程模型不适用于计算密集型的场景, 只适用于业务处理非常快速的场景</strong>.</p> <p>相比起来, <strong>单 Reactor 多线程模型, 业务逻辑处理 Handler 变成了多线程</strong>, 也就是说, 获取到 IO 读写事件之后, 业务逻辑是一批线程在处理.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2b14d7993cbfe6d0c82df5e8886f7ba6-20240421231949-k7f9e33.jpg" alt="">​</p> <p>优点是 Handler 收到响应后通过 send 把响应结果返回给客户端, 降低 Reactor 的性能开销, 提升整个应用的吞吐. 而且 Handler 使用多线程模式, 可以充分利用 CPU 的性能, <strong>提高了业务逻辑的处理速度</strong>.</p> <p>缺点是 Handler 使用多线程模式, 带来了多线程竞争资源的开销, 同时涉及共享数据的互斥和保护机制, 实现比较复杂. 另外, 单个 Reactor 承担所有事件的监听, 分发和响应, 对于高并发场景, 容易造成性能瓶颈.</p> <p>在此基础上, <strong>主从 Reactor 多线程模型, 是让 Reactor 也变为了多线程</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/7a4fafd4957ea738d462e015dfb8c55b-20240421231949-r9v8pyn.jpg" alt="">​</p> <p><mark><strong>当前业界消息队列的网络模型, 比如 Pulsar, Kafka, RocketMQ, 为了保证性能, 都是基于主从 Reactor 多线程模型开发的</strong></mark>.</p> <p>这种方案, 优点是 Reactor 的主线程和子线程分工明确. <strong>主线程只负责接收新连接, 子线程负责完成后续的业务处理. 同时主线程和子线程的交互也很简单, 子线程接收主线程的连接后, 只管业务处理即可, 无须关注主线程, 可以直接在子线程把处理结果返回给客户端</strong>. 所以, 主从 Reactor 多线程模型适用于高并发场景, Netty 网络通信框架也采用了这种实现.</p> <p>缺点是如果基于 NIO 从零开始开发, 开发的复杂度和成本较高. 另外 Acceptor 是一个单线程, 如果挂了, 如何处理客户端新连接是一个风险点.</p> <p>为了解决 Acceptor 的单点问题, 有些组件为了保证高可用性, 会对主从 Reactor 多线程做一些优化, 把 Acceptor 也变为多线程的形态. 我们在公有云上商业化版本的 Kafka 就是使用的这种模型.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/032c1b1331eceb41defd944eb0b849cc-20240421231949-q6p15bm.jpg" alt="">​</p> <p>讲到这里, 基于 IO 多路复用技术和 Reactor 模型, 已经可以解决网络模块的性能问题了. 接下来来看<strong>如何提高网络模块的稳定性和降低开发成本</strong>.</p> <h6 id="基于成熟网络框架提高稳定性并降低开发成本"><a href="#基于成熟网络框架提高稳定性并降低开发成本" class="header-anchor">#</a> 基于成熟网络框架提高稳定性并降低开发成本</h6> <p>这里的 &quot;稳定性&quot; 主要指代码的稳定性. 因为网络模块的特点是编码非常复杂, 要考虑的细节和边界条件非常多, 一些异常情况的处理也很细节, 需要经过长时间的打磨. 但是一旦开发完成, 稳定后, 代码几乎不需要再改动, 因为需求是相对固定的.</p> <p>在 Java 中, 网络编程的核心是一个基础的类库——Java NIO 库, 它的底层是基于 Linux/Unix IO 复用模型 Epoll 实现的.</p> <p>如果要基于 Java NIO 库开发一个 Server, 需要处理网络的闪断, 客户端的重复接入, 连接管理, 安全认证, 编解码, 心跳保持, 半包读写, 异常处理等等细节, 工作量非常大. 所以在消息队列的网络编程模型中, <strong>为了提高稳定性或者降低成本, 选择现成的, 成熟的 NIO 框架是一个更好的方案.</strong></p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/163fa86b085a25c1d5e1a3cb0e316f58-20240421231949-7mlwq5f.jpg" alt="">​</p> <p>而 Netty 就是这样一个基于 Java NIO 封装的成熟框架. 所以一提到 Java 的网络编程, 最先想到的就是 Netty. <strong>当前业界主流消息队列 RocketMQ, Pulsar 也都是基于 Netty 开发的网络模块, Kafka 因为历史原因是基于 Java NIO 实现的</strong>.</p> <p>接下来以 RocketMQ 和 Kafka 的网络模型为例, 来分析一下主流消息队列的网络模型的设计实现.</p> <h5 id="主流消息队列的网络模型实现"><a href="#主流消息队列的网络模型实现" class="header-anchor">#</a> 主流消息队列的网络模型实现</h5> <h6 id="kafka网络模型"><a href="#kafka网络模型" class="header-anchor">#</a> Kafka网络模型</h6> <p>Kafka 的网络层没有用 Netty 作为底层的通信库, 而是直接<strong>采用 Java NIO 实现网络通信</strong>. 在网络模型中, 也是参照 Reactor 多线程模型, 采用多线程, 多 Selector 的设计.</p> <p>看整个网络层的结构图. Processor 线程和 Handler 线程之间通过 RequestChannel 传递数据, RequestChannel 中包含一个 RequestQueue 队列和多个 ResponseQueues 队列. 每个 Processor 线程对应一个 ResponseQueue.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1d7c282b40c75d7c42966a60d35552fc-20240421231949-360j0ky.jpg" alt="">​</p> <p>具体流程上:</p> <ul><li>一个 Acceptor 接收客户端建立连接的请求, 创建 Socket 连接并分配给 Processor 处理.</li> <li>Processor 线程把读取到的请求存入 RequestQueue 中, Handler 线程从 RequestQueue 队列中取出请求进行处理.</li> <li>Handler 线程处理请求产生的响应, 会存放到 Processor 对应的 ResponseQueue 中, Processor 线程从其对应的 ResponseQueue 中取出响应信息, 并返回给客户端.</li></ul> <h6 id="rocketmq网络模型"><a href="#rocketmq网络模型" class="header-anchor">#</a> RocketMQ网络模型</h6> <p><strong>RocketMQ 采用 Netty 组件作为底层通信库, 遵循 Reactor 多线程模型, 同时又在 Reactor 模型上做了一些扩展和优化</strong>. 所以它的网络模型是 Netty 的网络模型, Netty 底层采用的是主从 Reactor 多线程模型, 模型的原理逻辑跟前面讲到的主从 Reactor 多线程模型是一样的.</p> <p>在主从 Reactor 多线程模型的理论基础上, 来分析一下 RocketMQ 中 NettyRemotingServer 的具体实现形式.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a1dd1a870050dc0bb825e28815a51214-20240421231949-f4m9ehk.jpg" alt="">​</p> <p>具体流程上:</p> <ol><li><strong>一个 Reactor 主线程负责监听 TCP 网络连接请求, 建立好连接, 创建 SocketChannel, 并注册到 Selector 上</strong>. RocketMQ 会自动根据 OS 的类型选择 NIO 和 Epoll, 也可以通过参数配置, 监听真正的网络数据.</li> <li>接收到网络数据后, 会<strong>把数据传递给 Reactor 线程池处理</strong>.</li> <li>真正执行业务逻辑之前, 会进行 SSL 验证, 编解码, 空闲检查, 网络连接管理, 这些工作在 <strong>Worker 线程池处理(defaultEventExecutorGroup)</strong> .</li> <li>处理业务操作, 放在<strong>业务 Processor 线程池</strong>中执行.</li></ol> <p>从 Kafka 和 RocketMQ 的网络模型的实现来看, 网络模块既可以基于原生的 Java NIO, 也可以基于 NIO 的框架(如 Netty)来完成开发, 不过<mark><strong>基本思想都是基于 IO 多路复用技术和 Reactor 模型来提高处理性能, 完成具体的编码实现</strong></mark>.</p> <p>但是到这里还没有结束, NIO 编程属于 TCP 层网络编程, 还需要进行<strong>协议设计, 编解码, 链路的建立/关闭</strong>等工作, 才算完成一个完整的网络模块的开发. 有没有更好的方案可以解决这些问题, 减少工作量呢?</p> <h5 id="nio编程和rpc框架"><a href="#nio编程和rpc框架" class="header-anchor">#</a> NIO编程和RPC框架</h5> <p>要想不关心底层的调用细节(如底层的网络协议和传输协议等), 可以调用远端机器上的函数或方法来实现, 也就是 RPC(Remote Procedure Call)远程过程调用.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6843dd12f1a5d30636d58d386a99c7e9-20240421231949-xiltje5.jpg" alt="">​</p> <p>因为 RPC 调用的是一个远端对象, 调用者和被调用者处于不同的节点上, 想完成调用, 必须实现 4 个能力.</p> <ul><li><strong>网络传输协议</strong>: 远端调用底层需要经过网络传输, 所以需要选择网络通信协议, 比如 TCP.</li> <li><strong>应用通信协议</strong>: 网络传输需要设计好应用层的通信协议, 比如 HTTP2 或自定义协议.</li> <li><strong>服务发现</strong>: 调用的是远端对象, 需要可以定位到调用的服务器地址以及调用的具体方法.</li> <li><strong>序列化和反序列化</strong>: 网络传输的是二进制数据, 因此 RPC 框架需要自带序列化和反序列化的能力.</li></ul> <p>讲到这里, 不知道你有没有发现, <strong>RPC 框架完成的工作等于上节通信协议和前面讲的网络模块设计两部分的工作</strong>. 在当前的微服务架构中, RPC 已经是很常用且很成熟的技术了.</p> <p><strong>那 RPC 框架作为消息队列中的网络模块</strong>会有哪些优缺点呢?</p> <p>以 gRPC 框架举例分析. gRPC 是 Google 推出的一个 RPC 框架, 可以说是 RPC 框架中的典型代表. 主要有以下三个优点:</p> <ul><li>gRPC 内核已经很好地实现了服务发现, 连接管理, 编解码器等公共部分, 可以把开发精力集中在消息队列本身, 不需要在网络模块消耗太多精力.</li> <li>gRPC 几乎支持所有主流编程语言, 开发各个消息队列的 SDK 可以节省很多开发成本.</li> <li>很多云原生系统, 比如 Service Mesh 都集成了 gRPC 协议, 基于 HTTP2 的 gRPC 的消息队列很容易被云原生系统中的其他组件所访问, 组件间的集成成本很低.</li></ul> <p>但是当前主流的消息队列都不支持 gRPC 框架, 这是因为如果支持就要做很大的架构改动. 而且 gRPC 底层默认是<strong>七层的 HTTP2 协议</strong>, 在性能上, 可能比直接基于 TCP 协议实现的方式差一些. 但是 HTTP2 本身在性能上做了一些优化, 从实际表现来看, 性能损耗在大部分场景下是可以接受的.</p> <p>所以如果是一个新设计的消息队列或者消息队列的新架构, 通过成熟的 RPC 框架来实现网络模块是一个蛮不错的方案. 比如 RocketMQ 5.0 中的 Proxy 就使用 gRPC 框架实现了网络模块.</p> <h5 id="总结-4"><a href="#总结-4" class="header-anchor">#</a> 总结</h5> <p>消息队列的网络模块主要解决的是<strong>性能, 稳定性, 成本</strong>三个方面的问题.</p> <p><mark><strong>性能问题, 核心是通过 Reactor 模型, IO 多路复用技术解决的</strong></mark>. Reactor 模式在 Java 网络编程中用得非常广泛, 比如 Netty 就实现了 Reactor 多线程模型. 即使不用 Netty 进行网络编程(比如 Kafka 直接基于 Java NIO 编程)的情况下, 网络模块也大多是参考或基于 Reactor 模式实现的. 因为 Reactor 模式可以结合多路复用, 异步调用, 多线程等技术解决高并发, 大流量场景下的网络模块的性能问题.</p> <p>在 Java 技术栈下, 网络编程的核心是 Java NIO. 但为了解决稳定性和开发成本的问题, 建议选择业界成熟的网络框架来实现网络模块, 而不是基于原生的 Java NIO 来实现. 成熟的框架分为成熟的 NIO 框架(如 Netty)和成熟的 RPC 框架(如 gRPC).</p> <p>目前业界主流的消息队列都是基于 Java NIO 和 Netty 实现的. Netty 是网络模块编程的常用选型, 大部分情况下, 可能还是最终选择. 但是 Netty 好用并不意味着所有的 Java 网络编程都必须选择 Java NIO 和 Netty.</p> <p>当需要构建一个组件的网络模块的时候, 要先知道这个组件的<strong>业务特点是什么, 需要解决哪些问题, 再来考虑使用什么技术</strong>. 比如在客户端连接数不多, 并发不高, 流量也很小的场景, 只需要一个简单的网络 Server 就够了, 完全没必要选择 Java NIO 或 Netty 来实现你的网络模块. 随着技术架构的迭代, 基于 RPC 框架的方案也是一个不错的选择.</p> <h5 id="思考题-2"><a href="#思考题-2" class="header-anchor">#</a> 思考题</h5> <blockquote><p>假如你的团队需要开发一款新的消息队列, 你需要完成网络模块的选型开发设计, 你的思考路径是什么?</p></blockquote> <ol><li>你要了解这款消息队<strong>列需要满足什么场景</strong>, 比如消息, 流, IOT 等.</li> <li>理解<strong>目标场景的业务形态</strong>, 比如 IOT 就需要管理大量连接, 消息就需要尽量保证低延时, 流的话就需要考虑吞吐问题等等.</li> <li>根据业务特点<strong>分析出技术架构的瓶颈和难点</strong>.</li> <li>考虑<strong>技术语言的选型问题</strong>, 用哪种语言合适, 比如 Java, Go, Rust, C++等. 这点应该结合技术需要和团队本身的技术栈来思考选择哪种语言.</li> <li>理解这个语言当前网络编程的相关库, 网络库, 网络库框架, 并且调研该语言主流网络编程技巧.</li> <li>基于理解的网络模块编程思想, 结合网络库去实现网络模块.</li> <li>在最后需要设计压测场景, 利用自研或开源的压测工具, 最后完成性能和稳定性验证.</li></ol> <h4 id="_05-存储-消息数据和元数据的存储是如何设计的"><a href="#_05-存储-消息数据和元数据的存储是如何设计的" class="header-anchor">#</a> 05-存储:消息数据和元数据的存储是如何设计的?</h4> <p>今天讲消息队列的存储模块.</p> <p>存储模块作为消息队列高吞吐, 低延时, 高可靠特性的基础保证, 可以说是最核心的模块. 从技术架构的角度来看, 存储模块包含 <strong>功能实现和性能优化</strong> 两个方面, 今天先聊存储模块的功能设计和实现.</p> <p>上节讲过, 存储模块的主流程是<strong>数据的写入, 存储, 读取, 过期</strong>. 读写, 持久化存储是基本功能, 但因为消息队列独有的产品特性, 主要被用来当缓冲分发, 它的数据存储是临时的, 数据持久化存储后, 在一定的时间或操作后, 需要能自动过期删除.</p> <p>那对于消息队列这样有特殊需求的存储模块, 在实现功能的时候要注意哪些事情呢? 带着这个问题开始今天的学习.</p> <p>首先, 一个前置信息要清楚, 消息队列中的数据一般分为 <strong>元数据和消息数据</strong>. <strong>元数据是指 Topic, Group, User, ACL, Config 等集群维度的资源数据信息, 消息数据指客户端写入的用户的业务数据</strong>. 下面先来看元数据信息的存储.</p> <h5 id="元数据信息的存储"><a href="#元数据信息的存储" class="header-anchor">#</a> 元数据信息的存储</h5> <p><mark><strong>元数据信息的特点是数据量比较小, 不会经常读写, 但是需要保证数据的强一致和高可靠, 不允许出现数据的丢失</strong></mark>. 同时, 元数据信息一般需要通知到所有的 Broker 节点, Broker 会根据元数据信息执行具体的逻辑. 比如创建 Topic 并生成元数据后, 就需要通知对应的 Broker 执行创建分区, 创建目录等操作.</p> <p>所以元数据信息的存储, 一般有两个思路.</p> <ul><li>基于<strong>第三方组件</strong>来实现元数据的存储.</li> <li>在<strong>集群内部</strong>实现元数据的存储.</li></ul> <p><strong>基于第三方组件来实现元数据的存储是目前业界的主流选择</strong>. 比如 Kafka ZooKeeper 版本, Pulsar, RocketMQ 用的就是这个思路, 其中 <strong>Kakfa 和 Pulsar 的元数据存储在 ZooKeeper 中, RocketMQ 存储在 NameServer 中(准确说是存储在 Broker + NameServer 中, 后面会详细说明)</strong> .</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3d1f0787356054efb7fcc7806a5c7a93-20240421231949-43kigyd.jpg" alt="">​</p> <p>这个方案最大的优点是<strong>集成方便, 开发成本低, 能满足消息队列功能层面的基本要求</strong>, 因为可以直接复用第三方组件已经实现的一致性存储, 高性能的读写和存储, Hook 机制等能力, 而且在后续集群构建中也可以复用这个组件, 能极大降低开发难度和工作成本.</p> <p>但也有缺点. 引入第三方组件会增加<strong>系统部署和运维的复杂度</strong>, 而且第三方组件自身的稳定性问题会增加系统风险, 第三方组件和多台 Broker 之间可能会出现数据信息不一致的情况, 导致读写异常.</p> <p><strong>另一种思路,</strong> <strong>集群内部实现元数据的存储是指在集群内部完成元数据的存储和分发</strong>. 也就是在集群内部实现类似第三方组件一样的元数据服务, 比如<strong>基于 Raft 协议实现内部的元数据存储模块或依赖一些内置的数据库</strong>. 目前 Kafka 去 ZooKeeper 的版本, RabbitMQ 的 Mnesia, Kafka 的 C++版本 RedPanda 用的就是这个思路.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3411d5e9b57efebf403edc06cd2488b6-20240421231949-62w6gez.jpg" alt="">​</p> <p>这个方案的优缺点跟第一个正好相反. <strong>优点是部署和运维成本低, 不会因为依赖第三方服务导致稳定性问题, 也不会有数据不一致的问题. 但缺点是开发成本高, 前期要投入大量的开发人力</strong>.</p> <p>总的来说, 当前主流选择第一种方案, 主要是出于开发成本考虑.</p> <p>用第三方组件导致的稳定性问题, 大部分可以通过后期的运维, 运营, 编码技巧来解决规避或降低发生频率, 但如果前期开发成本太大, 架构太复杂, 会影响项目的成型和业务的使用. 所以在项目前期, 大部分都会选择这个方案.</p> <p>如果消息队列核心架构已成熟或者前期允许有较大投入, 才会建议选择第二种方案. 因为第一种方案虽然开发成本较低, 但其使用成本, 机器资源成本, 运维成本还是偏高, 另外, 一些稳定性问题, 比如元数据不一致, 因为第三方组件的存在是无法根治的, 会有长久的隐患.</p> <h5 id="消息数据的存储"><a href="#消息数据的存储" class="header-anchor">#</a> 消息数据的存储</h5> <p>了解了元数据, 接下来讲<strong>消息数据的存储</strong>. 一般情况下, 消息队列的存储主要是指消息数据的存储, 分为<mark><strong>存储结构, 数据分段, 数据存储格式, 数据清理</strong></mark>四个部分.</p> <h6 id="数据存储结构设计"><a href="#数据存储结构设计" class="header-anchor">#</a> 数据存储结构设计</h6> <p>先看数据存储目录结构设计. 在消息队列中, 跟存储有关的主要是 <strong>Topic 和分区两个维度</strong>. 用户可以将数据写入 Topic 或直接写入到分区.</p> <p>不过如果写入 Topic, 数据也是分发到多个分区去存储的. 所以从实际数据存储的角度来看, <strong>Topic 和 Group 不承担数据存储功能, 承担的是逻辑组织的功能, 实际的数据存储是在在分区维度完成的</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9b91e1ab61c5c2c92a0e12d4ea0438a1-20240421231949-tx3cohu.jpg" alt="">​</p> <p>从技术架构的角度, 数据的落盘存储也有两个思路.</p> <ul><li><strong>每个分区单独一个存储 &quot;文件&quot;</strong> .</li> <li><strong>每个节点上所有分区的数据都存储在同一个 &quot;文件&quot;</strong> .</li></ul> <p>特别说明下, 这里的 &quot;文件&quot; 是一个虚指, 即表示所有分区的数据是存储在一起, 还是每个分区的数据分开存储的意思. 在实际的存储中, 这个 &quot;文件&quot; 通常以<strong>目录的形式存在, 目录中会有多个分段文件</strong>. 接下来讲到的文件都是表示这个意思.</p> <p><strong>第一个思路, 每个分区对应一个文件的形式去存储数据</strong>. 具体实现时, 每个分区上的数据顺序写到同一个磁盘文件中, 数据的存储是连续的. 因为消息队列在大部分情况下的<strong>读写是有序</strong>的, 所以<strong>这种机制在读写性能上的表现是最高的</strong>.</p> <p>但如果分区太多, 会占用太多的系统 FD 资源, 极端情况下有可能把节点的 FD 资源耗完, 并且硬盘层面会出现大量的随机写情况, 导致写入的性能下降很多, 另外管理起来也相对复杂. Kafka 在存储数据的组织上用的就是这个思路.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/b6yyc4b63b2794e877995c756000d371-20240421231949-avnkjyr.jpg" alt="">​</p> <p>具体的磁盘的组织结构一般有 &quot;目录+分区二级结构&quot; 和 &quot;目录+分区一级结构&quot; 两种形式. 不过从技术上来看, 没有太大的优劣区别.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>目录+分区二级结构: 
├── topic1
│   ├── partrt0
│   ├── 1
│   └── 2
└── topic2
    ├── 0
    ├── 1

 目录+分区一级结构: 
├── topic1-0
├── topic1-1
├── topic1-2
├── topic2-0
├── topic2-1
└── topic2-2

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p><strong>第二种思路, 每个节点上所有分区的数据都存储在同一个文件中, 这种方案需要为每个分区维护一个对应的索引文件, 索引文件里会记录每条消息在 File 里面的位置信息, 以便快速定位到具体的消息内容</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4e0ebbf928847bf60b3fd642ae654e0a-20240421231949-cv3732y.jpg" alt="">​</p> <p>因为 <strong>所有文件都在一份文件上, 管理简单, 也不会占用过多的系统 FD 资源, 单机上的数据写入都是顺序的, 写入的性能会很高</strong>. 缺点是同一个分区的数据一般会在文件中的不同位置, 或者不同的文件段中, 无法利用到顺序读的优势, 读取的性能会受到影响, 但是随着 SSD 技术的发展, 随机读写的性能也越来越高. 如果使用 SSD 或高性能 SSD, 一定程度上可以缓解随机读写的性能损耗, 但 SSD 的成本比机械硬盘高很多.</p> <p><strong>目前 RocketMQ, RabbitMQ 和 Pulsar 的底层存储 BookKeeper 用的就是这个方案</strong>.</p> <p>这种方案的数据组织形式一般是这样的. 假设这个统一的文件叫 <strong>commitlog</strong>, 则 commitlog 就是用来存储数据的文件,  <mark><strong>.index 是每个分区的索引信息</strong></mark>.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>.
├── commitlog
├── topic-0.index
├── topic-1.index
└── topic-2.index
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>那怎么选择呢? <strong>核心考虑是你对读和写的性能要求.</strong></p> <ul><li>第一种方案, 单个文件读和写都是顺序的, 性能最高. 但是当<strong>文件很多且都有读写的场景下</strong>, 硬盘层面就会退化为随机读写, 性能会严重下降.</li> <li>第二种方案, 因为只有一个文件, 不存在文件过多的情况, 写入层面一直都会是顺序的, 性能一直很高. 但是在消费的时候, 因为多个分区数据存储在同一个文件中, 同一个分区的数据在底层存储上是不连续的, 硬盘层面会出现随机读的情况, 导致读取的性能降低.</li></ul> <p>不过随机读带来的性能问题, 可以通过给底层配备高性能的硬件来缓解. 所以<strong>当前比较多的消息队列选用的是第二种方案, 但是 Kafka 为了保证更高的吞吐性能, 选用的是第一种方案</strong>.</p> <blockquote><p>关于 FD 的占用问题. Linux 上的 FD 数是可以配置的, 比如配置几十万个 FD 没问题, 所以我们一般不会用完系统的 FD 限制, 这一点在实际的落地中不需要太担心.</p></blockquote> <p>但是不管是方案一还是方案二, 在数据存储的过程中, 如果单个文件过大, 在文件加载, 写入和检索的时候, 性能就会有问题, 并且消息队列有自动过期机制, 如果单个文件过大, 数据清理时会很麻烦, 效率很低. 所以, 消息数据都会分段存储.</p> <h6 id="消息数据的分段实现"><a href="#消息数据的分段实现" class="header-anchor">#</a> 消息数据的分段实现</h6> <p><strong>数据分段的规则一般是根据大小来进行的, 比如默认 1G 一个文件, 同时会支持配置项调整分段数据的大小</strong>. 看数据目录中的文件分段示意图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1cb88018d4yy166ecd477c766ce66a13-20240421231949-2389kpe.jpg" alt="">​</p> <p>从技术上来看, 当数据段到达了规定的大小后, 就会新创建一个新文件来保存数据.</p> <p>如果进行了<strong>分段</strong>, 消息数据可能分布在不同的文件中. 所以我们在读取数据的时候, 就需要先定位消息数据在哪个文件中. 为了满足这个需求, 技术上一般有 <strong>根据偏移量定位或根据索引定位</strong> 两种思路.</p> <p><strong>根据偏移量(Offset)来定位消息在哪个分段文件中, 是指通过记录每个数据段文件的起始偏移量, 中止偏移量, 消息的偏移量信息, 来快速定位消息在哪个文件</strong>.</p> <p>当消息数据存储时, 通常会用一个自增的数值型数据(比如 Long)来表示这条数据在分区或 commitlog 中的位置, 这个值就是消息的偏移量.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/17ecbd8a23fc6d5ba185e21f78bb00c5-20240421231949-6jljesm.jpg" alt="">​</p> <p>在实际的编码过程中, 记录文件的起始偏移量一般有两种思路: <strong>单独记录每个数据段的起始和结束偏移量</strong>, 在文件名称中携带起始偏移量信息. 因为数据是顺序存储的, 每个文件记录了本文件的起始偏移量, 那么下一个文件的起始偏移量就是上一个文件的结束偏移量.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1e87141d2f9e052d5b4a68cdff738cd0-20240421231949-rgimtca.jpg" alt="">​</p> <p>如果用<strong>索引定位</strong>, 会直接存储消息对应的文件信息, 而不是通过偏移量来定位到具体文件.</p> <p>具体是通过<strong>维护一个单独的索引文件, 记录消息在哪个文件和文件的哪个位置. 读取消息的时候, 先根据消息 ID 找到存储的信息, 然后找到对应的文件和位置, 读取数据. RabbitMQ 和 RocketMQ 用的就是这个思路</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/24ebd2bc36905901fdd95eac868a062d-20240421231949-qz7lr4v.jpg" alt="">​</p> <p><strong>这两种方案所面临的场景不一样</strong>. 根据偏移量定位数据, 通常用在每个分区各自存储一份文件的场景; 根据索引定位数据, 通常用在所有分区的数据存储在同一份文件的场景. 因为在前一种场景, 每一份数据都属于同一个分区, 那么通过位点来二分查找数据的效率是最高的. 第二种场景, 这一份数据属于多个不同分区, 则通过二分查找来查找数据效率很低, 用哈希查找效率是最高的.</p> <p>接下来继续看消息数据的存储格式, 看看每行记录长什么样子, 都存储了哪些信息.</p> <h6 id="消息数据存储格式"><a href="#消息数据存储格式" class="header-anchor">#</a> 消息数据存储格式</h6> <p>消息数据存储格式一般包含<strong>消息写入文件的格式和消息内容的格式</strong>两个方面.</p> <p><strong>消息写入文件的格式指消息是以什么格式写入到文件中的</strong>, 比如 JSON 字符串或二进制. 从性能和空间冗余的角度来看, 消息队列中的数据基本都是以<mark><strong>二进制的格式</strong></mark>写入到文件的. 这部分二进制数据, 不能直接用 vim/cat 等命令查看, 需要用专门的工具读取, 并解析对应的格式.</p> <p>比如, 想查看 Kafka 消息数据存储文件中的数据, 如果用 cat 命令查看是乱码, 用日志解析工具 kafka.tools.DumpLogSegments 查看, 才是格式化的数据.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code># cat 00000000000000000000.log
&gt;f0z�sl{]�sl{���������������xlobo

# kafka-run-class.sh  kafka.tools.DumpLogSegments --files 00000000000000000000.log --print-data-log

baseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 LogAppendTime: 1681268702091 size: 74 magic: 2 compresscodec: NONE crc: 1714453217 isvalid: true
| offset: 0 LogAppendTime: 1681268702091 keysize: 2 valuesize: 4 sequence: -1 headerKeys: [] key: xu payload: lobo
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>消息内容的格式是指写入到文件中的数据都包含哪些信息</strong>. 对于一个成熟的消息队列来说, 消息内容格式不仅关系功能维度的扩展, 还牵涉性能维度的优化.</p> <p>如果消息格式设计得不够精简, 功能和性能都会大打折扣. 比如冗余字段会增加分区的磁盘占用空间, 使存储和网络开销变大, 性能也会下降. 如果缺少字段, 则可能无法满足一些功能上的需要, 导致无法实现某些功能, 又或者是实现某些功能的成本较高.</p> <p>所以, 在数据的存储格式设计方面, <strong>内容的格式需要尽量完整且不要有太多冗余</strong>.</p> <p>听起来有点抽象, 下面分析一下 Kafka 和 RocketMQ 的消息内容格式设计, 让你对具体的数据存储格式有更直观的感受.</p> <p>以一个具体的消息内容截图为例, 看看 Kakfa 的 V2 版本存储格式的内容.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2ed471618360416bb4ba331eb5e092c9-20240421231949-hsh3g5z.png" alt="">​</p> <p>看每个字段的含义.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/33d8678yy6b75b7663d6abcaf6d00404-20240421231949-fqrjmhl.jpg" alt="">​</p> <p>可以看到, Kafka 的消息内容包含了业务会感知到的消息的 <strong>Header, Key, Value, 还包含了时间戳, 偏移量, 协议版本, 数据长度和大小, 校验码等基础信息, 最后还包含了压缩, 事务, 幂等 Kafka 业务相关的信息</strong>.</p> <p>特别说明, 因为 Kafka 支持 Batch 特性, 所以消息格式中还包含 base 和 last 等 Batch 相关信息.</p> <p>再看 RocketMQ 的存储格式的内容.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a797510810aeb878c11de7ab70e5d787-20240421231949-58mqduf.png" alt="">​</p> <p>看每个字段的含义.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4ccc5bfbbab55cd7486de0a87eca9yy3-20240421231949-1rmavlp.jpg" alt="">​</p> <p>RocketMQ 的存储格式中也包含基础的 <strong>Properties</strong>(相当于 Kafka 中的 Header), Value, 时间戳, 偏移量, 协议版本, 数据长度和大小, 校验码等信息, 还包含了系统标记, 事务等 RocketMQ 特有的信息, 另外还包含了数据来源和数据目标的节点信息.</p> <p>对比看, 消息数据的存储格式虽然没有统一的规范, 但是一般包含<strong>通用信息和业务信息</strong>两部分. 通用信息主要包括时间戳, CRC, 消息头, 消息体, 偏移量, 长度, 大小等信息, 业务信息主要跟业务相关, 包含事务, 幂等, 系统标记, 数据来源, 数据目标等信息.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a8ea54c1c6f1585ebab42b4a326a2767-20240421231949-7gqsmlb.jpg" alt="">​</p> <p>前面讲过, 消息队列的数据在持久化存储后, 需要在一定策略后<strong>自动过期删除</strong>. 那<strong>消息队列的数据过期机制如何实现呢</strong>?</p> <h6 id="消息数据清理机制"><a href="#消息数据清理机制" class="header-anchor">#</a> 消息数据清理机制</h6> <p>消息队列中的数据最终都会删除, 时间周期短的话几小时, 甚至几分钟, 正常情况一天, 三天, 七天, 长的话可能一个月, 基本很少有场景需要在消息队列中存储一年的数据.</p> <p>消息队列的数据过期机制一般有<strong>手动删除和自动删除</strong>两种形式, 从实现上看主要有三种思路.</p> <ul><li><strong>消费完成执行 ACK 删除数据</strong></li> <li><strong>根据时间和保留大小删除</strong></li> <li><strong>ACK 机制和过期机制相结合</strong></li></ul> <p><strong>消费完成执行 ACK 删除数据, 技术上的实现思路一般是</strong>: 当客户端成功消费数据后, 回调服务端的 ACK 接口, 告诉服务端数据已经消费成功, 服务端就会<strong>标记删除该行数据, 以确保消息不会被重复消费</strong>. ACK 的请求一般会有单条消息 ACK 和批量消息 ACK 两种形式.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1ab659d29a236b11yy55a834yy663410-20240421231949-1fytvtn.jpg" alt="">​</p> <p>因为消息队列的 ACK 一般是顺序的, 如果前一条消息无法被正确处理并 ACK, 就无法消费下一条数据, 导致消费卡住. 此时就需要死信队列的功能, 把这条数据先写入到死信队列, 等待后续的处理. 然后 ACK 这条消息, 确保消费正确进行.</p> <p>这个方案, 优点是不会出现重复消费, 一条消息只会被消费一次. 缺点是 ACK 成功后消息被删除, <strong>无法满足需要消息重放的场景</strong>.</p> <p><strong>根据时间和保留大小删除指消息在被消费后不会被删除, 只会通过提交消费位点的形式标记消费进度</strong>.</p> <p>实现思路一般是<strong>服务端提供偏移量提交的接口, 当客户端消费成功数据后, 客户端会回调偏移量提交接口, 告诉服务端这个偏移量的数据已经消费成功了, 让服务端把偏移量记录起来</strong>. 然后服务端会根据消息保留的策略, 比如保留时间或保留大小来清理数据. 一般通过一个常驻的异步线程来清理数据.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/772a4735742ec4e89bb031fe84d08fc8-20240421231949-p0hv0gl.jpg" alt="">​</p> <p>这个方案, 一条消息可以重复消费多次. 不管有没有被成功消费, 消息都会根据配置的时间规则或大小规则进行删除. 优点是消息可以多次重放, 适用于需要多次进行重放的场景. 缺点是在某些情况下(比如客户端使用不当)会出现大量的重复消费.</p> <p>结合前两个方案, 就有了 <strong>ACK 机制和过期机制相结合的方案</strong>. 实现核心逻辑跟方案二很像, 但保留了 ACK 的概念, 不过 ACK 是相对于 Group 概念的.</p> <p><strong>当消息完成后, 在 Group 维度 ACK 消息, 此时消息不会被删除, 只是这个 Group 也不会再重复消费到这个消息, 而新的 Group 可以重新消费订阅这些数据. 所以在 Group 维度避免了重复消费的情况, 也可以允许重复订阅</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/17d26f435043399134305b93f3fe1835-20240421231949-0iac8sj.jpg" alt="">​</p> <p>纵观业界主流消息队列, 三种方案都有在使用, <strong>RabbitMQ 选择的是第一个方案, Kafka 和 RocketMQ 选择的是第二种方案, Pulsar 选择的是第三种方案</strong>. 不同消息队列的方案选择, 主要都是考虑架构设计和组件开发时业务场景的影响. 个人觉得第三种比较合理.</p> <p>前面虽然反复提到 &quot;删除&quot;, 但数据实际怎么删除也有讲究.</p> <p>消息数据是顺序存储在文件中的, 会有很多分段数据, 一个文件可能会有很多行数据. 那么在 ACK 或者数据删除的时候, 一个文件中可能既存在可删除数据, 也存在不可删除数据. 如果每次都立即删除数据, 需要不断执行 &quot;读取文件, 找到记录, 删除记录, 写入文件&quot; 的过程, 即使批量操作, 降低频率, 还是得不断地重复这个过程, 会导致性能明显下降.</p> <p>当前主流的思路都是 <mark><strong>延时删除, 以段数据为单位清理</strong></mark>, 降低频繁修改文件内容和频繁随机读写文件的操作.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9884d62373887596b694227ef242cfbd-20240421231949-l6j40go.jpg" alt="">​</p> <p>只有该段里面的数据都允许删除后, 才会把数据删除. 而删除该段数据中的某条数据时, 会先对数据进行标记删除, 比如在内存或 Backlog 文件中记录待删除数据, 然后在消费的时候感知这个<strong>标记</strong>, 这样就不会重复消费这些数据.</p> <h5 id="总结-5"><a href="#总结-5" class="header-anchor">#</a> 总结</h5> <p>消息队列的存储分为元数据存储和消息数据存储两方面.</p> <p><strong>元数据的存储主要依赖第三方组件实现, 比如 ZooKeeper, etcd 或者自研的简单元数据存储服务等等</strong>. 在成熟的消息队列架构中, 基于简化架构和提升稳定性的考虑, 都会考虑在集群内部完成元数据的存储和管理.</p> <p>消息数据的存储在功能层面包含<strong>数据存储结构设计, 数据分段存储, 数据存储格式, 数据清理机制</strong>四个方面.</p> <p>消息数据的存储主要包含 <strong>Topic 和分区两个维度</strong>. Topic 起逻辑组织作用, 实际的数据存储是在分区维度完成的. 所以在数据存储目录结构上, 都以分区为最小粒度去设计, 至于选择每个分区单独一个存储文件, 还是将每个节点上所有分区的数据都存储在同一个文件, 方案各有优劣, 可以根据实际情况去选择.</p> <p>因为大文件存在性能和资源占用, 数据清理成本等问题, 一般情况下, 都需要对数据文件进行分段处理, 分段的策略一般都是按照文件大小进行的.</p> <p>数据存储格式可以分为基础信息和业务信息两个维度, 数据格式需要遵循极简原则, 以达到性能和成本的最优.</p> <p>数据的过期策略一般有三种, <strong>ACK 删除, 根据时间和保留大小删除数据, 两者结合</strong>. 目前业界的实现比较多样, 从选择上来看, 两者结合的方案更合理.</p> <h5 id="思考题-3"><a href="#思考题-3" class="header-anchor">#</a> 思考题</h5> <blockquote><p>如果让你从头实现一个消息队列的存储模块, 你的思考路径是什么?</p></blockquote> <ol><li>首先需要想有哪些数据需要存储? 最主要的是不是消息数据?</li> <li>消息数据怎么存呢? 按照 Topic 维度存还是分区维度存呢?</li> <li>如果是分区, 那分区数据怎么存呢? 每个分区一个文件, 还是所有分区存到一个文件. 得去看看业界都是怎么做的, 这两个方案的优劣是什么.</li> <li>数据文件会很大, 可能几个 TB, 几十个 TB, 这些数据是不是需要分段呢? 是的话要怎么分段?</li> <li>如果数据分段了, 要根据什么分段呢? 分段后应该怎么定位到消息内容呢?</li> <li>消息队列的数据都需要清理, 业界一般都有哪些清理机制, 各自的优劣都是啥? 这些清理都是怎么实现的呢?</li></ol> <h4 id="_06-存储-如何提升存储模块的性能和可靠性"><a href="#_06-存储-如何提升存储模块的性能和可靠性" class="header-anchor">#</a> 06-存储:如何提升存储模块的性能和可靠性?</h4> <p>上一节讲了消息队列存储模块的功能实现, 今天来讲<strong>存储模块的性能优化</strong>.</p> <p>存储模块的性能优化, 核心要解决的其实就是两个问题:  <strong>&quot;写得快&quot; 和 &quot;读得快&quot;</strong> . 这两个问题如何解决呢? 从四点和存储性能优化有关的基础理论讲起.</p> <ul><li><strong>内存读写的效率高于硬盘读写</strong></li> <li><strong>批量读写的效率高于单条读写</strong></li> <li><strong>顺序读写的效率高于随机读写</strong></li> <li><strong>数据复制次数越多, 效率越低</strong></li></ul> <h5 id="提升写入操作的性能"><a href="#提升写入操作的性能" class="header-anchor">#</a> 提升写入操作的性能</h5> <p>上一节讲到, 消息队列的数据最终是存储在文件中的, 数据写入需要经过内存, 最终才到硬盘, 所以写入优化就得围绕 <strong>内存和硬盘</strong> 展开. 写入性能的提高主要有<strong>缓存写, 批量写, 顺序写</strong>三个思路, 这里对比来讲.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fbcdcb4b79bb26755a7ec015561aef8c-20240421231949-gcm3ghq.jpg" alt="">​</p> <h6 id="_1-缓存写和批量写"><a href="#_1-缓存写和批量写" class="header-anchor">#</a> 1.缓存写和批量写</h6> <p>在计算机理论基础中, 计算机多级存储模型的层级越高, 代表速度越快(同时容量也越小, 价格也越贵), 也就是说写入速度从快到慢分别是: <strong>寄存器 &gt; 缓存 &gt; 主存 &gt; 本地存储 &gt; 远程存储</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1301ac45580086ef1bf13fbaa21381bc-20240421231949-12pjys0.jpg" alt="">​</p> <p>所以基于理论 1 和 2:</p> <ul><li>内存读写的效率高于硬盘读写</li> <li>批量读写的效率高于单条读写</li></ul> <p>写入优化的主要思路之一是: <strong>将数据写入到速度更快的内存中, 等积攒了一批数据, 再批量刷到硬盘中</strong>.</p> <p>平时在一些技术文章看到的 &quot;<mark><strong>数据先写入 PageCache, 再批量刷到硬盘</strong></mark>&quot;, 说的就是这个思路. <strong>PageCache 指操作系统的页缓存, 简单理解就是内存, 通过缓存读写数据可以避免直接对硬盘进行操作, 从而提高性能</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/77b396170d405d0bf82b489781yyd276-20240421231949-2c4t0wg.jpg" alt="">​</p> <p><strong>具体来说就是把硬盘中的数据缓存到内存中, 这样对硬盘的访问就变成了对内存的访问. 然后再通过一定的策略, 把缓存中的数据刷回到硬盘</strong>. 一般情况下, 内存数据是自动批量刷到硬盘的, 这个逻辑对应用是透明的.</p> <p>把缓存数据刷回到硬盘, 一般有 &quot;<strong>按照空间占用比例</strong>&quot;, &quot;<strong>时间周期扫描</strong>&quot; 和 &quot;手动强制刷新&quot; 三种策略. <strong>操作系统内核提供了前两种处理策略</strong>, 不需要应用程序感知. 下面具体了解一下.</p> <p><strong>按空间占用比例刷新</strong> 是指当系统内存中的 &quot;脏&quot; 数据大于某个阈值时会将数据刷新到硬盘. 操作系统提供了两个配置项.</p> <ul><li>&quot;脏&quot; 数据在内存中的<strong>占比</strong>(dirty_background_ratio)</li> <li>&quot;脏&quot; 数据的绝对的<strong>字节数</strong>(dirty_background_bytes)</li></ul> <p><strong>当这两个配置超过阈值, 就会触发刷新操作</strong>. 如果两者同时设置, 则以绝对字节数为更高优先级.</p> <p><strong>按时间周期刷新</strong> 是指根据配置好的时间, 周期性刷新数据到硬盘. 主要通过脏页存活时间(dirty_expire_seconds) 和刷新周期(dirty_writeback_centisecs)两个参数来配置. 两个配置默认都是1/100, 也就说时间间隔为每秒 100 次, 根据刷新周期的配置周期性执行刷新, 刷新会检查脏页的存活时间是否超过配置的最大存活时间, 如果是则刷入硬盘.</p> <p>同时, 操作系统也提供了第三种方法 <strong>程序手动强制刷新</strong>, 可以通过系统提供的 <code>sync()/msync()/fsync()</code>​ 调用来强制刷新缓存. 通过操作系统的参数配置, 在 Java 代码中, 通过 Java.NIO 包中 FileChannel 提供的 write() 和 force() 方法, 实现写<strong>缓存和强制刷新缓存</strong>. 代码参考:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">FileChannel</span> channel <span class="token operator">=</span> fin<span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
file<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span>
file<span class="token punctuation">.</span><span class="token function">force</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>通过 FileChannel 提供的 write() 方法写数据时, FileChannel 把数据写入到缓存就会返回成功, 然后依赖操作系统的缓存更新策略, 将数据刷新到硬盘</strong>. 也可以在代码中调用 FileChannel 提供的 force() 方法, 把数据立即刷入刷盘中以免丢失.</p> <p><mark><strong>基本所有的消息队列在写入时用的都是这个方案, 比如 Kafka, RocketMQ, Pulsar 就是先写入缓存, 然后依赖操作系统的策略刷新数据到硬盘</strong></mark>.</p> <p>消息队列一般会同时提供: <strong>是否同步刷盘, 刷盘的时间周期, 刷盘的空间比例三个配置项</strong>, 让业务根据需要调整自己的刷新策略. 从性能的角度看, 异步刷新肯定是性能最高的, 同步刷新是可靠性最高的.</p> <h6 id="_2-随机写和顺序写"><a href="#_2-随机写和顺序写" class="header-anchor">#</a> 2.随机写和顺序写</h6> <p>写入操作的性能优化, 还有最后一条基础理论没用上: <strong>顺序读写的效率高于随机读写</strong>. 这里有两个问题很细节.</p> <p>首先, 要理解顺序写和随机写是针对谁的? 我们所说的都是针对硬盘的, 是整个操作系统和硬盘的关系, 而不是单文件和硬盘的关系.</p> <p>明白了这一点, 看下一个问题, &quot;单文件顺序写入硬盘&quot; 和 &quot;多文件顺序写入硬盘&quot;, 从硬盘的角度看都是顺序读写吗?</p> <p>单文件顺序写入硬盘很简单, 硬盘控制器只需在连续的存储区域写入数据, 对硬盘来讲, 数据就是顺序写入的.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6dbbd839d4a939a7479cb0787fdbed8a-20240421231949-lzikjz1.jpg" alt="">​</p> <p>多文件顺序写入硬盘, 系统中有<strong>很多文件同时写入</strong>, 这个时候从硬盘的视角看, 会发现操作系统同时对多个不同的存储区域进行操作, 硬盘控制器需要同时控制多个数据的写入, 所以从硬盘的角度是随机写的.</p> <blockquote><p>这里的硬盘控制器只是一个抽象, 它包含 CPU 调度, 硬盘驱动, DMA 设备, 写入调度算法等具体底层实现.</p></blockquote> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/73b1524828e269f8f9f57d7169118f93-20240421231949-221wt3x.jpg" alt="">​</p> <p>所以, 在消息队列中, 实现随机写和顺序写的核心就是 <strong>数据存储结构的设计</strong>.</p> <p>上节讲过数据存储结构设计有两个思路: <strong>每个 Partition/Queue 单独一个存储文件, 每台节点上所有 Partition/Queue 的数据都存储在同一个文件</strong>.</p> <p>第一种方案, 对单个文件来说读和写都是顺序的, 性能最高, 但当文件很多且都有读写, 在硬盘层面就会退化为随机读写, 性能会下降很多. 第二种方案, 因为只有一个文件, 不存在文件过多的情况, 写入层面一直都会是顺序的, 性能一直很高. 所以为了提高写的性能, 最好使用第二种方案.</p> <h5 id="提升写入操作的可靠性"><a href="#提升写入操作的可靠性" class="header-anchor">#</a> 提升写入操作的可靠性</h5> <p>因为消息队列基本都采用<strong>数据先写入缓存, 再写入硬盘</strong>的方案, 所以有丢失数据的风险, 比如数据还没刷新到硬盘中时, 机器就异常重启了, 数据就丢失了.</p> <p>为了提高数据可靠性, 在消息队列的存储模块中, 一般会通过三种处理手段: <strong>同步刷盘, WAL 预写日志, 多副本备份, 进一步提升数据的可靠性</strong>.</p> <h6 id="_1-同步刷盘"><a href="#_1-同步刷盘" class="header-anchor">#</a> 1.同步刷盘</h6> <p><strong>同步刷盘指每条数据都同步刷盘, 等于回到了直接写硬盘的逻辑, 一般通过写入数据后调用 force() 操作来完成数据刷盘</strong>. 这种方案无法利用内存写入速度的优势, 效率会降低很多.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/73157d635d126aeb23346f29b35758b4-20240421231949-rjcp1im.jpg" alt="">​</p> <p><strong>一般消息队列都会开放这个配置项, 默认批量刷盘, 但有丢失数据的风险</strong>. 如果业务需要修改为直接刷盘的策略来提高数据的可靠性, 则会有一定的性能降低. 至于如何提高同步刷盘的性能, 后面还会展开细讲.</p> <h6 id="_2-wal"><a href="#_2-wal" class="header-anchor">#</a> 2.WAL</h6> <p><strong>WAL(预写日志)指在写数据之前先写日志, 当出现数据丢失时通过日志来恢复数据, 避免数据丢失</strong>.</p> <p>讲到这里, 估计有同学有疑问了, WAL 日志需要写入持久存储, 业务数据也要写入缓存, 多了一步, 性能会不会降低呢?</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/277100c7c4155fd6074ee6a068652f8d-20240421231949-x581bs6.jpg" alt="">​</p> <p>没错, 从理论来看, WAL 机制肯定会比直接写入缓存中的性能低. 但实际落地的时候往往可以通过一些手段来优化, 降低影响, 达到性能要求.</p> <p>因为在消息队列中, 消息数据的数据量是非常大的, 不可能直接使用非常高性能的持久存储设备, 成本太高. 虽然 WAL 日志需要极高的写入性能, 但是数据量一般很小, 而且是可顺序存储的, 可预测的(根据配置的缓存大小和更新策略可明确计算).</p> <p>所以 <strong>在实际落地中, 可以采取 WAL 日志盘和实际数据盘分离的策略, 提升 WAL 日志的写入速度</strong>. 具体就是让 WAL 数据盘是高性能, 低容量的数据盘, 数据盘是性能较低, 容量较大的数据盘, 如果出现数据异常, 就通过 WAL 日志进行数据恢复. 这样给 WAL 日志选择合适的设备, 再加上并行读写等代码优化手段, 性能损失就可控了, 甚至可以忽略.</p> <p>不过, 这个方案也有缺点, 在实际部署运维过程中, 需要单独给 WAL 日志分配高性能的数据盘并进行相关处理配置, 运维成本相对较高. 但强制刷盘, WAL 预写日志这两种方案, 都是指<strong>单机维度</strong>的可靠性保证. 而在实际运维过程中, 单机是不可靠的, 都需要通过分布式的多副本存储来保证数据的高可靠, 也就有了第三种方案.</p> <h6 id="_3-多副本的备份"><a href="#_3-多副本的备份" class="header-anchor">#</a> 3.多副本的备份</h6> <p><mark><strong>多副本的备份就是将数据拷贝到多台节点, 每台节点都写入到内存中, 从而完成数据的可靠性存储</strong></mark>. 因为单机层面也是把数据写入到内存中就记录写入成功, <strong>单机层面也可能出现数据丢失, 所以核心思路是同时在多台节点中缓存数据, 只要不是多台节点同时重启, 数据就可以恢复</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/14d282ecd3cae4a3895a6f84f99dbdf1-20240421231949-p5om00k.jpg" alt="">​</p> <p>好处是可以在分布式存储的基础上做优化, <strong>通过多台缓存的手段来降低数据丢失的概率</strong>. 但是如果所有节点在同一时刻重启, 数据还是有可能丢失的, 无法保证百分百的数据高可靠.</p> <p>从消息队列业界的存储方案来看, 方案一所有产品都会支持, 方案二和方案三一般会选一种支持, Kakfa, RabbitMQ, RocketMQ 用的是第三种, Pulsar 用的是第二种.</p> <p>接下来看如何提升读取操作的性能.</p> <h5 id="提升读取操作的性能"><a href="#提升读取操作的性能" class="header-anchor">#</a> 提升读取操作的性能</h5> <p>提高读取的性能主要有<strong>读热数据, 顺序读, 批量读, 零拷贝</strong>四个思路.</p> <h6 id="_1-冷读和热读"><a href="#_1-冷读和热读" class="header-anchor">#</a> 1.冷读和热读</h6> <p>经过写优化后, 数据先经过内存缓存, 再批量刷到硬盘上, 而且根据消息队列的特性, 数据都是单分区顺序读写的. 所以在读取数据的时候, 有<strong>冷读和热读</strong>两种场景.</p> <p><strong>热读是指消息数据本身还在缓存中, 读取数据是从内存中获取, 此时性能最高, 不需要经过硬盘. 冷读是指消息数据刷到硬盘中了, 并且数据已经被换页换出缓存了, 此时读取数据需要从硬盘读取</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f06da30e248cb19e19b87be271d4375b-20240421231949-2faczxz.jpg" alt="">​</p> <p>Java 中使用代码实现读缓存很简单, 只需要使用 Java.NIO 包中的 FileChannel.read 数据.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">ByteBuffer</span> buffer <span class="token operator">=</span> <span class="token class-name">ByteBuffer</span><span class="token punctuation">.</span><span class="token function">allocate</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> byteRead <span class="token operator">=</span> channel<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>理想情况, 肯定全部是热读最好, 因为性能最高. 但是在代码层面, 是无法控制冷读或热读的, 只能通过<strong>配置更大的内存, 尽量保证缓存中保留更多的数据, 从而提高热读的概率</strong>.</p> <h6 id="_2-顺序读-随机读-批量读"><a href="#_2-顺序读-随机读-批量读" class="header-anchor">#</a> 2.顺序读,随机读,批量读</h6> <p>为了实现大吞吐, 在消费的时候服务端都会支持批量读的能力. 为了能尽快返回数据给客户端, 服务端都会实现数据的<strong>预读机制</strong>. 在读取数据的时候, 也读取客户下一步可能会用的数据, 预先加载到内存中, 以便更快返回数据.</p> <p>数据的预读分为两种: 硬盘层面预读, 应用程序的预读.</p> <p>硬盘层面的预读, 是在连续的地址空间中读取数据. <strong>但具体实现, 在程序中无法控制, 这和数据目录存储结构设计有关</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bc73ea61da11b845c5701eef7561c93f-20240421231949-263437r.jpg" alt="">​</p> <p>之前讲了两种数据存储目录结构设计. 方案一在读取的过程中, 因为数据是<strong>连续存储</strong>的, 数据预读非常方便, 只要在硬盘上读取连续的数据块即可, 不需要在程序上做逻辑处理, 性能最高.</p> <p>方案二需要根据分区上的数据索引, 在具体存储文件的不同位置读取数据. 数据可能是连续的, 也可能是不连续的. 这种情况下硬盘的<strong>预读就很有随机性</strong>, 大部分情况下在硬盘看来就是随机读. 性能比第一种方案低.</p> <p>应用程序的预读就比较简单, 一般通过程序中的逻辑关系, <strong>提前通过调度去硬盘读取数据</strong>(可能是连续的也可能是不连续的). 因为消息队列的数据是分区有序的, 当读取到某条数据时, 手动读取后面的一个批次的数据就可以了. 这种方案需要程序去控制, 比如 read(0) 时, 要同时读 read(1,10) 的数据, 相对繁琐, 并且性能较低.</p> <p>对比来看, 理想情况下, 肯定是<strong>硬盘层面的顺序预读的性能最高</strong>, 所以针对读取操作, 方案一更合适.</p> <h6 id="_3-零拷贝原理和使用方式"><a href="#_3-零拷贝原理和使用方式" class="header-anchor">#</a> 3.零拷贝原理和使用方式</h6> <p>零拷贝这个词你肯定很熟悉, 但具体是什么含义可能很难说上来. 用一张流程图来理解, 看从硬盘读取数据并发送给网卡的过程.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/80ecda9234bcc260018618a578ea6cd7-20240421231949-58r94e9.jpg" alt="">​</p> <p>如上图所示, 在正常读取数据的过程中, 数据要经过五步, <mark><strong>硬盘 -&gt; ReadBuffer -&gt; 应用程序 -&gt; SocketBuffer -&gt; 网卡设备, 四次复制</strong></mark>. 因为数据在复制过程耗费资源和时间, 会降低性能, 所以优化流程最重要的是减少数据复制的次数和资源损耗.</p> <p>值得注意的是, <strong>零拷贝指的是数据在内核空间和用户空间之间的拷贝次数, 即图中的第 2 步和第 3 步</strong>. 如果只有 1 和 4 两步, 没有执行 2 和 3 的话, 那么内核空间和用户空间之间的拷贝次数就是零, &quot;零拷贝&quot; 的零指的是这个次数 &quot;零&quot;, 因此是零拷贝.</p> <p>为了解决复制次数带来的性能损耗, &quot;零拷贝&quot; 这个概念就被提出来了. <strong>主要思路是通过减少数据复制次数, 减少上下文(内核态和用户态)切换次数, 通过 DMA(直接内存)代替 CPU 完成数据读写, 来解决复制和资源损耗的问题</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ab6480e91f47f254dd11505c522d3ed7-20240421231949-55ty3eb.jpg" alt="">​</p> <p>图中红色的线, 就是通过零拷贝相关技术优化后的效果.</p> <ul><li>将数据复制链路缩短成了: <mark><strong>硬盘 -&gt; ReadBuffer -&gt; 网卡设备, 复制次数从四次减为两次</strong></mark>.</li> <li>用户空间和内核空间之间的数据复制需要进行上下文切换, 优化完复制链路后, 数据只在内核空间复制传输, 就可以减少两次上下文切换.</li> <li><mark><strong>通过 DMA 来搬运数据, 使数据复制不需要通过 CPU, 释放 CPU</strong></mark>. DMA 全称是直接内存存取. 简单理解就是在 IO 设备和内存之间传递数据时, 数据搬运工作全部交给 DMA 控制器, CPU 不再参与任何与数据搬运相关的事情, 这样 CPU 就可以去处理别的事务, 从而释放 CPU.</li></ul> <p>零拷贝主要用于在消费的时候提升性能, 具体有两种实现方式: <strong>mmap+write 和 sendfile</strong>.</p> <p><strong>mmap 是一种内存映射文件的方法, 把文件或者其他对象映射到进程的地址空间, 修改内存文件也会同步修改, 这样就减少了一次数据拷贝</strong>. 所以, 不需要把数据拷贝到用户空间, 修改后再回写到内核空间.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fe2405cfbbd7e75ec8e970ec719e2ebd-20240421231949-vc1jn9d.jpg" alt="">​</p> <p>正常的 &quot;读取数据并发送&quot; 流程是通过 read + write 完成的, 比如:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>read(file, tmp_buf, len);
write(socket, tmp_buf, len);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>而操作系统层面的 read(), 系统在调用的过程中, 会把内核缓冲区的数据拷贝到用户的缓冲区里, 为了减少这一步开销, 可以<strong>用 mmap() 替换 read() 系统调用函数</strong>. 比如:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>buf = mmap(file, len);
write(sockfd, buf, len);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>在 Java 代码中, 实现 mmap 的方法很简单, 使用 Java NIO 包的 FileChannel 的 map 方法即可.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">FileChannel</span> fc <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">MappedByteBuffer</span> buf <span class="token operator">=</span> fc<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">FileChannel<span class="token punctuation">.</span>MapMode</span><span class="token punctuation">.</span><span class="token constant">READ_WRITE</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>另外一种实现思路 <strong>sendfile</strong>, 是指 Linux 内核提供的一个<strong>系统调用 sendfile()</strong> , 它可以<strong>将数据从一个文件描述符传输到另一个文件描述符</strong>. 之前图中的红色线路就是通过 senfile 系统调用和 DMA 技术, 将四次的数据复制次数变为了两次, 提高了性能.</p> <p>在 Java 中也可以使用零拷贝技术, 主要是在 NIO FileChannel 类中.</p> <ul><li><strong>transferTo() 方法</strong>: 可以将数据从 FileChannel 直接传输到另外一个 Channel.</li> <li><strong>transferFrom() 方法</strong>: 可以将数据从 Channel 传输到 FileChannel.</li></ul> <p><mark><strong>几乎所有的消息队列在消费时都使用了 sendfile 的调用, 因为它配合 DMA 技术至少可以提升一倍的消费速度</strong></mark>.</p> <h5 id="通过硬件和系统优化提升性能"><a href="#通过硬件和系统优化提升性能" class="header-anchor">#</a> 通过硬件和系统优化提升性能</h5> <p>讲到这里, 前面谈的都是<strong>软件层面</strong>的优化. 但在实际的运营部署中, 性能的提升也得靠硬件的支持. 接下来看如何提升硬件和系统的性能.</p> <p>从硬件和系统优化提升性能的角度, 主要可以通过提升<strong>硬件配置(如内存或硬盘), 配置多盘读写, 配置硬盘阵列</strong>三个手段来提高集群的性能.</p> <h6 id="_1-提升硬件配置"><a href="#_1-提升硬件配置" class="header-anchor">#</a> 1.提升硬件配置</h6> <p>为了提高热度的概率, 直接配备更大的机器内存, 性能提升最明显.</p> <p>另外, 消息队列是一款非常重视 IO 的组件, 使用更快的硬盘 IO 设备, 提高单机的吞吐能力, 也能快速提升性能. 硬盘类型很多, 比如物理机部署下的机械盘, SSD, NVMe SSD, 以及在云环境部署的各种规格的云盘. 核心衡量指标主要有三个: IOPS, 吞吐量, 延时, 这些指标越好, 性能越高.</p> <h6 id="_2-配置多盘读写"><a href="#_2-配置多盘读写" class="header-anchor">#</a> 2.配置多盘读写</h6> <p>系统层面, 可以通过在机器上挂<strong>多块硬盘</strong>提升单机的硬盘吞吐能力. 这种方案要内核支持这个机制, 在部署的时候进行相关配置才能生效.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4079a61a512454b8e20091690cdb48b1-20240421231949-2xdjui6.jpg" alt="">​</p> <p>一般实现思路是在消息队列的内核支持多目录读写的能力, 将不同的文件或者不同的数据段调度存放在不同硬盘设备对应的挂载目录中. 此时在数据的写入和读取的过程中, 就可以同时利用到多块盘的吞吐和存储.</p> <h6 id="_3-配置raid和lvm硬盘阵列"><a href="#_3-配置raid和lvm硬盘阵列" class="header-anchor">#</a> 3.配置RAID和LVM硬盘阵列</h6> <p>多目录读写的问题是多块盘之间无法共享 IO 能力和存储空间, 当遇到数据倾斜时, 在单机层面会出现性能和容量瓶颈. Linux 提供了 RAID 硬盘阵列和 LVM 逻辑卷管理两种方式, 通过串联多块盘的读写能力和容量, 提升硬盘的性能和吞吐能力.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/488b385cf99b0ba6797aa5ed408d027e-20240421231949-eqm5c0l.jpg" alt="">​</p> <h5 id="总结-6"><a href="#总结-6" class="header-anchor">#</a> 总结</h5> <p>写入性能优化的核心是<strong>缓存写, 批量写, 顺序写</strong>.</p> <p>内存的写性能比任何硬盘都高, 通过先写内存, 后批量刷新数据到硬盘, 可以降低硬盘的写入次数, 从而提升写入性能. 在写缓存的过程中, 要注意数据的可靠性, 可以通过同步刷盘, 副本同步, WAL 机制等手段提高性能和可靠性. 写入的时候, 顺序写的性能比随机写的性能高, 顺序写的核心是数据存储目录结构的设计.</p> <p>读操作的性能提升, 主要<strong>依赖热读, 顺序读, 批量读, 零拷贝</strong>四种手段.</p> <p>热读主要依赖可用内存的大小. 批量读指一次 IO 操作尽可能读取更多的数据, 避免多次的数据 IO 操作. 数据预读分为硬盘预读和应用程序预读两类, 主要思路都是提前读取数据缓存到内存中, 提高热读的命中率. 和写入一样, 顺序读的核心也是数据存储目录结构的设计.</p> <p>零拷贝主要用来提升消费的性能, 它只是一个概念, 不是一门具体的技术. 核心思路是 <strong>减少复制和上下文切换的次数, 通过 DMA 技术释放 CPU 的工作量</strong>, 从而提升消费性能. 底层的实现主要涉及 mmap 内存映射, sendfile 系统调用, DMA 直接内存读取三种技术手段. Java 代码的实现, mmap 和 sendfile 的操作都在 NIO FileChannel 类中, 对应 map, transferTo, transferFrom 三个方法的使用. DMA 技术在代码中无法控制, 依赖于操作系统的实现.</p> <p>另外, 在硬件和操作系统层面, 还可以通过提升硬件的规格和类型, 配置多盘读写, 配置 RAID 和 LVM 硬盘阵列三种手段来提高性能.</p> <h5 id="思考题-4"><a href="#思考题-4" class="header-anchor">#</a> 思考题</h5> <blockquote><p>数据的批量写入, 如果不用 PageCache 的缓存刷新机制, 可以在应用程序中管理数据完成批量写入吗? 如果可以怎么实现? 优缺点是什么?</p></blockquote> <p>可以的. 好处是可以跳过操作系统的刷盘策略, <strong>根据自己业务的读写特点自定义刷盘策略</strong>. 实现得好的话有助于提升缓存的命中率.</p> <p>应用程序可以通过<strong>使用 Direct IO 来模拟实现 PageCahce 的功能</strong>. 大致思路是<strong>通过 Direct IO 管理硬盘, 然后在应用中缓存数据, 等待数据达到一定量的时候再统一批量写入硬盘, 然后调用 force 刷新数据到硬盘</strong>. 这种方式的效果和写 PageCache 是一样的, 遇到的问题也是一样的. 区别在于数据缓存在哪里, 通过什么策略刷新到硬盘. 写 PageCache 的好处是不需要程序自己管理缓存, 不需要自定义策略写入, 操作系统都可以帮忙做, 缺点是可能无法百分百满足我们自己的业务场景.</p> <h4 id="_07-生产端-生产者客户端的sdk有哪些设计要点"><a href="#_07-生产端-生产者客户端的sdk有哪些设计要点" class="header-anchor">#</a> 07-生产端:生产者客户端的SDK有哪些设计要点?</h4> <p>今天讲消息队列的客户端.</p> <p>先问你一个问题: 你在使用消息队列的 SDK 生产消费数据的时候, 是否会有疑问, SDK 底层是怎么工作的, 由哪些功能模块组成呢? 接下来会用三节课来详细分析一下这个问题.</p> <p>消息队列的客户端主要包含<mark><strong>生产, 消费, 集群管控</strong></mark>三类功能. 这节课聚焦在生产和集群管控. 从客户端 SDK 实现的角度来看, 生产模块包含 <strong>客户端基础功能和生产相关功能</strong> 两部分, 其中基础功能是客户端中所有功能共用的.</p> <p>看一张生产模块的功能结构图.</p> <p><img src="/img/c7b6ce167752520263ea3c404d2c6561-20240421231949-3xgplko.jpg" alt=""></p> <p><strong>基础功能是蓝色部分, 包括请求连接管理, 心跳检测, 内容构建, 序列化, 重试, 容错处理</strong>等等. <strong>生产功能是黄色部分, 包括客户端寻址, 分区选择, 批量发送, 生产错误处理, SSL, 压缩, 事务, 幂等</strong>等等.</p> <p>那图中各个功能模块如何实现? 下面从基础功能开始讲解.</p> <h5 id="客户端基础功能"><a href="#客户端基础功能" class="header-anchor">#</a> 客户端基础功能</h5> <h6 id="连接管理"><a href="#连接管理" class="header-anchor">#</a> 连接管理</h6> <p>在网络模块, 讲过客户端和服务端之间基本都是通过各自语言的网络库, 创建 TCP 长连接进行通信的. 在大部分实现中, 为了避免连接数膨胀, 每个客户端实例和每台 Broker 只会维护一条 TCP 连接.</p> <p>建立一条 TCP 连接很简单, 更关键的是, 什么情况下建立连接? 一般有<strong>初始化创建连接和使用时创建链接</strong>两种方式.</p> <ul><li><strong>初始化创建连接</strong>, 指在实例初始化时就创建到各个 Broker 的 TCP 连接, 等待数据发送. 好处是提前创建好可以避免发送的时候冷启动. 缺点是需要提前创建好所有的连接, 可能导致连接空跑, 会消耗一定的资源.</li> <li><strong>使用时创建链接</strong>, 指在实例初始化时不建立连接, 当需要发送数据时再建立. 好处是发送时才建立, 连接的使用率会较高. 缺点是可能出现连接冷启动, 会增加一点本次请求的耗时.</li></ul> <p>因为客户端会有空闲连接回收机制, 创建连接的耗时一般较短, 所以在实际的架构实现中, 两种方式都会用, 优劣区别并不明显. 不过从资源利用率的角度考虑, <strong>建议使用晚建立连接的方式</strong>.</p> <p>因为连接并不是任何时候都有数据, 可能出现长时间连接空闲. 所以连接都会搭配连接回收机制, 连接建立后如果连接出现长时间空闲, 就回收连接. 连接回收的策略一般是判断这段时间内是否有发送数据的行为, 如果没有就判断是空闲, 然后执行回收.</p> <p>因为单个 TCP 连接发送性能存在上限, 就需要在客户端启动多个生产者, 提高并发读写的能力. 一般情况下, <strong>每个生产者会有一个唯一的 ID 或唯一标识来标识客户端</strong>, 比如 ProduceID 或客户端的 IP+Port.</p> <p>单个 TCP 的瓶颈和很多因素有关, 比如网路带宽, 网络延迟, 客户端请求端的 socketbuff 的配置, TCP 窗口大小, 发送速率导致本地数据反压堆积, 服务端请求队列的堆积情况, 收包和回包的速度等等.</p> <p>接下来来看看<strong>客户端和服务端之间的心跳检测</strong>.</p> <h6 id="心跳检测"><a href="#心跳检测" class="header-anchor">#</a> 心跳检测</h6> <p>心跳检测是客户端和服务端之间保活的一种机制, 检测服务端或者客户端的一方不可用时, 另一方可以及时回收资源, 避免资源浪费. 一般通过 ping-pong 的方式来发起探测.</p> <p><img src="/img/fa88d7962a6d19ef7286bd1f6eb8149b-20240421231949-6fs2u0m.jpg" alt=""></p> <p>消息队列一般都是基于 TCP 协议通信的. 所以客户端和服务端之间的<strong>心跳检测机制的实现, 一般有基于 TCP 的 KeepAlive 保活机制和应用层主动探测两种形式</strong>.</p> <p><img src="/img/736e686ce4dc8ae4b9f83ef5b4398684-20240421231949-cm359oa.jpg" alt=""></p> <p><strong>基于 TCP 的 KeepAlive 保活机制</strong> 是 TCP/IP 协议层内置的功能, 需要手动打开 TCP 的 KeepAlive 功能. 通过这种方案实现心跳探测, 优点是简单, 缺点是 KeepAlive 实现是在服务器侧, 需要 Server 主动发出检测包, 此时如果客户端异常, 可能出现很多不可用的 TCP 连接. 这种连接会<strong>占用服务器内存资源</strong>, 导致服务端的性能下降.</p> <p><strong>应用层主动探测</strong> 一般是 Client 向 Server 发起的, 主要解决灵活性和 TCP KeepAlive 的缺陷. 探测流程一般是客户端定时发送保活心跳, 当服务端连续几次没收到请求, 就断开连接. 这样做的好处是, 可以将压力分担到各个客户端, 避免服务端的过载.</p> <p>下面来看一下 Java NIO 框架 <strong>Netty 中心跳探测</strong>的实现, 来加深一下印象.</p> <p>Netty 支持心跳探测的关键是 <strong>IdleStateHandler</strong>, 来看它的构造器. 构造器包含读超时(readerIdleTime), 写超时(writerIdleTime), 读或写超时(allIdleTime), 时间单位(unit)四个参数, 这四个参数是心跳检测的主要配置.</p> <p><img src="/img/a0c19fb2edf238b13250ac44dfd5949b-20240421231949-spgsvna.png" alt=""></p> <ul><li><strong>读超时</strong>, 在指定的时间间隔内没有从 Channel 读取到数据时, 会触发一个 READER_IDLE 的 IdleStateEvent 事件.</li> <li><strong>写超时</strong>, 在指定的时间间隔内没有数据写入到 Channel 时, 会触发一个 WRITER_IDLE 的 IdleStateEvent 事件.</li> <li><strong>读或写超时</strong>, 在指定的时间间隔内没有读或写操作时, 会触发一个 ALL_IDLE 的 IdleStateEvent 事件.</li> <li>时间单位, 当超过时间间隔没有收到请求, 就会触发后续的处理逻辑, 一般是关闭连接.</li></ul> <p>此时, 如果触发了超时事件, 则会触发后续的比如连接重建, 报错等行为. 接下来来看看<strong>错误是如何处理</strong>的.</p> <h6 id="错误处理"><a href="#错误处理" class="header-anchor">#</a> 错误处理</h6> <p>从请求的角度, 有些错误是重试可以<strong>恢复</strong>的, 比如<strong>连接断开, Leader 切换, 发送偶尔超时, 服务端某些异常</strong>等; 有些错误是不可恢复的, 比如 Topic/分区不存在, 服务端 Broker 不存在, 集群和 Broker 长时间无响应等.</p> <p>所以, 在客户端的处理中也会将错误分为<mark><strong>可重试错误和不可重试错误</strong></mark>两类.</p> <p><img src="/img/5ae19fb69ba5cbc3304d69a9c8e99aa1-20240421231949-l035tr4.jpg" alt=""></p> <p>因为网络环境, 架构部署的复杂性, 集群可能出现短暂网络抖动, Leader 切换等异常, 可重试错误就是这类通过一次或多次重试可能恢复的异常; 不可重试的错误就是不管如何重试都无法恢复的异常.</p> <p>客户端收到可重试错误后, 会通过一定的策略进行<strong>重试</strong>, 尽量确保生产流程的顺利进行.</p> <p>虽然实现思路很直接, 很简单, 但在客户端 SDK 的实现过程中, 错误处理是一个包含很多细节的工作, 一般需要考虑下面几个点.</p> <ul><li><strong>如何定义可恢复错误和不可恢复错误</strong>.</li> <li>完整的错误码的定义和枚举, 好的<strong>错误码定义</strong>可以提高排查问题的效率.</li> <li>错误后重试的代码实现方式是否合理高效.</li> <li>判断<strong>哪些情况需要停止客户端, 向上抛错</strong>, 以免一些错误信息一直在 SDK 内空转, 提高上层感知异常和排查异常的难度.</li> <li>日志信息打印 debug, info, error 日志时, 是否包含了完整的内容.</li></ul> <p>发生错误后, 客户端一般会提供重试策略, 接下来来看看<strong>重试机制的实现</strong>.</p> <h6 id="重试机制"><a href="#重试机制" class="header-anchor">#</a> 重试机制</h6> <p><strong>重试策略一般会支持重试次数和退避时间的概念</strong>. 当消息失败, 超过设置的退避时间后, 会继续重试, 当超过重试次数后, 就会抛弃消息或者将消息投递到配置好的重试队列中.</p> <p>退避时间是可以配置的, 比如 1s, 10s, 1 分钟. 当出现错误时, 就会<strong>根据退避策略退避, 再尝试写入</strong>. 一般情况下, <strong>重试是有次数上限的, 当然也支持配置无限重试</strong>.</p> <p>退避策略影响的是重试的成功率, 因为网络抖动正常是 ms 级, 某些异常可能会抖动十几秒. 此时, 如果退避策略设置得太短, 在退避策略和重试次数用完后, 可能消息还没生产成功; 如果退避时间设置太长, 可能导致客户端发送堵塞消息堆积.</p> <p>所以<strong>消息队列生产者的重试次数和退避策略的设置是比较讲究的, 需要根据业务的场景仔细设计</strong>.</p> <p>另外, 客户端为了满足安全传输, 性能, 功能方面的需求, 客户端都会支持传输加密, 压缩, 事务, 幂等等功能. 这块在后面课程会展开细讲.</p> <p>那么在基础功能之上, 接下来再看一下生产客户端所需要的一些相关功能是如何实现的. 先来看一下客户端寻址机制.</p> <h5 id="生产相关功能"><a href="#生产相关功能" class="header-anchor">#</a> 生产相关功能</h5> <h6 id="客户端寻址机制"><a href="#客户端寻址机制" class="header-anchor">#</a> 客户端寻址机制</h6> <p>消息队列作为一个分布式系统, 分区会分布在集群的不同节点上. 所以从客户端的角度看, <mark><strong>往服务端写入数据的时候, 服务端有那么多台节点, 请求要发给哪台节点</strong></mark>呢?</p> <p><img src="/img/394d9f57e9b987da31148e186f493708-20240421231949-lhc5lp6.jpg" alt=""></p> <p>你可能觉得这个问题太简单了, 类似发送 HTTP 请求, 手动指定目标 Broker 的 IP 就行了. 就是说在生产者写数据到 Broker 的时候, 在代码里面手动指定分区对应的对端的 Broker 地址, 然后将数据写到目标 Broker.</p> <p>这个思路没问题, 但是手动指定对端 Broker 地址的时候, 怎么知道这个分区在这台 Broker 上的对应关系存在哪里呢? 为了解决这个问题, 业界提出了 <strong>Metadata(元数据)寻址机制和服务端内部转发</strong>两个思路.</p> <blockquote><p>1.Metadata(元数据)寻址机制</p></blockquote> <p>服务端会提供一个获取全量的 Metadata 的接口, 客户端在启动时, 首先通过接口拿到集群所有的元数据信息, 本地缓存这部分数据信息. 然后, 客户端发送数据的时候, 会根据元数据信息的内容, 得到服务端的地址是什么, 要发送的分区在哪台节点上. 最后根据这两部分信息, 将数据发送到服务端.</p> <p>​<img src="/img/460b153ac7bef219221e74e8828d70d7-20240421231949-74es7zk.jpg" alt="">​</p> <p><strong>消息队列的元数据是指 Topic, 分区, Group, 节点, 配置等集群维度的信息</strong>. 比如 Topic 有几个分区, 分区的 Leader 和 Follower 在哪些节点上, 节点的 IP 和端口是什么, 有哪些 Group 等等.</p> <p>在 Metadata 寻址机制中, 元数据信息主要包括 Topic 及其对应的分区信息和 Node 信息两部分. 下面看一下 Kafka 的元数据信息结构.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>主题分区元数据<span class="token operator">:</span> 
<span class="token punctuation">{</span>
    <span class="token property">&quot;test123&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token property">&quot;Topic&quot;</span><span class="token operator">:</span> <span class="token string">&quot;test123&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Partitions&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span>
                <span class="token property">&quot;ID&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token property">&quot;Error&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token property">&quot;Leader&quot;</span><span class="token operator">:</span> <span class="token number">101194</span><span class="token punctuation">,</span>
                <span class="token property">&quot;Replicas&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
                    <span class="token number">101194</span><span class="token punctuation">,</span>
                    <span class="token number">101193</span>
                <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token property">&quot;Isrs&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
                    <span class="token number">101194</span><span class="token punctuation">,</span>
                    <span class="token number">101193</span>
                <span class="token punctuation">]</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Error&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

 节点元数据<span class="token operator">:</span> 
<span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;ID&quot;</span><span class="token operator">:</span> <span class="token number">101195</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;9.130.62.0&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Port&quot;</span><span class="token operator">:</span> <span class="token number">6097</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;ID&quot;</span><span class="token operator">:</span> <span class="token number">101194</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;9.130.62.1&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Port&quot;</span><span class="token operator">:</span> <span class="token number">6096</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;ID&quot;</span><span class="token operator">:</span> <span class="token number">101193</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;9.130.62.2&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;Port&quot;</span><span class="token operator">:</span> <span class="token number">6095</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br></div></div><p><mark><strong>客户端一般通过 定期全量更新 Metadata 信息和请求报错时更新元数据信息 两种方式, 来保证客户端的元数据信息是最新的. 目前 Kafka, RocketMQ, Pulsar 用的都是这个方案</strong></mark>.</p> <blockquote><p>2.服务端内部转发机制</p></blockquote> <p>另外一种服务端内部转发机制, 客户端不需要经过寻址的过程, <strong>写入的时候是随机把数据写入到服务端任意一台 Broker</strong>.</p> <p>具体思路是<strong>服务端的每一台 Broker 会缓存所有节点的元数据信息, 生产者将数据发送给 Broker 后, Broker 如果判断分区不在当前节点上, 会找到这个分区在哪个节点上, 然后把数据转发到目标节点</strong>.</p> <p><img src="/img/cb183c3d5yyc79a59c8609b37c0399de-20240421231949-62rr9q5.jpg" alt=""></p> <p>这个方案的好处是分区寻址在服务端完成, 客户端的实现成本比较低. 但是生产流程多了一跳, 耗时增加了. 另外服务端因为转发多了一跳, 会导致服务端的资源损耗多一倍, 比如 CPU, 内存, 网卡, 在大流量的场景下, 这种损耗会导致集群负载变高, 从而导致集群性能降低.</p> <p>所以这种方案<strong>不适合大流量, 高吞吐的消息队列</strong>. 目前业界只有 RabbitMQ 使用这个方案.</p> <p>解决了请求要发送给哪个节点, 接下来来看看<strong>消息数据要写入到哪个分区</strong>.</p> <h6 id="生产分区分配策略"><a href="#生产分区分配策略" class="header-anchor">#</a> 生产分区分配策略</h6> <p><strong>数据可以直接写入分区或者写入 Topic. 写入 Topic 时, 最终数据还是要写入到某个分区. 这个数据选择写入到哪个分区的过程, 就是生产数据的分区分配过程. 过程中的分配策略就是生产分区分配策略</strong>.</p> <p><img src="/img/31ac8ab6fe9ac8651b0be3591424e73a-20240421231949-8wffqa3.jpg" alt=""></p> <p>一般情况下, 消息队列默认<mark><strong>支持轮询, 按 Key Hash, 手动指定, 自定义分区分配策略</strong></mark>四种分区分配策略.</p> <p><strong>轮询</strong> 是所有消息队列的默认选项. 消息通过轮询的方式依次写入到各个分区中, 这样可以保证每个分区的数据量是一样的, 不会出现分区数据倾斜.</p> <p>分区数据倾斜是指一个 Topic 的每个分区的数据量不一样, 有的分区数据量大, 有的小, 从而导致硬件的负载不均, 集群性能出现问题.</p> <p>但是如果需要保证数据的写入是<strong>有序</strong>的, 轮询就满足不了. 因为在消费模型中, 每个分区的消费是独立的, 如果数据顺序依次写入多个分区, 在消费的时候就无法保持顺序. 所以为了保证数据有序, 就需要保证 Topic 只有一个分区. 这是另外两种分配策略的思路.</p> <p><strong>按 Key Hash</strong> 是指根据消息的 Key 算出一个 Hash 值, 然后跟 Topic 的分区数取余数, 算出一个分区号, 将数据写入到这个分区中. 公式参考:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>partitionSeq = hash(key) % partitionNum
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>这种方案的好处是可以<strong>根据 Key 来保证数据的分区有序</strong>. 比如某个用户的访问轨迹, 以客户的 AppID 为 Key, 按 Key Hash 存储, 就可以确保客户维度的数据分区有序. <strong>缺点是分区数量不能变化, 变化后 Hash 值就会变, 导致消息乱序. 并且因为每个 Key 的数据量不一样, 容易导致数据倾斜</strong>.</p> <p><strong>手动指定</strong> 很简单, 就是在生产数据的时候, 手动指定数据写入哪个分区. 这种方案的好处就是灵活, 用户可以在代码逻辑中根据自己的需要, 选择合适的分区, 缺点就是业务需要感知分区的数量和变化, 代码实现相对复杂.</p> <p>除了这 3 种默认策略, 消息队列也支持 <strong>自定义分区分配策略</strong>, 让用户灵活使用. 内核提供 Interface(接口)机制, 用户如果需要指定自定义的分区分配策略, 可以实现对应的接口, 然后配置分区分配策略. 比如 Kafka 可以通过实现 org.apache.kafka.clients.producer.Partitioner 接口实现自定义分区策略.</p> <p>为了提高写入性能, 有的生产者客户端会提供批量(Batch)写入的语义.</p> <h6 id="批量语义"><a href="#批量语义" class="header-anchor">#</a> 批量语义</h6> <p>客户端支持批量写入数据的前提是, 需要在协议层支持批量的语义. 否则就只能在业务中自定义将多条消息组成一条消息.</p> <p><strong>批量发送的实现思路一般是在客户端内存中维护一个队列, 数据写入的时候, 先将其写到这个内存队列, 然后通过某个策略从内存队列读取数据, 发送到服务端</strong>.</p> <p>​<img src="/img/4c51b7633702cd7c27a6f5c458b30b91-20240421231949-rgi5v80.jpg" alt="">​</p> <p>批量发送数据的策略和存储模块的刷盘策略很像, 都是根据数据条数或时间聚合后, 汇总发送到服务端, 一般是满足时间或者条数的条件后触发发送操作, 也会有立即发送的配置项.</p> <p><strong>Kafka 是按照时间的策略批量发送的</strong>, 提供了 <code>linger.ms, max.request.size, batch.size</code>​ 三个参数, 来控制数据的批量发送.</p> <ul><li><strong>linger.ms</strong>: 设置消息延迟发送的时间, 这样可以等待更多的消息组成 Batch 发送. 默认为 0 表示立即发送.</li> <li><strong>max.request.size</strong>: 生产者能够发送的请求包大小上限, 默认为 1MB.</li> <li><strong>batch.size</strong>: 生产者会尝试将业务发送到相同的 Partition 的消息合包后再进行发送, 它设置了合包的大小上限.</li></ul> <p>Pulsar 也提供了 batchingEnabled, batchingMaxMessages, batchingMaxPublishDelayMicros 三个参数, 来控制数据<strong>批量发送</strong>.</p> <p>为了支持对于性能和可靠性有不同需求的业务场景, 客户端一般会支持多种数据发送方式.</p> <h6 id="数据发送方式"><a href="#数据发送方式" class="header-anchor">#</a> 数据发送方式</h6> <p>消息队列一般也会提供<strong>同步发送, 异步发送, 发送即忘</strong>三种形式.</p> <p>同步和异步更多是语言语法的实现, 同步发送主要解决数据发送的即时性和顺序性, <strong>异步发送主要考虑性能</strong>. 发送即忘可能不好理解, 下面重点讲下.</p> <p><strong>发送即忘指消息发送后不关心请求返回的结果, 立即发送下一条</strong>. 这种方式因为不用关心发送结果, 发送性能会提升很多. 缺点是当数据发送失败时无法感知, 可能有数据丢失的情况, 所以<strong>适合用在发送不重要的日志等场景</strong>. Kafka 提供了 ack=0, RocketMQ 提供了 sendOneway 来支持这种模式.</p> <p>讲完了发送相关的功能设计, 接下来看一下<strong>管控操作</strong>在客户端中的实现方式.</p> <h5 id="集群管控操作"><a href="#集群管控操作" class="header-anchor">#</a> 集群管控操作</h5> <p>集群管控操作一般是用来完成资源的<strong>创建, 查询, 修改, 删除</strong>等集群管理动作. 资源包括主题, 分区, 配置, 消费分组等等.</p> <p>从功能上来看, 消息队列一般会提供多种集群管理方式, 比如命令行, 客户端, HTTP 接口等等.</p> <p>命令行工具是最基本的支持方式. 如下图所示, 它的底层主要通过包装客户端 SDK 和服务端的相关功能接口进行交互. 程序编码上一般由 <strong>命令行,</strong> <strong>参数包装</strong>, <strong>底层 SDK 调用</strong> 三部分组成. 主要流程是接收参数, 处理参数, 调用 SDK 等相关操作.</p> <p><img src="/img/ccee33d1f32379cffff82328ee626069-20240421231949-od7ru4g.jpg" alt=""></p> <p>有的消息队列也会支持 HTTP 接口形式的管控操作. 好处是因为 HTTP 协议的通用性, 业务可以从各个环境发起管控的调用, 不用非得使用 admin SDK. 另外客户端封装 HTTP 接口实现命令行工具的成本也比较低.</p> <h5 id="总结-7"><a href="#总结-7" class="header-anchor">#</a> 总结</h5> <p>消息队列生产者客户端的设计, 主要关注下面三个部分.</p> <ol><li><strong>网络模块的开发和管理</strong>. 这部分是为了完成和服务端的通信, 比如请求和返回的构建, 心跳检测, 错误处理, 重试机制等.</li> <li>根据服务端提供的各个接口的协议结构, 构建请求, 完成序列化和反序列化后, 通过网络模块发起请求并获得返回.</li> <li>在前面两步的基础上, 添加各个业务层面的功能, 比如生产, 消费, 事务, 幂等, SSL 等等.</li></ol> <p><img src="/img/a522d1632c402a41af71fea7771c08cf-20240421231949-27b0x8c.jpg" alt=""></p> <p>客户端和服务端交互的过程中, 一般要经过元数据寻址, 以正确找到分区所在的 Broker. 如果想避免客户端寻址, 只能在服务端内进行转发, 但有性能和资源的损耗. 所以在主打吞吐的消息队列组件中, 转发的方案用得很少.</p> <p>从生产者的角度来看, 需要重点关注<strong>分区分配策略, 批量语义, 发送方式</strong>三个方面. 请求内容构建和序列化属于协议设计的内容, 主要取决于协议的具体设计和序列化/反序列化框架的选择.</p> <h5 id="思考题-5"><a href="#思考题-5" class="header-anchor">#</a> 思考题</h5> <blockquote><p>假设让你从头开始写一个消息队列的某个语言的 SDK, 思考步骤是怎样的?</p></blockquote> <ol><li>思考客户端的<strong>模块组成</strong>, 比如总结部分说到的三层结构.</li> <li>参考服务端网络模块的实现, 进行客户端网络模块的选型开发, 比如使用 Netty Client 或者 Java Socket Client, 然后完成连接管理, 心跳检测等网路模块的开发工作.</li> <li>了解这个消息队列的协议设计的内容, 各个接口的请求和返回的<strong>协议</strong>是什么样子的.</li> <li>思考如何构建请求, 实现构建各个请求相关的逻辑代码实现.</li> <li>思考<strong>序列化模块</strong>怎么实现.</li> <li>完成第一个接口的请求和返回的处理.</li> <li>根据各个接口的调用参数进行开发.</li> <li>如果需要支持 SSL, 就去参考这个语言官方的 SSL CLient 配置, 然后编码实现, 其他比如压缩的支持也是类似.</li></ol> <h4 id="_08-消费端-消费者客户端的sdk有哪些设计要点-上"><a href="#_08-消费端-消费者客户端的sdk有哪些设计要点-上" class="header-anchor">#</a> 08-消费端:消费者客户端的SDK有哪些设计要点?(上)</h4> <p>上节课讲了生产端, 这节课来讲讲消费端.</p> <p>从技术上看, 消费端 SDK 和生产端 SDK 一样, 主要包括<strong>客户端基础功能和消费相关功能</strong>两部分. 客户端基础功能在上一节讲过, 就不再重复.</p> <p>从实现来看, 消费相关功能包括 <mark><strong>消费模型</strong></mark>​<mark>,</mark> <mark><strong>分区消费模式</strong></mark>​<mark>,</mark> <mark><strong>消费分组(订阅)</strong></mark>​<mark>,</mark> <mark><strong>消费确认</strong></mark>​<mark>,</mark> <mark><strong>消费失败处理</strong></mark> 五个部分. 内容比较多, 所以本节课将会聚焦消费模型的选择和分区消费模式设计这两个部分, 下节会继续完成剩下三个部分的讲解.</p> <h5 id="消费模型的选择"><a href="#消费模型的选择" class="header-anchor">#</a> 消费模型的选择</h5> <p>为了满足不同场景的业务需求, 从实现机制上来看, 主流消息队列一般支持 <strong>Pull, Push, Pop</strong> 三种消费模型.</p> <h6 id="pull模型"><a href="#pull模型" class="header-anchor">#</a> Pull模型</h6> <p><mark><strong>Pull(拉)模型是指客户端通过不断轮询的方式向服务端拉取数据</strong></mark>. 它是消息队列中使用最广泛和最基本的模型, 主流的消息队列都支持这个模型.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f8cb7308f06113f96b53bbc1f986d2b9-20240421231949-9ogi8i1.jpg" alt="">​</p> <p>它的好处是客户端<strong>根据自身的处理速度去拉取数据, 不会对客户端和服务端造成额外的风险和负载压力</strong>. 缺点是可能会出现大量无效返回的 Pull 调用, 另外消费及时性不够, 无法满足一些需要全链路低耗时的场景.</p> <p>为了提高消费性能, Pull 模型都会支持<strong>批量读</strong>, 即 <strong>在客户端指定需要拉取多少条数据或者拉取多大的数据</strong>, 然后传递给服务端. 客户端拉取到数据并处理完成后, 再重复拉取数据处理. 如前面讲的, 这种拉取模式的缺点是可能会出现长时间轮询到空数据的情况, 从而浪费通信资源, 提高服务端的负载.</p> <p>来看下图的场景, 当 Topic1 数据已经被消费完, 此时如果消费者频繁来拉取数据并立即返回结果, 客户端就会不停地重复请求服务端. 当空数据请求特别多的时候, 就会造成资源损耗, 不利于提高吞吐, 也有可能导致负载问题.</p> <p>​<img src="/img/d13569ac0196a12bbd9d05e812c987d8-20240421231949-0w32e78.jpg" alt="">​</p> <p>为了解决这个问题, 正常的思路是<strong>在客户端根据一定策略进行等待和回避</strong>. 这样做的话, 就会出现如何设置等待时间的问题, 客户端等待时间设置不合理就会出现消费不及时的情况.</p> <p>所以为了解决空请求带来的问题, 一般<strong>服务端会协助处理</strong>, 有如下两个思路.</p> <blockquote><p>1.服务端hold住请求</p></blockquote> <p>当客户端根据策略拉取数据时, 如果没有足够的数据, 就先在服务端等一段时间, 等有数据后一起返回给客户端. 这种方案的好处是, 可以尽量提高吞吐能力, 不会有太多的空交互请求. 缺点是如果长时间不给客户端回包, 会导致客户端请求超时, 另外当数据不够时, hold 住请求的时间太长就会提高消费延时.</p> <blockquote><p>2.服务端有数据的时候通知客户端</p></blockquote> <p>当服务端不 hold 住请求, 立刻返回空数据, 客户端收到空数据时则不再发起请求, 会<strong>等待服务端的通知</strong>. 当服务端有数据的时候, 再主动通知客户端来拉取. 这种方案的好处是可以及时通知客户端来拉取数据, 从而降低消费延时. 缺点是因为客户端和服务端一般是半双工的通信, 此时服务端是不能主动向客户端发送消息的.</p> <p>所以在 Pull 模型中, 比较合适的方案是客户端告诉服务端: <strong>最多需要多少数据, 最少需要多少数据, 未达到最小数据时可以等多久</strong> 三个信息. 然后服务端首先判断是否有足够的数据, 有的话就立即返回, 否则就根据客户端设置的等待时长 hold 住请求, 如果超时, 无论是否有数据, 都会直接给客户端返回当前的结果.</p> <p>这种策略可以解决频繁不可控的空轮询请求. 即使全是空轮询, 对单个消费者来说, 其 TPS 也是可以预估的, 即总时间/等待时长 = 总轮询次数. 而如果需要降低消费延时, 可以通过降低最小获取的数据大小和最大等待时长来提高获取的频率, 从而尽量降低延时. 通过这种方案, 可以把理想的消费延迟时间降低到两次 Pull 请求之间的时间间隔.</p> <p>在一些业务消息的场景中, 因为应对的场景规模有限, 可以将最大等待时长设置为 0, 此时消费模型就变成了<strong>请求-返回的模式, 当没数据的时候就会立即返回数据, 其余逻辑交给客户端自己处理</strong>.</p> <h6 id="push模型"><a href="#push模型" class="header-anchor">#</a> Push模型</h6> <p>Push(推)模型是为了解决消费及时性而提出来的. 这个模型的本意是指<mark><strong>当服务端有数据时会主动推给客户端, 让数据的消费更加及时</strong></mark>. 理想中的思路如下图所示, 即当服务端有数据以后, 会主动推动给各个消费者. 这个思路是非常好的, 随着事件模型的发展, 为了解决消费的及时性, 很多消息队列都希望支持 Push 模型.</p> <p>​<img src="/img/d287737b178a9a6fd61c27a24b0db512-20240421231949-jf2bkky.jpg" alt="">​</p> <p>在实际的 Push 模型的实现上, 一般有 Broker 内置 Push 功能, Broker 外独立实现 Push 功能的组件, 在客户端实现伪 Push 功能三种思路.</p> <p><strong>第一种,</strong> <strong>Broker</strong> <strong>内置</strong> <strong>Push</strong> <strong>功能是指在 Broker 中内置标准的</strong> <strong>Push</strong> <strong>的能力, 由服务端向客户端主动推送数据</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2220e23cba67a3e392b48c02c3462505-20240421231949-944g28b.jpg" alt=""></p> <p>这种方案的好处是 Broker 自带 Push 能力, 无需重复开发和部署. Broker 内部可以感知到数据堆积情况, 可以保证消息被及时消费. 缺点是当消费者很多时, 内核需要主动维护很多与第三方的长连接, 并且需要处理各种客户端异常, 比如客户端卡住, 接收慢, 处理慢等情况. 这些推送数据, 异常处理, 连接维护等工作需要消耗很多的系统资源, 在性能上容易对 Broker 形成反压, 导致 Broker 本身的性能和稳定性出现问题.</p> <p>所以这种方案在主流消息队列中用得较少, 比如 RabbitMQ 和某些金融证券领域的消息队列, 为了保证消息投递的高效及时(比如全链路的毫秒级耗时), 才会采用这种方案.</p> <p><strong>第二种, Broker 外独立实现 Push 功能的组件是指独立于 Broker 提供一个专门实现推模型的组件</strong>. 通过先 Pull 数据, 再将数据 Push 给客户端, 从而简化客户端的使用, 提高数据消费的及时性.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6db5181a1714e327c375de7eae4a293b-20240421231949-4ov4o4u.jpg" alt=""></p> <p>这种方案的好处是<strong>将 Push 组件独立部署, 解决了 Broker 的性能和稳定性问题, 也能实现 Push 的效果</strong>. 缺点是虽然实现了 Push 的模型, 但其本质还是先 Pull 再 Push, 从全链路来看, 还是会存在<strong>延时较高</strong>的问题, 并且需要单独开发独立的 Push 组件, 开发和运维成本较高.</p> <p>从实际业务上来讲, 这种模型的使用场景较为有限, 主要用在回调, 事件触发的场景, 在实际的流消费场景中用得较少. 主要是因为通过第三方组件的 Push 灵活性不够, 性能会比 Pull 低.</p> <p><strong>第三种, 在客户端实现伪 Push 功能是指在客户端内部维护内存队列, SDK 底层通过 Pull 模型从服务端拉取数据存储到客户端的内存队列中. 然后通过回调的方式, 触发用户设置的回调函数, 将数据推送给应用程序, 在使用体验上看就是 Push 的效果</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/06ed827d2681386d9cef461d7a5ee7b1-20240421231949-5q5oewp.jpg" alt="">​</p> <p>这种方案的好处在于通过客户端底层的封装, 从用户体验看是 Push 模型的效果, 解决用户代码层面的不断轮询问题, 降低了用户的使用复杂度. 缺点是<strong>底层依旧是 Pull 模型, 还是得通过不断轮询的方式去服务端拉取数据</strong>, 就会遇到 Pull 模型遇到的问题.</p> <p>在客户端实现伪 Push, 是目前消息队列在实现 Push 模型上常用的实现方案, 因为它解决了客户体验上的主动回调触发消费问题. 虽然底层会有不断轮询和消费延时的缺点, 但是可以通过编码技巧来降低这两个问题的影响.</p> <p>因为 Push 模型需要先分配分区和消费者的关系, 客户端就需要感知分区分配, 分区均衡等操作, 从而在客户端就需要实现比较重的逻辑. 并且当客户端和订阅的分区数较多时, 容易出现需要很长的重平衡时间的情况. 此时为了解决这个问题, 业界提出了 Pop 模型.</p> <h6 id="pop模型"><a href="#pop模型" class="header-anchor">#</a> Pop模型</h6> <p><strong>Pop 模型想解决的是客户端实现较重, 重平衡会暂停消费并且可能时间较长, 从而出现消费倾斜的问题</strong>.</p> <p>它的思路是客户端不需要感知到分区, 直接通过 Pop 模型提供的 get 接口去获取到数据, 消费成功后 ACK 数据. 就跟发起 HTTP 请求去服务端拉取数据一样, <strong>不感知服务端的数据分布情况, 只需要拉到数据</strong>. 这种方案的好处是简化了消费模型, 同时服务端可以感知到消费的堆积情况, 可以根据堆积情况返回那些分区的数据给客户端, 这样也简化了消息数据的分配策略.</p> <p>从实现上来看, 它<strong>将分区分配的工作移到了服务端, 在服务端完成了消费者的分区分配, 进度管理</strong>, 然后暴露出了新的 Pop 和 ACK 接口. 客户端调用 Pop 接口去拿取数据, 消费成功后调用 ACK 去确认数据. 这和 HTTP 的 Request 和 Response 的使用模型一致.</p> <p>​<img src="/img/7f6f8e8603b1c9af0c594ec3b954c845-20240421231949-70g7owc.jpg" alt="">​</p> <h5 id="分区消费模式的设计"><a href="#分区消费模式的设计" class="header-anchor">#</a> 分区消费模式的设计</h5> <p>消息队列的数据是在 Partition/Queue 维度承载的. 所以消费过程中一个重要的工作就是<mark><strong>消费者和分区的消费模式问题, 即分区的数据能不能被多个消费者并发消费, 一条数据能不能被所有消费者消费到, 分区的数据能不能被顺序消费等等</strong></mark>.</p> <p>从技术上看, 在数据的消费模式上主要有<mark><strong>独占消费, 共享消费, 广播消费, 灾备消费</strong></mark>四个思路.</p> <p><strong>独占消费是指一个分区在同一个时间只能被一个消费者消费</strong>. 在消费者启动时, 会分配消费者和分区之间的消费关系. 当消费者数量和分区数量都没有变化的情况下, 两者之间的分配关系不会变动. 当分配关系变动时, <strong>一个分组也只能被一个消费者消费, 这个消费者可能是当前的, 也可能是新的</strong>. 如果消费者数量大于分区数量, 则会有消费者被<strong>空置</strong>; 反之, 如果分区数量大于消费者数量, 一个消费者则可以同时消费多个分区.</p> <p>​<img src="/img/e1996c88f34fe02a23c65ce487e89b8d-20240421231949-l7yhn7e.jpg" alt="">​</p> <p>独占消费的好处是可以<strong>保证分区维度的消费是有序</strong>的. 缺点是当数据出现倾斜, 单个消费者出现性能问题或 hang 住时, 会导致有些分区堆积严重. <mark><strong>现在大部分消息队列默认支持的就是独占消费的类型, 比如 Kafka, RocketMQ, Pulsar 等</strong></mark>.</p> <p><strong>共享消费是指单个分区的数据可以同时被多个消费者消费</strong>. 即分区的数据会<strong>依次投递给不同的消费者, 一条数据只会投递给一个消费者</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2b565d4a50802225d74c0b7f4304ef5b-20240421231949-e19wy9x.jpg" alt=""></p> <p>这种方式的好处是, 可以避免单个消费者的性能和稳定性问题导致分区的数据堆积. 缺点是<strong>无法保证数据的顺序消费</strong>. 这种模式一般用在对数据的有序性无要求的场景, 比如<strong>日志</strong>.</p> <p><strong>广播消费是指一条数据要能够被多个消费者消费到</strong>. 即分区中的一条数据可以投递给所有的消费者, 这种方式是需要广播消费的场景.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bb2b39c0762baaa2283438b280caa2cb-20240421231949-vf1mh5a.jpg" alt=""></p> <p>实现广播消费一般有内核实现广播消费的模型, 使用不同的消费分组消费和指定分区消费三种技术思路.</p> <ol><li><strong>内核实现广播消费的模型</strong>, 指在 Broker 内核中的消息投递流程实现广播消费模式, 即 Broker 投递消息时, 可以将一条消息吐给不同的消费者, 从而实现广播消费.</li> <li><strong>使用不同的消费分组对数据进行消费</strong>, 指通过创建不同的消费者组消费同一个 Topic 或分区, 不同的消费分组管理自己的消费进度, 消费到同一条消息, 从而实现广播消费的效果.</li> <li><strong>指定分区消费</strong>, 是指每个消费者指定分区进行消费, 在本地记录消费位点, 从而实现不同消费者消费同一条数据, 达到广播消费的效果.</li></ol> <p>三种方案的优劣对比如下:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f59f74ff20f77192c9f6b50abc5d6c92-20240421231949-b04f8vb.jpg" alt=""></p> <p>在常见的消息队列产品中, Pulsar 支持的 Share 消费模型就是第一种实现思路. Kafka 和 RocketMQ 主要支持第二和第三种实现思路.</p> <p><strong>灾备消费是独占消费的升级版, 在保持独占消费可以支持顺序消费的基础上, 同时加入灾备的消费者</strong>. 当消费者出现问题的时候, <strong>灾备消费者加入工作, 继续保持独占顺序消费</strong>. 好处是既能保持独占顺序消费, 又能保证容灾能力. 缺点是<strong>无法解决消费倾斜的性能问题</strong>, 另外还需要准备一个消费者来做灾备, 使用成本较高.</p> <p>​<img src="/img/24c795441bd156a1b6bd1a99d312c388-20240421231949-rtck3h7.jpg" alt="">​</p> <p>业界还有一些其他用得比较少的消费模式, 如果有兴趣, 可以去研究一下各个主流消息队列(如 Kafka, RocketMQ, Pulsar 等)的实现.</p> <h5 id="总结-8"><a href="#总结-8" class="header-anchor">#</a> 总结</h5> <p>在消费端, 为了提高消费速度和消息投递的及时性, 需要选择<strong>合适的消费模型</strong>, 目前主流有 <strong>Pull, Push, Pop</strong> 三种模型.</p> <p>这三种模型的应用场景都不一样. 目前业界<strong>主流消息队列使用的都是 Pull 模型</strong>. 但为了满足业务需求, 很多消息队列也会支持 Push 模型和 Pop 模型. 其中, Push 模型的及时性更高, 实现较为复杂, 限制较多. Pop 模型本质上是 Pull 模型的一种, 只是在实现和功能层面上, 与 Push 的实现思路和适用场景不一样. 所以在模型的选择上来看, 因为场景复杂, 三种模型都是需要的.</p> <p><strong>常用的消费模式一般有独占消费, 共享消费, 广播消费, 灾备消费四种. 为了避免堆积, 保证消息消费顺序, 一般需要选择分区独占的消费模式. 从单分区的维度, 共享消费的性能是最高的. 广播消费主要是通过创建多个消费分组, 指定分区消费来实现的. 灾备消费的场景用得相对较少</strong>.</p> <h5 id="思考题-6"><a href="#思考题-6" class="header-anchor">#</a> 思考题</h5> <blockquote><p>当 Topic 的消息写入存在倾斜, 某些分区消息堆积很多, 此时选择哪种分区消费模式可以解决问题?</p></blockquote> <p>可以分三种情况来解答.</p> <ol><li><strong>如果数据可以丢弃, 那么可以通过重置消费位点到最新来解决历史堆积, 让消费者可以消费新的数据</strong>. 不过, 这个方案有缺点, 重置位点之前的数据会丢失, 如果消费性能还是跟不上的话, 那么后续还是会堆积.</li> <li><strong>如果数据不能丢弃, 不用保证消费顺序, 那么可以将消费模式切换到共享消费模式, 则有多个消费者同时消费一个分区, 可以极大地提升消费速度, 还可以通过横向增加消费者, 从根本上解决堆积问题</strong>.</li> <li>如果数据不能丢弃, 且需要保证消费顺序, 那么就只能从发送端入手, 分析为何发送端写入倾斜, 然后解决写入倾斜的问题.</li></ol> <h4 id="_09-消费端-消费者客户端的sdk有哪些设计要点-下"><a href="#_09-消费端-消费者客户端的sdk有哪些设计要点-下" class="header-anchor">#</a> 09-消费端:消费者客户端的SDK有哪些设计要点?(下)</h4> <p>这节课继续来讲消费端, 上节课学习了消费模型的选择和分区消费模式设计, 这节课将学习剩下的三部分, 也就是<strong>消费分组(订阅), 消费确认, 消费失败处理</strong>.</p> <h5 id="消费分组"><a href="#消费分组" class="header-anchor">#</a> 消费分组</h5> <p>消费分组是用来组织消费者, 分区, 消费进度关系的逻辑概念. 为什么需要消费分组呢?</p> <p>在没有消费分组直接消费 Topic 的场景下, 如果希望不重复消费 Topic 中的数据, 那么就 <strong>需要有一个标识来标识当前的消费情况, 比如记录进度</strong>. 这个唯一标识就是消费分组.</p> <p>在一个集群中可以有<strong>很多消费分组, 消费分组间通过名称来区分</strong>. 消费分组自身的数据是集群元数据的一部分, 会存储在 Broker 的元数据存储服务中. <mark><strong>消费分组主要有管理消费者和分区的对应关系, 保存消费者的消费进度, 实现消息可重复被消费三类功能</strong></mark>.</p> <p>消费分组和 Topic 是强相关的, 它需要包含 Topic 才有意义, 一个空的消费分组是没有意义的. 如下图所示, 消费分组内有很多个消费者, 一个消费分组也可以订阅和消费多个 Topic, 一个 Topic 也可以被多个消费分组订阅和消费.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/77e59yy3fc26de63c6f6dea701a75252-20240421231949-8zxrv52.jpg" alt="">​</p> <p>因为 Topic 不存储真实数据, 分区才存储消息数据, 所以就需要解决<strong>消费者和分区的分配关系</strong>, 即 <mark><strong>哪个分区被哪个消费者消费, 这个分配的过程就叫做消费重平衡(Rebalance)</strong></mark> .</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/73768bb217c4da2b44301d8f21475f73-20240421231949-npdwxpn.jpg" alt="">​</p> <p>从流程上来看, 当新建一个消费分组的时候, 就需要开始分配消费者和分区的消费关系了. 分配完成后, 就可以正常消费. <strong>如果消费者和分区出现变动, 比如消费者挂掉, 新增消费者, 订阅的 Topic 的分区数发生变化等等, 就会重新开始分配消费关系</strong>, 否则就会存在某些分区不能被订阅和消费的情况.</p> <h6 id="协调者"><a href="#协调者" class="header-anchor">#</a> 协调者</h6> <p>从实现上来看, 如果要对消费者和分区进行分配, 肯定需要有一个模块拥有消费分组, 所有的消费者, 分区信息三部分信息, 这个模块一般命名为 <strong>协调者</strong>. 协调者主要的工作就是执行<strong>消费重平衡, 并记录消费分组的消费进度</strong>.</p> <p>如下图所示, 在消费分组创建, 消费者变化, 分区变化的时候就会触发重新分配. 分区分配的操作可以在协调者内部或者消费者上完成.</p> <ol><li>在协调者完成, 即协调者首先获取消费者和分区的信息, 然后在协调者内部完成分区分配, 最后再把分配关系同步给所有消费者.</li> <li>在消费者完成, 即负责分配的消费者获取所有消费者和分区的信息, 然后该消费者完成分区分配操作, 最后再把分配关系同步给其他消费者.</li></ol> <p>从技术上来看, 这两种形式的优劣区别并不大, 取决于代码的实现. <strong>一般在创建消费分组和消费者/ Topic 分区发生变化的时候, 会触发协调者执行消费重平衡</strong>.</p> <p>​<img src="/img/0d8af534dba3e33e9cc31926f607b904-20240421231949-1mk3ry9.jpg" alt="">​</p> <p>从实现的角度来看, <strong>协调者一般是 Broker 内核的一个模块, 就是一段代码或者一个类, 专门用来完成上述的工作</strong>. 当有多台 Broker 时, 协调者的实现有多种方式, 比如 Kafka 集群每台 Broker 都有协调者存在. 通过消费分组的名称计算出来一个 hash 值和 __consumer_offset 的分区数, 取余计算得出一个分区号. 最后这个分区号对应的 Leader 所在的 Broker 节点就是协调者所在的节点. 客户端就和计算出来的这台 Broker 节点进行交互, 来执行消费重平衡的相关操作.</p> <p>当有了协调者后, 就需要来确认<strong>哪个分区给哪个消费者了, 此时就需要一个分配策略来执行, 这就是消费分区分配策略</strong>.</p> <h6 id="消费分区分配策略"><a href="#消费分区分配策略" class="header-anchor">#</a> 消费分区分配策略</h6> <p>在具体实现上, 一般内核会默认提供几种分配策略, 也可以<strong>通过定义接口来支持用户自定义实现分区分配策略</strong>.</p> <p>分区分配策略的制定一般遵循以下三个原则:</p> <ol><li>各个分区的数据能<strong>均匀</strong>地分配给每个消费者, 保证所有消费者的负载最大概率是均衡的, 该原则最为常用.</li> <li><strong>在每次重新分配的时候, 尽量减少分区和消费者之间的关系变动</strong>, 这样有助于加快重新分配的速度, 并且保持数据处理的连续性, 降低处理切换成本.</li> <li><strong>可以允许灵活地根据业务特性制定分配关系</strong>, 比如根据机房就近访问最近的分区, 某个 Topic 的奇数分区分配给第一个消费者等等.</li></ol> <p>所有消息队列的默认策略都是相对通用的, 一般都会包含有<mark><strong>轮询, 粘性, 自定义三种类型的策略</strong></mark>.</p> <p><strong>轮询</strong> 就是指用轮询的方式将分区分配给各个消费者, 保证每个消费者的分区数量是尽量相同的, 从而保证消费者的负载最大概率上是均衡的. 思路是拿到所有主题的所有分区和所有消费者, 根据拿到的顺序(实际实现中可能会先全部打乱, 以确保随机性)将分区逐个分配给消费者. 分配到最后的效果是, 每个消费者所分到的分区数是一样的, 最多相差 1 个分区. 比如 tp0 有 3 分区, tp1 有 2 分区, tp2 有 3 分区, 分配后效果如下.</p> <blockquote><p>消费者1: tp0-0, tp2-1, tp1-1</p> <p>消费者2: tp2-2, tp0-1, tp2-0</p> <p>消费者3: tp1-0, tp0-2</p></blockquote> <p>因为 Topic 一般会有多个分区, 默认情况下写入大部分是均匀的. 这个方案的优点是, 从随机性的原理来看, 打乱分区后再分配给每个消费者, 消费者的负载大概率是均匀的. 但是也有可能出现不均衡, 比如当消费组同时订阅多个分区时, 有可能会将同一个 Topic 的多个分区都分配给一个消费者, 从而出现消费者的负载倾斜.</p> <p>在轮询的基础上, <strong>为了解决随机轮询的情况, 某些流量高的 Topic 可能会分配给同一个消费者</strong>. 业界提出了一些轮询方案的升级版本, 比如在随机的基础上, 将 Topic 的不同分区尽量打散到不同的消费者, 从而保证整体消费者之间的分区是均衡的, 如下所示.</p> <blockquote><p>消费者1: tp0-0, tp2-1, tp1-1</p> <p>消费者2: tp0-1, tp2-0, tp1-0</p> <p>消费者3: tp0-2, tp2-2</p></blockquote> <p>各个变种版本的思路核心都是为了消费者更加均衡, 避免消费倾斜. 所以当看到有些分配算法很像轮询又不太一样时, 只要从这个目的去拆解, 就会比较好理解了.</p> <p><strong>粘性</strong> 是指尽量减少分区分配关系的变动, 进而减少重平衡所耗费的时间和资源损耗. 即当已经分配好消费者和分区的消费关系后, 当消费者或者分区出现变动, 就会触发重平衡. 从底层来看, 可能就是一个消费者掉了或者新增分区. 此时需要重新进行分配的消费者和分区其实是有限的, 大部分的分配关系可以不动. 而此时如果使用轮询算法, 则要全部打散重来, 耗时就会很长, 并且浪费资源, 即把原先不需要重新分配的关系都重新分配一遍.</p> <p>粘性的效果如下所示, 比如当上面的消费者 3 挂了后, 只需要将 tp1-0, tp0-2 平均分给消费者 1 和 2 即可, 消费者 1 和 2 原先分配的分区不用动.</p> <blockquote><p>消费者1: tp0-0, tp2-1, tp1-1, tp1-0</p> <p>消费者2: tp2-2, tp0-1, tp2-0, tp0-2</p></blockquote> <p>在实际的实现中, 为了减少重新分配关系, 有一个非常常用的算法是 <mark><strong>一致性哈希</strong></mark>. 一致性哈希的算法经常用在负载均衡中. <strong>用一致性哈希实现粘性策略的优点是, 当节点或者分区变动时, 只需要执行少量的分区再分配即可</strong>.</p> <p>在一些消息队列中, 也会提供一些与自己相关的特色的分区分配策略. 比如 RocketMQ 内部就提供了根据机房就近分配, 指定机房分配两种策略, 这两种策略的协调者要感知到客户端和服务端的机房信息, 然后根据策略进行分配, 均主要用在跨可用区场景中. Kafka 也提供了轮询策略改进版 RoundRobinAssignor 分配策略. 这些策略的核心出发点, 都是为了解决消费者和分区之间的分配均衡, 重平衡耗时, 业务场景需要等诉求.</p> <p>自定义分区分配算法, 跟上节课生产端数据的分区分配策略是一样的, 内核会提供接口, 用户可以根据自身需求实现自定义算法, 然后指定配置生效即可. 比如 Kafka 提供了 org.apache.kafka.clients.consumer.internals.PartitionAssignor 接口来提供自定义分区分配策略.</p> <h5 id="消费确认"><a href="#消费确认" class="header-anchor">#</a> 消费确认</h5> <p><mark><strong>那么当数据被消费成功后, 就必须进行消费确认操作了, 告诉服务端已经成功消费了这个数据. 消费确认就是在消息队列中常说的 ACK</strong></mark>.</p> <p>一般情况下, <mark><strong>消息确认分为确认后删除数据和确认后保存消费进度数据两种形式</strong></mark>.</p> <p><strong>确认后删除数据</strong> 是指集群的每条消息只能被<strong>消费一次</strong>, 只要数据被消费成功, 就会回调服务端的 ACK 接口, 服务端就会执行数据删除操作. 在实际开发的过程中, 一般都会支持单条 ACK 和批量 ACK 两种操作. 这种方式不利于回溯消费, 所以<strong>用得比较少</strong>.</p> <p>​<img src="/img/12b587f119d537efb3a7115979941dc2-20240421231949-2o3atid.jpg" alt="">​</p> <p><strong>消费成功保存消费进度</strong> 是指当消费数据成功后, 调用服务端的消费进度接口来保存消费进度. 这种方式一般都是配合消费分组一起用的, <strong>服务端从消费分组维度来保存进度数据</strong>.</p> <p>​<img src="/img/ff28fc25ee6ef5d99596c701b8c5f7da-20240421231949-3i4tkuw.jpg" alt="">​</p> <p>为了<strong>保证消息的回溯消费和多次消费, 消息队列大多数用的是第二种方案</strong>.</p> <p><strong>数据的删除交由数据过期策略去执行</strong>. 保存消费进度一般分为<strong>服务端保存和客户端自定义保存</strong>两种实现机制.</p> <p><strong>服务端保存</strong> 是指当消费端消费完成后, 客户端需要调用一个接口提交信息, 这个接口是由服务端提供的 &quot;提交消费进度&quot; 接口, 然后服务端会持久保存进度. 当客户端断开重新消费时, 可以从服务端读取这个进度进行消费. 服务端一般会通过内置的 Topic 或者文件来持久保存该数据. 这种方式的优点就是客户端会封装好这些逻辑, 使用简单, 无需管理进度相关的信息, 缺点就是不够灵活. 服务端保存一般是默认的方案.</p> <p>在提交位点信息的时候, 底层一般支持自动提交和手动提交两种实现.</p> <ul><li><strong>自动提交</strong> 一般是根据时间批次或数据消费到客户端后就自动提交, 提交过程客户无感知.</li> <li><strong>手动提交</strong> 是指业务根据自己的处理情况, 手动提交进度信息, 以避免业务处理异常导致的数据丢失.</li></ul> <p>它们两者的优缺点如下表所示:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/144495cf3102ce8f56cbf729771a6eda-20240421231949-0wyyg69.jpg" alt=""></p> <p>一般情况下, 建议使用<strong>手动提交方式</strong>, 可以避免数据丢失.</p> <p><strong>客户端自定义保存</strong> 是指当消费完成后, 客户端自己管理保存消费进度. 此时就不需要向服务端接口提交进度信息了, 自定义保存进度信息即可, 比如保存在客户端的缓存, 文件, 自定义的服务中, 当需要修改和回滚的时候就比较方便. 这种方案的优点就是灵活, 缺点就是会带来额外的工作量.</p> <p>业界主流来看, 这两种方案用得都比较多, 不过默认情况下都是使用第一种方案, 业务需要的话就选择第二种方案.</p> <h5 id="消费失败处理"><a href="#消费失败处理" class="header-anchor">#</a> 消费失败处理</h5> <p>一个完整的消费流程包括消费数据, 本地业务处理, 消费进度提交三部分.</p> <p>那么从消费失败的角度来看, 就应该分为<mark><strong>从服务端拉取数据失败, 本地业务数据处理失败, 提交位点信息失败</strong></mark>三种情况. 下面逐一来看一下.</p> <p><strong>从服务端拉取数据失败</strong>, 和客户端的错误逻辑处理是一致的, 根据可重试错误和不可重试错误的分类, 进行重复消费或者向上抛错.</p> <p><strong>本地业务数据处理失败</strong>, 处理起来就比较复杂了. 如果是偶尔失败, 那么在业务层做好<strong>重试处理逻辑</strong>, 配合手动提交消费进度的操作即可解决. 如果是一直失败, 即使重试多次也无法被解决, 比如这条数据内容有异常, 导致无法被处理. 此时如果一直重试, 就会出现消费卡住的情况, 这就需要配合<strong>死信队列</strong>的功能, 将无法被处理的数据投递到死信队列中, 从而保存异常数据并保证消费进度不阻塞.</p> <p><strong>提交位点信息失败</strong>, 其处理方法通常是一直重试, 重复提交, 如果持续失败就向上抛错. 因为如果提交进度失败, 即使再从服务端拉取数据, 还是会拉到同一批数据, 出现重复消费的问题.</p> <h5 id="总结-9"><a href="#总结-9" class="header-anchor">#</a> 总结</h5> <p>从设计上看, 消费端要解决的问题依次分为三步:</p> <ol><li><strong>满足基本的消费需求, 能消费到数据, 确认数据</strong>.</li> <li><strong>满足稳定性和性能的需求, 能快速稳定地消费到数据</strong>.</li> <li><strong>支持功能方面的需求, 比如回溯消费, 消费删除, 广播消费等等</strong>.</li></ol> <p>为了能满足基本的消费需求, 服务端会提供消费和确认接口, 同时在客户端封装消费和确认操作中, 底层通过网络层和服务端建立, 维护 TCP 连接, 然后通过协议完成基本的消费操作.</p> <p>如果要<strong>回溯消费, 则需要单独记录消费进度</strong>. 这样就能抽象出消费分组的概念, 用来管理消费者, 分区, 消费进度的关系. 通过消费分组来记录消费进度, 从而实现数据的多次分发. 另外, 消费分组机制也可以用在广播消费的场景.</p> <p>在消费确认的过程中, 一般需要客户端回调服务端提供的确认接口. 确认接口分为确认删除和确认记录消费进度两种模式. 主流方式是在确认的时候记录消费进度.</p> <p>异常处理主要是为了保证数据能被正常消费, 重点关注不丢数据, 不重复消费, 不阻塞住消费三个问题, 需要针对不同的问题做不一样的处理.</p> <h5 id="思考题-7"><a href="#思考题-7" class="header-anchor">#</a> 思考题</h5> <blockquote><p>从代码的实现角度, 如果让你负责开发某个消息队列客户端的消费模块, 你会怎么思考? 依次做哪些事情?</p></blockquote> <ol><li>做功能分析. 分析消费端要实现哪些功能, 比如消费, 确认, 然后分析是否需要提供顺序消费, 广播消费, 回溯消费等能力.</li> <li>根据功能需求, 先看 Broker 侧是否支持这些能力, 因为从消息队列的角度, 客户端只是使用者, 能否实现功能依赖服务端.</li> <li>了解服务端提供了哪些接口, 调用方式是什么(TCP 或 HTTP), 协议内容是怎样的.</li> <li>分析功能要如何实现, 哪些功能需要和哪些接口交互, 然后完成消费模型和分区消费模式的选择.</li> <li>完成网络模块, 协议模块, 序列化/反序列化等基础模块的开发.</li> <li>通过基础模块和服务端提供的接口, 完成最基本的消费流程开发.</li> <li>完善消费组, 消费确认等模块的开发.</li> <li>完善异常失败处理, 日志记录, 指标监控等工作.</li></ol> <h4 id="_10-从基础功能拆解rabbitmq的架构设计与实现"><a href="#_10-从基础功能拆解rabbitmq的架构设计与实现" class="header-anchor">#</a> 10-从基础功能拆解RabbitMQ的架构设计与实现</h4> <p>在基础篇开篇的时候, 说过最基础的消息队列应该具备 <strong>通信协议</strong>, <strong>网络模块</strong>, <strong>存储模块</strong>, <strong>生产者</strong>, <strong>消费者</strong> 五个模块. 在之前的课程中, 详细分析了这五个模块的选型, 设计和实现思路, 接下来从消息和流的角度, 用四节课的篇幅分别讲一下<mark><strong>消息方向</strong></mark>的消息队列 RabbitMQ, RocketMQ, 流方向的消息队列 Kafka, Pulsar, 在这五个模块的实现思路和设计思想. 这节课先讲 RabbitMQ.</p> <p>​<img src="/img/9b8b5a5fe12b677377a3497c863373f1-20240421231949-tcja7ah.jpg" alt="">​</p> <h5 id="rabbitmq系统架构"><a href="#rabbitmq系统架构" class="header-anchor">#</a> RabbitMQ系统架构</h5> <p>在正式讲解之前, 先来看一下 RabbitMQ 的系统架构.</p> <p>​<img src="/img/f87175e8b0e42c14bf648dfa8f18608d-20240421231949-xshrspi.jpg" alt="">​</p> <p>如上图所示, RabbitMQ 由 <strong>Producer, Broker, Consumer</strong> 三个大模块组成. 生产者将数据发送到 Broker, Broker 接收到数据后, 将数据存储到对应的 Queue 里面, 消费者从不同的 Queue 消费数据.</p> <p>那么除了 Producer, Broker, Queue, Consumer, ACK 这几个消息队列的基本概念外, 它还有 Exchange, Bind, Route 这几个独有的概念. 下面简单解释下.</p> <p><strong>Exchange 称为交换器, 它是一个逻辑上的概念, 用来做分发, 本身不存储数据</strong>. 流程上生产者先将消息发送到 Exchange, 而不是发送到数据的实际存储单元 Queue 里面. 然后 Exchange 会根据一定的规则将数据分发到实际的 Queue 里面存储. 这个分发过程就是 <strong>Route</strong>(路由), <strong>设置路由规则的过程就是 Bind(绑定)</strong> . 即 Exchange 会接收客户端发送过来的 route_key, 然后根据不同的路由规则, 将数据发送到不同的 Queue 里面.</p> <p>这里需要注意的是, <strong>在 RabbitMQ 中是没有 Topic 这个用来组织分区的逻辑概念的</strong>. RabbitMQ 中的 Topic 是指 Topic 路由模式, 是一种路由模式, 和消息队列中的 Topic 意义是完全不同的.</p> <p>那为什么 RabbitMQ 会有 Exchange, Bind, Route 这些独有的概念呢?</p> <p>在我看来, 主要和当时业界的架构设计思想以及主导设计 AMQP 协议的公司背景有关. 当时的设计思路是: <strong>希望发消息跟写信的流程一样</strong>, 可以有一个集中的分发点(邮局), 通过填写好地址信息, 最终将信投递到目的地. 这个集中分发点(邮局)就是 Exchange, 地址信息就是 Route, 填写地址信息的操作就是 Bind, 目的地是 Queue.</p> <p>讲清楚基本概念和架构, 就围绕着前面提到的五个模块来分析一下 RabbitMQ, 先来看一下协议和网络模块.</p> <h5 id="协议和网络模块"><a href="#协议和网络模块" class="header-anchor">#</a> 协议和网络模块</h5> <p>在网络通信协议层面, RabbitMQ 数据流是基于<strong>四层 TCP 协议通信</strong>的, 跑在 TCP 上的应用层协议是 AMQP. 如果开启 Management 插件, 也可以支持 HTTP 协议的生产和消费. TCP + AMQP 是数据流的默认访问方式, 也是官方推荐的使用方式, 因为它性能会比 HTTP 高很多.</p> <p><strong>RabbitMQ 在协议内容和连接管理方面, 都是遵循 AMQP 规范</strong>. 即 RabbitMQ 的模型架构和 AMQP 的模型架构是一样的, 交换器, 交换器类型, 队列, 绑定, 路由键等都是遵循 AMQP 协议中相应的概念.</p> <p>AMQP 是一个应用层的通信协议, 可以看作一系列结构化命令的集合, 用来填充 TCP 层协议的 body 部分. 通过协议命令进行交互, 可以完成各种消息队列的基本操作, 如 Connection.Start(建立连接), Basic.Publish(发送消息)等等.</p> <p>下面是一张生产消息流程的协议命令交互图, 大概包含了<strong>建立连接, 发送消息, 关闭连接</strong>三个步骤.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3ac2a647eef108b497489ffd4ac373ac-20240421231949-ctuufd9.jpg" alt=""></p> <p>讲完了协议, 来看看网络模块.</p> <p>先来看下面这张图, 在 RabbitMQ 的网络层有 <strong>Connectoion 和 Channel</strong> 两个概念需要关注.</p> <p>​<img src="/img/ea2d2d5554a916929e2c26a3dd0aa145-20240421231949-wfyc2y2.jpg" alt="">​</p> <p>Connection 是指 TCP 连接, Channel 是 Connection 中的虚拟连接. 两者的关系是: 一个客户端和一个 Broker 之间只会建立一条 TCP 连接, 就是指 Connection. Channel(虚拟连接)的概念在这个连接中定义, 一个 Connection 中可以创建多个 Channel.</p> <p><strong>客户端和服务端的实际通信都是在 Channel 维度通信的</strong>. 这个机制可以减少实际的 TCP 连接数量, 从而降低网络模块的损耗. 从设计角度看, 也是基于 IO 复用, 异步 I/O 的思路来设计的.</p> <p>从编码实现的角度, RabbitMQ 的网络模块设计会比较简单. 主要包含 tcp_listener, tcp_acceptor, rabbit_reader 三个进程. 如下图所示, RabbitMQ 服务端通过 tcp_listener 监听端口, tcp_acceptor 接收请求, rabbit_reader 处理和返回请求. 本质上来看是也是一个<strong>多线程的网络模型</strong>.</p> <p><img src="/img/821c6d165ab208520114b1aa4a922462-20240421231949-g81lcvq.jpg" alt=""></p> <p>接下来看看 RabbitMQ 的存储模块.</p> <h5 id="数据存储"><a href="#数据存储" class="header-anchor">#</a> 数据存储</h5> <p>RabbitMQ 的存储模块也包含<strong>元数据存储与消息数据存储</strong>两部分. 如下图所示, RabbitMQ 的两类数据都是存储在 Broker 节点上的, 不会依赖第三方存储引擎. 先来看一下元数据存储.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0480177d8f6c5c26d09681e193b098e0-20240421231949-owk3ma7.jpg" alt=""></p> <h6 id="元数据存储"><a href="#元数据存储" class="header-anchor">#</a> 元数据存储</h6> <p><strong>RabbitMQ 的元数据都是存在于 Erlang 自带的分布式数据库 Mnesia 中的</strong>. 即每台 Broker 都会起一个 Mnesia 进程, 用来保存一份完整的元数据信息. 因为 Mnesia 本身是一个分布式的数据库, 自带了多节点的 Mnesia 数据库之间的同步机制. 所以在元数据的存储模块, RabbitMQ 的 Broker 只需要调用本地的 Mnesia 接口保存, 变更数据即可. 不同节点的元数据同步 Mnesia 会自动完成.</p> <p><strong>Mnesia 对 RabbitMQ 的作用, 相当于 ZooKeeper 对于 Kafka, NameServer 对于 RocketMQ 的作用</strong>. 因为 Mnesia 是内置在 Broker 中, 所以部署 RabbitMQ 集群时, 会发现只需要部署 Broker, 不需要部署其他的组件. 这种部署结构就很简单清晰, 从而也降低了后续的运维运营成本.</p> <p>在一些异常的情况下, 如果不同节点上的 Mnesia 之间的数据同步出现问题, 就会导致不同的 Mnesia 数据库之间数据不一致, 进而导致集群出现脑裂, 无法启动等情况. 此时就需要手动修复异常的 Mnesia 实例上的数据.</p> <p>因为 Mnesia 本身是一个数据库, 所以它和数据库一样, 可以进行增删改查的操作.</p> <h6 id="消息数据存储"><a href="#消息数据存储" class="header-anchor">#</a> 消息数据存储</h6> <p>如下图所示, RabbitMQ 消息数据的<strong>最小存储单元是 Queue, 即消息数据是按顺序写入存储到 Queue 里面的</strong>. 在底层的数据存储方面, 所有的 Queue 数据是存储在同一个 &quot;文件&quot; 里面的. 这个 &quot;文件&quot; 是一个虚拟的概念, 表示<strong>所有的 Queue 数据是存储在一起</strong>的意思.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/74b2ac5738e07dd057f240da425bd4a5-20240421231949-gsk37cr.jpg" alt="">​</p> <p>这个 &quot;文件&quot; 由<strong>队列索引(rabbit_queue_index)和消息存储(rabbitmq_msg_store)</strong> 两部分组成. 即在节点维度, 所有 Queue 数据都是存储在 rabbit_msg_store 里面的, 每个节点上只有一个 rabbit_msg_store, 数据会依次顺序写入到 rabbit_msg_store 中.</p> <p>rabbit_msg_store 是一个逻辑概念, 底层的实际存储单元分为两个, msg_store_persistent 和 msg_store_transient, 分别负责持久化消息和非持久化消息的存储.</p> <p>msg_store_persistent 和 msg_store_transient 在操作系统上是以<strong>文件夹</strong>的形式表示的, 具体的数据存储是以不同的文件段的形式存储在目录中, 所有消息都会以追加的形式写入到文件中. 当一个文件的大小超过了配置的单个文件的最大值, 就会关闭这个文件, 然后再创建一个文件来存储数据. 关于 RabbitMQ 底层的数据存储结构, 如下图所示:</p> <p>​<img src="/img/c64ca1f193546d64e7628efbb3c62828-20240421231949-rdyhiec.jpg" alt="">​</p> <p>队列索引负责存储, 维护队列中落盘消息的信息, 包括消息的存储位置, 是否交付, 是否 ACK 等等信息. 队列索引是 Queue 维度的, 每个 Queue 都有一个对应的队列索引.</p> <p>RabbitMQ 也提供了 <strong>过期时间(TTL)机制</strong>, 用来删除集群中没用的消息. 它支持单条消息和队列两个维度来设置数据过期时间. 如果在队列上设置 TTL, 那么队列中的所有消息都有相同的过期时间. 也可以对单条消息单独设置 TTL, 每条消息的 TTL 可以不同. 如果两种方案一起使用, 那么消息的 TTL 就会以两个值中最小的那个为准. 如果不设置 TTL, 则表示此消息不会过期.</p> <p>删除消息时, 不会立即删除数据, 只是从 Erlang 中的 ETS 表删除指定消息的相关信息, 同时更新消息对应的存储文件的相关信息. 此时文件中的消息不会立即被删除, 会被标记为已删除数据, 直到一个文件中都是可以删除的数据时, 再将这个文件删除, 这个动作就是常说的延时删除. 另外内核有检测机制, 会检查前后两个文件中的数据是否可以合并, 当符合合并规则时, 会进行段文件的合并.</p> <h5 id="生产者和消费者"><a href="#生产者和消费者" class="header-anchor">#</a> 生产者和消费者</h5> <p>在了解了 RabbitMQ 的协议, 网络模块和数据存储后, 再来看一下 RabbitMQ 的生产者和消费者的实现.</p> <p>当<strong>生产者和消费者连接到 Broker 进行生产消费的时候, 是直接和 Broker 交互的, 不需要客户端寻址</strong>. 客户端连接 Broker 的方式, 跟通过 HTTP 服务访问 Server 是一样的, 都是直连的. 部署架构如下图所示:</p> <p>​<img src="/img/d24b1062887f5294e4466aac8a2c8a16-20240421231949-js92rko.jpg" alt="">​</p> <p>RabbitMQ 集群部署后, 为了提高容灾能力, 就需要在集群前面<strong>挂一层负载均衡</strong>来进行灾备. 客户端拿到负载均衡 IP 后, 在生产或消费时使用这个 IP 和服务端直接建立连接. 因为 Queue 是具体存储数据的单元, 不同的 Queue 有可能分布在不同的 Broker 上, 就有可能出现生产或消费基于负载均衡 IP 请求到的 Broker, 并不是当前 Queue 所在的 Broker, 从而导致生产消费失败.</p> <p>为了解决这个问题, 在<strong>每个 Broker 上会设置有转发的功能</strong>. 在实现上, <strong>每台 Broker 节点都会保存集群所有的元数据信息. 当 Broker 收到请求后, 根据本地缓存的元数据信息判断 Queue 是否在本机上, 如果不在本机, 就会将请求转发到 Queue 所在的目标节点</strong>.</p> <p>从客户端的实现来看, 因为各个语言的实现机制不太一样, 基础模块的连接管理, 心跳管理, 序列化等部分遵循各编程语言的开发规范去实现. 例如网络模块的实现, 如果客户端是用 Java 语言写的, 那么可以使用 Java NIO 库完成网络模块的开发. 客户端和服务端传输协议的内容遵循 AMQP 协议, 底层以二进制流的形式序列化数据. 即根据 AMQP 协议的格式构建内容后, 然后序列化为二进制的格式, 传递给 Broker 进行处理.</p> <p>​<img src="/img/1d43484f7b21135639yye73a77549c4e-20240421231949-tk1e8mu.jpg" alt="">​</p> <p>生产端发送数据不是直接发送到 Queue, 而是直接发送到 Exchange. 即发送时需要指定 Exchange 和 route_key, 服务端会根据这两个信息, 将消息数据分发到具体的 Queue. 因为 Exchange 和 route_key 都是一个逻辑概念, 数据是直接发送到 Broker 的, 然后在服务端根据路由绑定规则, 将数据分发到不同的 Queue 中, 所以在客户端是没有发送生产分区分配策略的逻辑. 其实从某种程度来看, <strong>Exchagne 和 Route 的功能就是生产分区分配的过程, 只是将这个逻辑从客户端移动到了服务端而已</strong>.</p> <p>在消费端, RabbitMQ 支持 Push(推)和 Pull(拉)两种模式, 如果使用了 Push 模式, Broker 会不断地推送消息给消费者. 不需要客户端主动来拉, 只要服务端有消息就会将数据推给客户端. 当然推送消息的个数会受到 channel.basicQos 的限制, 不能无限推送, 在<strong>消费端会设置一个缓冲区来缓冲这些消息</strong>. 拉模式是指客户端不断地去服务端拉取消息, RabbitMQ 的拉模式只支持拉取单条消息.</p> <p>在 AMQP 协议中, 是没有定义 Topic 和消费分组的概念的, 所以在消费端没有消费分区分配, 消费分组 Rebalance 等操作, 消费者是直接消费 Queue 数据的.</p> <p>为了保证消费流程的可靠性, RabbitMQ 也提供了 <strong>消息确认机制</strong>. 消费者在消费到数据的时候, 会调用 ACK 接口来确认数据是否被成功消费.</p> <p>底层提供了<strong>自动 ACK 和手动 ACK 两种机制</strong>. 自动 ACK 表示当客户端消费到数据后, 消费者会自动发送 ACK, 默认是自动 ACK. 手动 ACK 表示客户端消费到数据后, 需要手动调用. ACK 的时候, 支持单条 ACK 和批量 ACK 两种动作, 批量 ACK 可以用来提升 ACK 效率. 另外, 为了提升 ACK 动作的性能, 有些客户端也支持异步的 ACK.</p> <h5 id="http协议支持和管控操作"><a href="#http协议支持和管控操作" class="header-anchor">#</a> HTTP协议支持和管控操作</h5> <p>在了解了上述的五个模块后, 最后来看一下 RabbitMQ 对 HTTP 协议的支持和管控操作.</p> <p>RabbitMQ 内核本身不支持 HTTP 协议的生产, 消费和集群管控等操作. 如果需要支持, 则需要先手动开启 Management 插件, 通过插件的形式让内核支持这个功能.</p> <p>大部分情况下, 都会建议启用 Management 插件, 否则集群使用就会不太方便. 如下图所示, 从实现上来看 Management 插件对 HTTP 协议的支持, 就是在开启插件的时候, 会启动一个新的 HTTP Server 来监听一个新的端口. 客户端只需要访问这个端口提供的 HTTP 接口, 就可以完成 HTTP 读写数据和一些集群管控的操作.</p> <p>​<img src="/img/373104dcd903214547b3f08fff7f2392-20240421231949-9d2vnkp.jpg" alt="">​</p> <p>开启插件后, 就可以通过 HTTP 接口实现生产, 消费, 集群的配置, 资源的创建, 删除等操作. 比如下面是一个查看 Vhost 列表的 curl 命令示例:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>curl -i --header &quot;authorization: Bearer &lt;token&gt;&quot; http://localhost:15672/api/vhosts
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h5 id="总结-10"><a href="#总结-10" class="header-anchor">#</a> 总结</h5> <p>RabbitMQ 主要有 Producer, Broker, Consumer, Exchange, Queue, Route, Bind, Connection, Channel, ACK 等概念.</p> <p>总结 RabbitMQ, 可以从以下七个方面入手:</p> <ol><li>协议层基于 AMQP 标准开发.</li> <li>网络层核心数据流基于 TCP 协议通信, 并通过 Connection 和 Channel 机制实现连接的复用, 以减少创建的 TCP 连接数量.</li> <li>存储层基于多个 Queue 数据统一到一个文件存储的思路设计, 同时支持分段存储和基于时间的数据过期机制.</li> <li>元数据存储是基于 Erlang 内置的数据库 Mnesia 来实现.</li> <li>客户端的访问是直连的, 没有客户端寻址机制.</li> <li>生产端是通过 Exchange 和 Route 写入数据的, 生产数据的分发是在服务端完成的, 其他消息队列的分发一般都是在客户端.</li> <li>消费端没有消费分组, 消费分区分配等概念, 直连 Queue 消费, 同时也提供了手动和自动两种 ACK 机制.</li></ol> <h5 id="思考题-8"><a href="#思考题-8" class="header-anchor">#</a> 思考题</h5> <blockquote><p>请按照基础篇的课程思路, 完整描述一下 RabbitMQ 从生产到消费的全过程?</p></blockquote> <p>跟经典的消息队列一样, RabbitMQ 的生产到消费总共经过生产者, Broker, 消费者三个模块. 大致的流程如下:</p> <p>在生产端, 客户端根据 AMQP 协议定义的命令字(如 Connection.Start/Start-Ok, Connection.Tune/Tune-Ok), 通过四层的 TCP 协议和 Broker 创建 Connection, Channel 进行通信. 客户端直连 Broker 服务, 不需要经过寻址, 然后客户端需要指定 Exchange, route_key 发送消息. 因为 AMQP 没有支持批量发送的协议, 消息会立即发送给给服务端. 通信协议的内容格式, 序列化和反序列化遵循 AMQP 的标准.</p> <p>Broker 收到消息后, <strong>根据 AMQP 协议反序列化解析出请求内容</strong>. 根据 Exchange 和 route_key 的信息, 结合路由模式, 将数据分发到具体的 Queue 中. 存储层收到消息后, 底层会将这条数据的结构进行整合, 添加一些额外信息, 如写入时间等, 然后将数据写入到同一个文件存储. Broker 支持数据过期机制, 当消息过期后, 数据会被删除.</p> <p><strong>消费端直接指定 Queue 消费, 不需要经过消费分组, 分区分配的过程</strong>. 消费端跟生产端一样, 根据 AMQP 协议连接上 Broker 后, 消费端直接从 Queue 中消费数据, 消费完成后通过手动 ACK 或自动 ACK 的方式 ACK 消息.</p> <h4 id="_11-从基础功能拆解rocketmq的架构设计与实现"><a href="#_11-从基础功能拆解rocketmq的架构设计与实现" class="header-anchor">#</a> 11-从基础功能拆解RocketMQ的架构设计与实现</h4> <p>上节分析了 RabbitMQ 在通信协议, 网络模块, 存储模块, 生产者, 消费者这五个模块的设计思路. 这节课用同一个思路来讲讲 RocketMQ.</p> <p>有一个蛮有意思的现象, 从统计数据来看, RabbitMQ 的用户数是最多的. 但是在程序员的口碑中, RocketMQ 无论是从性能还是稳定性上都是优于 RabbitMQ 的. 个人来看, <strong>RocketMQ 可以当作 RabbitMQ 的替代品</strong>, 因为 RocketMQ 在功能, 稳定性, 性能层面都比 RabbitMQ 的表现更好. 所以一起来看看为什么.</p> <h5 id="rocketmq系统架构"><a href="#rocketmq系统架构" class="header-anchor">#</a> RocketMQ系统架构</h5> <p>在正式讲解之前, 先来看一下 RocketMQ 的架构图.</p> <p>如下图所示, RocketMQ 由 <strong>Producer</strong>, <strong>NameServer</strong>, <strong>Broker</strong>, <strong>Consumer</strong> 四大模块组成. 其中, <strong>NameServer 是 RocketMQ 的元数据存储组件</strong>. 另外, 在 RocketMQ 5.0 后, 还增加了 <strong>Proxy 模块, 用来支持 gRPC 协议, 并为后续的计算存储分离架构做准备</strong>.</p> <p>​<img src="/img/6af4ab5debc9535849ab7da3e5022f38-20240421231949-yqgicdz.jpg" alt="">​</p> <p><strong>RocketMQ 有 Topic, MessageQueue, Group 的概念, 一个 Topic 可以包含一个或多个 MessageQueue, 一个 Group 可以订阅一个或多个 Topic. MessageQueue 是具体消息数据的存储单元, 订阅的时候通过 Group 来管理消费订阅关系</strong>.</p> <p>从流程上看, <mark><strong>Broker 在启动的时候会先连接 NameServer, 将各自的元数据信息上报给 NameServer, NameServer 会在内存中存储元数据信息. 客户端在连接集群的时候, 会配置对应的 NameServer 地址, 通过连接 NameServer 来实现客户端寻址, 从而连接上对应的 Broker</strong></mark>.</p> <p><mark><strong>客户端在发送数据的时候, 会指定 Topic 或 MessageQueue. Broker 收到数据后, 将数据存储到对应的 Topic 中, 消息存储在 Topic 的不同 Queue 中. 在底层的文件存储中, 所有 Queue 的数据是存储在同一个 CommitLog 文件中的. 在订阅的时候会先创建对应的 Group, 消费消息后, 再确认数据</strong></mark>.</p> <p>从客户端来看, 在 RocketMQ 5.0 以后, 也可以通过直连 Proxy, <strong>将数据通过 gRPC 协议发送给 Proxy</strong>. <strong>Proxy 在当前阶段本质上只是一个代理(gRPC 协议的代理), 不负责真正的数据存储, 当收到数据后, 还是将数据转发到 Broker 进行保存</strong>.</p> <p>学习完 RocketMQ 的基本概念和架构, 继续围绕上述的五个模块来分析一下 RocketMQ, 先来看一下协议和网络模块.</p> <h5 id="协议和网络模块-2"><a href="#协议和网络模块-2" class="header-anchor">#</a> 协议和网络模块</h5> <p>在协议方面, 如下图所示, RocketMQ 5.0 之前支持自定义的 <strong>Remoting 协议</strong>, 在 5.0 之后, 增加了 <mark><strong>gRPC 协议</strong></mark>的支持.</p> <p>这是在 Proxy 组件上完成了对 gRPC 协议的支持, 用的是前面讲的代理(Proxy)模式. 即 Broker 依旧只支持 Remoting 协议, 如果需要支持 gRPC 协议, 那么就需要单独部署 Proxy 组件.</p> <p>​<img src="/img/b1b45ffe1bf5e2870e53124815440dc9-20240421231949-sfd0jge.jpg" alt="">​</p> <p>在传输层协议方面, Remoting 和 gRPC 都是基于 TCP 协议传输的. Remoting 直接基于四层的 TCP 协议通信, gRPC 是基于七层的 HTTP2 协议通信, 不过 HTTP2 底层也是基于 TCP, 它们本质上都是应用层的协议.</p> <p>讲到这, 不知道你是否会想: <strong>Remoting</strong> <strong>不够用吗?</strong> <strong>为什么还需要</strong> <strong>gRPC</strong> <strong>呢?</strong></p> <p>在我看来, Remoting 从功能, 性能, 灵活性来看没有太大的问题. 它的主要缺点是<strong>私有协议客户端的重复开发成本, 以及与第三方服务集成的不便捷</strong>. 因为是私有协议, 所以 Remoting 在多语言 SDK 开发时, 基础网络模块的工作(如连接管理, 网络模型设计, 心跳管理等)都需要重新开发, 工作量很高. 另外, 生态连接在 RocketMQ 是一个很重要的工作, <strong>gRPC 作为公有协议, 有很多天然的生态集成能力, 比如 Service Mesh, Kubernetes 生态</strong>等等.</p> <p>关于 Remoting 协议的细节, 前面介绍协议时已经详细讲述了, 这里不再重复. 下面来聊一下 gRPC 协议, 先来看一下 gRPC 的架构图.</p> <p>​<img src="/img/b961c1a2a899610d7c0e0b5f24dcd0a3-20240421231949-yqebgxd.png" alt="图片">​</p> <p>如上图所示, <strong>gRPC 分为 Client 端和 Server 端, 底层基于 HTTP2通信, 内置了编解码模块, 也定义好了 Client 和 Server 之间的调用方式, 同时支持 TLS 加密, 是一个完整的 RPC 框架</strong>. 所以可以看到它在底层已经实现了网络通信, 协议的设计, 编解码框架等所有基础的工作. 从使用的角度来说, gRPC 提供了各个语言的开发库, 只需要集成对应语言的开发库, 即可完成网络模块的开发, 很轻便.</p> <p>因为在 RocketMQ网络模型 就分析了 RocketMQ 网络模块的详细实现, 这里就不重复讲了. 接下来看一下 RocketMQ 的存储层.</p> <h5 id="数据存储-2"><a href="#数据存储-2" class="header-anchor">#</a> 数据存储</h5> <p>RocketMQ 同 RabbitMQ 一样, 数据存储模块也分为<strong>元数据存储和消息数据存储</strong>两部分.</p> <h6 id="元数据存储-2"><a href="#元数据存储-2" class="header-anchor">#</a> 元数据存储</h6> <p>先来看一下元数据存储. <strong>RocketMQ 的元数据信息实际是存储在 Broker 上的, Broker 启动时将数据上报到 NameServer 模块中汇总缓存. NameServer 是一个简单的 TCP Server, 专门用来接收, 存储, 分发 Broker 上报的元数据信息. 这些元数据信息是存储在 NameServer 内存中的, NameServer 不会持久化去存储这些数据</strong>.</p> <p>​<img src="/img/278f259567c197cb42b8134880d0cb53-20240421231949-g4w9b83.jpg" alt="">​</p> <p>如上图所示, <strong>Broker 启动或删除时, 会调用 NameServer 的注册和退出接口, 每个 Broker 都会存储自己节点所属的元数据信息(比如有哪些 Topic, 哪些 Queue 在本节点上), 在 Broker 启动时, 会把全量的数据上报到 NameServer 中</strong>.</p> <p>从部署形态上看, NameServer 是<strong>多节点部署的, 是一个集群</strong>. 但是<mark><strong>不同节点之间是没有相互通信的, 所以本质上多个 NameServer 节点间数据没有一致性的概念, 是各自维护自己的数据, 由每台 Broker 上报元数据来维护每台 NameServer 节点上数据的准确性</strong></mark>.</p> <p>由于 NameServer 不负责具体消息数据的存储和分发, 所以在请求频率, 负载方面都不会很高. 所以在大多数场景下, NameServer 都是可以<strong>多集群共享</strong>的. 从功能上看, 它对 RocketMQ 的作用相当于 RabbitMQ 的 Mnesia.</p> <p>讲完了元数据, 再来看消息数据.</p> <h6 id="消息数据"><a href="#消息数据" class="header-anchor">#</a> 消息数据</h6> <p>RocketMQ 消息数据的最小存储单元是 MessageQueue, 也就是常说的 Queue 或 Partition. Topic 可以包含一个或多个 MessageQueue, 数据写入到 Topic 后, 最终消息会分发到对应的 MessageQueue 中存储.</p> <p>​<img src="/img/0dc590cca3709d82e04d3561e9223879-20240421231949-mcdyjc2.jpg" alt="">​</p> <p>在底层的文件存储方面, 并不是一个 MessageQueue 对应一个文件存储的, 而是<mark><strong>一个节点对应一个总的存储文件, 单个 Broker 节点下所有的队列共用一个日志数据文件(CommitLog)来存储</strong></mark>, 和 RabbitMQ 采用的是同一种存储结构. 存储结构如下图所示:</p> <p>​<img src="/img/e54d8fb1dffecbc91b978728b48a5369-20240421231949-j1ix22r.png" alt="图片">​</p> <p>图中主要包含 CommitLog, ConsumeQueue, IndexFile 三个跟消息存储相关的文件, 下面来了解一下.</p> <ul><li><strong>CommitLog</strong> 是消息主体以及元数据存储主体, 每个节点只有一个, 客户端写入到所有 MessageQueue 的数据, 最终都会存储到这一个文件中.</li> <li><strong>ConsumeQueue</strong> 是<strong>逻辑消费队列, 是消息消费的索引, 不存储具体的消息数据</strong>. 引入的目的主要是提高消息消费的性能. 由于 RocketMQ 是基于主题 Topic 的订阅模式, 消息消费是针对主题进行的, 如果要遍历 Commitlog 文件, 基于 Topic 检索消息是非常低效的. <strong>Consumer 可根据 ConsumeQueue 来查找待消费的消息, ConsumeQueue 文件可以看成是基于 Topic 的 CommitLog</strong> <mark><strong>索引文件</strong></mark>.</li> <li><strong>IndexFile</strong> 是索引文件, 它在文件系统中是以 HashMap 结构存储的. 在 RocketMQ 中, 通过 Key 或时间区间来查询消息的功能就是由它实现的.</li></ul> <p>值得关注的是, 因为消息数据会很多, <strong>CommitLog 会存储所有的消息内容. 所以为了保证数据的读写性能, 会对 CommitLog 进行分段存储</strong>. CommitLog 底层默认单个文件大小为 1G, 消息是顺序写入到文件中, 当文件满了, 就会写入下一个文件. <strong>对于 ConsumeQueue 和 IndexFile, 则不需要分段存储, 因为它们存储的是索引数据, 数据量一般很小</strong>.</p> <p>在消息清理方面, RocketMQ 支持按照时间清理数据. 这个时间是按照消息的生产时间计算的, 和消息是否被消费无关, <strong>只要时间到了, 那么数据就会被删除</strong>.</p> <p>不过跟 RabbitMQ 不同的是, RocketMQ 不是按照主题或队列维度来清理数据的, 而是<strong>按照节点的维度来清理</strong>的. 原因和 RocketMQ 的存储模型有关, 上面说到 RocketMQ 所有 Queue 的日志都存储在一个文件中, 如果要支持主题和队列单独管理, 需要进行数据的合并, 索引的重建, 实现难度相对复杂, 所以 RocketMQ 并没有选择主题和队列这两个维度的清理逻辑.</p> <p>好了, 协议, 网络, 数据存储就都讲完了, 接下来看一下 RocketMQ 客户端的生产者和消费者的实现.</p> <h5 id="生产者和消费者-2"><a href="#生产者和消费者-2" class="header-anchor">#</a> 生产者和消费者</h5> <p><strong>RocketMQ 的客户端连接服务端是需要经过客户端寻址的</strong>. 如下图所示, <strong>首先和 NameServer 完成寻址, 拿到 Topic/MessageQueue 和 Broker 的对应关系后, 接下来才会和 Broker 进行交互</strong>.</p> <p>​<img src="/img/c37175b6ba7ec1fc369f561e849b4fc8-20240421231949-i710xow.jpg" alt="">​</p> <h6 id="生产端"><a href="#生产端" class="header-anchor">#</a> 生产端</h6> <p>生产端的<strong>基础模块(如连接管理, 心跳检测, 协议构建, 序列化等工作), 则会以协议和网络层的设计为准, 使用不同编程语言 SDK 完成对应的开发</strong>. 例如, 在 Java 中, 可以使用 Netty 来构建客户端, 进行 TCP 通信, 根据 Remoting 协议构建请求数据, 序列化后向服务端发起请求, 或者直接使用 gRPC 框架的客户端进行通信.</p> <p>从生产端来看, 生产者是将数据发送到 Topic 或者 Queue 里面的. 如果是发送到 Topic, 则数据要经历生产数据分区分配的过程. <strong>即决定消息要发送到哪个目标分区</strong>.</p> <p>默认情况下, RocketMQ 支持<strong>轮询算法和最小投递延迟算法两种策略</strong>. 默认是轮询算法, 该算法保证了每个 Queue 中可以均匀地获取到消息. 最小投递延迟算法会统计每次消息投递的时间延迟, 然后根据统计出的结果将消息投递到时间延迟最小的 Queue. 如果是直接发送到 Queue, 则无需经过分区选择, 直接发送即可.</p> <p>由于 RocketMQ 在协议层不支持批量发送消息的协议, 所以在 SDK 底层是没有等待, 聚合发送逻辑的. 所以如果需要批量发送数据, 就需要在生产的时候进行聚合, 然后发送.</p> <p>为了满足不同的发送场景, <mark><strong>RocketMQ</strong></mark> <mark></mark> <mark><strong>支持单向发送, 同步发送, 异步发送三种发送形式</strong></mark>. 单向发送(Oneway)指发送消息后立即返回, 不处理响应, 不关心是否发送成功. 同步发送(Sync)指发送消息后等待响应. 异步发送(Async)指发送消息后立即返回, 在提供的回调方法中处理响应.</p> <h6 id="消费端"><a href="#消费端" class="header-anchor">#</a> 消费端</h6> <p>在 RocketMQ 消费端, 为了满足不同场景的消费需要, RocketMQ <strong>同时支持 Pull, Push, Pop 三种消费模型</strong>.</p> <p><mark><strong>默认的消费模型是 Pull, Pull 的底层是以客户端会不断地去服务端拉取数据的形式实现的</strong></mark>. Push 模型底层是以伪 Push 的方式实现的, 即在客户端底层用一个 Pull 线程不断地去服务端拉取数据, 拉到数据后, 触发客户端设置的回调函数. 让客户端从感受上看, 是服务端直接将数据 Push 过来的.</p> <p>另外, 当消费者和分区都很多的时候, 因为消费重平衡会消耗很长时间, 且重平衡期间的消费会暂停. 而在客户端也需要感知到复杂的重平衡行为, 各个语言的客户端需要较高的重复开发成本. 所以, <strong>RocketMQ 推出了 Pop 模式, 将消费分区, 分区分配关系, 重平衡都移到了服务端, 减少了重平衡机制给客户端带来的复杂性</strong>.</p> <p>RocketMQ 默认是通过<strong>消费分组机制</strong>来消费的. 即在客户端消费数据的时候, 会通过消费分组来管理消费关系和存储消费进度. 从实现上看, 同一条消息支持被多个消费分组订阅, 每个消费者分组可以有多个消费者.</p> <p>由于 Topic 和 Queue 模型的存在, <strong>在启动消费的时候, 就需要先分配消费者和分区消费关系. 这个过程就是 RocketMQ 消费端负载均衡. 在实现中, 消息按照哪种逻辑分配给哪个消费者, 就是由消费者负载均衡策略所决定的</strong>.</p> <p>根据消费者类型的不同, 消费者负载均衡策略分为<strong>消息粒度负载均衡和队列粒度负载均衡</strong>两种模式. 这里简单了解下.</p> <p><strong>消息粒度负载均衡</strong> 是指同一消费者分组内的多个消费者, 将按照消息粒度平均分摊主题中的所有消息. 即同一个队列中的消息, 会被平均分配给多个消费者共同消费.</p> <p>​<img src="/img/bb949f7cde7e5c710b7232b9978f3759-20240421231949-94n4vir.jpg" alt="">​</p> <p><strong>队列粒度负载均衡</strong> 是指同一消费者分组内的多个消费者, 将按照队列粒度消费消息, 即<strong>每个队列仅被一个消费者消费</strong>.</p> <p>​<img src="/img/278ceayydfbe148a7c7767497b5ccdbe-20240421231949-2je0t9a.jpg" alt="">​</p> <p><strong>消息粒度负载均衡就是之前讲到的共享消费模式, 而队列粒度负载均衡就是独占消费模式</strong>. 大部分情况下, <strong>推荐优先使用队列粒度负载均衡</strong>.</p> <p>当消费端消费数据成功后, 就需要<strong>保存消费进度信息</strong>. <mark><strong>RocketMQ 通过提交消费位点信息来保存消费进度. 在服务端, RocketMQ 会为每个消费分组维护一份消费位点信息, 信息中会保存消费的 最大位点, 最小位点, 当前消费位点 等内容</strong></mark>.</p> <p>​<img src="/img/db391cae3483d129fe5fc1d31eb2d242-20240421231949-kkjx5uc.jpg" alt="">​</p> <p>从实现来看, 客户端消费完数据后, 就会<strong>调用 Broker 的消费位点更新接口, 提交当前消费的位点信息</strong>.</p> <p>在服务端, <strong>消息被某个消费者消费完成后, 不会立即在队列中被删除, 以便当消费者客户端停止又再次重新上线时, 会严格按照服务端保存的消费进度继续处理消息</strong>. 如果服务端保存的历史位点信息已过期被删除, 此时消费位点向前移动至服务端存储的最小位点.</p> <p>讲完了生产者和消费者, 接下来来看看 RocketMQ 对 HTTP 协议的支持和集群管控操作的实现.</p> <h5 id="http协议支持和管控操作-2"><a href="#http协议支持和管控操作-2" class="header-anchor">#</a> HTTP协议支持和管控操作</h5> <p>RocketMQ 原生不支持 HTTP 协议的生产消费, 但是在一些云厂商的商业化版本是支持的. 从技术上来看, <strong>HTTP 协议的支持和 gRPC 的支持可以是一个技术思路, 即通过使用 Proxy 模式来实现</strong>.</p> <p>同样的, RocketMQ 的管控也是不支持 HTTP 协议的操作的. RocketMQ 的管控操作都是通过 Remoting 协议支持的, 在 gRPC 协议中也不支持管控操作. 即在 Broker 中, 通过 Remoting 协议暴露不同的接口或者在 NameServer 中暴露 TCP 的接口, 来实现一些对应的管控操作.</p> <p>客户端 SDK 会集成调用服务端这些接口的逻辑. 命令行工具就是通过客户端 SDK 来完成管控操作, 也可以在代码中通过 SDK 来执行管控操作.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9353b611ea01ff5b0a91fd6e6d510d5e-20240421231949-0nf059d.jpg" alt="">​</p> <h5 id="总结-11"><a href="#总结-11" class="header-anchor">#</a> 总结</h5> <p>现在来总结一下 RocketMQ.</p> <ol><li>协议层支持 Remoting 和 gRPC 两种协议.</li> <li>网络层是基于 Java NIO 框架 Netty 开发, 底层也是通过多路复用, 异步 IO, Reactor 模型等技术来提高网络模块的性能.</li> <li>存储层是基于多个 MessageQueue 的数据统一存储到一个文件的思路来设计的, 同时也支持分段存储和基于时间的数据过期机制.</li> <li>元数据存储是使用 Broker + 自定义的 NameServer 之间的配合来实现的.</li> <li>客户端的访问需要经过客户端寻址机制, 拿到元数据信息后, 才直连 Broker.</li> <li>生产端是将数据写入到 Topic 或分区, 写入 Topic 时需要经过生产分区分配操作, 确认最终写入的 MessageQueue 也支持多种写入方式.</li> <li>消费端有消费分组的概念, 也需要在多个消费者和消费分组之间进行消费的负载均衡, 最后通过提交消费位点的形式来保存消费进度.</li></ol> <h5 id="思考题-9"><a href="#思考题-9" class="header-anchor">#</a> 思考题</h5> <blockquote><p>请按照基础篇的思路, 描述一下 RocketMQ 从生产到消费的全过程, 越详细越好.</p></blockquote> <p>跟经典的消息队列一样, RocketMQ 生产到消费也经过了生产者, Broker, 消费者三个模块. 这里通过 Remoting 协议来讲解一下大致的流程, 具体如下:</p> <p>在生产端, 客户端通过四层的 TCP 协议和 NameServer 建立连接, 通过 Remoting 协议从 NameServer 获取到集群的元数据信息. 根据元数据信息, 和对应的 Broker 的建立 TCP 连接. 如果客户端指定了目标 Topic, 消息则先经过消息分区分配, 然后才将数据发送到 Broker 中. 因为 Remoting 也没有支持 Batch 的协议, 所以数据会直接发送到对应的 Broker, 可以使用单向发送, 同步发送, 异步发送三种发送形式.</p> <p>Broker 接收到数据后, 会先使用 Remoting 反序列化数据. 然后解析处理数据, 将数据整合后, 在底层会写入到同一个文件中, 存储数据的时候会进行分段存储. 如果是集群部署并设置了副本, 则数据会分发到其他 Broker 的副本中. 当数据过期后, Broker 会自动清理节点上的数据.</p> <p>在消费端, 可以先选择 Pull, Push, Pop 其中的一种消费模型. 客户端同样需要先和 NameServer 完成寻址操作. 消费端有消费分组的概念, 所以会先进行消费者和分区的消费关系分配的流程, 然后消费者会和自己消费的分区的 Leader 所在的 Broker 建立连接. 接着, 客户端会使用 Remoting 协议从 Broker 消费数据. 数据消费成功后, 最后会提交消费进度.</p> <h4 id="_12-从基础功能拆解kafka的架构设计与实现"><a href="#_12-从基础功能拆解kafka的架构设计与实现" class="header-anchor">#</a> 12-从基础功能拆解Kafka的架构设计与实现</h4> <p>上节课分析了 RocketMQ 在通信协议, 网络模块, 存储模块, 生产者, 消费者这五个模块的设计思路. 这节课同样还是分析 Kafka 在这五个模块的设计实现.</p> <p>在学习的过程中, 会<strong>发现 Kafka 和 RocketMQ 的架构是非常像的</strong>, 那为什么今天还要单独拿出一节课来分析 Kafka 呢? 因为它们俩面对的<strong>场景</strong>是不一样的, <strong>一个是消息场景, 一个是流场景, 所以它们在底层的协议设计, 存储模型, 消费方式的实现上也是不一样的</strong>. 而实现的不同, 又导致了它们在功能和性能上的表现不一样.</p> <p>接下来就从底层原理的角度来看一下, 它们都有哪些异同点.</p> <h5 id="kafka系统架构"><a href="#kafka系统架构" class="header-anchor">#</a> Kafka系统架构</h5> <p>首先来看一下 Kafka 的架构图.</p> <p>​<img src="/img/39d54678ca944b19d2470521dfbec15a-20240421231949-xyrhn85.jpg" alt="">​</p> <p>如上图所示, Kafka 由 <strong>Producer, Broker, ZooKeeper, Consumer</strong> 四个模块组成. 其中, <strong>ZooKeeper 用来存储元数据信息, 集群中所有元数据都持久化存储在 ZooKeeper 当中</strong>.</p> <p>Kafka 有 Topic 和分区的概念, 分区就相当于 RocketMQ 的 MessageQueue. 一个 Topic 可以包含一个或多个分区. 消费方面通过 Group 来组织消费者和分区的关系.</p> <p>到这你是不是发现了?  <strong>Kafka 架构和 RocketMQ 非常像.</strong>  从社区信息来看, RocketMQ 最初的设计应该参考过 Kafka, 所以它们的架构和概念非常像, 只是在具体实现方式上不太一样. 比如概念上分区和 MessageQueue 的作用是一样的, 元数据存储 ZooKeeper 和 NameServer 的作用也是一样的.</p> <p>前面讲过, <mark><strong>使用 ZooKeeper 作为元数据存储服务会带来额外的维护成本, 数据一致性和集群规模限制(主要是分区数)等问题. 所以 RocketMQ 使用 NameServer 替代 ZooKeeper, Kafka 3.0 使用内置的 Raft 机制替代 ZooKeeper, 就是为了解决这几个问题</strong></mark>.</p> <p>从消息的生命周期来看, 生产者也需要通过客户端寻址拿到元数据信息. 客户端通过生产分区分配机制, 选择消息发送到哪个分区, 然后根据元数据信息拿到分区 Leader 所在的节点, 最后将数据发送到 Broker. Broker 收到消息并持久化存储. 消费端使用消费分组或直连分区的机制去消费数据, 如果使用消费分组, 就会经过消费者和分区的分配流程, 消费到消息后, 最后向服务端提交 Offset 记录消费进度, 用来避免重复消费.</p> <p>讲完基本概念和架构, 继续围绕着基础篇的五个模块来分析一下 Kafka, 先来看一下协议和网络模块.</p> <h5 id="协议和网络模块-3"><a href="#协议和网络模块-3" class="header-anchor">#</a> 协议和网络模块</h5> <p>Kafka 是自定义的私有协议, 经过多年发展目前有 V0, V1, V2三个版本, 稳定在 V2 版本. 官方没有支持其他的协议, 比如 HTTP, 但是商业化的 Kafka 一般都会支持 HTTP 协议, 原因还是 HTTP 协议使用的便捷性.</p> <p>Kafka 协议从结构上来看包含协议头和协议体两部分, <strong>协议头包含基础通用的信息, 协议体由于每个接口的功能参数不一样, 内容结构上差异很大</strong>.</p> <p>Kafka 协议的细节在 应用通信协议设计 已经详细讲过了, 这里就不再重复. 关于协议的更多详细信息还可以参考 官方的协议文档.</p> <p>Kafka 服务端的网络层是<strong>基于 Java NIO 和 Reactor 来开发的, 通过多级的线程调度来提高性能</strong>. Kafka 网络层细节也讲过, 遗忘的话可以去复习.</p> <h5 id="数据存储-3"><a href="#数据存储-3" class="header-anchor">#</a> 数据存储</h5> <p>下面继续来看 Kafka 的存储层, Kafka 同样分为<strong>元数据存储和消息数据存储</strong>两部分.</p> <h6 id="元数据存储-3"><a href="#元数据存储-3" class="header-anchor">#</a> 元数据存储</h6> <p>上面说过, Kafka 的元数据是存储在 ZooKeeper 里面的. 元数据信息包括 Topic, 分区, Broker 节点, 配置等信息. <strong>ZooKeeper 会持久化存储全量元数据信息, Broker 本身不存储任何集群相关的元数据信息. 在 Broker 启动的时候, 需要连接 ZooKeeper 读取全量元数据信息</strong>.</p> <p>ZooKeeper 是一个单独的开源项目, 它自带了集群组网, 数据一致性, 持久化存储, 监听机制等等完整的能力. 它的底层是<strong>基于 Zab 协议组件集群</strong>, 有 Leader 节点和 Slave 节点的概念, 数据写入全部在 Leader 节点完成, Slave 负责数据的读取工作.</p> <p>​<img src="/img/5ed6a93804949915ebf406e7d76a7e78-20240421231949-fs5a98s.jpg" alt="">​</p> <p>从 ZooKeeper 的角度来看, <strong>Kafka 只是它的一个使用者</strong>, Kafka 用 ZooKeeper 的标准使用方式向 ZooKeeper 集群上写入, 删除, 更新数据, 以完成 Kafka 的元数据管理, 集群构建等工作. <strong>所以每台 Broker 启动时, 都会在 ZooKeeper 注册, 监听一些节点信息, 从而感知集群的变化</strong>.</p> <p>另外, <strong>Kakfa 集群中的一些如消费进度信息, 事务信息, 分层存储元数据, 以及 3.0 后的 Raft 架构相关的元数据信息, 都是基于内置 Topic 来完成存储的</strong>. 把数据存储在内置 Topic 中, 算是一个比较巧妙的思路了, 也是一个值得借鉴的技巧. Kafka 中存储不同功能的元数据信息的 Topic 列表如下所示:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6260ced9bbb35d3c9fc9185314df2d46-20240421231949-cqd9kqs.jpg" alt=""></p> <h6 id="消息数据-2"><a href="#消息数据-2" class="header-anchor">#</a> 消息数据</h6> <p>在消息数据存储方面, Kafka 的数据是以<strong>分区</strong>为维度单独存储的. 即写入数据到 Topic 后, <strong>根据生产分区分配关系, 会将数据分发到 Topic 中不同的分区</strong>. 此时底层不同分区的数据是存储在不同的 &quot;文件&quot; 中的, 即一个分区一个数据存储 &quot;文件&quot;. 这里提到的 &quot;文件&quot; 也是一个虚指, 在系统底层的表现是一个目录, 里面的文件会分段存储.</p> <p>如下图所示, 当 Broker 收到数据后, 是直接将数据写入到不同的分区文件中的. 所以在消费的时候, 消费者也是直接从每个分区读取数据. 这个存储模型和 RocketMQ, RabbitMQ 都不像, 这里的选择考虑和优劣势可以回顾 消息数据的存储.</p> <p>​<img src="/img/ffd5d608f6ffc0a2f506d098ba7f7782-20240421231949-her9166.jpg" alt="">​</p> <p>在底层数据存储中, Kafka 的存储结构是以 Topic 和分区维度来组织的. 一个分区一个目录, 目录名称是 <strong>TopicName + 分区号</strong>, 结构如下图所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>/data/kafka/data#ll
drwxr-xr-x 2 root root 4096 2月  15 2020 __consumer_offsets-0
drwxr-xr-x 2 root root 4096 2月  15 2020 __consumer_offsets-1
drwxr-xr-x 2 root root 4096 2月  15 2020 __consumer_offsets-2
drwxr-xr-x 2 root root 4096 2月  15 2020 __transaction_state-0
drwxr-xr-x 2 root root 4096 2月  15 2020 __transaction_state-1
drwxr-xr-x 2 root root 4096 2月  15 2020 __transaction_state-2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>每个分区的目录下, 都会有 <code>.index, .log, .timeindex</code>​ 三类文件. 其中, <code>.log</code>​ 是消息数据的存储文件, <code>.index</code>​ 是偏移量(offset)索引文件, <code>.timeindex</code>​ 是时间戳索引文件. 两个索引文件分别根据 Offset 和时间来检索数据.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>/data/data/data#ll __consumer_offsets-0
 总用量 0
-rw-r--r-- 1 root root 10485760 11月 19 2020 00000000000000000000.index
-rw-r--r-- 1 root root        0 2月  15 2020 00000000000000000000.log
-rw-r--r-- 1 root root 10485756 11月 19 2020 00000000000000000000.timeindex
-rw-r--r-- 1 root root        0 2月  15 2020 leader-epoch-checkpoint
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>在节点维度, 也会持久存储当前节点的数据信息(如 BrokerID)和一些异常恢复用的 Checkpoint 等数据.</p> <p>由于<strong>每个分区存储的数据量会很大, 分区数据也会进行分段存储</strong>. 分段是在 .log 进行的, 文件分段的默认数据大小也是 1G, 可以通过配置项来修改.</p> <p><strong>Kafka 提供了根据过期时间和数据大小清理的机制, 清理机制是在 Topic 维度生效的</strong>. 当数据超过配置的过期时间或者超过大小的限制之后, 就会进行清理. <strong>清理的机制也是延时清理的机制, 它是根据每个段文件进行清理的, 即整个文件的数据都过期后, 才会清理数据</strong>.</p> <p>特别说明的是, 根据大小清理的机制是在<strong>分区维度</strong>生效的, 不是 Topic. 即当分区的数据大小超过设置的大小, 就会触发清理逻辑. 这个机制和 RocketMQ 的清理机制是一致的, 但 RocketMQ 只提供了按节点维度配置的消息过期机制, 所以相比之下, 根据分区维度存储能带来一定的便捷.</p> <p>在存储性能上, <strong>Kafka 的写入大量依赖顺序写, 写缓存, 批量写来提高性能. 消费方面依赖批量读, 顺序读, 读缓存的热数据, 零拷贝来提高性能</strong>. 在这些技巧中, 每个分区的顺序读写是高性能的核心.</p> <p>接下来看一下客户端, 看看 Kafka 的生产者和消费者的实现.</p> <h5 id="生产者和消费者-3"><a href="#生产者和消费者-3" class="header-anchor">#</a> 生产者和消费者</h5> <p><strong>Kafka 客户端在连接 Broker 之前需要经过客户端寻址, 找到目标 Broker 的信息</strong>. 在早期, Kafka 客户端是通过链接 ZooKeeper 完成寻址操作的, 但是因为 ZooKeeper 的性能不够, 如果大量的客户端都访问 ZooKeeper, 那么就会导致 ZooKeeper 超载, 从而导致集群异常.</p> <p>所以在<strong>新版本的 Kafka 中, 客户端是通过直连 Broker 完成寻址操作</strong>的, 不会跟 ZooKeeper 交互. 即 Broker 跟 ZooKeeper 交互, 在本地缓存全量的元数据信息, 然后客户端通过连接 Broker 拿到元数据信息, 从而避免对 ZooKeeper 造成太大负载.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/49ca389c31ccd15cb11e3yyb31b3d449-20240421231949-yov7tdm.jpg" alt="">​</p> <p>RocketMQ 一直是通过 NameServer 完成寻址操作的, 这就是说的虽然 RocketMQ 和 Kafka 架构很像, 但是实际的实现相差很大.</p> <h6 id="生产者"><a href="#生产者" class="header-anchor">#</a> 生产者</h6> <p>生产者完成寻址后, <strong>在发送的时候可以将数据发送到 Topic 或者直接发送到分区</strong>. 发送到 Topic 时会经过生产分区分配的流程, 即根据一定的策略将数据发送到不同的分区.</p> <p><strong>Kafka 提供了轮询和 KeyHash 两种策略</strong>.</p> <p>轮询策略是指按<strong>消息维度轮询</strong>, 将数据平均分配到多个分区. Key Hash 是指根据消息的 Key 生成一个 Hash 值, 然后和分区数量进行取余操作, 得到的结果可以确定要将数据发送到哪个分区. 生产消息分配的过程是在客户端完成的.</p> <p>Kafka 协议提供了<strong>批量(Batch)发送</strong>的语义. 所以生产端会在本地先缓存数据, 根据不同的分区聚合数据后, 再根据一定的策略批量将数据写入到 Broker. 因为这个 Batch 机制的存在, <strong>客户端和服务端的吞吐性能会提高很多</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/92ce44f04a794c072c74de7dc2e48a2b-20240421231949-ceijjhd.jpg" alt="">​</p> <p>这里多讲一点, 客户端批量往服务端写有两种形式: <strong>一种是协议和内核就提供了 Batch 语义, 一种是在业务层将一批数据聚合成一次数据发送</strong>. 这两种虽然都是批量发送, 但是它们的区别在于:</p> <ol><li><strong>第一种批量消息中的每条消息都会有一个 Offset, 每条消息在 Broker 看来就是一条消息. 第二种批量消息是这批消息就是一条消息, 只有一个 Offset</strong>.</li> <li>在消费端看来, 第一种对客户端是无感的, 一条消息就是一条消息. 第二种需要消费者感知生产的批量消息, 然后解析批量, 逐条处理.</li></ol> <h6 id="消费者"><a href="#消费者" class="header-anchor">#</a> 消费者</h6> <p>Kafka 的消费端<strong>只提供了 Pull(拉)模式的消费. 即客户端是主动不断地去服务端轮询数据, 获取数据, 消费则是直接从分区拉取数据的</strong>. Kafka 提供了消费分组消费和直连分区消费两种模式, 这两者的区别在于, 是否需要进行消费者和分区的分配, 以及消费进度谁来保存.</p> <p><strong>大部分情况下, 都是基于消费分组消费</strong>. 消费分组创建, 消费者或分区变动的时候会进行重平衡, 重新分配消费关系. Kafka 默认提供了 RangeAssignor(范围), RoundRobinAssignor(轮询), StickyAssignor(粘性)三种策略, 也可以自定义策略. 消费分组模式下, 一个分区只能给一个消费者消费, 消费是顺序的.</p> <p>当客户端成功消费数据后, 会往服务端提交消费进度信息, 此时<strong>服务端也不会删除具体的消息数据, 只会保存消费位点信息</strong>. 位点数据保存在内部的一个 Topic(__consumer_offset)中. 消费端同样提供了自动提交和手动提交两种模式. 当消费者重新启动时, 会根据上一次保存的位点去消费数据, 用来避免重复消费.</p> <p>最后还是来看一下 Kafka 对 HTTP 协议和管控操作的支持.</p> <h5 id="http协议支持和管控操作-3"><a href="#http协议支持和管控操作-3" class="header-anchor">#</a> HTTP协议支持和管控操作</h5> <p>Kafka 内核是不支持 HTTP 协议的, 如果需要支持, 则需要在 Broker 前面挂一层代理. 如 Confluent 开源的 Kafka Rest.</p> <p>管控的大部分操作是通过 <strong>Kafka Protocol</strong> 暴露的, 基于四层的 TCP 进行通信. 还有部分可以通过直连 ZooKeeper 完成管控操作.</p> <p>在早期很多管控操作都是通过操作 ZooKeeper 完成的. 后来为了避免对 ZooKeeper 造成压力, 所有的管控操作都会通过 Broker 再封装一次, 即客户端 SDK 通过 Kafka Protocol 调用 Broker, Broker 再去和 ZooKeeper 交互.</p> <p>​<img src="/img/87e542e15283f885e1ebb58dca636369-20240421231949-u1y27xx.jpg" alt="">​</p> <p>Kafka 命令行提供了管控, 生产, 消费, 压测等功能, 其底层就是通过客户端 SDK 和 Broker 进行交互的. 在代码里面也可以通过客户端 SDK 完成相应的操作, <strong>不用必须通过命令行</strong>.</p> <p>因为历史的演进, 在一些命令行里面, 还残留着直连 ZooKeeper 的操作. 也可以通过直接操作 ZooKeeper 中的数据完成一些操作, 比如更改配置, 创建 Topic 等等.</p> <h5 id="总结-12"><a href="#总结-12" class="header-anchor">#</a> 总结</h5> <p>最后再来总结一下 Kafka.</p> <ol><li>协议层只支持私有的 Kafka Protocol 协议.</li> <li>网络层是<strong>基于原生的 Java NIO 开发, 底层也是通过多路复用</strong>, 异步 IO, Reactor 模型等技术来提高网络模块的性能.</li> <li>存储层是每个分区对应一份具体的存储文件, <strong>分区文件在底层会分段存储</strong>, 同时支持基于时间和大小的数据过期机制.</li> <li><strong>元数据存储是通过 ZooKeeper 来实现的</strong>, 所有的元数据都存储在 ZooKeeper 中.</li> <li>客户端的访问同样也需要经过<strong>客户端寻址机制</strong>. 老版本可以通过 ZooKeeper 获取元数据信息, 新版本只能通过 Broker 拿到元数据信息. 拿到所有元数据信息后, 才会直连 Broker.</li> <li>生产端支持将数据写入到 Topic 或指定写入某个分区, 写入 Topic 时需要经过生产分区分配操作, 选择出最终需要写入的分区, 同时支持批量写入的语义.</li> <li>消费端也有消费分组的概念, 消费时需要在多个消费者和消费分组之间进行消费的负载均衡, 同时也支持指定分区消费的模式.</li></ol> <h5 id="思考题-10"><a href="#思考题-10" class="header-anchor">#</a> 思考题</h5> <blockquote><p>请按照基础篇的思路, 描述一下 Kafka 从生产到消费的全过程?</p></blockquote> <p>Kafka 的生产到消费总共经过<strong>生产者, Broker, 消费者</strong>三个模块. 大致的流程如下:</p> <ol><li>在生产端, 客户端会先和 Broker 建立 TCP 连接, 然后通过 Kafka 协议访问 Broker 的 Metadata 接口获取到集群的元数据信息. 接着生产者会向 Topic 或分区发送数据, 如果是发送到 Topic, 那么在客户端会有消息分区分配的过程. 因为 Kafka 协议具有<strong>批量发送</strong>语义, 所以客户端会先在客户端缓存数据, 然后根据一定的策略, 通过异步线程将数据发送到 Broker.</li> <li>Broker 接收到数据后, 会根据 Kafka 协议解析出请求内容, 做好数据校验, 然后重整数据结构, 将数据按照分区的维度写入到底层不同的文件中. 如果分区配置了副本, 则消息数据会被同步到不同的 Broker 中进行保存.</li> <li>在消费端, Kafka 提供了消费分组消费和指定分区消费两种模式. 消费端也会先经过寻址拿到完整的元数据信息, 然后连接上不同的 Broker. 如果是消费分组模式消费, 则需要经过重平衡, 消费分区分配流程, 然后连接上对应的分区的 Leader, 接着调用 Broker 的 Fetch 接口进行消费. 最后一步也是需要提交消费进度来保存消费信息.</li></ol> <h4 id="_13-从基础功能拆解pulsar的架构设计与实现"><a href="#_13-从基础功能拆解pulsar的架构设计与实现" class="header-anchor">#</a> 13-从基础功能拆解Pulsar的架构设计与实现</h4> <p>上节课分析了 Kafka 在协议, 网络, 存储, 生产者, 消费者这五个模块的设计实现. 这节课用同样的思路来分析一下 Pulsar.</p> <p>近几年, 作为消息队列后起之秀的 Pulsar, 因为其<strong>存算分离, 多租户, 多协议, 丰富的产品特性, 支持百万 Topic</strong> 等特点, 逐渐为大家所熟知. 从定位来看, Pulsar 希望<mark><strong>同时满足消息和流的场景</strong></mark>. 从技术上来看, 它当前主要对标的是 Kafka, 解决 Kafka 在流场景中的一些技术缺陷, 比如计算层弹性, 超大分区支持等等.</p> <p>接下来就围绕着基础篇的知识点来拆解一下 Pulsar.</p> <h5 id="pulsar系统架构"><a href="#pulsar系统架构" class="header-anchor">#</a> Pulsar系统架构</h5> <p>先来看一下 Pulsar 的架构图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/904fd20b6ced9af51ae9c25e1c196171-20240421231949-1vfd8ua.jpg" alt="">​</p> <p>如上图所示, <mark><strong>Pulsar 的架构就复杂很多了, 它和其他消息队列最大的区别在于 Pulsar 是基于计算存储分离的思想设计的架构, 所以 Pulsar 整体架构要分为计算层和存储层两层. 通常说的 Pulsar 是指计算层的 Broker 集群和存储层的 BookKeeper 集群两部分</strong></mark>.</p> <p><strong>计算层包含 Producer, Broker, ZooKeeper, Consumer 四个组件, 用来完成 MQ 相关的功能. 存储层是独立的一个组件 BookKeeper, 是一个专门用来存储日志数据的开源项目, 它由 Bookies(Node)和 ZooKeeper 组成</strong>.</p> <p><strong>BookKeeper</strong> <strong>本质上就是一个远程存储</strong>. 比如 Kafka 的计算层是 Broker, 存储层是本地的硬盘空间, Broker 收到数据后, 通过本地文件的写入调用, 如 FileChannel, 将数据写入到本地文件. Pulsar 的计算层是 Broker, <strong>存储层是远程的 BookKeeper 集群</strong>, Broker 收到数据后, 通过 BookKeeper 的客户端 SDK 将数据写入到 BookKeeper 集群中.</p> <p>从部署上来看, <strong>计算层和存储层其实是独立的</strong>. 先部署一套存储的 BookKeeper 集群, 然后一套或多套 Pulsar 集群可以将数据写入到同一套 BookKeeper 集群中.</p> <p>​<img src="/img/11b510a8bda1b220db227a6e096b176e-20240421231949-nl53ise.jpg" alt="">​</p> <p><strong>在 Pulsar 中, 还可以看到一套或者多套 ZooKeeper</strong>. 因为 Pulsar 和 BookKeeper 都是使用 ZooKeeper 来存储元数据的. 在实际部署当中, 为了节省资源的开销, <strong>通常 Pulsar Broker 集群和 BookKeeper 会共用一套 ZooKeeper 集群</strong>.</p> <p><strong>当把 BookKeeper 当做一个存储来看, 会发现 Pulsar 计算层的架构和 Kafka 是一样的</strong>. Pulsar 也有 Topic, 分区, 订阅(消费分组)等概念, 客户端也需要经过寻址操作发现 Topic 对应的 Broker 节点. Broker 收到生产者的数据后, 会将数据写入到 BookKeeper 存储. 消费端会通过订阅(Subscription)来消费数据.</p> <p>Pulsar 会有一些自己的概念, 比如 Bundle, Bookie, Ledger, Entry 等. 这些概念都是和它的架构有关的, 比如 Bundle 是为了满足计算层弹性提出的概念, Bookie, Ledger, Entry 是存储层 BookKeeper 的概念. 这些在后面讲存算分离架构的时候会仔细讲.</p> <p>接下来继续围绕基础篇的五个模块来分析一下 Pulsar. 这节课主要分析 Pulsar Broker 的协议和网络模块, 至于 BookKeeper 的协议和网络模块, 有兴趣的话可以自己去研究下.</p> <h5 id="协议和网络层"><a href="#协议和网络层" class="header-anchor">#</a> 协议和网络层</h5> <p>和 Kafka 一样, Pulsar Broker 的协议也是<strong>自定义的私有协议</strong>. <strong>协议的格式是以行格式解析, 即自定义的编解码格式</strong>.</p> <p>如下图所示, Pulsar 的整体协议是行格式的自定义编解码, 但是协议中的<strong>命令(Command)和部分元数据是用 Protobuf 组织</strong>来表示的, 比如下图黄色的部分.</p> <p>​<img src="/img/76752aeb7e961bea75d74a1fe3641f0e-20240421231949-jf9lqgq.jpg" alt="">​</p> <p>从协议的结构来看, 协议也是分为<strong>协议头和协议体</strong>两部分. TotalSize+CommandSize+Commnad 就是协议头, Other 就是协议体, 协议体中包含很多请求维度需要的字段.</p> <p><strong>从协议的内容上看, Pulsar 协议分为了</strong> <strong>SimpleCommands</strong> <strong>和</strong> <strong>MessageCommands</strong> <strong>两种格式</strong>.</p> <p><strong>Simple Commands 指不需要携带消息内容的简单命令, 即指在交互过程中不需要携带消息内容的交互请求, 如建立连接, 心跳检测等等</strong>. 消息结构如下所示, 可以看到简单协议只携带了 TotalSize, CommandSize, Command 三个字段, 不携带消息体.</p> <p>​<img src="/img/fbb75b5b96124e861f45c5830962a285-20240421231949-uke5msk.jpg" alt="">​</p> <p><strong>Message Commands 指需要携带消息内容的复杂命令, 比如生产消息操作就需要携带消息内容, 生产者信息, 批量消息等等相关数据</strong>. 此时就需要使用 Message Commands 来进行交互, 它的结构如下:</p> <p>​<img src="/img/5c034716250062a85627b457091cfb9a-20240421231949-68lvt75.jpg" alt="">​</p> <p>从结构上来看, Message Commands 和 Simple Commands 是一样的, 它也包含了 TotalSize, CommandSize, Command 三个字段, 只是在 Simple Commands 的基础上, 多了很多个跟请求相关的字段, 如 Broker Entry Metadata, Message Metadata 等等.</p> <p>在编解码的过程中, <strong>协议是以行格式解析</strong>的. 以 Simple Commands 举例, 服务端拿到请求后, 先用 4 个字节拿到消息总长度, 然后根据之后 4 个字节拿到命令的长度, 再根据命令的长度拿到命令的内容, 然后<strong>再根据 Protobuf 格式解析出命令的具体内容</strong>. Message Commands 解析以此类推.</p> <p><strong>Pulsar Broker 的网络层是基于 Netty 框架开发实现的, 属于业界比较常用的实现方案</strong>. 如果想了解更多, 建议直接学习 Netty 的网络模型和开发指南, 这里就不展开了.</p> <h5 id="数据存储-4"><a href="#数据存储-4" class="header-anchor">#</a> 数据存储</h5> <p>现在来看一下 Pulsar 的存储层. 在数据存储方面, Pulsar 也同样分为<strong>元数据存储和消息数据存储</strong>两部分.</p> <h6 id="元数据存储-4"><a href="#元数据存储-4" class="header-anchor">#</a> 元数据存储</h6> <p>当前 Pulsar 元数据存储的核心是 ZooKeeper. <strong>最新版本的内核支持可插拔的元数据存储框架, 即支持将元数据存储到多种第三方存储引擎, 比如 etcd, 本地内存, RocksDB 等</strong>, 架构如下图所示:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6c46b2a6ff02fa186828113f541e232b-20240421231949-tq5h8y5.jpg" alt=""></p> <p>因为架构要求, Pulsar 需要存储更多元数据, 所以 Pulsar 对 ZooKeeper 造成的压力会更大. 也正因为如此, <strong>Pulsar 才会支持可插拔的元数据存储框架, 希望通过其他的存储引擎来缓解 ZooKeeper 的瓶颈</strong>.</p> <p>和 Kafka 一样, 因为都使用 ZooKeeper 来存储元数据, 那么 Kafka 遇到的问题, Pulsar 也都会遇到, 如<strong>集群的规模, 可承载的分区数</strong>等等. 从代码技术实现上来看, Pulsar 对 ZooKeeper 的使用和 Kafka 是类似的, 所以就不展开细讲了.</p> <h6 id="消息数据-3"><a href="#消息数据-3" class="header-anchor">#</a> 消息数据</h6> <p>接下来看一下 Pulsar 的消息存储. 在<strong>计算层, Pulsar 不负责消息存储. 流程上就是调用 BookKeeper 的 SDK, 往 BookKeeper 写入数据. 在 BookKeeper 看来, Pulsar Broker 就是 BookKeeper 集群的一个普通的客户端</strong>.</p> <p>在 Pulsar Broker, 消息数据的存储是以<strong>分区维度</strong>组织的, 即<strong>一个分区一份文件</strong>. <mark><strong>在实际的存储中, 分区的数据是以一段一段 Ledger 的形式组织的, 不同的 Ledger 会存储到不同的 Bookie 上. 每段 Ledger 包含一批 Entry, 一个 Entry 可以理解为一条消息</strong></mark>. 存储结构如下图所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/78a924ae3908e10cf78ef1afa4d22605-20240421231949-n1on6qx.jpg" alt="">​</p> <p>通过图示可以看到, 在 Broker 中, 消息会先以 Entry 的形式追加写入到 Ledger 中, <strong>一个分区同一时刻只有一个 Ledger 处于可写状态</strong>. 当写入一条新数据时, 会先找到当前可用的 Ledger, 然后写入消息. 当 Ledger 的长度或 Entry 个数超过阈值时, 新消息会存储到新的 Ledger 中. <strong>一个 Ledger 会根据 Broker 指定的 QW 数量, 存储到多个不同的 Bookie 中. 一个 Bookie 可以存放多个不连续的 Ledger</strong>.</p> <p>这种分段存储结构的好处就是, 当一台 Bookie(节点)的负载高了或者容量满了后, 就可以通过禁用该台节点的写入, 将负载快速转移到其他节点上, 从而实现存储的弹性. 讲到这里会发现, 在 Pulsar 看来, <strong>消息数据本质上就是分段存储的</strong>.</p> <p>在写入性能方面, Broker 不太关注实际的写入性能的提升, <strong>性能主要依赖 BookKeeper 的性能优化</strong>. <mark><strong>BookKeeper 在底层会通过 WAL 机制, 批量写, 写缓存的形式来提高写入的性能</strong></mark>. 底层的具体实现机制就不展开讲了, 有兴趣的话可以查阅相关资料。</p> <p><strong>同时, Pulsar 提供了</strong> <strong>TTL 和 Retention 机制来支持消息删除</strong>.</p> <ul><li>TTL 策略指消息在指定时间内没有被用户 ACK 掉时, 会被 Broker 主动 ACK 掉. 此处需注意, 这个 ACK 操作不涉及数据删除, 因为 TTL 不涉及与删除相关的操作.</li> <li>Retention 策略指消息被 ACK 之后(消费者 ACK 或者 TTL ACK)继续在 Bookie 侧保留的时间, 消息被 ACK 之后就归属于 Retention 策略, 即在 BookKeeper 保留一定时间. Retention 以 Ledger 为最小操作单元, 删除即是删除整个 Ledger.</li></ul> <p>所以说, TTL 仅用于 ACK 掉在 TTL 范围内应被 ACK 的消息, 不执行删除操作. <strong>真正删除的操作是依靠 Retention 策略来执行的</strong>. 下面再来看一下客户端, 看看 Pulsar 的生产者和消费者的实现.</p> <h5 id="生产者和消费者-4"><a href="#生产者和消费者-4" class="header-anchor">#</a> 生产者和消费者</h5> <p>因为 Pulsar 也是 Topic, 分区模型, 所以 Pulsar 客户端在进行生产消费之前, 也需要<strong>先进行客户端寻址操作. 通过寻址找到 Topic 分区所在的 Leader 节点, 然后连接上节点进行生产消费</strong>. Pulsar 支持通过 Pulsar 协议和 HTTP 协议两种形式来完成寻址操作.</p> <p>先来看看 Pulsar 的生产端.</p> <h6 id="生产端-2"><a href="#生产端-2" class="header-anchor">#</a> 生产端</h6> <p>Pulsar 生产端支持<strong>访问模式</strong>的概念. 访问模式指的是一个分区在同一时间支持怎样的生产者以何种方式写入. 比如一个分区同一时间是所有生产者都可以写, 还是只有一个生产者可以写, 还是多个生产者灾备写. 在其他消息队列中, 一般都是默认所有的生产者可以写.</p> <p><strong>Pulsar 提供了 Shared(共享), Exclusive(独占), WaitForExclusive(灾备)三种访问模式</strong>.</p> <p><strong>Shared 指允许多个生产者将消息写入到同一个 Topic. Exclusive 指只有一个生产者可以将消息写入到 Topic, 当其他生产者尝试写入消息到这个 Topic 时, 会发生错误. WaitForExclusive 指只有一个生产者可以将消息发送到 Topic, 其他生产者连接会被挂起而不会产生错误, 类似 ZooKeeper 的观察者模式</strong>.</p> <p>因为<strong>分区模型</strong>的存在, Pulsar 在生产端提供了 RoundRobinPartition(轮询), SinglePartition(随机选择分区), CustomPartition(自定义)三种路由模式, 用来决定数据会发送到哪个分区里面.</p> <ul><li>RoundRobinPartition, 指当消息没有指定 Key 时, 生产者以<strong>轮询方式</strong>将消息写入到所有分区.</li> <li>SinglePartition, 指当消息没有指定 Key, 生产者会随机<strong>选择一个分区</strong>, 并将所有消息写到这个分区. 针对上述这两种策略, 如果消息指定了 Key, 分区生产者会优先根据 Key 的 Hash 值将该消息分配到对应的分区.</li> <li>CustomPartition, 用户可以创建自定义路由模式, 通过<strong>实现 MessageRouter 接口来自定义路由规则</strong>.</li></ul> <p>因为 Pulsar 的协议支持 Batch 语义, 所以在<strong>生产端是支持批量发送的</strong>. 启用批量处理后, 生产者会在客户端累积并发送一批消息. 批量处理时的消息数量, 取决于最大可发送消息数和最大发布延迟.</p> <p>在客户端写入模式上, Pulsar 生产端也支持同步写入, 异步写入两种方式.</p> <h6 id="消费端-2"><a href="#消费端-2" class="header-anchor">#</a> 消费端</h6> <p>在消费端, <mark><strong>Pulsar 主要支持 Pull 消费模型, 即由客户端主动从服务端 Pull 数据来支持消费</strong></mark>. 同样的, Pulsar 在消费端也支持订阅的概念, 订阅对 Pulsar 的作用相当于 Kafka 的消费分组.</p> <p><strong>Pulsar 的订阅支持消息和分区两个维度, 即可以将整个分区绑定给某个消费者, 也可以将分区中的消息投递给不同的消费者</strong>.</p> <p>所以在实现上, Pulsar 支持<mark><strong>独占, 灾备, 共享, Key_Shared 四种订阅类型</strong></mark>.</p> <ul><li><strong>独占</strong>, 指一个订阅只可以与一个消费者关联, 只有这个消费者能接收到 Topic 的全部消息, 如果这个消费者故障了就会停止消费.</li> <li><strong>灾备</strong>, 指一个订阅可以与多个消费者关联, 但只有一个消费者会消费到数据, 当该消费者故障时, 由另一个消费者来继续消费.</li> <li><strong>共享</strong>, 指一个订阅可以与多个消费者关联, 消息会通过轮询机制发送给不同的消费者.</li> <li><strong>Key 共享</strong>, 指一个订阅可以与多个消费者关联, 消息根据给定的映射规则, 相同 Key 的消息由同一个消费者消费.</li></ul> <p><strong>Pulsar 支持持久化和非持久化两种订阅模式</strong>. 这两种模式的核心区别在于, 游标是否是持久化存储. 如果是持久化的存储, 当 Broker 重启后还可以保留游标进度, 否则游标就会丢失. RocketMQ 和 Kafka 的消费分组都是持久化的订阅.</p> <p>当客户端消费成功后, 为了确认消费完成, 也需要进行消费确认. <strong>消费确认就是提交当前消费的进度, Pulsar 指的是提交游标的进度. 它提供了累积确认和单条确认两种模式, 累积确认指消费者只需要确认收到的最后一条消息, 在此之前的消息, 都不会被再次发送给消费者; 单条确认指消费者需要确认每条消息并发送 ACK 给 Broker</strong>.</p> <p>如果希望保存消费进度, 那么就需要选择<strong>持久化订阅</strong>. 如果是为了提高 ACK 性能, 就需要选择<strong>累积确认</strong>.</p> <p>在实际运行过程中, Puslar 的单条 ACK 机制给 Broker 带来了蛮大的挑战. 因为允许客户端一条一条 ACK 数据, 就会造成某些数据一直不被 ACK, 从而造成<strong>消息空洞</strong>的现象.</p> <p>同时 Pulsar 也提供了取消确认的功能. 即当某些消息已经被确认, 已经消费不到数据了, 此时如果还想消费到数据, 就要通过客户端发送<strong>取消确认的命令, 使其可以再消费到这条数据</strong>. 取消确认操作支持单条和批量, 不过这两种操作方式在不同订阅类型中的支持情况是不一样的, 这一点需要注意一下.</p> <p>最后还是来看一下 Pulsar 对 HTTP 协议和管控操作的支持.</p> <h5 id="http协议支持和管控操作-4"><a href="#http协议支持和管控操作-4" class="header-anchor">#</a> HTTP协议支持和管控操作</h5> <p>在访问层面, Pulsar 的<strong>管控操作和生产消费数据流操作是分开支持的</strong>. 即<strong>数据流走的是自定义协议通信, 管控走的是 HTTP 协议形式的访问</strong>. 从访问上就隔离了管控和数据流操作, 在后续的权限管理, 客户端访问等方面提供了很多便利.</p> <p>​<img src="/img/f2aa5bd5f8ca5cda9a4c98a16849bfd5-20240421231949-i9uwbxb.jpg" alt="">​</p> <p>如上图所示, HTTP 协议的端口和私有协议的端口是独立的, 内核中启动了一个单独的 HTTP Server 来提供服务. 我们在代码上可以通过 HTTP Rest 的 API 直接进行管控操作. 命令行 CLI 的底层也是通过 HTTP Client 发起访问的, 用 HTTP 的好处就是, 不需要单独在二进制协议, 服务端接口, 客户端 SDK 方面单独进行管控的支持.</p> <p>在上面的 HTTP Rest 接口中, 同时提供了简单的生产接口和消费接口, 即可以通过 HTTP 协议进行数据的写入和消费, 但这个功能不建议用在现网的大流量的业务中. 如果需要支持 HTTP 协议的生产和消费, 有些商业化的产品是可以支持的, 底层技术层面走的还是 Proxy 的方案.</p> <h5 id="总结-13"><a href="#总结-13" class="header-anchor">#</a> 总结</h5> <p>这节讲了 Pulsar 的五个部分. 和其他 MQ 不一样的是, 因为 Pulsar 的社区当前发展很快, 随着时间的推移, <strong>这节课的内容可能会和最新版本的实现对不上</strong>.</p> <p>从产品定位上来看, Pulsar 把自己定位为 Kafka 的升级版. 所以它是在 Kafka 的基础上, 对概念进行了升级和细化, 以满足更多的场景, 同时也解决了 Kafka 自身的一些架构缺陷和功能不足问题. 如果从这个角度去理解 Pulsar, 就会比较好懂了, 比如 Pulsar 比 Kafka 会有更多的 Topic 类型, 更多的订阅模式以及更弹性的计算层和存储层等等.</p> <p>这节课用一张表格, 针对基础篇的知识点, 从 4 个主流消息队列出发, 做一下原理概览性的总结. 建议收藏!</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6f5ee139b09026cdf356492c948b4750-20240421231949-l35pc6h.jpg" alt="">​</p> <h5 id="思考题-11"><a href="#思考题-11" class="header-anchor">#</a> 思考题</h5> <blockquote><p>Pulsar为什么会对ZooKeeper造成很大的压力?</p></blockquote> <p>压力的来源主要<strong>是 Pulsar 在 ZooKeeper 中存储的元数据的大小</strong>.</p> <p>Pulsar 需要在 ZooKeeper 中存储 Topic, 分区, Broker 负载, Bundle, BookKeeper Ledger 等元数据信息, 这些数据需要<strong>占用大量的节点和空间</strong>. 而当 ZooKeeper 存储大量数据时, 因为其底层存储结构, ZooKeeper 的性能就会急速下降.</p> <p>而且 Pulsar 主打<strong>百万分区, 分区越多, 需要在 ZooKeeper 中保留的数据就越多</strong>, 也就导致了 ZooKeeper 的负载会更高, 压力的放大作用更明显.</p> <h3 id="进阶篇"><a href="#进阶篇" class="header-anchor">#</a> 进阶篇</h3> <h4 id="_14-集群-哪些环节会存在性能瓶颈和数据可靠性风险"><a href="#_14-集群-哪些环节会存在性能瓶颈和数据可靠性风险" class="header-anchor">#</a> 14-集群:哪些环节会存在性能瓶颈和数据可靠性风险?</h4> <p>在基础篇的课程中, 学习了最简单的消息队列的构建过程和底层原理. 接下来将开始进阶篇的学习, 进阶篇将从集群构建, 性能, 可靠性, 数据安全, 可观测性几个方面展开. 总结来说, <strong>我们将把单机的消息队列架构扩展成为分布式的高可靠, 高性能的完整集群</strong>.</p> <p>​<img src="/img/d9a28a4716af2f6087a7a99b84af1270-20240421231949-dgik6te.jpg" alt="">​</p> <p>这节课会先分析消息队列<mark><strong>集群中哪些环节可能存在性能瓶颈和可靠性风险</strong></mark>, 以便让你对消息队列的集群有一个整体认识.</p> <p>从技术上看, <mark><strong>消息队列的性能和可靠性由 生产者, Broker 集群, 消费者 三方共同保障</strong></mark>, 而不只是服务端的工作. 通常衡量集群性能的一个重要指标是<strong>全链路耗时</strong>, 即客户端发出一条消息到消费者消费到这条消息的时间差, 先来看一张图.</p> <p>​<img src="/img/0b4d49ba0594f57f0760a7ee5b688d4b-20240421231949-8r6pglw.jpg" alt="">​</p> <p>这是在展示当生产者发送一条消息到 Broker 存储, 消费者消费这条数据全流程所涉及到的组件. 接下来就将围绕着这个<mark><strong>链路</strong></mark>展开分析, 就从生产者开始.</p> <h5 id="生产者的性能和可靠性"><a href="#生产者的性能和可靠性" class="header-anchor">#</a> 生产者的性能和可靠性</h5> <p>先来画一张图, 梳理下在生产者客户端中需要关注的几个点, 主要分为客户端 SDK 和网络两大部分.</p> <p>​<img src="/img/8153ee8a8877affd9db7781b08de0632-20240421231949-vfl2crz.jpg" alt="">​</p> <h6 id="网络层面"><a href="#网络层面" class="header-anchor">#</a> 网络层面</h6> <p>在网络层面, 对性能和可靠性的影响主要包括 <mark><strong>连接协议</strong></mark>​<mark>,</mark> <mark><strong>传输加密</strong></mark>​<mark>,</mark> <mark><strong>网路稳定性</strong></mark>​<mark>,</mark> <mark><strong>网络延时</strong></mark>​<mark>,</mark> <mark><strong>网络带宽</strong></mark> 五个方面.</p> <p>前面讲过, <strong>生产者客户端会先和 Broker 建立并保持 TCP 长连接, 而不是在每次发送数据时都重新连接, 以确保通信的性能</strong>. 这也是默认情况下不用 HTTP 协议的原因.</p> <p>在数据传输过程中, 为了避免数据包被篡改, 窃取, 就需要进行<strong>传输加密</strong>. 因为网络质量不稳定, 传输过程中可能也存在丢包的情况, 此时就需要依赖 TCP 的<strong>重传机制</strong>来解决问题. 但当出现大量网络重传时, 就会极大地影响性能, 导致集群的吞吐下降和耗时上升. 这也是在系统运营过程需要<strong>监控网络包重传率</strong>的原因.</p> <p>另外当启用加密传输后, 数据的传输性能会下降, 这也是启用加密传输时一个需要考虑的点. 后面还会详细分析消息队列的安全机制, 这里先不展开.</p> <p>在性能部分, 客户端和服务端的<strong>网络耗时</strong>是绕不过去的. 特别在流量大, 高吞吐的场景下, 网络耗时对数据传输性能的影响更大. 一般情况下, 公有云内网耗时在 1ms 以内, 跨可用区通信的网络延时会增加 2-3ms. 如果是跨地域通信, 此时的网络延时可能会增加至少 5-10ms, 更远的话甚至几十几百 ms. 所以, 在客户端的部署上, 为了保证延时和吞吐, 就需要<strong>尽量将客户端和服务端部署在同一个可用区内网中, 以避免网络链路带来的影响</strong>.</p> <p>在网络部分, 还需要关注网络带宽. 如下图所示, <strong>一般会关注客户端节点网卡, 中间网络链路, Broker 节点的网卡三个部分的带宽容量</strong>. 客户端和 Broker 的网卡使用情况比较好发现和分析, 经常忽略且不容易分析的是中间网络带宽的使用情况, 比如在跨地域传输, 跨云传输的场景下, 中间网络带宽很容易成为瓶颈.</p> <p>​<img src="/img/0c7336a6964ef91b5d524cd72f2194c5-20240421231949-9at332x.jpg" alt="">​</p> <h6 id="sdk层面"><a href="#sdk层面" class="header-anchor">#</a> SDK层面</h6> <p>在 SDK 层面, 对性能和可靠性的影响主要包括 <mark><strong>发送模式</strong></mark>​<mark>,</mark> <mark><strong>批量语义</strong></mark>​<mark>,</mark> <mark><strong>异常处理</strong></mark>​<mark>,</mark> <mark><strong>生产者数量</strong></mark> 四个方面.</p> <p>在生产端, 一般支持<strong>发送即忘, 同步发送, 异步发送三种发送模式</strong>, 发送模式的设计思想是希望在性能和可靠性之间寻找平衡.</p> <ul><li><strong>发送即忘</strong> 是指调用 send() 函数后, <strong>不用等待服务端的返回结果, 因此可以不断地发送数据</strong>. 这种模式的性能是最高的, 可靠性是最低的, 因为数据发送失败后没有任何后续的容错处理.</li> <li><strong>同步发送</strong> 是指调用 send() 函数后, <strong>业务代码同步等待服务端的返回, 优点是能保证发送消息的顺序性, 这种模式的性能是最低的</strong>. 其性能高度依赖 Broker 和服务端之间的网络延时, 以及 Broker 的处理耗时.</li> <li><strong>异步发送</strong> 是指调用 send() 函数后, 使用<strong>异步线程回调的方式发送数据</strong>. 即在不阻碍主线程的情况下发送数据, 此时业务可以一直不停地发送数据. 但是如果 send() 速度大于底层发送给 Broker 的速度, 当 SDK 底层的线程池用完后, 发送数据也会阻塞.</li></ul> <p>总结一下, <strong>从性能上来看, 发送即忘 &gt; 异步发送 &gt; 同步发送. 从可靠性来看, 异步发送 = 同步发送 &gt; 发送即忘</strong>. 同步发送可以保证顺序, 异步发送因为重传机制的存在, 会无法保证顺序.</p> <p><strong>批量发送</strong>是指生产端是否支持 <strong>Batch 语义</strong>. Batch 语义就是前面讲到的批量发送, 批量比非批量的吞吐性能高. 从全链路延时来看, 因为批量发送需要在生产者客户端本地等待聚合数据, 所以非批量发送的全链路耗时会比批量发送的全链路延时低.</p> <p>当客户端接收到服务端的报错时, 如果没有正确地捕获异常, 进行重试和记录, 就有可能出现数据发送失败却不知道的情况, 最终导致数据丢失. 一般会在数据发送流程中, 做好异常捕获, 重试的逻辑, 并对发送结果进行记录. 比如发送失败的异常信息, <strong>发送时候记录消息的 ID 或者能唯一标识消息的信息, 从而做到发送数据的可追溯</strong>.</p> <p>最后, 因为单个生产者和单个 TCP 连接是有性能瓶颈的, 在业务中建议<strong>建立多个生产端实例同时来写入数据</strong>, 这样可以提高生产者的性能.</p> <p>接下来来看一下 Broker 的性能和可靠性.</p> <h5 id="broker的性能和可靠性"><a href="#broker的性能和可靠性" class="header-anchor">#</a> Broker的性能和可靠性</h5> <p><strong>Broker 的性能和可靠性分为单机和集群两个维度</strong>. 单机维度属于垂直扩容, 集群维度属于水平扩容. 先来看一下单机维度的性能和可靠性.</p> <h6 id="单机维度"><a href="#单机维度" class="header-anchor">#</a> 单机维度</h6> <p>在单机维度, Broker 的性能和可靠性提升可以拆成<strong>应用程序, 操作系统, 物理硬件</strong>三个层面.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ebd5b5336b5139acac7e0dea73d4bfa0-20240421231949-ddfc7mj.jpg" alt=""></p> <p><strong>应用程序</strong> 是指消息队列的应用程序本身, 比如 Java 编写的 Kafka Broker 程序, Erlang 编写的 RabbitMQ Broker 等等.</p> <p>如下图所示, <strong>应用程序的优化主要分为网络层, 逻辑层, 存储层三个模块</strong>. 其中网络层, 存储层的性能和可靠性是最重要的, 至于如何优化在基础篇已经讲过, 这里就不再重复了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f25706feece72b67320996af445af384-20240421231949-hnvznct.jpg" alt=""></p> <p>除了网络层和存储层, 逻辑层的处理速度也很重要. 比如在生产流程中, 需要进行数据解析, 数据校验, 数据重组, 协议转换等操作, 这些操作都需要通过<strong>编码</strong>实现, 编码质量的好坏会严重影响该流程的性能. 此时就需要用到相关语言的编程技巧, 来提升逻辑层的处理速度和稳定性. 后面会分享一些常用的 Java 编码技巧.</p> <p>另一方面, 应用程序的性能还受限于编程语言虚拟机, 比如 Java 虚拟机. 合理的对语言虚拟机调优可以极大地提高程序的处理性能. 比如 Java 虚拟机调优一般会关注 JDK 版本, 垃圾回收策略, 堆大小等等几个方面.</p> <p><strong>操作系统</strong> 是指通过<strong>调整操作系统参数</strong>来提高性能. 在消息队列中, 一般会建议<mark><strong>调整系统最大 FD, PageCache 刷盘策略, Socket 最大缓冲区大小, 进程可映射的内存区域数量等等配置来提高性能</strong></mark>. 从实际运营来看, 大部分情况下默认的系统参数都够用, 对这些参数的调优一般在需要深度优化挖掘单节点性能的场景中会用到. 如果想对 Kafka 集群的操作系统进行调优, 还可以参考 <a href="https://kafka.apache.org/documentation/#hwandos" target="_blank" rel="noopener noreferrer">Kafka 操作系统调优<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p><strong>物理硬件</strong> 是指节点的 <strong>CPU, 内存, 网卡, 硬盘等物理资源</strong>. 一般用更大规格的物理资源, 性能会更高. 从实际运营的角度, 通过升级物理硬件来提高性能, 也是最简单, 最直接的方式.</p> <p>但是你知道你的集群应该<strong>升配哪类物理资源规格</strong>吗? 是 CPU, 内存, 网卡, 硬盘都要一起升吗? 要升配到什么规格呢? 接下来看一下消息队列对于这四个指标的的需求情况.</p> <ol><li><strong>CPU</strong>: 因为消息队列并没有很复杂的计算逻辑, 核心流程是接收返回数据, 所以<strong>大部分情况下消息队列对 CPU 的需求并不高</strong>. 只有在比如开启压缩, TCP 连接数很高, 高频率 GC 的场景中会消耗较多 CPU. 所以如果一开始就上大规格的 CPU 节点, 就会存在浪费, 我们现网就有大量的 2C8G 的机器在运行且状态良好.</li> <li><strong>内存</strong>: 内存是 Broker 很<strong>依赖的资源</strong>, 因为数据的写入, 消费的热读等等都需要依赖内存. 比如 Broker 保存数据, 是先将数据写入到 PageCache 再刷新到硬盘的. 消费时如果命中内存中的数据, 性能会高很多. 另外较大的内存也就可以配置更大的堆, 从而避免 GC 带来的 CPU 损耗. <strong>消息队列一般也会用到堆外内存, 比如 PageCache 就是堆外内存, 所以即使没有配置给堆的内存也会被使用到</strong>.</li> <li><strong>网卡</strong>: 网卡<strong>只需要关注是否被打满就行</strong>, 打满了系统就会异常. 大部分业务中网卡容量都是够的, 比如某个云上虚拟机的网卡最小为 1.5Gbps(187MB/s). 对于一些大流量的业务, 就需要重点观察网卡的流量. 网卡打满的时候, 数据一致性, 客户端写入都会受到影响. 网卡和性能其实没有关系, 只要网卡没有被打满, 可以认为性能都是一样的.</li> <li><strong>硬盘</strong>: 消息队列是一个<mark><strong>非常依赖硬盘性能</strong></mark>的产品. 要满足<strong>低延时, 高吞吐</strong>的需求, 硬盘的吞吐就非常重要. 硬盘的三个衡量指标是 IOPS, 吞吐, 延时. 用高性能的硬盘会给集群带来很大的性能提升. 关于硬盘的性能提升, 可以回看前面存储的性能优化.</li></ol> <p>总结来讲, 单机就是垂直深度挖掘单机的的性能. 接下来看一下<strong>集群维度</strong>的可靠性和性能.</p> <h6 id="集群维度"><a href="#集群维度" class="header-anchor">#</a> 集群维度</h6> <p><strong>集群的核心思想就是水平扩容, 即通过水平扩容添加节点, 让集群拥有更强的处理能力</strong>. 在消息队列集群中, 性能和可靠性是通过创建更多分区, 多个副本, 并将分区和副本分配到多个节点上来实现的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4941f7b930d52f34b8baa2fdec13eef7-20240421231949-mexqtub.jpg" alt=""></p> <p>所以消息队列集群维度性能和可靠性的核心, 包括<strong>分区, 副本, 集群构建, 数据一致性, 集群可靠性和性能等等几个方面</strong>, 会在后面几节课展开来讲, 这里先不展开. 接下来看看消费者的性能和可靠性.</p> <h5 id="消费者的性能和可靠性"><a href="#消费者的性能和可靠性" class="header-anchor">#</a> 消费者的性能和可靠性</h5> <p>从技术上来看, 消费者的性能和可靠性也分为<strong>客户端 SDK 和网络</strong>两个部分. 其中网络部分和生产者是一样的, 就不再重复. 重点来看一下消费者 SDK 的性能和可靠性.</p> <p>在消费性能方面, 需要<strong>主要关注延时和堆积两个指标</strong>. 延时是指 Broker 保存一条消息后, 这条消息被客户端消费到的时间差. 堆积是指 Broker 堆积很多消息没有被及时消费.</p> <p>继续来看一张图, 消费者的性能和可靠性主要跟 <mark><strong>消费模型</strong></mark>​<mark>,</mark> <mark><strong>消费重平衡</strong></mark>​<mark>,</mark> <mark><strong>消费模式</strong></mark>​<mark>,</mark> <mark><strong>位点提交</strong></mark> 四个方面有关.</p> <p>​<img src="/img/c3c61d141e154baa532040dd5877f1db-20240421231949-rykpba8.jpg" alt="">​</p> <p>为了提高消息消费的及时性, 最好是选择 Push 模型, 即服务端有消息后主动 Push 给多个客户端, 此时的消费的延时是最低的. 从提高吞吐来看, 为了避免服务端堆积, 主流消息队列都是通过客户端主动批量 Pull 数据来提高吞吐, 避免堆积. <strong>一般情况下, Pull 模型都是默认的消费模型</strong>.</p> <p><strong>消息队列一般是通过消费分组(或订阅)消费数据, 以便能自动分配消费关系和保存消费进度</strong>. 此时当消费重平衡时, 为了重新分配消费关系, 所有的消费都会暂停, 从而会影响到消费性能. 如果重平衡次数较多, 问题就会更加严重. 所以, 像 Flink 等流式计算引擎, 都会绕过消费分组, 指定分区进行消费, 以避免重平衡带来的性能下降. 而 RocketMQ 为了解决重平衡问题, 就将重平衡移动到了 Broker 端, 尽量降低消费重平衡带来的性能影响.</p> <p>在分配消费关系的时候, 如果以分区粒度将分区分配给一个消费者, 此时当消费者性能有差别时, 就会出现消费倾斜, 导致分区堆积, 从而影响性能. 而如果是以消息粒度投递数据, 即一个分区的数据能够投递给不同的消费者, 此时就不会出现性能问题, 性能是更高的, 但是消息数据的顺序性无法保证. 所以为了提高消费性能, 可以选择<strong>合适的消费模式</strong>.</p> <p>从可靠性来看, 消费端是不存在丢数据的情况的. <strong>但是客户端如果存在错误提交消费位点(Offset)的情况, 比如应该提交 Offset 却没有提交, 就会导致重复消费; 或者不应该提交 Offset 却提交了 Offset, 就会导致消费者没有消费到应该消费的数据, 从而导致下游认为数据丢失. 此时从代码上来看, 建议是手动提交 Offset(或 ACK), 即消费到数据, 并且业务逻辑处理成功后, 才执行 ACK 或者提交 Offset</strong>.</p> <p>当消费完成, 需要<strong>提交位点</strong>后才能消费下一份数据, 此时如果提交位点的请求过慢, 也会影响消费的性能. 有的消息队列会同时支持单条 ACK 和批量 ACK 的特性, 正常来讲批量 ACK 的性能更高.</p> <p>在消费端, 对性能影响最大的是网络链路的耗时. 网络耗时会极大影响消费的性能, 特别是在跨区, 跨地域消费的情况下, 问题会更加明显. 所以依旧建议就近部署和消费.</p> <h5 id="总结-14"><a href="#总结-14" class="header-anchor">#</a> 总结</h5> <p>这节课了解了消息队列性能和生产者, Broker, 消费者三者相关. 下面从这三个维度来总结一下<strong>可能影响性能和可靠性的关键点</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6a04ec02d5d92ec6691eeac45cd9df8b-20240421231949-igltomv.jpg" alt=""></p> <h5 id="思考题-12"><a href="#思考题-12" class="header-anchor">#</a> 思考题</h5> <blockquote><p>根据二八原则, 集群中应该有某些点对于集群的性能和可靠性影响很大, 你认为主要有哪些?</p></blockquote> <ol><li>生产者是否批量发送</li> <li>客户端和服务端的网络延时情况</li> <li>Broker 单机维度的网络模块</li> <li>Broker 单机维度的存储层</li> <li>Broker 集群维度的分区和副本数</li> <li>消费模型的选择</li> <li>消费是否批量拉取数据</li> <li>消费模式的选择</li></ol> <h4 id="_15-集群-如何构建分布式的消息队列集群-上"><a href="#_15-集群-如何构建分布式的消息队列集群-上" class="header-anchor">#</a> 15-集群:如何构建分布式的消息队列集群?(上)</h4> <p>上节讲到集群的主要功能就是用来提高性能和数据可靠性. 从技术上看, 设计实现集群化的消息队列主要包含 <strong>节点发现</strong>, <strong>节点探活</strong>, <strong>元数据存储</strong>, <strong>集群管理</strong> 四个方面. 接下来将围绕着这四个方面, 用两节课来讲一下<strong>具体是怎么思考, 怎么实现集群</strong>的.</p> <h5 id="有状态服务和无状态服务"><a href="#有状态服务和无状态服务" class="header-anchor">#</a> 有状态服务和无状态服务</h5> <p>在此之前, 先来了解一下什么是<strong>有状态服务和无状态服务</strong>, 后面会用到.</p> <p>在日常开发中, 经常听到有状态服务和无状态服务这两个词. 二者之间最重要的一个区别在于: <strong>是否需要在本地存储持久化数据</strong>. 需要在本地存储持久化数据的就是有状态服务, 反之就是无状态服务.</p> <p>其实这里想说明的是, 有状态服务和无状态服务构建集群的思路是完全不一样的. HTTP Web 服务就是典型的无状态服务. 在搭建 HTTP Web 集群的时候, 经常会使用 Nginx 或者在其他网关后面挂一批 HTTP 节点, 此时后端的这批 HTTP 服务节点就是一套集群.</p> <p>​<img src="/img/199a3534be43198cc7819ddbf5d6f905-20240421231949-kcxhlhu.jpg" alt="">​</p> <p>如上图所示, <strong>因为 HTTP Web 是无状态的服务, 不同的节点不需要知道其他节点的存在</strong>. Nginx 认为后端所有的节点的功能是一样的, 所以请求经过 Nginx 后, 只需要根据一定转发策略, 如轮询, 加权轮询, 按 Key Hash 等将请求转发给后端的 Web 服务节点即可. 然后在节点增减的时候, Nginx 会感知到节点的增减, 执行转发或者不转发就行了.</p> <p><strong>消息队列是有状态服务. 消息是和分片绑定, 分片是和节点绑定. 所以, 当需要发送一个消息后, 就需要发送到固定的节点, 如果把消息发送到错误的节点, 就会失败</strong>. 所以, 为了将消息发送到对的节点和从对的节点削峰数据, 消息队列在消息的收发上, 就有<strong>服务端转发和客户端寻址</strong>两种方案.</p> <p>所以, <mark><strong>消息队列集群应该是按照有状态服务来设计的</strong></mark>. 接下来开始看看<strong>如何设计出一个集群化的消息队列服务</strong>.</p> <h5 id="消息队列的集群设计思路"><a href="#消息队列的集群设计思路" class="header-anchor">#</a> 消息队列的集群设计思路</h5> <p>当前业界主流的分布式集群, 一般都是基于<strong>主从(Master/Slave)思想</strong>来设计的. 即通过一个组件来管理整个集群的相关工作, 比如创建和删除主题, 节点上下线等等. 这个组件一般叫做 <strong>Master(主节点)或 Controller(控制器)</strong> .</p> <p>然后还需要有一个组件来完成<strong>集群元数据(比如节点信息, Topic 信息等等)的存储, 这个组件一般叫做元数据服务</strong>. 当然还有一批数据流节点来完成数据的读写和存储工作, 这个组件一般叫做 Broker 或者节点.</p> <p>所以一个消息队列集群的架构可能是下面图中的这个样子吗? 带着这个疑问, 正式开始设计我们的集群.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ee8db4ceda999771fd0d89d0805626de-20240421231949-7ho6sma.jpg" alt=""></p> <h6 id="元数据存储-5"><a href="#元数据存储-5" class="header-anchor">#</a> 元数据存储</h6> <p>先来看一下集群中的元数据是如何存储的.</p> <p>消息队列集群元数据是指集群中 Topic, 分区, 配置, 节点, 权限等信息. <strong>元数据必须保证可靠, 高效地存储, 不允许丢失. 因为一旦元数据丢失, 其实际的消息数据也会变得没有意义</strong>.</p> <p>从技术上看, 业界主要有<mark><strong>第三方存储引擎和集群内部自实现存储</strong></mark>两种方案.</p> <ul><li><mark><strong>依赖第三方存储引擎</strong></mark> 是指直接使用第三方组件来完成元数据信息的存储, 比如 ZooKeeper, <strong>etcd</strong>, 单机或者分布式数据库等等. 这种方案的优点是拿来即用, 无需额外的开发成本, 产品成型快, 稳定性较高. 缺点是需要依赖第三方组件, 会增加额外的部署维护成本, 并且受限于第三方组件的瓶颈和稳定性, 也可能会有数据一致性问题. <strong>目前业界主流消息队列都是选用的这个方案</strong>, 比如 RabbitMQ 基于 Mnesia 或 etcd, Kafka, Pulsar 基于 ZooKeeper 都是用的这个方案.</li> <li><mark><strong>集群内部自实现存储</strong></mark> 是指在消息队列应用内部自定义实现元数据存储服务, 相当于在消息队列集群中实现一个小型的 ZooKeeper. 这种方案的优点是集群内部集成了这部分能力, 部署架构就很简单轻量, 应用自我把控性高, 不会有第三方依赖问题. 缺点是开发成本高, 从头开始自研, 相对于成熟组件而言, 稳定性上短期会比较弱, 需要投入时间打磨.</li></ul> <p>业界的消息队列中, Kafka 去 ZooKeeper 后的 KRaft 架构中的元数据存储, 就是基于这个思路实现的. 个人是比较倾向于第二种方案的, 因为长期来看, 当组件成熟后, 在产品后期架构简单是一个非常大的优势.</p> <h6 id="节点发现"><a href="#节点发现" class="header-anchor">#</a> 节点发现</h6> <p>接下来来看看如何<strong>完成节点发现</strong>. 集群是由多个节点组成的, 此时组成集群的最基本要求就是: <strong>所有节点知道对方的存在或者有一个组件知道所有节点的存在, 这样才能完成后续的集群管理和调度. 这个过程就是节点发现的过程</strong>.</p> <p>从技术上看, 当前业界主要有<mark><strong>配置文件, 类广播机制, 集中式组件</strong></mark>三种手段来完成节点发现.</p> <ol><li><strong>配置文件</strong> 是指通过配置文件配置所有节点 IP, 然后节点启动后根据配置文件去找到所有的节点, 从而完成节点发现. 这种方案的好处就是实现简单, 在节点发现这块几乎不需要额外的开发成本, 缺点就是集群扩容需要修改配置文件, 水平扩容不方便, 需要重启. 业界 ZooKeeper 和 Kafka KRaft 就是用的这种方案.</li> <li><strong>类广播机制</strong> 是指通过广播, DNS 解析等机制, 自动去发现集群中所有节点. 比如通过解析 DNS 域名, 得到域名绑定的所有 IP, 从而发现集群中所有节点. 这种方案的好处是可以<strong>自动发现新节点, 自动扩容集群</strong>. 缺点是开发成本很高, 需要通过广播或者类似的机制发现集群中的其他节点. 业界的 RabbitMQ 和 Elasticsearch 用的就是这种方案.</li> <li><strong>集中式组件</strong> 是指<strong>所有节点都向集中式组件去注册和删除自身的节点信息</strong>, 此时这个组件就会包含所有节点的信息, 从而完成节点发现. 这种方案的好处是可以<strong>动态地感知节点的变更, 水平扩容非常方便</strong>, 实现也简单. 所以<mark><strong>当前主流消息队列都是用的这种方案</strong></mark>. 业界 Kafka 基于 ZooKeeper 的版本, RocketMQ, Pulsar 用的都是这种方案.</li></ol> <h6 id="节点探活"><a href="#节点探活" class="header-anchor">#</a> 节点探活</h6> <p>完成节点发现后, 接下来就需要能<strong>感知节点的变更, 以便在节点故障时及时将其踢出集群</strong>. 而这种动作就得依靠<mark><strong>节点探活</strong></mark>来实现.</p> <p>从实现角度来看, 一般需要<strong>有一个角色来对集群内所有节点进行探活或者保活, 这个角色一般是主节点(Master/Leader/Controller)或第三方组件</strong>.</p> <p>如下图所示, <strong>技术上一般分为主动上报和定时探测两种, 这两种方式的主要区别在于心跳探活发起方的不同</strong>. 从技术和实现上看, 差别都不大, 从稳定性来看, 一般<strong>推荐主动上报</strong>. 因为由中心组件主动发起探测, 当节点较多时, 中心组件可能会有性能瓶颈, 所以<strong>目前业界主要的探活实现方式也是主动上报</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9c844b8yy4749e6d0260d3ddb1e923f7-20240421231949-17r0lqr.jpg" alt=""></p> <p>从探测策略上看, 基本都是基于 <strong>ping-pong 的方式</strong>来完成探活. 心跳发起方一般会根据一定的时间间隔发起心跳探测. 如果保活组件一段时间没有接收到心跳或者主动心跳探测失败, 就会剔除这个节点. 比如每 3 秒探测一次, 连续 3 次探测失败就剔除节点. 探测行为一般会设置较短的超时时间, 以便尽快完成探测.</p> <p>以 Kafka 为例, 它是基于 ZooKeeper 提供的临时节点和 Hook 机制来实现节点保活的. 即节点加入集群时会创建 TCP 长连接并创建临时节点, 当 TCP 连接断开时就会删除临时节点. 临时节点的变更会触发后续的相关操作, 比如将节点加入集群, 将节点剔除集群等等.</p> <p>所以基于 ZooKeeper 实现节点发现和保活就很简单, 只要通过 SDK 创建临时节点即可, 只要 TCP 连接存活, 临时节点就会存在. 那么怎样确认连接存活呢? <strong>底层还是通过 ping-pong 机制, 客户端主动上报心跳的形式实现的</strong>.</p> <p>因为 ZooKeeper 具备这两个机制且组件相对成熟, 稳定性较高, 所以<strong>很多消息队列都会用 ZooKeeper 来实现节点发现和探活</strong>. 完成节点探活后, 接下来来看看<strong>集群的主节点是怎么选举出来</strong>的.</p> <h6 id="主节点选举"><a href="#主节点选举" class="header-anchor">#</a> 主节点选举</h6> <p>从技术上看, 理论上只要完成了节点探活, 即节点健康的情况下, 这批节点就都是能被选为主节点的. 当然, 有的集群可以配置哪些节点可以被选举为主节点, 哪些节点不能被选举主节点, 但是这点不影响后续的选举流程.</p> <p>主节点的选择一般有<mark><strong>相互选举和依赖第三方组件争抢注册</strong></mark>两种方式.</p> <p><strong>相互选举</strong> 是指所有节点之间相互投票, 选出一个得票最多的节点成为 Leader. 投票的具体实现可以参考 <strong>Raft 算法</strong>, 这里就不展开. 目前业界 Zookeeper, Elasticsearch, Kafka KRaft 版本等都是用的这种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6a4ed444061e250be6f42a1afe2a6c0f-20240421231949-kmyrw4v.jpg" alt=""></p> <p><strong>依赖第三方组件争抢注册</strong> 是指通过<strong>引入一个集中式组件来辅助完成节点选举</strong>. 比如可以在 ZooKeeper, etcd 上的某个位置写入数据, 哪个节点先写入成功它就是 Leader 节点. 当节点异常时, 会触发其他节点争抢写入数据. 以此类推, 从而完成主节点的选举.</p> <p>在消息队列中, 这个主节点一般称为 <strong>Controller</strong>(控制器), Controller 主要是用来完成集群管理相关的工作, 集群的管理操作一般指创建和删除 Topic, 配置变更等等行为.</p> <p>所以抽象来看, 一般情况下消息队列的集群架构如下所示:</p> <p>​<img src="/img/c7d7e9f72e447d90yydb74632c2521fc-20240421231949-gaqk3fe.jpg" alt="">​</p> <p>其中, Metadata Service 负责元数据的存储, Controller 负责读取, 管理元数据信息, 并通知集群中的 Broker 执行各种操作. 此时从实际架构实现的角度来看, Broker 的元数据上报可以走路径 1, 通过 Controller 上报元数据到 Metadata Service, 也可以直连 Metadata Service 走路径 2 上报元数据. 两条路径没有明显的优劣, 一般根据实际的架构实现时的选型做考虑.</p> <p><strong>当完成元数据存储, 节点发现, 节点探活, 主节点选举后, 消息队列的集群就创建完成了</strong>. 接下来通过集群启动, 创建 Topic, Leader 切换三个动作来分析一下集群的<mark><strong>运行机制</strong></mark>. 先来看一下集群启动的流程.</p> <h5 id="集群构建流程拆解"><a href="#集群构建流程拆解" class="header-anchor">#</a> 集群构建流程拆解</h5> <p><strong>集群启动其实就是节点启动的过程</strong>, 来看下图:</p> <p>​<img src="/img/5dc9e912e11b6906cb21317963ddae04-20240421231949-2b6t1k7.jpg" alt="">​</p> <p>节点启动大致分为以下四步:</p> <ol><li><strong>节点启动时在某个组件(如图中的 Controller 或 Metadata Service)上注册节点数据, 该组件会保存该节点的元数据信息</strong>.</li> <li><strong>节点注册完成后, 会触发选举流程选举出一个主节点(Controller)</strong> .</li> <li><strong>节点会定期向主节点(或 Metadata Service)上报心跳用来确保异常节点能快速被剔除</strong>.</li> <li><strong>当节点异常下线或有新节点上线时, 同步更新集群中的元数据信息</strong>.</li></ol> <p>从运行的角度看, 完成这一步, 集群就算已经构建完成了. 接下来来看下<strong>创建 Topic 的流程</strong>是怎样运行的.</p> <h6 id="创建topic"><a href="#创建topic" class="header-anchor">#</a> 创建Topic</h6> <p>下面是一张创建 Topic 流程各个组件的交互图.</p> <p>​<img src="/img/7ec388e27bbf896dc6316ba2b73d885f-20240421231949-3jlc4bg.jpg" alt="">​</p> <p>创建 Topic 大致分为以下四步:</p> <ol><li><strong>客户端指定分区和副本数量</strong>, 调用 Controller 创建 Topic.</li> <li>Controller 根据当前集群中的节点, 节点上的 Topic 和分区等元数据信息, 再根据一定的规则, <strong>计算出新的 Topic 的分区, 副本的分布, 同时选出分区的 Leader(主分片)</strong> .</li> <li>Controller 调用 Metadata Service <strong>保存元数据信息</strong>.</li> <li><strong>Controller 调用各个 Broker 节点创建 Topic, 分区, 副本</strong>.</li></ol> <p>再来看看删除 Topic 和扩容分区是如何执行的.</p> <p>如果要删除 Topic, 首先依旧要先往 Controller 发送一个删除 Topic 的指令; 然后 Controller 会通知 Topic 分区所在的节点, 删除分区和副本数据, 删除 Topic; 最后再删除 Metadata Service 中的 Topic 元数据. 扩容分区的操作也是类似的, Controller 接收到扩容分区的指令, 根据逻辑计算出新分区所在的节点, 然后通知对应的节点创建分区, 同时保存相关元数据.</p> <p>接下来再看看 Leader 切换是如何执行的.</p> <h6 id="leader切换"><a href="#leader切换" class="header-anchor">#</a> Leader切换</h6> <p>当新的 Broker 节点加入集群, 这个节点就需要在 Controller 上进行注册. 此时如果节点宕机, 因为新节点上没有分区或 Topic 数据, 所以不需要进行 Leader 切换.</p> <p>而如果已有节点下线, 因为节点上有分区的 Leader 存在, 所以需要进行 Leader 切换, 以便实现服务的高可用.</p> <p>因为<strong>集群会监听所有 Broker 的服务状态. 当 Broker 挂掉时, Controller 就会感知从而触发 Leader 切换操作</strong>. 下面是一张 Leader 切换的流程图.</p> <p>​<img src="/img/fa010ccdcdd953f21a0208f91459765c-20240421231949-qphggfd.jpg" alt="">​</p> <p>Leader 切换的流程可以分为以下四步:</p> <ol><li>Controller 会持续监听节点的存活状态, 持续监控 Broker 节点是否可用.</li> <li>根据一定的机制, 判断节点挂掉后, 开始触发执行 Leader 切换操作.</li> <li>Controller 通过 RPC 调用通知存活的 Broker2 和 Broker3, 将对应分区的 Follower 提升为 Leader.</li> <li>变更保存所有元数据.</li></ol> <p>从客户端的视角来看, <strong>服务端是没有机制通知客户端 Leader 发生切换的</strong>. 此时需要依靠<strong>客户端主动更新元数据信息来感知已经发生 Leader 切换. 客户端一般会在接收到某些错误码或者定期更新元数据来感知到 Leader 的切换</strong>.</p> <p>讲到这里, 你应该已经了解了集群构建的整体思路. 下节会详细聊一聊<strong>元数据存储服务的具体选型和实现</strong>, 同时详细讲一下 ZooKeeper 和 Kafka 的集群构建思路.</p> <h5 id="总结-15"><a href="#总结-15" class="header-anchor">#</a> 总结</h5> <p>集群构建的思路分为有状态服务和无状态服务, 两种类型服务的构建思路是不一样的. <strong>有状态服务需要解决元数据存储, 节点发现, 节点探活, 主节点选举等四部分</strong>.</p> <p>元数据存储主要有<strong>依赖第三方组件实现和集群内自定义实现元数据存储</strong>两个思路. 第三方组件主要有 ZooKeeper, etcd 等, 依赖第三方组件是当前主流的选择, 因为其实现较为简单, 前期稳定性较高. 自定义实现元数据存储是指在消息队列 Broker 集群内实现元数据存储服务, 从而简化架构, 实现虽较为复杂, 但长期来看相对更合理.</p> <p><strong>节点发现主要有静态发现和动态发现两个思路</strong>. 静态发现是指通过配置文件配置好集群的所有节点, 各个节点之间通过配置内容来发现对方, 从而组建成一个集群. 动态发现是指依赖一个中心组件或者类广播机制来动态完成节点之间的相互发现, 即当节点上线或下线的时候, 及时感知到变化, 从而将节点加入到集群或者从集群中剔除.</p> <p><strong>节点探活主要分为主动上报和定时探测两种, 业界主要使用主动上报的实现形式</strong>.</p> <p>主节点在消息队列中一般叫做 Controller, 一般通过节点间选举或者依赖第三方组件争抢注册来完成选举. Controller 主要用来完成集群内的管理类操作, 如节点上下线, Topic 创建/删除/修改, Leader 切换等等. Controller 由集群中的某个 Broker 担任.</p> <h5 id="思考题-13"><a href="#思考题-13" class="header-anchor">#</a> 思考题</h5> <blockquote><p>基于上面的集群方案, 如果要实现分区缩容你会怎么做? 你觉得需要注意哪些事情?</p></blockquote> <p>大体流程如下:</p> <ol><li>客户端发送缩容分区的请求给 Controller, 请求参数中包含要缩容哪个 Topic, 缩容几个分区.</li> <li>Controller 判断请求是否合理, 计算出哪些分区可以缩容.</li> <li>Controller 向可以缩容的分区所在的 Broker 节点发送删除分区请求.</li> <li>当删除分区成功后, Controller 更新 Topic 分区相关的元数据.</li></ol> <p>这里需要注意的是, <strong>一旦删除分区后, 数据就会被删除, 此时数据就无法恢复了</strong>. 所以在删除分区的时候, 要考虑分区中的数据如何处理, 比如迁移走或者先禁止写入, 支持消费, 然后等分区中的数据都过期后再删除.</p> <h4 id="_16-集群-如何构建分布式的消息队列集群-下"><a href="#_16-集群-如何构建分布式的消息队列集群-下" class="header-anchor">#</a> 16-集群:如何构建分布式的消息队列集群?(下)</h4> <p>接着上节课的内容, 继续来看如何构建集群, 先来看<strong>元数据存储服务的设计选型</strong>. 在消息队列的集群架构中, 元数据存储服务的选型和实现是整个架构设计的核心, 其他模块的设计实现都是围绕着元数据存储服务来展开的.</p> <h5 id="元数据存储服务设计选型"><a href="#元数据存储服务设计选型" class="header-anchor">#</a> 元数据存储服务设计选型</h5> <p>上节讲到过, 业界主要有<strong>基于第三方存储引擎和集群内部自实现元数据存储两种方案</strong>. 先来分析一下这两种方案的具体实现.</p> <h6 id="基于第三方存储引擎"><a href="#基于第三方存储引擎" class="header-anchor">#</a> 基于第三方存储引擎</h6> <p>这个方案最重要的一件事就是 <strong>组件选型</strong>.</p> <p>从技术上来看, 一般只要具备可靠存储能力的组件都可以当作第三方引擎. 简单的可以是单机维度的内存, 文件, 或者单机维度的数据库, KV 存储, 进一步可以是分布式的协调服务 ZooKeeper, etcd 等等.</p> <p>正常来讲, 大多数消息队列只会支持一种存储引擎, 因为一种存储引擎基本够用了. 但是也会有如 <strong>Pulsar 支持插件化的元数据存储服务, 用来简化不同场景下的部署成本, 比如单机运行, 测试集成, 现网部署等等</strong>.</p> <p>从分布式的角度来看, 单机维度的存储能满足的场景有限, 也会有单机风险. 所以<mark><strong>业界主流的分布式消息队列都是选用分布式的协调服务, 如 ZooKeeper, etcd 等来当集群的元数据存储服务</strong></mark>. 所以基于第三方存储引擎的集群架构图一般是下面这样子.</p> <p>​<img src="/img/de265236e7de626c227bccb8e430dfb1-20240421231949-b42u0x9.jpg" alt="">​</p> <p>如图所示, 这是一个由单独的元数据存储集群和多台 Broker 节点组成的消息队列集群. Broker 连接上 Metadata Service 完成节点发现, 探活, 主节点(Controller)选举等功能. <strong>其中 Controller 的角色是由某一台 Broker 兼任的</strong>.</p> <p>在图中可以看到 Controller 和 Metadata Service 是分开的, 各自承担着不同的职能. <strong>Controller 是无状态的, 因为它不负责保存数据, 只负责计算逻辑. 所以在这种情况下, 一般就会让集群中的某台 Broker 来承担 Controller 的功能. 当这台 Broker 挂了后, 可以依赖元数据存储服务把 Controller 切换到新的 Broker. 因为它是无状态的, 所以切换是非常快的</strong>.</p> <p>多说一句, 在这个架构图中, 如果把元数据服务替换成 ZooKeeper, 这个架构就是 Pulsar 和 Kafka 了. 如果把元数据服务换成 NameServer, 这个架构就是 RocketMQ 了.</p> <p>不过你会发现, 如果使用这个方案, 集群最少得有 6 个节点, 这会导致部署成本, 运维复杂度变高. 那有没有可能简化架构呢? 继续来看集群<strong>内部自实现元数据存储</strong>的方案.</p> <h6 id="集群内部自实现元数据存储"><a href="#集群内部自实现元数据存储" class="header-anchor">#</a> 集群内部自实现元数据存储</h6> <p>从技术上看, 可以通过<strong>在多台 Broker 的进程中实现分布式的元数据存储</strong>, 从而解决依赖第三方组件的一些弊端. 整体架构如下图所示:</p> <p>​<img src="/img/a6ef8f66c29978c8f63a957124668fd3-20240421231949-qyeqes7.jpg" alt="">​</p> <p><strong>从技术实现来看, 主要有三个思路</strong>:</p> <ol><li>直接在 Broker 内部构建一个<strong>小型的元数据存储集群</strong>来提供服务.</li> <li>通过某些可以内嵌到进程的小型的分布式存储服务来完成元数据的存储.</li> <li>通过某些可以内置的单机持久化的服务, 配合节点间的元数据同步机制来完成元数据的存储.</li></ol> <p>第一种方案需要在 Broker 中实现一个元数据集群. 这个元数据集群和 Broker 集群最大的差别在于它只需要承担单个集群的元数据管理存储, 数据量和规模很小, 集群一般不需要扩容. 所以这个集群适合使用 &quot;通过配置发现节点的方案&quot; 来构建集群. Kafka 的 KRaft 架构用的就是这种方案.</p> <p>第二种方案是利用某种可以<strong>内嵌到进程的存储服务来存储元数据</strong>, 比如 Mnesia 或 RocksDB. 如果是单机的存储引擎, 比如 RocksDB, 那么主要适用于单机部署的场景. 单机存储引擎的方案如果要实现元数据的集群化, 那么就得在节点之间实现相互同步数据的机制, 这个就相对复杂许多. 而如果是分布式的存储引擎, 如 Mnesia, 那么就简单许多, 几乎没有工作量, 直接调用存储引擎的接口存储元数据即可.</p> <p>第三种方案是<strong>在节点上部署一个持久化的单机存储引擎</strong>, 如 RocksDB 等. 然后在 Broker 内维护节点间的元数据数据的一致性. 这种方式也是一种实现比较简单的方案, 开发难度低于第一种方案, 高于第二种方案.</p> <p>从业界实现来看, 目前第一种和第二种方案都有在使用. 第三种方案主要用在单机模式下, 问题是要维护多个节点的存储服务之间的数据一致性, 有一定的开发工作量, 并且保持数据强一致比较难.</p> <p>总结来看, 在集群中实现元数据服务的优点是, 后期架构会很简洁, 不需要依赖第三方组件. 缺点是需要自研实现, 研发投入高. 而如果使用独立的元数据服务, 因为是现成的组件, 产品成型就会很快, 这也是当前主流消息队列都是依赖第三方组件来实现元数据存储的原因. 所以当前主流消息队列的架构如下所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/7bed34f302522bcf84e78e0890ec48e9-20240421231949-djhp8xj.jpg" alt="">​</p> <p>接下来就用实际案例结合前面这些基础知识点, <strong>来看一下 ZooKeeper, Kafka 是如何构建集群的</strong>, 先来看一下 ZooKeeper.</p> <h5 id="zookeeper的集群构建"><a href="#zookeeper的集群构建" class="header-anchor">#</a> ZooKeeper的集群构建</h5> <p>ZooKeeper 是一个分布式的数据协调服务, 本质上是一个<strong>简单的, 分布式, 可靠的数据存储服务</strong>. 核心操作就是数据的写入, 分发, 读取和 Hook. 从客户端看, 主要操作就是写入和读取. 从服务端看, 主要操作就是集群构建, 数据接收, 存储, 分发和 Hook.</p> <p>在集群构建上, 它会事先在<strong>配置中定义好集群中所有节点的 IP 列表</strong>. 然后集群启动时, 会在这些<strong>节点之间进行选举, 经过多数投票机制, 选举出一个 Leader 节点, 从而构建成为集群</strong>. 在单节点上, 集群构建相关的配置一般如下所示, 配置中会包含所有节点信息.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>server.0=10.0.32.1:2888:3888
server.1=10.0.32.2:2888:3888
server.2=10.0.32.3:2888:3888
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>在节点启动的时候, 节点之间就会两两进行通信, 触发投票</strong>. 然后根据票数的多少, 基于多数原则, 选择出一个 Leader 出来. 当 Leader 节点发生宕机或者增加节点时, 就会重新触发选举.</p> <p>​<img src="/img/cd081e32f511fbe4681de84f4fbc3358-20240421231949-047uyet.jpg" alt="">​</p> <p>多数投票是一个经常用到的投票机制, 即某个节点获得票数超过可投票的节点的一半后, 就可以当选为 Leader. <strong>从实现角度, 一般是通过集群中节点之间的通信和间隔随机投票的机制来完成投票, 以保证能够在短时间内完成选举</strong>.</p> <p>当选举完成后, <strong>Leader 会主动给各个 Follower 节点发送 ping-pong 请求, 以确定节点是否还活着</strong>. 当 Follower 心跳异常时, 就会剔除该节点, 当集群中可用的节点数少于总节点数的一半, 就会选举不出 Leader, 从而导致集群异常.</p> <p>因为 ZooKeeper 只是一个<strong>数据存储服务</strong>, 并没有很多管控操作, Leader 节点就负责数据的写入和分发, Follower 不负责写入, 只负责数据的读取. 当 Leader 收到操作请求时, 比如创建节点, 删除节点, 修改内容, 修改权限等等, 会保存数据并分发到多个 Follower, 当集群中有一半的 Follower 返回成功后, 数据就保存成功了. 当 Follower 收到写入请求时, 就把写入请求转发给 Leader 节点进行处理.</p> <p>因为功能和定位上的差异, ZooKeeper 上是没有 Controller 和元数据存储的概念的. 它是比较典型的基于固定配置构建集群的方式.</p> <h5 id="kafka的集群构建"><a href="#kafka的集群构建" class="header-anchor">#</a> Kafka的集群构建</h5> <p>前面说过, 目前主流消息队列集群主要是<strong>基于第三方组件来构建</strong>的. 而 Kafka 正是这种方案的典型实现, 接下来就来看一下 <strong>Kafka 基于 ZooKeeper 和基于 KRaft 构建集群的两种实现方式</strong>. 先来看一下基于 ZooKeeper 的构建思路.</p> <h6 id="基于zookeeper的集群"><a href="#基于zookeeper的集群" class="header-anchor">#</a> 基于ZooKeeper的集群</h6> <p>在这种架构中, <mark><strong>Kafka 将 ZooKeeper 作为节点发现和元数据存储的组件, 通过在 ZooKeeper 上创建临时节点来完成节点发现, 并在不同的节点上保存各种元数据信息</strong></mark>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/07fd1ef326f52623dcd147c654dde44f-20240421231949-qabjino.jpg" alt=""></p> <p>如图所示, Broker 在启动或重连时, 会根据配置中的 ZooKeeper 地址找到集群对应的 ZooKeeper 集群. 然后会在 ZooKeeper 的 <code>/broker/ids</code>​ 目录中创建名称为<mark><strong>自身 BrokerID 的临时节点</strong></mark>, 同时在节点中保存自身的 Broker IP 和 ID 等信息. 当 Broker 宕机或异常时, TCP 连接就会断开或者超时, 此时<strong>临时节点就会被删除</strong>. 如下两张图, 分别是 <code>/broker/ids</code>​ 节点下的结构和 BrokerID 中的内容.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ab4cd337378cf05176160835ba057a74-20240421231949-xbsxwdi.jpg" alt=""></p> <p><strong>注册完这些信息后, 节点发现就算完成了</strong>. 节点之间的探活依赖 ZooKeeper 内置的探活机制, 前面讲过, 这里不再赘述. 接下来来看一下 Kafka 中的 Controller.</p> <p>在 Kafka 中, Controller 是一个<strong>虚拟</strong>概念, 是运行在某台 Broker 上的一段代码逻辑. 集群中需要确认一台 Broker 承担 Controller 的角色, 那 Controller 是怎么选出来的呢? 来看一看.</p> <p>Kafka 的 Controller 选举机制非常简单, <mark><strong>即在 ZooKeeper 上固定有一个节点 /controller. 每台 Broker 启动的时候都会去 ZooKeeper 判断一下这个节点是否存在. 如果存在就认为已经有 Controller 了, 如果没有, 就把自己的信息注册上去, 自己来当 Controller</strong></mark>. 集群每个 Broker 都会监听 /Controller 节点, 当监听到节点不存在时, 都会主动去尝试创建节点, 注册自己的信息. <strong>哪台节点注册成功, 这个节点就是新的</strong> <strong>Controller</strong>.</p> <p>Controller 会监听 ZooKeeper 上多个不同目录, 主要<strong>监听目录中子节点的增加, 删除, 节点内容变更</strong>等行为. 比如会通过监听 <code>/brokers/ids</code>​ 中子节点的增删, 来感知集群中 Broker 的变化. 即当 Broker 增加或删除时, ZooKeeper 目录中就会创建或删除对应的节点. 此时 Controller 通过 Hook 机制就会监听到节点发生了变化, 就可以拿到变化节点的信息, 根据这些信息, 触发后续的业务逻辑流程.</p> <p>Kafka 集群中每台 Broker 中都有集群全量的元数据信息, 每台节点的元数据信息大部分是通过 Controller 来维护的, 比如 Topic, 分区, 副本. 当这些信息发生变化时, Controller 就会监听到变化. 然后根据不同的 Hook(如创建, 删除 Topic 等), 将这些元数据通过 TCP 调用的形式通知给集群中其他的节点, 以保持集群中所有节点元数据信息是最新的.</p> <p>接下来用 Topic 的创建流程, 来串联一下集群中的 Controller 的集群管理和元数据存储.</p> <p>​<img src="/img/082decf91e6yy8a7f853714e2c13ceb3-20240421231949-hu5p65a.jpg" alt="">​</p> <p>如图所示, Kafka 创建 Topic 有两种形式(图中 1 和 2), 即<strong>通过 Broker 来创建和通过 ZooKeeper 来创建</strong>. 当调用 Broker 创建 Topic 时, Broker 会根据本地的全量元数据信息, 算出新 Topic 的分区, 副本分布, 然后将这些数据写入到 ZooKeeper. 然后 Controller 就会 Hook 到创建 Topic 的行为, 更新本地缓存元数据信息, 通知对应的 Broker 节点创建分区和副本.  所以, 也可以通过直接生成计划然后, 写入到 ZooKeeper 的方式来创建 Topic.</p> <h6 id="基于kraft的集群"><a href="#基于kraft的集群" class="header-anchor">#</a> 基于KRaft的集群</h6> <p>接下来来看一下基于 KRaft 构建的 Kafka 集群.</p> <p>如下图所示, 从架构的角度, 基于 KRaft 实现的 Kafka 集群做的事情就是<strong>将集群的元数据存储服务从 ZooKeeper 替换成为内部实现的 Metadata 模块</strong>. 这个模块会同时完成 Controller 和元数据存储的工作.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/17fc12dc3cf8aec9975ded5fb0ccb578-20240421231949-zhzcg6p.jpg" alt=""></p> <p>前面讲过, <strong>集群元数据需要分布式存储才能保证数据的高可靠</strong>. 所以 <strong>Kafka KRaft 架构的 Metadata 模块是基于 Raft 协议实现的 KRaft, 从而实现元数据可靠存储的</strong>.</p> <p>因为 Kafka 的 Metadata 模块只需要完成元数据存储, 所以它的设计思路和 ZooKeeper 是一样的, 是<strong>主从架构</strong>. 即通过在配置文件中配置节点列表, 然后通过投票来选举出 Leader 节点. 这个节点会承担集群管控, 元数据存储和分发等功能.</p> <p>Metadata 模块的配置如下所示. 即通过配置项 <code>controoler.quorum.votes</code>​ 配置允许成为 Controller 的节点列表, 然后这些节点之间会通过投票选举出 Leader 节点, 这个 Leader 会完成 Controller 和元数据存储的工作. 这个 Leader 相当于基于 ZooKeeper 版本中的 Controller 和 ZooKeeper 的 Leader.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>process.roles=broker,controller
controller.quorum.voters=1@localhost:9093
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>所以在这个版本架构的实现中, 就只有 Controller 了, 然后 Controller 自带了元数据存储的功能. 所以架构上就会变成了下面这个样子.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/56eac7f60459b843ed614117ec4059f9-20240421231949-7uu7cev.jpg" alt="">​</p> <p>如上图所示, <strong>Broker 之间通过投票选举出来的 Leader 节点就是 Controller</strong>. 此时所有 Broker 都会和 Controller 保持通信, 以维护节点的在线状态, 从而完成节点发现. 当 Controller 发现 Broker 增加或异常时, 就会主动执行后续的操作.</p> <p>所以, 从链路来看, 这个<strong>架构简化了通过监听 ZooKeeper 来发现节点变更的流程, 链路更短, 稳定性更高. 和基于 ZooKeeper 的架构一样, 每台 Broker 依旧有集群全量的元数据信息, 这些元数据信息的维护也是通过 Controller 完成的</strong>.</p> <p>接下来看一下 KRaft 架构下创建 Topic 的流程, 来看下图:</p> <p>​<img src="/img/1b98c69f143e5381cdacffe819d12140-20240421231949-pmspw9p.jpg" alt="">​</p> <p>这里因为没有 ZooKeeper, 所以<strong>创建 Topic 只有通过 Broker 创建的方式</strong>. 通过 Admin SDK 调用 Broker 创建 Topic, 如果 Broker 不是 Controller, 这个请求就会转发到当前的 Controller 上. Controller 会根据本地的元数据信息生成新 Topic 的分区, 副本的分布, 然后调用对应的 Broker 节点完成分区和副本数据的创建, 最后会保存元数据.</p> <p>其他的操作, 如删除 Topic, 修改配置, 创建 ACL 等操作的流程是一样的.</p> <p>讲到这里, 你会发现<strong>基于 KRaft 的 Kafka 架构比基于 ZooKeeper 架构简单清晰非常多, 操作链路也短很多</strong>. 这样可以解决基于 ZooKeeper 架构中一些难以解决的问题, 如集群可承载分区数量上限较低, 缓存不一致等等.</p> <h5 id="总结-16"><a href="#总结-16" class="header-anchor">#</a> 总结</h5> <p>目前, 消息队列的主流实现方式都是依赖第三方组件来完成数据存储, 常见的有 ZooKeeper, etcd 等. 为了简化架构, 还可以通过在集群内自建元数据存储服务来替代第三方组件, 虽然需要研发投入, 但从架构长期演进的合理性来看, 我是推荐这种方式的, 毕竟后期架构会很简洁.</p> <p>ZooKeeper 集群的组件, 是基于配置文件中指定集群中其他节点的 IP 地址和端口来实现节点发现的, 属于单播发现机制. 这种方式的缺点就是扩容需要修改配置, 重启集群. 所以, 还有一种通过配置多播地址和端口来实现集群发现的方式, 其好处是可以动态发现节点, 属于单播的一种升级, 目前 Elasticsearch 和消息队列 RabbitMQ 都属于多播的实现.</p> <p>从 Kafka 的集群构建来看, 基于独立的元数据存储服务, 会导致架构复杂和引入缓存不一致等问题. 集群内部实现元数据存储, 可以简化架构, 避免不一致. 从技术合理性来看, 更建议使用<strong>内置元数据存储</strong>的方案.</p> <h5 id="思考题-14"><a href="#思考题-14" class="header-anchor">#</a> 思考题</h5> <blockquote><p>请简单描述一下 Kafka 集群中修改配置/权限操作的流程?</p></blockquote> <p><strong>Kafka 修改配置/权限的实现, 是每个 Broker 直接去监听 Broker 中的节点</strong>. Broker 会直接监听 ZooKeeper 上的节点, 然后根据 Hook 到的信息, 做对应的操作. 比如修改集群和 Topic 配置, 就是 Broker 通过直接监听 ZooKeeper 的不同子节点来实现的. 这种方式的好处是, Broker 直接监听 ZooKeeper, 避免 Controller 转发一道, 从而避免让 Controller 成为瓶颈, 整体链路更短, 出问题的概率也更低.</p> <h4 id="_17-可靠性-分布式集群的数据一致性都有哪些实现方案"><a href="#_17-可靠性-分布式集群的数据一致性都有哪些实现方案" class="header-anchor">#</a> 17-可靠性:分布式集群的数据一致性都有哪些实现方案?</h4> <p>前两节讲完了消息队列集群的设计要点和思路, 也讲到了在集群中引入副本的概念来实现数据的分布式可靠存储. 这节课就来讲一下集群中<strong>数据的一致性</strong>, 看看它是<strong>如何保证这些分布在多个节点上的副本上的数据是一致的</strong>.</p> <h5 id="分区-副本和数据倾斜"><a href="#分区-副本和数据倾斜" class="header-anchor">#</a> 分区,副本和数据倾斜</h5> <p>首先来讲一下分区, 副本和数据倾斜, 这个是学习后面内容的一个基础.</p> <p>前面讲过, <strong>副本之间一般都有主从</strong>的概念. 为了达到容灾效果, 主从副本需要分布在不同的物理节点上, 来看一张图.</p> <p>​<img src="/img/830a5dff0c6e547e6af32ba0f1af432b-20240421231949-7zt36yq.jpg" alt="">​</p> <p>如上图所示, 这是一个<strong>三副本的分片, Leader 和 Follower 会分布在三个节点上</strong>. 控制副本分布的工作, 就是由上节课讲到的控制器来完成的. 控制器会根据当前的节点, Topic, 分区, 副本的分布信息, 计算出新分区的分布情况, 然后调用不同的 Broker 完成副本的创建(不同消息队列的具体流程可能不一样, 但是运行原理是一致的).</p> <p>从功能上来看, 在这种主从架构中, 为了保证数据写入的顺序性, <strong>写入一般都是由 Leader 负责</strong>. 因为组件功能特性和实现方式的不同, <strong>Follower 在功能上一般会分为这样两种情况</strong>.</p> <ol><li><strong>只负责备份</strong>. 即写入和读取都是在 Leader 完成的, 平时 Follower 只负责数据备份. 当 Leader 出现异常时, Follower 会提升为 Leader, 继续负责读写.</li> <li><strong>既负责备份也负责读取, 不负责写入</strong>. 即正常情况下, Leader 负责写入, Follower 负责读取和数据备份. 当发生异常时, Follower 会提升为 Leader.</li></ol> <p>第一种方案的缺点在于, 读取和写入都是在 Leader 完成, 可能会导致 Leader 压力较高. 第二种方案的问题是, 如果 Follower 支持读取, 那么就需要保证集群数据的<strong>强一致性</strong>, 即所有副本的数据在同一时刻都需要保证是最新的.</p> <p>这两个缺点中, 第一个方案的缺点是比较好解决的, 可以通过在 Topic 维度增加分片, 并控制分片的 Leader 分布在不同的节点, 来降低单分片和单节点的负载. 而第二个是比较难解决的, 当分片的数据量很大, 要保证数据在集群中的强一致, 又要保证可用性, 基于 CAP 理论, 技术上很难解决. 这个难点后面会用 CAP 一致性协议来解释. 所以在<strong>目前消息队列的实现中, 一般都是用的第一种方案, 即 Master-Slave 的架构</strong>.</p> <p>在这种主从架构中, 如果分区分布不合理或者分区数设置过少时, 那就有可能会发生<strong>数据倾斜</strong>. 如何解决呢?</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/679ecc19bfee7e7123364991279a51c3-20240421231949-7wj9big.jpg" alt="">​</p> <p>如上图所示, 在具体实现中可以通过<strong>增加分区</strong>, 然后将不同的分区的 Leader 分布在不同的节点上. 此时, <strong>只要保证每个分区的写入是均匀的, 那么就可以避免倾斜问题.</strong></p> <p>不过这里你可能会想, 分区写入一定会是均匀的吗? 当然不一定. 那如何解决倾斜呢? 这个会在架构升级篇讲到, 可以先思考下. 不过解决这个问题不是这节课的重点, 这里只要了解什么是数据倾斜就可以了.</p> <p>讲完了分区, 副本, 数据倾斜, 接下来来看一下<strong>副本(Leader 和 Follower)之间的数据同步方式</strong>.</p> <h5 id="副本间数据同步方式"><a href="#副本间数据同步方式" class="header-anchor">#</a> 副本间数据同步方式</h5> <p>从机制上来看, 副本之间的同步方式有<mark><strong>同步复制和异步复制</strong></mark>两种.</p> <ol><li><strong>同步复制</strong> 是指主节点接收到数据后, 通过<strong>同步多写</strong>的方式将数据发送到从节点.</li> <li><strong>异步复制</strong> 是指主节点接收到数据后, 通过<strong>主节点异步发送或者从节点异步拉取的方式</strong>将数据同步到从节点.</li></ol> <p>在目前主流的消息队列中, 大部分只会实现其中一种方式, <strong>比如 Kakfa 是异步复制, Pulsar, RabbitMQ 是同步复制. RocketMQ 是比较特殊的那个, 既支持同步复制也支持异步复制</strong>.</p> <p>从数据复制的具体实现上看, 一般有<strong>通过 Leader 推送和 Follower 拉取</strong>两种方式.</p> <ol><li><strong>Leader 推送</strong> 是指当 Leader 接收到数据后, 将数据发送给其他 Follower 节点, Follower 保存成功后, 返回成功的信息给 Leader.</li> <li><strong>Follower 拉取</strong> 是指 Follower 根据一定的策略从 Leader 拉取数据, 保存成功后, 通知 Leader 数据保存成功.</li></ol> <p>这两种形式在业界都有在用, 其中 <strong>Leader 推送是用得比较多的策略</strong>, Follower 拉取用得比较少. 它们优缺点如下:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/85319816aa61ddc3340f1ebb6251cec2-20240421231949-uoea3oe.jpg" alt=""></p> <p>目前主流消息队列 <strong>RabbitMQ, RocketMQ 都是用的第一种方案, Kafka 用的是第二种方案. Pulsar 是计算存储分离的架构, 从某种意义上来说, 用的也是第一种方案</strong>.</p> <p>接下来看看 CAP 和一致性模型.</p> <h5 id="cap和一致性模型"><a href="#cap和一致性模型" class="header-anchor">#</a> CAP和一致性模型</h5> <p>在分布式系统领域, CAP 理论对于分布式系统的设计影响非常大, 几乎所有的分布式课程都会讲解 CAP, 所以就不展开分析了, 简单复习下就好.</p> <p><strong>CAP</strong> <strong>是指一致性, 可用性,</strong> <strong>分区容忍性</strong>.</p> <ul><li><strong>一致性(Consistency)</strong> 是指每次读取要么是<strong>最新的数据</strong>, 要么是一个错误.</li> <li><strong>可用性(Availability)</strong> 指 Client 在<strong>任何时刻的读写操作都能在限定的延迟内完成, 即每次请求都能获得一个正确的响应, 但不保证是最新的数据</strong>.</li> <li><strong>分区容忍性(Partition Tolerance)</strong> 是指在分布式系统中, 不同机器无法进行网络通信的情况是必然会发生的, 在这种情况下, 系统应保证可以正常工作.</li></ul> <p>因为在大部分情况下, <mark><strong>分布式系统分区容忍性是必须满足的条件</strong></mark>. 所以, 从理论上看每个分布式系统只能满足其中两个, 比如 AP, CP. 这也是经常说的<strong>分布式系统是满足 AP 还是满足 CP 的原因</strong>.</p> <p><img src="/img/915cfc5dc0ed1ab9925bc03a0cdd5b50-20240421231949-1smb71l.jpg" alt=""></p> <p>所以在消息队列的实现中, 因为面对的<strong>功能业务场景不一样</strong>(比如消息和流), 此时对一致性和可用性的要求不一样, 所以对 AP 和 CP 的支持程度和方式也会不一样. 但是为了支持更多的场景, <strong>大部分消息队列都会支持更灵活的 AP 和 CP 策略</strong>.</p> <p>简单来说, 就是因为消息队列在业务中是用来当缓冲的, 起削峰填谷的作用, 所以<mark><strong>可用性是必须要满足</strong></mark>的. <strong>消息队列从某种意义上是一个 AP 的系统, 但是作为一个存储系统, 它又必须保证数据可靠性, 所以就会在一致性上想办法</strong>.</p> <p>在分布式系统中, 一致性模型分为强一致, 弱一致和最终一致三种.</p> <ul><li><strong>强一致</strong> 是指数据写入 Leader 后, 所有 Follower 都写入成功才算成功.</li> <li><strong>弱一致</strong> 是指数据写入 Leader 后, 不保证 Follower 一定能拉到这条数据.</li> <li><strong>最终一致</strong> 是指数据写入 Leader 后, 在一段时间内不保证所有的副本都能拉到这条数据, 但是<strong>最终状态是所有的副本都会拉到数据</strong>.</li></ul> <p>​<img src="/img/a0284c71b103bdbeb8e44489bfbd3f04-20240421231949-zm93yhd.jpg" alt="">​</p> <p>接下来看<strong>消息队列在一致性和可靠性</strong>上是怎么实现的.</p> <h5 id="集群数据一致性和可靠性实现"><a href="#集群数据一致性和可靠性实现" class="header-anchor">#</a> 集群数据一致性和可靠性实现</h5> <p>从技术上看, 消息队列作为存储系统, 弱一致一般是不考虑的, 所以一般是在<strong>强一致和最终一致</strong>上做选择. 但是如果有场景(比如日志)需要弱一致呢? 要怎么满足?</p> <p>从技术上来看, 消息队列都会支持通过<strong>配置</strong>生效的, 灵活的一致性策略. 即允许通过修改配置来调整一致性策略, 比如在一些需要强一致的场景中, 可以通过修改配置来支持强一致. 同样的需要最终一致或者弱一致时, 也可以通过修改配置来生效.</p> <p>从实现的角度看, 内核对灵活的一致性策略的支持一般有<strong>集群维度固定配置和用户/资源维度灵活配置</strong>两个实现思路.</p> <ol><li><strong>集群维度固定配置</strong> 是指在集群部署的时候, 就配置好集群的一致性策略, 比如 RocketMQ, Pulsar, ZooKeeper.</li> <li><strong>用户/资源维度灵活配置</strong> 是指在客户端写入数据的时候或者在 Topic/Queue 维度, 可以配置不同的一致性策略, 比如 Kafka 和 RabbitMQ.</li></ol> <p>第一种方案的好处是用户不用关心一致性的配置, 理解成本也较低, 缺点是不够灵活. 第二种方案, 用户需要知道并设置一致性策略, 很灵活. 第二种虽然增加了理解和配置的成本, 但是在我看来使用成本其实也不高, 所以<strong>会推荐使用第二种方案</strong>.</p> <p>接下来来看一下 ZooKeeper, Kafka, Pulsar 这三个组件是<strong>如何实现分布式数据可靠性</strong>的, 之所以挑选它们, 是因为其具有一定的代表性. ZooKeeer 作为分布式协调服务, 对<strong>数据可靠性要求是最高</strong>的, 数据量也比较小. Kafka 是经典的流领域的消息队列, 数据量大, 需要<strong>保证高性能, 高吞吐, 对可靠性的要求较低</strong>. Pulsar 是计算存储分离架构, 它的写入是通过 BookKeeper 完成的, 模型上很特殊.</p> <p>下面先来看看 ZooKeeper 是如何实现分布式数据的一致性和可靠性的.</p> <h6 id="zookeeper数据一致性和可靠性"><a href="#zookeeper数据一致性和可靠性" class="header-anchor">#</a> ZooKeeper数据一致性和可靠性</h6> <p>ZooKeeper 没有副本的概念, 只有主从节点的概念, 即所有节点上的数据都是一样的. <strong>主从节点之间通过 Zab 协议来保证集群中数据的最终一致</strong>.</p> <p>基于该协议, ZooKeeper 通过主备复制, Epoch 等概念来保证集群中各个副本之间数据的一致性. 在 ZooKeeper 中, <strong>写入只能在 Leader 完成, Leader 收到数据后会再将数据同步到其他 Follower 节点中, Follower 可以负责读取数据</strong>.</p> <p><mark><strong>Zab 协议本质上是最终一致的协议</strong></mark>. 它遵循多数原则, 即当多数副本保存数据成功后, 就认为这条数据保存成功了. 多数原则的本质是在一致性和可用性之间做一个权衡, 即如果需要全部副本都成功, 当底层出现问题时, 系统就不可用, 而最终一致的可靠性又太弱. 所以<strong>多数原则是一个平衡且合理的方案, 在业界也是用得最多的</strong>.</p> <p><strong>ZooKeeper 的多数原则是固定的, 即数据写入成功的节点数要超过集群总节点的一半, 数据才算成功</strong>. 如下图所示, 这是一个三节点的 ZooKeeper 集群, 根据半数原则, 只要有两个节点成功写入数据, 就完成了数据写入.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c2d174b5d399eb9550162b51194711c1-20240421231949-swg2rgo.jpg" alt=""></p> <p>另外, ZooKeeper 需要<strong>保证数据的高可靠, 不允许丢失</strong>. 而在多数原则理论中, 如果数据只写入到 Leader 和 Follower 中, 此时这两台节点同时损坏或者集群发生异常时导致 Leader 频繁切换, 数据就可能会损坏或丢失. 为了解决这些复杂场景, Zab 协议定义了 Zxid, 崩溃恢复等细节来保证数据不会丢失.</p> <p>这里因为 Zab 协议是一个非常经典的一致性协议, 就不展开讲了, 如果有兴趣, 可以去研究一下它的细节. 接下来看看 Kafka 是如何保证数据的一致性和可靠性的.</p> <h6 id="kafka数据一致性和可靠性"><a href="#kafka数据一致性和可靠性" class="header-anchor">#</a> Kafka数据一致性和可靠性</h6> <p><strong>Kakfa 在分区维度有副本的概念, 副本之间通过自定义的 ISR 协议来保证数据一致性</strong>.</p> <p>在实现中, Kafka 同时支持<strong>强一致, 弱一致, 最终一致</strong>. 和 ZooKeeper 默认的多数原则不同, <strong>Kafka 的一致性策略是在客户端指定的. 客户端会指定 ACK 参数, 参数值 -1, 0, 1, 分别表示强一致, 弱一致, 最终一致</strong>.</p> <p>另外, 和 ZooKeeper 不同的是, Kafka 的副本同步是通过 Follower <strong>主动拉取</strong>的形式实现的. 如下图所示, 每台 Follower 节点会维护和 Leader 通信的线程, Follower 会根据一定的策略不停地从 Leader 拉取数据, 当数据写入到 Leader 后, Follower 就会拉到对应的数据进行保存.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c6947a1148f92505ayy4fe43f8e05109-20240421231949-mq2qfwj.jpg" alt=""></p> <p>这里解释一下. 如果客户端设置 ACK=-1 表示数据要强一致, 数据写入到 Leader, 就需要<strong>所有 Follower 都拉取到数据后, 数据才算保存成功</strong>. 设置 ACK=0 表示弱一致, 客户端<strong>写入数据后就不管</strong>了, 不管 Leader 有没有写入成功, Follower 有没有同步. 当 ACK=1 表示最终一致, <strong>只要 Leader 写入成功后, 就认为成功, 不管 Follower 有没有同步</strong>.</p> <p>因为 Follower 是可以批量拉取数据的, 所以 Kafka 在副本拉取数据的性能上会高许多. 在我看来, 这个模型的设计是蛮优秀的, 通过<strong>批量拉取 Leader 数据来提高一致性的性能</strong>. 但是这个协议存在的缺点是, 实现上比较复杂, 需要维护副本线程, ACK 超时时间等机制, 并且在一些边界场景, 比如 Leader 频繁切换的时候, 可能会导致分区的数据发生截断, 从而导致数据丢失.</p> <p>在我看来, Kafka 这样设计的原因和它主打性能和吞吐的定位有关, ISR 一致性协议的考虑主要也是围绕这两点展开的. 为了解决 Leader 切换, 数据截断等问题, <strong>Kafka 引入了副本水位, Leader Epoch, 数据截断等概念, 来保证数据的可用性和可靠性</strong>. 从结果上看, ISR 协议可能存在数据丢失的情况. 后面讲 Kafka 的时候会再详细讲一下 ISR 协议.</p> <p>在 Kafka 去 ZooKeeper 的版本中, Kakfa 的<strong>元数据模块使用基于 Raft 协议实现的 KRaft 来替代 ZooKeeper, 从而实现元数据的分布式可靠存储</strong>. 此时 Kakfa 元数据的一致性和可靠性的实现, 其理论基础可以参考 Raft 协议, 理论模型都是一致的, 只是实现的细节有些不同. 另外 Kafka 去 ZooKeeper 的版本, 其消息数据的数据一致性模型依旧是 ISR 模型, 这块和前面讲到的是一样的.</p> <h6 id="pulsar数据一致性和可靠性"><a href="#pulsar数据一致性和可靠性" class="header-anchor">#</a> Pulsar数据一致性和可靠性</h6> <p>接下来看看 Pulsar 是如何保证数据的一致性和可靠性的.</p> <p><strong>Pulsar 是计算存储分离的架构</strong>, 我们常说的 Pulsar 都是指 Pulsar 的 Broker. <strong>Broker 本身是不保存数据的, 数据是保存在 BookKeeper 中. 所以 Pulsar 的数据一致性协议是配合 BookKeeper 一起完成的</strong>.</p> <p>​<img src="/img/d18b4e15ac99b74a869d0aeb6f630452-20240421231949-0ebrwgf.jpg" alt="">​</p> <p>如上图所示, 数据发送到 Pulsar Broker 中后, Broker 会调用 BookKeeper 的客户端, 通过 Ledger 和 Entry 将数据写入到 BookKeeper 中. 所以从 Pulsar Broker 的角度来看, <strong>数据的一致性就是通过控制 Ledger 数量和</strong> <strong>Ledger 在</strong> <strong>BookKeeper 上的分布来实现的</strong>.</p> <p>在 Pulsar Broker, 通过配置 Write Quorum Size(Qw) 和 Ack Quorum Size(Qa)两个参数可以控制数据的一致性. <strong>Qw 指的是 Ledger 的总副本数, Qa 指数据写入几个副本后算写入成功</strong>. 比如 Qw=3, Qa=2, 就表示 Ledger 有三副本, 只要写入两个副本, 数据就算写入成功. 当前, Qw 和 Qa 这两个参数是在 Broker 端固定配置的, 不能单独指定.</p> <p><strong>Pulsar 副本间的数据同步方式是 Leader 收到数据后, 主动写入到多个 Ledger 的</strong>. Leader 会等到配置的 Qa 数量的副本写入成功, 才告诉客户端写入成功. Broker 和 BookKeeper 之间是以流的方式写入数据的, 即会先创建一个 Ledger, 然后将消息包装为一个一个的 Entry, 然后通过流的方式写入到 Ledger 中. <strong>流方式的写入可以提高写入的性能</strong>.</p> <p>从设计思路上对比 Kafka 和 BookKeeper 的一致性实现, Kakfa 的一致性放到了服务端实现, 让客户端的使用更加轻松, 无需感知底层的实现; <strong>而 BookKeeper 的实现方式, 在客户端实现了更多细节, 减轻了内核的工作量</strong>.</p> <h5 id="总结-17"><a href="#总结-17" class="header-anchor">#</a> 总结</h5> <p>一般讲分布式系统一致性和可靠性时, 都会用大量的篇幅去讲 CAP, Raft, Paxos 等一致性协议. 其实是没问题的, 不管是 ZooKeeper 的 Zab, Kafka 的 ISR 和 KRaft, 还是 Pulsar 基于 BookKeeper 实现的一致性协议, 都是 Paxos 和 Raft 的实现或简化. 但是这几个协议不是一节课能讲完的, 并且我认为讲解的意义不大, 因为网上资料非常多, 也有原始的论文可以参考. 建议课后去深入研究一下 CAP, Raft 和 Paxos.</p> <p>在消息队列中, 都会通过<strong>主从架构和控制分区, 副本的分布来提升集群性能和数据可靠性</strong>. 在分区副本模型中, 需要注意的是数据倾斜对集群的影响.</p> <p><strong>多个副本之间则是通过一致性协议来维护副本间数据的一致性. 副本之间的数据同步机制主要分为同步复制和异步复制两种. 从实现上来, 数据的同步主要有 Leader 推送和 Follower 拉取两种策略</strong>.</p> <p>在 CAP 协议中, <strong>大多数消息队列都是 AP 的系统, 同时会在强, 弱, 最终一致性上做权衡</strong>. 多数原则是用得比较多的策略, 比如 ZooKeeper, Pulsar 都是用的这个策略. 从具体实现的角度, <mark><strong>有的消息队列会提供灵活的 AP, CP, CA 切换机制, 以满足不同场景对一致性的追求</strong></mark>.</p> <p>从技术的视角来看, 强一致, 最终一致, 弱一致并没有好坏之分, 只有合适之分. 需要<strong>根据自己的业务形态</strong>来进行合适的选择, 比如在追求性能, 不追求可靠性, 且允许数据丢失的场景中, 弱一致就是合适的, 并不需要无限追求强一致.</p> <h5 id="思考题-15"><a href="#思考题-15" class="header-anchor">#</a> 思考题</h5> <blockquote><p>RabbitMQ 的 Queue 在镜像模式下的一致性模型和可靠性是怎样的?</p></blockquote> <p>RabbitMQ 是通过配置镜像队列的机制来实现多副本的, 数据可靠性的核心是多副本和一致性复制策略. 多副本之间的数据同步, 是通过同步复制, Leader 推送模型来实现的.</p> <p>从实现上来看, RabbitMQ 的镜像模式基于主从架构的模型. 镜像队列是在 Queue 的维度配置的, 共有 All, Exactly, Node 三种策略. 其中, All 是指强一致; Exactly 是允许指定同步的副本数, 这和多数策略很像, 属于最终一致; Node 可以指定数据需要固定同步的节点列表, 严格意义来说也是强一致, 因为被选中的节点都需要写入数据才算数据保存成功. 从实现上看, 在 RabbitMQ 的镜像模式中, 不支持弱一致的一致性策略.</p> <h4 id="_18-性能-java开发分布式存储系统都有哪些常用的编码技巧"><a href="#_18-性能-java开发分布式存储系统都有哪些常用的编码技巧" class="header-anchor">#</a> 18-性能:Java开发分布式存储系统都有哪些常用的编码技巧?</h4> <p>前面讲了消息队列各个模块的设计, 权衡, 思考, 选型, 基本覆盖了基础核心架构中的所有细节了.</p> <p>我一直认为, 架构设计选型和编码是两个事情, 魔鬼在细节, 不管多牛逼的架构, 都需要细致的工程化实现, 才能达到预期的效果. 这节课将用很零散的方式讲一下<strong>用 Java 来开发存储系统时会用到的一些技巧及其背后的原理</strong>. 其中的每个知识点都是独立的, 可以挑自己感兴趣的部分学习.</p> <h5 id="pagecache调优和direct-io"><a href="#pagecache调优和direct-io" class="header-anchor">#</a> PageCache调优和Direct IO</h5> <p>我们一直会听到 PageCache, 简单理解它就是<strong>内存</strong>. 写内存性能肯定是最高的. 但是 PageCache 并不是万能的, 在某些情况下会存在命中率低, 导致读写性能不高的情况. 遇到这种情况, 就需要在业务上进行处理. 先来看下面这张图:</p> <p>​<img src="/img/586ac52baff5c8c9e6644da62d962f80-20240421231949-vkicciy.jpg" alt="">​</p> <p>如上图所示, <mark><strong>应用程序读取文件, 会经过应用缓存, PageCache, DISK(硬盘)三层. 即应用程序读取文件时, Linux 内核会把从硬盘中读取的文件页面缓存在内存一段时间, 这个文件缓存被称为 PageCache</strong></mark>.</p> <p><strong>缓存的核心逻辑是</strong>: 比如应用层要读 1KB 文件, 那么内核的<strong>预读算法</strong>则会以它认为<strong>更合适的大小</strong>进行预读 I/O, 比如 16-128KB. 当应用程序下次读数据的时候, 会先尝试读 PageCache, 如果数据在 PageCache 中, 就会直接返回; 如果数据不在 PageCache 中, 就会触发从硬盘读取数据, 效率就会变低.</p> <p>这种预读机制, 在顺序读的时候, 性能会很高, 因为已经预先加载了. 但是有以下三种情况, <strong>PageCache 无法起作用</strong>.</p> <ol><li><strong>使用 FIleChannel 读写时, 底层可能走 Direct IO, 不走页缓存</strong>.</li> <li><strong>在内存有限或者不够用的时候, 频繁换页, 导致缓存命中率低</strong>.</li> <li><strong>大量随机读的场景, 导致页缓存的数据无法命中</strong>.</li></ol> <p>为了解决上面这类 PageCache 无法起作用的场景, 有一种解决思路是: <strong>通过使用</strong> <strong>Direct IO 来模拟实现</strong> <strong>PageCahce</strong> <strong>的效果</strong>. 原先内核提供的 PageCache 的底层实现(比如数据加载, 缓存命中, 换页, 刷盘等)是由操作系统来控制的, 我们无法灵活控制, 因此导致在一些场景中无法满足要求.</p> <p>那么新的思路是: <strong>可以绕过操作系统, 直接使用通过自定义 Cache + Direct IO 来实现更细致, 自定义的管理内存, 命中和换页等操作, 从而针对业务场景来优化缓存策略, 从而实现比 PageCache 更好的效果</strong>. 从技术实现上看, 它和使用 C++ 管理内存编程是一样的效果.</p> <p>解决思路来看下图:</p> <p>​<img src="/img/d86190bb6cfe6f3c0ba882335b71b219-20240421231949-m91wo1m.jpg" alt="">​</p> <p>通过前面所学可以知道, NIO 中的 FileChannel 主要和 ByteBuffer 打交道, mmap 直接和缓存打交道, 而 Direct IO 直接和硬盘打交道. 即 <strong>Direct IO 是直接操作硬盘中的数据的, 不经过应用缓存和页缓存</strong>.</p> <p>那么这个思路的核心实现就是: <strong>通过自定义 Cache 管理, 缓存加载, 换页等行为, 让这些策略可以满足当前业务和场景的需求</strong>. 比如在随机读或者内存不够的场景下, 提高页缓存的命中率.</p> <p>在 Java 中, Direct IO 可以通过 JNA/JNI 调用 Native 方法实来实现. GitHub 上有封装好了 Java JNA 库, 实现了 Java 的 Direct IO, 直接就可以使用. 有兴趣的话可以去研究一下这个 GitHub 项目:  <a href="https://github.com/smacke/jaydio" target="_blank" rel="noopener noreferrer">https://github.com/smacke/jaydio<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h5 id="filechannel和mmap"><a href="#filechannel和mmap" class="header-anchor">#</a> FileChannel和mmap</h5> <p>Java 原生的 IO 主要可以分为<strong>普通 IO, FileChannel(文件通道), mmap(内存映射)</strong> 三种.</p> <p>其中, java.io 包中的 FileWriter 和 FileReader 属于普通 IO; java.nio 包中的 FileChannel 属于 NIO 的一种; mmap 是调用 FileChannel.map() 实例出来的一种特殊读写文件的方式, 被称为<strong>内存映射</strong>. 基于字节传输的传统 IO 基本很少用了, 当前主要使用 FileChannel 和 mmap.</p> <p>先来看一下 FileChannel, 它的基本使用方式如下:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">FileChannel</span> fileChannel <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">RandomAccessFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;test.data&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;rw&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 写数据</span>
<span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token keyword">long</span> position <span class="token operator">=</span> <span class="token number">10L</span><span class="token punctuation">;</span>
fileChannel<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token class-name">ByteBuffer</span><span class="token punctuation">.</span><span class="token function">wrap</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//当前位置写入数据</span>
fileChannel<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token class-name">ByteBuffer</span><span class="token punctuation">.</span><span class="token function">wrap</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> position<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//指定位置写入数据</span>

<span class="token comment">// 读数据</span>
<span class="token class-name">ByteBuffer</span> buffer <span class="token operator">=</span> <span class="token class-name">ByteBuffer</span><span class="token punctuation">.</span><span class="token function">allocate</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">long</span> position <span class="token operator">=</span> <span class="token number">10L</span><span class="token punctuation">;</span>
fileChannel<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 当前位置读取1024byte 的数据</span>
fileChannel<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buffer<span class="token punctuation">,</span>position<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 指定位置读取 1024byte 的数据</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>从技术上看, <strong>FileChannel 大多数时候是和 ByteBuffer 打交道的</strong>, 可以将 ByteBuffer 理解为一个 byte[] 的封装类. ByteBuffer 是在应用内存中的, 它和硬盘之间还隔着一层 PageCache.</p> <p>如下图所示, 即 FileChannel 写的时候经历了<strong>应用内存 -&gt; PageCache -&gt; 磁盘</strong>三个步骤.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2e4c7986069cb2f423bd02ce2ef640b6-20240421231949-i5pyb2z.jpg" alt="">​</p> <p>从使用上看, 通过 filechannel.write 写入数据时, 会将数据从应用内存写入到 PageCache, 此时便认为完成了落盘操作. 但实际上, 操作系统最终将 PageCache 的数据自动刷到了硬盘. 这也是 FileChannel 提供了一个 force() 方法来通知操作系统进行及时刷盘的原因.</p> <p>接着来看一下 mmap, 先看一下它的基本使用方式:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">MappedByteBuffer</span> mappedByteBuffer <span class="token operator">=</span> fileChannel<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">FileChannel<span class="token punctuation">.</span>MapMode</span><span class="token punctuation">.</span><span class="token constant">READ_WRITE</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> filechannel<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> position <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>

<span class="token comment">// 从当前位置写入1kb 的数据</span>
mappedByteBuffer<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 从指定位置写入1kb 的数据</span>
<span class="token class-name">MappedByteBuffer</span> subBuffer <span class="token operator">=</span> mappedByteBuffer<span class="token punctuation">.</span><span class="token function">slice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
subBuffer<span class="token punctuation">.</span><span class="token function">position</span><span class="token punctuation">(</span>position<span class="token punctuation">)</span><span class="token punctuation">;</span>
subBuffer<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p><strong>mmap 是一个把文件映射到内存的操作, 因此可以像读写内存一样读写文件. 它省去了用户空间到内核空间的数据复制过程, 从而提高了读写性能</strong>.</p> <p>如下图所示, <strong>mmap 的写入也是先把数据写入到 PageCache, 不是直接把数据写到硬盘中</strong>. 它的底层借助了内存来加速, 即 MappedByteBuffer 的 put 实际是对内存进行操作. 具体刷盘依赖操作系统定时刷盘或者手动调用 mappedByteBuffer.force() 刷盘.</p> <p>​<img src="/img/f4e05ebbfc34a7d38b0a9c4b332f39c0-20240421231949-dikrhvi.jpg" alt="">​</p> <p>从经验来看, mmap 在内存充足, 数据文件较小且相对固定的场景下, 性能比 FileChannel 高. <strong>但它有这样几个缺点</strong>:</p> <ol><li>使用时必须先<strong>指定好内存映射的大小</strong>, 并且一次 Map 的大小限制在 1.5G 左右.</li> <li><strong>是由操作系统来刷盘的</strong>, 手动刷盘时间不好掌握.</li> <li>回收非常复杂, 需要手动释放, 并且代码和实现很复杂.</li></ol> <p>实际使用中, 在消息队列数据文件分段的场景下, 因为每个段文件的大小是固定的, 且大小还是可配置的, 所以是可以使用 mmap 来提高性能的. 在 RocketMQ 的源码中, 可以看到 NIO 和 mmap 都有在使用, 但是主要的写是通过 mmap 来完成的.</p> <p>不过在大部分情况下, 我认为 FileChannel 完全可以胜任 IO 工作. 所以在写文件中, <strong>推荐优先考虑 FileChannel. 在一些数据量小, 内存充足的场景下, 再换成 mmap 来实现</strong>.</p> <h5 id="预分配文件-预初始化-池化"><a href="#预分配文件-预初始化-池化" class="header-anchor">#</a> 预分配文件,预初始化,池化</h5> <p>在提高文件写入性能的时候, <strong>预分配文件</strong>是一个简单实用的优化技巧. 比如前面讲过, 消息队列的数据文件都是需要分段的, 所以<strong>在创建分段文件的时候, 可以预先写入空数据(比如0)将文件预分配好</strong>. 当真正写入业务数据的时候, 速度就会快很多.</p> <p>下面是一个预分配文件的代码示例:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">allocate</span><span class="token punctuation">(</span><span class="token class-name">FileChannel</span> fileChannel<span class="token punctuation">,</span> <span class="token keyword">long</span> preFileSize<span class="token punctuation">)</span> <span class="token keyword">throw</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
    <span class="token keyword">int</span> bufferSize <span class="token operator">=</span> <span class="token number">1024</span><span class="token punctuation">;</span>
    <span class="token class-name">ByteBuffer</span> byteBuffer <span class="token operator">=</span> <span class="token class-name">ByteBuffer</span><span class="token punctuation">.</span><span class="token function">allocateDirect</span><span class="token punctuation">(</span>bufferSize<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> bufferSize<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        byteBuffer<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">byte</span><span class="token punctuation">)</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    byteBuffer<span class="token punctuation">.</span><span class="token function">flip</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">long</span> loop <span class="token operator">=</span> preFileSize <span class="token operator">/</span> bufferSize<span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">long</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> loop<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        fileChannel<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>byteBuffer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        byteBuffer<span class="token punctuation">.</span><span class="token function">flip</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    fileChannel<span class="token punctuation">.</span><span class="token function">force</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    fileChannel<span class="token punctuation">.</span><span class="token function">position</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>另外, 对一些需要重复用到的对象或者实例化成本较高的对象<strong>进行预初始化</strong>, 可以降低核心流程的资源开销.</p> <p>还一点就是<strong>对象池化</strong>, 对象池化是指只要是需要反复 new 出来的东西都可以池化, 以避免内存分配后再回收, 造成额外的开销. Netty 中的 Recycler, RingBuffer 中预先分配的对象都是按照这个池化的思路来实现的.</p> <h5 id="直接内存-堆外-和堆内内存"><a href="#直接内存-堆外-和堆内内存" class="header-anchor">#</a> 直接内存(堆外)和堆内内存</h5> <p>想必这个概念你已经很熟悉了. 如下图所示, <strong>堆内和堆外的堆是指 JVM 堆, 堆内内存就是指 JVM 堆内部的内存空间, 堆外就是指除了 JVM 堆以外的内存空间</strong>. 堆内内存加上堆外内存等于总内存.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4a3c99e3f26992da898eac1788b9a88f-20240421231949-lsql9vk.jpg" alt=""></p> <p>虽然概念熟悉, 但你知道什么时候使用堆内内存, 什么时候使用堆外内存吗?</p> <p><strong>关于堆内内存和堆外内存的选择, 有下面五点建议</strong>:</p> <ol><li>当需要<strong>申请大块的内存</strong>时, 堆内内存会受到限制, 可以尝试<strong>分配堆外内存</strong>.</li> <li><strong>堆外内存适用于生命周期中等或较长的对象</strong>.</li> <li><strong>堆内内存刷盘的过程中, 还需要复制一份到堆外内存, 多了一步, 会降低性能</strong>.</li> <li>创建堆外内存的消耗要大于创建堆内内存的消耗, 所以<strong>当分配了堆外内存之后, 要尽可能复用它</strong>.</li> <li>可以使用池化 + 堆外内存的组合方式. 比如代码中如果需要频繁 new byte[], 就可以研究一下 <code>ThreadLocal&lt;ByteBuffer&gt;</code>​ 和 <code>ThreadLocal&lt;byte[]&gt;</code>​ 的使用机制.</li></ol> <p>如果用 Java 写存储系统(比如消息队列), 会建议尽量优先考虑是否可以用堆外内存.</p> <h5 id="同步刷盘"><a href="#同步刷盘" class="header-anchor">#</a> 同步刷盘</h5> <p>不管是在使用 NIO 还是 mmap, 都是需要先操作缓存, 然后依赖操作系统去刷盘或者手动刷盘. 如果依赖操作系统刷盘, 在一些极端场景可能会出现数据丢失. 而如果每次写入都强制刷盘, 就会导致性能下降厉害.</p> <p>所以之前讲过, 多数消息队列会提供<strong>同步刷盘和异步刷盘</strong>两种机制给用户选择, 用户可以根据不同场景来选择不同的策略. 这种方案是把数据的可靠性选择交给用户, 如果为了更高的性能, 那就选择异步刷盘, 如果选择可靠性, 就同步刷盘, 接受性能下降.</p> <p>那<strong>有办法提高同步刷盘的性能吗</strong>? 你的直觉是不是只能通过更高性能的硬盘, 比如 SSD, NVMe, 或者 AEP 这种性能更高的存储介质了. 除了存储介质外, 有没有其他的解法呢?</p> <p>从应用程序的角度来看, 可以通过<strong>批量同步刷盘</strong>的操作来提高性能. 批量同步刷盘的核心思路是: <strong>每次刷盘尽量刷更多的数据到硬盘上</strong>. 技术上是指通过<strong>收集多线程写过来的数据</strong>, 汇总起来批量同步刷到硬盘中, 从而提高数据同步刷盘的性能.</p> <p>来看一下具体的实现思路, 来看下图:</p> <p>​<img src="/img/f22cf752b7a1876f42813dc5b58902b7-20240421231949-t13sj72.jpg" alt="">​</p> <p>业务线程 T1 到 T6 的数据通过内存将数据发送给 IO 线程. 然后业务线程进入 await 状态, 当 IO Thread 收集到一定的数据后, 再一起将数据同步刷到硬盘中. 最后唤醒 T1到 T6线程, 返回写入成功.</p> <p><strong>这个方案和</strong> <strong>PageCache</strong> <strong>写入的最大区别在于</strong>: fileChannel.write() 只要写 PageCache 成功就会直接返回, 后续的刷盘动作交给操作系统去执行, 在客户端看来数据已经写入成功了, 但是底层却没有写入成功. 而新方案中写入线程是可以感知到刷盘的结果的, 当同步刷盘失败, 则 IO 线程会通知业务线程写入失败, 业务线程就会进行重试或给客户端返回失败.</p> <p>基础篇的网络模块中讲过, 在消息队列系统中, 客户端都是由<strong>多个生产者</strong>写入的, 服务端会通过 React 模型配合后端 Process 线程池来处理请求. 此时 Broker 接收到数据后, 会分发给多个 Process 线程处理, 当 Process 线程处理完数据后, 如果需要同步刷盘, 就可以使用上面这种优化方案来提高性能.</p> <p>另外, 在主流的消息队列中, 为了避免同步刷盘, 常用的方案是 <strong>通过多副本机制来实现数据的高可靠</strong>. 如下图所示, <strong>数据会写入到多个副本中, 每个副本只写入到本节点的 PageCache, 然后就返回成功</strong>. 因为多台节点同时挂掉的概率很低, 所以消息丢失的概率也就很低了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/270e2464868e6cb0a10cacdf2d1820ba-20240421231949-x2kmzxp.jpg" alt=""></p> <h5 id="新的存储aep"><a href="#新的存储aep" class="header-anchor">#</a> 新的存储AEP</h5> <p>来看看什么是 AEP, 这部分相当于一个科普. 在选用硬盘的时候, 经常会听到 SSD, SATA, NVMe 等存储介质. 因为在传统存储系统中, 通常采用机械盘或 SSD 作为后端存储系统的缓存.</p> <p>随着存储技术的发展, Intel 推出了基于 3D Xpoint 技术的新型存储介质傲腾内存(AEP). 相比普通内存, AEP 拥有有大容量, 非易失的特点, 相当于<strong>大容量的持久化的内存</strong>.</p> <p>从使用上看, 由于它的使用方式和普通内存不一样, 并且成本较高, 导致它没有被大规模应用. 但是作为一个存储介质, 它的优点就是快, <strong>速度比</strong> <strong>SSD 快出 1~n 个数量级</strong>. 所以在一些追求极限性能的场景中, 比如某些金融级的消息队列, 此时应用程序已经无法再提升性能了, 就得依靠更好的<strong>硬件来提高性能</strong>, 这时候就可以选择 AEP 作为存储介质.</p> <h5 id="线程绑核"><a href="#线程绑核" class="header-anchor">#</a> 线程绑核</h5> <p>在消息队列的进程中, 负责各种功能的线程很多, 比如处理请求, 处理 IO, 清理数据等等, 此时就会有 CPU 争用和线程切换的情况. 频繁的线程切换会导致性能下降, 而 IO 线程占用的资源和时间较多, 切换成本较高.</p> <p>所以在一些追求性能和隔离性的场景中, 可以通过<strong>线程绑核</strong>的操作来实现更好的性能. 比如在一些重 IO 的操作中, 留几个核心专门给 IO 线程使用, 这样就可以完全避免 IO 线程的时间片争用.</p> <p>在 Java 中实现绑核操作, 可以通过这个项目来实现: <a href="https://github.com/OpenHFT/Java-Thread-Affinity" target="_blank" rel="noopener noreferrer">https://github.com/OpenHFT/Java-Thread-Affinity<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>使用的代码 demo 如下所示:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// lock one of the last CPUs</span>
<span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token class-name">AffinityLock</span> lock <span class="token operator">=</span> <span class="token class-name">AffinityLock</span><span class="token punctuation">.</span><span class="token function">acquireLockLastMinus</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h5 id="ssd的4kb对齐"><a href="#ssd的4kb对齐" class="header-anchor">#</a> SSD的4KB对齐</h5> <p><strong>SSD 4KB 对齐指的将 SSD 盘的物理扇区和逻辑扇区对齐, 从而提高 SSD 盘读写性能的一种技巧</strong>, 是 SSD 盘经典的优化技巧.</p> <p><strong>底层大致的原理是</strong>: 如果读取一次数据, 要跨多个物理扇区, 那么性能就会下降; 如果每次读取刚刚好是读一个物理扇区的数据, 那么性能就会很高. 我在网上找了两张图来说明一下效果.</p> <p>如果读取的刚好是一个物理扇区, 那么就不需要跨物理扇区读, 读取性能就会更高. 当然, 这块的细节很多, 如果有兴趣的话可以深入去研究下, 这里只是知道有这么个东西.</p> <p>基于这个理论, 在使用 SSD 的时候, 如果追求性能, 并且场景合适, 可以使用这个技巧来提高性能. 但是在实际系统中, 特别是在消息系统, 因为用户的消息的大小是动态变化的, 消息基本不可能是 4KB 的整数倍. 所以如果强制要求 4KB 对齐, 就需要进行空数据填充, 当消息量多的时候, 填充行为可能会导致额外的硬盘空间浪费.</p> <h5 id="其他一些优化手段"><a href="#其他一些优化手段" class="header-anchor">#</a> 其他一些优化手段</h5> <p>接下来继续分享几个常用的优化手段.</p> <h6 id="jvm调优"><a href="#jvm调优" class="header-anchor">#</a> JVM调优</h6> <p>从结果来看, <strong>JVM 调优是提高性能的一个重要操作</strong>. 在消息系统中, 需要尽量<strong>降低 GC 的次数, 避免 Full GC 和 STW 等</strong>. 实际操作中, 可以通过<strong>调整年轻代堆的大小, 比例以及选择合适的垃圾回收算法等方式来优化</strong>. 这里就不展开了, 这块的资料非常丰富.</p> <h6 id="减少线程切换"><a href="#减少线程切换" class="header-anchor">#</a> 减少线程切换</h6> <p>大家经常听到进程, 线程, 协程这几个概念. 从切换成本来看, 进程最高, 协程最低. 目前主流 Java 版本不支持协程, 最新的 JDK 19 才开始支持协程. 所以当前用得最多的就是<strong>线程</strong>.</p> <p>在一些追求高性能的场景中, 线程切换也会影响性能. 所以在实际的开发中, 需要<strong>关注线程切换的次数</strong>. 为了减少线程切换的次数, 一般有这样几个建议:</p> <ol><li>减少锁的持有时间.</li> <li><strong>降低锁的粒度, 锁分离, 锁分段</strong>.</li> <li><strong>乐观锁代替竞争锁</strong>, CAS 代替 Synchronized.</li> <li>Condition await 替换 Object wait, Condition signal 替换 Object notify, Condition signalAll 替换 Object notifyAll, 整体上解决提前唤醒和无法做到区分唤醒的问题.</li> <li><strong>合理地设置线程池中的线程数</strong>.</li></ol> <h6 id="unsafe"><a href="#unsafe" class="header-anchor">#</a> Unsafe</h6> <p>sun.misc.Unsafe 是 JDK 提供的原生工具类, 它可以在 Java 中实现内存分配与回收, CAS, 类实例化, 内存屏障等等操作. 跟 C/C++一样, 它可以在 Java 中直接操作内存, 执行底层系统调用.</p> <p>它的好处就是灵活, 像 C++ 一样使用 Java. 缺点就是 Unsafe 是一个不安全的操作, 在 JDK 8 中可以使用, 但是从 JDK 9 开始非标准库的模块都无法访问到它了.</p> <p>在存储系统开发中, 在某些场景下, 如果需要更细致地操作内存, 就可以考虑它.</p> <h6 id="其他知识点"><a href="#其他知识点" class="header-anchor">#</a> 其他知识点</h6> <ol><li>顺序读比随机读快, 顺序写比随机写快.</li> <li>合并写入比单独写入快.</li> <li>在某些场景下, 比如数据的集合长度是固定的时候, 可以考虑数组替代或者重写 Map, 用来降低 HashMap 的 overheap.</li> <li>文件分段.</li></ol> <h5 id="总结-18"><a href="#总结-18" class="header-anchor">#</a> 总结</h5> <p>这节课总结了一些用 Java 开发存储系统时经常会用到的技巧. 在我的经验中, 我认为在大的设计框架差别不大的情况下, <strong>性能差异很多就是因为这些不起眼的细节</strong>. 这节课主要讲的是 IO 相关的优化操作, 主要是因为消息队列本身就是一个重 IO 的存储系统, IO 模块的性能提升是整个系统性能提升的关键.</p> <p>Java IO 性能核心还是缓存, 批量写和异步刷盘. 从使用的角度, 基本只要关注 FileChannel, mmap 即可. 在一些极限场景下, 可以关注一下 Direct IO 的使用. 同步刷盘并不是噩梦, 可以通过一些代码上的优化, 来提高同步刷盘的能力.</p> <p>在某些场景, 预分配文件和初始化一些资源可以带来意料之外的性能提升. 在内存的使用上, 建议多关注一下对外内存的使用. 新的硬盘介质, 线程绑核, 4KB 对齐, 减少线程切换, Unsafe 的使用等等这些技巧, 最好也都了解下, 有一个全局的视角, 在某些场景下都会用到.</p> <h4 id="_19-安全-身份认证-资源鉴权和加密传输都是怎么实现的"><a href="#_19-安全-身份认证-资源鉴权和加密传输都是怎么实现的" class="header-anchor">#</a> 19-安全:身份认证,资源鉴权和加密传输都是怎么实现的?</h4> <p>近几年业界的安全问题频繁发生, 系统数据的安全性也越来越受到重视. 作为消息队列的主要使用者, 我经常有这么一个疑问: <strong>消息队列是如何保证数据安全的</strong>? 想必你在使用消息队列产品的时候, 应该也有同样的疑问.</p> <p>在我看来, 从消息队列架构全流程拆解的角度, 消息队列的系统安全由六部分组成: <strong>网络隔离</strong>, <strong>传输安全</strong>, <strong>集群认证</strong>, <strong>资源授权</strong>, <strong>自我保护</strong>, <strong>数据加密</strong>.</p> <p>​<img src="/img/4b04f9604ff1393efcc414604d5e92e0-20240421231949-ct79j3j.jpg" alt="">​</p> <p>今天先来聊一聊网络隔离, 传输安全, 集群认证, 资源授权四个部分, 整体了解一下集群的安全控制, 思考如何在传输过程, 访问控制两方面保证数据安全. 下一节再讲自我保护和数据加密.</p> <h5 id="网络隔离的安全性"><a href="#网络隔离的安全性" class="header-anchor">#</a> 网络隔离的安全性</h5> <p>关于网络隔离, 你可能听过一个观点: 不管是什么系统, 从安全的角度来看, 最完美的保护就是<strong>网络隔离</strong>. 这很好理解, 一个完全隔离封闭的网络, 是不会存在网络安全问题的, 因为别人根本无法访问它.</p> <p>在云服务中, 虚拟网络(VPC)就是一个独立的子网. 如果不做对外打通(比如开通公网, 跟其他网络拉专线), 它的数据在这个网络内就是安全的.</p> <blockquote><p>虚拟网络只是独立网络的一种叫法, 你的公司可能有内网的概念, 它就是独立网络的一种.</p></blockquote> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0420ce7a5b1f9d7e78e6f665110697c5-20240421231949-lan5yiv.jpg" alt=""></p> <p>但是, 在实际工业环境中, 除非是一些特殊的银行, 国企机构的私有云环境会有完整的网络隔离, 大部分情况下, 系统是需要和外部服务进行交互的. 比如外网或者其他子网的服务需要访问消息队列, 或者内网应用需要外网的某些服务, 此时就需要进行打通, 网络隔离就无法起作用了.</p> <p>在网络必须打通的情况下, 如果你对安全的要求不是特别高, 按默认的方式使用消息队列就可以了, 因为<strong>几乎所有的消息队列默认都是不开启认证鉴权的, 比如 Kafka, RocketMQ, Pulsar, RabbitMQ 默认都可以直接访问的</strong>.</p> <p>如果内网中的各个服务需要进行访问控制, 比如支付团队的机密数据是不能让其他团队访问到的, 就需要后续认证和鉴权机制的存在, 稍后会讲到.</p> <h5 id="数据传输过程加密"><a href="#数据传输过程加密" class="header-anchor">#</a> 数据传输过程加密</h5> <p>应用必须访问外界服务, 也必定存在公网的数据传输. 为了防止数据在传输过程中不被窃取, 改变, 确保数据的完整性, 需要对传输过程中的<strong>数据进行加密</strong>.</p> <p>从技术的角度来看, 数据传输安全的核心是 SSL/TLS, 可以简单理解成, 如果要保证传输过程中的数据安全, 就要用 SSL/TLS. 消息队列也是这个逻辑, <strong>几乎所有的消息队列产品,</strong> <strong>传输过程中的加密机制都是基于 SSL/TLS 实现的</strong>, 可以在它们的官方文档找到相应的资料, 比如支持 TLS 的 <a href="https://pulsar.apache.org/docs/2.11.x/security-tls-transport/" target="_blank" rel="noopener noreferrer">Pulsar<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 或者 <a href="https://www.rabbitmq.com/ssl.html" target="_blank" rel="noopener noreferrer">RabbitMQ<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 支持 <a href="https://kafka.apache.org/documentation/#security_ssl" target="_blank" rel="noopener noreferrer">SSL 的 Kafka<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>那你可能会疑问了, SSL/TLS 是什么意思? 有什么区别吗? 为什么不同的 MQ 支持不同?</p> <p>简单理解, <strong>SSL 和 TLS 是同一个东西</strong>. SSL 3.0 及之前的版本叫 SSL, 3.0 之后叫做 TLS, TLS 是 SSL 的升级版.</p> <p>所以你会发现, 有些消息队列官网说支持 SSL, 有些支持 TLS, 一部分原因是各个产品安全模块开发的时间不一样, 所以支持的 SSL 协议版本不一样, 比如 TLS 1.3 是 2018 年才发表的. 但从应用角度看, 它俩的区别并不大, 比如证书制作步骤, 代码库的调用方法都差不多.</p> <p>前面讲过, 大部分消息队列为了保证延时和吞吐, 都是基于四层的 TCP 协议构建的, 所以在<strong>加密传输的实现上都是 TCP + SSL/TLS</strong>. 另外在七层的加密传输中, HTTPS 是我们最熟悉的一种, 它的底层机制是基于 HTTP + SSL 实现的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4de70a2b7cda9c3c0b374bf62d2873b1-20240421231949-ax43x5y.jpg" alt=""></p> <p>从技术上看, 传输加密由两部分组成, <strong>服务端代码开启支持 SSL 和客户端配置 SSL 访问</strong>.</p> <p>服务端开启 SSL 分为两步, 首先需要制作 SSL 证书(<a href="https://kafka.apache.org/documentation/#security_ssl_ca" target="_blank" rel="noopener noreferrer">证书制作参考<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>), 然后使用<strong>对应语言的 SSL 库在服务端支持 SSL 协议</strong>, 比如使用 Java Netty 开发支持 SSL 的 Server(<a href="https://netty.io/4.0/api/io/netty/handler/ssl/SslHandler.html" target="_blank" rel="noopener noreferrer">Java Netty 集成 SSL 参考<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>).</p> <p>客户端连接时, 通过<strong>消息队列 SDK 集成的 SSL 功能, 携带对应的公钥和证书信息, 与服务端进行通信</strong>(<a href="https://netty.io/4.0/api/io/netty/handler/ssl/SslHandler.html" target="_blank" rel="noopener noreferrer">Java Netty 客户端集成 SSL 参考<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>).</p> <h5 id="连接建立时的身份认证"><a href="#连接建立时的身份认证" class="header-anchor">#</a> 连接建立时的身份认证</h5> <p>加密传输, 只能解决数据在网络传输过程中的安全性, 此时消息队列集群资源还处于一个门户大开的状态, 只要网络能通, 集群就能被直接连接访问. 为了解决这个问题, 就需要<strong>开启集群认证</strong>.</p> <p><strong>集群认证,</strong> <strong>通俗解释就是消息队列中的登录功能</strong>. 前面提到, 默认情况下消息队列是不开启认证的, 需要时可以通过配置开启认证. 认证是客户端连接服务端的第一道门槛, 主要是解决客户端连接到服务端时, 是否允许建立连接的问题.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/efd3d49cd52c14dfe9330c885c018808-20240421231949-g5vu90b.jpg" alt=""></p> <p>抽象来看, <strong>认证就是客户端携带认证信息(比如用户名+密码, Token, Auth 等)连接上服务端. 服务端首先会判断当前开启或配置的认证类型, 然后校验这些信息, 如果通过, 就允许建立连接, 否则, 就返回认证错误</strong>.</p> <p>不过, 消息队列的身份认证真的这么简单吗? 为什么你看到的消息队列的身份认证看起来那么复杂呢? 可能有好多概念, 比如 SASL, OAuth, SCRAM, PLAINTEXT, Keberos, MTLS, JWT 等等.</p> <p>要了解这些, 需要先来看一下身份认证的原始需求是什么, 它其实包含两个方面: <strong>完成身份认证</strong>, <strong>支持多种认证方式</strong>.</p> <p>所以从代码实现上来看, 为了支持多种认证方式, 一般会包含<strong>认证框架和具体认证实现</strong>两部分. 认证框架负责制定认证的规则和实现机制, 多种具体的认证机制就基于框架制定的规则和机制来实现不同的认证方式.</p> <h6 id="框架和实现"><a href="#框架和实现" class="header-anchor">#</a> 框架和实现</h6> <p>最简单的认证框架, 可以是一个 Java 的接口定义. 具体代码也很简单, 先定义一个接口 <strong>AuthenticationProvider</strong>, 接口中包含了 authenticate 方法, 只要实现了这个接口的类都是认证实现类, 都可以执行认证操作.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">AuthenticationProvider</span> <span class="token keyword">extends</span> <span class="token class-name">Closeable</span> <span class="token punctuation">{</span>
  <span class="token annotation punctuation">@Deprecated</span>
  <span class="token keyword">default</span> <span class="token class-name">String</span> <span class="token function">authenticate</span><span class="token punctuation">(</span><span class="token class-name">AuthenticationDataSource</span> authData<span class="token punctuation">)</span>
  <span class="token keyword">throws</span> <span class="token class-name">AuthenticationException</span> <span class="token punctuation">{</span>
	 <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">AuthenticationException</span><span class="token punctuation">(</span><span class="token string">&quot;Not supported&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>顺着这个思路, 来看看当前主流的消息队列支持的认证方式, 分析一下实现思路上是否是类似的.</p> <h6 id="身份认证框架"><a href="#身份认证框架" class="header-anchor">#</a> 身份认证框架</h6> <p>先来看一下各个<strong>主流消息队列和认证方式</strong>, 我整理成了表格, 看起来包含了好多专业术语, 别担心, 其实不复杂, 当拆解了这些术语的含义, 会发现跟我们平时使用用户名密码登录后台系统没什么区别.</p> <p>​<img src="/img/10af4f5fb6968a731f1931c58fe23699-20240421231949-yg029oy.jpg" alt="">​</p> <p>先来看 Kafka, Kafka 的每种认证方式上都包含了 SASL, 那什么是 SASL 呢?</p> <p>SASL 的全称是 Simple Authentication and Security Layer, 翻译过来就是 <strong>简单身份验证和安全层</strong>, 可以把它理解为一个框架, 在这个框架上扩展各种身份验证提供程序就可以了.</p> <p>所以, Kafka 在开发的时候引入了 SASL, 然后基于 SASL 实现各种认证插件, 比如 GSSAPI, PLAIN, SCRAM, OAUTH 等等, 程序上就可以顺利集成各种认证机制了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/345dd5e7d0c7bdae548d47387dayy652-20240421231949-4kt85ec.jpg" alt=""></p> <p>所以 Kafka 从源码上看就是基于 SASL 框架去实现各种认证机制的. Java Sever 集成 SASL 的实现可以参考 <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/sasl/sasl-refguide.html" target="_blank" rel="noopener noreferrer">Oracle 官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>RabbitMQ 的实现机制和 Pulsar 类似. 都是在内核提供了一个自定义实现的, <strong>可插入的身份验证框架</strong>, 基于认证接口实现各种认证机制, 并在配置文件中指定要启用的认证插件和参数, 然后开启认证的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/5056c87fe6b1ba4341baf8200467c95b-20240421231949-2q0l6z5.jpg" alt=""></p> <p><strong>Kafka 和 Pulsar</strong> <strong>/ RabbitMQ</strong> <strong>最大的区别在于认证框架的选择</strong>. SASL 框架的机制更完善, 基于 SASL 需要遵循编码规范和机制, 相对复杂, 同时功能也相对较强, 这是可预期的.</p> <p>但是从消息队列的角度来看, 一般自定义的身份认证框架基本可以满足认证需求. 而且基于自定义的机制, 实现起来会比较简单, 编码成本较低. 所以, 从我的角度来看, 自定义的身份认证框架就够了.</p> <h6 id="身份认证实现"><a href="#身份认证实现" class="header-anchor">#</a> 身份认证实现</h6> <p>有了认证框架, 那怎样<strong>实现身份认证</strong>呢?</p> <p>最简单的认证实现就是<strong>用户名+密码</strong>, 把用户名和密码传递给服务端进行比对. 不过为了安全性和各个场景下都能方便认证, 业界提供了非常多种的认证机制, 比如 <strong>OAuth, Token, Kerberos, PLAINTEXT</strong> 等等.</p> <p>下面介绍几种主流的认证机制, 虽然具体实现方式不一样, 但宏观思路基本是一致的.</p> <blockquote><p>用户名+密码的机制</p></blockquote> <p>Kafka 的 PLAIN, SCRAM, RabbitMQ 的 PLAIN, AMQPPLAIN, RocketMQ 的 AccessKey 和 SecretKey 都属于这类, <strong>用户名+密码</strong>完成身份认证, 区别在于底层的实现不一样.</p> <p>比如 Kafka 的 PLAIN, 是把用户账户文件配置到一个静态文件中, 每次想要添加新的账户, 都需要重启 Kafka 去加载静态文件, 才能使之生效, 十分不方便. SCRAM 就在这个基础上升级, 将用户名和密码存在了 ZooKeeper 上, 可动态变更用户名和密码. 以此类推.</p> <blockquote><p>Kerberos</p></blockquote> <p>Kerberos 是一种计算机网络授权协议, 用来在非安全网络中对个人通信进行身份认证, 属于一种标准的授权协议. 很多组件中都会支持它, 所以在很多消息队列产品或者大数据产品的认证模块中都会经常看到.</p> <p>使用 Kerberos 的时候, 一般需要先配置一个 Kerberos 配置中心, 然后消息队列配置上配置中心的相关信息, 收到客户端的验证请求的时候, 通过 Kerberos 配置中心完成认证.</p> <blockquote><p>OAuth 认证</p></blockquote> <p>你应该非常熟悉, 在 Web 开发中用得很多. 它的授权过程简单理解就是<strong>获取令牌(Token)的过程</strong>. 它<strong>允许用户以 Token 的形式, 授权第三方应用访问他们存储在另外服务提供者上的信息</strong>.</p> <p>其他的比如 JWT, 原始 Token 授权, mTLS 等等, 原理是类似的, 区别是不同厂商推出的满足不同特定的场景下的认证机制.</p> <h5 id="集群资源的访问控制"><a href="#集群资源的访问控制" class="header-anchor">#</a> 集群资源的访问控制</h5> <p>身份认证解决的是 &quot;是否允许连接建立&quot;, 回答 &quot;你是谁&quot; 的问题. 那<strong>建立连接后是否就能访问所有的资源</strong>了呢? 答案肯定是不行的. 因为在很多场景下, 比如一个公司规模不大的时候, 整个公司会共用一套集群. 此时如果一些部门的数据不能让其他部门看到, 身份认证就不能满足需求了.</p> <p>此时就需要<strong>访问控制机制</strong>起作用了.</p> <h6 id="数据类和资源类操作控制"><a href="#数据类和资源类操作控制" class="header-anchor">#</a> 数据类和资源类操作控制</h6> <p>如果你运营过消息队列的集群, 应该知道集群有两类操作, 一种是集群资源类的操作, 比如主题和用户信息的创建删除, 限流配额信息的配置. 一种是数据资源类的操作, 比如生产消费某个数据.</p> <p>集群资源类的操作属于运维类操作, 一般需要运维部门人员来管理. 数据资源类的操作一般是研发人员在使用. 因为职能不同, 比如研发一般是不允许执行集群的配置变更的. <strong>所以这两类操作是需要隔离的</strong>.</p> <p>这两类资源的访问控制, 在实现上有两种思路.</p> <ul><li><strong>独立两条链路</strong>, 比如数据操作(生产和消费)使用 TCP 链路, 集群资源的操作使用 HTTP 链路.</li> <li><strong>同一条链路上实现两种操作</strong>, 数据操作和集群资源操作在同一条 TCP 或 HTTP 链路上完成, 然后通过接口或资源类型维度的鉴权来实现管控.</li></ul> <p>先看两条链路的方案. 业务方主要访问数据链路, 运维方主要访问资源链路. 它的好处是资源类操作和数据类操作分开, 从而在内核层面对鉴权控制实现的成本更低, 编码量更少. 在集群的交付和运营层面, 无需额外配置访问权限, 配置维护成本较低. Pulsar 和 RabbitMQ 用的就是这种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d358b60318f67a7bfae817f7872f09d9-20240421231949-wkf36sd.jpg" alt=""></p> <p>另一种单条链路的方案, 在一条链路上完成所有的操作, 无需在内核中开启两个 Server. 坏处就是需要额外设计多个维度(比如集群, 主题, 配置相关)的权限控制, 内核的编码量较多, 而且在集群运维时的配置成本也较高. 业界的 Kafka, RocketMQ 用的就是这种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/718e84d7c912a139a1f961fc1faae706-20240421231949-ygicxv8.jpg" alt=""></p> <p>两种不同选择的主要原因主要和当时研发人员的选择有关. 从个人的角度, 比较建议第一种两条链路的方案. 因为从内核实现和运维配置的角度来看, 开发和配置的成本会低很多.</p> <h6 id="访问控制机制acl"><a href="#访问控制机制acl" class="header-anchor">#</a> 访问控制机制ACL</h6> <p>即使完成了数据和资源链路的独立, 在数据链路内还是会包含<strong>生产, 消费两个行为</strong>, 另外可能有幂等, 事务等特性, 在资源链路里面也会有资源的增删改查等操作. 在一些情况下, 需要对这些操作做更细粒度的控制, 这时候就需要<strong>访问控制技术(ACL)</strong> 登场了.</p> <p>如果你用过任何一款消息队列, 肯定会听过 ACL. ACL 全称是访问控制机制, 简单来说, 就是解决 &quot;<strong>某个资源能不能被访问, 能被谁访问</strong>&quot; 的问题. 因此 ACL 包含两部分: <strong>一是定义好哪些行为和资源需要进行鉴权, 二是如何实现鉴权</strong>.</p> <p><strong>从被访问主体的角度(即哪些行为和资源需要鉴权), 一般分为三类</strong>.</p> <ul><li><strong>资源</strong>: 主要对主题/ Queue, 消费分组/订阅, 集群三类资源做访问控制. 另外一些消息队列独有的概念也会有需要做访问控制, 比如 RabbitMQ 的 Exchange.</li> <li><strong>操作</strong>: 主要分为读, 写, 创建, 删除, 修改, 配置等, 比如允许生产消费数据, 允许创建删除修改 Topic, 允许修改集群配置.</li> <li><strong>接口</strong>: 一般会限制对集群接口的访问, 比如限制某些用户不能访问某些接口.</li></ul> <p><strong>从访问控制主体的角度(即如何实现鉴权), 一般需要包含用户和 IP 两个维度</strong>.</p> <ul><li>用户维度就是指控制某个用户的访问权限.</li> <li>IP 维度是指这个资源只能从某个或某些 IP 发起访问.</li></ul> <p>用户和 IP 的控制一般可以叠加使用, 限制某些用户只能从某些 IP 发起访问.</p> <p>上面两个方面, 基本可以在主流消息队列产品中对号入座, 找到相应的实现. 以 Kafka, RabbitMQ 具体看看主流消息队列的访问控制粒度.</p> <p>Kafka 在权限控制做得比较精细. 从资源和 API 两个维度做了访问控制. 资源主要分为主题, 消费分组, 集群三个维度, 几乎涉及所有主要的 API, 控制操作包括读, 写, 创建, 删除, 修改, 描述等等.</p> <p>​<img src="/img/a6d646a3291584723f52dc80a297b515-20240421231949-vzigjg2.png" alt="">​</p> <p>它做这么精细的一部分原因在于, 它是在一条链路上实现数据和资源两类操作的, 为了保证安全性, 需要做更精细的管控.</p> <p>再来看一下使用两条链路方案的 RabbitMQ, RabbitMQ 主要对 Exchange, Queue, 生产, 订阅等维度做了控制, 控制操作包括读, 写, configure(资源的定义创建删除等).</p> <p>​<img src="/img/ccd2476ba9786274263432ab04895a90-20240421231949-2phunrg.png" alt="">​</p> <p>它没有做接口维度的控制, 主要原因在于 RabbitMQ 的集群配置主要通过 HTTP API 完成. 另外它的维度比 Kafka 少一些, 因为 RabbitMQ 的架构更简单, 所以接口和功能都更少.</p> <p><strong>那访问控制机制具体如何实现呢</strong>?</p> <p>其实非常简单, 在实现上就一个函数的工作量, 流程分为两步.</p> <ol><li>请求接入的时候, 获取到当前连接的用户信息或者 IP 信息.</li> <li>在请求处理的开始, 调用访问控制的实现函数(比如 authorizeByResourceType), 传入当前访问的操作(比如生产, 消费, 配置)以及用户或 IP 信息, 和内存中的授权数据比较, 返回是否具有权限.</li></ol> <p>虽然鉴权的实现逻辑比较简单, 但在具体编码实现上, <strong>消息队列一般都会支持一个可插拔的鉴权机制</strong>, 即可以通过配置自定义的鉴权类来实现自定义的鉴权.</p> <p>比如 Kafka 的鉴权配置就是可插拔的, 通过配置 <code>authorizer.class.name</code>​ 的参数, 来制定 ACL 的鉴权规则. 它的实现就是定义接口, 然后实现接口的检验函数来完成校验.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>authorizer.class.name=kafka.security.authorizer.AclAuthorizer
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h6 id="超级用户"><a href="#超级用户" class="header-anchor">#</a> 超级用户</h6> <p>访问控制中还有一个非常必要的角色--超级用户.</p> <p>在系统中有一个默认的超级用户, 是非常必要的. 如果没有超级用户, 一旦分配出去的用户被不小心或者恶意修改, 系统就无法恢复访问了, 超级用户的存在可以很好地避免这个问题. 另外, 在系统运维过程中, 超级用户会带来很多管理上的便利, 比如运维负责人的临时, 紧急状态的操作.</p> <p>超级用户的配置一般是写死固定在配置文件当中的, <strong>不能被修改和删除</strong>. 在内核中会读取超级用户信息, 然后在访问控制的时候, 对是否是超级用户进行单独判断. Kafka 就有这个机制, 而 RabbitMQ 没有, 导致 RabbitMQ 在日常运营过程中总会不时遇到用户密码被改动的情况, 需要特殊处理恢复访问, 运营很不方便也不安全.</p> <h5 id="总结-19"><a href="#总结-19" class="header-anchor">#</a> 总结</h5> <p>消息队列的安全性主要由四部分组成, 分别是: <strong>网络间的隔离(网络隔离), 传输过程中的安全性(传输安全), 连接建立时的身份认证(集群认证), 连接建立后的访问控制(资源授权)</strong> . 只要做好这四个方面, 基本能够解决大部分的安全问题.</p> <p>传输加密是可选的, 它主要用在公网环境中. 因为私有网络的安全性较高, 一般不会发生数据窃取, 修改等问题, 所以在私有网络中使用的意义不是特别大. 加密传输的缺点是会消耗较多资源, 并且性能会有一定的下降.</p> <p>业界的身份认证机制非常多样, 它们在安全性上有细微的差别, 比如安全性的强弱. 但是基本所有的认证机制都可以满足需求, 根据适合自己的需要来选就可以了.</p> <p>访问控制 ACL, 从技术实现上来看并不是很复杂的, 它的核心是定义好哪些行为和资源需要进行鉴权, 从而保证系统各个环节的安全性.</p> <h5 id="思考题-16"><a href="#思考题-16" class="header-anchor">#</a> 思考题</h5> <blockquote><p>从做一个 Web 后台管理系统的角度来看, 传输加密, 认证, 鉴权分别对应系统中的什么呢?</p></blockquote> <p>传输加密对应的是 Web 页面的 HTTPS 访问. 认证对应的是系统登录时的用户名和密码校验. 鉴权对应的是后台系统中的权限分配, 即 A 用户可以访问菜单 1, B 用户可以访问菜单 2.</p> <h4 id="_20-安全-如何设计高吞吐和大流量分布式集群的限流方案"><a href="#_20-安全-如何设计高吞吐和大流量分布式集群的限流方案" class="header-anchor">#</a> 20-安全:如何设计高吞吐和大流量分布式集群的限流方案?</h4> <p>上节课讲了网络隔离, 传输加密, 认证, 鉴权, 今天继续讲消息队列系统安全的第二部分: <strong>数据自我保护和服务自我保护</strong>.</p> <p>​<img src="/img/05ececaa48cd53814c75a0fd5d036436-20240421231949-xtjc7jp.jpg" alt="">​</p> <p>数据维度的<strong>自我保护主要指如何保证服务端数据的安全, 不被窃取</strong>. 服务维度的自我保护主要指集群的<strong>限流机制</strong>, 通过限制客户端的流量, 请求, 连接等保护自身不被击垮.</p> <p>先来看一下<strong>如何保证存储的数据不会被第三方窃取</strong>.</p> <h5 id="集群中的数据加密"><a href="#集群中的数据加密" class="header-anchor">#</a> 集群中的数据加密</h5> <p>如果你从事金融或证券领域, 因为企业的数据比较重要, 应该经常会问: 发送到消息队列中的数据能不能加密后再存储?</p> <p>这个问题希望达到的效果是: 当客户端发送消息 A(比如 hello world)到 Broker, Broker 保存到磁盘的数据是一串内容 A 加密后的字符串, 当消费端消费数据时, Broker 将加密后的字符串解密成消息 A 返回给消费端.</p> <p>​<img src="/img/4a3d3348afb76855fd1993333bf446f3-20240421231949-9vsos8m.jpg" alt="">​</p> <p>在业务看来, 数据<strong>加密配合传输加密, 认证, 鉴权等机制</strong>, 在数据的安全性上是非常强的.</p> <p><strong>要实现这个效果一般有以下两种方案</strong>:</p> <ol><li>第一种就是上面说的, 由<strong>服务端自动化做好加密解密</strong>. 工作量全在服务端, 客户端没有任何工作量.</li> <li>第二种是客户端在生产的时候自助做好加密逻辑, 在消费的时候自助做好解密操作. 好处在于消息队列服务端没有任何工作量, 坏处在于工作量全部在客户端, 所有的客户端和消费端都需要感知加密的逻辑, 在编码和协调各方的成本方面较高.</li></ol> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bbe61fa889186e5bc869a3139eae16f4-20240421231949-ilytvge.jpg" alt="">​</p> <p>不过<strong>目前业界主流开源消息产品都是不支持消息加密的</strong>, 一般无法用第一个方案, 但一些闭源的商业化消息队列产品具备这个能力. 在我看来, 这是一个刚需能力, 特别在银行, 证券行业的服务部署到公有云的场景中. 所以一般推荐用第二种方案.</p> <p>不过还是可以拓展说说, 如果需要第一种方案, 技术上要怎么实现呢? 主要分为三步.</p> <ol><li>首先, <strong>把接收到的数据解析为生产端发送出来的原始消息格式</strong>. 需要解析是因为客户端可能设置了批量发送, 压缩等行为, 导致服务端收到的格式和原始的消息不一致.</li> <li>其次, <strong>对这些消息进行加密, 并存储到磁盘</strong>.</li> <li>最后, <strong>在客户端消费数据时, 把加密的消息解密成为原始接收到的消息格式返回给客户端</strong>.</li></ol> <p>这里最需要关注的是第二步, 加密算法的选择, 核心依据是: <strong>可以解密获得原始数据, 加解密速度快, 安全性高</strong>.</p> <p>加密算法分为可逆加密和不可逆加密. 可逆加密意思就是经过加密后的数据, 能够经过解密步骤还原出原始数据, 主要算法有 DES, AES 等. 不可逆加密就是指加密后的消息无法还原出原始数据, 主要算法有 MD5, SHS 等. 从需求来看, 肯定需要选择可逆加密类的算法.</p> <p>不过, 可逆加密又分为对称加密和不对称加密. 如何选择呢?</p> <p>它们俩最大的区别在于加解密的速度和安全性. 对称加密的优点是解密速度快, 但保密性差, 主要算法有 DES, 3DES, AES 等. 非对称加密的优点是加密算法保密性好, 但是加解密速度要远远低于对称加密, 主要算法有 RSA, DSA, ECC 等.</p> <p>因为消息队列需要较高的性能, 并且数据的加解密都是在服务端内核完成的, 安全性较高. <strong>所以一般选择对称加密算法, 比如 AES</strong>.</p> <p>加解密的过程会消耗很多 CPU 资源, 对程序的性能和吞吐影响较大. 所以一般情况下, <strong>服务端需要配备一些加密算法硬件加速设备, 以提高加解密的速度</strong>. 比如英特尔的 AES-NI, 它是商品硬件中最常见的加密加速器.</p> <p>好, 到这里已经完成了集群数据维度的自我保护, 那么如何保护好集群的服务不会因为外力原因而崩溃呢? 在服务自我保护维度, 主要包含两个方面: <strong>服务限流, 服务降级</strong>.</p> <h5 id="消息队列限流机制思考"><a href="#消息队列限流机制思考" class="header-anchor">#</a> 消息队列限流机制思考</h5> <p>限流可以说是每个系统的标配, 业界在限流方面的理论结构和开源组件也都非常丰富. 限流主要包含两个部分, <strong>限流算法和实现机制</strong>. 先了解一下不同机制的具体实现和优缺点, 最后会针对具体案例, 实战设计限流方案.</p> <p>目前有四种常见的限流算法.</p> <p>​<img src="/img/b527f1cce08868c27e117571yy6039bd-20240421231949-comj9tp.jpg" alt="">​</p> <p>在业务系统中, 这四种算法都比较常用. 因为消息队列经常需要应对突发流量, 需要尽量平滑的限流机制, 所以从实现上来看会比较<strong>推荐令牌桶算法</strong>.</p> <p>限流的实现机制主要分为两种: <strong>单机限流和全局限流</strong>.</p> <p>单机限流就好理解了, 限流配额发送到单机维度, 在内存中完成计数, 比对, 限流决策. 它的优点是在单机内存内完成限流逻辑的闭环, 几乎不影响主流程的耗时. 缺点是集群部署时, 无法在多台节点之间共享集群信息, 从而导致无法进行集群维度的限流.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c317f6449d5abb0978d816f93d4ec1c5-20240421231949-n2s3t04.jpg" alt="">​</p> <p><strong>全局限流, 一般基于第三方的集中式服务来实现分布式的多机限流</strong>. 在集中式服务中完成配额的记录, 限流判断等行为, 各个服务节点, <strong>通过对中心服务的上报和访问完成限流</strong>. 在第三方组件的选择上, 主要有 Redis, Sentinel, ASAS, PolarisMesh 等. 优缺点跟单机限流刚好相反, 能在多节点之间完成限流信息的共享, 但是在限流操作上的耗时较高.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/29f2bdb99b5cb3e1a7c4120cbfcc6432-20240421231949-m6polc0.jpg" alt="">​</p> <h6 id="全局限流还是单机限流"><a href="#全局限流还是单机限流" class="header-anchor">#</a> 全局限流还是单机限流?</h6> <p>消息队列的核心产品特性是<strong>高吞吐, 低延时</strong>. 所以消息队列对限流方案的最核心的诉求就是, 限流操作不能对性能产生影响. 基于这个诉求来讨论一下是全局限流还是单机限流.</p> <p>如果为了满足高吞吐和低延时, 肯定要限流操作不对性能产生影响, 就只能用单机限流. 但是, 消息队列一般是分布式多机组成的集群形态部署的, 为了多台节点共享限流数据, 在集群维度实现限流, 就只能用全局的限流方案.</p> <p>这两种方案是从机制上是互斥的, 如何选择呢?</p> <p><strong>当前主流消息队列产品, 主要选择还是单机限流机制, 比如 Kafka, Pulsar</strong>. 思路是: 放弃集群维度的精准限流, 将集群总的配额根据节点数据量均分到每个节点, 在每个节点内部完成单机限流.</p> <p>这种方案的好处就是限流的逻辑对耗时无影响, 另外<strong>主流程不会依赖第三方服务, 不会因为第三方服务的稳定性问题导致主流程不可用</strong>.</p> <p>缺点是当写入, 读取出现倾斜时, 会出现单机维度达到限流值, 集群维度却没有达到限流值的问题. 这个问题, 可以通过<strong>不断地动态调节单机限流配额的方式, 尽量提高限流精度</strong>, 但是这也无法根本解决毛刺, 限流不精准等问题.</p> <p>而全局限流的耗时问题, 通过架构层面上的优化, 可以将每次限流操作耗时消耗控制在 1～5ms 之间. 这个级别的耗时, 大部分情况下客户是可以接受的. 所以<strong>全局限流的最大问题是在主流程引入第三方服务而带来的稳定性风险, 此时就会强依赖第三方服务的稳定性</strong>.</p> <p>所以, 限流方案的选择, 会建议 <strong>优先使用全局限流的机制, 支持临时开启关闭限流能力, 支持限流策略降级结合的机制</strong>, 让某些延时敏感的客户或者限流 Server 异常的时候, 支持关闭限流或者降级为单机限流.</p> <p>业界消息队列在限流方面的工作做得没有特别精细, 比如 Pulsar 和 Kafka 都是基于单机限流策略实现的, RabbitMQ 和 RocketMQ 主要是消费端的一些限流机制, 服务端限流做的工作较少. 从实现程度来看都不够完整, 都有各自的侧重点和优缺点.</p> <p>有了限流机制, 就可以看看<strong>具体要对哪些资源和维度进行限流</strong>.</p> <h6 id="对哪些资源和维度进行限流"><a href="#对哪些资源和维度进行限流" class="header-anchor">#</a> 对哪些资源和维度进行限流</h6> <p>从消息队列的特性上来看, 主要对<mark><strong>流量, 连接数, 请求数</strong></mark>三类资源进行限流, 有些消息队列还会对 CPU 和内存进行限制. 限制的维度一般包括: 集群, 节点, 租户/ Namespace, Topic, Partition, Group/Subscribe 六个维度.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2b19c786f2b55a5bb16dde3512c41d72-20240421231949-z7q3w60.jpg" alt="">​</p> <p><strong>流量限制</strong> 指对生产, 消费的流量限制, 是消息队列的核心限流指标. 因为很多问题都是流量波动引起的, 限制好集群的流量, 很大程度上能保证集群的稳定. 所以你会在各款消息队列里看到对流量的限制. 一般会对集群, 节点, 租户/ Namespace, Topic, Group/Subscribe 这几个维度配置.</p> <p><strong>连接数限制</strong> 指对客户端<strong>连接到服务端的 TCP 连接数量进行限制</strong>. 因为 TCP 连接的建立和关闭需要消耗 CPU, 内存等资源, 限制是为了保护服务端不会因为连接数太多, 耗尽资源, 导致服务不可用. 虽然现在技术上的网络编程有异步 IO, 多路复用等技术, 但是连接太多还是会出现问题. 所以 RabbitMQ 在连接的基础上设计了 Channel 信道, 避免 TCP 连接频繁建立关闭, TCP 连接数太多.</p> <p>连接数主要从三个层面进行限制.</p> <ul><li>服务端单机可承载的最大连接数限制.</li> <li>客户端单个 IP 可建立的连接数.</li> <li>单个集群可建立的总链接数.</li></ul> <p>连接数的限制一般在集群, 节点, 租户/ Namespace 三个维度配置.</p> <p><strong>请求数限制</strong> 指对单个接口的访问频次进行限制, 来保护集群自身的可用性. 比如消息队列中的获取元数据(Lookup, 寻址)接口, 这个接口一般需要返回所有 Topic, 分区, 节点的数据, 需要做很多获取, 组合, 聚合的操作, 很消耗 CPU. 在客户端很多的情况下, 如果客户端同时更新元数据, 很容易把服务端的 CPU 耗完, 导致集群生产消费异常. 请求限流就能起很好的保护作用. 连接数的限制一般在集群, 租户/ Namespace 两个维度配置.</p> <h6 id="发生限流后怎么处理"><a href="#发生限流后怎么处理" class="header-anchor">#</a> 发生限流后怎么处理</h6> <p>当限流发生后, 会发生什么事情呢? 按正常的逻辑, 限流发生后, 肯定是拒绝请求或者流量了. 但注意, 在消息队列里, 是需要<strong>分情况来考虑</strong>的.</p> <p>因为消息队列本身的功能是削峰填谷, 在有突发流量的时候, 流量很容易超过配额. 此时, 机器层面一般是有能力处理流量的, 如果直接拒绝流量, 就会导致消息投递失败, 客户端请求异常. 所以在限流后, 一般有两种处理形式.</p> <ol><li><strong>返回超额错误, 拒绝请求或流量</strong>.</li> <li><strong>延时回包, 通过加大单次请求的耗时, 整体上降低集群的吞吐</strong>. 因为正常状态下, 客户端和服务端的连接数是稳定的, 如果提升单次处理请求的耗时, 集群整体流量就会相应下降.</li></ol> <p>Kafka 的主要处理机制是延时回包. <strong>延时回包的优点是可以承载突发流量, 当有突发流量时, 不会对客户端造成严重影响, 缺点是无法精准限制流量</strong>. 比如 Kafka 在 Ack=0的时候或者客户端不断新建连接打入流量的时候, 客户端的流量会突破服务端的限制, 极端情况下会打爆集群. 此时就需要配合返回超额错误拒绝流量的策略, 以达到保护集群的目的.</p> <p>返回超额错误的实现很简单, 收到流量后, 根据当前使用的限流算法来判断是否超过限流配额, 是的话, 就返回报错.</p> <p>延时回包的实现比较复杂, 收到流量后, 需要根据当前的延时回包算法, 计算一个延时回包的时长, 然后把回包信息放入到延时回包队列(延时回包队列的实现一般是使用时间轮的方案), 等过了延时回包的时间, 再给客户端回包.</p> <p>延时回包的算法设计起来比较复杂, 下面看一个例子, <a href="https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/ClientQuotaManager.scala" target="_blank" rel="noopener noreferrer">Kafka 的延时回包算法代码<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>​<img src="/img/fd4ce6dec3061277c78abb3263247531-20240421231949-6tpz0uh.png" alt="">​</p> <p>在算法的核心逻辑中, O 是观测到的速率, T 是 W 窗口内的目标速率, 为了让 O 降到 T, 需要给 W 增加一个 X 的延迟, 使得 O * W / (W + X) = T. 求 X, 得到 X = (O - T)/T * W. 如果自己实现延时回包, 这个逻辑很值得参考.</p> <h5 id="消息队列全局限流设计"><a href="#消息队列全局限流设计" class="header-anchor">#</a> 消息队列全局限流设计</h5> <p>了解了各种机制的优缺点和具体实现思路, 接下来来实操综合运用一下, 如何<strong>为一个消息队列集群设计实现单机限流方案和全局限流方案</strong>.</p> <h6 id="单机限流方案"><a href="#单机限流方案" class="header-anchor">#</a> 单机限流方案</h6> <p>单机限流的方案思路比较简单, 首先将集群总配额除以集群总的节点数, 得到每个节点上可用的配额. 在各个节点下发配额数据, 然后在单机维度使用漏斗算法等算法, 实现单机维度的限流.</p> <p>具体实现分以下四步:</p> <ol><li><strong>计算单节点的配额</strong>.</li> <li>存储每个节点的配额信息, 以免节点重启后配额信息丢失, 比如 Kafka 和 Pulsar 都是存储在 ZooKeeper 上.</li> <li>为每个节点下发变更配额信息, 节点在重启的时候加载配额信息.</li> <li>当生产消费的时候, 在内存存储计算流量, 并和配额数据进行比较, 确认是否限流.</li></ol> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4b26e3513ddceb7e6e01767b78b63729-20240421231949-q4mlsr2.jpg" alt="">​</p> <p>单机限流还有一个小优化, <strong>可以实时监控每台节点的限流情况, 动态修改每台节点的配额</strong>. 通过判断, 给流量较高的节点分配较多的配额, 给流量较少的节点分配较少的配额, 从而在<strong>流量倾斜</strong>的时候, 也能够做到较为精准的限流.</p> <h6 id="全局限流方案"><a href="#全局限流方案" class="header-anchor">#</a> 全局限流方案</h6> <p>从技术上看, 全局限流方案思考的核心有三点.</p> <ol><li>对当前主流程不能影响或者影响极低.</li> <li>限流的精度需要仔细权衡, 需要考虑限流是否足够精准, 是否会有倾斜.</li> <li>需要设计好<strong>回退措施</strong>, 即限流组件抖动时, 不能影响主流程.</li></ol> <p>接下来看看全局限流的方案思路, 相对复杂, 主要分为五步.</p> <ol><li>首先选择一个<strong>集中式的限流 Server</strong>, 可以选择业界的全局限流的组件, 比如 Sentinel 或 PolarisMesh, 也可以是消息队列内置实现的一个全局限流的组件, 简单点也可以是 MySQL 或者 Redis.</li> <li>然后<strong>把组件中写入限流配额</strong>.</li> <li><strong>在生产和消费时, 向限流 Server 记录配额信息, 获取限流状态, 判断是否进行限流</strong>.</li> <li>同时根据单机限流的方案, 在本地缓存一份均分的配额数据, 当限流 Server 异常时, 直接使用本地缓存的配额数据进行计算限流.</li> <li>同时<strong>提供开关</strong>, 在某些情况下可以关闭限流.</li></ol> <p>另外, 在代码实现层面, 还可以<strong>插件化地支持多种限流机制</strong>, 通过配置可生效. 从代码实现流程来看, 如下图所示, 具体实现可以分为五步.</p> <ol><li>往限流 Server 写入集群配额.</li> <li>同时 Broker 会获取到均摊的配额信息, 流程和单机限流方案一样.</li> <li>生产消费的时候, 会判断是否走本地限流逻辑, 是的话, 跟单机限流方案一样.</li> <li>正常会走上报数据和获取限流状态的逻辑, 进行限流判断.</li> <li>同时支持开启关闭限流状态, Broker 允许接收指令开启或关闭限流信息.</li></ol> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c588a77024649689b678c98993c8061a-20240421231949-ybpojwg.jpg" alt="">​</p> <h5 id="消息队列的服务降级"><a href="#消息队列的服务降级" class="header-anchor">#</a> 消息队列的服务降级</h5> <p>在实际的生产环境中, 因为一些环境因素的影响, 比如节点故障, 机房故障或某些异常的攻击行为. 可能导致一些限流策略无法生效, 就会导致集群在一段时间内的负载很高或无法正常提供服务. 此时需要进行服务降级, <strong>通过拒绝流量或者拒绝连接的方式, 完成自我保护, 以保证消息队列核心链路的功能正常使用</strong>.</p> <p>消息队列中常见的降级策略一般有三种.</p> <ul><li><strong>配置 Broker 的 CPU 或内存的使用率额度</strong>, 当使用率到达配额时, 通过拒绝生产或消费流量的形式来保证服务的部分正常. 通常会优先拒绝生产流量, 因为大部分集群过载是生产流量过大引起的. 此时禁止生产流量的写入, 可以保证消费的正常, 服务不至于崩溃, 消费端可以及时消费掉积压的数据. RabbitMQ 就内置了这个策略.</li> <li><strong>配置磁盘保护机制</strong>, 可以保护消费不会有异常. 当真实的磁盘使用率使用达到一定的程度时, 就禁止流量写入. 因为在消息队列中, 磁盘较容易被打满, 打满的话如果还允许写入服务程序就会有异常, 从而影响消费.</li> <li><strong>判断异常自动重启 Broker</strong>, 通过自动判断服务的运行情况, 决定是否重启 Broker. 比如当发现频繁发生 Full GC 的时候, 就自动重启自身服务, 以达到回收资源的目的. 这种方式用得比较少, 因为比较危险, 可能会导致集群中的所有 Broker 频繁重启. 一般需要依赖第三方组件的多维度判断, 以降低误重启的风险.</li></ul> <h5 id="总结-20"><a href="#总结-20" class="header-anchor">#</a> 总结</h5> <p>集群在运行过程中, 需要保证存储的数据安全, 不会被第三方窃取, 也需要能够保护好自身的服务, 不会因为外力的原因而崩溃. 即使在服务异常的情况下, 也尽量保证自身的服务部分可用.</p> <p><strong>数据保护的核心逻辑是通过加密保护数据</strong>. 加密算法的选择需要兼顾安全性和加解密的速度. 因为是在 Broker 内部完成加解密的, 安全性较高, 所以重点关注加解密的速度. 我推荐对称加密算法, 我们也可以通过专有的设备加快加解密的速度.</p> <p><strong>服务保护的核心是限流机制. 限流方案的选择主要有全局限流和单机限流两种方案</strong>. 推荐的选择是复合方案, 也就是在大部分场景下, 启用全局限流方案, 在全局限流不能正常工作时, 启动单机限流方案. 限流算法的选择上, 建议使用令牌桶算法.</p> <p>一些情况下, 限流机制无法百分百保证服务的正常运行, 还需要预备紧急状态下的降级机制.</p> <h5 id="思考题-17"><a href="#思考题-17" class="header-anchor">#</a> 思考题</h5> <blockquote><p>全局限流 Server 选型的要点是什么? 社区有哪些选择?</p></blockquote> <ol><li><strong>集群部署</strong>, 具备横向扩容, 自动容灾切换的能力.</li> <li>最好自带<strong>可降级</strong>的能力, 以降低开发成本.</li> <li>最好是<strong>长连接</strong>, 这样在数据上报和获取状态的耗时较低.</li></ol> <p>业界主要有 Redis, Sentinel, ASAS, PolarisMesh 等.</p> <h4 id="_21-可观测性-如何设计实现一个好用的分布式监控体系"><a href="#_21-可观测性-如何设计实现一个好用的分布式监控体系" class="header-anchor">#</a> 21-可观测性:如何设计实现一个好用的分布式监控体系?</h4> <p>&quot;可观测性&quot; 是近几年技术圈很火的话题, 特别是 OpenCensus 和 OpenTracing 合并成立 OpenTelemetry 后, 可观测性的发展速度越来越快, 越来越成熟.</p> <p><strong>OpenTelemetry 主要是解决可观测性数据的获取规范问题</strong>, 类似消息队列领域的 AMQP 和 OpenMessaging, 目的都是打造一个标准化规范. 它系统地将可观测性分为<mark><strong>指标(Metrics), 日志(Logs), 跟踪(Traces)</strong></mark> 三个方面. 在消息队列领域, 可观测性建设主要也是围绕着这三点展开.</p> <p>今天先来聊一聊<strong>怎样实现好用的指标和日志模块, 以便快速定位业务问题出在哪里</strong>, 下一节讲<strong>跟踪</strong>(Traces).</p> <h5 id="指标需要关注哪几个维度"><a href="#指标需要关注哪几个维度" class="header-anchor">#</a> 指标需要关注哪几个维度?</h5> <p>从技术上看, 指标分为<strong>单机维度和集群维度</strong>.</p> <p>单机维度的指标主要分为<strong>操作系统, 语言虚拟机, 应用进程</strong>三层.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ba53de20a22eba0992b1dc6f1688a4cb-20240421231949-k91zdrx.jpg" alt=""></p> <p>所以, 从排查问题的角度来看, 需要关注对应的三层指标.</p> <ul><li><strong>操作系统</strong>: IaaS 层指标的 CPU, 内存, 网卡, 硬盘等等.</li> <li><strong>语言虚拟机</strong>: Java 虚拟机的 GC, 线程池, 堆容量等等.</li> <li><strong>应用进程</strong>: 进程中的生产消费各阶段耗时, 接口的请求数, 进程文件句柄数量等等.</li></ul> <p><strong>集群维度是多个应用进程(节点)构成的集群维度的一些监控指标</strong>, 比如集群中的 Topic 总数, 分区数, Controller 节点的负载等等.</p> <p>这两个维度讲得有点宽泛, 接下来就详细讲一下<strong>需要关注哪些具体的关键指标, 以便能快速定位出问题</strong>.</p> <h5 id="消息队列有哪些关键指标"><a href="#消息队列有哪些关键指标" class="header-anchor">#</a> 消息队列有哪些关键指标?</h5> <p>虽然各款消息队列产品的功能, 定位, 架构的差别很大, 指标也是特定于系统的, 但是消息队列的几个核心流程都是相似的, 比如元数据获取, 生产消费流程等逻辑.</p> <p>所以, 所有的消息队列有通用的<strong>核心指标</strong>, 主要有五类: <mark><strong>集群(Cluster), 节点(Node/Broker), 主题(Topic), 分区/队列(Partiton/Queue), 消费分组/订阅(Group/Subscription)</strong></mark> .</p> <p>​<img src="/img/9de541eb1301dcbfacfa398181ec71e5-20240421231949-lz615di.jpg" alt="">​</p> <blockquote><p>集群</p></blockquote> <p><strong>集群指标主要是集群资源数量相关的</strong>, 比如主题数量, 分区数量, 节点数量等集群维度的信息, 这类信息的影响在于 <strong>数量</strong>. 如果某些资源数量过大, 有可能影响集群的稳定.</p> <p>几乎所有的消息队列产品, 在主题或分区数量太多的情况下, 都会出现性能下降或者不稳定问题. 比如, RabbitMQ 的每个节点需要同步缓存全量 Queue 数据, 如果 Queue 太多, 会导致单机负载变高. Kafka 的分区过多, 会加大 Controller 的压力. Pulsar 的分区太多, 会对 ZooKeeper 造成压力等等.</p> <blockquote><p>节点</p></blockquote> <p><strong>节点指标一般包含节点的生产消费的吞吐量, 耗时, 消息数, 接口的请求数, 错误码, 耗时, JVM FullGC, YongGC 的次数, 节点的 TCP 连接数等等</strong>.</p> <p>节点相关的指标, 都是需要重点关注的指标. 因为消息队列主打高吞吐, 低延时, 所以耗时和吞吐量是业务最直接感知的指标. 比如出现报错时, 接口维度的错误码统计就需要重点关注. 比如客户端出现耗时高, 首先就需要观察各个节点的生产消费的耗时; 然后观察是否发生 GC, 接口调用次数, 连接是否有异常; 最后关注 IaaS 层指标, 如 CPU, 内存, 网卡等指标是否有异常, 不管在什么时候, <strong>IaaS 指标和 Java 虚拟机相关的指标都是非常重要的</strong>.</p> <blockquote><p>主题和分区</p></blockquote> <p><strong>主题指标一般是主题维度的吞吐量, 消息条数, 生产和消费耗时数据</strong>. 当业务反馈只有某些主题异常时, 这些指标可以用来定位问题.</p> <p>分区维度的指标是一样的, 只是可以细化到定位分区和队列维度的异常.</p> <blockquote><p>消费分组和订阅</p></blockquote> <p>消费分组/订阅的指标一般是<strong>消费速度, 未消费的消息数量(堆积数)</strong> . 平时用来观察消费的情况, 比如消费速度是否跟得上, 是否有堆积等等. 或者当消费出现异常的时候, 可以通过这个指标用来判断消费速度是否有问题, 然后结合主题和分区维度的指标, 最终确认问题.</p> <p>结合这五个维度的指标, 基本可以定位出常见的性能和稳定性问题.</p> <p><strong>除了通用的指标, 不同的产品因为架构实现不一样, 会有各自的独特指标</strong>. 如果需要进一步定位问题, 就需要结合这些指标去分析. 比如 Kafka 的 Controller 和协调器, Pulsar 的 Ledger, RabbitMQ 的 Exchange 相关的指标, 这部分主要和稳定性相关, 需要理解各个组件的架构才能理解指标的含义, 后面会详细讲.</p> <p>这些指标从技术上理解, 流量或者请求次数应该是一个累加的值, 线程池的容量应该是一个可加可减的值, 耗时应该是一个包含分布信息的值, 线程状态应该是一个瞬时的值. <strong>那从编码的角度, 如何实现记录这些指标呢</strong>?</p> <h5 id="如何记录指标"><a href="#如何记录指标" class="header-anchor">#</a> 如何记录指标?</h5> <p>先来看一个小需求: <strong>从功能上需要记录 Broker 维度的生产消息数量, 生产的流量, 接口调用耗时, 生产连接数, 进程启动状态五个信息</strong>. 来看一下这五个指标的功能定义:</p> <ul><li><strong>生产消息数量</strong>, 应该是一个累加的值.</li> <li><strong>生产的流量</strong>, 也是一个累加的值.</li> <li><strong>接口调用耗时</strong>, 应该是一个分布的值.</li> <li><strong>生产连接数</strong>, 应该是一个可加可减的值.</li> <li><strong>进程启动状态</strong>, 应该是一个瞬时值.</li></ul> <p>那如果在代码中要记录这些指标, 应该怎么实现呢?</p> <h6 id="主流的指标库"><a href="#主流的指标库" class="header-anchor">#</a> 主流的指标库</h6> <p>从编码实现的角度来看, 业界有多种指标的记录方式, 如下图所示, 比较常见的有以下五种:</p> <ul><li>Java Metrics</li> <li>Prometheus Metrics</li> <li>Kafka 基于 Metrics 实现的自定义 KafkaMetrics</li> <li>Golang 的指标库 go-metrics(一般各个语言也会有对应的 Metrics 库)</li> <li>可观测性标准 OpenTelemetry 中的 Metrics</li></ul> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/56a1f643dyy4286f3096bc9bcfec9466-20240421231949-4b9776u.jpg" alt=""></p> <p>接下来主要分析一下 Java Metrics,  Prometheus, OpenTelemetry 支持的指标类型.</p> <p><strong>Java Metrics 提供了五种指标类型</strong>.</p> <ul><li><strong>Gauge</strong>: 提供返回一个变量的<strong>瞬时值/当前值</strong>, 可以用来定义指标的<strong>当前状态的瞬时值</strong>, 比如当前集群是否限流.</li> <li><strong>Counter</strong>: 是一种特殊的 Gauge 度量, 它提供一个获取可增可减的时刻量, 比如线程池的空余容量.</li> <li><strong>Meter</strong>: 用来测量事件发生的<strong>频率</strong>, 也可以统计最近 1 分钟, 5 分钟和 15 分钟的频率, 比如接口请求的频率.</li> <li><strong>Histogram</strong>: 常用来统计数据的<strong>分布</strong>, 比如最小值, 最大值, 平均值和中值, 还可以进行百分比的分布统计, 例如 TP75, TP90 和 TP99等, 接口请求的耗时分布.</li> <li><strong>Timer</strong>: 可以理解为 Meter+Histogram 的合体, 需要同时使用 Histograms 和 Meters 功能时, 就可以用 Timers.</li></ul> <p><strong>Prometheus Metrics 提供了四种指标类型</strong>.</p> <ul><li><strong>Gauge</strong>: 记录<strong>可增可减的时刻量</strong>.</li> <li><strong>Counter</strong>: 是一个<strong>只增不减的计数器</strong>.</li> <li><strong>Histogram</strong>: 直方图, 在<strong>一段时间范围内对数据进行采样, 最后将数据展示为直方图</strong>.</li> <li><strong>Summary</strong>: 概要, 反映百分位值, 例如某 RPC 接口, 95% 的请求耗时低于 100ms, 99% 的请求耗时低于200ms.</li></ul> <p>可以看到 Java Metrics 库和 Prometheus 指标类型基本相似, 但含义和功能并不完全相同. 这也是可观测性标准 OpenTelemetry 中特意强调指标(Metrics)的理由, 希望在指标定义方面制定一套统一规范, 并提供各个语言的代码库, 降低重复开发的成本和使用者理解学习的成本.</p> <p><strong>OpenTelemetry 主要提供了六种指标类型</strong>(详细可参考 <a href="https://opentelemetry.io/docs/concepts/signals/metrics/" target="_blank" rel="noopener noreferrer">OpenTelemetry Metrics 官网文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>).</p> <ul><li><strong>Counter</strong>: 递增的计数器.</li> <li><strong>CounterObserver</strong>: 异步方式的递增计数器.</li> <li><strong>UpDownCounter</strong>: 可增可减的计数器.</li> <li><strong>UpDownCounterObserver</strong>: 异步方式的可增可减计数器.</li> <li><strong>Histogram</strong>: 统计一组数据, 如直方图.</li> <li><strong>GaugeObserver</strong>: 异步的方式观测最新数据的计量器.</li></ul> <p>知道了各个库的指标定义, 回到上面的需求, 看要如何完成记录指标.</p> <h6 id="小需求的实现"><a href="#小需求的实现" class="header-anchor">#</a> 小需求的实现</h6> <p>假设用 Prometheus Metrics 来记录指标.</p> <p>​<img src="/img/yyab3b58d092886c0651f4cce048a8ed-20240421231949-gflbjm3.jpg" alt="">​</p> <p>如上图所示, 结合需求和指标类型的功能定义来看, 生产消息数量, 生产的流量, 生产连接数是累加值, 可以用 Counter 表示; 接口调用耗时是分布值, 可以用 Histogram 表示; 进程启动状态是瞬时值, 可以用 Gauge 表示.</p> <p>知道了用什么指标类型, 那怎么编码实现呢? 来看下面的 Prometheus Java 代码示例:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">//counter 的使用</span>
<span class="token class-name">Counter</span> requests <span class="token operator">=</span> <span class="token class-name">Counter</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">&quot;rocketmq_messages_in_total&quot;</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">help</span><span class="token punctuation">(</span><span class="token string">&quot;Rocketmq messages in total&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">register</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
requests<span class="token punctuation">.</span><span class="token function">inc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// gauge 的使用</span>
<span class="token class-name">Gauge</span> proxyUp <span class="token operator">=</span> <span class="token class-name">Gauge</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">&quot;rocketmq_proxy_up&quot;</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">help</span><span class="token punctuation">(</span><span class="token string">&quot;Rocketmq proxy up&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">register</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
proxyUp<span class="token punctuation">.</span><span class="token function">inc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
proxyUp<span class="token punctuation">.</span><span class="token function">dec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// histogram 的使用</span>
<span class="token class-name">Histogram</span> requestLatency <span class="token operator">=</span> <span class="token class-name">Histogram</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">&quot;rocketmq_rpc_latency&quot;</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">help</span><span class="token punctuation">(</span><span class="token string">&quot;Rocketmq rpc latency&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">register</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
requestLatency<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Runnable</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// Your code here.</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>从上面的示例中知道了代码如何记录. 如果想了解更多具体的使用细节, 可以参考 <a href="https://github.com/prometheus/client_java" target="_blank" rel="noopener noreferrer">Prometheus Java Client 官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>业界主流消息队列指标模块实现, Kafka 是基于 Java Metrics 的, RabbitMQ, Pulsar, RocketMQ 4.0 是基于 Prometheus 的, <strong>RocketMQ 5.0 以后是基于 OpenTelemetry 规范的</strong>.</p> <p>现在指标在进程内部已经被记录了, 必须暴露出来给<strong>监控系统</strong>集成才有意义. 你是不是在想, 暴露指标不是很容易嘛, 比如将指标定期写入到文件, 或者开个 HTTP 端口给其他系统拉取就可以了.</p> <h5 id="如何暴露指标"><a href="#如何暴露指标" class="header-anchor">#</a> 如何暴露指标?</h5> <p><strong>指标暴露的目的是让第三方系统简单, 规范地获取到指标</strong>. 接下来来看一下主流的指标暴露方案.</p> <h6 id="业界主要指标暴露方案"><a href="#业界主要指标暴露方案" class="header-anchor">#</a> 业界主要指标暴露方案</h6> <p>从技术上看, 如下图所示, 当前业界主要的指标暴露方案, 大致可以分为四种.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/aaec468c5c7c1060974d36ce80fa0e1d-20240421231949-knn2cov.jpg" alt=""></p> <blockquote><p>自定义 TCP/HTTP 接口</p></blockquote> <p>自定义 TCP 接口是指通过服务本身暴露四层的 TCP 接口, 来暴露服务内的指标数据. 这种方式需要先设计私有协议, 然后 Client SDK 封装接口来拉取数据. 缺点是私有协议访问, 不方便被集成, 并且添加定义指标需要修改访问协议, 工作量很大.</p> <p>自定义 HTTP 接口指在服务内启动一个 HTTP Server, 通过 HTTP 协议暴露指标内容. 这种方式相对自定义 TCP 接口来说会更方便点, 但是数据量大时在性能层面会有一些瓶颈.</p> <blockquote><p>JMX Service Server</p></blockquote> <p>JMX(Java Management Extensions)是 Java 提供的一套标准的代理和服务, 通过基于 TCP 层的 JMX 协议远程获取数据. 早期在 Java 里面用得比较多, 近几年用的人相对较少. 主要缺点是只能在 Java 里面用, 而且只能通过 JMX 私有协议访问.</p> <blockquote><p>Prometheus 标准接口</p></blockquote> <p><strong>Prometheus 是在服务内部启动一个 HTTP 服务, 然后暴露 /Metrics 接口, 供客户端拉取数据</strong>.</p> <blockquote><p>OpenTelemetry 上报</p></blockquote> <p><strong>OpenTelemetry 定义了一个接收器 Collector, 即指标上报方根据 OpenTelemetry 的规范将数据上报到 Collector 中. 跟上面三种不一样, 前三种是 Pull 模型, OpenTelmetry 是 Push 的模型</strong>.</p> <p>在早期, Prometheus 还未发展成熟时, 前面两种用得比较多, 比如 Kafka 用的是 JMX Service, RocketMQ 5.0以前用的是集成在 Admin 里面的自定义 TCP Insterface 方式, RabbitMQ 用的是自定义 HTTP 接口.</p> <p>随着 Prometheus 和 OpenTelemetry 的发展, 这两种方案用的越来越多. 接下来主要来看这两种方案的使用, 先来看一下 Prometheus 方案.</p> <h6 id="标准prometheus方案"><a href="#标准prometheus方案" class="header-anchor">#</a> 标准Prometheus方案</h6> <p>从技术上看, Prometheus 采集指标主要有下面两种形式.</p> <p><strong>第一种是在内核中内置 HTTP Server, 然后暴露 /metrics 接口, 返回 Prometheus 需要的格式数据</strong>. 天生就支持集成 Peometheus 监控, 使用起来很方便, 基本没有缺点. Pulsar, RocketMQ5.0 就是这种形式. RabbitMQ 是通过提供 Prometheus 插件来实现的, 也可以算是这一类.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f7bf96a8db048f3439b5f2fcdb7b0bfe-20240421231949-lvge3ab.jpg" alt=""></p> <p><strong>第二种是额外提供 Export 组件</strong>. Kafka, RocketMQ 4.0 就是这种形式. 为什么有这种形式呢? 因为如果要内置 Prometheus Metrics 接口, 首先要内置一个 HTTP Server, 然后在指标注册时使用 Prometheus 的格式来注册, 以确保符合规范.</p> <p>但是很多组件已经发展了多年, Metrics 模块已经成熟稳定, 投入大力气改造的收益不大. 所以一般会先开发一个单独的 Export 组件, 使用原先的 TCP/HTTP 方式去拉取指标, 然后整合成 Prometheus 需要的格式. 最后通过自身暴露的 HTTP /metrics 接口, 把指标暴露给 Prometheus 集成. 这样既不用改变原先的代码, 又能实现 Prometheus 的集成.</p> <p>​<img src="/img/da16d0c8c5fbf0d4451d73c6145b0557-20240421231949-r5chcm1.jpg" alt="">​</p> <p><strong>这两种基于 Prometheus 的指标暴露格式, 使用起来简单方便, 方案成熟, 适合中小规模的集群部署</strong>. 但在一些大企业或者云平台, 当集群有几万, 几十万节点时, 需要实现秒级的指标采集, <strong>Prometheus 会有明显的性能瓶颈</strong>.</p> <p>所以, 这类平台或者企业都会有自研的分布式指标采集系统, 通过定期的 Pull 模型去访问 Broker 拉取各种指标, 汇总计算.</p> <p>​<img src="/img/a545f15aef3e828111d34b7b5bc020db-20240421231949-x2c1ig5.jpg" alt="">​</p> <p>分布式指标采集系统, 解决的是大规模异构集群的指标采集, 以及采集中的性能, 调度相关的问题. 它的实现比较复杂.</p> <h6 id="标准opentelemetry方案"><a href="#标准opentelemetry方案" class="header-anchor">#</a> 标准OpenTelemetry方案</h6> <p>可观测性规范 OpenTelemetry 推荐的指标暴露方式, 需要<strong>部署一个 Collector 来传输指标数据</strong>. OpenTelemetry 官方和各个云厂商都有提供 Collector 的实现, 可以很方便地把数据上报到它们提供的 Collector 中.</p> <p><mark><strong>可以把 Collector 理解为一个服务端, 专门用来接收数据, 它会根据 OpenTelemetry 定义的规范接收数据</strong></mark>. 只要是按照 OpenTelemetry 定义的规范, 就能成功上报数据, 不会有厂商绑定或产品绑定的问题.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/983da7844dbb1cee71e74a2e686884b2-20240421231949-yr14c00.jpg" alt=""></p> <p>上面只是简短的技术思路, 没有代码示例. 如果需要了解更多具体使用, 请参考 <a href="https://prometheus.io/" target="_blank" rel="noopener noreferrer">Prometheus 官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://opentelemetry.io/" target="_blank" rel="noopener noreferrer">OpenTelemetry 官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>从使用上来看, 目前用得最多的是 Prometheus 方案, 主要原因是成熟且生态已经完整了. OpenTelemetry 作最为一个标准规范, 后续估计也会慢慢发展. 个人还是比较习惯用 Prometheus 方案, 但长期来看, 如果是全新的组件, 建议基于 OpenTelemetry 来设计实现指标模块.</p> <p>到这里, 如何实现好用的监控指标就学完了, 接下来看看如何印打日志. 打印日志听起来很简单, 其实学问很多.</p> <h5 id="怎样打印日志"><a href="#怎样打印日志" class="header-anchor">#</a> 怎样打印日志?</h5> <p>看日志的时候经常遇到两个问题.</p> <ul><li>出问题的时候, 日志太少了, 找不到问题.</li> <li>出问题的时候, 日志太多了, 一下子就刷没了, 找不到了.</li></ul> <p>对于第一个问题, 日志太少, 首先要 <strong>保证日志内容完整, 携带需要排查的所有信息</strong>.</p> <p>这也是为什么很多大的开源项目都会把 Logs 模块独立出来. 一般情况, 独立日志模块有两个好处: 一是代码封装, 让使用更加方便; 二是需要在项目中规范日志的内容或格式, 比如统一日志格式(JSON 格式, 文本格式), 或者内容中默认带上时间戳, 带上请求 ID 等等, 让日志内容更加完整.</p> <p>不过完整的日志内容说起来简单, 但是因为业务形态, 技术体系不同, 什么日志格式才能叫完整呢?</p> <p>说实话, 这是没有答案的, 就跟一千个人有一千个哈姆雷特是一个道理. 但是<strong>可以参考一下 OpenTelemetry Logs 推荐的标准规范内容, 看看日志一般要包含哪些内容</strong>. 因为 OpenTelemetry Logs 的格式是经过社区各个大厂的人员不断讨论出来的, 有比较好的参考意义. 另外日志的打印, 也建议使用 OpenTelemetryLogs 组件, 它的内容很齐全, 集成起来也方便.</p> <p><mark><strong>Opentelmetry 推荐的日志内容主要包含事件, ID, 日志级别, 内容, 额外信息五部分</strong></mark>, 跟自己定义是类似的, 但是它还包含了日志来源, 日志作用域等信息, 有助于确定日志发生的上下文, 辅助排查问题. 而这些字段自己设计的时候很容易忽略, 这就是参考标准的意义.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/8373c0754491683f20757f8978c8750a-20240421231949-n53nydl.jpg" alt=""></p> <p>当然对格式的定义, 大家肯定会有自己的见解, 可以看社区的讨论 <a href="https://docs.google.com/document/d/1ix9_4TQO3o-qyeyNhcOmqAc1MTyr-wnXxxsdWgCMn9c/edit#heading=h.1c8voo540fzy" target="_blank" rel="noopener noreferrer">OpenTelemetry Log Data Model<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>建议可以尽量多打印一些打日志. 在关键的节点都可以放上日志, 比如请求的接收和返回, 每条消息进/出延时队列, 死信队列的时间.</p> <p>现在第一个问题解决了, 但是一旦多打日志, 又容易出现第二个问题. 日志太多, 很难找到需要的日志, 这个时候需要 <strong>控制好合适的日志级别</strong>.</p> <p>我们最经常使用的日志级别一般是 Info, Warn, Error, 可以多用 Trace, Debug 级别的日志, 比如接收请求的时间和内容, 请求返回的时间和内容可以定义为 Trace. 这里也分享一个技巧, 平时可以设置为 Info 级别, 在出问题的时候再调整日志级别, 查看更详细的日志.</p> <p>不过在大部分日志库里, 修改日志级别是需要重启应用的, 或者需要经过特殊的配置, 才能实现日志级别的动态修改. 所以, 为避免在出问题时需要重启进, 程调整日志级别, 需要在应用中 <strong>配置可动态修改的日志级别</strong>(具体如何配置, 资料很多, 比如使用 SpringBoot 可以根据文档 <a href="https://www.springcloud.io/post/2022-03/dynamically-modifying-logger-log-levels/#gsc.tab=0" target="_blank" rel="noopener noreferrer">《在 Spring Boot 应用程序中动态修改 Logger 日志级别》<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 配置可动态修改的日志级别).</p> <p>另外还要注意日志的保留策略, 因为磁盘空间有限, 通常会配置保留日志的文件数或者大小, 比如每个日志文件1G, 保留 50 个文件. 在系统异常的时候, 可能会产生很多的异常信息, 文件可能会被滚动刷没, 所以可以动态设置日志保留时间也非常重要.</p> <p>最后, 为了更好地排查问题, 需要 <strong>把不同的日志分类, 写入不同的文件</strong>.</p> <p>如果在应用启动时, 把不同功能, 模块的日志都打印到一个文件里面, 日志之间会相互穿插, 干扰问题的排查. 所以一般需要把不同的模块, 功能的日志单独文件记录, 以便问题排查(日志分类的配置方式, 可以参考 <a href="https://github.com/apache/kafka/blob/trunk/config/log4j.properties" target="_blank" rel="noopener noreferrer">Kafka 默认日志配置<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>).</p> <h5 id="总结-21"><a href="#总结-21" class="header-anchor">#</a> 总结</h5> <p>消息队列集群的指标应该关注<strong>操作系统, 语言虚拟机, 应用进程</strong>三个维度. 其中最需要重点关注应用进程.</p> <p>应用进程的监控主要分为集群, 节点, Topic, 分区, 消费分组五大模块. 另外还需要关注一些消息队列架构特有的指标, 比如 RabbitMQ 的 Exchange, Kafka 的 Controller 等等.</p> <p>从记录指标上来看, 业界有多种指标库来记录指标. 主要有 Java Metrics, Prometheus Metrics, OpenTelemetry 等库. 目前使用最多的是 Prometheus Metrics, OpenTelemetry 作为一个新的规范, 也建议考虑使用.</p> <p>从指标暴露的角度来看, 主要有 JMX Service Server, 自定义 TCP/HTTP 接口, Prometheus 标注接口, OpenTelemetry 几种方案. 业界主流消息队列集群都有在用. 如果是新组件, 我比较建议你使用 Prometheus 或 OpenTelemetry 方案.</p> <p>基于我自己运营开源集群和自研消息队列的经验, 也总结了打印日志时需要关注的四点.</p> <ul><li>日志内容要完整, 携带我们需要排查的所有信息.</li> <li>日志内容要做到该打的要打, 不该打的不打.</li> <li>能够动态调整日志的级别和保留策略.</li> <li>独立分类的日志文件.</li></ul> <h5 id="思考题-18"><a href="#思考题-18" class="header-anchor">#</a> 思考题</h5> <blockquote><p>如果让你在当前主要维护的一个服务中实现透明监控, 你会怎么做?</p></blockquote> <p>首先, 我会调研一下公司当前有没有团队实现过现类似的透明监控, 然后调研一下当前团队和公司有的监控系统是基于什么实现的. 考虑这个点是因为, 希望能够和公司已有的监控体够尽量贴合, 以减少后续独立开发维护的成本.</p> <p>如果是独立的一个模块, 并且公司已经有了 Prometheus 服务, 会建议用 Prometheus 的全套方案, 利用 Peometheus 数据类型注册指, 内置 HTTP Server 暴露 /Metrics 的方式提供数据. 这种方式的好处就是简单方便, 实现成本低.</p> <p>如果是一个全新的大项目, 包含多个组件, 建议用 OpenTelemetry 的方案. 从长期来看, OpenTelemetry 在完整度和可维护性上会更优雅.</p> <h4 id="_22-可观测性-如何设计实现消息轨迹功能"><a href="#_22-可观测性-如何设计实现消息轨迹功能" class="header-anchor">#</a> 22-可观测性:如何设计实现消息轨迹功能?</h4> <p>今天讲可观测性的第三部分: <strong>跟踪(Traces)</strong> , 在消息队列领域, Traces 通常被称为<strong>消息轨迹</strong>, 意思是消息在系统中的运行轨迹. 消息轨迹在业务消息方向是刚需, 因为业务消息如果出现丢失, 大概率会导致流程异常.</p> <p>比如订单的快递运送流程没有正确处理一条订单号的消息, 后续就会出现无法跟踪这个订单派送的问题. 如果你负责过消息队列基础服务的日常值班, 一定会经常接到用户反馈说消息丢了, 想让平台查清楚为什么丢了. 这个问题, 你会怎么排查呢?</p> <p>如果想排查清楚, 首先要搞清楚有没有丢, 如果丢了, 还要搞清楚是哪一个环节丢的. 想弄清楚这两个问题, 就必须有消息轨迹的功能. 那今天就来讲一讲<strong>消息轨迹功能怎样设计</strong>.</p> <h5 id="丢消息是怎么回事"><a href="#丢消息是怎么回事" class="header-anchor">#</a> 丢消息是怎么回事?</h5> <p>到底什么是 &quot;丢消息&quot;? 你的第一印象是不是服务端把我的消息弄丢了. 其实在消息队列里面, 丢消息没这么简单.</p> <p>从广义上来讲, 消息队列的丢消息是指生产了一条消息, 但是预期中的消费者却没有消费到这条消息. 但是这个过程, 不是只有一种服务端弄丢了消息这一个场景. 下面结合消息的生命周期, 来看看可能有哪些情况.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2d492a43d228fa836f49aee8cbcdc2a3-20240421231949-wfwzafs.jpg" alt="">​</p> <ul><li><strong>生产消息失败</strong>, 生产端把消息写入到服务端时失败了, 这时有可能是服务端有异常, 也有可能是消息的内容或格式不符合规范, 比如太长了.</li> <li>消息设置了延时属性, 消息进入了延时队列后, 没有在定义的延时时间内出队列, 从而没有在特定的时间执行, <strong>错过了消息的有效处理时间</strong>, 被业务抛弃.</li> <li>消息在服务端存储完成后, 因为服务端一致性算法(强一致, 最终一致)的设定问题, 或者异步刷盘, 服务端重启, 消息截断之类的行为, 导致<strong>持久化的消息丢失</strong>了.</li> <li>一般消息队列的消费模型是根据 Offset 来定位消费位点或者重置消费位置的. 如果<strong>消费端设置了错误的位点</strong>, 比如下一条应该消费位点 100 的消息, 但消费端因为异常忽略了 100, 直接从 101 开始消费. 从服务端的角度, 100 的消息就没有被消费过, 而消费者看来, 100 的消费就是没被消费到, 此时从消费端的视角, 消息就是丢失了.</li> <li><strong>当消费端拉到消息后, 如果业务处理有异常, 经过了多次处理后依旧失败, 消息进入了死信队列</strong>, 除非业务配置了订阅消费死信队列的消息, 否则这条消息的生命周期就算结束了. 此时消费端还是没有消费到消息, 消息可以算丢失了.</li></ul> <p>所以从生产消费的流程看, 消息的生命周期是很长的, 只要其中有一步出现问题, 从业务角度看, 就会出现类似消息丢失的感知. <strong>而消息轨迹就是为了还原轨迹, 跟踪单条消息的运行周期</strong>.</p> <p>不过要定位到单条消息生命周期和运行轨迹, 得先有消息的<strong>唯一标识</strong>.</p> <h5 id="消息的唯一标识"><a href="#消息的唯一标识" class="header-anchor">#</a> 消息的唯一标识</h5> <p>消息的唯一标识, 一般是指消息的唯一 ID, 和 OpenTelemetry Traces 中的 <strong>Trace ID</strong> 是同一个东西.</p> <p>业界主流消息队列对消息 ID 的实现有两种形式. 一种是明确有消息 ID 概念的, 一条消息一定会有一个对应的消息 ID, 比如 RocketMQ.</p> <p>另一种没有明确消息 ID 概念的, 会用另外的形式来标识这是一条消息. 比如 RabbitMQ 的消息 ID 是 Header 中的一个可选项, 不是必传, 如果不传就没有消息 ID 的概念. Kafka 唯一标识一条消息, 是通过 Topic + Partition + Offset 来实现的, 严格意义上来讲, 这种没有明确 ID 的消息队列, 无法唯一标识一条消息队列.</p> <p><mark><strong>一条消息的生命周期是从客户端发出来的时候开始算的, 所以发送出来的时候, 就应该赋予消息一个唯一 ID</strong></mark>, 这才能真正表达消息的唯一. 一旦在服务端赋予唯一 ID, 因为客户端可能会重复发送同一条数据, 服务端就会认为是两条数据, 生成两个 ID. 所以, <strong>消息 ID 的生成一般是在客户端 SDK 自动生成或者业务手动生成指定的</strong>.</p> <p>唯一 ID 的生成方式, 业界主要有四种.</p> <ul><li>最简单的就是 UUID, 通过各个语言的 UUID 库生成一个唯一的字符串.</li> <li>集中式的 ID 生成方案, 通过某个中央引擎, 比如 MySQL 自增列, Redis 自增值, ZooKeeper 自增值等机制保证全局唯一.</li> <li><strong>SnowFlake 算法</strong>, 通过 Twitter 开源的 SnowFlake 算法生成唯一 ID.</li> <li>自定义算法: 通过自定义的算法生成唯一的 ID.</li></ul> <p>在消息队列领域, 主要用的是后两种, 因为消息队列的消息一般很大, 几千亿几万亿级别, UUID 有一定概率会重复, 集中式的 ID 生成会增加 SDK 复杂度, 基本不会用. SnowFlake 算法是一个成熟的算法, 拿来即用. 自己设计算法, 保证不重复也可以, 和 SnowFlake 的区别只在于是否是一个成熟开源的算法. 所以从技术选择来看, 比较倾向于第三种方案, 因为经过工业界的验证, 并且表现稳定.</p> <p>现在有了唯一 ID, 就可以开始记录消息轨迹了, 那在<strong>设计消息轨迹实现的时候, 应该考虑哪些因素</strong>呢?</p> <h5 id="消息轨迹的设计应该注意什么"><a href="#消息轨迹的设计应该注意什么" class="header-anchor">#</a> 消息轨迹的设计应该注意什么?</h5> <p>从技术实现来看, 消息轨迹的设计分为三步: <mark><strong>记录, 存储, 查询</strong></mark>. 记<strong>录指在合适的地方记录轨迹信息, 比如生产端消息发出的时间. 存储指将这些轨迹信息存储到某个引擎中. 查询指要能支持消息查询</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6yy74caa643e4335e7c1f6c684c6c9d1-20240421231949-tnqvu5c.jpg" alt=""></p> <p>那在这三步在设计的时候, 应该注意哪些点呢?</p> <p>记录轨迹, 核心诉求就是<strong>能在合适的地方记录轨迹信息, 达到排查问题的效果</strong>. 关键节点, 比如生产端发出消息, 生产端接收到服务端的返回, 服务端收到消息, 进/出延时队列, 服务端看到消息被消费, 消费端记录到消费到消息, 消费端记录处理成功/失败, 消息进入到死信队列等等.</p> <p>记录轨迹<strong>不能影响主流程的稳定性和性能</strong>. 首先不能影响性能, 比如生产流程正常耗时 10ms, 记录轨迹就不能花费5ms, 要尽量减少对流程性能的影响, 最好是无感知. 另外记录消息的方式不能影响主流程的稳定性, 因为轨迹是旁路, 偶尔丢失轨迹是允许的, 但是不能影响到主流程.</p> <p>记录之后的存储, 查询是强相关的. 存储主要是为查询服务的, 因为消息轨迹是一个写多读少的模型, 我们选择 <strong>存储引擎, 写入性能一定要足够优秀</strong>, 不然会影响消息轨迹的写入存储, 影响轨迹查询的及时性.</p> <p>其次从成本角度考虑, 虽然现在硬盘和物理机越来越便宜, 但是因为消息轨迹对比消息有几倍的放大, 比如上面 RabbitMQ 的例子就有 9 倍的放大, 在成本结构中存储的成本占比是最大的. 所以首先 <strong>消息轨迹的内容要足够精简</strong>, 最精简的可以只包含两个字段——消息 ID, 时间, 就能满足需求.</p> <p>另外, 轨迹存在的意义就是查询, 所以<strong>引擎要能支持多维度的查询</strong>. 以 RabbitMQ 为例, 因为 RabbitMQ 在正常情况下是没有消息 ID 的, 一般需要根据时间, Vhost, Exchange, Channel, Connection, Queue 等多个维度复合查询, 所以引擎必须支持多维度的查询, 不能是 KV 类型的存储引擎.</p> <p>但是支持多维度并不意味着越多越好, 引擎满足必要的查询需求就可以了, 不要有太多额外的能力. 因为一般会通过索引或某种数据结构的形式来满足查询需求. 复杂的查询需求, 存储成本就会相应升高. 而消息轨迹的查询需求虽然可能多维度, 但是场景是固定的, 只要设计上能满足这些查询场景就够了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/225df651f8795ca91fa6abc6a66f52f2-20240421231949-qyql2rf.jpg" alt=""></p> <h5 id="消息轨迹的实现方案设计"><a href="#消息轨迹的实现方案设计" class="header-anchor">#</a> 消息轨迹的实现方案设计</h5> <p>掌握了设计要点, 就要用在<strong>技术的选型和实现</strong>上了. 不过光讲知识点可能不好记, 下面从一个具体案例开始, 假设要设计一个 RabbitMQ 消息轨迹的技术方案.</p> <ol><li>预计所有集群总节点规模在几百个左右.</li> <li>每个集群主要承载业务消息, 消息量不是特别大.</li> <li>集群不需要记录死信队列, 延时队列的进出信息, 只需要记录生产者, 服务端, 消费者三者的生产, 接收, 消费的时间.</li> <li>需要支持多维度的查询条件, 比如 Vhost, Exchange, Channel, Connection, Queue, RouteKey 中的一个或多个字段的组合等值查询, 同时需要支持 Headers, Body 的模糊查询.</li> <li>成本要求较为宽松, 基本不做限制.</li></ol> <p>对于这样的项目背景, 你会怎么设计呢? 接下来带着思考, 进入具体的设计方案分析.</p> <p>消息队列是富客户端的应用, 客户端 SDK 需要有较重的逻辑, 比如重试, 事务, 批量发送等等. 所以<strong>从消息队列的角度看, 完整的消息轨迹包含客户端和服务端两个部分</strong>.</p> <h6 id="客户端轨迹数据记录"><a href="#客户端轨迹数据记录" class="header-anchor">#</a> 客户端轨迹数据记录</h6> <p>客户端的轨迹记录一般有两种实现形式. 一种是<strong>客户端将轨迹数据写入到本地文件, 通过第三方组件采集到轨迹系统; 另一种是客户端将轨迹数据通过 Broker 提供的 TCP/HTTP 接口, 或者通过内置主题的方式, 写入到集群中的某个主题中</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4fceb4a63d79f726634e7c4a1834418b-20240421231949-jexgkl6.jpg" alt=""></p> <p>使用消息队列一般会用标准 SDK 访问集群, 加上客户端部署的方式和位置无法控制, 如果用第一种方案, 客户端的轨迹数据很难实现统一的采集上报, 所以一般会选择第二种方案, <strong>在 SDK 中内置轨迹上报的逻辑, 记录轨迹信息并发送到服务端</strong>.</p> <p>TCP/HTTP 服务收到轨迹数据后, 需要保存轨迹数据, 保存逻辑和服务端轨迹数据的保存是一样的, 一起看下.</p> <h6 id="服务端轨迹数据记录"><a href="#服务端轨迹数据记录" class="header-anchor">#</a> 服务端轨迹数据记录</h6> <p>正常情况下<strong>服务端保存轨迹数据</strong>, 有四种形式: <strong>本地文件, 内置 Topic, 第三方服务, 单机维度的存储引擎</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ecd8f041fceb4c68f775c087a514bb2b-20240421231949-hs8g41l.jpg" alt=""></p> <blockquote><p>本地文件</p></blockquote> <p>在链路跟踪或正常的系统架构中, 选择本地文件存储, 然后采集上报到存储引擎的方式, 基本所有的系统都这样用过.</p> <p>优点就是使用方便快捷, 体系成熟, 因为业界的 ELK 体系很成熟, 所以数据采集, 上报, 存储, 分析一条流很常用. 缺点是链路较长, 成本较高, 并且每台节点都需要部署 Agent 采集数据, 运维相对复杂.</p> <blockquote><p>内置 Topic</p></blockquote> <p>内置 Topic 把轨迹数据发送到消息队列的某个内置主题中, 第三方系统消费内置主题中的轨迹数据, 写入到持久存储引擎中.</p> <p>优点是复用了消息队列内置的缓存能力, 不需要依赖第三方存储, 存储成本较低, 同时也可以通过部署远程的消费者集群(跟分布式指标采集系统的原理一样)来消费轨迹数据, 然后存储, 避免了单机运维的复杂度. 缺点是需要单独开发一个单独服务, 去消费轨迹数据并存储, 开发成本较高.</p> <blockquote><p>第三方服务</p></blockquote> <p>直接将轨迹数据存入到第三方存储中, 是指记录轨迹数据的时候, 直接把数据发送到 ES 等第三方系统.</p> <p>优点是简单直接, 链路较短, 运维复杂度较低. 缺点是记录轨迹链路的稳定性依赖于第三方系统, 很容易因为第三方系统的抖动, 导致主链路不稳定. 所以这种方式业界用得比较少, 但是在一些数据量较小, 业务不是特别重要的场景下, 还是有人用.</p> <blockquote><p>单机维度的存储引擎</p></blockquote> <p>把轨迹数据直接存储在各个节点上的文件系统, 或部署在该节点上独立的存储服务中.</p> <p>优点是链路很短, 成本很低, 不需要额外的比如 Kafka, Elasticsearch 的成本. 缺点是查询麻烦, 如果单机挂掉, 轨迹数据就会丢失.</p> <p>以上是从成本角度考虑的. 前面讲过消息轨迹虽然很重要, 但漏记是允许的, 只要保证大部分情况下能用就行, 允许短时间不可用.</p> <p>从使用者的角度, <strong>如果查询的频率较低, 投入很多成本, 从 ROI 来看收益不高</strong>. 所以一些系统在设计时, 就会考虑复用单机的存储和检索能力. 比如每台 Broker 部署一个 RocksDB 服务, 数据存储到每台 Broker 的 RocksDB 上, 需要检索的时候, 依次访问每台 Broker 上的服务去查询消息.</p> <p>总的来说, <strong>四种方案都有人用, 选择的依据在于对成本和可靠性的考量</strong>. 第一, 二种用得比较多, 比如 RocketMQ 和 RabbitMQ 就是用的第二种. 个人也<strong>推荐内置主题的形式</strong>, 因为复用了消息队列的缓冲和存储的能力, 性能较高, 也适合远程的分布式采集. 最主要的是不依赖第三方系统, 在私有化部署或者独立部署的过程中, 可以完成组件内的闭环.</p> <h6 id="持久存储引擎的选择"><a href="#持久存储引擎的选择" class="header-anchor">#</a> 持久存储引擎的选择</h6> <p>持久存储引擎存在的意义就是高可靠, 长期地保存轨迹数据, 并提供所需要的数据检索能力. 所以对于引擎, 有三个要求: <strong>数据不能丢</strong>, <strong>能长期保留数据</strong>, <strong>具备检索能力</strong>.</p> <p>业界主流的存储引擎有不少. 从数据可靠性来看, 这些引擎都具备高可靠存储的能力, 也具备长期保留数据的能力. 因为消息轨迹在检索方面的需求相对比较固定, 主要是根据消息 ID 或时间+消息 ID 进行精准查询, 基本所有的存储引擎都可能满足条件.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e93e78ddb28090845ba795a7bf7bca9c-20240421231949-94dub0t.jpg" alt=""></p> <p><strong>那一般怎么选呢</strong>? 你可能会想, 很简单啊, 选 ElasticSearch, ES 本身就是很强大且通用的搜索引擎, 访问方便, 性能也很高, 检索能力强大.</p> <p>回答是没错的, 大部分情况下选择都是用 ES. 但是 ES 的缺点也很明显, 前面说了它的<strong>存储放大严重, 很占磁盘空间, 会导致成本较高</strong>.</p> <p>在我看来, 除了技术上的功能, 性能层面的选择, 成本也是一个非常重要的因素. 因为在大规模集群的消息轨迹的架构设计中, 成本是一个非常重要的选项. <strong>如果业务流量较低, 轨迹数据较少, 用 ES 很合适</strong>, 因为功能和性能都满足要求, 成本也不会有太大压力.</p> <p>但是, 在大规模的集群(比如几万台节点)运营中, 更多在权衡的不是功能和性能, 而是如何在<strong>功能, 性能, 稳定性, 成本</strong>四个点之间取得平衡. 思考的路径一般是 <strong>可以牺牲一部分的功能, 性能或稳定性, 在满足基本需求的基础上, 尽量降低成本</strong>.</p> <p>而且因为数据规模不同, 公司常用存储引擎不一样, 也有的会用 <strong>ClickHouse</strong>, HBase 等引擎存储轨迹数据. 从消息轨迹的业务上来看, 功能都是满足的, 从成本来看, 主要看数据规模. 所以, 在引擎选择上, 并没有定性的结论, 但是 ES 还是最普遍的.</p> <h5 id="rabbitmq消息轨迹方案设计实操"><a href="#rabbitmq消息轨迹方案设计实操" class="header-anchor">#</a> RabbitMQ消息轨迹方案设计实操</h5> <p>了解了具体的技术选型, 回过头看 RabbitMQ 消息轨迹的案例, 我分享一下我的方案和思考点, 整体流程分为五步.</p> <p>​<img src="/img/4e85e4c06306993919bba3f749dd3a5f-20240421231949-un25hlc.jpg" alt="">​</p> <ol><li><strong>存储引擎选择</strong>: 消息查询需要支持多维度查询和模糊查询, 只有几百个节点且主要承载业务消息, 所以整体的轨迹数据量预期不会太大, 加上成本限制不是特别严重, 我会<strong>选择 ES 当存储引擎</strong>.</li> <li><strong>客户端轨迹记录</strong>: RabbitMQ 无法记录客户端(Produce 和 Consumer)的轨迹, 我会单独<strong>提供一套 SDK 实现集成轨迹的发送逻辑, 把数据发送到 RabbitMQ 集群中的 amq.rabbitmq.trace 中</strong>.</li> <li><strong>服务端轨迹记录</strong>: RabbitMQ 内核已经实现了轨迹的功能. 只要打开 Trace 开关, 就能把生产接收的时间和消费拉取的时间等数据写入到名为 amq.rabbitmq.trace 的 Exchange 中, 无需重复开发.</li> <li><strong>实现轨迹数据存储</strong>: 当记录完轨迹后, 可以开发一个客户端去消费集群中的 Trace Queue, 消费完数据往 ES 存储.</li> <li><strong>轨迹查询</strong>: 轨迹查询平台查询轨迹的时候, 直接通过 HTTP Rest 访问 ES 的接口查询轨迹数据即可.</li></ol> <p>这个方案比较简单务实. 不过 RabbitMQ 的 Queue 堆积太多数据, 可能会造成集群压力较大, 导致不稳定.</p> <p>所以如果想在 &quot;实现轨迹数据存储&quot; 这一步保证消费的性能, 也可以直接<strong>把数据写入到本地文件</strong>, 然后通过 <strong>Filebeat, Fluend</strong> 等采集器把数据采集到 ES. 这种方案相比直接发送 ES, 消费速度更快, Trace Queue 基本不会有堆积.</p> <h5 id="分享一个大集群的实际案例"><a href="#分享一个大集群的实际案例" class="header-anchor">#</a> 分享一个大集群的实际案例</h5> <p>RabbitMQ 的方案设计, 集群比较小, 实际工作时集群规模都比较大, 所以这里也想分享一个对应的实际案例, 蛮实用的, 也很有意思.</p> <p>在现网大规模集群的轨迹架构中, 因为节点数非常多, 轨迹数据非常大, 全部集群数据加起来接近 PB 级, 如果存储到 ES 进行查询, 成本会爆炸.</p> <p>为了极限降低成本, 我们曾经实现一个<strong>内部的消息轨迹查询</strong>功能. 用的是服务端保存轨迹数据的第四种方案, 把轨迹数据写入到本地文件, 按时间分段存储, 配置了本地文件的清理策略, 比如只保留最近十天, 然后在节点上起一个 HTTP Server, 接收轨迹关键字比如轨迹 ID, 最后通过执行 Linux 原生的 grep 命令检索本地文件, 查询起来性能还是可以的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fc9f34874fb7740f05345ec3ccf96d88-20240421231949-j5wyf00.jpg" alt=""></p> <p>这个方案因为利用了 Linux 原生的 grep 字符串匹配能力, 加上一般情况下, 消息队列 Broker 的本地磁盘容量都会有一定的冗余, 所以几乎零成本实现了消息轨迹.</p> <h5 id="总结-22"><a href="#总结-22" class="header-anchor">#</a> 总结</h5> <p>消息轨迹记录了消息从生产到消费完成或消费失败的整个生命周期. <strong>从轨迹中, 可以看到生产时间, 服务端收到数据的时间, 进入延时队列, 消费成功或者进入死信队列时间等等</strong>. 有了消息轨迹, 就可以完美定位消息丢失的问题.</p> <p>在小规模集群的运营过程中, 将 ES 当做存储引擎是比较常用的方案. 在数据非常少的场景中, 有时候 MySQL 也可以当作存储引擎. 业界的 <strong>ClickHouse, HBase</strong> 也可以作为存储引擎的备选方案.</p> <p>在大规模的集群运营中, 从方案选择上来看, 不能只关注技术层面的功能和性能, 更重要的是需要关注成本. 如果成本非常严苛, 可以选择适当牺牲功能和性能, 以降低成本. 有时候适当牺牲, 可以降低相当大比例的成本.</p> <h5 id="思考题-19"><a href="#思考题-19" class="header-anchor">#</a> 思考题</h5> <blockquote><p>在 RabbitMQ 的消息轨迹方案设计中, 如果调整 1 和 5 的条件, 数据量变为非常大, 而成本需要尽量控制, 你会如何设计方案呢?</p></blockquote> <p>首先, 我会先拉起讨论, 看消息查询的功能是否可以简化, 比如是否可以简化为只根据消息 ID 查询. 根据消息 ID 查询有一个前提, 因为 RabbitMQ 的消息 ID 不是必传的, 如果要根据消息 ID 查询, 就需要在客户端封装的时候, 默认生成一个唯一 ID.</p> <p>如果不能改变查询条件的话, 存储引擎的选择基本只能用 ES 了. 如果可以只根据 ID 查询, 在存储引擎的选择上就可以有很多选择, 比如 MongoDB, HBase.</p> <p>接下来就需要尽量精简轨迹内容, 极端情况下, 只保留消息 ID, 类型(Produce, Consume), 记录时间三个字段, 就可以满足排障功能了.</p> <p>如果需要进一步压缩成本, 可以把轨迹存在本地硬盘, 利用本来空闲的空间, 使用 grep 实现查询检索的功能.</p> <h4 id="_23-从集群角度拆解rabbitmq的架构设计与实现"><a href="#_23-从集群角度拆解rabbitmq的架构设计与实现" class="header-anchor">#</a> 23-从集群角度拆解RabbitMQ的架构设计与实现</h4> <p>在进阶篇, 首先分析了消息队列集群中哪些地方可能存在性能瓶颈和可靠性风险, 然后依次讲解了集群构建, 数据一致性, 数据安全, 集群可观测性四大模块的设计和选型思路. 同时也分享了一些 Java 在开发存储系统过程中的编码技巧.</p> <p>接下来围绕着进阶篇的内容, 用<strong>四节课分别讲一下消息方向的 RabbitMQ, RocketMQ 以及流方向的 Kafka, Pulsar 在这几个方面的实现</strong>. 另外也可以先复习下第 10～13 讲, 有助于更好更完整地理解内容.</p> <p>那么这节就先来讲一下 RabbitMQ, 从集群构建的设计思路开始.</p> <h5 id="集群构建"><a href="#集群构建" class="header-anchor">#</a> 集群构建</h5> <p>前面讲过, 集群构建由 <strong>节点发现</strong> 和 <strong>元数据存储</strong> 两部分组成. RabbitMQ 也是一样的实现思路.</p> <p>在节点发现方面, RabbitMQ 通过<strong>插件化</strong>的方式支持了多种发现方式, 用来满足不同场景下的集群构建需求. 如下图所示, 主要分为 <strong>固定配置发现, 类广播机制发现, 第三方组件发现, 手动管理</strong> 等 4 种类型, 以及固定配置, DNS, AWS(EC2), Kubernetes, Consule, etcd, 手动管理等 7 种<strong>发现方式</strong>.</p> <p>​<img src="/img/78ceyy4c08aaf07bea5494ebcb42afda-20240421231949-6xj0mz5.jpg" alt="">​</p> <ul><li><strong>固定配置发现</strong>: 是指通过在 RabbitMQ 的配置文件中配置集群中所有节点的信息, 从而发现集群所有节点的方式. 和 ZooKeeper 的节点发现机制是一个思路.</li> <li><strong>类广播机制发现</strong>: 是指<strong>通过 DNS 本身的机制解析出所有可用 IP 列表, 从而发现集群中的所有节点</strong>. 和 Elasticsearch 通过多播来动态发现集群节点是类似的思路.</li> <li><strong>第三方组件发现</strong>: 是指通过多种第三方组件发现集群中的所有节点信息, 比如 <strong>AWS(EC2), Kubernetes, Consul, etcd</strong> 等. 和 Kafka, Pulsar 依赖 ZooKeeper, RocketMQ 依赖 NameServer 是一个思路.</li> <li><strong>手动管理</strong>: 是 RabbitMQ 比较特殊的实现方式, 是指通过命令 rabbitmqctlctl 工具往集群中手动添加或移除节点. 即依赖人工来管理集群, 这种方式使用起来不太方便, 其他消息队列很少采用这个方案.</li></ul> <p>再来看一下元数据存储, 之前说到过, RabbitMQ 的元数据是通过内置数据库 Mnesia 来存储的. 这里需要重点注意的是, Mnesia 是一个分布式的数据库, 可以简单理解为它是 Erlang 语言自带的内置的分布式数据库. 这点非常重要, 因为 Mnesia 已经是分布式存储了, 所以在进程启动就具备了元数据存储能力.</p> <p>RabbitMQ 基于 Erlang 开发的一个好处就是, <strong>相当于天生自带了一个 Kafka KRaft 构建的元数据存储服务</strong>. 基于这个前提, 再去思考整个集群的构建过程, 就会比较容易理解 RabbitMQ 的集群构建思路.</p> <p>接下来看看 RabbitMQ 集群维度的数据可靠性.</p> <h5 id="数据可靠性"><a href="#数据可靠性" class="header-anchor">#</a> 数据可靠性</h5> <p>RabbitMQ 集群维度数据可靠性的核心是 <strong>副本和数据一致性协议</strong>. 在之前的课程中知道 RabbitMQ 没有 Topic, 只有 Queue 的概念. 所以是通过在 Queue 维度创建副本来实现数据的高可靠.</p> <p>比较特殊的是, RabbitMQ 在创建 Queue 时没有副本概念, 即创建出来的 Queue 都是<strong>单副本</strong>的. 如果要支持多副本, 在 3.8.0 之前需要通过配置镜像队列来实现, 在 3.8.0 后可以使用 Quorum Queue(仲裁队列)来实现.</p> <p>所以从集群维度看, <strong>RabbitMQ 的数据可靠性是由镜像队列和仲裁队列来保证的</strong>. 因为在 RabbitMQ 3.8.0 之前, 这是数据可靠的唯一手段.</p> <h6 id="镜像队列"><a href="#镜像队列" class="header-anchor">#</a> 镜像队列</h6> <p>在 RabbitMQ 中, 镜像队列是一个独立的功能. 它通过为 Queue 创建副本, <strong>完成主从副本之间数据同步, 维护主从副本之间数据的一致性等 3 个手段来保证数据的可靠性</strong>.</p> <p>队列的副本数量是通过 All, Exactly, Nodes 3 种策略来设置的.</p> <ul><li>All 是指集群中所有节点上都要有这个 Queue 的副本.</li> <li>Exactly 是指 Queue 的副本分布在几个节点上, 可以理解成 Queue 的副本数.</li> <li>Nodes 是指这个 Queue 的副本具体分布在哪几个节点上.</li></ul> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bc0252d52e36a063b41e48f1ce51a713-20240421231949-024gbvk.jpg" alt=""></p> <p>通过指定这三个策略, 用户可以<strong>控制副本数量和副本的分布</strong>. 在其他队列的实现中, 一般会在创建队列时指定副本数, 然后内核根据当前的分区和副本信息, 以节点之间的负载均衡为目标, 自动算出副本的分布, 然后创建副本. 而 RabbitMQ 把这个过程, 通过策略的形式让用户来选择, 更加灵活的同时, 用户的使用成本也会更高.</p> <p>RabbitMQ 的镜像队列是通过内核中的 GM 模块将数据分发到从副本, 从而完成主从副本之间的数据同步. GM 模块能保证组播数据的原子性, 即保证数据要么能发送到所有模块上, 要么不能.</p> <p>副本间数据一致性策略, 使用的是强一致的策略. <strong>从性能上来看, 这个强一致的策略也是影响性能的一个重要原因</strong>.</p> <p>总结来说, 镜像队列在实现上有同步和性能上的缺陷, 主要体现在以下三点:</p> <ol><li>强一致的同步策略很影响性能, 导致集群的性能不高.</li> <li>当节点挂掉后, 节点上的队列数据数据都会被清空, 需要重新从其他节点同步数据.</li> <li>队列同步数据时会阻塞整个队列, 导致队列不可用. 如果数据量很大, 同步时间长会导致队列长时间不可用.</li></ol> <p>所以, 3.8.0 以后, RabbitMQ <strong>用仲裁队列替代了镜像队列</strong>来解决这些问题.</p> <h6 id="仲裁队列"><a href="#仲裁队列" class="header-anchor">#</a> 仲裁队列</h6> <p>从实现的角度看, 仲裁队列是<strong>基于 Raft 算法</strong>来设计的, 依赖 Raft 共识协议来确保数据的一致性和可靠性.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/47d4c6b6d445ced517be56454954ed2d-20240421231949-sf6x78n.jpg" alt=""></p> <p>如上图所示, <strong>仲裁队列是主从模型, 至少得有三个副本</strong>. 通过主副本和多个从副本之间的数据同步, 来实现数据的高可靠. 队列会选举出主副本来实现数据的读写, 当主副本不可用, 会根据算法从副本中选举出新的主副本.</p> <p>和镜像队列不同的是: <strong>当副本挂掉重新启动时, 只需要从主节点同步增量数据, 并且不会影响主副本的可用性, 从而避免了镜像队列的缺点</strong>.</p> <p>在数据一致性方面, 仲裁队列通过 Raft 协议来完成副本间的数据同步和一致性.</p> <p>使用的是多数原则, 即多数副本写入成功后, 就算数据写入成功. 因为一个集群需要超过一半的节点可以工作, 所以一个集群至少需要 3 个节点. 当有 3～4 个节点时, 只能允许一个节点损坏; 当有 5 个节点时, 允许两个节点损坏, 以此类推. 对于大于 5 个节点的仲裁队列, 性能会下降很多, 原因就是需要超过 3 个节点拿到数据才算写入成功.</p> <p>整体来看, <strong>RabbitMQ 的仲裁队列和 ZooKeeper 的 Zab 协议, Pulsar 的一致性协议是一样的, 通过遵循多数原则来保证一致性</strong>. 更多的仲裁队列细节, 可以参考官方文档 <a href="https://www.rabbitmq.com/quorum-queues.html" target="_blank" rel="noopener noreferrer">quorum-queues<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h5 id="安全控制"><a href="#安全控制" class="header-anchor">#</a> 安全控制</h5> <p>接下来看看 RabbitMQ 的安全机制. 在安全篇讲到, 消息队列的安全的核心分为<strong>传输加密, 认证, 鉴权</strong> 3 个方面. 下面也从这 3 个方面来分析一下 RabbitMQ.</p> <h6 id="传输加密"><a href="#传输加密" class="header-anchor">#</a> 传输加密</h6> <p>在传输加密方面, RabbitMQ 内置了对 TLS 的支持, <strong>通过 TLS 来实现数据的加密传输</strong>.</p> <p>从内核实现的角度来看, 内核对 TLS 的支持是根据 TLS 的官方标准实现的. TLS 是通用的加密通信标准, 消息队列对于 TLS 来说只是一个使用者. 代码实现的方式对于所有消息队列或者所有组件都是一样的, 内核直接通过官网标准文档集成这部分能力即可. 比如 <strong>Java 写的服务端需要支持 TLS</strong>, 可以参考 <a href="https://snyk.io/blog/implementing-tls-in-java/" target="_blank" rel="noopener noreferrer">Implementing TLS in Java<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p><strong>从使用的角度来看, 需要先创建证书, 然后在服务端配置 TLS 相关信息来启用传输加密. 客户需要配置公钥等信息来和服务端创建加密的连接</strong>.</p> <p>在 RabbitMQ 中支持 TLS, 如下图所示, 主要有以下两种形式:</p> <ul><li><strong>直接配置 RabbitMQ 支持 TLS</strong>.</li> <li><strong>在代理或者负载均衡(如 HAProxy)上配置支持 TLS</strong>.</li></ul> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c7d7ea9c5fb07ff866702feb8faaecc3-20240421231949-571psg5.jpg" alt="">​</p> <p>从安全的角度来看, 两种选择并没有太明显的优劣势. 在 RabbitMQ Broker 中, 当启动 TLS 后, 服务端需要指定一个新的端口来支持 TLS. 即支持 TLS 和不支持 TLS 的服务端口是不一样的.</p> <h6 id="身份认证"><a href="#身份认证" class="header-anchor">#</a> 身份认证</h6> <p>当客户端连接到 RabbitMQ Broker 时, 必须先进行身份认证, 才能进行后续的操作.</p> <p>当前版本的 RabbitMQ 主要支持用户名/密码认证和 X.509 证书两种认证形式. 同时通过插件化机制, 支持了 LDAP 认证, HTTP 接口认证, IP 来源认证等认证方式.</p> <p>从具体实现的角度, RabbitMQ 基于 SASL 认证框架, 实现支持了 PLAIN, AMQPPLAIN, EXTERNAL 三种机制.</p> <ul><li>PLAIN 和 AMQPPLAIN 就是用户名/密码这种明文形式的认证.</li> <li>EXTERNAL 是指插件化支持多种认证形式, 比如 LADP, X.509, IP 范围认证就是以这种方式实现的. 可以参考官方文档 <a href="https://www.rabbitmq.com/access-control.html" target="_blank" rel="noopener noreferrer">RabbitMQ 权限控制<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</li></ul> <p><strong>在认证配置上, RabbitMQ 支持链式认证</strong>. 即同时支持多种认证方式, 比如在某些高安全要求的场景, 需要完成多重身份认证才算认证成功, 就可以用到链式认证.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6aa89a963246c66edecdb93bf334b103-20240421231949-b74u3zt.jpg" alt=""></p> <p>如上图所示, 需要同时完成 IP 来源认证, LDAP 认证, 用户名密码认证三重认证才算认证通过. 这种链式的认证方式的好处是, 可以满足多种场景, 一般主流消息队列同时只能支持其中的一种认证方式, 所以在认证配置的实现上, RabbitMQ 做得蛮好的.</p> <h6 id="资源鉴权"><a href="#资源鉴权" class="header-anchor">#</a> 资源鉴权</h6> <p>接下来看看资源鉴权. <strong>RabbitMQ 的鉴权分为管理页面和数据流两个方面</strong>.</p> <p>管理页面指启用 Management 插件后的 Manager 页面. 这个页面可以执行查看监控, 创建资源, 删除资源等操作, 权限很大. 所以为了保证集群的安全, 需要对这个页面的访问进行<strong>权限控制</strong>. 管理页面的 UI 如下所示:</p> <p>​<img src="/img/8387d7f7c521fc39fd0fab41c4bde542-20240421231949-asjty3y.png" alt="">​</p> <p>Manager 页面权限控制的方式是, 在创建用户时通过指定不同用户的访问角色类型, 从而控制不同用户在管理页面上的操作权限. Manager 页面支持 management, policymaker, monitoring, administrator 四种角色类型, 分别表示不同的权限粒度, 算是一个比较常规的管控页面的权限控制实现方式.</p> <p>数据流的权限控制, 主要包括资源操作(如创建, 创建等), 写入, 读取三种类型, 分别对应 Configure, Write, Read 三种权限. 主要支持对 Vhost 和 Exchange 两种资源进行鉴权.</p> <h5 id="可观测性"><a href="#可观测性" class="header-anchor">#</a> 可观测性</h5> <p>RabbitMQ 的可观测性主要由<strong>监控, 健康检查, 日志和消息轨迹</strong>四个部分组成, 先来看看监控指标.</p> <p>整体来看, RabbitMQ 的监控指标非常丰富且立体, 如下图所示, 主要可以分为集群, 节点, 队列, 应用程序四个维度.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/92865318050b53d2da31513e6a1212a0-20240421231949-gzzetiy.jpg" alt=""></p> <ul><li><strong>集群维度</strong>: 主要包含集群的监控指标, 比如 Exchange 数, Queue 数, Channel 数, 生产者数, 消费者数等等.</li> <li><strong>应用程序维度</strong>: 主要包含进程级的监控信息, 比如 Socket 连接打开率, Channel 打开率等等.</li> <li><strong>队列维度</strong>: 主要包含队列的监控指标, 比如队列上的消息总数, 未确认的消息总数等等.</li> <li><strong>节点维度</strong>: 主要包含节点的信息, 比如硬件层面的 CPU, 内存, 硬盘, 操作系统层面的 Socket 连接数, 文件描述符数量, Erlang 虚拟机层面的 Erlang 线程数, GC 情况等等.</li></ul> <p>从现网运营经验来看, 只要熟悉了这些指标的含义, 基本就可以解决现网各种常见故障. 如果想了解完整的指标信息, 可以参考 <a href="https://www.rabbitmq.com/monitoring.html#rabbitmq-metrics" target="_blank" rel="noopener noreferrer">RabbitMQ Metrics<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>在指标暴露方面, RabbitMQ 提供了 <strong>Prometheus + Grafana, HTTP API, 命令行工具</strong>等多种方式. 默认情况下, 官方推荐使用 <strong>Prometheus + Grafana</strong> 的方式, 所以在现网的使用中, 大部分也是使用 Prometheus + Grafana 来完成监控指标的采集.</p> <p>在某些和内部监控系统或者运营系统集成的场景中, 通过 HTTP API 获取监控指标也是常用的方式. 在现网排查问题时, 直接使用命令行工具 rabbitmq-diagnostics 或 rabbitmq-top 来查看负载, 也是非常常用的. 下图就是通过 rabbitmq-top 命令行来查看进程监控的结果, 非常齐全.</p> <p>​<img src="/img/8e756488b86ccbedb4843a95fb12ecca-20240421231949-l4r7e6z.png" alt="">​</p> <p>同时, RabbitMQ 因为其历史悠久, 应用广泛, 很多商业化或者开源的监控组件都天然支持和它集成, 比如 Zabbix, DataDog, AWS CloudWatch 等. 所以, 从指标的暴露方式来看, RabbitMQ 做得非常好, 非常完整, 能满足各个环境下的部署和监控运维需求.</p> <p>值得一提的是, <strong>RabbitMQ</strong> <strong>内核自带了健康检查机制</strong>. 即支持通过命令行工具(rabbitmq-diagnostics)或 HTTP API 的方式对集群发起健康检查. 检查集群的创建 Exchange, 创建 Queue, 生产消费消息全流程是否正常.</p> <p>这个拨测机制是非常有用的, 因为在现网集群运行中, 监控指标只是二级信息, 不能直接表达出集群是否有异常. 有可能监控指标异常, 但集群运行正常, 相反集群运行异常, 监控指标可能正常. 所以, 通过模仿客户端的实际行为, 比如先创建资源, 生产数据, 消费数据的全流程, 可以更加精准地发现集群是否有问题. 在具体使用上, 如果想了解更多的健康检查信息, 还可以看 <a href="https://www.rabbitmq.com/monitoring.html#health-checks" target="_blank" rel="noopener noreferrer">RabbitMQ Health Chcek<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>RabbitMQ 的日志模块跟其他组件的日志模块差不多, 它支持多种类型, 多种级别的日志记录. 也支持将不同类型的日志打印到不同的文件, 比如 Connection, Channel, Upgrade, Queue 等等. 同时也支持按时间, 大小保留滚动文件. 如果需要了解更多日志配置的细节, 可以参考 <a href="https://www.rabbitmq.com/logging.html" target="_blank" rel="noopener noreferrer">RabbitMQ Logging<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>RabbitMQ 对消息轨迹的支持, 前面已经讲过, 这里就不展开说了, 可以去回顾下.</p> <h5 id="总结-23"><a href="#总结-23" class="header-anchor">#</a> 总结</h5> <p>在集群构建方面, RabbitMQ 通过 Erlang 自带的分布式数据库 Mnesia 来实现元数据信息的存储. 通过插件的形式支持多种节点发现机制, 主要包括<strong>固定配置发现, 类广播机制发现, 第三方组件发现, 手动管理</strong>四种类型.</p> <p>集群构建完成后, RabbitMQ 通过副本机制, 镜像队列或仲裁队列来实现数据的一致性和可靠存储. 镜像队列因为本身的一些架构缺陷, 会逐步被仲裁队列替换. 仲裁队列是基于 Raft 算法来实现的, 写入的可靠性遵循多数原则, 即只要多数节点写入成功就可以.</p> <p>在安全管控方面, RabbitMQ 通过传输加密, 身份认证, 资源鉴权三个维度来保证数据安全. 传输加密主要支持 TLS, 同时支持多种身份认证机制, 比如用户名/密码, LDAP 等. 资源鉴权支持对 Vhost, Exchange 两种资源进行鉴权, 权限分为配置, 写入, 读取三种.</p> <p>在可观测方面, RabbitMQ 内核提供了丰富的多维度的监控指标, 并提供了多种指标采集方式. 官方推荐 Prometheus + Grafana 来实现集群监控. RabbitMQ 在内核支持了健康检查机制, 健康检查是及时发现集群问题的一个非常好用的方法.</p> <p>RabbitMQ 原生不支持消息轨迹的功能, 但可以基于 Firehose 插件来扩展支持消息轨迹的功能.</p> <h5 id="思考题-20"><a href="#思考题-20" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为什么 RabbitMQ 支持多种节点发现机制, 其他的消息队列却不支持? 为什么 RabbitMQ 支持手动通过命令行来完成节点发现?</p></blockquote> <p>这两个问题的核心都是因为有 Mnesia 的存在.</p> <p>因为有 Mnesia, RabbitMQ 就不需要依赖第三方组件来完成元数据存储, 因此就只需要能找到集群中的其他所有节点就可以了. 节点发现就只需要发现节点, 而不需要考虑后续的数据存储. 因此在开发实现层面会更简单, 实现插件机制也更方便. 只要能及时发现集群中的节点变更, 然后再变更 Mnesia 中的信息就可以了.</p> <p>因为有 Mnesia, 手动操作完节点后, 就相当于完成了节点发现, 节点信息可以直接保存在 Mnesia 数据库中, 此时所有的节点就可以在自身的 Mnesia 数据库中看到集群的所有节点, 算是另一种形式的节点发现.</p> <h4 id="_24-从集群角度拆解rocketmq的架构设计与实现"><a href="#_24-从集群角度拆解rocketmq的架构设计与实现" class="header-anchor">#</a> 24-从集群角度拆解RocketMQ的架构设计与实现</h4> <p>上节讲完了 RabbitMQ, 今天继续来看看同样是消息方向的 RocketMQ 在集群构建, 部署形态, 数据可靠性, 安全控制, 可观测性等五个方面的设计实现.</p> <h5 id="集群构建-2"><a href="#集群构建-2" class="header-anchor">#</a> 集群构建</h5> <p>首先还是从<strong>元数据存储和节点发现</strong>两个方面来分析一下 RocketMQ 的集群构建.</p> <p>在前面的课程中知道 RocketMQ 的元数据是存储在 NameServer 中. 严格意义上来说, 这个说法是不对的.  <strong>RocketMQ 的元数据实际是存储在 Broker 上, 不是直接存储在 NameServer 中</strong>. NameServer 本身只是一个缓存服务, 没有持久化存储的能力, 先来看一张图示.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f1488df73a06ac0735e5b927b233df87-20240421231949-f79avvz.jpg" alt="">​</p> <p>如上图所示, 元数据信息实际存储在每台 Broker 上, 每台 Broker 会在本节点维护持久化文件来存储元数据信息. 这些元数据信息主要包括节点信息, 节点上的 Topic, 分区信息等等. <strong>在 Broker 启动时, 会先连接 NameServer 注册节点信息, 并将保存的元数据上报到所有 NameServer 节点中</strong>. 此时所有 NameServer 节点就有全量的元数据信息了, 从而完成了节点之间的发现.</p> <p>从原理来看, <strong>RocketMQ 是基于第三方组件 NameServer 来完成节点发现的. 即通过上报节点信息到一个中央存储, 从而发现集群中的其他节点</strong>.</p> <p>Broker 和 NameServer 之间会有 <strong>保活机制</strong>, Broker 会定期和 NameServer 保持心跳探测, 来确认节点运行正常. 当 Broker 异常时, 就会被踢出集群.</p> <p>跟 RabbitMQ 不同的是, RocketMQ 发展至今, 其集群部署形态经历了多次大的升级. 为了更好地理解数据可靠性, 需要先理解 RocketMQ 的各种部署形态以及它们想解决的问题. 主要有 Master/Slave, DLedger, Controller 三种部署模式. 下面先来看一下 Master/Slave 模式.</p> <h5 id="部署模式"><a href="#部署模式" class="header-anchor">#</a> 部署模式</h5> <h6 id="master-slave模式"><a href="#master-slave模式" class="header-anchor">#</a> Master/Slave模式</h6> <p>Master/Slave 模式就是典型的<strong>主从架构</strong>, 和 MySQL 的主从原理一样.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f9dd399c23e5c4296f7799f69ba7d808-20240421231949-5xeya73.jpg" alt=""></p> <p>如上图所示, 集群部署时会先配置 Broker 是 Master 节点还是 Slave 节点. <strong>Master 负责写入, Slave 负责备份和读取</strong>. 早期架构是不支持主从切换的, 即当 Master 挂了以后, Slave 无法成为 Master. 此时会导致一些只能在 Master 上完成的工作无法完成, 比如数据写入, Offset 操作, 结束事务等等.</p> <p>所以在创建 Topic 时, <strong>会建议在多个 Master 节点上同时创建这个 Topic 及其所有分区</strong>, 来看下图:</p> <p>​<img src="/img/e484c501c48718f340039d1d420131ef-20240421231949-tl1fqfj.jpg" alt="">​</p> <p>如上图所示, 所有的 Master 节点都可以同时为这个 Topic 提供服务. 当某个 Master 节点挂了后, 其他 Master 节点依旧可以提供同样的服务, 不影响新数据的写入. 这种方式的好处是当负载过高时, 可以通过快速横向添加节点来扩容. 缺点是这个模型无法保证生产的消息的有序. 节点挂了以后, 这个节点上的未消费的数据不能被消费, 并且 Topic 和分区数会有放大效应. 因为每个节点上都需要创建全量的 Topic 和分区, 此时瓶颈就存在单个节点上了.</p> <p>既然有 Slave 的存在, 理论上当 Master 故障后, Slave 就需要接替 Master 继续提供服务. 所以<strong>为了解决 Master/Slave 的主从切换问题, RocketMQ 引入了 DLedger 来完成这个事情</strong>.</p> <h6 id="dledger模式"><a href="#dledger模式" class="header-anchor">#</a> Dledger模式</h6> <p><strong>DLedger 模式是为了解决分区选主和主从切换问题而引入的</strong>. 因为如果要实现主从切换, 就需要先<strong>保证主从之间数据的一致性, 所以 DLeger 的核心是通过 Raft 算法实现的 Raft Commitlog</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0fc5f08f1c15281b004c0dff47abe2e3-20240421231949-i5c894k.jpg" alt=""></p> <p>如上图所示, Dledger 用<strong>基于 Raft 算法实现的 Raft Commitlog 代替了原来的 Commitlog, 使得 Commitlog 具备了选举和切换的能力</strong>.</p> <p>因为是基于 Raft 算法实现的, 所以根据 Raft 算法的多数原则, <strong>集群最少必须由三个节点来组成</strong>. 不同节点的 Raft Commitlog 之间会根据 Raft 算法来完成数据同步和选主操作. <strong>当 Master 发生故障后, 会先通过内部协商, 然后从 Slave 节点中选出新的 Master, 从而完成主从切换</strong>.</p> <p>因为实现方式的原因, Deledger 模式最少需要三个节点, 并且无法兼容 RocketMQ 原生的存储和复制能力(比如 Master/Slave 模式), 而且这个模式维护较困难. 所以为了解决这几个问题, <strong>RocketMQ 将 DLedger(Raft)能力进行上移, 重新实现了选主组件 DLedger Controller, 这就是 RocketMQ 的 Controller 模式, 也叫做 DLedger Controller 模式</strong>.</p> <h6 id="controller模式"><a href="#controller模式" class="header-anchor">#</a> Controller模式</h6> <p>DLedger Controller 是一个新的部署形态, 它的核心是<mark><strong>基于 Raft 算法实现了一个选主组件 Controller. Controller 主要用来在副本之间进行 Leader 选举和切换</strong></mark>. 它是集群部署的, 多个 Controller 之间是通过 Raft 算法来完成主 Controller 选举的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f94ec4a7d51da220434cfde9c9a48a00-20240421231949-3ajr9nk.jpg" alt=""></p> <p>如上图所示, Controller 模式跟 Dledger 模式最大的差别在于, <strong>Controller</strong> <strong>是一个可选的, 松耦合的组件, 可以选择内嵌在 NameServer 中, 也可以独立部署</strong>. 而且它和底层存储的 Commitlog 模块是独立的, 即存储模块不一定非得是 Raft Committlog, 也可以是 Commitlog. 所以 Controller 可以用在 Master/Slave 模式中, 当部署 DLedger Controller 组件后, 原本的 Master-Slave 部署模式下的 Broker 组就拥有了容灾切换能力.</p> <p>Controller 主要由 Active Controller, Alter SyncStateSet, Elect Master, Replication 四个部分组成.</p> <ul><li>Active Controller 是指通过 Raft 算法在多个 Controller 之间选举会选出的主 Controller.</li> <li>Alter SyncStateSet 指分区副本中允许选为 Master 的副本集合.</li> <li>Elect Master 指分区副本间选主操作.</li> <li>Replication 指分区副本间的数据复制的动作.</li></ul> <p>从运行机制上看, 首先会<strong>通过 Raft 算法选举出主 Controller</strong>. 主 Controller 会维护每个分区可用的 SyncStateSet 集合. 当节点变动时, Elect Master 会在从 SyncStateSet 集合中选举出新的主节点. 主从副本间的数据通过 Replication 模块来完成.</p> <p>如果以前有了解过 Kafka, 会发现 RocketMQ 的 Controller 模式和 Kafka 架构是非常像的, 都维护了一个分区粒度的可用副本的集合, 然后通过 Controller 来完成副本间的选主, 通过 Replication 模块来完成数据的同步.</p> <p>从设计思路上看, RocketMQ 的 Controller 模式跟前面提到的独立的 Metada Service 架构是一致的. 如下图所示, 如果把图中 Broker 上的 Controller 上移, 就是 RocketMQ Controller 的实现.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/de265236e7de626c227bccb8e430dfb1-20240421231949-zlh7jls.jpg" alt="">​</p> <p>了解了 RocketMQ 的三种主要部署模式, 接下来从<strong>副本, 选主, 数据一致性</strong>三个方面来分析一下 RocketMQ 的实现.</p> <h5 id="数据可靠性-2"><a href="#数据可靠性-2" class="header-anchor">#</a> 数据可靠性</h5> <p><strong>RocketMQ 也是通过多副本来提高数据可靠性的</strong>. 在不同部署模式中, 副本机制和数据一致性的具体实现也不一样. 这也是上面要先讲部署架构的原因.</p> <p>在 Master/Slave 模式中, RocektMQ 提供了<strong>异步复制和同步双写</strong>两种模式.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/cd4ac0fac830c6120ac0ea8dcb1431d6-20240421231949-m8rkezn.jpg" alt=""></p> <p>异步复制和同步双写就是对应前面讲到的同步和异步的复制方式, <strong>主要的区别是性能和数据可靠性</strong>.</p> <ul><li><strong>性能层面</strong>: 异步复制 &gt; 同步双写.</li> <li><strong>可靠性层面</strong>:  异步复制 &lt; 同步双写.</li> <li><strong>一致性层面</strong>: 同步双写是强一致, 异步复制是最终一致.</li></ul> <p>在 Dledger 模式中, 因为是基于 Raft 算法实现的 Commitlog. 所以在数据一致性上, 遵循的是 Raft 的 <strong>多数原则</strong>. 即数据最少得三副本, 同时得多数副本写入成功才算成功. 如下图所示, 比如总共 3 个副本需要写入 2 个,  5 个副本需要写入 3 个.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4b65431ff9276608a70761c52d5c3fb1-20240421231949-cm02ped.jpg" alt="">​</p> <p>Dledger 模式副本间数据同步是采用 <strong>同步写入</strong> 的方式, 即 Master 收到数据后, 同步将数据写入到副本, 多数副本写入成功后, 就算数据写入成功. 这个实现方式和 ZooKeeper 是一样的. 从一致性上来看, 这种方式属于最终一致.</p> <p>在 Controller 模式中, <strong>数据的一致性是可以配置的</strong>, 可以通过<strong>参数 inSyncReplicas 来配置数据写入成功的副本数</strong>. 比如 3 个副本且 inSyncReplicas 配置为 2, 表示写入 2 个副本时算数据写入成功; 配置为 1 则表示写入 1 个副本就算数据写入成功, 以此类推. 同时也提供了 allAckInSyncStateSet 参数, 来设置要全部写入成功才算成功.</p> <p><strong>Controller 模式的数据一致性策略和 Pulsar 的策略是一样的, 都是通过配置来调整一致性的级别</strong>. 同样的, Controller 模式副本间的数据同步也是属于同步写入的方式. 从一致性上来看, <strong>inSyncReplicas 属于最终一致性, allAckInSyncStateSet 属于强一致</strong>.</p> <h5 id="安全控制-2"><a href="#安全控制-2" class="header-anchor">#</a> 安全控制</h5> <p>接下来从传输安全, 认证, 鉴权展开看看 RocketMQ 的安全控制.</p> <p>在传输安全方面, RocketMQ Broker <strong>支持 TLS 加密传输</strong>. 从技术上看, RocketMQ Broker 也是使用标准 Java Server 集成 TLS 的用法来实现的. 代码实现上直接查看相关使用手册即可, 可以直接参考这个文档 <a href="https://snyk.io/blog/implementing-tls-in-java/" target="_blank" rel="noopener noreferrer">Implementing TLS in Java<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>从配置的角度来看, 如果 Broker 端需要启用 TLS 功能, 则需要先创建或购买证书, 然后在 Broker 上配置证书, 秘钥, 端口等信息. 在客户端访问时, 配置证书的相关信息即可. 下面是一个参考的配置:</p> <div class="language-yml line-numbers-mode"><pre class="language-yml"><code><span class="token comment"># Broker 端配置</span>
tls.test.mode.enable=false
tls.server.need.client.auth=require
tls.server.keyPath=/opt/certFiles/server.key
tls.server.keyPassword=123456
tls.server.certPath=/opt/certFiles/server.pem
tls.server.authClient=false
tls.server.trustCertPath=/opt/certFiles/ca.pem

<span class="token comment"># 客户端配置</span>
tls.client.keyPath=/opt/certFiles/client.key
tls.client.keyPassword=123456
tls.client.certPath=/opt/certFiles/client.pem
tls.client.authServer=false
tls.client.trustCertPath=/opt/certFiles/ca.pem

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>在认证方面, 当前版本的 RocketMQ 只支持一种明文(PLAIN)的用户名/密码认证方式. 即先从服务端申请 AccessKey(用户名)和 SecretKey(密码), 支持动态申请, 然后客户端通过配置<strong>传递 AccessKey 和 SecretKey 来完成身份认证</strong>. 同时 RocketMQ 分为管理员账户和普通账户, 管理员账户拥有集群的所有权限, 普通账户需要经过授权才能进行某些操作.</p> <p>在鉴权方面, <strong>RocketMQ 支持 Topic 和 Group 两种资源的鉴权</strong>. 权限分为 DENY, ANY, PUB, SUB 四个类型, 分别表示拒绝, 全部权限, 发送, 订阅. 同时也支持 IP 白名单的功能, 即支持对来源 IP 进行限制. 同样的, 也支持通过 RocketMQ 的命令行工具 mqadmin 动态增删用户及相关的权限信息, 比如通过 mqadmin 查询 ACL 信息.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>sh mqadmin clusterAclConfigVersion -n 192.168.1.2:9876 -c DefaultCluster
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>从底层实现看, <strong>用户和权限信息保存在 Broker 上的文件中</strong>, 并不是存储在某个中央服务上, 比如 NameServer.  <strong>这个设计也符合当前 RocketMQ 元数据存储的实现思路</strong>. 当变更信息时, 就修改文件的内容, Broker 会监听文件的变化, 重新加载全量信息.</p> <p>最后来看一下 Broker 端执行权限校验的主要步骤.</p> <ol><li><p>检查是否命中全局 IP 白名单, 如果是, 则认为校验通过; 否则走 2.</p></li> <li><p>检查是否命中用户 IP 白名单, 如果是, 则认为校验通过; 否则走 3.</p></li> <li><p>校验签名, 校验不通过, 抛出异常; 校验通过, 则走 4.</p></li> <li><p>对用户请求所需的权限和用户所拥有的权限进行校验, 通过就走后续逻辑, 不通过, 抛出异常. 用户所需权限的校验需要注意以下内容:</p> <ul><li>特殊的请求, 例如 UPDATE_AND_CREATE_TOPIC, 只能由 Admin 账户进行操作;</li> <li>对于某个资源, 如果有显性配置权限, 则采用配置的权限, 如果没有显性配置权限, 则采用默认的权限.</li></ul></li></ol> <h5 id="可观测性-2"><a href="#可观测性-2" class="header-anchor">#</a> 可观测性</h5> <p>接下来主要从<strong>指标, 日志, 消息轨迹</strong>三个维度来聊聊 RocketMQ 的可观测性. RocketMQ 在指标方面分为 5.0 之前和之后两个版本, 两个版本的实现方式都很大的不同.</p> <p>在 5.0 之前的版本中, <strong>指标的定义和记录是依赖一个 Broker 内部自定义实现的指标管理器 BrokerStatsManager 来实现的</strong>. 通过在内存中维护一个 Map 来记录不同的指标, 主要<strong>支持 Broker, Producer, Consumer Groups, Consumer 四个维度的指标</strong>. 指标暴露方式是通过 RocketMQ Export + RocketMQ Remoting 来实现的.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/423b492b794ef017fa0425c5fe450004-20240421231949-upi2c41.jpg" alt="">​</p> <p>如上图所示, Export 使用 Admin SDK 通过 Remoting 协议调用 Broker 获取指标数据. Export 会不断地从 Broker Pull 数据, 然后在内部进行整合, 再通过自身的 HTTP Service 的 /Metrics 接口暴露给 Prometheus 集成展示.</p> <p><strong>这种方式主要有 3 个缺点</strong>: Broker 指标定义不符合开源规范, 难以和其他开源可观测组件搭配使用; 大量 RPC 调用会给 Broker 带来额外的压力; 拓展性较差, 当需要增加或修改指标时, 必须先修改 Broker 的 Admin 接口.</p> <p>为了解决这些问题, RocketMQ 在 5.0 版本重构了指标模块. <strong>新版的 RocketMQ 基于 OpenTelemtry 规范完全重新设计实现了指标模块</strong>. 在指标数量方面, 新的指标模块在之前版本的基础上, 支持了更多维度, 更丰富的指标, 比如 Broker, Proxy 等.</p> <p>在指标定义记录方面, 选用兼容 Promethues 的 Counter, Guage, Histogram 等类型来完成指标的记录, 并且遵循 Promethues 推荐的指标命名规范.</p> <p><strong>在指标暴露方面, 新版的指标模块提供了 Pull, Push, Export 兼容三种方式</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/14f89157d0fe9969f25eddb35cd29e91-20240421231949-d59jut5.jpg" alt="">​</p> <p>如上图所示, Pull 模式主要与 Prometheus 兼容, 适合于运维 K8s 和 Promethues 集群的用户. 通过在 Broker 内核启动一个 HTTP Server, 暴露 /metrics 接口来给 Prometheus 拉取指标数据.</p> <p><strong>Push 模式是 OpenTelemetry 推荐使用的模式</strong>. 需要先部署 Collector 来接收传输指标数据. Broker 会主动将指标推送给对应的 Collector, 然后通过 Collector 来暴露指标. Collector 是 OpenTelemetry 规范推荐的使用方式.</p> <p><strong>Export 兼容是指兼容了当前 RocketMQ Export 的使用方式</strong>. 即现在使用 RocketMQ Export 的用户无需变更部署架构即可接入新 Metrics. 从实现来看, Export 获取指标数据的方式从早期的通过 Remoting 协议 Pull 数据, 换成了 Broker 根据 OpenTelemetry 规范将指标数据 Push 给 Export.</p> <p>RocketMQ 的底层的日志, 使用的是 Java 中标准的 Logback 和 SLF4J 日志框架进行日志记录, 因此日志就天然具备日志分级(ERROR, WARN, INFO 等), 日志滚动, 按大小时间保留等特性. 在日志格式定义方面, RocketMQ 通过独立的日志库来进行封装, 属于常见的标准用法.</p> <p>接下来看看消息轨迹. RocketMQ 的消息轨迹, 在我看来是消息队列里面支持得最好的了. 因为完整的消息轨迹需要包含生产者, Broker, 消费者三部分的信息, 如果需要支持生产端和消费端的轨迹信息, 就需要在客户端 SDK 中集成轨迹信息上报的功能. <strong>RocketMQ</strong> <strong>在生产端和消费端实现了这个功能, 而其他大部分消息队列在</strong> <strong>SDK</strong> <strong>是没有这个功能的</strong>.</p> <p>​<img src="/img/56c24f7f96e6f32a6a4778134407c5e9-20240421231949-yf41f3q.jpg" alt="">​</p> <p>如上图所示, RocketMQ 的生产端和消费端的 SDK 集成了轨迹信息上报模块. 当数据发送或消费成功时, 如果开启轨迹上报, 客户端会将轨迹数据上报到集群中的内置 Topic 或者自定义 Topic 中. 因此 Broker 端就保存有全链路的轨迹信息了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d9fbab0fd63b7f3e4e14a14bd024336d-20240421231949-d5vtwlv.jpg" alt=""></p> <p><strong>同时 RocketMQ 会为每条消息赋予一个唯一 ID</strong>. 当消息发送成功后, 可以根据消息 ID 查看轨迹信息. 如果需要, 还可以把轨迹信息存储到一些第三方系统(比如 Elasticsearch), 以便后续查询. 也可以通过命令行工具 mqadmin, 根据消息 ID 来查询轨迹信息, 如下所示:</p> <p>​<img src="/img/58e60d291c2196cc2fc08391cbaca4db-20240421231949-arv0jda.png" alt="">​</p> <h5 id="总结-24"><a href="#总结-24" class="header-anchor">#</a> 总结</h5> <p>在集群构建方面, 节点发现是依赖 NameServer 完成的. 元数据是存储在本地 Broker, 在启动时上报到 NameServer 中的.</p> <p>在部署模式方面, RocketMQ 经历了 <code>Master/Slave, Dledger, Controller</code>​ 三种模式. 其中 Controller 模式属于消息队列中常见的架构形式.</p> <p>在数据可靠性方面, RocketMQ 也是依赖副本来实现数据的高可靠. 不同的部署模式的数据一致性支持不一样. 在 Master/Slave 架构中, 支持<strong>最终一致和强一致</strong>两种. 在 Dledger 架构中, 支持多数原则, 属于最终一致. 在 Controller 中, 可以自定义写入成功的副本数, 不强制一定是多数原则, 也是属于最终一致的一种.</p> <p>在安全方面, RocketMQ 也是围绕着<strong>加密传输, 认证, 鉴权</strong>三个部分展开. 依赖 TLS 来实现加密传输. 认证方式支持得比较简单, 只支持明文的用户名密码认证. 主要支持 Topic 和 Group 两种资源的鉴权, 包含拒绝, 全部权限, 发送, 订阅四种权限, 同时也支持 IP 白名单认证.</p> <p>在可观测性方面, 指标的实现分为两个阶段, 5.0 之前通过自定义实现的指标记录, 通过 Remoting 暴露指标, 通过 RocketMQ Export 和 Prometheus 来完成监控. 5.0 之后遵循 OpenTelemetry 的规范重构了指标模块, 支持标准的指标定义和统计方式, 并在内核支持了 Prometheus, OpenTelemetry Collector, RocketMQ Export 三种暴露方式.</p> <p>在消息轨迹方面, 通过在客户端 SDK 支持轨迹上报, RocketMQ 支持了全链路的轨迹记录上报功能.</p> <h5 id="思考题-21"><a href="#思考题-21" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为什么 RocketMQ 会支持这么多种部署模式, 出于什么考虑呢?</p></blockquote> <p>在我看来, 这不是一个单纯的技术问题. 我认为 RocketMQ 的多种部署模式就是<strong>演进</strong>出来的. 从部署模式的演进, 可以看到国内互联网架构演进的影子, 如从 Master/Slave(类 MySQL)到 Dledger(Raft 实现数据一致性)再到 Controller(选主, 复制, Leader 切换).</p> <p>经历了多种架构的演进, 可能有最初的设计的问题, 但是我认为它的演进受它的历史和业务背景因素所影响, 比如开发周期, 人力投入, 业务需要等因素都会影响技术决策.</p> <p>从 RocketMQ 架构来看, 可以看到目前中国互联圈经常提到的一个说法: <strong>架构是演进出来的, 不是设计出来的.</strong>  对于这个观点, 当然见仁见智, 大家看法都不一样. 但我觉得, 我们应该尊重每个系统的架构设计, 不要直接用好坏的标准来评价, 可以抱着理解, 拥抱的角度来理解它的设计.</p> <h4 id="_25-从集群角度拆解kafka的架构设计与实现"><a href="#_25-从集群角度拆解kafka的架构设计与实现" class="header-anchor">#</a> 25-从集群角度拆解Kafka的架构设计与实现</h4> <p>上节讲完了 RocketMQ, 这节课再来看一下<strong>流消息领域</strong>的消息队列 Kafka.</p> <p>因为前面已经详细描述了, 基于 ZooKeeper 和 KRaft 来构建集群的两种方式, 在这里就不再重复. 这节会详细分析 Kafka 副本之间的数据一致性, 数据同步机制, Leader 切换, 数据截断.</p> <h5 id="数据可靠性-3"><a href="#数据可靠性-3" class="header-anchor">#</a> 数据可靠性</h5> <p>Kafka 集群维度的数据可靠性也是通过副本来实现的, 而<strong>副本间数据一致性是通过 Kafka ISR 协议来保证</strong>的. ISR 协议是现有一致性协议的变种, 它是参考业界主流的一致性协议, 设计出来的符合流消息场景的一致性协议.</p> <p><strong>ISR 协议的核心思想是</strong>: 通过副本拉取 Leader 数据, 动态维护可用副本集合, 控制 Leader 切换和数据截断 3 个方面, 来提高性能和可用性.</p> <p>​<img src="/img/7e4cf5f54694b1624f91b31f2a2c7ced-20240421231949-15emvdo.jpg" alt="">​</p> <p>参考图示, 这是一个包含 1 个 Leader, 2 个 Follower 的分区. 如果是基于 Raft 协议或者多数原则实现的一致性算法, 那么当 Leader 接收到数据后, 就会直接分发给部分或全部副本. 前面两节说到的 RabbitMQ 的镜像队列, 仲裁队列和 RocketMQ 的 Master/Slave, Dledger 都是这么实现的.</p> <p>这种机制在流消息队列的大吞吐场景中主要有两个缺点:</p> <ol><li>收到数据立即分发给多个副本, 在请求量很大时, 和副本之间的频繁交互会导致数据分发的性能不高.</li> <li>计算一致性的总副本数是固定的, 当某个副本异常时, 如果还往这个副本分发数据, 此时会影响集群性能.</li></ol> <h6 id="副本拉取leader数据"><a href="#副本拉取leader数据" class="header-anchor">#</a> 副本拉取Leader数据</h6> <p>为了提高数据分发性能, 主要的解决思路就是 <strong>数据批量分发</strong>. 所以在实现上看, Kakfa 是<strong>通过 Follower 批量从 Leader 拉取数据来完成主从副本间的数据同步, 并提高性能</strong>的.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6818b32b368215f3451402b1ff7d79fe-20240421231949-06slw97.jpg" alt="">​</p> <p>如上图所示, Follower 会<strong>维护一批线程来从 Leader 拉取数据</strong>. 此时, 比如当 Leader 接收到 1000 次数据, 在 Leader 主动分发的场景中, 就需要往两个 Follower 分别发起 1000 次请求. 而在 ISR 模型下, 假设 Follower 每批次拉取 50 条数据, 此时每个 Follower 和 Leader 间的网络交互次数就减少到了 20 次, 从而极大地提高了一致性的性能.</p> <p>这里你可能就会有一个疑问: <strong>如果是 Follower 来服务端拉取数据, 那么当数据写入 Leader 后是直接告诉客户端写入成功吗?</strong>   回答这个问题之前先来看一张图.</p> <p>​<img src="/img/d0408914e4fa9961ea544b297ef5f7f5-20240421231949-4t7qadp.jpg" alt="">​</p> <p>从实现的角度看, 当<strong>配置最终一致(ACK=1)或者强一致(ACK=-1)</strong> 时, Leader 接收到数据后不会立即告诉客户端写入成功. 而是请求会进入一个<strong>本地的队列进行等待, 等待 Follower 完成数据同步</strong>. 当数据被副本同步后, Leader 才会告诉客户端写入成功.</p> <p>等待这个行为的技术实现的核心思想是 Leader 维护的定时器, <strong>时间轮</strong>. 简单理解就是<strong>时间轮会定时检查数据是否被同步, 是的话就返回成功, 否的话就判断是否超时, 超时就返回超时错误, 否则就继续等待</strong>. 时间轮的具体实现, 后面会详细分析.</p> <h6 id="动态维护可用副本集合"><a href="#动态维护可用副本集合" class="header-anchor">#</a> 动态维护可用副本集合</h6> <p>在具体实现方面, ISR 会维护一个可用的副本集合. 上节讲过, RocketMQ 的 Controller 会维护可用副本集合 SyncStateSet, 这两者的思路是一样的.</p> <p>即有一个三副本的分区, 当服务都正常时, 可用副本集合就有 3 个元素, 比如 [A, B, C]. 当某个副本异常时, 比如副本宕机或副本性能有问题无法跟上 Leader 时, 就会自动把这个副本剔出可用副本的集合, 如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>[A, B, C] =&gt; [A, B]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>基于这个设计, 此时总的可用副本为 2. 强一致计算的总副本数量也为 2, 则只要这<strong>两个副本写入成功</strong>即可. 从而解决有问题节点不影响强一致可用性的问题.</p> <p><strong>那怎么判断副本有异常呢?</strong>  从技术实现来看, 一般通过两种策略来判断.</p> <ol><li><strong>副本所在节点是否宕机</strong>, 如果副本的节点挂了, 就认为这个副本是不可用的. 那如何判断副本的节点挂了呢? 那就是前面讲到的节点的心跳的探活机制.</li> <li><strong>副本的数据拉取进度是否跟不上 Leader, 即副本来 Leader Pull 数据的速度跟不上数据写入 Leader 数据的速度</strong>. 此时如果 Follower 一直追不上 Leader, 这个 Follower 就会被踢出 ISR 集合.</li></ol> <p>在 Kafka 的实现中, 最开始支持按数据条数去判断 Follower 是否跟得上 Leader. 但是因为不同 Topic 的流量不一样, 根据数据条数很难准确判断落后情况. 后来支持按照时间来判断落后情况, 比如 Follower 落后 Leader 多久, 则表示 Follower 跟不上 Leader. 当然, 这是一个配置, 可以调整.</p> <h6 id="控制leader切换和数据截断"><a href="#控制leader切换和数据截断" class="header-anchor">#</a> 控制Leader切换和数据截断</h6> <p>Leader 切换的触发条件一般是节点的心跳探活失败后, 由 Controller 或者元数据存储服务来触发的.</p> <p>当出现 Leader 切换, 如果所有节点的数据是强一致的, 则直接进行 Leader 切换, 不需要任何其他的处理, 也不会有数据丢失的问题. 这种方式实现是最简单的, 开发成本也最低, 但是性能较差. 比如 RabbitMQ 的镜像队列和 RocketMQ 的 Master/Slave 的同步双写就是这种方案.</p> <p>因为 Kafka ISR 协议是最终一致的, 所以在某些极端的场景中会出现数据丢失和截断, 所以需要在实现上做特殊的处理.</p> <p>那什么情况下会出现数据丢失和截断呢?</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e5198a7def400ba3486d8365ebcf72dc-20240421231949-zyriteb.jpg" alt=""></p> <p>如上图所示, 按照最终一致和多数原则, 如果有 2 个副本 A 和 B 写入成功后, 就会告诉客户端数据写入成功. 此时, 如果这两台节点同时挂掉, <strong>就会有 C 节点成为 Leader 和 C 节点不成为 Leader 两种场景</strong>.</p> <p>如果是 C 节点不能成为 Leader, 此时就不会有丢数据或截断问题. 开发实现也简单, 只是问题发生时, 服务就不可用.</p> <p>如果 C 节点可以成为 Leader, 此时就可能会出现<strong>数据截断</strong>. 比如 A, B 有 100 条数据, C 只有 90 条数据, 此时 A, B 挂了, C 成为 Leader 后重新接收数据. 当 A 和 B 启动后, 因为 C 这里也会有 90～100 之间的数据, 如果要合并数据就会冲突. 所以一般遇到这种情况, 就会丢弃数据, 然后就会有数据丢失.</p> <p>在 Kafka 的实现中, <strong>这两种情况都是支持的, 支持在 Topic 维度调整配置来选择这两个操作</strong>. 所以 Kafka 的 ISR 协议的很大一部分工作, 就是在代码层面处理 Leader 切换, 数据阶段的操作.</p> <h5 id="安全控制-3"><a href="#安全控制-3" class="header-anchor">#</a> 安全控制</h5> <p>接下来从传输安全, 认证, 鉴权 3 个方面, 来分析一下 Kafka 的安全控制机制.</p> <p>Kafka 支持 TLS/SSL 进行数据加密传输. 从代码实现层面看, 服务端和客户端支持这部分能力, 和 RocketMQ 是一样的, 都是 Java 代码的标准用法, 这里就不再赘述了.</p> <p>讲安全时讲过, SASL 是一个身份验证和安全的框架. Kafka 在这个框架下实现了 GSSAPI, PLAIN, SCRAM, OAUTHBEARER, Delegation Token 5 种认证方式.</p> <p><a href="https://docs.oracle.com/cd/E19253-01/819-7056/6n91eac3u/index.html" target="_blank" rel="noopener noreferrer">GSSAPI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 全称是通用安全服务应用编程接口(Generic Security Service Application Programming Interface, GSS-API)的简称, 它的目的是为应用程序提供一种用于保护发送数据的方法. 它主要用在和 Kerberos 认证对接的过程. 在 Java Server 支持 GSSAPI 可以看这个 <a href="https://www.baeldung.com/java-gss" target="_blank" rel="noopener noreferrer">教程<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>这里多说一句, Kerberos 是安全的, 单点登录的, 可信的第三方相互身份验证服务.</p> <p>PLAIN 就是明文的用户名, 密码认证机制, 通过服务端提供的用户名密码来完成校验. PLAIN 是 Kafka 早期提供的明文认证机制, 它的用户名和密码是写在 Broker 的配置文件中的, 不支持动态修改.</p> <p>为了解决这个问题, Kakfa 支持了 SCRAM 机制, SCRAM 也是明文的认证机制. 它跟 PLAIN 最大的区别是, 它的用户名和密码是存储在 ZooKeeper 中的, 并支持 <strong>动态修改</strong>.</p> <p>OAUTHBEARER 是 Kafka 为了支持 OAuth 认证机制而引入的. OAuth 是常用的认证机制, 它本质是一个安全的, 开放而又简易的第三方认证机制. 和其他的授权方式不同的是, OAuth 授权不会使第三方触及到用户的帐号信息, 即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权, 从而更加安全. 在 Java Server 支持 OAuth 可以看这个 <a href="https://github.com/authlete/java-oauth-server" target="_blank" rel="noopener noreferrer">项目<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>Delegation Token 是一种轻量级的 Token 认证机制, 从实现原理来看, 就是服务端签发保存 Token, 客户端携带 Token 来完成认证. Token 信息也是保存在 ZooKeeper 上的.</p> <p>在实现上, Kafka 的认证是一个独立的模块, 通过接口形式实现了多种常见的认证机制. 接下来来看看 <strong>Kafka 的鉴权</strong>.</p> <p>Kakfa 对资源的<strong>管控粒度是比较细</strong>的, 主要支持对 Topic, Group, Cluster, TransactionalId, DelegationToken, User 等 6 种资源进行控制, 并给这些资源提供了 Read, Write, Create, Delete, Alter, Describe, ClusterAction, DescribeConfigs, AlterConfigs, IdempotentWrite, CreateTokens, DescribeTokens, All 等 13 种<strong>权限</strong>, 分别对应数据的读写, 资源的增删改查, 集群管控, 配置修改, Token 配置, 全部权限等类型. <strong>同样的, Kafka 也支持对来源 IP 的限制</strong>.</p> <p>从实现来看, 用户的全新信息是保存在 ZooKeeper 的 <code>/kafka-acl</code>​ 目录中的. 目录结构和权限如下所示:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>/kafka-acl
  - Cluster
  - DelegationToken
  - Group
  - Topic
  - TransactionalId

# 权限配置详情 
<span class="token punctuation">{</span>
    <span class="token property">&quot;version&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
    <span class="token property">&quot;acls&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;*&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;operation&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Write&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;permissionType&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Allow&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;principal&quot;</span><span class="token operator">:</span> <span class="token string">&quot;User:*&quot;</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;*&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;operation&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Read&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;permissionType&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Allow&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;principal&quot;</span><span class="token operator">:</span> <span class="token string">&quot;User:*&quot;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>从运行的角度来看, 在 Broker 启动时, 会加载全部权限信息到<strong>内存</strong>中. 当客户端访问某个功能时, 会率先进行权限比对. 当 ZooKeeper 节点的内容更新时, 会下发通知, 通知 Broker 重新读取 ZooKeeper 节点中的数据更新内存的内容. 如果想对 Kafka 权限配置有更加细致的了解, 可以参考这个 <a href="https://kafka.apache.org/documentation/#security" target="_blank" rel="noopener noreferrer">文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 或者安装包自带的工具 kafka-acls.sh.</p> <p>从这么多细分权限可以知道, Kakfa 在权限管控这里是做得非常细致. 在现网运营过程中, 基本是够用了的.</p> <h5 id="可观测性-3"><a href="#可观测性-3" class="header-anchor">#</a> 可观测性</h5> <p>接下来从指标, 日志, 消息轨迹来看一下 Kafka 的可观测性. Kafka 的指标定义是基于 Yammer Metrics 库来实现的. Yammer Metrics 是 Java 中一个常用的指标库, 它提供了 Histogram, Meters, Gauges 等类型来统计数据. 对于 Kafka 的作用就是, 使用这个库可以完成各种类型指标的统计和记录, 代码使用方式如下:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code>val batchProcessingTimeHist <span class="token operator">=</span> <span class="token class-name">KafkaYammerMetrics</span><span class="token punctuation">.</span><span class="token function">defaultRegistry</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">newHistogram</span><span class="token punctuation">(</span><span class="token function">metricName</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> tags<span class="token punctuation">)</span><span class="token punctuation">,</span> biased<span class="token punctuation">)</span>
batchProcessingTimeHist<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这个库的使用并不复杂, 只需要引入包直接使用即可. 不过, 如果是希望在自己的系统内注册统计指标, 建议使用 OpenTelemetry Metrics 或者 Prometheus Metrics, 这两种是近期在指标方面更常用的方案.</p> <p><strong>在指标暴露方面, Kakfa 只支持 JMX 方式的指标获取</strong>. 即如果需要从 Kafka 进程采集指标, 就需要先在 Broker 上开启 JMX Server. 然后客户端通过 JMX Client 去 Broker 采集对应的指标.</p> <p>在实际运营中, 主要有 3 种通过<strong>指标监控 Broker</strong> 的方式.</p> <p>​<img src="/img/beb3yy6f1cd58e453b8f5c7a6df99a70-20240421231949-e3pz510.jpg" alt="">​</p> <p>如上图所示, 可以通过代码使用 JMX Client 直接去采集 Broker 中的指标数据, 然后自定义处理. 也可以通过 JMX Export 采集指标, 然后和 Prometheus 集成展示. 从实现来看, JMX Export 底层也是通过 JMX Client 去 Broker 采集数据的. 另外社区提供了 Kafka Export 通过 Kafka Protocol 去获取消费进度, Topic 信息等相关信息, 然后再和 Prometheus 集成展示.</p> <p>在日志方面, <strong>Kafka 也是基于 Log4j 库去打印日志</strong>, 依赖 Log4j 库的强大, 支持常见的日志功能, 这里就不再细数. 同时通过配置支持, 将不同模块的日志打印到不同文件, 如 Controller, Coordinator, GC 等等, 以便在运营过程中提高问题排查的效率.</p> <p>在<strong>消息轨迹方面, Kafka 并没有提供对消息轨迹功能的支持</strong>. 如果需要支持, 得改造内核. 从技术上来看, 即在客户端 SDK 实现轨迹上报的功能, 在服务端记录生产时收到的数据信息和消费时发送的数据信息.</p> <p>这里简单解释一下: <strong>为什么 Kakfa 没有提供消息轨迹的功能?</strong></p> <p>在我看来, 主要是因为 Kakfa 定位的是<strong>流场景</strong>, 大吞吐的消息队列. 一般用在日志场景中, 这些场景消息数量是非常大的. 如果支持消息轨迹, 那么一条消息至少需要生产者, Broker, 消费者 3 条轨迹信息, 此时轨迹数据的量就非常恐怖, 从<strong>成本角度来看收益很低</strong>.</p> <p>当然, 也可以支持轨迹数据采样, 但是采样的话, 对消息场景来讲, 如果是重要消息, 就需要每一条消息都有轨迹. 对于不重要的消息, 也没必要采样. 所以基于这些考虑, Kafka 社区对消息轨迹的支持就比较弱. 当然, 有一些公司会通过改动内核来支持消息轨迹, 这也是可行的. 因为这可以满足把 Kafka 当作业务消息管道来用的场景. 从技术实现来看, 并不复杂.</p> <h5 id="总结-25"><a href="#总结-25" class="header-anchor">#</a> 总结</h5> <p>在集群构建方面, <strong>Kafka 支持依赖 ZooKeeper 和 KRaft 两种形态来存储元数据并完成集群构建, 依赖 Controller 来完成集群的管理, Leader 切换</strong>等等.</p> <p>在数据可靠性方面, <strong>Kafka 依赖 ISR 协议来保证数据的高可靠</strong>.</p> <p><strong>Kafka 的支持通过 SSL 来完成数据的加密传输</strong>. 同时支持 GSSAPI, PLAIN, SCRAM, OAUTHBEARER, Delegation Token 等 5 种认证方式, 并支持对 Topic, Group, Cluster, TransactionalId, DelegationToken, User 等 6 种资源进行鉴权, 提供了 Read, Write, Create, Delete, Alter, Describe, ClusterAction, DescribeConfigs, AlterConfigs, IdempotentWrite, CreateTokens, DescribeTokens, All 等 13 种权限. 从安全管控来说, Kafka 做得非常细致.</p> <p>在可观测性方面, Kafka 基于 Yammer Metrics 库完成了指标的定义, 基于 JMX 完成了指标的暴露. 在现网运营过程中, 可以通过 Kafka Export + JMX Export + JMX 来完成集群监控体系的搭建. Kafka 对消息轨迹的需求不高, 内核不支持轨迹相关功能, 不过可以通过内核改造和 SDK 改造来支持消息轨迹, 开发难度并不高.</p> <h5 id="思考题-22"><a href="#思考题-22" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为保证副本一致性, 在 Leader 收到数据主动分发给副本的实现中, 当某个节点出问题时, 如何设计退避方案, 以避免出现一些频繁的无效的调用?</p></blockquote> <p>一般来讲, 在 Leader 主动分发的场景中, 当 Leader 收到数据后, 会同时给多个副本分发数据, 以提高分发性能.</p> <p>此时在 Leader 端, 为了避免异常副本的影响, 一般会提供<strong>请求降级机制</strong>. 即如果某个副本有性能问题或者宕机, Leader 连续分发数据就会超时或者失败. Leader 就可以根据一定的策略记录失败信息, 比如连续 3 次失败则进行降级, 在接下来的 30s 不给这个副本分发数据. 以此类推进行降级, 直至剔除这个副本.</p> <p>同时也需要对副本进行定时探测, 以保证副本恢复后, 可以再给副本分发数据.</p> <h4 id="_26-从集群角度拆解pulsar的架构设计与实现"><a href="#_26-从集群角度拆解pulsar的架构设计与实现" class="header-anchor">#</a> 26-从集群角度拆解Pulsar的架构设计与实现</h4> <p>上节讲完了 Kafka , 这节再来看一下消息队列领域最新的成员 Pulsar.</p> <p>基础篇讲过, 从设计定位上来看, <strong>Pulsar 是作为 Kafka 的升级替代品</strong>出现的, 它主要解决了 Kafka 在集群层面的弹性和规模限制问题. 那么现在就从<strong>集群的角度</strong>来拆解一下 Pulsar 的架构设计和实现, 先来看一下集群构建.</p> <h5 id="集群构建-3"><a href="#集群构建-3" class="header-anchor">#</a> 集群构建</h5> <p>在当前版本, Pulsar 集群构建和元数据存储的核心依旧是 ZooKeeper, 同时社区也支持了弱 ZooKeeper 化改造. 如下图所示, Pulsar Broker 集群的构建思路和 Kafka 是一致的, 都是<strong>通过 ZooKeeper 来完成节点发现和集群的元数据管理</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d4090c7722effb453b5c965753736d62-20240421231949-bgd7fr2.jpg" alt=""></p> <p>从实现角度来看, Broker 启动时会在 ZooKeeper 上的对应目录创建名称为 <strong>BrokerIP + Port</strong> 的子节点, 并在这个子节点上存储 Broker 相关信息, 从而完成节点注册. <strong>Pulsar Broker 的节点信息是存储在 ZooKeeper 上的 /loadbalance/brokers 节点上</strong>, 目录结构如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>[zk: 9.164.54.17:2181(CONNECTED) 67] ls /loadbalance/brokers
[30.13.4.1:8080, 30.13.8.2:8080, 30.13.4.3:8080]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>还是从实现的角度, Pulsar 的<strong>全部元数据都持久化存储在 ZooKeeper 中, 同时 Broker 也会缓存一部分数据</strong>. Pulsar 在 ZooKeeper 中主要存储了包括集群管控, 存储层的 Bookie, Ledgers, 计算层 LoadBalance, Bundle, 周边功能 Schema, Stream, Function 等信息. ZooKeeper 中的节点结构如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>[admin, bookies, counters, ledgers, loadbalance, managed-ledgers,
namespace, pulsar, schemas, stream, zookeeper]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>在集群管理方面, 每个 Pulsar 集群都有一个<strong>主节点</strong>(Master Node).</p> <h6 id="主节点"><a href="#主节点" class="header-anchor">#</a> 主节点</h6> <p>主节点对 Pulsar 的作用, 就相当于 Kakfa 中的 Controller. <strong>主节点负责管理集群的元数据和状态信息</strong>, 例如主题, 订阅, 消费者等. 主节点还负责协调集群中的各个节点, 例如选举副本, 分配分区等.</p> <p>那么主节点是怎么产生的呢?</p> <p><strong>当一个节点启动时, 它会向 ZooKeeper 注册自己, 并尝试成为主节点</strong>. 如果当前没有主节点, 或者当前的主节点失效了, 那么该节点就会成为新的主节点. 如果多个节点同时尝试成为主节点, 那么它们会通过 ZooKeeper 的选举机制来进行竞争, 最终只有一个节点会成为主节点.</p> <p>从节点机制上看, 和 Kafka 的 Controller 选举机制的实现是一样的. 从代码的角度, 也是<strong>依赖 ZooKeeper 的存储和 Watch 来实现分布式协调</strong>. 所以可以看出, <strong>ZooKeeper 作为分布式协调服务, 用处非常广泛</strong>.</p> <p>之前提到过 Zookeeper 集群本身存在性能和容量限制. 从技术上分析, 是因为 ZooKeeper 在底层的存储数据结构是<strong>分层树</strong>结构. 分层树结构在读取时需要<strong>多层检索</strong>, 从而导致数据如果存储在硬盘, 读取性能会很低. 因此 ZooKeeper 只有将所有数据加载到内存中, 才能提供较好的性能.</p> <p>此时单个节点可承载的容量上限, 就是集群所能承载的容量上限. 而 Pulsar 存算分离架构和计算层弹性需要存储很多元数据, 所以 ZooKeeper 就成为了瓶颈. 为了解决这个问题, Pulsar 走的技术路径是<strong>弱 ZooKeeper</strong>, 而不是去 ZooKeeper.</p> <h6 id="弱zookeeper实现"><a href="#弱zookeeper实现" class="header-anchor">#</a> 弱ZooKeeper实现</h6> <p>弱 ZooKeeper 就是<strong>允许将 ZooKeeper 替换为其他的单机或分布式协调服务</strong>. 目前支持 <strong>ZooKeeper, etcd, RocksDB, 内存</strong>四种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1d3e7239b09cb9e7531a97a1722f05f6-20240421231949-kkp6c7z.jpg" alt=""></p> <p>如上图所示, <mark><strong>基于 etcd 的方案是当前集群化部署的推荐方案</strong></mark>. etcd 底层存储是 <strong>B 树</strong>的结构, 在硬盘层面的读取性能较高, 不一定要把数据加载到内存中, 所以存储容量不受单机的限制.</p> <p>基于 RocksDB 的方案和 RabbitMQ 的 Mnesia 大致上是一个思路, 都是基于节点层面的存储引擎来完成元数据的存储. RocksDB 的方案主要用在单机模式上, 主要原因是 RocksDB 是一个单机数据库.</p> <p>基于内存的方案主要用在集成测试的场景中.</p> <p>从实现角度, 这种可插拔的方案都是 <strong>先定义好接口</strong>, 比如获取资源, 获取子节点, 增加或删除内容等等. 然后<strong>具体的元数据引擎实现会继承这个接口, 去实现不同的逻辑</strong>. 如下代码是 Pulsar 可插拔的元数据服务所定义的接口 MetadataStore.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">MetadataStore</span> <span class="token keyword">extends</span> <span class="token class-name">AutoCloseable</span> <span class="token punctuation">{</span>
    <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Optional</span><span class="token punctuation">&lt;</span><span class="token class-name">GetResult</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token class-name">String</span> path<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> <span class="token function">getChildren</span><span class="token punctuation">(</span><span class="token class-name">String</span> path<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Boolean</span><span class="token punctuation">&gt;</span></span> <span class="token function">exists</span><span class="token punctuation">(</span><span class="token class-name">String</span> path<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Stat</span><span class="token punctuation">&gt;</span></span> <span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">String</span> path<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> value<span class="token punctuation">,</span> <span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> expectedVersion<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Void</span><span class="token punctuation">&gt;</span></span> <span class="token function">delete</span><span class="token punctuation">(</span><span class="token class-name">String</span> path<span class="token punctuation">,</span> <span class="token class-name">Optional</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> expectedVersion<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>讲到这里, 应该会发现, 不同的消息队列(RabbitMQ, RocketMQ, Kafka, Pulsar)在元数据存储, 节点发现的具体实现都是不一样的. 不过从原理上来看, 应该也会觉得 <strong>这 4 个消息队列在集群构建模块上都很相似</strong>.</p> <h5 id="数据可靠性-4"><a href="#数据可靠性-4" class="header-anchor">#</a> 数据可靠性</h5> <p>接下来来看看 Pulsar 数据的可靠性. <strong>Pulsar 是计算存储分离的架构, 数据是通过 Ledger 和 Entry 的形式写入 BookKeeper 的</strong>. 所以跟其他消息队列不一样的是, Pulsar 的 Topic 没有副本概念, <mark><strong>消息数据的可靠性是通过 Ledger 多副本来实现的</strong></mark>.</p> <p>前面讲过, <strong>Pulsar 通过在 Broker 中设置 Qw 和 Qa 来设置 Ledger 的总副本数和写入成功的副本数. 所以从一致性来看, Pulsar 既可以是强一致, 也可以是最终一致</strong>.</p> <p>接下来来看一张图, 应该在前面看到过.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/78a924ae3908e10cf78ef1afa4d22605-20240421231949-y8czn77.jpg" alt="">​</p> <p>如上图所示, <strong>每条消息是一个 Entry, 一批 Entry 组成一个 Ledger, 一批 Ledger 组成一个分区</strong>. 所以当数据不断写入分区时, Broker 会根据条件来不停地创建分区维度的 Ledger. 这个条件通常是 Ledger 的固定长度, 另外当 Ledger 写入流断开时, 也会创建新的 Ledger.</p> <p>所以, 在 Ledger 创建时就会根据设置的 Qw 数量, 在 多个 Bookie 中创建 Ledger. <strong>这个过程就需要控制 Ledger 分布在哪些 BookKeeper 节点, 怎么实现的呢</strong>?</p> <p>BookKeeper 可以通过配置<strong>机架感知</strong>(RackawareEnsemblePlacementPolicy), <strong>区域感知</strong>(RegionAwareEnsemblePlacementPolicy), <strong>可用区感知</strong>(ZoneawareEnsemblePlacementPolicy)3 种集成放置策略, 来控制 Ledger 在 BookKeeper 多节点中的分布, 从而实现多副本数据的高可靠和跨机架, 跨可用区, 跨区域容灾.</p> <p><strong>当一个 Bookie 节点挂了后, BookKeeper 会自动检测到该节点的失效, 并将该节点上的 Ledger 副本切换到其他节点上</strong>. 具体来说, BookKeeper 会使用 Quorum 机制来进行副本切换, 确保新的副本和原有的副本具有相同的数据内容和顺序. 在副本切换过程中, BookKeeper 会使用一些机制来保证数据的一致性和完整性, 例如写前确认, 写后确认等等.</p> <h5 id="安全控制-4"><a href="#安全控制-4" class="header-anchor">#</a> 安全控制</h5> <p>接下来来看一下 Pulsar 在安全控制方面的实现.</p> <p>Pulsar 提供了 <strong>传输加密</strong>, <strong>身份认证</strong>, <strong>资源鉴权</strong>, <strong>端到端加密</strong> 四种手段.</p> <h6 id="传输加密-2"><a href="#传输加密-2" class="header-anchor">#</a> 传输加密</h6> <p>默认情况下, Pulsar 客户端是通过明文方式与 Broker 通信的, 也不需要经过身份认证和授权.</p> <p>为了保证数据在传输过程中的安全, Pulsar 支持通过 TLS 对数据进行加密传输. 从使用角度, 需要先申请或者创建证书, 然后在 Broker 中配置启用 TLS, 再在客户端配置证书信息来完成访问.</p> <p>从代码实现的角度, Pulsar 是使用 <a href="https://github.com/netty/netty-tcnative" target="_blank" rel="noopener noreferrer">netty-tcnative<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 库在 Broker 中实现支持 TLS 的. 在部署层面, Pulsar 支持在 Pulsar Broker 和 Pulsar Proxy 组件开启 TLS. 即如果要支持 TLS 传输, 既可以通过配置 Proxy 来支持, 也可以通过 Broker 来支持. Pulsar Proxy 是 Pulsar 内核自带的一个代理模块, 可以理解是一个负载均衡.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c0c1416023b7507521c6be3yya0c099d-20240421231949-y9n3ase.jpg" alt=""></p> <h6 id="端到端加密"><a href="#端到端加密" class="header-anchor">#</a> 端到端加密</h6> <p>除了支持 TLS 传输加密, Pulsar 还支持数据端到端加密. 即<strong>在生产者端加密消息, 然后在消费者端解密消息</strong>, 从而保证数据在 Broker 保存的是经过加密后的数据, 这能有效避免存储在 Broker 中的数据被泄露.</p> <p>​<img src="/img/13d504f85955949ayyd70a40a1a615d8-20240421231949-6rk8ymz.jpg" alt="">​</p> <p>从实现的角度, Pulsar 会使用 <strong>动态生成的对称会话密钥</strong> 来加密数据. 来看下图, 这是 Pulsar 在生产者端加密消息, 然后在消费者端解密消息的流程图.</p> <p>​<img src="/img/6e7cb22e58f11644149d9d769b355eb8-20240421231949-3shj58y.png" alt="">​</p> <p>如上图所示:</p> <ol><li><strong>生产者会定期(每 4 小时或在发布一定数量的消息后)生成一个会话密钥</strong>, 然后使用对称算法(例如 AES)对消息进行加密, 并每 4 小时获取一次非对称公钥.</li> <li>生产者使用消费者提供的公钥, 然后使用非对称算法(例如 RSA)加密会话密钥, 并在消息头中携带加密后的会话秘钥信息.</li> <li>消费者读取消息头, 并使用其私钥解密会话密钥.</li> <li>消费者使用解密的会话密钥来解密消息.</li></ol> <p><strong>端到端加密在一些对数据安全要求较高的场景中用得很多, 比如金融, 快递等</strong>等. 其他消息队列很少有支持端到端加密功能的, Pulsar 的这项功能极大地降低了用户的使用成本.</p> <h6 id="身份认证-2"><a href="#身份认证-2" class="header-anchor">#</a> 身份认证</h6> <p>Pulsar 当前支持 <a href="https://pulsar.apache.org/docs/3.0.x/security-tls-authentication/" target="_blank" rel="noopener noreferrer">mTLS<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-jwt/" target="_blank" rel="noopener noreferrer">JSON Web Token 令牌<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-athenz/" target="_blank" rel="noopener noreferrer">Athenz<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-kerberos/" target="_blank" rel="noopener noreferrer">Kerberos<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-oauth2/" target="_blank" rel="noopener noreferrer">OAuth 2.0<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-openid-connect/" target="_blank" rel="noopener noreferrer">OpenID Connect<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://pulsar.apache.org/docs/3.0.x/security-basic-auth/" target="_blank" rel="noopener noreferrer">HTTP 基本身份验证<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 等 7 种认证方式.</p> <p>从代码实现的角度, 都是标准的 Java Server 的集成实现, 即 Java Server + mTLS, Java Server + Athenz 等等.</p> <p>为了更好地支持多种身份认证方式, Pulsar 在内核提供了一个<strong>可插拔的身份认证框架</strong>. 即可以通过实现接口, 自定义实现身份认证机制. 自定义实现插件分为客户端和服务端两部分.</p> <ul><li>自定义实现客户端身份验证插件 org.apache.pulsar.client.api.AuthenticationDataProvider 为 Broker/Proxy 提供身份验证数据.</li> <li>自定义实现 Broker/Proxy 身份验证插件 org.apache.pulsar.broker.authentication.AuthenticationProvider 用来对客户端的身份验证数据进行身份验证.</li></ul> <p>同时 Pulsar 也支持链式的身份认证, 即 <strong>支持同时配置多种身份认证方式</strong>. 比如希望将集群的认证方式从 JWT 升级为 OAuth2.0, 此时可以同时配置两种认证方式, 如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>authenticationProviders=org.apache.pulsar.broker.authentication.AuthenticationProviderToken,org.apache.pulsar.broker.authentication.AuthenticationProviderOAuth2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在上面的配置中, Broker 收到请求后会先进行 JWT 认证. 如果无法通过 JWT 认证, 则使用 OAuth2.0 认证. 这点和 RabbitMQ 鉴权的实现思路是一样的.</p> <h6 id="资源鉴权-2"><a href="#资源鉴权-2" class="header-anchor">#</a> 资源鉴权</h6> <p>同样的, Pulsar 也提供了<strong>插件化的鉴权机制</strong>. 默认情况下, 如果不配置鉴权, 认证通过后就可以访问集群中的所有资源.</p> <p>Broker 当前提供了 AuthorizationProvider 和 MultiRolesTokenAuthorizationProvider 两种鉴权实现, 其中 MultiRolesTokenAuthorizationProvider 只支持配合 JWT 认证使用. 可以在 Broker 配置文件中配置启用哪种鉴权插件.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>authorizationProvider=org.apache.pulsar.broker.authorization.AuthenticationProviderToken
或
authorizationProvider=org.apache.pulsar.broker.authorization.MultiRolesTokenAuthorizationProvider
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>和其他消息队列直接通过用户名或者客户端信息来完成鉴权不一样的是, <strong>Pulsar 是通过 Role Token(角色令牌)来完成鉴权的</strong>. Role Token 本质就是一个字符串, 是一个逻辑的概念, 用来在后续授权中标识客户端身份用的.</p> <p>从实现上看, <strong>认证组件完成认证后会将客户端和角色(Role)关联</strong>, 即客户端不管使用的是 Auth2.0, JWT 或 Kerberos 认证方式, 当通过认证后都会关联一个 Role. 然后再根据这个 Role 携带的权限信息来进行鉴权.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0ae88481b3cbcbb96623a8519c0f01de-20240421231949-ai7ymtf.jpg" alt=""></p> <p>Pulsar 的 Role 分为超级用户和普通用户. 超级用户有集群的所有权限, 如创建, 删除租户, 并且对所有租户具有访问权限, 超级用户需要在 Broker 的配置文件中进行配置.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>authorizationEnabled=true
superUserRoles=my-super-user-1,my-super-user-2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>另外 Tenant(租户)有 Tenant Admin(租户管理员)概念. 在创建租户时, 可以指定租户的 Admin Role, 这个 Role 拥有这个 Tenant 的全部权限.</p> <p>Pulsar 支持对 Broker, Tenant, Namespace, Topics 四个维度鉴权. 其中 Broker, Tenant 主要是管控级别的操作, 比如创建, 删除资源等. Namespace 和 Topic 级别的主要是生产和消费相关的权限管控, 其中 Namespace 还有 Function 相关的权限控制.</p> <h5 id="可观测性-4"><a href="#可观测性-4" class="header-anchor">#</a> 可观测性</h5> <p>接下来从指标和消息轨迹两个方面讲一下 Pulsar 的可观测性.</p> <p>Pulsar 定位<strong>云原生消息队列</strong>, 所以它的指标模块主要围绕 <strong>Prometheus 和 Grafana 体系</strong>来搭建的.</p> <p>在指标定义记录方面, Pulsar 使用 Prometheus 指标库来完成指标记录. 从代码上看, 是通过引入 Java 的 io.prometheus 库来实现的, 具体实现可以参考 <a href="https://prometheus.io/docs/concepts/metric_types/" target="_blank" rel="noopener noreferrer">官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 在记录指标时, 支持 Counter, Gauge, Histogram, Summary 四种指标类型, 用来完成瞬时值, 统计值, 分布值的统计.</p> <p>Pulsar 的架构相对复杂, 组件较多, Pulsar 为所有组件都提供了丰富的指标. 主要包含了 Broker, BookKeeper, ZooKeeper, Proxy, Function, IO 等等, 详细的指标参考 <a href="https://pulsar.apache.org/docs/3.0.x/reference-metrics/" target="_blank" rel="noopener noreferrer">Pulsar 指标<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>在指标暴露方面, Pulsar 通过在组件上支持 HTTP 接口 /metrics 来支持 Prometheus 的采集. 接口的数据格式是标准 Prometheus 格式, <strong>直接配置 Prometheus 采集 + Grafana 展示或告警即可</strong>, 使用成本较低. 跟 RocketMQ 的支持 Prometheus 方案是一样的.</p> <p><strong>Pulsar 的指标模块采用的是当前业界最常用的方案</strong>. 如果在自定义的组件中需要实现指标, 建议可以直接参考.</p> <p>当前社区版本的 Pulsar 是不支持消息轨迹的, 但是一些商业化的版本是支持的. 从技术实现的角度来看, 和之前讲过的其他消息队列实现思路一样, 这里不再赘述.</p> <h5 id="总结-26"><a href="#总结-26" class="header-anchor">#</a> 总结</h5> <p>其实 Pulsar 的总结是最不好写的, <strong>因为 Pulsar 社区发展非常快, 可能没几天内容就会过期, 失效或总结错误</strong>. 所以如果需要了解最新的信息, 建议去看源码或官方的最新文档.</p> <p>但是万变不离其宗, 当掌握了原理, 无论如何变化都不过是变化而已.</p> <p>接下来用一张表格, 针对进阶篇的所有知识点, <strong>从四个主流消息队列的角度来做一个原理概览性的总结</strong>. 建议收藏!</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/5168b25e17b36bcd1eef9b0f10c13f03-20240421231949-md3p5nn.jpg" alt="">​</p> <h5 id="思考题-23"><a href="#思考题-23" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为什么在去 ZooKeeper 的路上选择了可插拔的元数据存储框架, 而不是去掉第三方存储引擎?</p></blockquote> <p>在我看来, 引入其他元数据存储引擎只能缓解, 不能根治, 在 ZooKeeper 上遇到的问题, 在其他引擎上也会遇到. 并且引入其他引擎后, 架构的部署成本也没有降低, 复杂度依旧很高. 我认为, 比较好的方式是<strong>去掉第三方元数据引擎, 在 Broker 集群内部实现元数据的自我组织和管理</strong>.</p> <p>那么为什么 Pulsar 还会走可插拔的路径呢?</p> <p>在我看来和开发成本有关, 因为去掉第三方元数据存储依赖是一件工作量非常非常大的事情, 需要对架构做一个非常大的改动, 会消耗社区大量的人力, 不适合 Pulsar 当前快速发展的阶段. 使用可插拔框架的思路, 改动量较小, 可以引入 etcd 这样的性能较高的引擎来缓解当前遇到的问题, 引入单机的 RocksDB 来降低集群的部署复杂度, 引入内存存储来降低单机版本的部署成本等等, 总之会带来蛮多好处.</p> <h3 id="功能篇"><a href="#功能篇" class="header-anchor">#</a> 功能篇</h3> <h4 id="_27-基础功能-topic-分区-订阅等基本功能是如何实现的"><a href="#_27-基础功能-topic-分区-订阅等基本功能是如何实现的" class="header-anchor">#</a> 27-基础功能:Topic,分区,订阅等基本功能是如何实现的?</h4> <p>在基础篇和进阶篇, 构建了一个分布式的消息队列集群. 接下来就开始往这个集群里面添加各种功能. 后面会用八节课来分析 <strong>消息队列的基本功能, 顺序消息和幂等, 延时和定时消息, 事务消息, 死信队列和优先级队列, 消息查询, Schema, WebSocket</strong> 等功能的技术选型和设计思路. 将这些功能加入到集群之后, 一个完整的消息队列基本就打造出来了.</p> <p>在本节课程中, 会重点讲解以下 4 个消息队列基础功能的实现, 这四部分的内容相互独立, 可以挑有需求的知识点来学习.</p> <ol><li><strong>静态/动态配置的实现</strong>: 配置是集群的基础模块, 看一下如何在集群中实现静态和动态配置.</li> <li><strong>集群和节点元数据的设计</strong>: 集群构建需要设计, 存储集群和节点的元数据, 看一下它们应该包含什么内容, 如何存储.</li> <li><strong>Topic 和分区的支持</strong>: Topic 和分区是消息队列生产消费的最小单位, 看一下 Topic 和分区的元数据应该包含哪些内容, 以及如何存储这些元数据.</li> <li><strong>消费分组(订阅)的管理</strong>: 详细讲一下消费进度的存储格式和保存机制的实现.</li></ol> <p>为了便于理解, 假设现在的集群是<strong>基于第三方存储引擎 ZooKeeper 来实现</strong>的. 具体如下图所示:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/093daba2b27cd1a0c397920d288b48e2-20240421231949-9pfl31g.jpg" alt=""></p> <h5 id="如何实现静态和动态配置"><a href="#如何实现静态和动态配置" class="header-anchor">#</a> 如何实现静态和动态配置</h5> <h6 id="静态配置"><a href="#静态配置" class="header-anchor">#</a> 静态配置</h6> <p>静态配置是在业务开发中经常用到的, 配置信息一般以 YAML, JSON, Properties 等格式存储. 在服务启动时加载配置文件到内存当中, 进行业务逻辑处理.</p> <p>静态配置的好处是简单易用, 能满足大部分的需求. 缺点是每次变更都需要修改文件内容, 并重启服务. 在一些业务中, 重启应用是比较重的操作, 可能会对业务产生一定的影响. 所以就需要引入动态配置.</p> <h6 id="动态配置"><a href="#动态配置" class="header-anchor">#</a> 动态配置</h6> <p>动态配置是指服务可以从某个地方动态加载配置信息. 如下图所示, 即 Broker 启动时会通过某个第三方服务, 比如 <strong>ZooKeeper, etcd, 某个名字服务等来加载配置</strong>. 当需要变更配置时, 直接往第三方服务写入新的配置即可, Broker 会自动监听到配置的变更.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/16f0027f9f76ed5458f86788674a112b-20240421231949-ln6mzr6.jpg" alt=""></p> <p>由于动态配置在技术上的实现方式比较多, 这里就介绍两种常用的. 一种是 <strong>基于第三方组件</strong>, 另一种是 <strong>基于本地文件</strong>.</p> <p>第三方组件, 以 ZooKeeper 的实现为例.</p> <p>基于 ZooKeeper 是指可以<strong>在 ZooKeeper 创建持久节点存储配置信息</strong>, 然后 Broker 通过 ZooKeeper 提供的 Watch 机制来监听节点. 当节点内容变更时可以及时感知, 并进行后续的处理.</p> <p>从实现上来看, 可以在 ZooKeeper 上创建  <strong>/config 节点</strong>, 在 /config 下创建 Cluster, Broker, Topic 3 个节点, 分别来保存集群, 节点, Topic 的 3 个维度的配置信息. <strong>然后 Broker 监听这 3 个节点的变更来执行后续的配置变更操作</strong>. ZooKeeper 的目录结构可以如下设计:</p> <p>​<img src="/img/3ce624689a970535d9a8829a46b003d3-20240421231949-caxzbkq.jpg" alt="">​</p> <p>从运行机制上来看, Broker 监听 ZooKeeper 有以下两种思路:</p> <ol><li><strong>Broker 会通过 ZooKeeper 的 Watch 机制监听 /config 下的每个节点, 感知到节点内容的变化, 再进行后续的操作, 比如更新配置</strong>.</li> <li><strong>Broker 会监听一个专门通知配置更新的节点, 比如 /config/notification, 然后根据这个通知节点的内容, 再去判断哪个配置发生了变更</strong>.</li></ol> <p><strong>这两种思路的主要区别在于</strong>: 第一种方案变更了配置后, Broker 会立刻监听到, 立即生效. 第二种方案允许先变更配置而不立即生效, 在需要生效的时候再给 /config/notification 写入通知数据, 触发配置生效.</p> <p>从灵活性来看, 第二种思路会更合理, 能满足更多场景. 至于代码实现, 可以参考这个文档 <a href="http://www.java2s.com/example/java-api/org/apache/zookeeper/watcher/watcher-0-29.html" target="_blank" rel="noopener noreferrer">Example usage for ZooKeeper Watcher<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>基于本地文件的思路是指在代码实现中, 通过代码技巧监听本地配置文件的变更, 只要本地文件变更了, 就进行配置变更的操作. 这种方案不需要依赖第三方组件, 实现也简单, 所以在很多场景中都会这么实现. 缺点是, 如果是分布式集群, 配置变更就得变更所有的 Broker 节点上的配置, 比较繁琐, 流程也很长. 一般都需要额外的系统来辅助变更, 比如运营发布系统或 Broker 内置一个配置变更的接口供远程调用.</p> <p>以上两种方案, 从技术上看, <strong>基于第三方组件会更合理</strong>. 但是在消息队列里面, 因为需要保持架构的简洁度, 基于本地文件也是一种常用的方案. 比如 <strong>Kafka 和 Pulsar 就是基于 ZooKeeper 来实现的动态配置, 因为架构中已经集成了 ZooKeeper. RocketMQ 的 Nameserver 是一个缓存组件, 没有实际的存储和 Watch 机制, 无法实现类似 ZooKeeper 的效果, 所以用的是热加载本地文件的方案</strong>.</p> <h5 id="集群和节点元数据的格式和存储"><a href="#集群和节点元数据的格式和存储" class="header-anchor">#</a> 集群和节点元数据的格式和存储</h5> <p>接下来看一下集群和节点的元数据一般会包含哪些信息, 以及如何存储.</p> <h6 id="集群元数据"><a href="#集群元数据" class="header-anchor">#</a> 集群元数据</h6> <p>集群元数据是用来保存集群维度的一些基本信息. 最简单的集群元数据一般只需要包含<strong>集群 ID 和集群名字</strong>两个信息. 集群 ID 用来唯一标识这个集群, 集群名称可以直观识别集群的用途, 所以集群的元数据结构一般如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>{
  &quot;ClusterId&quot;:&quot;bmfursdfk&quot;,
  &quot;ClusterName&quot;:&quot;Trade&quot;
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>集群维度的元数据需要持久化存储, 所以可以在 ZooKeeper 上创建<strong>持久化节点 /Cluster 来存储集群的的元数据</strong>.</p> <p>​<img src="/img/ce2bb9fc92279d680a1507cce1749fc1-20240421231949-w5toc88.jpg" alt="">​</p> <p>因此集群初始化的流程是: <strong>Broker 启动时检查 ZooKeeper 的 /Cluster 节点是否创建, 以确保集群已经经过了初始化. 一般是集群中的第一台 Broker 节点启动时, 会触发集群初始化的逻辑. 初始化的逻辑会自动生成一个集群 ID, 然后根据配置好的集群名称, 一起写入到 /Cluster 节点里面</strong>.</p> <h6 id="节点元数据"><a href="#节点元数据" class="header-anchor">#</a> 节点元数据</h6> <p>节点元数据是用来<strong>保存 Broker 维度的一些基本信息</strong>. Broker 元数据一般至少要包含节点的唯一标识 BrokerID, 节点的 IP, 节点监听的端口 3 个字段.</p> <p>值得一提的是, 有的消息队列会用 &quot;<strong>节点 IP + 节点监听端口</strong>&quot; 二元组来标识 Broker, 而不是通过 BrokerID. 但是在容器化和云上的 CVM 环境中, IP 分配是随机的. 当节点销毁后, 重新分配出来的节点的 IP 可能会是一样的. 从而在一些极端场景下, 可能发生客户端识别集群错误, 从而出现异常的情况.</p> <p>所以, 这里还是建议使用 BrokerID 来唯一标识集群. 所以 Broker 节点的元数据结构一般如下所示:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;BrokerID&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment">// BrokerID 的类型可以是 Int 型, 也可以是字符串型, 区别不大. </span>
  <span class="token property">&quot;BrokerIP&quot;</span><span class="token operator">:</span><span class="token string">&quot;192.2.1.1&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;BrokerPort&quot;</span><span class="token operator">:</span><span class="token number">8901</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>从技术上看, 节点的元数据存储一般有这样两个思路:</p> <ul><li><strong>所有 Broker 元数据都存储在一个 ZooKeeper Node</strong>, 比如 /node, 节点内容如下:</li></ul> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;BrokerID&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerIP&quot;</span><span class="token operator">:</span> <span class="token string">&quot;192.2.1.1&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerPort&quot;</span><span class="token operator">:</span> <span class="token number">8901</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;BrokerID&quot;</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerIP&quot;</span><span class="token operator">:</span> <span class="token string">&quot;192.2.1.2&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerPort&quot;</span><span class="token operator">:</span> <span class="token number">8901</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;BrokerID&quot;</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerIP&quot;</span><span class="token operator">:</span> <span class="token string">&quot;192.2.1.3&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;BrokerPort&quot;</span><span class="token operator">:</span> <span class="token number">8901</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><ul><li><strong>每个 Broker 元数据独立一个 ZooKeeper Node 存储</strong>, 比如 /nodes/broker1, /nodes/broker2 等, 节点内容如下:</li></ul> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token punctuation">{</span>
    <span class="token string">&quot;BrokerID&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
    <span class="token string">&quot;BrokerIP&quot;</span><span class="token operator">:</span> <span class="token string">&quot;192.2.1.1&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;BrokerPort&quot;</span><span class="token operator">:</span> <span class="token number">8901</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>因为 Broker 数量不会很多, 一个集群大概是百或千的量级, 所以如果从 Broker 数量来看, 这两个方案的区别不大. 目前业界主要使用的是第二个思路, 主要的原因是: <strong>Broker 元数据分开存储方便管理, 避免节点间相互影响, 也可以避免单个 ZooKeeper Node 的数据量过大存不下</strong>.</p> <p>所以在持久化存储方面, 可以在 ZooKeeper 上创建持久化的 /brokers 节点, 然后在这个节点下为每台 Broker 创建名称为 BrokerID 的<strong>临时节点</strong>, 用来存储 Broker 的元数据. 所以 Broker 在集群中的元数据的存储结构就如下图所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/55a37358eyy77d53755d36584d8b27cf-20240421231949-ww3n1sy.jpg" alt="">​</p> <p>Broker 初始化的流程是: <strong>Broker 启动时会在 /Brokers 下面创建名称为自身 BrokerID 的临时节点, 然后写入自己的元数据</strong>. Broker 异常时, 会自动删除注册的节点.</p> <h5 id="在集群中支持topic和分区"><a href="#在集群中支持topic和分区" class="header-anchor">#</a> 在集群中支持Topic和分区</h5> <p>接下来看一下如何在一个空的集群中支持 Topic 和分区.</p> <p>前面的课程中讲到 Topic 和分区是消息队列集群的一个基本概念. 不知道你有没有过这样的疑问: <strong>消息队列一定要有 Topic 和分区的概念</strong>呢?</p> <h6 id="一定要有topic和分区吗"><a href="#一定要有topic和分区吗" class="header-anchor">#</a> 一定要有Topic和分区吗?</h6> <p>从业界主流消息队列来看, RocketMQ, Pulsar, Kafka 都有 Topic 的概念. 而 RabbitMQ 只有 Queue, 没有 Topic 概念, 但是 RabbitMQ 中的 Exchange + Route 起到的就是 Topic 的作用. 消息发送到 Exchange 中后, 会根据配置的路由关系, 将数据发送到不同的 Queue 中.</p> <p><mark><strong>从性能角度来看, 如果只有一个分区, 就会有性能瓶颈, 无法提供水平扩容的能力</strong></mark>. 此时就需要在前面包一层概念, 让它来组织多个分区, 这就是 Topic.</p> <p>所以如下图所示, 在<strong>消息队列中 Topic 和分区是必须的概念, Topic 是用来组织分区的逻辑概念, 分区用来存储实体的消息数据</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/60c323373e3a98f3f0848ec6bcb4856d-20240421231949-py4b4ry.jpg" alt=""></p> <p>接下来看一下, <strong>Topic 和分区的元数据都包含哪些信息</strong>呢?</p> <h6 id="topic和分区的元数据"><a href="#topic和分区的元数据" class="header-anchor">#</a> Topic和分区的元数据</h6> <p>从功能上来看, Topic 至少需要 TopicID, Topic 名称, 分区和副本在集群中的分布 3 个元素. 下面用一个简单的 JSON 格式字符串来表示 Topic 的元数据信息.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;TopicID&quot;</span><span class="token operator">:</span> <span class="token string">&quot;shlnjdlfsakw&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;TopicName&quot;</span><span class="token operator">:</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;Replica&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;Partition&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token property">&quot;Leader&quot;</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token property">&quot;Rep&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
                <span class="token number">0</span><span class="token punctuation">,</span>
                <span class="token number">1</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>可以看到, 在上面的示例中, TopicID, TopicName, Replica 分别表示 Topic 的唯一 ID, Topic 的名称以及分区副本的分布信息. 其中 Replica 里面的 Partition 表示当前是第几个分区, Leader 表示分区的 Leader 是哪台 Broker, Rep 表示副本是分布在哪些 Broker 上的.</p> <p>Topic 的信息是需要<strong>持久化保存</strong>的, 那如何存储这些元数据呢?</p> <h6 id="元数据的持久化存储"><a href="#元数据的持久化存储" class="header-anchor">#</a> 元数据的持久化存储</h6> <p>在基于 ZooKeeper 的架构中, 可以在 ZooKeeper 集群中<strong>创建一个持久化的节点来存储 Topic 的相关信息</strong>.</p> <p>如下图所示, 可以在 ZooKeeper 的根目录创建持久节点 /topics 存储 Topic 信息, 然后为 Topic1, Topic2, Topic3这 3 个 Topic 分别创建 <code>/topics/topic1, /topics/topic2, /topics/topic3</code>​ 节点来存储对应 Topic 的元数据.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/73828e5c70d0a002c55b9df32116ea7c-20240421231949-64yj4is.jpg" alt="">​</p> <p><strong>在集群启动时, 就会为每一个分区选举出来一个 Leader, 然后更新对应的 Leader 字段信息</strong>. 当节点出现变动时, 也会触发 Leader 节点切换流程和更新 Leader 节点信息的逻辑.</p> <h5 id="消费分组-订阅-的进度管理"><a href="#消费分组-订阅-的进度管理" class="header-anchor">#</a> 消费分组(订阅)的进度管理</h5> <p>接下来来看一下<strong>消费分组的进度是如何管理和保存</strong>的.</p> <p>消费进度主要有两个关联操作:</p> <ol><li>消费者根据消费分组名称来<strong>获取分区的消费进度信息</strong>.</li> <li>消费者在消费分组维度提<strong>交分区的消费进度信息</strong>.</li></ol> <p>从功能上来看, 获取消费进度的频率比较低, 一般初始化的时候拉取一次, 而<strong>更新 Offset 是每次消费请求都要执行的, 所以消费进度是一个低查询, 高更新的操作</strong>. 围绕着这些特性, 先来看一下消费进度的存储格式应该是什么样子的.</p> <h6 id="消费进度的存储格式"><a href="#消费进度的存储格式" class="header-anchor">#</a> 消费进度的存储格式</h6> <p>前面的课程中讲过, 消费进度的信息是在消费分组记录的, 一个<strong>消费分组可以消费多个 Topic</strong>. 所以应该根据 &quot;<strong>消费分组</strong> <strong>+</strong> <strong>Topic + 分区号</strong>&quot; 三元组来记录消费进度.</p> <p>假设消费分组 group1 同时消费 Topic1, Topic2, Topic3 三个 Topic, 这三个 Topic 的分区数量分别为 3个, 1个, 2个. 那么消费位点的存储格式可以如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>group1,Topic1,0,0
group1,Topic1,1,0
group1,Topic1,2,0
group1,Topic2,0,0
group1,Topic3,0,0
group1,Topic3,1,0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>在上面的实例中, 每一行分别表示<strong>消费分组, Topic, 分区号, 消费进度</strong>四个信息.</p> <p>从存储格式上来看, 一般存储的格式会用 <strong>JSON 格式或者自定义的行格式</strong>(行格式也可以是二进制格式), 用 JSON 格式和行格式存储的示例如下所示:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token comment">// 存储格式: </span>
<span class="token punctuation">{</span>
  <span class="token property">&quot;GroupName&quot;</span><span class="token operator">:</span><span class="token string">&quot;group1&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;TopicName&quot;</span><span class="token operator">:</span> <span class="token string">&quot;topic1&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Partition&quot;</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token property">&quot;Offset&quot;</span><span class="token operator">:</span><span class="token number">0</span>
<span class="token punctuation">}</span>

<span class="token comment">// 行格式</span>
group1<span class="token punctuation">,</span>topic1<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>两种格式的区别主要在空间占用和搜索效率两个方面. 所以在设计存储格式的时候, 就需要考虑这两个事情:</p> <ol><li><strong>搜索效率高</strong>.  设计好合适的存储数据结构, 比如哈希表, B 树等. 这里细节太多, 就先不展开.</li> <li><strong>不要占用太多额外的存储空间</strong>. 这一点考虑的就是存储的格式定义, 比如 JSON 或二进制格式.</li></ol> <p>从功能和开发成本上看, 两者的区别不大. 从可读性上, 个人建议直接用 JSON 格式就可以了. 主要考虑是这个消费位点的数据量不会很大, JSON 的可读性较好. 即使用 JSON 格式, 占用的额外空间也不会太大.</p> <h6 id="消费进度的保存机制"><a href="#消费进度的保存机制" class="header-anchor">#</a> 消费进度的保存机制</h6> <p>接下来看一下消费进度是如何保存的.</p> <p>从技术上来看, 最常用的<strong>保存消费进度的思路有存 ZooKeeper, 存本地文件, 存内部的 Topic, 存其他存储引擎 4 种思路</strong>. 下面逐一分析下.</p> <p><strong>存 ZooKeeper 是当前架构下一种最简单直观的方法</strong>. 通过在 ZooKeeper 中为每个消费分组创建一个<strong>持久化的节点</strong>, 比如 /groups/group1, 来保存每个消费分组的消费进度信息.</p> <p>因为 ZooKeeper 自带了分布式存储和一致性, 所以从功能实现上是最简单直接的. 但是<strong>当消费分组或者消费者数量很多时, 就会占用较多的 ZooKeeper 存储空间</strong>. 另外消费进度提交时都需要频繁对 ZooKeeper 节点进行更新, 这样会给 ZooKeeper 造成较大的压力, 从而容易使 ZooKeeper 集群高负载, 导致集群异常.</p> <p><strong>存本地文件也是一种常用的思路</strong>. 这种方案需要选择合适的数据结构来存储数据, 以便进行高效的写入和更新. 一般情况下, 如果实现优雅, 性能则不用担心. 另外存本地文件, 数据在本地硬盘存储, 存储容量一般是够的. 这个方案最大的问题是, 消费进度的数据文件<strong>不是分布式存储</strong>的. 当单机节点损坏或单机故障时, 就会导致无法读取消费进度数据或者消费进度丢失. 为了解决这个问题, 就需要在不同节点上同步消费进度数据, 并保持消费数据的一致性. 可以想一下, 要在不同节点同步文件数据, 并且保持文件数据的一致性, 是不是和分区副本的模型很像? 从技术上来看, 是一样的. 所以, 就有了将消费进度数据存储在某一个内部的 Topic 的思路.</p> <p><strong>存内部的 Topic 是指在集群中创建一个特殊名字的 Topic</strong>, 比如 consumer_group_offset. 此时这个 Topic 不允许普通用户读写, 只允许用来保存消费进度.</p> <p>如下图所示, 我们知道分区的数据是顺序存储的, 并且消息队列的分区是没有搜索和更新的能力的. 此时就有一个问题, 消费进度如何读取和更新呢?</p> <p>​<img src="/img/e9a41c34d1bd2fb7e08e31f5ee026f60-20240421231949-eehxaxj.jpg" alt="">​</p> <p>从功能特性上来看, 一个消费分组在一个分区维度的消费进度的值<strong>只有一个, 即最新的那个值</strong>.</p> <p>所以有一种思路是: <strong>提供有压缩功能的 Topic</strong>, 即 Topic 支持根据消息的 Key 对消息进行压缩. 比如消费分组 group 消费 Topic1 的 0 分区的进度的消息 Key 为 group1-topic1-0, Value 为消费位点, 比如 100. 根据消息的 Key 进行压缩, 只保留最后一条数据. 此时提交 Offset 的时候就不需要更新, 只需要将最新的消费进度的数据 &quot;group1-topic1-0: 101&quot; 写入到 Topic 中.</p> <p>依托 Topic 的压缩特性, 只保留最后一条数据, 就可以让数据量大幅度减少. 再配合一些编码技巧, 如缓存, 索引, 二分查找等, 就能大大提升获取当前消费分组的位点信息的速度.</p> <p><strong>存其他存储引擎是指将消费进度存储在其他的存储引擎中</strong>, 比如 MySQL, Redis 或其他第三方引擎等. 这种方案本质上和存 ZooKeeper 的思路是一样的. 遇到的问题也一样, 主要是<strong>性能和稳定性方面</strong>的不足. 和存 ZooKeeper 最大的区别在于, 如果在消息队列 Broker 上采用这个方案, 就得单独为存储消费进度信息而引入一个存储组件, 这样会增加系统复杂度, 还要考虑第三方组件的稳定性问题.</p> <p>一般将消费进度存储到第三方引擎的场景是在消费者客户端. 即消费者不使用消费分组来管理消费进度, 而是自定义管理消费进度信息, 此时可能会将消费进度存储到第三方存储引擎中, 以保证消费进度不丢失.</p> <p>从选择上来看, <strong>目前 Kafka 的消费位点保存方案最开始用的是存 ZooKeeper, 后来用的是存内部的 Topic 的方案. RocketMQ 用的是存本地文件的方案. Pulsar 用的是存其他存储引擎 BookKeeper 的方案, Pulsar 能用这种方案的原因在于它是存算分离的架构, 天然自带了存储引擎 BookKeeper, 因此不会因为存储消费进度而引入额外的复杂度和成本</strong>.</p> <h5 id="总结-27"><a href="#总结-27" class="header-anchor">#</a> 总结</h5> <p>这节课的元数据都是以必备的, 最基础的角度来设计的. 随着业务功能的增加, 元数据就会不断丰富. 所以主流消息队列的元数据, 因为功能和架构的不同都会很复杂, 但是基础的信息都是一样的.</p> <p>集群和 Broker 元数据是构成消息队列集群的基础. 最基础的集群元数据主要包含集群 ID 和集群名称两个信息. 最基础的 Broker 主要包含 BrokerID, BrokerIP, BrokerPort 三个信息. 只要有这几个信息, 就能构建成一个消息队列集群.</p> <p>Topic 是消息队列最基本的概念, 从理论上来说没它不行. 它的主要功能是<strong>给分区提供一个横向扩容的能力</strong>, 并用来组织多个分区的逻辑关系. 最基础的 Topic 和分区的元数据主要包含 TopicID, Topic 名称, 分区和副本在集群中的分布信息三部分. 在分布信息中还会包含分区号, 分区 Leader, 副本的分布3个子信息.</p> <p>消费进度一般以 &quot;消费分组 + Topic + 分区号&quot; 三元组来记录消费进度. 记录的格式一般有 JSON 格式和自定义行格式两种. 从功能和开发成本来看, 一般情况下 JSON 格式就够了.</p> <p>消费进度的保存机制主要有存 ZooKeeper, 存本地文件, 存内部的 Topic, 存其他存储引擎四种思路. 它们在不同的架构中, 优缺点不一样, 根据当前的架构选择合适的方案即可. 从业界主流消息队列来看, 四种方案都有在用.</p> <h5 id="思考题-24"><a href="#思考题-24" class="header-anchor">#</a> 思考题</h5> <blockquote><p>假设将元数据存储服务从 ZooKeeper 换成 MySQL, 元数据的增删改查应该是怎样的一个流程?</p></blockquote> <ol><li>写入操作: 将 ZooKeeper 的 create 操作, 换成 MySQL 的 insert 操作.</li> <li>更新操作: 将 ZooKeeper 的 update 操作, 换成 MySQL 的 update 操作.</li> <li>删除操作: 将 ZooKeeper 的 delete 操作, 换成 MySQL 的 delete 操作.</li> <li>心跳超时: 原先只需要 Zookeeper 的客户端在 ZooKeeper 上创建临时节点就可以了, 在 ZooKeeper 的底层集成了连接超时, 删除临时节点的操作. 如果是 MySQL, 大致的思路是在 Broker 中维护一个线程定时去更新 MySQL 中的行记录的时间, 然后通过另外一个线程去检查是否超期, 然后删除记录.</li> <li>Watch 机制: ZooKeeper 自带了 Watch 机制, 很多监听操作 ZooKeeper 底层自动完成了. 如果是 MySQL, 同样的得不停地定时去表里面查询配置是否更新, 然后执行后续的操作.</li></ol> <p>从上面几步看下来, 有两个比较明显的结论:</p> <ol><li>可以通过 Interface 机制去定义接口, 然后用不同的实现方式去实现这些接口, 从而支持多种底层引擎的元数据服务.</li> <li>使用 ZooKeeper 这种分布式协调服务, 比使用 MySQL 这种持久化存储引擎来存储元数据更加简单好用.</li></ol> <h4 id="_28-顺序消息和幂等-如何实现顺序消息和数据幂等"><a href="#_28-顺序消息和幂等-如何实现顺序消息和数据幂等" class="header-anchor">#</a> 28-顺序消息和幂等:如何实现顺序消息和数据幂等?</h4> <p>这节课来讲一下消息队列中的<strong>顺序消息和幂等机制</strong>实现.</p> <p>在消息队列中, 消息是否能有序是一个常常被问到的问题. 因为在业务中, 比如在有序事件处理, 数据实时增量同步等情况下, 就需要消息队列支持顺序消息的机制. 接下来就来看看消息队列中顺序消息的定义和实现.</p> <h5 id="顺序消息的定义和实现"><a href="#顺序消息的定义和实现" class="header-anchor">#</a> 顺序消息的定义和实现</h5> <p>在消息队列中, 消息的顺序性一般指的是时间的顺序性, 排序的依据就是时间的先后. 从功能来看, 即 <strong>生产端发送出来的消息的顺序和消费端接收到消息的顺序是一样的</strong>. 牢记这个定义, 对于我们后面理解顺序消息的实现很重要.</p> <h6 id="消息队列的存储结构特性"><a href="#消息队列的存储结构特性" class="header-anchor">#</a> 消息队列的存储结构特性</h6> <p>回顾一下前面讲过的消息队列的底层存储结构. 消息队列的底层消息是<strong>直接顺序写入到文件</strong>的, 没有用到 B 树, B+树等任何数据结构. 从技术上看主要有如下两个方面的原因:</p> <ol><li>复杂的数据结构会影响数据写入和读取的性能.</li> <li>消息队列功能需求较为简单, 不太需要复杂的数据结构来支持检索等操作.</li></ol> <p>所以, 理想情况下顺序消息的实现是: <strong>生产端按顺序发送消息, Broker 端按接收到的顺序存储消息, 消费端按照 Broker 端存储的顺序消费消息</strong>. 那技术上的实现真的有这么简单吗? 我们继续分析.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/069374fe8a3098bb5cd1ef7ac4abfc0d-20240421231949-k4zvkmx.jpg" alt="">​</p> <p>如上图所示, 实现顺序消息的核心就是: <mark><strong>Broker 接收到的消息的顺序要和生产端发出来的顺序是一致的</strong></mark>. 那在实际的场景中, 会发生什么事呢?</p> <ol><li><strong>如果有多个生产者, 因为发送时间点不一样, 网络延迟不一样, 此时多个生产者发送到 Broker 的顺序就无法保证有序, 此时落盘的顺序就无法保证</strong>.</li> <li>如果是单个生产者且是异步发送, 其底层实现是有多个异步线程在负责发送数据, 此时可能会<strong>失败重试</strong>. 然后就会出现 Broker 接收到消息的顺序和发送的顺序不一样的情况, 此时落盘的顺序也无法保证.</li> <li>如果 Topic 有多个分区, 即使是一个生产者同步发送, 因为生产者的生产分区分配策略的存在, <strong>消息可能会被分发到多个分区里面, 此时也无法保证顺序性</strong>.</li></ol> <p>所以基于消息队列架构上的这些特性, 接下来看看<strong>在消息队列中如何实现顺序消息</strong>.</p> <h6 id="基于顺序存储结构的设计"><a href="#基于顺序存储结构的设计" class="header-anchor">#</a> 基于顺序存储结构的设计</h6> <p>基于顺序存储结构的设计, 是指保持消息队列底层顺序存储结构不变的前提下, 实现顺序消息的技术方案.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3217de363e6babed33de427db252fc18-20240421231949-cd9a314.jpg" alt="">​</p> <p>如上图所示, 这是一个三分区的 Topic 的底层存储结构. 结合前面提到的 3 种实际的场景, 为了实现顺序消息就需要满足<strong>单一生产者, 同步发送, 单一分区三个因素</strong>. 就是说在当前的顺序存储结构中, 消息队列实现顺序消息的前提是: <mark><strong>一个生产者同步发送消息到一个分区才能保证消息的有序</strong></mark>.</p> <p>其中, <strong>单一生产者+同步发送</strong> 是为了解决生产端数据发送的有序性, 只有前面一条数据写入成功后, 后面的数据才能继续写入. 从而规避重试发送, TCP 网络延迟带来的不同的请求包到达 Broker 的时间不一样, 导致 Broker 保存数据的顺序和客户端发送的顺序不一致的问题.</p> <p><strong>单一分区</strong> 是为了解决消息数据被发送到不同的分区中, 导致的不同消费者消费不同分区中的消息的顺序不可控的情况.</p> <p>那就有一个问题: 如果只能是单一分区, 消息队列就失去了水平扩容能力, 而无法水平扩容对性能的影响会很大. 那有解决办法吗?</p> <p>有一个点需要知道, <strong>在实际的业务场景中很少会要求所有的的数据是有序的</strong>. 比如在数据库 Binlog 订阅的场景中, 假设一个数据库里面有 100 张表, 此时一般只需要保证每张表或者某一行记录的变更记录是有序的即可, 因为下游的处理的主体一般是表或者行. 所以在实际的场景中, 只需要<strong>保证局部有序</strong>即可, 而不需要全局有序.</p> <p>那么从技术上看, 就只要<strong>保证局部有序的数据写入同一个分区</strong>即可, 即 <mark><strong>根据某个标识将需要有序的数据发送到同一个分区中</strong></mark>. 举个例子来说明这个标识的作用.</p> <p>​<img src="/img/0ede26c23bdb16096b583b05405b41df-20240421231949-8x2gneq.jpg" alt="">​</p> <p>如上图所示, 给每一批需要排序的消息赋予一个标识, 然后把标识为 k1, k2, k3 的消息分别固定发送到分区一, 二, 三, 从而在满足单一生产者, 同步发送, 单一分区三个因素的同时, 也可以具备水平扩容的能力.</p> <p>这个方案有个缺点是: <strong>如果某一个标识的数据量特别大, 就可能会出现写入数据倾斜</strong>. 比如 k1 的数据量非常大, k2, k3 的数据量很小, 数据就会全部写入到 k1 中, 从而导致集群 Broker 之间的负载出现倾斜, 影响集群的稳定性.</p> <p>目前来看, 在当前消息队列的架构中, 数据倾斜纯依靠服务端很难解决, 需要客户端配合, 将数据打散写入到多个分区中, 不过这样做就无法保证消息的顺序了.</p> <p>所以如果要同时解决数据倾斜和保证顺序消息, 就需要引入复杂的数据结构. 即类似 MySQL 的实现, 在消费的时候对数据进行排序, 然后再返回给客户端.</p> <h6 id="主流消息队列的实现机制"><a href="#主流消息队列的实现机制" class="header-anchor">#</a> 主流消息队列的实现机制</h6> <p>接下来来看一下, 目前主流消息队列对于<strong>顺序消息的支持方式</strong>.</p> <p>四款主流消息队列对于顺序消息的实现机制如下:</p> <p>​<img src="/img/ffff9e021107ca607cd619cda3031f61-20240421231949-i61lqkc.jpg" alt="">​</p> <p><mark><strong>Kafka 和 Pulsar 是通过生产端按 Key Hash 的方案将数据写入到同一个分区. RocketMQ 是通过消息组(功能上类似消息 Key)将同一个消息组的数据写入到不同的 MessageQueue</strong></mark>. RabbitMQ 是通过 Exchange 和 Route Key 的机制, 将数据写入到不同的 Queue 里面.</p> <p>接下来看一下实现的细节.</p> <p><strong>Kafka 和 Puslar 的生产端支持按 Key Hash 的生产分区分配策略</strong>. 只需要给每条消息<strong>赋予一个消息 Key</strong>, 比如将属于 AppID 1001 客户的消息的 Key 都设置为 1001, 此时 Key 为 1001 的消息会被固定发送到同一个分区. 配合生产端的单个生产者和同步发送机制, 就可以保证属于 AppID 为 1001 的数据被有序存储.</p> <p><strong>RocektMQ 支持消息组(MessageGroup)的概念</strong>. 在生产端指定消息组, 则同一个消息组的消息就会被发送到同一个分区中. 此时这个消息组起到的作用和 Kakfa 的消息的 Key 是一样的.</p> <p>RabbitMQ 在生产时没有生产分区分配的过程. 它是通过 Exchange 和 Route Key 机制来实现顺序消息的. Exchange 会根据设置好的 Route Key 将数据路由到不同的 Queue 中存储. 此时 Route Key 的作用和 Kafka 的消息的 Key 是一样的.</p> <p>总结来看, Kafka 和 Pulsar 中的消息 Key, RocketMQ 的消息组, RabbitMQ 的 Route Key 就是前面提到的 <strong>标识</strong>. 只要标识一样数据, 就会被路由到同一个分区进行存储, 从而保持消息有序. 关于这四款主流消息队列的生产端的实现, 可以回顾一下前面的内容.</p> <h5 id="幂等机制的定义和实现"><a href="#幂等机制的定义和实现" class="header-anchor">#</a> 幂等机制的定义和实现</h5> <p>接下来来看看<strong>幂等的定义和实现机制</strong>, 先来看看什么是幂等.</p> <p>在开发一些 App 服务时, 经常会提到 <strong>接口幂等</strong> 这个词. <strong>接口幂等是指无论调用多少次, 接口执行的结果都是一样的</strong>. 以写入接口举例, 接口幂等的语义就是不管写入多少次, 这条消息只会被<strong>真正写入一次, 不会被重复写入</strong>. 查询, 删除, 变更类型的接口的幂等语义也是一样的.</p> <p>那么消息队列中的幂等是指什么呢?</p> <h6 id="消息队列中幂等的定义"><a href="#消息队列中幂等的定义" class="header-anchor">#</a> 消息队列中幂等的定义</h6> <p><strong>消息队列中的幂等主要指生产幂等和消费幂等, 当然还有其他一些集群管控类的操作的幂等</strong>, 比如创建 Topic, 切换 Leader 等.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/8ec71f8eb5f7cabf857d42f22c855yyb-20240421231949-gzaj0qr.jpg" alt=""></p> <p><strong>生产幂等</strong> 通常指同一条消息不会被重复写入到 Broker. 即同一条消息客户端无论重复发送多少次, 服务端也只会保存一份这条消息.</p> <p><strong>消费幂等</strong> 很少被单独提到. 前面讲到的消息队列主要是基于消费位点的消费机制. 只要客户端不提交消费位点信息, 此时消费天生就是幂等的. 即不管怎么消费, 返回的都是同一条消息. 而如果提交了 Offset, 就会自动消费下一条数据, 也符合设计预期. 在提交位点的操作中, 即使重复提交了同一个位点, 消费位点保存的都是同一个值, 对消费也不会产生影响.</p> <p>因此消费端谈的更多的是 <strong>Exactly Once, 即如何保证一条消息只会被消费一次</strong>. 这个话题在后面讲消息队列事务时再展开细讲. 所以接下来就重点来看看生产端的幂等是如何实现的.</p> <h6 id="生产幂等的设计实现"><a href="#生产幂等的设计实现" class="header-anchor">#</a> 生产幂等的设计实现</h6> <p>先来思考一个问题: 如果一条消息客户端发送了多次, 而 Broker 端只能保存一份, 此时最核心要解决的是什么问题呢?</p> <p>答案应该是: <strong>Broker 怎么识别接收到的多条消息是指同一条消息</strong>? 即如果 Broker 不知道收到的消息是否为同一条, 那就无法拒绝重复的消息.</p> <p>先来看下面这个示例:</p> <p>​<img src="/img/8e728581ef78c941ef859da755116da3-20240421231949-bv9xpiw.jpg" alt="">​</p> <p>你认为生产端的第二, 三行是同一条消息吗? 答案是: 不是同一条消息. 原因是 Producer 主动调用了两次 send 方法, 所以应该认为客户端发送了两条消息. 此时这两条消息都需要保存.</p> <p>再来看一下下面这个场景:</p> <p>​<img src="/img/a20e25d2c929dcbc6af1d32bffb9b44b-20240421231949-mpp621n.jpg" alt="">​</p> <p>Producer 只调用了一次 send 方法, 只发送了一条消息. 但是因为底层网络或者其他故障, 这条消息在底层被重传了 2 次, 导致 Broker 端收到两条内容都是 abc 的消息. 此时从 Broker 端看来, 无法区分清楚收到的两条内容都是 abc 的消息, 客户端是主动 send 了一次还是两次?</p> <p>讲到这里, 就知道了<strong>消息的唯一性应该是以 Producer 的 send 调用为准</strong>. 即 Producer send 一次就表示发送了一条消息, send 两次表示发送两条消息. 所以就需要<strong>在客户端调用 send 的时候标识消息的唯一性, 以标识消息的唯一</strong>.</p> <p>从技术上来看, 主要有两种方案.</p> <blockquote><p>1.通过消息唯一 ID 实现幂等</p></blockquote> <p>通过消息唯一 ID 实现幂等是指在发送消息的时候, 为<strong>每条消息分配唯一的消息 ID(MsgID), 来表示消息的唯一性</strong>. 如下图所示, 消息中携带 MsgID 发送到 Broker, Broker 根据 MsgID 判断这条消息是否已经接收, 如果没有就保存数据, 否则就拒绝写入.</p> <p>​<img src="/img/2e0c79d2a000ba535f196a899d270091-20240421231949-6bh80ij.jpg" alt="">​</p> <p>基于这种方案的前提是, <strong>需要在生产端开启按 Key Hash 的机制, 以保证同一个 MsgID 的消息可以发送到同一个分区中</strong>. 否则如果同一条消息多次发送投递到不同分区, 此时就无法判断之前是否接收过这条消息了.</p> <p>这种方案主要有两个技术问题需要重点解决: <mark><strong>一个是消息唯一 ID 的生成策略, 另一个是 Broker 如何识别之前没有接收过这个消息 ID</strong></mark>.</p> <p><strong>消息唯一 ID 的生成策略</strong>, 也可以理解为分布式唯一 ID 的生成, 这样就比较好理解. 技术上最简单的就是 UUID, 但是因为 UUID 的内容长度和有可能重复等问题, 在消息队列中并不适用.</p> <p>技术上看, 在业务系统中常常基于 MySQL/Redis/ZooKeeper 等第三方系统或基于雪花(Snowflake)算法生成分布式唯一 ID. 但是在消息队列客户端直接集成 MySQL/Redis/ZooKeeper 等引擎的复杂度太高, 所以这个方案基本不可用, 因此<strong>雪花算法算是比较常用的方案</strong>.</p> <p>雪花算法的目标是生成一个唯一的 int64(long) 的整形数字. 它的核心思想是将 long 型的64位区分为5段进行组合, 以生成规定的唯一数字. 来看一下 64 位 long 型的结构:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bc4f5d4e35d1d441029fa577f74d9595-20240421231949-07uql72.jpg" alt="">​</p> <p>如上图所示, 64位 long 型的结构一般可以分为 <strong>符号位, 时间戳, 数据中心 ID, 机器 ID, 计数器</strong> 5个字段, 每个字段的意义是不一样的. 算法的核心是数据中心 ID 和机器 ID 这两个字段, 只要这两个字段的内容是唯一的, 那么就可以保证生成的 long 型的值是唯一的.</p> <p>一般情况下从业务上看, 只需要在 Topic 维度保持消息的顺序性就可以. 前面在提到消息队列架构中, 会有集群 ID 和 TopicID 来唯一标识集群和 Topic, 因此可以将雪花算法中的数据中心 ID 和机器 ID 替换为集群 ID 和 TopicID, 这样就可以使生成的消息 ID 是唯一的.</p> <p><strong>Broker 如何识别之前没有接收过这个消息 ID</strong>, 就是说需要<strong>在 Broker 端设计保存已经接收到的所有 MsgID, 用来在接收到消息后将消息 ID 和当前接收过的所有的消息 ID 做一个比较, 以判断消息是否重复</strong>.</p> <p>此时有一个问题是, 理论上 Broker 需要保留已经接收过的所有消息 ID 的集合, 而消息队列作为一个大吞吐的存储组件, Broker 历史接收的消息量会很大. 消息 ID 的记录, 匹配的性能肯定会有问题, 并且也需要占用大量硬盘空间.</p> <p>从实际实现的角度来看, 有几个小技巧可以分享一下.</p> <ul><li><strong>可以在 Topic 维度保存消息 ID, 不需要将集群所有的消息 ID 都存在一起</strong>, 这样可以提高消息 ID 保存, 加载和查询的性能.</li> <li>因为消息队列的消息有过期的机制, 消息 ID 的集合可以只保留当前还在生命周期内的消息 ID. 好处是消息 ID 的数量就会减少很多, 从而提高性能, 减少存储空间. 缺点是客户端可能重新发送过期的消息(这点理论上可能性较低, 几乎可以忽略), 另外需要给消息 ID 集合设计过期机制, 会增加一定的开发成本.</li> <li><strong>可以引入布隆过滤器来判断消息 ID 是否在已接收过的消息 ID 集合中, 用来提高消息 ID 去重判断的性能</strong>. 布隆过滤器的作用是用于检索一个元素是否在一个集合中.</li></ul> <p>整个方案的思路看下来, 如果通过在 Broker 上识别重复的 MsgID 来实现幂等, 需要在代码层面做很多细致的工作, 代码工作量不小. 那有没有简单一些的方案呢? 接下来就来看一下<strong>通过生产者 ID 和自增序号来实现幂等</strong>的方案.</p> <blockquote><p>2.通过生产者 ID 和自增序号实现幂等</p></blockquote> <p>在前半部分讲到, 我们认为 Producer 调用一次 send 就是一条新的消息, 所以<strong>幂等的逻辑主体应该是生产者</strong>.</p> <p>所以该方案的核心思路是: <strong>为每个生产者赋予唯一的 ID, 生产者 ID 是全局唯一的</strong>. 然后生产者启动时生成一个从0开始的自增序号, 用来表示这个生产者发送出去的消息, 每条消息分别有一个自增序号, 比如 0, 1, 2... 即<strong>通过 Producer 和 seqnum 二元组来唯一标识消息</strong>.</p> <p>特别说明一下, 生产者 ID 可以用上面提到的 Snowflake 算法来生成, 因为生产者很少, 甚至直接用 UUID 也可以, 毕竟 UUID 重复的几率也非常低.</p> <p>来看一下下面这张图:</p> <p>​<img src="/img/b96762db952ea8ba4f428c435dfc869a-20240421231949-mm0qsyy.jpg" alt="">​</p> <p>在上图中, 生产者有一个唯一 ID p1, 消息中会携带 ProducerID 和 seqnum 两个值来唯一标识这条消息. 此时 Broker 会根据这个二元组判断是否收到过这条消息, 是就保存, 否就拒绝.</p> <p>从实现的角度, 服务端理论上依旧要保留这个生产者所有发送成功的 seqnum 的集合, 这样才能判断消息是否有重复. 此时如果生产者很多并且生产者一直没有重启的话, 服务端就需要保留非常多的 Producer 和 seqnum 数据.  <strong>此时开发复杂度和上一个方案是差不多的, 技术实现上只是把标识从 MsgID 换为 Producer + seqnum 而已, 没有本质区别</strong>.</p> <p>既然没有本质区别, 那么这个方案跟第一种方案的区别哪里呢? 从技术上看, 有一个<strong>技巧</strong>可以不保存生产者所有发送成功的 seqnum 集合, 但是又可以识别出所有已发送的 seqnum.</p> <p>这个技巧的思路是: <strong>不保留所有的 seqnum, 只保留最新收到的 seqnum</strong>. 此时如果收到的消息的 seqnum 是下一条 msg, 那么就正常保存数据. 否则就放进队列中先等待, 等待下一条 msg 收到后, 再来判断是否保存该数据, 甚至可以直接拒绝消息写入.</p> <p>通过下面这张图来说明一下:</p> <p>​<img src="/img/de2yy635b56029f4c23126f7efbdc2a1-20240421231949-jihn1gv.jpg" alt="">​</p> <p>Broker 收到的 Producer ID 为 p1 的生产者的最新的 seqnum 为 4(current seqnum), 那么下一条允许收到的 seqnum 是 5. 如果下一条是 5, 则保存数据, 然后 current seqnum 更新为 5, 并等待 seqnum 为6的数据. 而如果此时发送过来的是 8, 就可以有<strong>两种策略</strong>:</p> <ul><li>策略一: 先把 8 缓存在 Broker 内存中, 等待收到 6 和 7 后, 再把 8 写入存储. 这种方案的缺点是 6 和 7 可能永远接收不到, 而 Broker 就需要一直保存 8 这条数据. 因此可能会发生内存溢出或占用额外的存储空间.</li> <li>策略二: <strong>给客户端返回可重试错误, 触发客户端的重复发送机制</strong>. 此时客户端重试写入时, 如果 Broker 已经收到 7 的数据, 在等待 8 了, 此时这条消息就可以顺序写入了.</li></ul> <p>目前业界主流的消息队列只有 Kafka 支持幂等, 其他三款消息队列 RocketMQ, RabbitMQ, Pulsar 都不支持. 所以接下来<strong>简单看一下 Kafka 幂等机制的实现方式</strong>.</p> <h6 id="kafka的幂等机制的实现方案"><a href="#kafka的幂等机制的实现方案" class="header-anchor">#</a> Kafka的幂等机制的实现方案</h6> <p>kafka 的生产者在启动时会为<strong>每个生产者分配一个唯一 ID</strong>. 这个唯一 ID 是客户端从 Broker 申请的, 不是自己生成的. 来看下图:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6f70200b2aeb7ea1e97e22c5d7608824-20240421231949-gbd7kq8.jpg" alt=""></p> <p>从实现上看, Broker 通过在 ZooKeper 创建一个节点来生成自增 ID, 然后返回给客户端, 从而保证生产者的 ID 是这个集群唯一的, 属于基于第三方系统来生成分布式唯一 ID. 这里要注意的是, <strong>唯一 ID 是 Broker 和 ZooKeeper 交互生成的, 而不是客户端直接和 ZooKeeper 交互生成的, 这是为了避免给客户端引入了过高的复杂度</strong>.</p> <p>Kafka 支持 Batch 语义, 所以在发送消息的时候会为每批次消息赋予一个 seqnum, 用来标识这个生产者发送的消息的唯一性. 和上面的思路有些不一样的是, Kafka 在<strong>每个 Topic-Partition 维度都会有一个独立的 seqnum</strong>, 即通过 <strong>PID, Topic, PartitionNum, seqnum</strong> 四元组来唯一标识一条消息. 稍后再来说明为何这样实现.</p> <p>先重点来看一下, <strong>Kafka 是怎样判断发送的消息是否重复的</strong>?</p> <p>从具体实现上看, Broker 端会缓存 PID 对应 Topic-Partition 的<strong>五个最近的 batch 信息</strong>. 比如曾经接收过1, 2, 3, 4, 5, 6 六个消息, 此时只会缓存 2~6 五个消息 ID. 如下图所示, Broker 接收到数据后, 会循环缓存中的数据, 判断是否重复, 重复就拒绝, 不重复就直接保存.</p> <p>​<img src="/img/964b540200ab03f8dab7eaa1637f603a-20240421231949-9cv7ris.png" alt="">​</p> <p>此时有一个问题是, 如果消息 1 过期后, 客户端再把消息 1 发送过来, 此时判断结果就是不重复, 从而写入数据, 那么数据就没办法达到真正意义上的幂等了. 所以从具体实现上来看, <strong>Kafka 的幂等是无法实现完全幂等的, 只能支持部分的幂等</strong>.</p> <p>既然这样, 那为什么还用这个方案呢?</p> <p>上面提到过, 如果使用保留判断最后一个 seqnum 的方案, 就会对性能有影响. 如果实现强幂等则需要缓存全量 seqnum, 对内存和存储空间的压力较大, 判断匹配性能也会较低, 从而对写入性能产生影响.</p> <p>Kafka 的实现方案可以说是一个<strong>取舍</strong>的方案. 因为 Kafka 主打的是高性能, 不能因为幂等的特性导致性能下降太多. <strong>通过缓存少量的数据来实现大部分情况下的幂等, 也不会对内存和性能造成太大影响, 只是付出的代价是不能支持完全的幂等</strong>.</p> <p>现在回到上面的问题, 为什么要用 PID, Topic, PartitionNum, seqnum 四元组来唯一标识一条消息?</p> <p>可以想一下基于这个实现机制, 如果每台节点只保留 5 条数据, 那么几乎一下子缓存就被刷掉了. 即使调大缓存大小, 因为有些分区的数据量大, 有些分区数据量小, 此时一些小分区的数据缓存一下子就被挤出去了, 从而完全无法实现幂等. 因此基于这个四元组来缓存数据, 就是一个可以理解的方案了.</p> <p>至于为什么是 5 条, 我这里也没答案, 个人判断是拍的一个数字. 如果非得从技术方面解释, 可以这么解释:</p> <p>因为数据是存在内存中的, 需要保证这个功能的缓存数据不会对内存造成压力, 因此需要控制内存的使用总量. 因此假设单台 Broker 可支持的分区数为 P, 单台生产者的数量为 M, 存的消息数量为 N, 此时消耗的内存总量为 T, 因此:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>T = P * M * N
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>因为 M 是完全不可控的, P 取决于用户的运营策略, 某种意义也不可控, 所以内核可控的就是 N. 因此 N 如果太大, 则会对内存造成太多压力, 所以 N 就不能太大. 基于此, 可能就拍了个 5 吧. 值得一提的是, 5 是 hard code 在代码里面的, 不能改动.</p> <h5 id="总结-28"><a href="#总结-28" class="header-anchor">#</a> 总结</h5> <p><strong>消息队列中的顺序消息是指时间先后的顺序, 即生产消息的顺序和消费消息的顺序需要保持一致</strong>. 主要实现思路是基于底层顺序存储的结构特点来设计的. 这种实现方式成本较低, 也比较贴合消息队列架构和功能的特点.</p> <p><mark><strong>核心逻辑是需要满足单一生产者, 同步发送, 单一分区三个因素. 单一生产者+同步分区是为了解决生产端数据发送的有序性, 单一分区解决的是多分区消费的无序性</strong></mark>.</p> <p>在现实场景中, 一般不需要数据全量有序, 而是<strong>局部数据的有序</strong>. 因此可以为需要局部有序的消息赋予同一个唯一标识, 然后将同一个标识的消息发送到一个分区, 从而解决一个 Topic 只有一个分区, 从而导致性能不足的问题.</p> <p>目前主流消息队列的顺序消息的方案, 都是基于上面的思路来实现的. 单从技术合理性来看, 数据的顺序性也可以通过查询时的重排序来完成, 即在查询的时候, 根据需要排序的信息完成排序, 然后发送结果给客户端. 这种方案的技术复杂度较高, 并且性能较低, 不太适合消息队列, 所以消息队列用得比较少.</p> <p>消息队列的幂等分为<strong>生产幂等, 消费幂等, 集群管控类操作幂等</strong>三种类型. 从功能上来看, 在消息队列中的幂等主要指生产幂等.</p> <p>生产幂等的技术实现方案主要分为 &quot;<strong>通过消息唯一 ID 实现幂等</strong>&quot; 和 &quot;<strong>通过生产者 ID 和自增序号实现幂等</strong>&quot; 两种思路. 主要区别是, 解决 Broker 如何唯一识别一条消息的思路不一样. 第一种是通过唯一的消息 ID 来唯一识别一条消息, 第二种是通过生产者 ID 和消息序号 seqnum 来唯一识别一条消息.</p> <p>从实现的角度来看, 两种方案的实现思路差别不大. 开发成本上各有各有优劣势, 都可以使用. 个人会比较倾向于第一种, 因为第一种思路中的消息 ID 是消息队列的一个基本需求, 这部分的开发工作量不会浪费. 从而只需要在服务端实现消息 ID 的去重即可, 整体来看实际收益较高.</p> <p>目前业界主流消息队列 Kafka 的幂等机制, 就是基于第二种思路来实现的.</p> <h4 id="_29-延时消息-如何实现高性能的定时-延时消息"><a href="#_29-延时消息-如何实现高性能的定时-延时消息" class="header-anchor">#</a> 29-延时消息:如何实现高性能的定时/延时消息?</h4> <p>上节课讲完了顺序消息和幂等机制, 这节来看看消息队列中的<strong>定时和延时消息是如何实现的</strong>. 在消息队列中, 定时和延时消息的底层技术实现是一样的, 后面统一用 <strong>延时消息</strong> 来称呼. 下面从延时消息的使用场景和定义讲起.</p> <h5 id="延时消息的场景和定义"><a href="#延时消息的场景和定义" class="header-anchor">#</a> 延时消息的场景和定义</h5> <p>先来看一个延时消息典型的使用场景. 在网上购买商品下单的过程中, 有个功能是: 下单完成后 30 分钟如果没有完成支付, 则这个订单就自动被取消.</p> <p>如下图所示, 从技术上来看, 为了实现这个功能, 最直观的思路是可以将订单数据存在 DB 的表中. 然后通过定时程序每秒定时去扫描订单数据, 判断如果超过 30 分钟则进行后续的处理.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a5c763094c428aa0497223004b1f959e-20240421231949-htj0q8s.jpg" alt=""></p> <p>这个方案的问题是, 业务方维护成本较高, 需要开发维护定时任务并处理扩缩容, 以保证数据处理的及时性. 当订单数据量很大时, 就容易出现性能问题. 另外可能无法实现高精度的延时.</p> <p>因此理想状态是延时逻辑下沉到某个底层的引擎去实现, 业务不需要感知任何延时逻辑, 正常处理数据即可. 在技术体系中, 这个底层引擎一般由消息队列来担任. 因此只要在类似这种 <strong>需要定时或者延时触发某个行为的场景</strong>, 都可以用到延时消息.</p> <p>从技术上看, 消息队列中延时消息的定义是: 客户端发送设置了到期时间的消息到 Broker 后, 该消息在时间到期后能被下游消费到.</p> <p>从功能表现来看, 就是 <strong>Broker 接收到客户端发送的延时消息后, 将消息设置为不可见, 在时间到期后把消息从不可见变为可见, 从而让下游可以消费到数据</strong>.</p> <h5 id="从技术上拆解延时消息"><a href="#从技术上拆解延时消息" class="header-anchor">#</a> 从技术上拆解延时消息</h5> <p>接下来从技术上来拆解一下延时消息. 先通过下面这张图来了解一下<strong>延时消息的生命周期</strong>.</p> <p>​<img src="/img/db8c22f1411bd3fb204d3b0e8883dbd6-20240421231949-sxjtwus.jpg" alt="">​</p> <p>从使用上来看, 假设生产端发送定时 30 分钟后或者明天早上 8 点可见的消息给 Broker, Broker 在接收到延时消息后, 会先<strong>持久化存储消息, 然后标记这个消息不可见</strong>. 再通过内部实现的定时机制, 延时到期后 <strong>将不可见消息变为可见消息</strong>, 从而让客户端可以正常消费到这条数据.</p> <p>所以从技术上来看, 消息队列实现延时消息主要包含<mark><strong>数据存储, 如何让消息可见, 定时机制, 主动推送</strong></mark>四个部分.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c9f4783cf362be766bd9379b4af02fee-20240421231949-8zmvhsr.jpg" alt=""></p> <p>因为数据存储和主动推送在基础篇详细分析过, 这里就不再展开, 可以去回顾一下. 这节课重点讲解 &quot;如何让消息可见&quot; 和 &quot;定时机制&quot;.</p> <h6 id="如何让消息可见"><a href="#如何让消息可见" class="header-anchor">#</a> 如何让消息可见</h6> <p>在技术上看, 消息队列让消息从不可见变为可见的核心思路都是: <strong>先将数据写入到一个临时存储, 然后根据一定的机制在数据到期后让消费端可以消费到这条消息</strong>. 这个临时存储一般有以下 3 种选择:</p> <ol><li>单独设计的数据结构</li> <li><strong>独立的 Topic</strong></li> <li>本地的某个<strong>存储引擎</strong>(如 RocksDB, Mnesia 等)</li></ol> <p>为了在延时到期后消费者可以消费到这些消息, 从技术上看主要两个实现思路:</p> <ol><li><strong>定时检测写入</strong></li> <li><strong>消费时判断数据是否可见</strong></li></ol> <p><strong>定时检测写入</strong>, 是指 Broker 收到数据后先将数据存储到某一个存储中(比如某个内置 Topic), 同时有独立的线程去判断数据是否到期. 如果数据到期, 则将数据拉出来写入到实际的 Topic, 从而让消费端可以正常消费数据.</p> <p>这种方案的好处是, 对生产消费的主流程改造较小. 只需要在写入的时候做一个区分逻辑, 然后独立实现定时检测, 将到期数据写入到目标 Topic 即可. <strong>缺点是在延时消息量大的时候, 到期时间不会那么精准</strong>.</p> <p><strong>消费时判断数据是否可见</strong>, 是指每次消费时判断是否有到期的延时消息, 是的话就从第三方存储拉取延时消息返回给消费者, 从而实现消息从不可见到可见.</p> <p>​<img src="/img/b384440fd4ed5135997d5cf40bb1e6cc-20240421231949-d8ee4hx.jpg" alt="">​</p> <p>如上图所示, 生产端在写入数据的时候也会将数据写入到第三方存储. 但是和前一种方案不同的是, 每次消费时会主动去判断第三方存储中是否有消息到期, 有的话就把到期数据返回给客户端.</p> <p>这种方案的好处是省去了定时线程的检测写入逻辑, 流程简单许多. 但是因为消费操作的 QPS 一般很高, 在设计这个第三方存储的时候, 需要尽量提高获取操作的性能, 并降低对内存的占用. 另外每次都去检测是否有延时消息, 可能会出现性能问题.</p> <p>从业界具体实现来看, <strong>大多都是选择定时检测写入的方式</strong>. 因为消费是客户端发起的, 频率不可控, 每次消费都去检查是否有延时消息, 可能会对集群的性能造成影响.</p> <p>接下来我们来看看定时机制的实现思路.</p> <h6 id="定时机制的实现"><a href="#定时机制的实现" class="header-anchor">#</a> 定时机制的实现</h6> <p>直观上来看, 定时机制的核心逻辑是: <strong>随着时间的推进, 拿出到期的延时消息进行处理</strong>. 所以从技术上看, 定时机制可以拆解为<strong>定时器和延时消息定位</strong>处理两部分.</p> <p><strong>定时器</strong> 指按照时间向前推进, 比如毫秒, 秒级, 分钟级向前推进. 下面是一个最简单的定时器实现:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token comment">//todo</span>
    <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">10L</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//单位 ms</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>在各个语言中, 也会封装一些高级的定时器或定制机制, 比如 Java 语言中的定时器 Timer 和 TimerTask, 延时队列 DelayQueue, Go 中的 Timer, Ticker 等等.</p> <p><strong>延时消息定位处理</strong> 指的是随着定时器推进, 在每个时间刻度可以高效定位, 获得需要处理的延时消息列表. 即需要重点关注添加, 获取的时间复杂度.</p> <p>用一张图来讲一下这两个概念, 下图是一个最大延时 5 秒的延时功能.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0fdc9ec7470bbbd09dc547a3856233b7-20240421231949-uf0mdqt.jpg" alt=""></p> <p>从延时消息的生命周期来看, 主要分为 3 步:</p> <ol><li>初始化数据结构, 来存储数据.</li> <li>添加延时事件, 根据延时的时间, 将数据挂到图中对应的刻度下.</li> <li>获取延时事件, 当时间刻度往前走, 延时到期时将图中这个刻度下的数据都取出来处理.</li></ol> <p>在这个示例中可以用一个二维数组来存储数据, 即:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">int</span> arr<span class="token operator">=</span><span class="token keyword">new</span> <span class="token keyword">int</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>  <span class="token comment">// 表示5个刻度, 每个刻度中最多放10条延时消息</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>不过这个示例的局限性很大, 真实的延时消息一般需要满足下面 6 点要求:</p> <ol><li>需要<strong>支持任意的延时精度</strong>, 比如秒级, 甚至毫秒级.</li> <li>需要支持<strong>尽可能长的延时消息</strong>, 比如一个月, 一年.</li> <li>可支持的<strong>延时消息的数量应该很大</strong>, 比如十万级或者百万级.</li> <li>添加, 获取延时事件的时间复杂度要尽量低.</li> <li>延时消息要保证<strong>可靠不丢失</strong>.</li> <li>在实现时需要尽量控制对内存的占用.</li></ol> <p>为了满足以上要求, 下面来看看延时消息的两种主流技术方案.</p> <h5 id="延时消息的技术方案"><a href="#延时消息的技术方案" class="header-anchor">#</a> 延时消息的技术方案</h5> <p>延时消息的实现主要有基于<strong>轮询检测机制的实现和基于时间轮机制</strong>的实现两种方案.</p> <h6 id="基于轮询检测机制的实现"><a href="#基于轮询检测机制的实现" class="header-anchor">#</a> 基于轮询检测机制的实现</h6> <p>该方案的核心思路是: <strong>将延时消息写入到独立的存储中, 利用类似 while + sleep 的定时器, 来推进时间, 通过独立线程检测数据是否到期, 然后从第三方存储中取出到期的数据进行处理</strong>.</p> <p>该方案由 <strong>定时线程</strong> 和 <strong>第三方存储</strong> 两部分组成.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/248ea10101d5d9e4698667f8deb7290f-20240421231949-hurgh0v.jpg" alt=""></p> <p>如上图所示, 该方案不需要维护时间刻度, 只要设计合适的数据结构来存储延时消息列表, 以达到精度和性能的要求即可. 从操作上看, 主要由插入和获取两个操作组成, 此时需要关注的是插入和获取的时间复杂度. 我们追求的目标是 <strong>这两个操作的时间复杂度尽量低</strong>, 因此关键的工作是选择合适的<strong>底层存储结构</strong>.</p> <p>下面整理了一下常用的数据结构在插入和获取方面的时间复杂度.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9703c0b0eafd2f60c4339d6e58ba2f38-20240421231949-yefl315.jpg" alt=""></p> <p>由表格数据可以知道, 如果更关注插入的性能, 那么就得选择红黑树和链表. 如果更关注获取的性能, 则可以选择排序链表和堆. 因为插入和获取的时间复杂度不全是 O(1), 所以当某个 Topic 的数据量很大时, 还是会出现性能问题.</p> <p>可以通过 <strong>分治</strong> 的思想来缓解性能并提高精度.</p> <p>如下图所示, 可以将原来的每个 Topic 一个存储结构, <strong>拆分为多个存储结构</strong>. 比如可以根据时间进行拆分, 如 1 小时, 6 小时, 12 小时, 1 天, 大于 1 天等 5 个维度. 从而降低每个存储结构的长度, 在一定程度上解决性能问题.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/89ca8464c06afcb0674e849682050a27-20240421231949-3w5w8zv.jpg" alt="">​</p> <p>这种方案的优点是实现相对简单, 开发成本较低. 缺点是延时的精度太粗, <strong>无法做到精准的延时</strong>. 但是从实际业务上来看, 因为大部分业务不需要非常精准的延时消息, 也允许在延时消息的场景中有一定的性能下降. 所以这种方案基本能够满足大部分延时消息的需求, 这也是<strong>业界很多主流消息队列都采用的方案</strong>.</p> <h6 id="基于时间轮机制的实现"><a href="#基于时间轮机制的实现" class="header-anchor">#</a> 基于时间轮机制的实现</h6> <p>接下来再看看基于时间轮机制的实现.</p> <p>该方案的核心思路也是: <strong>将延时消息写入到独立的存储中, 然后通过构建多级时间轮, 在每个时间刻度上挂载需要处理的延时消息的索引列表. 再依赖时间轮的推进, 获取到需要处理的延时消息列表, 进行后续的处理</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6e565554483e0b77ddc68be07694fe9b-20240421231949-cp902v1.jpg" alt="">​</p> <p>本质上看, 时间轮和基于轮询检测的思路是一样的. 区别在于, 基于时间轮机制可以达到以下 4 个效果:</p> <ol><li>插入和获取的时间复杂度都是 O(1)</li> <li>可以支持任意时间精度的延时消息</li> <li>可以支持任何时长的延时消息</li> <li>每个时间刻度都可以支持任意多的元素</li></ol> <p>那它是怎么实现这 4 个效果的呢? 简单看一下时间轮算法的设计思想.</p> <p>时间轮是一个很成熟的算法, 分为 <strong>单级时间轮</strong> 和 <strong>多级时间轮</strong>, 多级时间轮是单级时间轮的扩展. 它的核心思想是:</p> <ol><li>先设定好最小的时间精度, 然后将时间划分为多个维度, 比如年, 月, 日, 时, 分, 秒. 通过多级的时间轮来表示时间.</li> <li>在每个刻度上挂上一个待处理的延时消息链表, 链表的元素存储了延时消息的索引信息.</li> <li>添加延时消息时, 找到刻度对应的链表, 在链表最后加上该元素, 所以时间复杂度为 O(1).</li> <li>获取延时消息时, 找到刻度对应的链表, 把这个刻度对应的链表都拿出来处理, 时间复杂度也是 O(1).</li></ol> <p>这里不太好理解, 下面通过一张图来了解一下多级时间轮.</p> <p>​<img src="/img/38c8b6fca79549b73682e90bf2ee8c26-20240421231949-2zw0i1e.png" alt="">​</p> <p>如上图所示, 这是包含 Seconds, Minutes, Hours 三个级别的时间轮, 每一个时间轮的最大刻度为 8, 上一级时间轮最小刻度等于下一级时间轮刻度的总和. 当设定好时间精度和时间轮的维度后, 如果是添加延时消息, 则在多级时间轮上<strong>找到对应时间的延时消息列表, 把消息插入到列表中</strong>. 如果是<strong>获取到期的延时消息, 也是根据时间轮找到当前时间的延时消息列表, 然后把整个列表拿出来处理即可</strong>. 对时间轮算法细节有兴趣的同学, 可以研究一下 <a href="http://www.cs.columbia.edu/~nahum/w6998/papers/sosp87-timing-wheels.pdf" target="_blank" rel="noopener noreferrer">官方论文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>在我看来, 时间轮算法的核心思路比较好理解, 难的是在工程实现方面. 它的核心是: <strong>对于内存使用量的控制</strong> 和 <strong>状态持久化</strong> 两个方面. 即在实现多级时间轮的功能的基础上, 要尽量减少这个时间轮对内存资源的占用. 对于时间轮的工程实现, 这里就不展开了, 建议去研究一下 Kafka 的延时机制, Kakfa 的延时机制底层就是时间轮算法, 它的实现在性能和空间占用方面的表现都非常好.</p> <p>从理论上看, 基于时间轮算法来实现延时消息是一个更好的方案. 但是在编码实现上的挑战, 就比基于轮询检测的方案大很多. 需要重点考虑以下 4 点:</p> <ol><li>如何通过合适的数据结构, 使插入和获取的时间复杂度都为 O(1)?</li> <li>如何尽量降低对于内存的消耗?</li> <li>如何完成时间轮信息的持久化和多节点间的同步?</li> <li>在代码实现层面, 如何低成本实现时间轮?</li></ol> <p>基于这个信息, 你大概可以理解为什么大部分消息队列会基于轮询检测的方案来实现延时消息了吧.</p> <p>最后简单来看一下<strong>主流消息队列在延时方面的实现思路</strong>.</p> <h5 id="主流消息队列的延时机制实现"><a href="#主流消息队列的延时机制实现" class="header-anchor">#</a> 主流消息队列的延时机制实现</h5> <h6 id="rocketmq延时消息的设计思路"><a href="#rocketmq延时消息的设计思路" class="header-anchor">#</a> RocketMQ延时消息的设计思路</h6> <p>社区版本的 RocketMQ, <strong>不支持任意时间的延迟, 它提供了 18 个级别的延时消息</strong>, 分别是:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>从原理来看, RocketMQ 的延时消息是<strong>基于轮询检测机制</strong>的思路来实现的.</p> <p>​<img src="/img/b9d9d4657b94c88a3953c0ff1e17c6fe-20240421231949-6gg4l61.jpg" alt="">​</p> <p>如上图所示, <mark><strong>RocketMQ 在内核定义了名为 SCHEDULE_TOPIC_XXXX 的 Topic 来存储延迟消息. 该 Topic 包含18 个队列, 每个队列对应一个延迟级别. 比如队列 0 就代表延迟 1s 的队列, 队列 1 就代表延迟 5s 的队列</strong></mark>.</p> <p>生产者把延迟消息发送到 Broker 之后, Broker 会<strong>根据生产者定义的延迟级别放到对应的队列中</strong>. 而消息原本应该去的 Topic 和队列, 会暂时存放在消息的属性(property)中.</p> <p>在 RocketMQ 中, 会有<strong>专门的线程池去处理延迟消息</strong>. 比如 18 个延迟级别, 就会生成 18 个定时任务, 每个任务对应一个队列. 这个任务每隔 100 毫秒就会去查看对应队列中的消息, 判断消息的执行时间. 如果到了执行时间, 那么就会把消息发送到其本该投递的 Topic 中, 这样消费者就能消费到消息了.</p> <h6 id="rabbitmq延时消息的设计思路"><a href="#rabbitmq延时消息的设计思路" class="header-anchor">#</a> RabbitMQ延时消息的设计思路</h6> <p>RabbitMQ 的延迟消息有<strong>基于死信队列和集成延迟插件</strong>两种实现方案.</p> <p><strong>基于死信队列</strong> 是指使用两个队列, <strong>一个队列接收消息不消费, 然后等待指定时间过后消息过期, 再由该队列绑定的死信 Exchange 机制再次将其路由到另一个队列提供业务消费</strong>. 实际流程如下所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/421a8817e1de4074b918946beffe0c44-20240421231949-ininmhd.jpg" alt="">​</p> <p><strong>集成延迟插件</strong>(rabbitmq-delayed-message-exchange)是指延时消息不直接投递到队列中, 而是先转储到本地 Mnesia 数据库中, 然后定时器在消息到期后再将其投递到队列中. 实际流程如下所示:</p> <p>​<img src="/img/c7430618f6f9b928317fa0fd3714390e-20240421231949-acuwoar.jpg" alt="">​</p> <p>从根本上看, RabbitMQ 的这两种方案也属于是 <strong>基于轮询检测机制</strong> 的一种.</p> <h6 id="pulsar延时消息的设计思路"><a href="#pulsar延时消息的设计思路" class="header-anchor">#</a> Pulsar延时消息的设计思路</h6> <p>Pulsar 实现延迟消息的思路是比较特殊, 也比较取巧, 没有独立线程来检测消息到期, 而是<strong>在消费的时候通过消费动作来触发检测</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e703c092e5c24e53c307af861afeded4-20240421231949-06vgqpn.jpg" alt="">​</p> <p>如上图所示, <strong>延迟投递的消息会先保存到一个叫做 Delayed Message Tracker 的数据结构中. Delayed Message Tracker 在堆外内存维护一个 delayed index 优先级队列, 这个优先级队列会根据延迟时间进行堆排序, 延迟时间最短的会放在队列的头部, 时间越长越靠近队列尾部</strong>.</p> <p>消费者消费时, 会先去 Delayed Message Tracker 检查, 是否有到期需要投递的消息. 如果有到期的消息, 则从 Tracker 中拿出对应的 index, 找到对应的消息进行消费. 如果没有到期的消息, 则直接消费正常的消息. 如果集群出现 Broker 宕机或者 Topic 的 Leader 切换, Pulsar 会重建 delayed index 队列, 来保证延迟投递的消息能够正常工作.</p> <p>从根本上来看, Pulsar 的方案也是 <strong>基于轮询检测机制</strong> 的一种, 只是<strong>用来检测的线程是消费线程</strong>而已.</p> <h6 id="kafka延时机制的设计思路"><a href="#kafka延时机制的设计思路" class="header-anchor">#</a> Kafka延时机制的设计思路</h6> <p>kafka 本身不支持延时消息, 但是支持延时机制, 用于延时回包, 延时确认的场景.</p> <p>从技术上看, Kafka 的延时机制是 <strong>典型的基于时间轮算法</strong> 来实现的. 它的实现核心是多级时间轮以及使用 Java 的 DelayQueue 来保存延时数据和推进时间, 整体实现性能和实现方案是非常优雅的. 这块网上的资料很多, 就不展开讲细节了, 有兴趣的话可以自己去研究下.</p> <h5 id="总结-29"><a href="#总结-29" class="header-anchor">#</a> 总结</h5> <p>消息队列的延时消息, 解决的是客户端发送的消息在一定时间后可以被消费端消费到的问题. 从技术上拆解, 可以分为<strong>数据存储, 如何让消息可见, 定时机制, 主动推送</strong>四个部分. 其中如何<strong>让消息可见和定时机制</strong>是这节课重点解决的问题.</p> <p>如何让消息可见, 从技术上来看, 有定时检测写入和消费时判断数据是否可见两个思路. 两种方案都是<strong>先将数据写入到一个独立的存储</strong>. 区别在于, 前一种方案会有独立线程定时检测数据是否到期, 然后将到期的数据写入到实际的 Topic. 后一种方案是指每次消费时都去检查一下是否有消息到期, 有的话就直接返回给消费者, 省去了写入原 Topic 的步骤. 个人推荐前一种方案.</p> <p>定时机制的核心逻辑是随着时间的推进, 能够精准高效获得到期的延时消息进行处理. 从技术上看, 可以拆解为定时器和延时消息定位处理两部分. 定时器负责推进时间, 延时消息定位处理是指设计合适的数据结构, 来高效完成延时消息的定位和取出.</p> <p>在延时消息的整体技术方案层面, 主要有基于轮询检测机制的实现和基于时间轮机制的实现两种方案. 目前主流消息队列主要采用前一种方案, 原因是时间轮的方案实现较为复杂, 实现成本较高. 从技术合理性来看, 时间轮是一种更好的方案.</p> <p>主流消息队列中, RocketMQ, RabbitMQ, Pulsar 都实现了延时消息, Kafka 没有实现延时消息, 但是支持延时机制. <strong>RocketMQ, RabbitMQ, Pulsar 的设计思路都是基于轮询检测机制的实现</strong>, Kafka 的延时机制是经典的时间轮实现, 支持毫秒级的任意时长的延时机制.</p> <h5 id="思考题-25"><a href="#思考题-25" class="header-anchor">#</a> 思考题</h5> <blockquote><p>消息队列是 Topic 和分区模型, 此时有个问题是: 在存储引擎选择层面, 是每个 Topic 或分区独享存储结构, 还是 Broker 上所有的 Topic 共享存储结构?</p></blockquote> <p>这个问题要分为两个方面回答.</p> <ol><li>基于轮询检测机制的实现. 从个人的角度, 因为延时消息天然根据时间排序, 所以不需要在分区维度去单独存储. 而每台 Broker 所有 Topic 共享一个存储结构, 当有的 Topic 延时消息太多, 可能导致其他 Topic 的延时消息无法被及时处理. 所以建议开启延时消息属性的 Topic, 独立一个存储结构.</li> <li>基于时间轮机制的实现. 基于时间轮的方案, 就可以一台 Broker 共用一个时间轮, 一份存储结构. 因为时间轮每个刻度的数据是全部需要处理的, 不需要查找, 拿出来定位处理即可.</li></ol> <h4 id="_30-事务消息-如何实现一个完整的事务消息模块"><a href="#_30-事务消息-如何实现一个完整的事务消息模块" class="header-anchor">#</a> 30-事务消息:如何实现一个完整的事务消息模块?</h4> <p>上节课讲完了延时消息, 这节来看看消息队列中的事务消息. 作为一个研发人员, 最熟悉的应该就是 MySQL 或 Redis 的事务.</p> <p>事务有一个特点, 它的概念很明确, 也很常见, 但是它在不同的存储引擎的作用以及实现都是不一样的. 所以如果想使用某个引擎中的事务功能, 就必须先理解一下<strong>引擎中实现的事务的功能是什么, 能达到什么效果</strong>, 再去理解和使用它, 不能想当然地把经典的 MySQL 的事务的功能套入到新的引擎去使用.</p> <p>下面就从最基础的开始, <strong>先来看一下消息队列中的事务消息是什么, 以及用户在什么情况下会用到事务消息</strong>.</p> <h5 id="消息队列中的事务是什么"><a href="#消息队列中的事务是什么" class="header-anchor">#</a> 消息队列中的事务是什么</h5> <p>从原始概念来看, 事务是并发控制的单位, 是用户定义的一个操作序列. 简单解释, 事务是一批操作的集合. 它有 ACID 四个特性, 分别是: <strong>原子性, 一致性, 隔离性, 持久性</strong>.</p> <ol><li>原子性指这批操作要么全部成功, 要么全部失败.</li> <li>一致性指事务中的所有操作的结果符合预期, 都能达到想要的结果.</li> <li>隔离性指不同事务间是完全隔离的, 不相互干扰.</li> <li>持久性指事务一旦被提交, 那么它的执行结果则是永久的.</li></ol> <p>总结一句话就是, 一批操作执行后, 具备 ACID 四个特性, 那么这批操作就是事务操作.</p> <p>又因为一致性, 隔离性, 持久性并不具有唯一性, 在其他场景也会有这些概念. 所以, 事务可以进一步理解为: <strong>一批操作必须具备原子性, 必须同时成功或同时失败</strong>.</p> <p>所以事务在消息队列中也应该也是<strong>一系列操作的集合</strong>. 那么问题就来了, 是什么操作的集合呢?</p> <p>在前面的课程中知道了消息队列中的核心操作是生产, 消费, 集群管控三种类型的操作. 其中值得引入事务的主要是生产和消费操作. 从客户端的视角来看, 就有 <strong>生产事务, 消费事务, 生产+消费事务, 消费+处理+生产</strong> 等等多种组合场景. 从业界来看, 不同消息队列实现的是满足不同场景的事务, 不同事务的具体技术实现也是不一样的.</p> <p>所以接下来先从功能层面来看一下业界四款主流消息队列 RabbitMQ, RocketMQ, Kafka, Pulsar 都支持什么形态的事务消息.</p> <h5 id="主流消息队列的事务功能"><a href="#主流消息队列的事务功能" class="header-anchor">#</a> 主流消息队列的事务功能</h5> <h6 id="rabbitmq的事务消息"><a href="#rabbitmq的事务消息" class="header-anchor">#</a> RabbitMQ的事务消息</h6> <p>RabbitMQ 支持的事务满足的是 <strong>生产消息的事务</strong>. 即一批生产操作要么全部成功, 要么全部失败.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1829300bfc0fcc4e0221a86270b1384e-20240421231949-km5qzhh.jpg" alt=""></p> <p>如上图所示, RabbitMQ 的事务是在 Channel 维度实现的. 将通道(Channel)设置为事务模式后, 所有发送到该通道的消息都将被缓存下来. 事务提交后, 这些消息才会被投递到具体的 Exchange 中. 如果事务提交失败, 可以进行事务回滚, 使消息不会被发送到目标 Exchange.</p> <h6 id="rocketmq的事务消息"><a href="#rocketmq的事务消息" class="header-anchor">#</a> RocketMQ的事务消息</h6> <p>RocketMQ 支持的事务满足的是 <strong>生产消息</strong> 和 <strong>本地事务</strong> 相结合的一种事务形态. 这句话不太好理解, 下面通过购物下单的例子来说明一下.</p> <p>在下单流程中, 一般需要将订单数据插入 DB, 并往消息队列发送订单消息. 此时可能有两种情况: <strong>出现消息生产成功, DB 插入失败; DB 插入成功, 生产写入失败</strong>.</p> <p>RocketMQ 为了满足这种场景而设计实现当前的事务形态. <mark><strong>即事务的操作集合有 发送消息 和 本地操作(比如插入 DB)两种类型. 只有两种操作都成功, 事务才算成功</strong></mark>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0bbea1e838149e6ef791087187ab9c8b-20240421231949-0l9ocb0.jpg" alt=""></p> <p>如上图所示, <mark><strong>生产者发送事务消息到 Broker, Broker 会在 Commitlog 持久化存储这条消息并标记为不可见. 当客户端本地操作执行完成后, 再提交二次确认结果, 将消息标记为可见, 让消费端可以消费到消息. 但特殊的是 RocketMQ 提供了客户端回查机制, 也就是说当生产消息成功, 本地事务失败时, Broker 会根据一定的策略对客户端的本地事务发起回查, 以尽量保证事务的成功率</strong></mark>.</p> <p>RocketMQ 事务消息仅支持在 MessageType 为 Transaction 的 Topic 内使用. 也就是说<strong>事务是在 Topic 维度生效的, 事务消息也只能发送到类型为事务消息的 Topic 中</strong>.</p> <h6 id="kafka的事务消息"><a href="#kafka的事务消息" class="header-anchor">#</a> Kafka的事务消息</h6> <p>Kafka 支持的事务跟 RabbitMQ 一样, 满足的也是 <strong>生产消息</strong> 的事务. 即保证一批生产操作要么全部成功, 要么全部失败. 和 RabbitMQ 事务不同的是, <strong>Kafka 的事务是在事务 ID 维度生效的</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4dd1cbaffb9c0be10yyfb310de3de950-20240421231949-x5rjsy2.jpg" alt="">​</p> <p>如上图所示, 客户端会先设置一个事务 ID, 多个生产者中设置的事务 ID 可以是一样的. 用这个事务 ID 开启事务后, 可以实现对多个 Topic, 多个 Partition 的原子性的写入. Broker 收到消息后, 会按正常流程保存事务消息, 只是将这些消息标记为不可见. 当提交事务后, 才将这些消息标记为可见, 让消费端可以消费到.</p> <p>另外在底层实现中, 事务 ID 以及事务相关的状态保存在一个叫做 <code>__transaction_state</code>​ 的内部 Topic 中, 用来持久化保存事务 ID, 状态等信息.</p> <h6 id="pulsar的事务消息"><a href="#pulsar的事务消息" class="header-anchor">#</a> Pulsar的事务消息</h6> <p>Pulsar 主要满足的是 <strong>消费+处理+生产</strong> 的事务. 简单理解就是用来满足<strong>流场景将消费, 处理, 生产消息整个过程定义为一个原子操作, 以保证整个操作的原子性</strong>, 所以 Pulsar 事务包含的操作有消费, 处理, 生产三种操作.</p> <p>​<img src="/img/fa245ee50c8eececf89dfd6b55bc9bed-20240421231949-r7oyv10.jpg" alt="">​</p> <p>如上图所示, 从底层实现来看, Pulsar 的事务处理流程与 Kafka 的事务处理思路大致保持一致. 都是通过事务 ID 来标记事务, 开启事务投递消息, 都会将消息标记为不可见, 同时往一个内部的 Topic 记录事务的状态数据. 等全流程处理都成功后, 才会提交事务. 此时在生产端标记消息可见, 在消费端提交消费位点, 从而完成整个流程.  <strong>Pulsar</strong> <strong>的事务可以看作是</strong> <strong>Kafka</strong> <strong>事务的升级版, 它保证的是流处理操作的原子性</strong>.</p> <p>讲到这里, 可以总结出三点关键信息:</p> <ol><li>不同消息队列对事务消息的功能定义都不一样.</li> <li><strong>都是基于两阶段事务来设计的, 分为生产消息(准备阶段)和提交事务(确认阶段)</strong> .</li> <li><strong>生产事务都是先将消息标记为不可见, 等提交事务后再将消息标记为可见</strong>.</li></ol> <p>基于这三点, 接下来从技术角度来拆解一下消息队列的事务消息的实现.</p> <h5 id="分布式事务理论基础"><a href="#分布式事务理论基础" class="header-anchor">#</a> 分布式事务理论基础</h5> <p>首先从事务的理论基础开始讲起.</p> <p>从技术上来看, 事务可以分为 <strong>单机事务</strong> 和 <strong>分布式事务</strong>. 单机事务是指在单机层面完成一系列原子操作, 比如 MySQL 的事务就属于单机事务. 消息队列是分布式架构, 所以<strong>消息队列实现的事务都属于分布式事务范畴</strong>.</p> <p>从技术上看, <mark><strong>分布式事务的解决方案一般有 XA(2PC/3PC)和 TCC 两种</strong></mark>. XA 指的是 XA 分布式事务协议, 通常包含两阶段事务(2PC)和三阶段事务(3PC)两种实现方式.</p> <h6 id="两阶段事务-2pc"><a href="#两阶段事务-2pc" class="header-anchor">#</a> 两阶段事务(2PC)</h6> <p>两阶段事务将事务的提交分为两个阶段: <strong>请求阶段(Commit-request)和提交阶段(Commit)</strong> . 简单来讲就是所有参与者将各自的执行结果告知协调者, 协调者根据收到的结果决定所有参与者是提交还是回滚操作.</p> <p>​<img src="/img/c3c8554ff7a5d936d8cda544857417a8-20240421231949-wfuscfq.jpg" alt="">​</p> <ol><li>协调者询问所有参与者是否可以进行提交, 并等待所有参与者响应.</li> <li>所有参与者开始执行事务(但是不提交事务), 并告知协调者自己的执行结果是成功(本地事务执行成功)还是失败(本地事务执行失败), 然后等待协调者通知最终是提交事务还是回退事务.</li> <li>如果协调者收到所有节点都执行成功了, 那么通知所有节点全部进行提交事务操作, 否则只要存在一个参与者执行失败, 或者协调者超时了还没有收到全部参与者的执行结果, 那么就通知所有参与者回退事务.</li> <li>所有参与者根据协调者的通知, 统一进行提交或者回退事务, 并反馈信息.</li></ol> <p>二阶段事务本身存在一些缺陷, 比如<strong>同步阻塞问题, 单点故障, 数据不一致</strong>等, 所以业界提出了三阶段事务, 对两阶段事务做了一些优化.</p> <h6 id="三阶段事务-3pc"><a href="#三阶段事务-3pc" class="header-anchor">#</a> 三阶段事务(3PC)</h6> <p>三阶段事务是二阶段事务的改进版, 将 2PC 中的<strong>准备阶段一分为二, 用于保证在最后提交阶段之前, 所有的节点状态都是一致的</strong>. 并且在协调者和参与者中都引入了超时机制, 一旦参与者长时间没有收到协调者的通知, 那么参与者将执行提交事务操作.</p> <p>​<img src="/img/e1b7994ef08d8d7a98e34f63cbac517f-20240421231949-87gx88z.jpg" alt="">​</p> <blockquote><p>CanCommit 阶段</p></blockquote> <ul><li>协调者询问所有参与者是否可以进行提交, 并等待所有参与者响应;</li> <li>所有参与者预估判断是否可以提交(这里不执行事务), 将结果(YES/NO)反馈给协调者;</li> <li>如果上一阶段存在参与者返回 NO, 或者协调者等待超时, 那么中断事务, 不继续后面的操作;</li> <li>如果所有参与者都返回 YES, 则进入 PreCommit 阶段.</li></ul> <blockquote><p>PreCommit 阶段</p></blockquote> <ul><li>协调者通知参与者进入准备阶段, 并等待参与者响应;</li> <li>参与者执行事务(但不提交), 并将执行结果反馈给协调者, 然后等待协调者通知最终是提交事务还是回退事务.</li></ul> <blockquote><p>DoCommit 阶段</p></blockquote> <ul><li>如果所有参与者都反馈了 YES, 那么协调者向参与者发送提交事务的通知;</li> <li>参与者返回 NO, 或者协调者等待超时, 那么协调者向参与者发送回退事务的通知.</li></ul> <p><strong>3PC 存在的问题是, 协调者在向所有参与者发送回退事务指令的情况下, 如果因为网络原因导致参与者没有收到通知, 当参与者等待超时后会自动执行提交事务, 这样就造成了数据不一致的现象</strong>.</p> <h6 id="tcc事务"><a href="#tcc事务" class="header-anchor">#</a> TCC事务</h6> <p><strong>TCC 主要在应用层面上, 需要自己编写业务逻辑, TCC 将业务分为 Try, Confirm, Cancle 三部分逻辑. Try 为尝试执行业务, 如果 Try 阶段执行成功则进入 Confirm 阶段, 确认执行业务, 否则进入 Cancle 阶段, 取消执行业务</strong>.</p> <ol><li>Try 阶段: 尝试执行业务, 完成业务的检查, 预留业务需要的资源.</li> <li>Confirm 阶段: 直接使用 Try 阶段的预留资源执行业务, 这里不需要进行业务校验, 因为在 Try 阶段已经校验过了.</li> <li>Cancle 阶段: 取消执行业务.</li></ol> <p>结合这些理论基础和前面提到的知识点就可以知道, <mark><strong>消息队列事务其实就是</strong></mark> <mark></mark> <mark><strong>XA 两阶段提交的实现</strong></mark>. 而且 2PC 是目前消息队列事务的主要实现方式, 所以接下来看一下消息队列<strong>基于 2PC 理论实现事务的技术要点</strong>.</p> <h5 id="消息队列的事务方案设计"><a href="#消息队列的事务方案设计" class="header-anchor">#</a> 消息队列的事务方案设计</h5> <p>从技术上来看, 先以 <strong>生产事务</strong> 举例说明来拆解一下技术核心点. 先来看下图, 这是消息队列实现事务消息的大致流程.</p> <p>​<img src="/img/9e36823faf475f6683121b9d013c245d-20240421231949-9qhrys6.jpg" alt="">​</p> <p>总共可以分为 4 步:</p> <ol><li>初始化事务, 假设以事务 ID 来标识一个事务, 初始化的时候就需要<strong>把事务 ID 信息存储到事务协调者</strong>上.</li> <li>第一阶段客户端会把消息都发送到不同的 Topic 和不同的分区中, 因此数据是发送到不同 Broker 的, 此时在事务没有提交的时候, <strong>数据应该是不可见</strong>的.</li> <li>第二阶段客户端会<strong>提交事务</strong>, 告诉协调者所有的操作都成功了, 此时可以把这次事务相关的信息都提交给事务协调者, 比如本次事务所包含的 Topic 和分区等.</li> <li>当客户端提交事务后, <strong>协调者会通知把所有 Broker 上的这些数据都变为可见</strong>.</li></ol> <p>从中可以拆解出以下 3 个技术点:</p> <ul><li>因为事务的状态需要存储, 查询, 所以<strong>需要将事务状态信息进行持久化存储</strong>.</li> <li>因为多台数据是发送到多台 Broker, 所以在提交事务时客户端需要通知事务协调者, 让事务协调者去通知所有 Broker 的数据变为可见, 所以<strong>需要一个事务协调器</strong>.</li> <li>因为第一阶段提交的事务消息是不可见, 第二阶段事务提交后可见或回滚, 所以<strong>需要设计一个将数据从不可见变为可见的机制</strong>.</li></ul> <p>下面来逐一分析下这几个技术要点.</p> <h6 id="如何存储事务状态信息"><a href="#如何存储事务状态信息" class="header-anchor">#</a> 如何存储事务状态信息</h6> <p>从前面的流程就知道, 事务状态是用来记录, 查询的, 在提交事务的阶段去通知各个 Broker 去执行提交事务的操作, 所以需要为事务相关的元数据找一个地方存储.</p> <p>消息队列本身就是一个存储引擎, 所以很多消息队列就会<strong>选择创建一个内部的 Topic 用来存储事务相关的数据</strong>, 这样实现起来就没有额外的开发成本. 比如 Kakfa 和 Pulsar 都是存在一个内部的 Topic 里面的; RocketMQ 的事务状态信息是存储在 Commitlog 中的; RabbitMQ 的事务状态信息没有一个集中式的存储, 而是依赖于 TCP 连接和信道级别的处理, 都依赖于该信道内的上下文来获取事务信息.</p> <p>所以在设计的时候, 可以根据当前架构的特点去选择合适的存储. 如果是<mark><strong>在消息队列中, 比较建议是通过内部 Topic 来存储, 因为可以复用 Topic 的分布式存储的能力</strong></mark>.</p> <h6 id="事务协调者如何设计"><a href="#事务协调者如何设计" class="header-anchor">#</a> 事务协调者如何设计</h6> <p>事务的协调者从具体实现来讲就是一段代码逻辑. 它主要负责 <strong>保存事务的状态信息</strong> 和 <strong>通知事务的提交, 回滚</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ee057bedd8845a20e7d09e1d542c8c1a-20240421231949-c6zvyy8.jpg" alt=""></p> <p>参考图示, 从技术上看, 事务协调者的设计整体分为以下 3 步:</p> <ol><li>如何选出事务协调者?</li> <li>协调者如何保存状态?</li> <li>协调者如何通知其他 Broker 提交, 回滚事务?</li></ol> <p>一般情况下, 事务协调者都是由<strong>某台 Broker 担任</strong>的. 所以直观上看, 可以固定某一台 Broker 当作事务的协调者, 这是最简单的, 但是这会涉及到这台 Broker 故障时候的事务协调者的可用性切换问题. 如果是单独实现, 肯定技术上卡点不大, 只是开发成本较高.</p> <p>所以在消息队列中, 比如 Kafka 或 Pulsar, 它们的实现是:</p> <ol><li><strong>先创建一个内部的 Topic 来存储事务状态数据</strong>.</li> <li><strong>通过一定的算法将事务 ID 哈希计算后, 算出这个事务 ID 的数据存储在哪个分区</strong>.</li> <li><strong>这个分区 Leader 所在的 Broker 就是这个事务 ID 的事务协调者</strong>.</li></ol> <p>选出事务协调者后, 客户端就和这台 Broker 进行交互, 直接将事务状态数据写入到算出来的这个分区中. 然后当接收到客户端提交事务的请求时, 再通过内部接口通知各个 Broker 提交事务.</p> <h6 id="如何实现消息从不可见到可见"><a href="#如何实现消息从不可见到可见" class="header-anchor">#</a> 如何实现消息从不可见到可见</h6> <p>其实这个问题和上节讲到的延迟消息的消息从不可见到可见的思路基本是一致的.</p> <p>从技术上来看主要有两种思路:</p> <ol><li><strong>先将消息写入到其他的地方, 然后等事务提交的时候再将数据写入到实际的 Topic 当中</strong>, 目前主流消息队列 RabbitMQ 用的是这个方案.</li> <li><strong>数据按照原先的流程直接写入原先的 Topic 中, 只是这条消息会加上事务 ID 相关信息, 同时标记为事务消息, 在事务没有提交的时候标记这条消息为不可见</strong>.</li></ol> <p>其中第一种方案在上一节课讲了很多了, 也比较好理解, 这里就不展开了. 这里着重讲一下第二种方案的实现思路.</p> <p>先来看一下下面这张图:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/03b8dc13caa446c9672ef4c4c78ff581-20240421231949-xl9zwfi.jpg" alt=""></p> <p>基础篇讲过, 消息队列底层是<strong>顺序存储</strong>的结构. 所以如上图所示, 如果以事务 ID 为标识来实现事务, 此时在某个 Topic 中就有可能既有事务消息, 又有非事务消息. 其中事务消息可能有已提交的事务(如上图中黄色的 m3), 也有未提交的事务(如上图中粉色的 m2).</p> <p>此时在顺序存储结构中, <strong>数据是顺序消费</strong>的. 不过这里有一个问题, 如果遇到未提交的事务, 消费端能不能继续往下消费呢?</p> <p>有两种情况:</p> <ol><li><strong>不能向下消费</strong>. 这种相当于消费者顺序消费, 如果遇到有未确认的事务消息, 此时依旧不往下消费. 因为事务消息有过期时间, 等到这条事务消息过期了或者被提交了再继续消费. 这种方案是最简单的, 没有太多工作量, 也不需要对主流程进行修改.</li> <li><strong>可以向下消费</strong>. 此时相当于会跳过这些未确认的消息, 但是在后续的消费过程中都需要来判断一下这些消息是否已经被确认, 是的话就需要投递给消费者. 这种方式一般需要单独维护未确认的事务消息列表, 以提高消费时检查的性能, 实现起来成本较高.</li></ol> <p>在目前的主流消息队列中, 这两种方案都有人在使用. 第一种方案可能会出现消费卡顿, 消费较慢的问题, 但是可以保持消费顺序, 且实现简单. 第二种方案, 消费速度较高, 但是会有消费乱序的情况, 且实现相对复杂. 所以, 从实现上来看, 得考虑是否有顺序消息, 消费速度的需求, 然后选择其中一种合适的方案.</p> <p>另外还有一个问题, 我们知道在消息队列的顺序存储结构中, 消息的内容是不能改的. 那在这种模式下如何将一个消息从未确认变为已确认, 从不可见变为可见呢?</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/b9b52abae3c18a1de1363b4ec3785feb-20240421231949-jyf9nxa.jpg" alt="">​</p> <p>如上图所示, 为了解决这个问题, 因为消息内容是不能更改的, 所以一般需要引入另外一个数据结构来存储事务的状态, 标记这个事务消息是否提交, 然后在消费的时候进行判断.</p> <h5 id="总结-30"><a href="#总结-30" class="header-anchor">#</a> 总结</h5> <p>事务是一批操作的集合, 这批操作要么全部成功, 要么全部失败. 在消息队列中, 操作主要分为生产和消费, 所以消息队列的事务也可以说是一批生产, 消费的操作的集合.</p> <p>不同消息队列实现的事务是不一样的. 简单说集合中支持的操作是不一样的, 从客户端的视角来看, 就有生产事务, 消费事务, 生产+消费事务, 消费+处理+生产等等多种组合场景.</p> <p>目前主流消息队列 RabbitMQ 和 Kakfa 支持的是生产的事务, RocketMQ 支持的是生产的事务+本地的事务, Pulsar 支持的是消费 + 处理 + 生产的流场景的事务.</p> <p>事务分为单机事务和分布式事务, 消息队列的事务属于分布式事务的范畴. 分布式事务的实现主要有两阶段事务, 三阶段事务, TCC 三种. 目前消息队列的事务主要都是基于两阶段事务的理论基础来实现的.</p> <p>消息队列的事务方案设计, 主要关注如何存储事务状态信息, 如何实现事务协调者, 如何实现消息从不可见到可见三个问题.</p> <p>事务状态信息的存储一般建议通过内置的 Topic 来实现, 成本较低. 事务协调者可以参考 Kafka 和 Pulsar 的事务协调者的实现, 它们的方案比较优雅. 消息从不可见变为可见主要有延迟投递和标记两个思路, 目前用的比较多的是标记. 在消息生产时标记为不可见, 事务提交时标记为可见.</p> <h5 id="思考题-26"><a href="#思考题-26" class="header-anchor">#</a> 思考题</h5> <blockquote><p>为什么消息队列的事务不选择三阶段事务或者 TCC 呢?</p></blockquote> <p>三阶段事务(3PC)相对两阶段事务(2PC)多了一步, 就是询问阶段, 即<strong>询问是否有资源</strong>. 但是在消息队列的场景中, <strong>消息生产, 消费进度提交是不需要询问是否有资源的, 只需要保证操作本身成功</strong>, 此时 3PC 的这一步询问在消息队列的场景中就没有意义.</p> <p><strong>TCC 是用在业务场景中的, 客户端需要去实现资源的锁定, 提交和回滚操作, 完全客户端自定义实现, 不适合消息队列这种基础组件的场景</strong>.</p> <h4 id="_31-死信队列和优先级队列-如何实现死信队列和优先级队列"><a href="#_31-死信队列和优先级队列-如何实现死信队列和优先级队列" class="header-anchor">#</a> 31-死信队列和优先级队列:如何实现死信队列和优先级队列?</h4> <p>在日常业务的消费数据过程中, 如果遇到数据无法被正确处理, 就需要先手动把消息保存下来然后 ACK 消息, 这样才能顺利消费下一条数据. 此时如果消息队列拥有死信队列的功能, 就不需要这么繁琐的操作, 直接开启死信队列就可以实现同样的效果. 另外, 当需要在业务中对消息设置优先级, 让优先级高的消息能被优先消费, 此时就需要用到消息队列中优先级队列的特性.</p> <p>为了让你了解<strong>死信队列和优先级队列</strong>这两个功能特性的底层实现, 这节课会详细分析它们的技术方案.</p> <h5 id="什么是死信队列"><a href="#什么是死信队列" class="header-anchor">#</a> 什么是死信队列</h5> <p>从本质上来看, <strong>死信队列不是一个队列, 而是一个功能</strong>. 为什么这么说呢?</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6f9cd72d80d565db20d9f20345be8e53-20240421231949-mijwxus.jpg" alt="">​</p> <p>参考图示, 在实际业务场景中, 死信队列一般有以下三种形态:</p> <ol><li>在生产端, 如果数据写入某个 Topic 一直失败, 则<strong>生产端可以将数据临时写入到另外一个 Topic, 这样可以避免后续数据写入阻塞</strong>.</li> <li>在 Broker 端, <strong>如果存储在 Topic 的数据到过期后还没被消费, 则可以将这些数据写入到另外一个 Topic 中, 这样可以避免数据丢失</strong>.</li> <li>在消费端, <strong>如果消费者消费到某条数据后本地处理一直失败, 消费就会阻塞, 此时可以将这条数据投递到另外一个 Topic 中, 这样可以避免消费阻塞</strong>.</li></ol> <p>在上面这三种情况中, <mark><strong>当数据写入失败, 数据过期, 消费处理失败后, 自动将有问题的数据投递到另一个存储的功能就叫做死信队列</strong></mark>. 在实际业务中, 用得最频繁的就是生产失败和消费失败时的死信队列.</p> <h5 id="死信队列实现的技术方案"><a href="#死信队列实现的技术方案" class="header-anchor">#</a> 死信队列实现的技术方案</h5> <p>接下来从技术上看一下死信队列是如何实现的.</p> <p>从技术上看, 生产和消费的死信队列的效果, 业务端都能 <strong>自定义实现</strong>. 如下图所示:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4912442e9d60a2a4da00cd25fd0a7afd-20240421231949-uq9hv08.jpg" alt=""></p> <p>在生产端, 业务一直写入失败时, 业务逻辑可以自行将数据写入到其他的 Topic 中, 然后标记数据写入成功, 从而保证业务的正常进行. 再来看下面这张图:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1yyffaebf114d4742edd37e6f33e7fd0-20240421231949-7lxc44b.jpg" alt=""></p> <p>可以看到, 消息队列死信队列存在的意义是: <strong>将业务自定义处理这部分复杂重复的工作包装在消息队列内部完成, 从而降低业务的使用成本</strong>.</p> <p>这里不知道你会不会有疑问, 在这两张图中, 死信队列配置的 Topic 就一定是 Topic 吗? 可以是其他的存储引擎(比如 MySQL)吗? 如果是 Topic 的话, 是同一个集群中的 Topic, 还是不同集群中的 Topic 呢? 接下来就找找答案!</p> <h6 id="死信队列的存储目标"><a href="#死信队列的存储目标" class="header-anchor">#</a> 死信队列的存储目标</h6> <p>在日常的叫法中, 因为大部分情况下, 会将数据投递到消息队列集群中的另外一个 Topic, 所以会<strong>将死信队列数据投递的目标 Topic 叫做死信队列</strong>. 但是严格意义上说, 这样称呼是不对的.</p> <p>从功能上来看, 死信队列的目标一般是同一个集群或另一个集群中的 Topic. 但是从技术上来看, <strong>死信队列的目标引擎也可以是其他的存储, 比如说 ES, MySQL 等</strong>.</p> <p>那什么时候是集群内/跨集群的 Topic, 什么时候是其他存储呢? 这个问题没有固定答案, 一般可以从业务自定义实现的死信队列和社区消息队列 SDK 实现的死信队列两个角度来看.</p> <p><strong>如果是业务自定义实现的死信队列, 那么一般可以灵活选择其他存储引擎或其他集群的 Topic</strong>. 因为在一些企业内部, 为了满足业务侧的需求, 会二次扩展社区的 SDK 功能. 比如在业务稳定性的要求下, 为了保证生产操作数据流的稳定, 会要求在当前集群异常的时候, 将数据临时存储在另外一个引擎或另一个消息队列的集群中, 以保证数据流的稳定, 不中断.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/7d464d6fe838ef377ef166ea71825e4b-20240421231949-tb6a9km.jpg" alt=""></p> <p><strong>如果是消息队列内核 SDK 实现的死信队列, 一般只支持同一个集群内的另外一个 Topic 作为目标存储, 最多支持跨集群 Topic 的投递</strong>. 这是因为如果客户端 SDK 集成其他的引擎, 客户端就需要耦合其他引擎的写入逻辑, 这会让消息队列的 SDK 变得很臃肿, 不够单一, 长期来看维护成本很高, 所以<strong>社区的 SDK 一般不会支持跨存储引擎的投递</strong>.</p> <p><img src="/img/61793312f7e8d21ab13yy6cf076cc921-20240421231949-3wm6yqx.jpg" alt=""></p> <h6 id="死信队列的方案设计"><a href="#死信队列的方案设计" class="header-anchor">#</a> 死信队列的方案设计</h6> <p>接下来看一下消息队列内核 SDK 是如何实现死信队列功能的, 其设计方案也比较有代表性.</p> <p>从功能上看, 可以分为 <strong>生产死信队列, 消费死信队列, Broker</strong> <strong>死信队列</strong> 三种场景.</p> <p>先来回顾一下生产数据的全流程:</p> <ol><li>客户端初始化生产者.</li> <li>客户端将数据发送到目标 Topic, 如果成功, 流程结束, 继续下一次发送.</li> <li>如果失败, 则判断客户端有没有配置重试机制, 如果没有, 流程结束, 给业务报错.</li> <li>如果有, 则进行重试, 当重试次数用完后, 给业务侧报错.</li></ol> <p>从正常流程来看, 上面的逻辑是没问题的, 客户端可以<strong>感知到异常</strong>并进行处理, 但是业务侧的需求是: 底层基础组件需要尽量保证集群可用. 而当集群不可用时, 能不能把数据先存到其他地方, 等集群可用时再继续投递, 把逻辑闭环在底层, 以免上层业务逻辑感知到更复杂的处理逻辑.</p> <p>此时如下图所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1yyffaebf114d4742edd37e6f33e7fd0-20240421231949-7lxc44b.jpg" alt="">​</p> <p>流程就变成了:</p> <ol><li>如果有, 则进行重试, 当重试次数用完后, 判断是否启用死信队列, 如果没有启用, 给业务端报错.</li> <li>如果启用, 那么则将数据投递到死信队列, 上层业务正常处理返回, 从而保证上层应用的正常运行.</li></ol> <p>从代码实现上来看并不复杂, 只需要两步:</p> <ol><li>在启动生产者的时候配置好死信队列的配置信息.</li> <li>在生产失败的最后一步, 代码判断是否启用死信队列, 就将数据写入目标队列即可.</li></ol> <p>以下为死信队列的伪代码示例:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// init  producer &amp;&amp; deadLetterProducer</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
   producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span><span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">if</span><span class="token punctuation">(</span>enableDeadLetter<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      deadLetterProducer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span>
   <span class="token punctuation">}</span>
   <span class="token keyword">throw</span> e
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>再来看一下消费数据的全流程:</p> <ol><li>客户端初始化消费者.</li> <li>消费者正常消费数据, 处理数据, 如果数据处理成功, 则提交消费进度, 流程结束.</li> <li>如果数据处理失败, 则进行重试, 重试到一定次数还失败的话, 就直接报错.</li></ol> <p>跟上面类似, 引入死信队列后, 此时如下图所示:</p> <p>​<img src="/img/43f186f0cebaa151578562cff4b7e8f4-20240421231949-5xnrt4m.jpg" alt="">​</p> <p>流程就变成了:</p> <ol><li>如果数据处理失败, 则进行重试, 重试到一定次数还失败的话, 就直接报错. 如果没有配置死信队列, 则直接报错, 且不提交消费进度.</li> <li>如果配置了死信队列, 则将消息投递到死信队列, 然后正常提交消费进度, 开始消费下一条消息.</li></ol> <p>从代码实现上来看, 通过一段伪代码来看一下消费的流程.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 消费的代码</span>
message <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
   <span class="token comment">// todo process</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span><span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   consumer<span class="token punctuation">.</span><span class="token function">markFail</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
consumer<span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>用户正常消费处理数据, 当处理失败后, 就记录本批次数据处理的失败次数. 当失败次数达到配置的次数后, 就将本次消费到的数据写入到死信队列, 并且自动提交 Offset.</p> <p>讲到这里会发现: <strong>生产和消费的死信队列的功能都是在客户端完成的, 基本不需要服务端参与</strong>.</p> <p>Broker 的死信队列的实现逻辑跟延时消息很像. 简单来说, 就是<strong>当消息过期或在删除的逻辑上加上死信队列的判断逻辑时, 则根据配置的死信队列信息, 将数据投递到某个目标队列</strong>.</p> <p>讲完了死信队列的设计方案, 接下来看一下业界主流消息队列都支持什么形态的死信队列.</p> <h6 id="主流消息队列的死信功能"><a href="#主流消息队列的死信功能" class="header-anchor">#</a> 主流消息队列的死信功能</h6> <p>目前来看, 只有 RocketMQ, RabbitMQ 支持死信队列.</p> <p>其中, RocketMQ 实现的是 <strong>消费死信队列</strong>. 即当一条消息消费失败, RocketMQ 会自动进行重试. <strong>达到最大重试次数后, 若消费依然失败, 则表明消费者在正常情况下无法正确地消费该消息. 此时如果开启了死信队列, 则不会立刻将消息丢弃, 而是将其发送到该消费者对应的特殊队列中</strong>.</p> <p>这种正常情况下无法被消费的消息称为死信消息(Dead-Letter-Message), 存储死信消息的特殊队列称为<strong>死信队列</strong>(Dead-Letter Queue). 在具体实现中, RocketMQ 会<strong>自动创建内部 Topic, 然后将消息投递到这个内部 Topic 中</strong>.</p> <p>RabbitMQ 实现的是 <strong>生产和 Broker 内的死信队列</strong>. RabbitMQ 的死信队列称为死信交换机(Dead-Letter-Exchange, DLX). 在功能上, 当消息变成死信消息后, 它会被重新发送到另一个交换机中, 这个交换机就是 DLX, 绑定 DLX 的队列就称之为死信队列.</p> <p>当出现这三种情况, 消息就会被变为死信消息, 投递到死信交换机中:</p> <ol><li>消息被拒绝</li> <li>消息过期</li> <li>队列达到最大长度</li></ol> <p>从实现上看, RocketMQ 和 RabbitMQ 的投递目标都是本集群内的资源, 比如 Topic, Exchange, Queue.</p> <h5 id="什么是优先级队列"><a href="#什么是优先级队列" class="header-anchor">#</a> 什么是优先级队列</h5> <p>讲完了死信队列, 下面再来看一下优先级队列.</p> <p>先来看一个示例. 在很多业务场景中, 会对客户进行分级, 比如头部客户, 中腰部客户, 尾部客户等. 此时有个需求是, 在给这些客户发通知时, <strong>希望头部客户先收到通知, 然后是腰部客户, 最后是尾部客户</strong>.</p> <p>在这个场景中, 就可以利用优先级队列的特性. 如下图所示, 只要发送通知的时候在每条消息上<strong>附带这个客户的优先级</strong>信息, 比如头部客户的优先级是 10, 中腰部是 5, 尾部是 1, 此时不管生产端发送数据的顺序是怎样的, <strong>消费端一定是先拿到优先级高的信息, 然后进行推送</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ae9d97f8f3afaf4d5d26a349c3e02d5b-20240421231949-j62e3oo.jpg" alt=""></p> <p>而如果没有优先级队列, 此时就需要在生产端严格控制发送顺序, 业务侧的工作量就会放大很多倍. 有了优先级队列后, 生产端和消费端就可以像普通消息一样生产和消费消息即可.</p> <p>所以总结来说, 优先级队列的定义就是: <strong>客户端在发送消息的时候会给每条消息加上优先级信息, 不管客户端发送消息的顺序是怎样, Broker 都会保证消费端一定会先消费到优先级高的消息</strong>.</p> <h5 id="如何设计实现优先级队列"><a href="#如何设计实现优先级队列" class="header-anchor">#</a> 如何设计实现优先级队列</h5> <p>接下来从技术上来看一下内核是怎样支持优先级队列的.</p> <p>从业界来看, 实现优先级队列有两条路径:</p> <ol><li>当消息队列内核不支持时, <strong>业务自定义实现优先级队列</strong>的效果.</li> <li><strong>在消息队列内核支持优先级队列</strong>.</li></ol> <p>分别来说一下这两种实现的主要思路.</p> <h6 id="业务实现优先级队列的效果"><a href="#业务实现优先级队列的效果" class="header-anchor">#</a> 业务实现优先级队列的效果</h6> <p>在实际业务中, 大部分情况下优先级的设置会有一个数量范围, 比如总共分为 10 等优先级, 从 1~10. 另外在前面的课程讲过, 消息队列是 Topic 分区模型.</p> <p>所以可以<strong>基于 Topic 和分区模型来实现优先级队列的效果</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/354af8d9b2928df9ed7c0e43c4ed9966-20240421231949-yo5mtlh.jpg" alt=""></p> <p>核心思路是: <strong>为每个优先级分配一个分区, 写入时将不同的优先级数据写入到不同的分区. 消费时指定分区消费, 优先消费优先级高的分区</strong>.</p> <p>进一步说, 为了保证性能和横向扩容的能力, 可以<strong>为每个优先级级别分一个独立的 Topic 来存储数据</strong>. 比如优先级 1 的数据存储在 Topic1 中, 优先级 2 的数据存储在 Topic2 中, 以此类推.</p> <p>这种方案从功能上勉强可以满足优先级队列的需求, 但是缺陷比较明显. 主要缺点是没法支持灵活的优先级设置, 在优先级级别很多的情况下, 会额外冗余很多的分区和 Topic. 另外在生产端和消费端都需要感知到分区 / Topic 和优先级的关系, 控制写入和消费, 这会导致客户端的逻辑很复杂.</p> <p>所以从技术合理性来看, 还是<strong>在消息队列内核实现优先级队列更加合理</strong>.</p> <h6 id="内核支持优先级队列"><a href="#内核支持优先级队列" class="header-anchor">#</a> 内核支持优先级队列</h6> <p>那么要在 Broker 内核实现优先级队列, 从技术上看主要分为两步.</p> <ol><li><strong>协议层面</strong>: 客户端<strong>发送消息时需要给消息加上优先级信息</strong>, 所以请求协议就需要支持添加优先级信息的字段.</li> <li><strong>内核层面</strong>: Broker 接收到数据后, 需要<strong>经过某种机制保证消费者优先消费到高优先级的消息</strong>.</li></ol> <p>其中协议层面的改动较为简单, 只需要添加一个表示优先级信息的<strong>字段</strong>即可, 比如在消息体里面加上 priority 字段用来表示这个消息的优先级是什么. 回顾一下前面讲到的 Kafka 的协议体, 如下图所示, 如果要在 Kafka 中加上优先级队列的特性, 则在 data 字段里面加上 priotity 字段即可.</p> <p><img src="/img/b4b4b2822dbfcf349da7eef311d6e11f-20240421231949-p6vy9wb.jpg" alt=""></p> <p>这里主要看看<strong>内核层面如何支持</strong>, 从技术上来看, 主要有以下几个思路:</p> <ol><li><strong>正常写入数据, 同时维护一个按照优先级排序后的消息索引, 消费的时候根据索引的顺序去定位读取数据</strong>.</li> <li><strong>数据写入时对存量的消息数据进行全量重排序, 然后按正常逻辑进行消费</strong>.</li> <li><strong>用空间换时间, 只支持固定维度的优先级</strong>, 比如总共 100 个优先级. 在底层对于开启优先级队列的数据, 进行分文件顺序存储. 在写入的时候根据优先级顺序写入不同文件段, <strong>消费的时候优先消费优先级高的数据</strong>.</li></ol> <p>从实际实现的角度来看, 第二和第三种方案用得比较少, 因为需要对消息队列的顺序存储模型做较大改动. 比如第二种方案需要频繁把数据全部取出来, 排序后再重新写入, 对资源的消耗太大. 第三种方案需要修改底层数据的存储模型, 改动也较大.</p> <p>所以方案一是比较常用的方案, 它的主要思路是: <strong>在内核中维护一个按优先级信息排序的索引结构, 索引指向消息数据的实际存储位置</strong>. 当数据写入时, 会<strong>先把数据按照原先的流程写入到分区里面, 然后根据消息的优先级信息去更新优先级索引. 消费的时候会先读取优先级队列中的数据, 判断应该读取哪些数据, 定位到具体消息数据返回给客户端</strong>.</p> <p>​<img src="/img/155ef81b7b75f56162df78a629601c7b-20240421231949-rygkvay.jpg" alt="">​</p> <p>所以, 可以知道方案一主要的工作量是优先级索引的实现. 它的实现从技术上看, <strong>存在两个问题</strong>, 必须要搞明白.</p> <ol><li><strong>选择哪种数据结构来存储</strong>? 以保证插入和获取的时间复杂度较低.</li> <li><strong>如何实现索引数据的持久化存储和快速重建</strong>?</li></ol> <p>从功能上来看, 因为只有排序没有搜索的需求, 所以可以基于 <strong>排序链表</strong> 来构建优先级索引. 接下来需要选择合适的排序算法, 排序算法主要关注的是时间复杂度和空间占用.</p> <p>不妨先来对比一下 8 个主流排序算法的时间复杂度和稳定性.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/20b93915d2985788f3e0ba09eyyddaf0-20240421231949-kj4p5wx.jpg" alt=""></p> <p>因为消息队列堆积的数据可能会很大, 所以需要选择数据量大时性能仍然优秀且稳定的算法. 从具体业务使用场景分析, 消息队列优先级一般是相对固定的, 有阶梯的, 比如固定的 5 个, 10 个优先级这样子. 基于这两个信息, 结合上面的表格, 会建议选择 <strong>归并排序</strong>.</p> <p>第一个问题解决了, 那么下一个问题: <strong>如何实现索引数据的持久化存储和快速重建</strong>?</p> <p>从实现来看, 为了性能考虑, 索引数据一般需要缓存在<strong>内存</strong>中. 所以还需要评估对内存的占用情况.</p> <p>这里给你一个基本的评估算法吧.</p> <ul><li>假设链表的每个元素存储 <strong>分区号, 消息位点, 优先级</strong> 三个数据, 都是 int 型数据, 则每个节点占用的空间是12个字节.</li> <li>假设支持最大容量为 100w 的优先级索引, 则占用的空间是 1000000*12/1024/1024~=11MB.</li> <li>假设一个节点可以支持 100 个优先级队列的话, 占用 1.1G 的内存.</li></ul> <p>从数值上来看, 空间占用并不大. 所以可以优先考虑存储在内存中. 但是当需要支持容量更大的优先级队列时, 则要考虑是否需要文件排序.</p> <p>那么是否要对索引数据持久化存储呢?</p> <p>个人的建议是不用的, 因为源数据都存储在分区中. 建议当索引数据丢失时, 直接通过读取分区来读取源数据, 然后重建优先级索引即可. 这样的话, 在 Leader 切换的时候, 可以复用这部分的能力, 直接在新的 Leader 重建优先级索引即可.</p> <p><strong>目前主流消息队列对优先级队列支持的较少, 只有 RabititMQ 支持</strong>. 接下来就来看一下 RabbitMQ 中优先级队列的实现方式.</p> <h6 id="rabbitmq中优先级队列的实现"><a href="#rabbitmq中优先级队列的实现" class="header-anchor">#</a> RabbitMQ中优先级队列的实现</h6> <p>先来看一下 RabbitMQ 中优先级队列的使用, 主要分为以下 3 步:</p> <ol><li>创建队列时, 通过设置 x-max-priority 属性来设定队列的最大优先级.</li> <li>发送消息时, 可以使用消息的 priority 属性来设置消息的优先级.</li> <li>消费端无需进行任何更改, 可以像普通队列一样消费消息.</li></ol> <p>下面来看一个代码示例:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 创建了名为 priority_queue 的优先级队列, 其最大优先级为 10. </span>
channel<span class="token punctuation">.</span><span class="token function">queue_declare</span><span class="token punctuation">(</span>queue<span class="token operator">=</span>'priority_queue'<span class="token punctuation">,</span> arguments<span class="token operator">=</span><span class="token punctuation">{</span>'x<span class="token operator">-</span>max<span class="token operator">-</span>priority'<span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment">// 向优先级队列 priority_queue 发送了一个带有优先级为 5 的消息</span>
channel<span class="token punctuation">.</span><span class="token function">basic_publish</span><span class="token punctuation">(</span>exchange<span class="token operator">=</span>''<span class="token punctuation">,</span> routing_key<span class="token operator">=</span>'priority_queue'<span class="token punctuation">,</span> body<span class="token operator">=</span>'<span class="token class-name">Hello</span> <span class="token class-name">World</span><span class="token operator">!</span>'<span class="token punctuation">,</span> properties<span class="token operator">=</span><span class="token class-name"><span class="token namespace">pika<span class="token punctuation">.</span></span>BasicProperties</span><span class="token punctuation">(</span>priority<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>从 RabbitMQ 内核底层实现来看, 核心是优先级排序. 即在 RabbitMQ 中优先级队列 <strong>通过优先级堆(Priority Heap)的数据结构进行消息优先级的排序</strong>. 对于具有不同优先级的消息, 会被放入不同的子队列, 每个子队列对应一个优先级. 当有消息进入优先级队列时, RabbitMQ 会将其放入相应优先级的子队列.</p> <p>当消费者从优先级队列消费消息时, <strong>RabbitMQ 会先检查优先级最高的子队列</strong>, 如果有消息, 则从中取出一个消息并发送给消费者; 如果优先级最高的子队列为空, 则检查次高优先级的子队列, 以此类推. 当所有子队列都为空时, 说明优先级队列中没有消息.</p> <p>另外还需要注意, <strong>大量使用优先级队列可能会导致性能下降</strong>. 实际应用中应该根据需求和资源情况决定是否使用优先级队列.</p> <h5 id="总结-31"><a href="#总结-31" class="header-anchor">#</a> 总结</h5> <p>严格来讲, <mark><strong>死信队列是一个功能, 不是一个队列. 它实现的是, 当数据处理失败后, 将数据缓存起来, 继续处理后面的数据, 以避免影响业务的流程</strong></mark>.</p> <p><strong>死信队列的功能主要分为生产死信队列, Broker 死信队列, 消费死信队列三种形态</strong>. 即当数据生产失败, 数据过期, 消费失败时, 将数据先存到另外一个地方, 然后继续主流程. 从功能上看, 这个存储数据的目的地可以是第三方存储, 也可以是集群内或跨集群的 Topic. 默认情况下都是集群内的另外一个 Topic.</p> <p>生产和消费的死信队列的主要逻辑都是在消息队列 SDK 实现的, 逻辑并不复杂. 一般的流程是在数据处理失败的最后一个环节, 判断是否开启死信队列, 是的话就将数据写入到死信队列中.</p> <p>目前主流消息队列 RocketMQ, RabbitMQ 支持死信队列的功能.</p> <p><strong>优先级队列是指不管生产端消息的顺序是什么, 消费端肯定会先拿到优先级高的消息</strong>. 即客户端在发送消息的时候给每条消息加上优先级信息, 不管客户端发送消息的顺序是怎样的, Broker 都会保证消费端一定会先消费到优先级高的消息.</p> <p><strong>业务可以将不同优先级的消息写入到不同的分区或 Topic 中, 消费端优先去读取优先级较高的分区或 Topic, 从而实现类优先级队列的效果, 但是这种方案业务的使用成本会较高</strong>.</p> <p>标准的方案是在消息队列内核支持优先级队列. 从技术上来看, 一般会通过在内存中维护优先级索引来实现优先级队列. 即写入时将消息树正常写入到分区, 但是会根据优先级数据维护一个优先级索引. 消费的时候先去优先级索引获取优先级高的数据, 然后再去定位读取具体的消息数据.</p> <p>目前主流消息队列对优先级队列支持得较少, <strong>只有 RabititMQ 支持优先级队列</strong>.</p> <h5 id="思考题-27"><a href="#思考题-27" class="header-anchor">#</a> 思考题</h5> <blockquote><p>在你当前的业务中, 有哪些场景需要用到死信队列和优先级队列?</p></blockquote> <p>以电商场景来举例.</p> <ol><li>在订单处理的场景, 如果订单的某个字段丢失, 导致这个订单无法被处理, 此时就需要<strong>先忽略这个订单</strong>, 继续处理后续的订单. 面对这个情况, 就可以在消费的时候启用死信队列, <strong>将无效的消息写入到死信队列中</strong>.</li> <li>同样是在订单场景, 在快递派送流程希望 VIP 客户优先派送, 此时就需要根据客户的城市, 属性, VIP 级别等信息对客户进行分级. 然后在往下游管道生成快递信息的时候, 附上优先级信息. 此时下游会根据优先级拿到需要处理的快递列表, 从而保证优先级高的订单被优先处理.</li></ol> <h4 id="_32-消息查询-如何实现消息查询功能"><a href="#_32-消息查询-如何实现消息查询功能" class="header-anchor">#</a> 32-消息查询:如何实现消息查询功能?</h4> <p>这节课来讲讲在消息队列中如何<strong>实现消息查询</strong>.</p> <p>从功能上来看, 消息队列的核心功能是生产和消费, 查询并不是它的主要工作, 但在一些场景中用户还是需要对消息进行查询. 最常见的场景是: <strong>用户觉得某条消息丢了, 需要查询这条消息是否保存在 Broker 中, 此时会怎么做呢?</strong>   除此之外, 还有哪些场景会用到消息查询的功能呢? 这节课就重点解决这两个问题.</p> <h5 id="什么时候会用到消息查询"><a href="#什么时候会用到消息查询" class="header-anchor">#</a> 什么时候会用到消息查询</h5> <p>首先, 来看下面两个行格式和 JSON 格式的消息数据示例. 它们主要包含时间戳, 消息位点, 消息 ID, 消息 Key, 消息内容等 5 个部分.</p> <blockquote><p>Nginx日志</p></blockquote> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>timestamp:1691711859099
messageId:kvhnfdskui
offset:1
key: 空
value: 
66.249.65.159 - - [06/Nov/2014:19:10:38 +0600] &quot;GET /news/53f8d72920ba2744fe873ebc.html HTTP/1.1&quot; 404 177 &quot;-&quot; &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5376e Safari/8536.25 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><blockquote><p>JSON格式的日志</p></blockquote> <div class="language-json line-numbers-mode"><pre class="language-json"><code>timestamp<span class="token operator">:</span><span class="token number">1691711859099</span>
messageId<span class="token operator">:</span>vkjfikdsfd
offset<span class="token operator">:</span><span class="token number">2</span>
key<span class="token operator">:</span> c816991f-adfe<span class="token number">-4617</span>-8cf3-9997aea90ded
value<span class="token operator">:</span> 
<span class="token punctuation">{</span>
    <span class="token property">&quot;@timestamp&quot;</span><span class="token operator">:</span> <span class="token number">1.64880350063659E9</span><span class="token punctuation">,</span>
    <span class="token property">&quot;@filepath&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/var/log/tke-log-agent/test7/c816991f-adfe-4617-8cf3-9997aea90ded/c_tke-es-687995d557-n29jr_default_nginx-add90ccf49626ef42d5615a636aae74d6380996043cf6f6560d8131f21a4d8ba/jgw_INFO_2022-02-10_15_4.log&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;log&quot;</span><span class="token operator">:</span> <span class="token string">&quot;15:00:00.000[4349811564226374227] [http-nio-8081-exec-64] INFO com.qcloud.jgw.gateway.server.topic.TopicService&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;pod_name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;tke-es-687995d557-n29jr&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;namespace_name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;default&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;pod_id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;c816991f-adfe-4617-8cf3-9997aea90ded&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;10.0.96.47&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;container_name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;nginx&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;docker_id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;add90ccf49626ef42d5615a636aae74d6380996043cf6f6560d8131f21a4d8ba&quot;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>所以基于上面的消息数据, 从用户视角看, 一般就有以下 4 种查询需求:</p> <ol><li><strong>根据消息位点(Offset)信息查询消息</strong>.</li> <li><strong>根据某个时间点或时间范围查询消息</strong>.</li> <li><strong>根据消息 ID 查询消息</strong>.</li> <li><strong>根据消息 Key 或消息中的某个内容查询消息</strong>.</li></ol> <p>另外, 消息轨迹数据需要导入到第三方引擎进行存储和查询. 如果能在 Topic 中实现查询功能, 那么就能省掉轨迹数据导出和第三方引擎的成本. 这也是消息队列内核内置查询功能的收益之一.</p> <p>接下来来看一下关于消息队列支持查询的几个理论型知识点.</p> <h5 id="消息队列支持查询的理论基础"><a href="#消息队列支持查询的理论基础" class="header-anchor">#</a> 消息队列支持查询的理论基础</h5> <p>先来回顾一下前面讲过的消息数据的存储结构.</p> <h6 id="消息数据存储结构"><a href="#消息数据存储结构" class="header-anchor">#</a> 消息数据存储结构</h6> <p>消息队列的底层是分段存储, 也知道底层存储结构有每个分区单独一个存储 &quot;文件&quot; 和每个节点上所有分区的数据都存储在同一个 &quot;文件&quot; 这两个方案. 因为从消息查询的角度来看, 两种方案的技术实现基本一致, 所以接下来就基于方案一来分析一下消息查询的实现.</p> <p>下面是基于方案一实现的分区维度的底层分段数据结构图. 可以看到, <strong>一个分区由多个数据段组成</strong>, 比如 Offset 从 1-10000 的数据段, Offset 从 10000-30000 的数据段.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ef641dcd8f5798366c903b8f711819d6-20240421231949-fmyp3cq.jpg" alt="">​</p> <p><strong>每个数据段里面的数据由多个数据组成, 每个数据又由消息位点和消息组成</strong>.</p> <p>​<img src="/img/b1f143b6d0647bdf652c7d7e2de956a0-20240421231949-6jnku26.jpg" alt="">​</p> <p>那怎么在这个数据结构上进行数据查询呢? 从技术上来看, <mark><strong>核心是数据索引的构建</strong></mark>. 所以接下来就来看一下为什么需要索引? 以及如何构建索引?</p> <h6 id="关于索引的一些知识点"><a href="#关于索引的一些知识点" class="header-anchor">#</a> 关于索引的一些知识点</h6> <blockquote><p>问题1: 为什么一定要构建索引呢?</p></blockquote> <p>从技术上看, 查询的核心就是<strong>速度</strong>, 不能每次都去遍历所有的数据, 也不能直接从硬盘中检索数据, 因为基于硬盘搜索数据的性能很低. 所以<strong>构建索引最主要的原因是, 可以把数据加载进内存, 提高数据的处理效率</strong>.</p> <blockquote><p>问题2: 如何构建索引?</p></blockquote> <p>在我看来构建索引需要思考两个点, <strong>一是索引不能占用太多内存空间, 二是索引元素的增加, 删除, 检索的时间复杂度要尽量低</strong>.</p> <p>所以构建索引的核心就是<strong>选择合理的数据结构存储索引数据</strong>. 从业界来看, MySQL 用的是 &quot;B+树&quot; 来构建索引, Elasticsearch 使用的是 &quot;倒排索引&quot;, 从而支持高性能, 复杂的查询. 消息队列查询的核心也是设计合理的数据结构来构建索引, 以满足对应的查询需求.</p> <p>不过<strong>索引是需要持久化存储的</strong>, 应该怎么持久化存储索引呢?</p> <p>索引的持久化存储肯定是存储在文件上的, 而消息数据底层是分段存储的. 所以如下图所示, 从技术上看, 在索引的构建上有 <strong>所有段文件构建一个索引</strong> 和 <strong>每个数据段构建索引</strong> 两个思路.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/04a21496e72544706bc914561fff0ff1-20240421231949-lfkaau4.jpg" alt="">​</p> <p>技术实现上, 这两种方案都会用到, 根据不同的场景来选择合适的方案即可. 至于如何选择, 在后面会细讲.</p> <h5 id="内核支持简单查询"><a href="#内核支持简单查询" class="header-anchor">#</a> 内核支持简单查询</h5> <p>接下来看一下内核是如何支持查询的.</p> <p>先来看看内核一般会支持哪些类型的查询, 分为以下 3 种:</p> <ol><li><strong>根据 Offset 查询, 即根据 Topic, 分区, Offset 去查询到对应的消息</strong>.</li> <li>根据时间戳查询, 即根据时间戳去查询到这个时间戳对应的消息, 或根据时间戳范围查询到这个范围内的消息.</li> <li>根据消息 ID 查询, 即根据消息 ID 去查询到这个消息 ID 对应的消息.</li></ol> <h6 id="根据offset查询数据"><a href="#根据offset查询数据" class="header-anchor">#</a> 根据Offset查询数据</h6> <p>从功能上看, 根据 Offset 查询数据一般是根据 <strong>Topic, 分区, Offset</strong> <strong>三元组</strong> 来查询数据. 基于上述的存储模型可以知道, 此时分区的存储结构已经是一个多级索引, 具体说是一个三级索引.</p> <ul><li>第一级: Topic. 因为每个 Topic 的数据单独存储.</li> <li>第二级: 分区. 因为每个分区的数据单独存储.</li> <li>第三级: Offset 索引. 构建 Offset 和具体文件位置的索引.</li></ul> <p>不难看出, 我们的主要工作是<strong>实现第三级索引</strong>. 从上面讲到的理论基础可以知道, 其实就是选择合适的数据结构来存储索引. 那是不是上来就引入 B+树, 倒排索引, 红黑树呢?</p> <p>当然不是. 需要先分析当前底层<strong>存储和数据的特征, 然后结合需求来实际分析如何实现</strong>.</p> <p>消息队列底层是 <strong>顺序存储的模型, 所以 Offset 是顺序递增的</strong>. 简单理解, 数据已经是一个天然顺序了, 基于一个天然顺序的数据来做检索就非常简单, 直接<mark><strong>引入二分查找</strong></mark>就可以.</p> <p>所以索引文件的数据结构实现就很简单.</p> <p>​<img src="/img/493be332f26c3a2d205393d8f3f13eb9-20240421231949-7lwoveb.jpg" alt="">​</p> <p>如上图所示, 可以<strong>用顺序链表来存储索引数据</strong>. <strong>每个链表节点存储消息位点(Offset)和消息所在的文件的位置(Position)两个元素. 基于顺序链表, 如果要搜索某个 Offset 的数据, 直接使用二分查找(折半查找)即可, 查找的时间复杂度为 O(logn), 顺序链表的插入的时间复杂度为 O(1)</strong> .</p> <p>因为要持久化存储, 所以文件中索引数据的格式可以用下面的格式进行存储.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>offset: 1 position: 10
offset: 10 position: 20
offset: 20 position: 55
offset: 30 position: 70
offset: 300 position: 90
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>在上面的示例中, 不知道你是否注意到了 Offset 和 Position 是<strong>单向递增</strong>的, 但都不是连续的, 这是为什么呢?</p> <p>可以试想一下, 假设有 10 亿条数据, 按照上面的设计应该也有 10 亿个索引节点. 以此类推, 如果数据更大, 索引数据会占用大量的存储空间, 所以在顺序链表的基础上, 可以引入 <mark><strong>跳跃表</strong></mark> 来节省空间.</p> <p>​<img src="/img/d72982d04afb1e998e22ebe2338bed03-20240421231949-038mud5.jpg" alt="">​</p> <p>如上图所示, 引入跳跃表的主要思路是按照一定的间隔跳跃着保留中间元素. 当检索数据时, 通过二分算法找到离目标最近的前一个跳跃表元素. 如果恰好是需要寻找的元素, 就直接返回, 否则就往后遍历数据找到数据.</p> <p>举个例子说明, 比如要找到上图中的元素 22, 流程就是:</p> <ol><li>通过二分算法找到离 22 最近的前一个跳跃表元素 20, 得到 20 对应的 Offset=20 和 Position=55, 查找的时间复杂度为 O(logn).</li> <li>因为步骤 1 找到的节点不是需要的 22, 所以向后遍历两个元素就可以找到数据 22, 这一步理论的时间复杂度为 O(n). 但是可以通过控制两个跳跃表索引元素之间的节点数量, 来降低时间复杂度. 比如固定为间隔 10, 此时时间复杂度就是一个常量 10, 所以从算法来看, 这个时间复杂度是可以忽略的.</li></ol> <p>引入跳跃表结构后, 通过 <strong>牺牲一定的时间复杂度换取了空间复杂度的大幅度降低</strong>, 是一个蛮推荐的方案.</p> <p>最后再来看一下<strong>内存占用率的使用控制</strong>, 先来算个数据.</p> <p>假设每个数据段都有 1 千万条数据, 那么引入跳跃表前占用的内存空间是:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>2个 int 型的容量 * 1000w =8byte * 1000w ~=76MB. 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>引入跳跃表后占用的内存空间是:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>2个 int 型的容量 * 20w =8byte * 20w ~=1.52MB
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>因此可知, 引入索引不会占用太多的内存空间, 引入跳跃表后还可以大幅度降低对内存空间的占用. 接下来来看看如何实现根据时间戳进行查询.</p> <h6 id="根据时间戳查询数据"><a href="#根据时间戳查询数据" class="header-anchor">#</a> 根据时间戳查询数据</h6> <p>从需求上看, 根据时间戳查询主要有以下两种查询场景:</p> <ol><li>根据<strong>时间戳查询到指定位置的数据</strong>.</li> <li>根据时间戳范围查询到范围内的数据.</li></ol> <p>消息队列内核一般只支持第一种场景. 因为从技术上看, 构建高性能的范围查询是一个复杂的话题, 涉及到的知识点非常多. 从消息队列内核的角度看, 从技术上也能实现, 但是代码复杂度会提高很多, 要增加大量内核开发维护成本. 所以<strong>目前消息队列内核支持第二种场景的比较少</strong>.</p> <p>如下图所示, 从技术上看, 消息队列实现根据时间查询的思路是: 先根据时间戳找到对应的 Offet, 然后再根据 Offset 查询到对应的数据.</p> <p>所以技术上的核心思路是: <strong>构建时间戳和 Offset 对应的索引</strong>.</p> <p>因为消息数据是根据时间戳递增存储的, 所以时间戳和 Offset 索引也是基于顺序链表构建的. 链表节点由毫秒时间戳和消息位点组成.</p> <p>​<img src="/img/94cc3b7a8bbf6b66b6c34fe361b0f5bd-20240421231949-953z3cg.jpg" alt="">​</p> <p>同样的因为需要持久化存储, 所以底层索引文件内容格式可以如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>timestamp: 1691236897071 offset: 744267032
timestamp: 1691236898193 offset: 744267036
timestamp: 1691236899167 offset: 744267040
timestamp: 1691236899752 offset: 744267044
timestamp: 1691236900204 offset: 744267048
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>现在你应该会发现, 时间戳和 Offset 也不是连续的. 时间戳不连续是合理的, 因为可能有的时间没有数据. 但是 Offset 理论上应该是连续的, 不连续的原因和其实上面一样, 主要是为了节省空间引入了跳跃表的实现.</p> <p>基于上面的设计来看一个示例. 假设需要根据时间戳来找到某条数据实, 流程就是:</p> <ol><li>通过二分算法查找到最近的前一个时间戳, 获取到它对应的 Offset, 时间复杂度为 O(logn).</li> <li>根据这个 Offset 去读取文件, 遍历后续的数据找到大于等于这个时间戳的的数据, 读取数据.</li></ol> <p>在这个模型下, 如果想根据时间范围进行查询, 有一个思路是: 当实现第一种场景后, 可以查询两次时间戳. 然后根据查询返回开始 Offset 和结束 Offset, 去读取需要的数据.</p> <h6 id="根据消息id查询数据"><a href="#根据消息id查询数据" class="header-anchor">#</a> 根据消息ID查询数据</h6> <p>最后再来看看如何实现根据消息 ID 查询数据.</p> <p>消息 ID 和前面讲到的时间戳, Offset, 最大的不同是 <strong>消息</strong> <strong>ID</strong> <strong>是无序的</strong>. 如果能保证所有消息 ID 是有序的, 那查询的实现思路和前面两种就是一样的. 但要构建一个全局有序的消息 ID 生成器, 复杂度太高了, 一般不会这么做.</p> <p>按照上面的思路, 应该通过<strong>构建消息 ID 和 Offset 组成的二元索引</strong>来完成查询需求, 索引的格式可以是下面这样子. 即根据消息 ID 找到对应的 Offset, 然后再根据 Offset 找出消息内容.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>msgID:dfangjfjhs offset:10
msgID:mbvnjdlfjd offset:21
msgID:otidfkjifd offset:33
msgID:ddnbklfdid offset:40
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>从技术上来看, 根据消息 ID 查询数据有简单实现和复杂实现两种方案.</p> <p>简单实现的本质是<strong>结合消息队列本身底层顺序存储的特征而设计的一种取巧的方法</strong>. 思路如下:</p> <ol><li>客户端通过 SnowFlake 算法生成唯一的消息 ID.</li> <li>查询的时候根据消息 ID 反解析出消息 ID 对应的时间戳, 因为 SnowFlake 算法中有一部分数据是时间戳.</li> <li>结合这个时间戳去搜索消息.</li></ol> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c679dcdff8ac2bb0db76615a073c8ded-20240421231949-nnbv53s.jpg" alt=""></p> <p>这个方案的好处是, 几乎不需要开发工作量, 流程简单通用. 缺点是可能会误判, 即消息明明存在, 但是却搜索不出来. 因为消息 ID 在客户端生成, SnowFlake 算法的时间戳也是客户端的时间, 所以在一些异常或延时消息的场景中, 数据写入 Topic 或分区的时间和客户端发送出来的时间相差很大, 从而导致根据 SnowFlake 解析出的客户端时间无法查询到消息.</p> <p>复杂方案则是是 <strong>基于哈希表, B+树, 红黑树等数据结构来构建消息 ID 和 Offset 的索引</strong>, 同时保证在索引元素添加和获取的时候的时间复杂度较低, 从而满足查询需求. 因为根据消息 ID 查询消息的需求是很固定的, 所以会建议使用哈希表来构建索引, 因为哈希索引结构能够实现高效的消息查询.</p> <p>业界主流消息队列 <strong>RocketMQ 就是基于哈希表来构建消息 ID 和 Offset 的索引的</strong>. 简单来看一下底层的实现原理, 大概分为以下 4 点:</p> <ol><li><strong>RocketMQ 的索引存储在 IndexFile(索引文件)中, 通过使用哈希索引结构来构建索引</strong>.</li> <li>在 IndexFile 中, 消息 ID 被哈希成一个固定长度的 Key. 这个 Key 通过哈希函数映射到一个哈希槽(Slot)上. <strong>哈希槽里存储的是该 Key 对应消息在 CommitLog 中的物理偏移量</strong>.</li> <li>RocketMQ 使用 <strong>开放寻址法</strong>(Open Addressing)来解决哈希冲突问题. 当不同的 Key 映射到相同的哈希槽时, 会根据预设的步长(step)逐个检查其他槽位, 直到找到一个空闲槽位.</li> <li>同时哈希索引结构为每个 Key 维护一个链表, 用于将 Key 映射到多个物理偏移量(例如当一个消息发送到多个队列时). 这种哈希索引结构使得 RocketMQ 在查询消息时能够通过 Key 快速定位到对应的哈希槽, 再根据物理偏移量找到实际消息, 从而提高查询效率.</li></ol> <p>你应该发现了上面三种都是<strong>简单固定</strong>的查询场景, 而如果要实现复杂查询怎么办呢?</p> <h5 id="借助第三方工具实现复杂查询"><a href="#借助第三方工具实现复杂查询" class="header-anchor">#</a> 借助第三方工具实现复杂查询</h5> <p>从实际使用的角度来看, 消息队列支持复杂查询主要有<strong>第三方引擎支持查询和工具化简单查询</strong>两种思路.</p> <h6 id="第三方引擎支持查询"><a href="#第三方引擎支持查询" class="header-anchor">#</a> 第三方引擎支持查询</h6> <p>第三方引擎支持查询是指引入第三方查询引擎, <strong>将 Kafka 的数据导入到下游引擎</strong>, 依赖引擎的能力来实现复杂的数据查询, 比如 Kafka + Hive, Kafka + Elasticsearch, Kafka + Trino(以前的 Presto SQL).</p> <p>如下图所示, 上面这几个方案的思路都是一样的. 核心思路都是<strong>先将数据清洗处理变成结构化的数据, 然后导入到下游的查询引擎中, 然后依赖搜索引擎的复杂检索能力来提供检索服务</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9e581fdb6794e3318ce2d4cc113bbaac-20240421231949-rzfa9f7.jpg" alt=""></p> <p>这几个方案的主要区别在于使用方式, 支持的查询能力, 资源部署的成本不一样. 比如搜索引擎是否能够自主从 Kafka 拉取数据, 还是需要依赖一个独立的组件导入数据, 但是从结果上来看都是基本可以满足复杂查询需求的.</p> <p>从具体落地使用上来看, 上面这三种方案业界用得都比较多. 从选择上来看, 一般业务都是根据自己当前所拥有的资源来决定使用哪一个. 比如当前已经有一套 Elasticsearch 了, 就选择 Kafka + Elasticsearch, 举一反三. 这么选择也是因为这几个方案之间的差别不是特别大.</p> <p>不过这个方案有一个前提是, 需要 Kakfa 里面的数据都是规范的<strong>格式化的数据</strong>, 或者需要经过数据清洗格式化后才能导入到下游的引擎中.</p> <p>从技术上看, 消息队列数据规范格式化需要依赖 Schema 来实现, 下一节会细讲 Schema. 而数据清洗和导入下游引擎, 还需要依赖连接器来实现, 也会在后面的课程中展开细讲.</p> <h6 id="工具化简单查询"><a href="#工具化简单查询" class="header-anchor">#</a> 工具化简单查询</h6> <p>工具化简单查询是指<strong>自定义编码去消费数据</strong>, 然后在代码里面加过滤条件, 从而实现查询.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2fa545059805eb1040990c7a3c05123d-20240421231949-0fdl55d.jpg" alt=""></p> <p>这个方案直观看上去, 存在性能低, 时间复杂度高, 不灵活等严重缺点, 但在实际场景中它是非常实用的.</p> <p>例如, 在出问题的时候, 偶尔需要根据消息内容或者消息 Key 模糊查询数据是否在集群中. 这个需求非常常见, 但是使用频率低.</p> <p>从技术上看, 标准方案是把数据清洗后导入到下游引擎, 然后查询. 这个方案的缺点就是成本太高, 太复杂, 因为使用频率太低, 就有一种杀鸡用牛刀的感觉, 综合讲 ROI 太低了. 所以面对这种场景就可以使用这种思路.</p> <p>它的核心是: 在运营平台支持根据时间范围, 消息 Key, 对内容进行模糊查询的功能. 底层的实现就是上面说的消费+过滤的方案. 从使用上来看, 虽然慢一点, 但是也能满足需求, 在运营和 ROI 层面来看是非常实用的.</p> <h5 id="总结-32"><a href="#总结-32" class="header-anchor">#</a> 总结</h5> <p>查询是消息队列的辅助功能, 使用的场景和频率不高.</p> <p>从功能上看, 一般会支持按消息位点查询, 按时间戳查询, 按消息 ID 查询, 按消息 Key 或消息内容模糊查询四种场景.</p> <p>查询的核心是索引的构建. 因为消息队列底层顺序存储的特性, 在按消息位点查询和按时间戳查询的场景中, 基于顺序存储和二分查找就可以快速实现数据的检索.</p> <p>而根据消息 ID 查询有简单方案和复杂方案两种. 简单方案是根据消息 ID 反解析出时间戳, 然后根据时间戳去查询消息, 缺点是精准度不够. 标准方案是使用比如哈希表等数据结构来构建索引, 实现精准查询, 缺点是实现成本较高, 但是能实现高效的精准查询.</p> <p>复杂的查询不应该在内核中支持, 因为这会导致内核逻辑复杂, 增加开发和维护的成本. 复杂的查询要交由专业的查询引擎来支持, 即将数据导出到下游的 Elasticsearch, Hive 中, 基于这些引擎的查询能力实现复杂查询.</p> <p>从实际业务上来看, 工具化简单查询是一个非常实用的技巧. 只需要在运营端开发功能, 不需要内核的任何改动. 在使用频率较低的复杂查询场景中, 使用的 ROI 会特别高.</p> <h4 id="_33-schema-如何设计实现schema模块"><a href="#_33-schema-如何设计实现schema模块" class="header-anchor">#</a> 33-Schema:如何设计实现Schema模块?</h4> <p>这节课来看看消息队列中的 Schema 模块. 看到 Schema 这个词, 你可能会有点陌生, 从而产生一些疑问. 比如 Schema 是什么? 它有什么用? 什么时候可以用到它? 这节课就重点解决这三个问题.</p> <h5 id="schema是什么"><a href="#schema是什么" class="header-anchor">#</a> Schema是什么</h5> <p>Schema 翻译过来是 &quot;模式&quot; 的意思. 它表示的是<strong>数据结构定义</strong>, 即定义数据是什么格式的.</p> <p>如下图所示, 默认情况下消息数据在生产者, Broker, Consumer 的全流程中, 代码层面没有对消息内容格式进行限制或校验.</p> <p>​<img src="/img/0f757ba92e14a277dfb7276547fe7459-20240421231949-zzf9cxo.jpg" alt="">​</p> <p>因此存在的问题是: 消费者和生产者需要线下对齐数据格式, 然后消费者根据约定的消息格式编写相应的处理逻辑. 当生产端的数据格式或者某个字段的数据类型发生变化时, 如果没有及时通知下游消费者, 消费者就会无法解析数据, 导致数据消费异常.</p> <p>Schema 就是用来解决全流程中的数据格式的规范定义问题, 即<strong>保证上下游数据在传递过程中, 消息可以根据指定的格式和定义进行传递</strong>.</p> <p>举个例子, 在订单场景中, 一般通过消息管道传递订单数据, 实现系统解耦. 因此每个订单数据必须包含订单 ID(OrderID)字段, 否则下游就无法处理. 此时就可以启用 Schema, 在生产端规范数据传递, 在 Broker 端进行数据校验, 在消费端根据指定的格式进行数据解析.</p> <p>那 Schema 具体是一个什么形式呢? <strong>其本质就是一个字符串, 用来定义数据是什么样子的. 然后客户端和服务端会根据定义的这个格式, 组装, 校验, 解析消息数据, 从而规范数据的传递</strong>.</p> <p>可以通过 MySQL 中表的 Schema, 来理解消息队列中的 Schema. 它们都是表达这批数据有几个字段, 这个字段是什么类型, 长度是多长这些信息.</p> <p>看一段代码示例, 比如需要接收包含名字和地域两个字段的数据, 此时通过 MySQL Schema 和消息队列 Schema 分别如下表示. MySQL 表的 Schema:</p> <div class="language-sql line-numbers-mode"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token keyword">IF</span> person<span class="token punctuation">(</span>
   id <span class="token keyword">INT</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">AUTO_INCREMENT</span><span class="token punctuation">,</span>
   name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>
   region <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>消息队列数据的 Schema:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;maxLength&quot;</span><span class="token operator">:</span><span class="token number">100</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;region&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;maxLength&quot;</span><span class="token operator">:</span><span class="token number">40</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>那如何在消息队列的架构中支持 Schema 特性呢? 继续来看一下.</p> <h5 id="schema技术方案设计"><a href="#schema技术方案设计" class="header-anchor">#</a> Schema技术方案设计</h5> <p>先来分析一下需求, 知道整体的需求是: <strong>需要规范生产到消费的数据的格式化传递</strong>. 所以拆解需求后, 可以分为以下五点:</p> <ol><li>Scehma 信息是如何存储的?</li> <li>客户端, Broker 如何获取到 Schema 信息?</li> <li>Schema 是在什么维度生效的? 比如 Topic 维度, 集群维度, 命名空间维度, 消息维度等等.</li> <li>Schema 信息可以变更吗? 变更后生产者, Broker, 消费者如何处理?</li> <li>生产者, Broker, 消费者如何使用 Schema?</li></ol> <p>带着这五个问题来看一张架构图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/aedcda34522a5908c6603ca4cd150a3d-20240421231949-gp9hvzm.jpg" alt="">​</p> <p>从图中可以看到, 在当前消息队列架构的基础上, 引入了一个新的组件: Schema Register, 即 Schema 注册中心. SchemaRegister 的作用是 <strong>持久化保存具体的 Schema 信息, 并提供接口给客户端增删改查</strong> <strong>Scheme</strong> <strong>信息</strong>.</p> <p>在消息全生命周期中, Scheme 的使用可以拆解为五个步骤.</p> <ol><li>生产者或消费者可以自动调用 SchemaRegister 创建 Schema 信息, 也可以通过运营端增加 Schema 的信息.</li> <li>一旦开启了 Schema, 生产者, 消费者初始化时需要配置 SchemaRegister 的访问地址. 启动的时候, 从 SchemaRegister 获取所需的 Schema 信息, 并缓存起来.</li> <li>生产者启动时会配置好本次需要发送的数据的 Schema. 此时 SDK 会根据客户端配置的 Schema 信息判断这个 Schema 是否存在. 如果存在就正常发送, 如果不存在则判断集群是否允许自动注册 Schema. 如果允许自动注册, 则调用 SchemaRegister 提供的 CreateSchema 接口进行注册. SchemaRegister 会为每个 Schema 分配唯一的 ID, 生产者会将这个 ID 写入到消息的属性中.</li> <li>Broker 启动时会从 Schema 注册中心获取全量的 Schema 信息, 缓存到本地. 当接收到消息数据后, 拿出消息中的 SchemaID, 获取到具体的 Schema 信息, 然后使用这个 Schema 信息对数据进行校验.</li> <li>消费端启动时也会加载 Schema 信息, 获取到数据后, 根据消息 ID 及其对应的 Schema 去解析, 处理数据. 如果不符合格式的数据, 就丢弃或者报错.</li></ol> <p>讲完了整体的运行过程, 接下来来详细看一下 Schema Register 的实现.</p> <h6 id="schema-register"><a href="#schema-register" class="header-anchor">#</a> Schema Register</h6> <p><strong>Schema Register 也称为 Schema 注册中心. 它的功能是存储数据, 并提供增, 删, 改, 查的功能接口来管理 Schema 信息</strong>.</p> <p>所以, Schema Register 本质上是一个 Server, 由计算逻辑层和存储层两部分组成. 计算逻辑层负责提供增删改查的接口支持对 Schema 信息的操作, 持久层负责分布式, 持久化存储 Schema 信息.</p> <p>​<img src="/img/1054ea6629c3bd948d6d4220f84830dd-20240421231949-5p106au.jpg" alt="">​</p> <p>从技术上看, Schema Register 有独立部署和 Broker 内核集成两种实现形态.</p> <p><strong>独立部署</strong> 是指 Schema Register 独立成一个 Server 进行部署, 比如它可以是一个 HTTP Server, 通过 MySQL 存储 Schema 信息, 暴露 Restful 接口提供服务.</p> <p>这种方案是目前主流消息队列用得最多的方案, 业界 Kafka, RocketMQ, Pulsar 用的都是这种方案. 它最大的好处是: <strong>独立部署的 Schema 服务可以给多套消息队列集群使用</strong>. 比如一个公司只需要部署一套 Schema Register 即可, 毕竟一套消息队列集群独立部署一个 Schema Register 太浪费了.</p> <p>从代码实现上来看, 独立的 Schema Register 开发复杂度不高. 一般基于 Spring Boot + MySQL 就可以实现.  但是这里有一个点, 引入 MySQL 当作存储的话, 相当于需要多部署一个 MySQL, 会增加系统部署运维的复杂度. 所以我们一般会把数据存储在消息队列的 Topic, 因为 Topic 也是分布式的可靠存储, 从而避免引入 MySQL.</p> <p>但是在某些私有部署场景, 独立部署的 Schema Register 就会增加部署运维的复杂度. 那有没有可能把 Schema Register 集成在 Broker 内核中呢?</p> <p><strong>Broker</strong> <strong>内核集成</strong> 是指在 Broker 内核实现 Schema Register. 如下图所示, 即在 Broker 上提供四层或七层的接口来满足 Schema 信息的增删改查等操作, 同时集群内部创建一个内部 Topic 来保存 Schema 信息.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/5a44e28ecb7612ae2bbea3d7dd01e404-20240421231949-lr846bq.jpg" alt="">​</p> <p>所以这种方案的技术实现思路大致如下:</p> <ol><li>创建一个内部的 Topic(比如 <code>__schema</code>​)来存储 Schema 信息.</li> <li>在 Broker 中实现 Schema CRUD 接口, 来支持增删改查等操作. 接口是四层 TCP 还是七层 HTTP, 区别不大, 主要是根据架构的实际情况来决定.</li> <li>接口的逻辑就主要是对 <code>__schema</code>​ 中的内容进行操作.</li></ol> <p>这种方案的好处跟第一种刚好是相反的, 是通过增加内核的复杂度来降低部署的复杂度. 这种方案的最大缺点是, Schema Register 修改都需要更新内核版本, 成本太高了. 因为 Schema Register 本质上是一个独立的服务, 单独部署维护的技术合理性更高. 这也是业界主流消息队列都使用第一种方案的原因.</p> <h6 id="schema格式设计"><a href="#schema格式设计" class="header-anchor">#</a> Schema格式设计</h6> <p>接下来来看一下 Scehma 的格式是什么样子的. 前面讲到, <strong>Schema 格式可以简单理解为 MySQL 的表的结构</strong>. 还是基于上面的例子进行扩展说明.</p> <p>因为 Schema 是和具体的消息队列集群绑定的, 所以 Schema 信息应该<strong>包含集群信息</strong>. 进一步, 如果有租户的概念, 那么 Schema 信息也需要<strong>包含租户的信息</strong>. 从技术上看, Schema 都是和 Topic 进行绑定的, 即表示当前这个 Topic 允许接收什么格式的数据. 所以, Schema 信息也需要<strong>包含 Topic 信息</strong>.</p> <p>除了这些基础信息, 最关键的是要标识这个消息数据的格式, 即需要表达出以下两个信息:</p> <ol><li>包含 name, region 两个字段.</li> <li>name 的类型是字符串, 最大的长度是 100; region 的类型也是字符串, 最大的长度是 40.</li></ol> <p>基于上面的需求, 可以用 JSON 格式来表示 Schema, 具体如下所示:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
  	<span class="token property">&quot;id&quot;</span><span class="token operator">:</span><span class="token string">&quot;kjdsjfudfd&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;version&quot;</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span>
    <span class="token property">&quot;cluster&quot;</span><span class="token operator">:</span><span class="token string">&quot;cluster1&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;tenant&quot;</span><span class="token operator">:</span><span class="token string">&quot;tenant1&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;topic&quot;</span><span class="token operator">:</span><span class="token string">&quot;topic1&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;schema1&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;properties&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
      <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;maxLength&quot;</span><span class="token operator">:</span><span class="token number">100</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
       <span class="token punctuation">{</span>
        <span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;region&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;type&quot;</span><span class="token operator">:</span><span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span>
        <span class="token property">&quot;maxLength&quot;</span><span class="token operator">:</span><span class="token number">40</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>在上面的 Schema 中:</p> <ol><li>​<code>id</code>​ 是这个 Schema 的唯一标识, 后续的变更, 查询, 删除都是根据这个唯一 ID 来的.</li> <li>​<code>version</code>​ 表示这个 <code>id</code>​ 对应的版本. 因为每个 Schema 会经过多次修改, 所以一个唯一 ID 会存在多个版本的 Schema. 严格来说,  <code>id + version</code>​ 才能唯一标识一个 Schema.</li> <li>​<code>cluster</code>​,  <code>tenant</code>​,  <code>topic</code>​,  <code>name</code>​ 分别表示集群, 租户, Topic 和 Schema 的名称.</li> <li>​<code>properties</code>​ 是 Schema 的重点内容, 表示这个消息的数据的格式. 它是一个 JSON 数组, 里面有多个元素, 用来表示这个 Schema 应该包含哪些字段以及每个字段的信息. 比如上面的 name 是字符串型, 最大长度是100, region 也是 string 型, 最大长度是40.</li></ol> <p>所以如下图所示, 一个 Schema 的具体结构可以是这样的.</p> <p>​<img src="/img/eeaff9e412d15c41ec4f18257a03e384-20240421231949-mwe9m2x.jpg" alt="">​</p> <p>当然这个 Schema 格式只是一个基础, 实际场景中还需要更多的字段来表达更多信息. 所以在实现上, 还需要进行一定的扩展.</p> <p>刚刚说到, <strong>Schema 一般是跟 Topic 绑定的</strong>, 所以拉长时间周期来看, Topic 的 Schema 肯定变更. 可能是从一个 Schema 换成了另外一个 Schema, 或者在当前的基础上添加, 删除字段, 修改字段类型等等.</p> <p>所以如下图所示, Topic 中肯定会存在前后数据的 Schema 不一样的情况.</p> <p>​<img src="/img/c894f4bcbac3c8d5f5095e244459296f-20240421231949-otljkop.jpg" alt="">​</p> <p>那么<strong>当生产者发送消息时, 每条消息就需要携带所属的 SchemaID 和 Version 标记</strong>. 此时:</p> <ul><li>当 Broker 收到数据, 会根据 SchemaID 和 Version 去找到对应的 Schema 详情, 进行<strong>数据校验</strong>.</li> <li>当消费端收到数据时, 会根据 SchemaID 和 Version 去找到对应的 Schema 详情, 进行<strong>数据解析处理</strong>.</li></ul> <p>所以, 在消息的协议结构中, 就需要<strong>增加 SchemaID 和 SchemaVersion 两个字段</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/df8209793caaa86f09c528163c83cdf0-20240421231949-qomplxo.jpg" alt=""></p> <p>下面来看一下 Broker 端是如何集成 Schema 的.</p> <h6 id="服务端集成schema"><a href="#服务端集成schema" class="header-anchor">#</a> 服务端集成Schema</h6> <p>先来回顾一下上面的那张架构图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/aedcda34522a5908c6603ca4cd150a3d-20240421231949-gp9hvzm.jpg" alt="">​</p> <p>从 Broker 的角度来看, 它对 Schema 的支持主要分为以下四个部分:</p> <ol><li>添加 Schema Register 相关配置, 比如 Schema Register 的地址.</li> <li>启动时从 Schema Register 加载本集群的 Schema 信息, 缓存在本地.</li> <li>判断是否开启 Schema, 或者在什么维度(比如集群维度, 租户维度, Topic 维度)开启 Schema.</li> <li>接收到数据时, 从消息中解析出 SchemaID, 根据 ID 找到对应的 Schema 对数据进行校验.</li></ol> <p>所以整体来看, Broker 端集成 Schema 的工作量并不大. 接下来再看看客户端是如何集成 Schema 的.</p> <h6 id="客户端集成schema"><a href="#客户端集成schema" class="header-anchor">#</a> 客户端集成Schema</h6> <p>先来看一段 Pulsar 生产端和消费端使用 Schema 特性的代码示例.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">SchemaDemo</span> <span class="token punctuation">{</span> <span class="token comment">// 定义一个 Schema</span>
   <span class="token keyword">public</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>
   <span class="token keyword">public</span> <span class="token keyword">int</span> age<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SchemaDemo</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> pulsarClient
       <span class="token punctuation">.</span><span class="token function">newProducer</span><span class="token punctuation">(</span><span class="token class-name">Schema</span><span class="token punctuation">.</span><span class="token function">JSON</span><span class="token punctuation">(</span><span class="token class-name">SchemaDemo</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// 生产使用 Schema</span>
       <span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token string">&quot;my-topic&quot;</span><span class="token punctuation">)</span>
       <span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Consumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SchemaDemo</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> pulsarClient
       <span class="token punctuation">.</span><span class="token function">newConsumer</span><span class="token punctuation">(</span><span class="token class-name">Schema</span><span class="token punctuation">.</span><span class="token function">JSON</span><span class="token punctuation">(</span><span class="token class-name">SchemaDemo</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// 消费使用 Schema</span>
       <span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token string">&quot;my-topic&quot;</span><span class="token punctuation">)</span>
       <span class="token punctuation">.</span><span class="token function">subscriptionName</span><span class="token punctuation">(</span><span class="token string">&quot;my-sub&quot;</span><span class="token punctuation">)</span>
       <span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 生产</span>
<span class="token class-name">SchemaDemo</span> schemaDemo <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SchemaDemo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
schemaDemo<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">&quot;puslar&quot;</span><span class="token punctuation">;</span>
schemaDemo<span class="token punctuation">.</span>age <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">;</span>
producer<span class="token punctuation">.</span><span class="token function">newMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span>schemaDemo<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 消费</span>
<span class="token class-name">Message</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SchemaDemo</span><span class="token punctuation">&gt;</span></span> message <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">receive</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token class-name">TimeUnit</span><span class="token punctuation">.</span><span class="token constant">SECONDS</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><p>上面的核心流程是, <strong>定义了一个数据结构 SchemaDemo, 然后在生产端使用这个数据结构发送数据, 在消费端使用这个数据结构来解析数据</strong>. 在生产端, 集成 Schema 后的主要流程如下:</p> <ol><li>生产端加上 Schema Register 相关配置.</li> <li>生产端启动时, 从 Schema Register 加载相关的 Schema 信息, 比如本次发送的集群, Topic 等.</li> <li>定义好要发送的数据格式, 并构建数据.</li> <li>在发送服务端之前, <strong>SDK 会根据客户端配置的 Schema 信息判断这个 Schema 是否存在</strong>. 如果存在就正常发送, 如果不存在则判断集群是否允许自动注册 Schema. 如果允许自动注册, 则调用 SchemaRegister 提供的 CreateSchema 接口进行注册. SchemaRegister 会为每个 Schema 分配唯一的 ID, 生产者会将这个 ID 写入到消息的属性中.</li></ol> <p>消费端集成 Schema 的流程和生产端基本类似, 具体如下:</p> <ol><li>消费端加上 Schema Register 相关配置.</li> <li>消费端启动时, 从 Schema Register 加载相关的 Schema 信息, 比如本次消费的集群, Topic 等.</li> <li>同时也会把消费端设置的 Schema 和 Topic 与实际的 Schema 进行比对, 然后判断是否使用还是自动注册这个 Schema, 流程和生产的第四步是一样的.</li> <li>拿到数据, 先判断是否携带 SchemaID, 然后判断是否是有效的 Schema, 再解析处理.</li></ol> <p>不过, 此时有个问题是, <strong>消息内容数据是以什么格式发送</strong>的呢?</p> <h6 id="序列化和反序列化"><a href="#序列化和反序列化" class="header-anchor">#</a> 序列化和反序列化</h6> <p>这个问题想问的是, 比如需要发送 name 和 region 两个信息, 那这个消息内容是以什么格式序列化和反序列化后发送呢? 这里一定要约定好使用的格式, 否则下游就不知道如何解析数据了.</p> <p>目前业界主要支持 Avro, JSON, Protobuf, Thrift 等多种数据格式. 即<strong>消息发送时, 数据是以 Avro, JSON, Protobuf 等格式来编码的</strong>.</p> <p>在消息队列中, 编解码一般是在生产端和消费端配置的, 比如 Kakfa 的配置如下:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 生产使用 avro 格式来编码</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
               <span class="token class-name">KafkaAvroSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 消费 avroJson 格式来编码</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span>
 <span class="token string">&quot;org.apache.kafka.common.serialization.ByteArraySerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>目前主流消息队列 Kafka, RocketMQ, Pulsar 在内核都支持了 Schema. 从技术的角度来看, RocketMQ, Kakfa, Pulsar 在 Schema 上的技术方案基本一致. 一方面是因为场景和需求都是一样的, 另一方面也是相互借鉴参考导致的.</p> <p>接下来就主要分析一下 RocketMQ Schema 的详细实现.</p> <h5 id="rocketmq-schema的实现"><a href="#rocketmq-schema的实现" class="header-anchor">#</a> RocketMQ Schema的实现</h5> <p>来看下面这张架构图:</p> <p>​<img src="/img/71decc3687708a2250e5e3b18b87140a-20240421231949-1rb8cyc.png" alt="">​</p> <p>如图所示, 可以看到 <strong>RocketMQ 在原先架构中引入了 Schema Registry 用于保存 Schema 信息</strong>, 也可以看到 Schema Registry 和 Broker 是分开部署的.</p> <p>Schema Registry 通过 SpingBoot 开发了 HTTP 服务, 提供了 Restful 接口支持创建, 更新, 删除, 绑定等操作. 当前支持使用内置的 Compact Topic 来存储 Schema 信息, 未来规划引入 MySQL 等 DB 型存储.</p> <p>RocketMQ 的 Schema 格式如下:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ebb7e335abe6f49a04a26f98b15ab8a8-20240421231949-urdbh41.jpg" alt=""></p> <p>来看一下 SchemaIDL 的内容示例, 可以看到, 它包含 <code>name</code>​ 和 <code>id</code>​ 两个字段, <code>name</code>​ 和 <code>id</code>​ 都是字符串类型, <code>id</code>​ 的默认值为0.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;record&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;SchemaName&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;namespace&quot;</span><span class="token operator">:</span> <span class="token string">&quot;rocketmq.schema.example&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;fields&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;string&quot;</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;string&quot;</span><span class="token punctuation">,</span>
            <span class="token property">&quot;default&quot;</span><span class="token operator">:</span> <span class="token string">&quot;0&quot;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>如果生产者和消费者每一次收发消息都要与 Registy 交互, name 就会非常影响性能和稳定性. <strong>因此 RocketMQ 在客户端缓存了 Schema 信息, 从而让 Schema 更新频率比较低</strong>.</p> <p>下面再来看一个 RocketMQ 客户端使用 Schema 的实例, 先来看一下底层的客户端和服务端是如何集成 Schema 的.</p> <p>先来看生产者示例:</p> <p>​<img src="/img/de6c59af66e8889f9f4770d83f6a512c-20240421231949-hwnyjg8.png" alt="">​</p> <p>可以看到, <strong>在生产者启动时, 配置了 SchemaRegister 的访问地址, 并配置了序列化方式为 Avro</strong>. 然后可以看到发送的数据是结构体 Payment, 而不是普通的字符串. 此时会解析 Schema 并检查其是否符合 Topic Schema 兼容性要求. 如果通过, 生产者将序列化数据, 并为其添加 SchemaID 等信息; 如果验证失败, 发送请求将被拒绝.</p> <p>在 Broker 端, <strong>Broker 通过 RocksDB 做了一层 Schema 的缓存</strong>, 避免频繁对 Schema Register 的访问. 当接收到数据后, 再从消息里面解析出 SchemaID, 对数据进行校验.</p> <p>再来看看消费者示例:</p> <p>​<img src="/img/246b4cce6b0e40dbd0369671ff370f83-20240421231949-18u699l.png" alt="">​</p> <p><strong>消费端创建时, 同样需要指定 Registry URL 和序列化类型, 然后通过 getMessage 方法直接获取泛型或实际对象</strong>. 此时如果消费到的数据类型不是需要的类型, 就会报错.</p> <h5 id="总结-33"><a href="#总结-33" class="header-anchor">#</a> 总结</h5> <p><strong>Schema 是数据结构定义的意思, 即定义数据是什么格式的. 消息队列中的 Schema 用来保证上下游数据在传递过程中, 消息根据指定的格式和定义进行传递, 从而解决上游的数据变更所导致的下游消费失败问题</strong>.</p> <p>消息队列 Schema 的核心是: <mark><strong>客户端按照指定的数据格式发送数据, Broker 按照配置的数据格式进行校验, 消费者根据指定的格式解析数据</strong></mark>.</p> <p>Schema Register, 即 Schema 注册中心, 它是 Schema 特性的核心模块. 它一般是一个独立的服务, 用来<strong>保存 Schema 信息, 并提供管理 Schema 的增删改查接口</strong>. 大部分情况下, 都会将 Schema 信息存储在消息队列中的 Topic, 以避免引入其他存储组件, 增加复杂度.</p> <p>因为 Schema Register 一般会给多个物理集群使用, 所以存储时需要明确 Schema 属于哪个集群, 哪个租户, 哪个 Topic. 因此 Schema 存储时会携带集群, 租户, Topic 等信息. 每个 Schema 会有一个唯一 ID 来标识, 因为一个 Schema 可能有多个版本, 所以一般也会有一个 Version 字段.</p> <p>Schema 最重要的是数据的 DDL 的定义, 即这个数据包含哪些字段, 字段的类型是什么样子的.</p> <p>Broker 和客户端在启动时都需要配置 Schema Register 的地址, 然后存储 Schema 信息. 生产端发送时会对发送的数据进行校验, Broker 也会对收到的数据进行校验, 消费者消费到数据时也会进行比对, 从而保证链路的数据是符合规范的.</p> <h4 id="_34-websocket-如何在消息队列内核中支持websocket"><a href="#_34-websocket-如何在消息队列内核中支持websocket" class="header-anchor">#</a> 34-WebSocket:如何在消息队列内核中支持WebSocket?</h4> <p>这节课来看一下如何在消息队列内核中支持 WebSocket. 如果你以前了解过 WebSocket, 就知道 WebSocket 是一个协议. 消息队列在自身私有协议的基础上, 还会支持像 HTTP 这样的公有协议.</p> <p>那为什么需要支持 WebSocket 协议呢? 又是如何支持的? 带着这两个问题开始今天的课程.</p> <h5 id="websocket是什么"><a href="#websocket是什么" class="header-anchor">#</a> WebSocket是什么</h5> <p>首先来了解一下 WebSocket 是什么.</p> <p>WebSocket 是一种基于 TCP 传输协议的应用层协议, 它设计的初衷是解决 Web 应用程序中的<strong>实时双向通信</strong>问题. 它跟 HTTP 协议一样, 也是一种标准的公有协议. 所以它也有协议头, 协议体, 数据帧格式, 建立连接, 维持连接, 数据交换等等各个细节. 只要记住一个重点: <strong>WebSocket 是一个可以在浏览器中使用的支持双向通信的应用层协议</strong>, 就可以了.</p> <p>接下来了解一下 WebSocket 的协议特点和主要的应用场景.</p> <blockquote><p>特点和应用场景</p></blockquote> <p>从某种角度讲, WebSocket 协议可以理解为 HTTP 协议的升级版本, 它主要有这样五个特点.</p> <ol><li><strong>持久化连接</strong>: WebSocket 建立了一个持久化的 TCP 和 TLS 连接, 从而减少了握手过程中的延迟并提高性能.</li> <li><strong>全双工通信</strong>: WebSocket 允许客户端和服务器在同一时刻发送和接收消息, 实现了全双工通信.</li> <li><strong>低带宽开销</strong>: WebSocket 在数据分帧处理方面采用了紧凑的二进制格式, 并对附加元数据进行了优化, 以实现低带宽开销.</li> <li><strong>与</strong> <strong>HTTP</strong> <strong>兼容</strong>: WebSocket 协议兼容 HTTP 协议, 使用与 HTTP 相同的默认端口(80 和 443), 能够通过现有的网络基础设施进行传输, 并得到大多数现代浏览器的支持.</li> <li><strong>跨域通信</strong>: WebSocket 协议允许跨域通信(在配置允许的情况下), 使得客户端可以与不同域名上的服务器建立连接.</li></ol> <p>因为协议具备这些特点, 在需要<strong>高度实时性和低延迟的场景中, WebSocket 是一种理想的解决方案</strong>. 所以 WebSocket 在 Web 即时通讯, 在线游戏, 实时股票和金融信息流, 物联网通信和在线协作工具等场景中会被大量使用.</p> <p>接下来了解一下 WebSocket 协议和消息队列的关系, 来回答一下 &quot;<strong>为什么消息队列需要支持 WebSocket 协议</strong>&quot;.</p> <h5 id="websocket协议和消息队列"><a href="#websocket协议和消息队列" class="header-anchor">#</a> WebSocket协议和消息队列</h5> <p>从应用场景来看, <strong>消息队列需要的是 WebSocket 协议支持的双工通信的特性</strong>.</p> <p>前面讲消费模型的时候讲过, Push 模型可以实现当服务端有数据时主动将数据推送给消费者, 从而降低消费延时. 而客户端要接收数据, 一般要启动端口.</p> <p>从技术上看, 消费者其实就是一个 Server, 而在客户端维护这个 Server 是有成本的.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4a898532502ff7a2605be9680f920799-20240421231949-9fzxecz.jpg" alt=""></p> <p>如果引入 WebSocket 协议, 消费者通过 WebSocket 协议和 Broker 建立连接. 因为 WebSocket 协议是双向通信的, 所以 <strong>Broker 就可以直接将数据推送给消费者, 而不需要在客户端实现一个 Server</strong>. 因此开发工作量就降低特别多.</p> <p>​<img src="/img/d32b659c52e23b7772eb4f6be5be8d3a-20240421231949-44lk99z.jpg" alt="">​</p> <p>所以说, <strong>长连接和双向通信是 WebSocket 实现高度实时性和低延迟的技术核心</strong>, 也是消息队列需要支持 WebSocket 协议的重要原因.</p> <p>接下来用 WebSocket 和 <strong>MQTT Broker</strong> 结合的一个案例, 让你更直观感受一下它们组合起来使用的优势.</p> <p>​<img src="/img/6cf2082d6cc3406368a1266dfde49060-20240421231949-hxpnyca.jpg" alt="">​</p> <p>参考图示, 这里想要展现的的场景是: 物联网传感器(例如气体传感器)收集数据后, 将数据通过 MQTT 协议发送到 MQTT Broker. 收到数据的同时, Broker 可以通过 WebSocket 将数据推送到浏览器或客户端, 从而及时更新监控面板或者触发告警.</p> <p><strong>因为 MQTT 和 WebSocket 都是双向通信的, 也可以在浏览器中通过 WebSocket 协议将消息发送到 MQTT Broker, 然后 MQTT Broker 再将消息发送给 IoT 终端</strong>.</p> <p>在上面的场景中, 核心就是双向通信提升了消息传递的及时性. 当把 MQTT Broker 换作其他的消息队列, 就可以应用在类似的场景中.</p> <p>支持多协议一般有内核支持和 Proxy 模式两种形态. 因为实现方式基本差不多, 下面就重点看一下<strong>如何在消息队列的内核中支持 WebSocket 协议</strong>.</p> <h5 id="内核中支持websocket协议"><a href="#内核中支持websocket协议" class="header-anchor">#</a> 内核中支持WebSocket协议</h5> <p>从技术拆解来看, 在内核中支持 WebSocket 协议, 主要分为以下四部分工作:</p> <ol><li><strong>确定在 WebSocket 上支持哪些功能</strong>, 比如生产, 消费.</li> <li>设计生产, 消费等功能的请求和返回协议.</li> <li>在内核中支持 WebSocket Server.</li> <li>Broker 通过 WebSocket 协议推送数据.</li></ol> <h6 id="支持功能"><a href="#支持功能" class="header-anchor">#</a> 支持功能</h6> <p>从实际业务场景来看, <strong>WebSocket 主要用在消息队列的数据流上</strong>. 因为消息队列数据流的操作主要是生产和消费, 所以在 WebSocket 协议上主要也是支持生产, 消费等操作.</p> <p>接下来看一下 WebSocket 协议的生产和消费如何设计.</p> <h6 id="生产消费协议设计"><a href="#生产消费协议设计" class="header-anchor">#</a> 生产消费协议设计</h6> <p>从技术上看, WebSocket 兼容 HTTP. 可以简单理解成, <strong>WebSocket 是基于 HTTP 的</strong>. 所以从使用的角度, 如下所示, WebSocket 协议包含 URI 和 Body 两个部分.</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>URI: wss://javascript.info/article/websocket/demo/hello

Body: { &quot;payload&quot;: &quot;SGVsbG8gV29ybGQ=&quot; }
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>URI 表示 WebSocket Server 的地址, Body 是请求内容, 可以发现跟 HTTP 协议很像. 所以, 生产, 消费协议跟设计普通的 HTTP API 区别不大, 就是定义 URI, 定义访问参数和返回参数. 请求 Body 一般也是使用 JSON 格式来传递.</p> <p>接下来看一下生产请求的协议设计, 示例如下:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>URI<span class="token operator">:</span>
    wss<span class="token operator">:</span><span class="token comment">//mqserver.com/send/ns1/tp1</span>
body<span class="token operator">:</span> 
<span class="token punctuation">{</span>
  <span class="token property">&quot;key&quot;</span><span class="token operator">:</span> <span class="token string">&quot;k1&quot;</span><span class="token punctuation">,</span> 
  <span class="token property">&quot;value&quot;</span><span class="token operator">:</span> <span class="token string">&quot;v1&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;properties&quot;</span><span class="token operator">:</span><span class="token string">&quot;{&quot;</span>p1<span class="token string">&quot;:1,&quot;</span>p2<span class="token string">&quot;:2}&quot;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>在上面的示例中, /send/ns1/tp1 表示发送数据到租户 ns1 中的 Topic tp1, body 是 JSON 格式的数据, 包含 key, value, properties 三个字段, 分别表示消息的 key, 消息的 value, 消息的属性.</p> <p>接下来看一下返回值, 示例如下:</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token comment">// 请求成功</span>
<span class="token punctuation">{</span>
   <span class="token property">&quot;result&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ok&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;messageID&quot;</span><span class="token operator">:</span> <span class="token string">&quot;CAAQAw==&quot;</span>
<span class="token punctuation">}</span>
<span class="token comment">// 请求失败</span>
<span class="token punctuation">{</span>
   <span class="token property">&quot;result&quot;</span><span class="token operator">:</span> <span class="token string">&quot;send-error:3&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;errorMsg&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Failed to de-serialize from JSON&quot;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>这个返回值就是一个普通的 JSON 格式的返回值. result 表示请求结果, messageID 表示这条消息的 ID, errorMsg 表示错误信息.</p> <p>协议设计整体看下来, 其实就是普通的 HTTP API 的设计, 没有太多的新东西. 其他的比如消费, 位点提交等接口, 设计思路是类似的, 就不展开了.</p> <p>设计好了协议, 来看一下如何<strong>在内核中支持 WebSocket Server</strong>.</p> <h6 id="支持websocket-server"><a href="#支持websocket-server" class="header-anchor">#</a> 支持WebSocket Server</h6> <p>从技术上来看, 在内核中支持 WebSocket Server 并不复杂, 因为各个语言都有对应的库来实现. 下面<strong>通过 Netty 来实现一个 WebSocket Server</strong>, 举例说明一下如何在 Broker 内支持 WebSocket, 代码示例如下:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token class-name">StartWebServer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    <span class="token class-name">EventLoopGroup</span> bossGroup <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">NioEventLoopGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">EventLoopGroup</span> workerGroup <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">NioEventLoopGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token class-name">ServerBootstrap</span> b <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ServerBootstrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        b<span class="token punctuation">.</span><span class="token function">group</span><span class="token punctuation">(</span>bossGroup<span class="token punctuation">,</span> workerGroup<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">channel</span><span class="token punctuation">(</span><span class="token class-name">NioServerSocketChannel</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">childHandler</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ChannelInitializer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SocketChannel</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initChannel</span><span class="token punctuation">(</span><span class="token class-name">SocketChannel</span> ch<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                        <span class="token class-name">ChannelPipeline</span> pipeline <span class="token operator">=</span> ch<span class="token punctuation">.</span><span class="token function">pipeline</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        pipeline<span class="token punctuation">.</span><span class="token function">addLast</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HttpServerCodec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// HTTP 协议解析, 用于握手阶段</span>
                        pipeline<span class="token punctuation">.</span><span class="token function">addLast</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HttpObjectAggregator</span><span class="token punctuation">(</span><span class="token number">65536</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// HTTP 协议解析, 用于握手阶段</span>
                        pipeline<span class="token punctuation">.</span><span class="token function">addLast</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">WebSocketServerCompressionHandler</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// WebSocket 数据压缩扩展</span>
                    <span class="token punctuation">}</span>
                <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">ChannelFuture</span> f <span class="token operator">=</span> b<span class="token punctuation">.</span><span class="token function">bind</span><span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        f<span class="token punctuation">.</span><span class="token function">channel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">closeFuture</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
        workerGroup<span class="token punctuation">.</span><span class="token function">shutdownGracefully</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        bossGroup<span class="token punctuation">.</span><span class="token function">shutdownGracefully</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">class</span> <span class="token class-name">MyWebSocketServerHandler</span> <span class="token keyword">extends</span> <span class="token class-name">SimpleChannelInboundHandler</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">WebSocketFrame</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">channelRead0</span><span class="token punctuation">(</span><span class="token class-name">ChannelHandlerContext</span> ctx<span class="token punctuation">,</span> <span class="token class-name">WebSocketFrame</span> frame<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>frame <span class="token keyword">instanceof</span> <span class="token class-name">TextWebSocketFrame</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">String</span> request <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TextWebSocketFrame</span><span class="token punctuation">)</span> frame<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            ctx<span class="token punctuation">.</span><span class="token function">channel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeAndFlush</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TextWebSocketFrame</span><span class="token punctuation">(</span><span class="token string">&quot;receive: &quot;</span> <span class="token operator">+</span> request<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><p>在上面的代码中, 主要需要关注的是 pipeline.addLast 和 writeAndFlush 两部分代码. addLast 主要用来做协议相关的解析, <strong>writeAndFlush 是给客户端返回数据的, 它是双工通信的重要环节</strong>. 只要往 Channel 回写数据, 此时客户端就可以收到数据, 从而实现主动推送消息给客户端.</p> <p>因为数据推送给客户端是 WebSocket 的一个重要功能, 所以接下来讲一下 <strong>Broker 如何基于 WebSocket 协议实现主动消息推送</strong>.</p> <h6 id="主动消息推送"><a href="#主动消息推送" class="header-anchor">#</a> 主动消息推送</h6> <p>先来看一下下面这张图, 这是一个消息主动推送的场景.</p> <p>​<img src="/img/c3e433aa7b67f96059f49f6b1724759b-20240421231949-lspmodw.jpg" alt="">​</p> <p>参考图示, 当数据写入到 Broker 中的 Topic tp1 时, 因为 WebSocket 是双向通信的, 所以 Broker 收到消息后, 可以<strong>直接将消息推送给客户端</strong>. 这个推送的逻辑一般是在<strong>内核中维护异步线程去回写数据到客户端</strong>实现的. 可以回顾一下 Push 模型的实现, 结合起来看, 理解会更深入一点.</p> <p>目前业界<strong>主流消息队列只有 Pulsar 和 RabbitMQ 支持了 WebSocket 协议</strong>. 从技术上看, 两者的实现思路基本一致. 所以接下来就挑 Puslar 来分析一下它是如何支持 WebSocket 协议的.</p> <h5 id="pulsar如何支持websocket协议"><a href="#pulsar如何支持websocket协议" class="header-anchor">#</a> Pulsar如何支持WebSocket协议</h5> <p>如下图所示, Pulsar 内核支持两种 WebSocket 部署形式. 一种是在内核中启动, 一种是作为单独组件部署. 从代码实现来看, 两者的区别不大, 对于 WebSocket Server 的支持是同一份代码, 只是启动的地方不一样而已.</p> <p>​<img src="/img/65de0ac91d2f074628efa0044dcbc8f9-20240421231949-as0h3ez.jpg" alt="">​</p> <p>从代码实现上看, Pulsar 是基于 Jetty 的 WebSocket 包来实现 WebSocket Server 的, 属于很标准的用法. 有兴趣的同学可以参考 <a href="https://github.com/apache/pulsar/tree/master/pulsar-websocket" target="_blank" rel="noopener noreferrer">GitHub 的仓库源码<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>Pulsar 支持生产, 消费, 读取消费位点 3 个功能. 下面简单看一下生产操作的请求 URI, Body, 返回值.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token comment">// 请求 URI</span>
ws<span class="token operator">:</span><span class="token comment">//broker-service-url:8080/ws/v2/producer/persistent/:tenant/:namespace/:topic</span>

<span class="token comment">// 请求体 Body</span>
<span class="token punctuation">{</span>
  <span class="token property">&quot;payload&quot;</span><span class="token operator">:</span> <span class="token string">&quot;SGVsbG8gV29ybGQ=&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;properties&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">&quot;key1&quot;</span><span class="token operator">:</span> <span class="token string">&quot;value1&quot;</span><span class="token punctuation">,</span> <span class="token property">&quot;key2&quot;</span><span class="token operator">:</span> <span class="token string">&quot;value2&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment">// 处理成功的返回值: </span>
<span class="token punctuation">{</span>
   <span class="token property">&quot;result&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ok&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;messageID&quot;</span><span class="token operator">:</span> <span class="token string">&quot;CAAQAw==&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;context&quot;</span><span class="token operator">:</span> <span class="token string">&quot;1&quot;</span>
<span class="token punctuation">}</span>
<span class="token comment">// 处理失败的返回值</span>
<span class="token punctuation">{</span>
   <span class="token property">&quot;result&quot;</span><span class="token operator">:</span> <span class="token string">&quot;send-error:3&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;errorMsg&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Failed to de-serialize from JSON&quot;</span><span class="token punctuation">,</span>
   <span class="token property">&quot;context&quot;</span><span class="token operator">:</span> <span class="token string">&quot;1&quot;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>可以看到在 URI 的定义上, Pulsar 定义了 请求的版本, 生产接口, 租户, 命名空间, Topic 等信息, 用来标识数据发给谁. 请求体里面的 payload, properties 分别表示消息内容和消息属性.</p> <p>返回值里面则包含了 result, messageID, errorMsg, context 等信息, 分别表示请求返回结果, 消息 ID, 错误信息和上下文信息.</p> <p>最后来看一下 Python 客户端的代码示例.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> websocket<span class="token punctuation">,</span> base64<span class="token punctuation">,</span> json

<span class="token comment"># If set enableTLS to true, your have to set tlsEnabled to true in conf/websocket.conf.</span>
enable_TLS <span class="token operator">=</span> <span class="token boolean">False</span>
scheme <span class="token operator">=</span> <span class="token string">'ws'</span>
<span class="token keyword">if</span> enable_TLS<span class="token punctuation">:</span>
    scheme <span class="token operator">=</span> <span class="token string">'wss'</span>

TOPIC <span class="token operator">=</span> scheme <span class="token operator">+</span> <span class="token string">'://localhost:8080/ws/v2/producer/persistent/public/default/my-topic'</span>

ws <span class="token operator">=</span> websocket<span class="token punctuation">.</span>create_connection<span class="token punctuation">(</span>TOPIC<span class="token punctuation">)</span>

<span class="token comment"># encode message</span>
s <span class="token operator">=</span> <span class="token string">&quot;Hello World&quot;</span>
firstEncoded <span class="token operator">=</span> s<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">&quot;UTF-8&quot;</span><span class="token punctuation">)</span>
binaryEncoded <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>firstEncoded<span class="token punctuation">)</span>
payloadString <span class="token operator">=</span> binaryEncoded<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'UTF-8'</span><span class="token punctuation">)</span>

<span class="token comment"># Send one message as JSON</span>
ws<span class="token punctuation">.</span>send<span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">'payload'</span> <span class="token punctuation">:</span> payloadString<span class="token punctuation">,</span>
    <span class="token string">'properties'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">'key1'</span> <span class="token punctuation">:</span> <span class="token string">'value1'</span><span class="token punctuation">,</span>
        <span class="token string">'key2'</span> <span class="token punctuation">:</span> <span class="token string">'value2'</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'context'</span> <span class="token punctuation">:</span> <span class="token number">5</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

response <span class="token operator">=</span>  json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>ws<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> response<span class="token punctuation">[</span><span class="token string">'result'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'ok'</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span> <span class="token string">'Message published successfully'</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Failed to publish message:'</span><span class="token punctuation">,</span> response<span class="token punctuation">)</span>
ws<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br></div></div><p>客户端的代码逻辑很清晰, 分为构建 URI, 初始化连接, 组装参数, 发送生产请求, 处理返回, 关闭连接六个流程.</p> <p>因此, 可以看出 Pulsar 对 WebSocket 的支持也不复杂, 主要是<strong>协议的兼容和适配</strong>.</p> <h5 id="总结-34"><a href="#总结-34" class="header-anchor">#</a> 总结</h5> <p>WebSocket 是一种实时协议, 它在单个 TCP 连接上提供持久的全双工通信, 即双向通信. 双向通信非常适合需要实时更新的系统, 简单说就是允许服务端主动推送数据给客户端的场景. 比如金融行情, 实时多人游戏, 聊天应用程序和实时地理位置更新等等.</p> <p>消息队列支持 WebSocket 协议的核心诉求就是 WebSocket 的双向通信的特性. 因为基于这个特性, Broker 可以很方便地将数据推送给各个客户端, 从而提高数据传递的及时性.</p> <p>消息队列支持 WebSocket 协议主要有内核支持和 Proxy 模式两种形态. 从实现机制上看, 这两种方案差别不大. 主要就是确定需要支持的功能点, 各个功能点的协议设计, 内核支持 WebSocket Server, 实现主动推送逻辑四个部分.</p> <p>从业界来看, 支持 WebSocket 协议的消息队列并不多. 虽然 WebSocket 结合消息队列有一定的使用场景, 但是用户也可以自定义实现一个 WebSocket Server, 然后消费消息队列的数据, 再将数据推送到客户端, 实现类似的功能, 并且整体开发成本并不高. 所以严格来讲, WebSocket 协议不是消息队列的核心功能, 但因为有场景需求, 所以我们还是花了一节课的时间来梳理它, 希望能完善你的知识体系.</p> <h4 id="_35-从高级功能拆解4款主流mq的架构设计与实现"><a href="#_35-从高级功能拆解4款主流mq的架构设计与实现" class="header-anchor">#</a> 35-从高级功能拆解4款主流MQ的架构设计与实现</h4> <p>到了本节就讲完了功能篇的所有知识点了. 下面根据本阶段的课程内容, 整理了一下 4 款主流消息队列所支持的功能清单.</p> <p>​<img src="/img/b8e4438217c6d8cf3c62f4bb6017655c-20240421231949-xo51a35.jpg" alt="">​</p> <p>在上面的表格中, 会发现一个现象, Pulsar 支持的功能最多, RabbitMQ 和 RocketMQ 其次, Kafka 支持的功能最少. 原因前面说过, 和它们自身的定位和发展历史有关.</p> <p>接下来从功能出发, 来分析一下这 4 款主流消息队列的原理和使用方式. 先来个说明, 这节课中的每个部分都是独立的, 可以挑感兴趣的内容进行学习.</p> <h5 id="rabbitmq"><a href="#rabbitmq" class="header-anchor">#</a> RabbitMQ</h5> <p>RabbitMQ 支持顺序消息, 定时和延时消息, 事务消息, 优先级队列, 死信队列, WebSocket 等功能, 但是不支持消息查询, 幂等消息和 Schema.</p> <h6 id="顺序消息"><a href="#顺序消息" class="header-anchor">#</a> 顺序消息</h6> <p>如下图所示, RabbitMQ 顺序消息的核心是底层 Queue 维度的顺序存储模型. 图中将 RouteKey=A 绑定给 Queue1, 把 RouteKey=B 绑定给 Queue2. <strong>发送数据时只要给需要顺序的消息设置相同的 RouteKey, 就能保证这些消息是有序的</strong>.</p> <p>​<img src="/img/46a346e837b4a937b834545f2e9b5a0e-20240421231949-oz8kmd8.jpg" alt="">​</p> <p>需要注意的是, 这个路由关系是在定义 Exchange 时绑定的, 代码示例如下:</p> <div class="language-Java line-numbers-mode"><pre class="language-java"><code># 创建 queue
channel<span class="token punctuation">.</span><span class="token function">queue_declare</span><span class="token punctuation">(</span>queue<span class="token operator">=</span>'route_queue1'<span class="token punctuation">,</span>
                      exclusive<span class="token operator">=</span><span class="token class-name">True</span><span class="token punctuation">,</span> durable<span class="token operator">=</span><span class="token class-name">True</span><span class="token punctuation">)</span>

# 绑定 queue 到交换机<span class="token punctuation">,</span> 并指定 routing key
channel<span class="token punctuation">.</span><span class="token function">queue_bind</span><span class="token punctuation">(</span>exchange<span class="token operator">=</span>'direct_exchange'<span class="token punctuation">,</span>
                  queue<span class="token operator">=</span><span class="token string">&quot;route_queue1&quot;</span><span class="token punctuation">,</span> routing_key<span class="token operator">=</span>routingKey<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>绑定完成 Exchange 和 Queue 的关系后, 就可以将消息投递到 Queue 中. 下面的示例表示, RouteKey 为 A 的数据都会保存到名为 route_queue1 的 Queue 中.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code>channel<span class="token punctuation">.</span><span class="token function">basic_publish</span><span class="token punctuation">(</span>exchange<span class="token operator">=</span>'direct_exchange'<span class="token punctuation">,</span>
                      routing_key<span class="token operator">=</span><span class="token char">'A'</span><span class="token punctuation">,</span>
                      body<span class="token operator">=</span><span class="token punctuation">(</span>'hello world'<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">encode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                     properties<span class="token operator">=</span><span class="token class-name"><span class="token namespace">pika<span class="token punctuation">.</span></span>BasicProperties</span><span class="token punctuation">(</span>delivery_mode<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h6 id="定时和延时消息"><a href="#定时和延时消息" class="header-anchor">#</a> 定时和延时消息</h6> <p>RabbitMQ 的定时和延时消息, 有基于死信队列和集成延迟插件两种方案, 这部分前面已经详细讲了, 就不展开了.</p> <h6 id="事务消息"><a href="#事务消息" class="header-anchor">#</a> 事务消息</h6> <p><strong>RabbitMQ 的事务是指生产的事务</strong>, 是在 Channel 维度生效的. 底层是两阶段事务的实现, 包含开启事务, 提交事务, 回滚事务三个阶段.</p> <p>在 Channel 维度开启事务后, 在这条 Channel 中生产的消息不会立即被投递到目标 Exchange, 而是会先在一个临时的 Exchange 中保存数据. 当提交事务后, 再把数据投递到实际的 Exchagne 中. 如果事务回滚, 则将临时数据丢弃.</p> <p>下面是 RabbitMQ 使用事务的示例, 代码中最重要的就是开启事务(txSelect), 提交事务(txCommit), 回滚事务(txRollback)三个函数的使用.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">Connection</span> connection<span class="token operator">=</span><span class="token keyword">null</span><span class="token punctuation">;</span>
<span class="token class-name">Channel</span> channel<span class="token operator">=</span><span class="token keyword">null</span><span class="token punctuation">;</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
   connection <span class="token operator">=</span> factory<span class="token punctuation">.</span><span class="token function">newConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//连接工厂创建连接</span>
   channel <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">createChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//创建信道</span>
   channel<span class="token punctuation">.</span><span class="token function">txSelect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//开启事务</span>
   channel<span class="token punctuation">.</span><span class="token function">queueDeclare</span><span class="token punctuation">(</span><span class="token constant">QUEUE_NAME</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
            <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//绑定队列</span>
   channel<span class="token punctuation">.</span><span class="token function">basicPublish</span><span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> <span class="token constant">QUEUE_NAME</span><span class="token punctuation">,</span>
            <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token string">&quot;Hello World!&quot;</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token class-name">StandardCharsets</span><span class="token punctuation">.</span><span class="token constant">UTF_8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   channel<span class="token punctuation">.</span><span class="token function">txCommit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">//提交事务</span>
   <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot; [x] Sent '&quot;</span> <span class="token operator">+</span> message <span class="token operator">+</span> <span class="token string">&quot;'&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   channel<span class="token punctuation">.</span><span class="token function">txRollback</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//回滚事务</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><h6 id="优先级队列"><a href="#优先级队列" class="header-anchor">#</a> 优先级队列</h6> <p>RabbitMQ 的优先级队列的效果是保证优先级高的消息能有先被消费者消费到. 它的底层是通过优先级堆(Priority Heap)的数据结构进行消息优先级的排序, 然后在消费的时候优先返回给客户优先级高的消息.</p> <p>下面是使用优先级的代码示例, 核心点是创建优先级队列时指定最大优先级, 然后发送消息时给每个消息设置优先级. 每个消息的优先级不能超过队列的最大优先级. 在消费的时候, 优先级高的消息会被优先消费.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 创建了名为 priority_queue 的优先级队列, 其最大优先级为 10. </span>
channel<span class="token punctuation">.</span><span class="token function">queue_declare</span><span class="token punctuation">(</span>queue<span class="token operator">=</span>'priority_queue'<span class="token punctuation">,</span> arguments<span class="token operator">=</span><span class="token punctuation">{</span>'x<span class="token operator">-</span>max<span class="token operator">-</span>priority'<span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment">// 向优先级队列 priority_queue 发送了一个带有优先级为 5 的消息</span>
channel<span class="token punctuation">.</span><span class="token function">basic_publish</span><span class="token punctuation">(</span>exchange<span class="token operator">=</span>''<span class="token punctuation">,</span> routing_key<span class="token operator">=</span>'priority_queue'<span class="token punctuation">,</span> body<span class="token operator">=</span>'<span class="token class-name">Hello</span> <span class="token class-name">World</span><span class="token operator">!</span>'<span class="token punctuation">,</span> properties<span class="token operator">=</span><span class="token class-name"><span class="token namespace">pika<span class="token punctuation">.</span></span>BasicProperties</span><span class="token punctuation">(</span>priority<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h6 id="死信队列"><a href="#死信队列" class="header-anchor">#</a> 死信队列</h6> <p>RabbitMQ 支持死信队列的功能. 它的作用是, <strong>如果遇到 客户端发送消息被拒绝, 消息过期没被消费, 队列达到最大长度 三种场景, 消息会被投递到死信队列中</strong>.</p> <p>和其他常见的实现方案不同的是, <strong>RabbitMQ 的死信队列是在 Broker 中闭环完成的, 客户端不需要感知到死信队列的逻辑</strong>.</p> <p>从使用上看, RabbitMQ 的死信队列的使用分为三步.</p> <ol><li>创建死信交换机, 定义一个名为 dlx_direct 的 Exchange.</li></ol> <div class="language-java line-numbers-mode"><pre class="language-java"><code>channel<span class="token punctuation">.</span><span class="token function">exchange_declare</span><span class="token punctuation">(</span>
    exchange<span class="token operator">=</span>'dlx_direct'<span class="token punctuation">,</span> exchange_type<span class="token operator">=</span><span class="token class-name">ExchangeType</span><span class="token punctuation">.</span>direct<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ol start="2"><li>创建死信队列, 并绑定到死信交换机. 创建一个名为 dead_queue 的 Queue, 并将这个 Queue 绑定到名为 dlx_direct 的 Exchange 中.</li></ol> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 定义死信交换机</span>
channel<span class="token punctuation">.</span><span class="token function">queue_declare</span><span class="token punctuation">(</span>queue<span class="token operator">=</span>'dead_queue'<span class="token punctuation">)</span>
<span class="token comment">// 死信队列绑定到第一步创建的死信</span>
channel<span class="token punctuation">.</span><span class="token function">queue_bind</span><span class="token punctuation">(</span>
    queue<span class="token operator">=</span>'dead_queue'<span class="token punctuation">,</span> exchange<span class="token operator">=</span>'dlx_direct'<span class="token punctuation">,</span> routing_key<span class="token operator">=</span>'dead_queue'<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><ol start="3"><li>创建正常队列时, 设置死信属性. 创建一个名为 dxl_queue 的正常队列, 并给它设置死信队列的属性, 设置死信队列为 dlx_direct, 路由 Key 为 dead_queue.</li></ol> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>channel.queue_declare(
    queue=&quot;dlx_queue&quot;,
    arguments={
        'x-dead-letter-exchange': 'dlx_direct',
        'x-dead-letter-routing-key': 'dead_queue'
    })

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>当完成这三步后, 在生产端就生产消费消息即可, <strong>当遇到上面说的三种场景, 数据就会自动变为死信消息, 从而进入死信队列</strong>.</p> <p>如果要消费到死信队列中的消息, 则直接按照普通的消费逻辑去消费死信队列对应的 Queue 里面的消息即可.</p> <h6 id="websocket"><a href="#websocket" class="header-anchor">#</a> WebSocket</h6> <p>前面讲到, WebSocket 协议的支持分为协议的设计, 内核 WebSocket Server 的支持 两部分. RabbitMQ 支持 WebSocket, 在协议设计层面是以 STOMP over WebSockets 和 MQTT over WebSockets 的形式实现的. 即没有单独设计协议, 而是直接使用 STOMP 和 MQTT 协议以 WebSocket 的形式通信.</p> <p>从使用上需要先启用对应的插件, 开启 STOMP over WebSockets 和 MQTT over WebSockets 的插件. 具体如下所示:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 启用基于 Stomp 协议的 websocket 插件: </span>
rabbitmq<span class="token operator">-</span>plugins enable rabbitmq_web_stomp

<span class="token comment">// 启用基于 MQTT 协议的 websocket 插件</span>
rabbitmq<span class="token operator">-</span>plugins enable rabbitmq_web_mqtt
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>启用插件后, 直接使用对应的协议编解码, 然后通过 WebSocket 协议和 RabbitMQ Broker 交互即可. 代码示例如下:</p> <div class="language-js line-numbers-mode"><pre class="language-js"><code><span class="token keyword">var</span> ws <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">WebSocket</span><span class="token punctuation">(</span><span class="token string">'ws://127.0.0.1:15674/ws'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">var</span> client <span class="token operator">=</span> Stomp<span class="token punctuation">.</span><span class="token function">over</span><span class="token punctuation">(</span>ws<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>上面的示例, 客户端通过 URL ws://127.0.0.1:15674/ws 和 Broker 建立通信, 然后通过 STOMP 协议进行通信. 如果需要了解更多细节, 可以参考官方文档 <a href="https://www.rabbitmq.com/web-stomp.html" target="_blank" rel="noopener noreferrer">STOMP over WebSockets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://www.rabbitmq.com/web-mqtt.html" target="_blank" rel="noopener noreferrer">MQTT over WebSockets<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h5 id="rocketmq"><a href="#rocketmq" class="header-anchor">#</a> RocketMQ</h5> <p>RabbitMQ 支持顺序消息, 定时和延时消息, 事务消息, 死信队列, 消息查询, Schema 等功能, 不支持幂等, 优先级队列, WebSocket 功能.</p> <h6 id="顺序消息-2"><a href="#顺序消息-2" class="header-anchor">#</a> 顺序消息</h6> <p><strong>RocketMQ 的顺序消息是一个独立的功能, 它是通过消息组(MessageGroup)来实现顺序消息的功能</strong>. 发送顺序消息时, 需要为每条消息设置归属的消息组, 相同消息组的多条消息能保证顺序.</p> <p>如下图所示, 携带 MessageGroup1, MessageGroup2, MessageGroup3, MessageGroup4的消息, 会被哈希发送到不同的 Queue, 同一个消息组的消息会被发送到同一个 Queue.</p> <p>​<img src="/img/0997cb87cb30de8ff2a8b197df51d9cc-20240421231949-0706a9z.png" alt="">​</p> <p>下面是一个<strong>发送顺序消息</strong>的代码示例, 代码的核心是 setMessageGroup 函数, 给这条消息设置一个消息组 fifoGroup001, 同一个消息组的消息会发送到同一个 Queue.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 顺序消息发送. </span>
<span class="token class-name">MessageBuilder</span> messageBuilder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MessageBuilderImpl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token class-name">Message</span> message <span class="token operator">=</span> messageBuilder<span class="token punctuation">.</span><span class="token function">setTopic</span><span class="token punctuation">(</span><span class="token string">&quot;topic&quot;</span><span class="token punctuation">)</span>
                <span class="token comment">// 设置消息索引键, 可根据关键字精确查找某条消息. </span>
                <span class="token punctuation">.</span><span class="token function">setKeys</span><span class="token punctuation">(</span><span class="token string">&quot;messageKey&quot;</span><span class="token punctuation">)</span>
                <span class="token comment">// 设置消息 Tag, 用于消费端根据指定 Tag 过滤消息. </span>
                <span class="token punctuation">.</span><span class="token function">setTag</span><span class="token punctuation">(</span><span class="token string">&quot;messageTag&quot;</span><span class="token punctuation">)</span>
                <span class="token comment">// 设置顺序消息的排序分组, 该分组尽量保持离散, 避免热点排序分组. </span>
                <span class="token punctuation">.</span><span class="token function">setMessageGroup</span><span class="token punctuation">(</span><span class="token string">&quot;fifoGroup001&quot;</span><span class="token punctuation">)</span>
                <span class="token comment">// 消息体. </span>
                <span class="token punctuation">.</span><span class="token function">setBody</span><span class="token punctuation">(</span><span class="token string">&quot;messageBody&quot;</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
     <span class="token comment">// 发送消息, 需要关注发送结果, 并捕获失败等异常</span>
     <span class="token class-name">SendReceipt</span> sendReceipt <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>sendReceipt<span class="token punctuation">.</span><span class="token function">getMessageId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><h6 id="定时和延时消息-2"><a href="#定时和延时消息-2" class="header-anchor">#</a> 定时和延时消息</h6> <p>前面讲了 RocketMQ 定时和延时消息的底层原理, 这里补充几点使用注意事项.</p> <ol><li>定时时间指的是消息到期的时间, 延时时间需要转换成消息的到期时间, 即当前系统时间后的某一个时间戳, 而不是一段延时时长.</li> <li>定时时间的格式是毫秒级的 Unix 时间戳, 即需要将要设置的时刻转换成时间戳形式.</li> <li>定时时长最大值默认为 24 小时, 不支持自定义修改.</li> <li>定时时间必须设置在定时时长范围内, 超过范围则定时不生效, 服务端会立即投递消息.</li></ol> <p>下面来看一个定时消息的示例, 代码中最需要注意的是 <strong>setDeliveryTimestamp</strong>, 它设置了这条消息在 10 分钟后可以被消费者消费到.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 定时/延时消息发送</span>
<span class="token class-name">MessageBuilder</span> messageBuilder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MessageBuilderImpl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token comment">// 以下示例表示: 延迟时间为10分钟之后的 Unix 时间戳. </span>
<span class="token class-name">Long</span> deliverTimeStamp <span class="token operator">=</span> <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">10L</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">;</span>
<span class="token class-name">Message</span> message <span class="token operator">=</span> messageBuilder<span class="token punctuation">.</span><span class="token function">setTopic</span><span class="token punctuation">(</span><span class="token string">&quot;topic&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">// 设置消息索引键, 可根据关键字精确查找某条消息. </span>
      <span class="token punctuation">.</span><span class="token function">setKeys</span><span class="token punctuation">(</span><span class="token string">&quot;messageKey&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">// 设置消息 Tag, 用于消费端根据指定 Tag 过滤消息. </span>
      <span class="token punctuation">.</span><span class="token function">setTag</span><span class="token punctuation">(</span><span class="token string">&quot;messageTag&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">setDeliveryTimestamp</span><span class="token punctuation">(</span>deliverTimeStamp<span class="token punctuation">)</span>
      <span class="token comment">// 消息体</span>
      <span class="token punctuation">.</span><span class="token function">setBody</span><span class="token punctuation">(</span><span class="token string">&quot;messageBody&quot;</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
    <span class="token comment">// 发送消息, 需要关注发送结果, 并捕获失败等异常. </span>
    <span class="token class-name">SendReceipt</span> sendReceipt <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>sendReceipt<span class="token punctuation">.</span><span class="token function">getMessageId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h6 id="事务消息-2"><a href="#事务消息-2" class="header-anchor">#</a> 事务消息</h6> <p>前面讲了 RocketMQ 事务的原理. 它是一种<mark><strong>基于生产 + 本地事务的两阶段事务实现</strong></mark>.</p> <p>从使用上来看, 需要分为<strong>创建消息类型为 TRANSACTION 的 Topic 和发送事务消息两步</strong>.</p> <ol><li>创建 Topic, 并设置 Topic 的 message.type 的属性为 TRANSACTION, 示例如下:</li></ol> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>./bin/mqadmin updatetopic -n localhost:9876 -t TestTopic -c DefaultCluster -a +message.type=TRANSACTION
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ol start="2"><li><strong>在生产端发送事务消息</strong>. 下面是官网提供的事务 Demo, 可以看到的步骤是: <strong>先在构建生产者的时候初始化一个本地事务, 然后开启生产的事务, 再根据本地事务的执行情况, 判断是否提交事务. 如果本地事务执行成功, 就提交事务, 否则就回滚事务</strong>. 代码里面有详细的注释说明, 可以看一下.</li></ol> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 演示 demo, 模拟订单表查询服务, 用来确认订单事务是否提交成功. </span>
<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">checkOrderById</span><span class="token punctuation">(</span><span class="token class-name">String</span> orderId<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">// 演示 demo, 模拟本地事务的执行结果. </span>
<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">doLocalTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ClientException</span> <span class="token punctuation">{</span>
    <span class="token class-name">ClientServiceProvider</span> provider <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ClientServiceProvider</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">MessageBuilder</span> messageBuilder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MessageBuilderImpl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 构造事务生产者: 事务消息需要生产者构建一个事务检查器, 用于检查确认异常半事务的中间状态. </span>
    <span class="token class-name">Producer</span> producer <span class="token operator">=</span> provider<span class="token punctuation">.</span><span class="token function">newProducerBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token punctuation">.</span><span class="token function">setTransactionChecker</span><span class="token punctuation">(</span>messageView <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
                <span class="token comment">/**
                 * 事务检查器一般是根据业务的 ID 去检查本地事务是否正确提交还是回滚, 此处以订单 ID 属性为例. 
                 * 在订单表找到了这个订单, 说明本地事务插入订单的操作已经正确提交; 如果订单表没有订单, 说明本地事务已经回滚. 
                 */</span>
                <span class="token keyword">final</span> <span class="token class-name">String</span> orderId <span class="token operator">=</span> messageView<span class="token punctuation">.</span><span class="token function">getProperties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">&quot;OrderId&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">Strings</span><span class="token punctuation">.</span><span class="token function">isNullOrEmpty</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token comment">// 错误的消息, 直接返回 Rollback. </span>
                    <span class="token keyword">return</span> <span class="token class-name">TransactionResolution</span><span class="token punctuation">.</span><span class="token constant">ROLLBACK</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
                <span class="token keyword">return</span> <span class="token function">checkOrderById</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token class-name">TransactionResolution</span><span class="token punctuation">.</span><span class="token constant">COMMIT</span> <span class="token operator">:</span> <span class="token class-name">TransactionResolution</span><span class="token punctuation">.</span><span class="token constant">ROLLBACK</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 开启事务分支. </span>
    <span class="token keyword">final</span> <span class="token class-name">Transaction</span> transaction<span class="token punctuation">;</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        transaction <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 事务分支开启失败, 直接退出. </span>
        <span class="token keyword">return</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token class-name">Message</span> message <span class="token operator">=</span> messageBuilder<span class="token punctuation">.</span><span class="token function">setTopic</span><span class="token punctuation">(</span><span class="token string">&quot;topic&quot;</span><span class="token punctuation">)</span>
            <span class="token comment">// 设置消息索引键, 可根据关键字精确查找某条消息. </span>
            <span class="token punctuation">.</span><span class="token function">setKeys</span><span class="token punctuation">(</span><span class="token string">&quot;messageKey&quot;</span><span class="token punctuation">)</span>
            <span class="token comment">// 设置消息 Tag, 用于消费端根据指定 Tag 过滤消息. </span>
            <span class="token punctuation">.</span><span class="token function">setTag</span><span class="token punctuation">(</span><span class="token string">&quot;messageTag&quot;</span><span class="token punctuation">)</span>
            <span class="token comment">// 一般事务消息都会设置一个本地事务关联的唯一 ID, 用来做本地事务回查的校验. </span>
            <span class="token punctuation">.</span><span class="token function">addProperty</span><span class="token punctuation">(</span><span class="token string">&quot;OrderId&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;xxx&quot;</span><span class="token punctuation">)</span>
            <span class="token comment">// 消息体. </span>
            <span class="token punctuation">.</span><span class="token function">setBody</span><span class="token punctuation">(</span><span class="token string">&quot;messageBody&quot;</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 发送半事务消息</span>
    <span class="token keyword">final</span> <span class="token class-name">SendReceipt</span> sendReceipt<span class="token punctuation">;</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        sendReceipt <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>message<span class="token punctuation">,</span> transaction<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 半事务消息发送失败, 事务可以直接退出并回滚. </span>
        <span class="token keyword">return</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 执行本地事务, 并确定本地事务结果. 
     * 1. 如果本地事务提交成功, 则提交消息事务. 
     * 2. 如果本地事务提交失败, 则回滚消息事务. 
     * 3. 如果本地事务未知异常, 则不处理, 等待事务消息回查. 
     */</span>
    <span class="token keyword">boolean</span> localTransactionOk <span class="token operator">=</span> <span class="token function">doLocalTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>localTransactionOk<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            transaction<span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">// 业务可以自身对实时性的要求选择是否重试, 如果放弃重试, 可以依赖事务消息回查机制进行事务状态的提交. </span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            transaction<span class="token punctuation">.</span><span class="token function">rollback</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClientException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">// 建议记录异常信息, 回滚异常时可以无需重试, 依赖事务消息回查机制进行事务状态的提交. </span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br></div></div><h6 id="死信队列-2"><a href="#死信队列-2" class="header-anchor">#</a> 死信队列</h6> <p>跟 RabbitMQ 不同的是, RocketMQ 的事务是 <strong>消费的事务</strong>. 即当一条消息初次消费失败, 消息队列会自动进行消息重试. 达到最大重试次数后, 若消费依然失败, 则表明消费者在正常情况下无法正确地消费该消息, 此时, 消息队列不会立刻将消息丢弃, 而是将其发送到该消费者对应的特殊队列中.</p> <p>消费端使用死信队列代码示例如下, 核心就是在<strong>消费的时候设置死信队列名称和消费者组名称</strong>. 设置了这两个参数, 当消费消息失败, 则消息会被投递到设置好的死信队列中.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 1. 创建 DefaultMQPushConsumer 实例</span>
<span class="token class-name">DefaultMQPushConsumer</span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DefaultMQPushConsumer</span><span class="token punctuation">(</span><span class="token string">&quot;DLQ_CONSUMER&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 2. 设置 NameServer 地址</span>
consumer<span class="token punctuation">.</span><span class="token function">setNamesrvAddr</span><span class="token punctuation">(</span><span class="token string">&quot;127.0.0.1:9876&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 3. 设置死信队列名</span>
consumer<span class="token punctuation">.</span><span class="token function">setDLQName</span><span class="token punctuation">(</span><span class="token string">&quot;DLQ_NAME&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 4. 设置处理死信队列消息的消费者组</span>
consumer<span class="token punctuation">.</span><span class="token function">setDLQConsumerGroup</span><span class="token punctuation">(</span><span class="token string">&quot;DLQ_CONSUMER_GROUP&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 5. 启动消费者实例, 连接 NameServer</span>
consumer<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h6 id="消息查询"><a href="#消息查询" class="header-anchor">#</a> 消息查询</h6> <p>RocketMQ 支持丰富的查询功能, 它提供了根据 <strong>根据 Offset, 根据时间戳, 消息 ID</strong> 三种类型的消息查询. 从技术上来看, 都是通过构建<strong>二级索引</strong>的方式来提高数据查询的速度.</p> <p>根据 Offset 查询消息的代码示例如下. 即消费者通过调用 Consumer 的 Pull 方法来获取指定队列(MessageQueue)的指定偏移量位置(offset)的消息, 同时可以设置拉取的数量. 下面的示例表示在获取 <code>queue1</code>​ 中, 偏移量是从 10 开始的往后 32 条消息.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 设置偏移量</span>
<span class="token keyword">long</span> offset <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// 拉取消息</span>
    <span class="token class-name">PullResult</span> pullResult <span class="token operator">=</span>consumer<span class="token punctuation">.</span><span class="token function">pull</span><span class="token punctuation">(</span><span class="token string">&quot;queue1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;*&quot;</span><span class="token punctuation">,</span> offset<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>pullResult<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 更新偏移量</span>
    offset <span class="token operator">=</span> pullResult<span class="token punctuation">.</span><span class="token function">getNextBeginOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 消费消息并设置延迟, 模拟业务处理</span>
    <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>根据时间戳查询消息的示例如下, 可以使用 consumer.searchOffset 方法获取与指定时间戳最近的消息偏移量(Offset), 然后再根据 Offset 去获取到对应的消息.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 设置查询消息的时间戳(毫秒)</span>
<span class="token keyword">long</span> timestamp <span class="token operator">=</span> <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 获取与时间戳最近的消息偏移量</span>
<span class="token keyword">long</span> offset <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">searchOffset</span><span class="token punctuation">(</span>mq<span class="token punctuation">,</span> timestamp<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// 拉取消息</span>
    <span class="token class-name">PullResult</span> pullResult <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">pull</span><span class="token punctuation">(</span>mq<span class="token punctuation">,</span> <span class="token string">&quot;*&quot;</span><span class="token punctuation">,</span> offset<span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>pullResult<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 更新偏移量</span>
    offset <span class="token operator">=</span> pullResult<span class="token punctuation">.</span><span class="token function">getNextBeginOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 消费消息并设置延迟, 模拟业务处理</span>
    <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>据消息 ID 查询消息示例如下, 它需要使用到 MQAdmin 来查询消息. 下面代码表示查询消息 ID 为 <code>k1</code>​ 的消息的内容.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 创建 DefaultMQAdminExt 对象</span>
<span class="token class-name">DefaultMQAdminExt</span> mqAdmin <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DefaultMQAdminExt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 设置 NameServer 地址</span>
mqAdmin<span class="token punctuation">.</span><span class="token function">setNamesrvAddr</span><span class="token punctuation">(</span><span class="token string">&quot;localhost:9876&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 启动</span>
mqAdmin<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 查询消息 ID</span>
<span class="token class-name">String</span> msgId <span class="token operator">=</span> <span class="token string">&quot;k1&quot;</span><span class="token punctuation">;</span>
<span class="token comment">// 根据消息 ID 查询消息</span>
<span class="token class-name">MessageExt</span> message <span class="token operator">=</span> mqAdmin<span class="token punctuation">.</span><span class="token function">viewMessage</span><span class="token punctuation">(</span><span class="token string">&quot;TopicTest&quot;</span><span class="token punctuation">,</span> msgId<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 输出消息内容</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>message <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;Message: &quot;</span> <span class="token operator">+</span> message<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;Message not found.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h6 id="schema"><a href="#schema" class="header-anchor">#</a> Schema</h6> <p><strong>当前 RocketMQ 消息体的数据格式没有限制</strong>. 当上游数据类型变更后, 如果下游没有及时修改代码. 就有可能解析失败, 从而导致链路异常. 为了解决这个问题, <mark><strong>RocektMQ 近期引入了 RocketMQ Schema 来规范上下游数据的传递</strong></mark>.</p> <p>前面详细讲解了它的实现, 如果需要了解更多, 可以去 GitHub 仓库 <a href="https://github.com/apache/rocketmq-schema-registry" target="_blank" rel="noopener noreferrer">Apache Rocektme Schema<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 查看更多信息.</p> <h5 id="kafka"><a href="#kafka" class="header-anchor">#</a> Kafka</h5> <p>Kafka 支持顺序消息, 幂等, 事务消息, 消息查询, Schema 等功能, 不支持定时和延时消息, 优先级队列, 死信队列, WebSocket 等功能.</p> <h6 id="顺序消息-3"><a href="#顺序消息-3" class="header-anchor">#</a> 顺序消息</h6> <p><strong>Kafka 实现的顺序消息是单个生产者维度的顺序消息, 即多个生产者之间的数据是无法保证有序的</strong>.</p> <p>单个生产者实现顺序消息也有以下两个限制:</p> <ul><li>如果 Topic 只有一个分区, 那么消息会根据服务端收到的数据顺序存储, 则数据就是分区有序的.</li> <li>如果 Topic 有多个分区, 可以在生产端指定这一类消息的 Key, 这类消息都用相同的 Key 进行消息发送, Kafka 会根据 Key 哈希取模选取其中一个分区进行存储, 由于一个分区只能由一个消费者进行监听消费, 此时消息就具有消息消费的顺序性了.</li></ul> <p>另外需要注意客户端参数 linger.ms 的设置. 如果设置了 linger.ms 大于 0, 则消息重传可能会导致消息无法保证有序. 因此就需要把 linger.ms 设置为 0, 即表示数据立即发送.</p> <blockquote><p>linger.ms 表示消息延迟发送的时间, 它的用处是可以等待更多的消息组成 batch 发送. 默认为 0 表示立即发送. 当待发送的消息达到 batch.size 设置的大小时, 不管是否达到 linger.ms 设置的时间, 请求也会立即发送.</p></blockquote> <p>下面代码示例是表示, 通过在生产端设置 linger.ms 和消息 ID 为 <code>key1</code>​, 来保证消息是有序的.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">&quot;1000&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>

producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span>
    <span class="token string">&quot;key1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;&quot;</span>code<span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span>message<span class="token operator">:</span>&quot; <span class="token operator">+</span> <span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token constant">SYSTEM</span><span class="token punctuation">.</span><span class="token function">nanoseconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h6 id="幂等"><a href="#幂等" class="header-anchor">#</a> 幂等</h6> <p>前面讲过, Kafka 支持 <strong>生产的幂等</strong>, 即通过为每个生产者分配唯一的 ProducerID 和为这个生产者发送的消息分配一个自增的序号 SeqNum 来唯一标识这条消息. Broker 会根据 ProducerID 和 SeqNum 来实现消息的重复判断, 从而保证消息不重复.</p> <p>下面是生产者开启幂等的代码示例. 如下所示, 核心代码是设置 <code>enable.idempotence</code>​ 为 true, 只要设置了这个参数, 就相当于<strong>开启幂等</strong>了, 使用起来非常简单.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;bootstrap.servers&quot;</span><span class="token punctuation">,</span> bootstrap<span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;retries&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 重试次数</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;batch.size&quot;</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 批量发送大小</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;buffer.memory&quot;</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 缓存大小, 根据本机内存大小配置</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;linger.ms&quot;</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 发送频率, 满足任务一个条件发送</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;client.id&quot;</span><span class="token punctuation">,</span> clientId<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 发送端 id,便于统计 &quot;token#sfdiewrnxkcvvulsdfsdfdsijuiewrewr&quot;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;key.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;value.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;enable.idempotence&quot;</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 设置幂等性</span>
<span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Long</span> startTime <span class="token operator">=</span> <span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token constant">SYSTEM</span><span class="token punctuation">.</span><span class="token function">milliseconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Integer</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token comment">// 开启事务</span>
        <span class="token comment">// 发送消息到 producer-syn</span>
        producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">&quot;msg1&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><h6 id="事务消息-3"><a href="#事务消息-3" class="header-anchor">#</a> 事务消息</h6> <p>Kafka 的事务是<strong>两阶段事务</strong>的实现, 主要保证的是<strong>生产的事务</strong>. 它可以保证对多个分区写入操作的原子性, 操作的原子性是指多个操作要么全部成功, 要么全部失败, 不存在部分成功, 部分失败的可能.</p> <p>为了使用事务, 需要在客户端显式设置唯一的 <code>transactional.id</code>​ 参数并开启幂等特性. 因此通过将 transactional.id 参数设置为非空从而开启事务特性的同时, 需要将 enable.idempotence 设置为 true. 如果用户将 enable.idempotence 设置为 false, 则会报错.</p> <p>下面是 Kafka 生产事务的使用示例. 核心代码就是 transactional.id 和 enable.idempotence 参数的配置, 以及 beginTransaction, commitTransaction, abortTransaction 三个步骤.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;bootstrap.servers&quot;</span><span class="token punctuation">,</span> bootstrap<span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;retries&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 重试次数</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;batch.size&quot;</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 批量发送大小</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;buffer.memory&quot;</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 缓存大小, 根据本机内存大小配置</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;linger.ms&quot;</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 发送频率, 满足任务一个条件发送</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;client.id&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;producer-txn-test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 发送端 id,便于统计</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;key.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;value.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;transactional.id&quot;</span><span class="token punctuation">,</span> txnId<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 每台机器唯一</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">&quot;enable.idempotence&quot;</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 设置幂等性</span>
<span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Long</span> startTime <span class="token operator">=</span> <span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token constant">SYSTEM</span><span class="token punctuation">.</span><span class="token function">milliseconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Integer</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token comment">// 开启事务</span>
        producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 发送消息到 producer-syn</span>
        producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">&quot;message&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 终止事务</span>
        producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h6 id="消息查询-2"><a href="#消息查询-2" class="header-anchor">#</a> 消息查询</h6> <p>从功能上来看, <strong>Kafka 支持按照 Offset 和时间戳查询消息</strong>. 从内核的实现来看, 技术原理通过构建 Offset 和时间戳的二级索引来加快数据查询的速度. 二级索引底层在底层的数据结构如下所示:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/53a022326eb615b9e7a48269e2632bcb-20240421231949-cgxp47h.png" alt="">​</p> <p>​<code>.timeindex</code>​ 索引的内容如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>timestamp: 1693001346933 offset: 62369391
timestamp: 1693001346957 offset: 62369395
timestamp: 1693001347033 offset: 62369397
timestamp: 1693001420165 offset: 62369402
timestamp: 1693001420203 offset: 62369408
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>​<code>.index</code>​ 索引的内容如下所示:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>offset: 62369391 position: 4462
offset: 62369395 position: 9664
offset: 62369397 position: 13986
offset: 62369402 position: 18309
offset: 62369408 position: 23699
offset: 62369414 position: 29882
offset: 62369418 position: 35910
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>所以从原理上看, 根据 Offset 查询数据, 就是通过 Offset 找到数据在文件中的具体位置. 根据时间查询数据, 就是通过时间找到 Offset, 然后再根据 Offset 找到对应的数据. 具体的实现原理可以回顾一下第 32 讲.</p> <h6 id="schema-2"><a href="#schema-2" class="header-anchor">#</a> Schema</h6> <p>Kafka 社区版本支持的 Schema 不是一个完整的功能. 完整的 Schema 只有在 Kafka 的商业化公司 Confluent 提供的商业化版本的 Kafka 才支持. 比如 Kafka Schema Registry 这个项目是在 Confluent 公司的仓库中的, 并没有贡献给 Apache.</p> <p>Kafka Schema 整体的架构思路和 第33讲 基本一致, 如果需要可以去回顾一下.</p> <h5 id="pulsar"><a href="#pulsar" class="header-anchor">#</a> Pulsar</h5> <p>Pulsar 支持顺序消息, 幂等, 定时和延时消息, 事务消息, 死信队列, 消息查询, Schema, WebSocket 等功能, 不支持优先级队列.</p> <p>因为 Pulsar 的发展很快, 功能点的代码和设计思路都有持续的迭代和演化. 当前的总结可能很快就会过期, 所以就不总结了. 可以先根据官网资料学习一下最新的设计和实现.</p> <h5 id="总结-35"><a href="#总结-35" class="header-anchor">#</a> 总结</h5> <p>总结下来, 你会发现不同消息队列在功能方面的支持是很不一样的, 侧重点各有不同. 但是同一个功能的底层实现原理, 大家的思路基本是一致的.</p> <p>从用户的角度来看, 功能是选型的核心. 所以在业务消息类的场景, 会优先推荐使用 RocketMQ. 在流方向的场景, 会推荐使用 Kafka。</p> <p>最后想说明的是, 虽然 Pulsar 支持的功能是最多的, 但并不代表 Pulsar 是最优解. 选型除了功能外, 稳定性也是重要的考虑点. <strong>Pulsar 因为迭代较快, 目前还处于快速发展阶段, 一些功能还在开发中, 在使用时需要判断是否适合生产场景</strong>.</p> <h3 id="架构升级篇"><a href="#架构升级篇" class="header-anchor">#</a> 架构升级篇</h3> <h4 id="_36-云原生-业界mq的计算存储分离是如何实现的"><a href="#_36-云原生-业界mq的计算存储分离是如何实现的" class="header-anchor">#</a> 36-云原生:业界MQ的计算存储分离是如何实现的?</h4> <p>在功能篇分析了消息队列中多个主要功能的技术实现. 从这节课开始, 将结合 <strong>云原生, Serverless,  EDA(Event-driven Architectures), 存算分离, 分层存储, 数据集成</strong> 等一些业界较新的技术架构理念, 来讲一下消息队列如何与这些架构理念结合, 以及结合后会具备哪些实际价值.</p> <p>这节课就重点学习一下<strong>消息队列的存算分离架构</strong>.</p> <h5 id="什么是存算分离架构"><a href="#什么是存算分离架构" class="header-anchor">#</a> 什么是存算分离架构</h5> <p>首先得清楚什么是存算分离架构.</p> <p>存算分离中的  <strong>&quot;存&quot; 是指存储层, &quot;算&quot; 是指 &quot;计算层&quot;</strong> . 简单理解 &quot;计算&quot; 就是功能相关的实现, &quot;存储&quot; 是指数据落地持久化存储. 消息队列中的存储层是指包括存储结构设计, 消息存储格式, 数据分段等具体的数据存储功能. 计算层是指包括协议解析, 事务消息, 延时消息等主要消耗计算资源(如 CPU)的功能模块.</p> <p>跟存算分离相对的是存算一体, &quot;分离&quot; 和 &quot;一体&quot; 是指计算层和存储层是否在一台机器上.</p> <p>如下图所示, 这是存算一体的消息队列的架构. 从单机维度看, <strong>计算层和存储层都在同一个 Broker 中, 由多台 Broker 组成一个集群</strong>. 这种存算一体的架构就是典型的有状态服务.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d2c96dyy4acde2c581df15b1yy40edcf-20240421231949-vp2bmf1.jpg" alt="">​</p> <p>存算一体架构的最大特点就是计算层和存储层没有明显的界限, 从代码层面上看, 计算层和存储层交互的操作就是文件的读写, 比如前面讲到的 FileChannel.write, FileChannel.read. 它的主要优势是架构简单, 开发实现成本较低. 缺点是它是一个<strong>有状态服务, 无法快速弹性地扩容</strong>.</p> <p>而随着数据量越来越大, 具备弹性快速扩缩容能力的消息队列集群可以极大地降低资源和人力成本, 而 <mark><strong>存算分离架构则是目前实现弹性消息队列集群的主要技术方案</strong></mark>.</p> <p>再来看下面这张图, 图中分离了计算层集群和存储层集群. <mark><strong>计算层集群主要负责消息功能类的操作, 比如压缩解压, 事务消息, 死信消息等等. 存储层负责数据的存储</strong></mark>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bff2a2629db3016c304737160c2780fb-20240421231949-nc96nh5.jpg" alt=""></p> <p><strong>从数据流动来看, 当数据写入到计算层集群, 计算层会进行相关处理, 然后通过网络协议将数据写入到存储集群. 从功能上看, 存储集群几乎没有任何逻辑, 核心工作就是接收到数据, 然后存储</strong>.</p> <p>存算分离架构的优点是<strong>计算层为无状态, 因此计算层的扩缩容就很方便</strong>. 缺点是架构变复杂, 代码实现难度也提升很多, 日常的运维, 研发的学习成本也会相应提高. 另外计算层和存储层的交互从本地调用变为了网络协议的调用, 性能上会有一些下降.</p> <p>所以可以看到, 存算分离和存算一体架构有各自的优缺点. 那消息队列真的需要存算分离的架构吗? 关于这个问题每个人都有自己的看法和判断, 我讲一下自己的观点.</p> <h5 id="我们真的需要存算分离架构吗"><a href="#我们真的需要存算分离架构吗" class="header-anchor">#</a> 我们真的需要存算分离架构吗</h5> <p>我个人的判断是: <strong>存算分离是消息队列架构中的可选项, 而不是必选项</strong>. 为什么这么说呢?</p> <p>存算分离架构最大的好处就是<strong>集群变得更加弹性</strong>. 从终态来说, 没有存算分离, 消息队列架构就无法 Serverless 化, 也就无法做到快速扩缩容. 从成本结构的角度来看, 没法快速扩缩容, 那么就无法提高集群的利用率, 也就无法很好地降低成本.</p> <p>那既然如此, 它应该是一个必选项, 为什么还是一个可选项呢?</p> <p>我认为核心原因是: <strong>用户诉求的多元化</strong>. 在我多年负责消息队列云产品的经历中, 最大的感受就是<strong>用户是多元的, 从而导致诉求也是多元的</strong>. 也就是说, <strong>不是所有的客户对弹性和成本都有很强的诉求</strong>.</p> <p>来看一下以下几类常见的客户:</p> <ol><li>某个中长尾企业客户, 业务规模不大, 可以说很小. 他们对消息队列的需求是稳定, 能用, 免运维. 因为规模不大, 弹性和成本不是他们的痛点.</li> <li>某个大型企业, 大部分业务的流量都不高, 而且一般按部门划分使用. 所以他们的核心诉求跟第一类客户很像, 只是多了一些成本的诉求.</li> <li>某个私有化部署或自建集群的客户, 他们的要求是能满足业务场景, 集群稳定, 运维简单, 不要出问题.</li> <li>某个大型企业的核心业务, 流量比较大, 也有弹性的需求. 从业务角度看, 稳定性, 出问题的恢复速度是他们的核心诉求. 弹性和成本是很重要, 但那是第二梯队考虑的事儿.</li> <li>某个云服务提供商, 提高产品竞争力是核心诉求, 而成本是产品竞争力的核心.</li></ol> <p>从上面的用户画像来看, 1, 2, 3 类型的用户数量基本占了 80%~90%; 4 类型的客户, 弹性和成本是很重要的一个点, 但是他们也愿意投入更多成本来提高稳定性; 5 类型的客户, 弹性和成本是他们的核心诉求.</p> <p>所以有个有趣的现象是, 你去观察一些技术文章, 大会分享, <strong>提存算分离概念最多的一般都是云服务提供商</strong>. 原因就是他们有这个需求, <strong>而一些小公司, 更多是聚焦在功能和使用层面, 对存算分离没有那么刚需</strong>. 从理论上来看呢, 这也符合二八原则, 即大部分的客户其实并不需要存算分离架构带来的好处, 或者因为规模限制, 根本用不到存算分离的优势.</p> <p>所以上面才会说存算分离是可选项, 而不是必选项. 或者说合理的架构是: <strong>既可以存算一体也可以存算分离的可插拔的存储结构</strong>.</p> <p>接下来拆解一下如果要实现存算分离的架构, 技术上都是怎么做的?</p> <h5 id="实现存算分离架构的技术思考"><a href="#实现存算分离架构的技术思考" class="header-anchor">#</a> 实现存算分离架构的技术思考</h5> <p>从功能上来看, 存储层的核心功能就是保证数据高性能和可靠的存储, 本身没有太多复杂的计算逻辑. 所以存算分离架构的核心就是<mark><strong>选择合适的存储层引擎</strong></mark>.</p> <p>因为不同存储层引擎的特性不一样, 所以基于不同引擎设计出来的系统架构也完全不一样. 那么如何选择合适的存储层引擎呢?</p> <h6 id="如何选择合适的存储层引擎"><a href="#如何选择合适的存储层引擎" class="header-anchor">#</a> 如何选择合适的存储层引擎</h6> <p>先来看下图, 从业界的主流组件来看, 可选择的存储层引擎主要有<strong>对象存储, 分布式存储服务, 虚拟云盘</strong>三类.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/f2247e878fe05b88776b065ab6897588-20240421231949-mxtlnnl.jpg" alt=""></p> <ul><li><strong>对象存储</strong> 是指各个云厂商提供的商业化的对象存储服务, 比如 AWS 的 S3, 腾讯云的 COS 等.</li> <li><strong>分布式存储服务</strong> 是指一些专门用来提供分布式的数据存储的组件, 比如 HDFS, BookKeeper 等等. 也有一些公司会自己开发分布式文件系统, 比如阿里的盘古, 腾讯的 CFS 等等.</li> <li><strong>虚拟云盘</strong> 是指云厂商提供的在线云盘服务.</li></ul> <p><strong>对象存储</strong>最大的特点是, 它具备分布式可靠存储的能力且存储成本较低. 缺点是读写方式不够灵活, 流式读写性能较低. 所以在消息队列这种需要高性能, 高吞吐的场景中, 比较难以大规模在实时流数据场景中使用. 但是因为它具有非常明显的成本优势, 业界还是在持续探索对象存储在实时流场景中的使用, 以求通过技术手段发挥其成本价值.</p> <p><strong>分布式存储服务</strong>的优点是具备分布式存储能力, 读写性能也较高. 缺点是存储集群本身会有一些稳定性和可靠性问题. 从技术上看, 稳定性和可靠性问题可以通过技术和运维优化来解决.</p> <p><strong>云盘</strong>的特点是数据在远端是多副本可靠存储的, 天然支持分布式可靠存储的能力. 它的缺点是云盘需要先绑定节点, 同一时间只允许一台 Broker 写入数据到云盘. 当 Topic 的分区迁移, Leader 切换的时候, 需要将云盘从老的 Broker 节点卸载, 再挂载到新的 Broker 节点, 在这个过程中服务是停止的. 从技术上看来, 这个缺点几乎是不可解决的.</p> <p>因为<strong>分布式存储服务一般会提供多语言的流式写入的 API 进行数据读写, 读写性能较高, 比较适合消息队列的数据特点</strong>. 所以从业界落地的角度来看, <strong>分布式存储服务用得比较多</strong>. 比如 Pulsar 的存储层使用的是 BookKeeper, RocketMQ 5.0 的存储层用的是原先的 Broker 集群.</p> <p>完成了存储层引擎选择之后, 接下来看看存储层和计算层的设计实现. 这里主要分析<strong>存储层中分区存储模型的设计</strong> 和 <strong>计算层弹性无状态的写入</strong>这两个关键部分.</p> <p>从前面的课程可以知道, 分区是消息数据的最小单位. 所以在分层的架构中, 首先要解决的就是计算层分区维度消息数据的存储问题, 即<strong>分区数据在存储层是如何存储</strong>的.</p> <h6 id="存储层-分区存储模型的设计"><a href="#存储层-分区存储模型的设计" class="header-anchor">#</a> 存储层:分区存储模型的设计</h6> <p>前面讲到了存算一体架构中的消息数据的存储模型, 讨论了在单机维度, 所有分区的数据都在一个 &quot;文件&quot;, 还是每个文件都是独立的 &quot;文件&quot;. 这在存算分离的架构中也是同样需要考虑的.</p> <p>在存算一体架构中, 这两种模型各有优劣, 都有成熟产品使用. <strong>但是在存算分离的架构中, 基本都是每个分区一个 &quot;文件&quot;的方案</strong>. 主要是出于数据的读写性能考虑. 在存算分离的架构中, 是通过网络协议从存储层读取数据的.</p> <p>来看下图, 如果数据存储在一份文件中, 则存储层在读取数据时就需要维护<strong>二级索引</strong>, 并启动随机读, 在性能上会有一定的降低.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/9a4bae1bf1bef235af504eabbec815d9-20240421231949-lyslfb5.jpg" alt=""></p> <p>所以合理的方案如下图所示, 不同的分区在存储层有独立的 &quot;文件&quot; 存储, 然后<strong>顺序读写不同的段文件</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bd9d05e056d1ef44097e6320136b9e43-20240421231949-o5et5e7.jpg" alt=""></p> <p>分区存储模型的设计, 严重依赖存储层引擎的选择, 一会儿讲 RocketMQ 和 Pulsar 的分区存储模型时, 再结合这部分的内容, 会理解得更加透彻.</p> <p>接下来看一下<strong>计算层如何实现无状态的写入</strong>.</p> <h6 id="计算层-弹性无状态的写入"><a href="#计算层-弹性无状态的写入" class="header-anchor">#</a> 计算层:弹性无状态的写入</h6> <p>上面讲到, 存储层是一个具备多副本可靠存储能力的分布式存储服务. 所以如下图所示, <strong>计算层中 Topic 的分区就不需要有副本的概念</strong>, 数据的可靠存储可以交给存储层去解决. 即<strong>计算层的 Topic 永远是单分区</strong>.</p> <p>从数据流的角度来看, 分区的数据写入到存储层, 依赖存储层多副本存储的能力实现数据的可靠存储. 从技术来看, 副本并没有被省掉, 只是将副本概念下沉到了存储层而已.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4dca4e0639732aee385b487f97572316-20240421231949-07ol3o6.jpg" alt="">​</p> <p>在上图中, Broker 接收到数据后, 是需要转发到存储层存储的. 客户端数据写入到分区有 Metadata(元数据)寻址机制和服务端内部转发机制两种形式. 在存算一体的架构中, 推荐使用的是<strong>元数据寻址方案</strong>. 但是在存算分离的架构中, 数据都需要转发写入到存储层, 因为都需要再转发一次, 所以<strong>服务端内部转发</strong>也变为了一种常用方案.</p> <p>比如 Pulsar 当前的计算层 Broker 和分区也是绑定的, 也需要经过寻址, 所以 Pulsar 用的就是元数据寻址方案. RocketMQ 5.0 架构中, Proxy 是完全无状态的, 每台计算层 Broker 收到数据后, 转发写入到后端的存储层, 所以 <strong>RocketMQ 用的是服务端内部转发的方案</strong>.</p> <p>从技术上看, <strong>计算层和存储层之间的调用是比较重要的一个模块</strong>. 计算层 Broker 需要使用存储层引擎提供的 SDK 或者写入方式将数据写入到存储层. 比如 Pulsar 是调用 BookKeeper 提供的 SDK 将数据写入 BookKeeper 的. 此时考验的就是编码的技巧和功力了, 比如线程管理, 线程安全, 批量写入等等.</p> <p>另外, <strong>计算层</strong> <strong>Broker 对消息队列各个功能的支持, 都是在进阶篇讲的方案, 不会因为架构的变化有大的改变</strong>, 但是在实现细节上会有些许差异, 比如事务的实现, 有兴趣的话可以去研究下.</p> <p>目前业界<strong>主流消息队列 Kakfa, RocketMQ , RabbitMQ 都是存算一体的架构</strong>. RocketMQ 从 5.0 版本开始, 在往存算分离架构的方向演化, 但本质还是存算一体的架构. <strong>而 Pulsar 从一开始的设计就是存算分离的架构</strong>.</p> <p>一个是从存算一体演化到存算分离架构, 一个是一开始就是往存算分离架构设计的, 两条技术路径演化是不一样的. 接下来分析一下 RocketMQ 5.0 和 Pulsar 在存算分离上的架构的实现, 看一下有什么异同点.</p> <h5 id="业界主流存算分离架构分析"><a href="#业界主流存算分离架构分析" class="header-anchor">#</a> 业界主流存算分离架构分析</h5> <p>先来看看 RocketMQ 存算分离的架构. 严格意义上说, 当前 RocketMQ 5.0 不是存算分离的架构, 只是 <strong>代理(Proxy)模式</strong>.</p> <h6 id="rocketmq5-0架构分析"><a href="#rocketmq5-0架构分析" class="header-anchor">#</a> RocketMQ5.0架构分析</h6> <p>来看下面这张图, 这是 RocketMQ 5.0 中添加了 Proxy 组件后的架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/53cb96a89dfd51a6bfb8fcb9c999e277-20240421231949-4jukmw4.jpg" alt=""></p> <p>在上图中, gRPC Server 就是 Proxy 组件, NameServer, Broker A1 和 A2 的 Master/Slave 就是原先的主从结构的 Broker 集群, <strong>gRPC Server 前面可以挂载负载均衡组件</strong>. MQAdmin 客户端和 RocketMQ 5.0 的客户端可以直连负载均衡或 gRPC Server, 进行读写, 管控等操作. <strong>gRPC Server 收到请求后, 再把请求转发到实际的 Broker 集群</strong>.</p> <p>上面的架构图有点复杂, 可以简化为下面这张图就更好理解了. 可以看到, RocketMQ 5.0 就是在原先 Broker 集群的基础上添加了一个 Proxy 组件.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fffea0cec04c5f40bf2eca465a9dddb4-20240421231949-m4e4uzf.jpg" alt=""></p> <p>所以从技术上看, <strong>当前的 Proxy 组件只是转发层, 不处理任何计算和存储的逻辑</strong>. 集群实际意义上的计算和存储逻辑, 都是在 Broker 集群上完成的. 这就是前面所说的, 当前 RocketMQ 5.0 的架构不是真正意义上的存算分离架构的原因. 更准确的说法是, <strong>RocketMQ 5.0 只是从当前存算一体的架构往存算分离架构演化走出了第一步</strong>.</p> <p>在我看来, 接下来 RocketMQ 要做的就是将当前 Broker 集群上的计算逻辑向上移动到 Proxy 组件里面, 让 Proxy 组件来完成计算层逻辑. 从而把当前的 Broker 集群完全变为一个存储层. 此时结合上面讲到的存算分离的设计思路:</p> <ol><li>在存储引擎的选择上, RocketMQ 实际就是选择分布式存储服务的方案, 只是这个分布式存储服务是 RocketMQ 当前已经有的 Broker 集群.</li> <li>在分区存储模型的设计上, 我个人判断, 短时间还是大概率会沿用当前的分区存储模型. 因为如果改动存储模型, 从架构演化的角度来看, 改动太大, 开发成本太高.</li> <li>无状态写入则是一个比较好实现的方案, 当前 Proxy 的写入就是完全无状态的. 数据随机写入任意一台 Proxy, 再转发到具体的 Broker 集群.</li></ol> <p>所以可以看到, RocketMQ 的存算分离架构是演化来的, 而不是一开始就往这个方向设计. 因此 RocketMQ 往存算分离架构演化的挑战非常大, 因为它需要兼顾到当前架构中的功能和设计模型. 简单说就是, 有很多的历史包袱. 接下来来看看 Pulsar 存算分离的架构.</p> <h6 id="pulsar存算架构分析"><a href="#pulsar存算架构分析" class="header-anchor">#</a> Pulsar存算架构分析</h6> <p><strong>Pulsar 的架构从一开始就是往存算分离设计的</strong>. 先来回顾一下前面讲到过的 Pulsar 的架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/904fd20b6ced9af51ae9c25e1c196171-20240421231949-1vfd8ua.jpg" alt=""></p> <p>Pulsar 在设计的时候, 就选择好了<strong>使用 Apache BookKeeper 来当作它的存储层</strong>. 那为什么选择 BookKeeper, 不选择其他引擎呢? 在我看来, 有以下三方面原因:</p> <ol><li><strong>Bookeeper 设计的初衷就是用来高性能地存储分布式流日志的</strong>, 而日志最大的特点就是顺序的 Append 模型, 消息队列的消息数据特点也是顺序 Append 的, 所以 BookKeeper 就很适合当作消息队列的存储层.</li> <li>BookKeeper 具备流式读写的能力, 写入和读取的性能较高, 并且具备分布式可靠存储的特性.</li> <li>因为 Pulsar 社区的主要开发者是之前是维护 BookKeeper 的成员, 比较熟悉 BookKeeper, 这可能也是其中一个原因.</li></ol> <p>以下还是在第 13 讲讲过的 Pulsar 消息数据底层的分区存储模型, 来看下图简单回顾一下.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/78a924ae3908e10cf78ef1afa4d22605-20240421231949-qahktdi.jpg" alt=""></p> <p>参考图示, <strong>Pulsar 计算层的分区都是单副本的, 即没有副本的概念</strong>. 每个 Pulsar 分区底层由多个 Ledger 组成, 每个 Ledger 只包含一个分区的数据. 每个 Ledger 有多个副本, <strong>这些 Ledger 副本分布在 BookKeeper 集群中的多个节点上</strong>.</p> <p>从架构设计的角度, 存储层 BookKeeper 跟 Pulsar 没有关系, 它是一个独立的开源项目, 消息队列相关的特性都是在计算层 Broker 中实现的.</p> <p><strong>Pulsar 在设计分区存储模型的时候, 是根据 BookKeeper 已有的特性和概念来设计的</strong>.</p> <p>比如说, BookKeeper 的最小存储单位是 Ledger, Ledger 里面由多个 Entry 组成, <strong>每个 Entry 可以理解就是一条数据</strong>.</p> <p>基于 BookKeeper 的这些特性, Pulsar 分区模型的底层单位就是 Ledger, 每条消息就是一个 Entry, 每个 Ledger 都是一个数据分段. 这就是我们说的, <strong>分区存储模型的设计依赖于底层分布式存储引擎的选择的原因</strong>. 如果选择了其他的分布式存储引擎, 分区存储模型可能就是另外的实现.</p> <p>再来看下面这张图, 在计算层中 Pulsar 的分区是和某台 Broker 进行绑定的, 可以简单理解这台 Broker 就是分区的 Leader, 分区数据的读写都是在这条 Broker 上完成的. 客户端的生产消费请求发送到这台 Broker 后, Broker 会先经过计算逻辑的处理, 再去 BookKeeper 节点读写数据. 当某台 Broker 负载高时, 就需要快速迁移分区降低 Broker 负载. 因为计算层就都是无状态的, 迁移起来就很快, 直接修改元数据即可.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/093aa637b5d9fc9ea6062e4b6bcc0a0c-20240421231949-phxas65.jpg" alt=""></p> <p>在内核具备了快速迁移的能力后, 为了能够进行快速的负载调度, 内核就需要具备自动化调度迁移的能力. 所以 Pulsar 在内核中提供了<strong>自动化负载均衡的机制</strong>, 即有一个主节点(可以理解就是讲过的 Controller 节点)不断地检测每台 Broker 的负载, 然后根据一定的负载均衡策略执行 Topic 自动迁移, 将负载高的节点上的分区迁移到负载低的节点. 具体的迁移策略, 就不展开了, 有兴趣的同学可以去看一下官方文档 <a href="https://pulsar.apache.org/docs/3.1.x/concepts-broker-load-balancing-overview/" target="_blank" rel="noopener noreferrer">Broker LoadBalancing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>同时, 为了提高负载均衡和迁移的效率, <strong>Pulsar 引入了 Bundle 的概念</strong>. 参考图示, Bundle 是处于 Namespace 和 Topic 之间的一个概念, 它是用来组织多个 Topic 的一个逻辑概念. <strong>即一个 Namespace 有多个 Bundle, 一个 Bundle 里面有多个 Topic</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/19f5e54ab7e7f3f02bd61371c7851cae-20240421231949-q26bqrr.jpg" alt=""></p> <p>那为什么要引入 Bundle 呢? 引入 Bundle 又有什么好处呢?</p> <p>从技术上看, <strong>引入 Bundle 的主要原因是 Pulsar 有自动负载均衡机制, 会把负载较高的 Broker 上的一些 Topic 迁移到负载较低的 Broker 中, 从而实现 Broker 间负载的均衡</strong>.</p> <p>而这个迁移如果以 Namespace 为单位, 可能会一下子迁移很多 Topic. 而如果以 Topic 为单位, 每次搬移数据又可能会很小, 因为迁移过程中需要修改大量 Topic 和 Broker 之间的元数据. 所以, 以 Bundle 为单位进行迁移是最合适的, 用它迁移 Topic 会容易很多.</p> <h5 id="总结-36"><a href="#总结-36" class="header-anchor">#</a> 总结</h5> <p><strong>存算分离架构不是银弹, 它的核心优势是具备快速扩容能力, 以及快速扩缩容能力带来的成本优势</strong>. 但是相比存算一体的架构, 存算分离架构的研发和运维成本很高. 大部分客户用不到, 甚至不需要存算分离架构带来的优势. 所以从用户角度来看, 存算分离架构应该是一个可选项, 而不是必选项.</p> <p>随着云服务的普及, 像消息队列这种基础服务, 最终会慢慢往云服务收归. 站在云服务厂商的角度, 弹性和成本将成为其核心竞争力. 存算分离架构带来的集群弹性, 在成本方面具有非常强的优势. 所以存算分离对于这些厂商来说, 是一个必须要走的路.</p> <p>从技术上来看, 选择一个可靠的远程存储是存算分离架构中最重要的点. 目前业界远程存储主要有对象存储, 分布式存储服务, 虚拟云盘三种类型的选择. 从消息队列的特性和业界的实现来看, 分布式存储服务是用得最多的方案, 比如 BookKeeper, 阿里的盘古等等.</p> <p>在存算分离架构中, 分区存储模型的设计是非常重要的一个点. 但是从落地来看, 一般是在选择好存储层引擎的基础上, 再根据消息队列的存储特点进行设计。</p> <p>另外, 在存算分离架构中, <strong>计算层的弹性有以下三个关键点</strong>:</p> <ol><li><strong>Topic 能够快速地迁移, 不需要进行消息数据搬迁</strong>, 这一点基于存算分离的架构就可以实现.</li> <li><strong>能够自动地迁移</strong>, 即不需要人工介入, 系统能够自动化地均衡迁移. 这点要求集群内核具备自动化调度的能力.</li> <li><strong>能够高效地迁移, 迁移过程是高效快速的, 且对集群没有影响</strong>. 这一点就很灵活, 比如 Pulsar 中的 Bundle 就是起的这个作用.</li></ol> <p>从业界的进展来看, 目前 RocketMQ 5.0 开始在往存算分离的架构演化, Pulsar 从设计开始就走的存算分离的架构方向. 存算分离架构的主要痛点在于研发成本高, 周期长, 稳定性有待提升, 还无法提供长期稳定的服务.</p> <p>在我看来, 虽然 Pulsar 是第一个存算分离架构的消息队列, 但不能说它走的技术路径就是全对的. 但是它本身的很多设计思想, 很有先进性, 很值得去参考.</p> <h4 id="_37-云原生-mq的分层存储架构都有哪些实现方案"><a href="#_37-云原生-mq的分层存储架构都有哪些实现方案" class="header-anchor">#</a> 37-云原生:MQ的分层存储架构都有哪些实现方案?</h4> <p>这节课来看看消息队列中<strong>分层存储</strong>的功能. 很多人对分层存储的概念比较模糊, 经常会将它和存算分离混淆在一起. 从功能上来看, 两者是完全不一样的. <strong>存算分离架构主要解决的是集群架构的弹性问题, 而分层存储架构解决的是低成本存储冷数据的问题</strong>.</p> <p>下图是两种形态的架构对比, 存算分离是将计算层和存储层独立开来, 分别负责计算相关逻辑和存储数据. <strong>而分层存储在本地完成计算和存储逻辑, 然后将 Broker 本地的冷数据上传到远程进行存储, 需要时再拉下来处理</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/16b9614yy0e756b5de3ab4f4a415f486-20240421231949-ewsvflv.jpg" alt=""></p> <p>从技术上看, 左边的存算分离架构也可以支持分层存储的特性, 即把存储层中的冷数据再导入到另外一个存储系统存储.</p> <p><strong>那分层存储是怎么实现的呢? 业界主流消息队列是如何支持分层存储的呢</strong>?</p> <h5 id="什么是分层存储"><a href="#什么是分层存储" class="header-anchor">#</a> 什么是分层存储</h5> <p>首先来了解一下什么是分层存储.</p> <p>消息队列中的分层存储, 就是经常见到的<mark><strong>冷热数据分开存储</strong></mark>. 在存算一体的消息队列架构中, 消息数据是以分段的形式存储在本地硬盘中的. 一般情况下, 消息数据保留的时间比较短, 大部分在一天左右. 而如果要保留长时间的数据, 就需要占用大量的本地硬盘空间, 这会导致存储成本较高.</p> <p>为了降低存储成本, <strong>消息队列参考了冷热数据分离的思路, 提出了分层存储的概念</strong>. 如下图所示, 写入数据的时候还是将数据写入到本地, 然后通过在 Broker 中设置一定的策略<strong>将 Broker 上的老数据上传到远程的分布式文件系统中. 在消费的时候, 再从远程拉取数据到本地, 给消费端消费</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2f28f901bf9d80a6530b2036ea86066f-20240421231949-jgw9lff.jpg" alt=""></p> <p>从技术上看, 远程存储系统与存算分离架构的存储引擎的选择思路不太一样. 因为分层存储的数据一般是以数据段的形式上传到远端文件系统的.</p> <p>所以总结来看, 分层存储就是指<strong>在不改动本地存算一体架构的前提下, 通过一定的策略将本地的数据存储到远程, 从而降低本地硬盘的负载压力. 在消费的时候, 再从远端文件系统下载对应的数据, 提供给消费者消费</strong>.</p> <p>清楚了分层存储的定义, 接下来看看分层存储的应用场景和局限.</p> <h5 id="分层存储的应用和局限"><a href="#分层存储的应用和局限" class="header-anchor">#</a> 分层存储的应用和局限</h5> <p>从用户的角度来看, 分层存储的核心作用是: <strong>通过将数据存储到更廉价的存储中, 来降低存储成本</strong>.</p> <p>因为消息队列本质上是一个存储引擎, 所以从理论上看分层存储是能带来成本价值的. 如下图所示, 单台 Broker 日常需要存储 5TB 数据, 开启分层存储后, 就可以将 4TB 数据存储到远程, 本地只需要保留 1TB 的数据.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/20c89317e42b55yy6b43c5057419dec9-20240421231949-iwunduv.jpg" alt=""></p> <p>从成本计算的角度, 一般远程存储的存储成本是本地的三分之一, 所以成本计算如下:</p> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>原先的成本 = 5TB * 1 = 5
开启分层后的成本 = 1TB * 1 + 4 * 1/3 = 2.3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以看到, 总成本节省了近乎一半, 听起来很不错.</p> <p><strong>那分层存储是成本优化的银弹吗? 它有什么缺点吗?</strong></p> <p>从技术上来看, 成本的降低是以<strong>牺牲性能和稳定性为代价</strong>的. 可以明确两个信息:</p> <ol><li>从计算机理论基础可以知道, 远程存储的性能肯定是比本地硬盘低的.</li> <li>引入了第三方存储系统, 第三方存储系统的稳定性肯定会影响消息队列集群的稳定性.</li></ol> <p>因为消息队列是一个需要高性能, 高可靠, 高稳定的系统, 所以说分层存储并不是成本优化的银弹.</p> <p>分层存储的价值在于在什么场景中使用它. 这句话怎么理解呢? 还是上节课说到的那句话,  <strong>&quot;用户是多元的, 从而诉求也是多元的&quot;</strong> .</p> <p>从技术上来看, <strong>可以通过技术和运维层面的优化, 来提高读取远程数据的性能和稳定性</strong>. 但是在极端场景下, 这两个问题还是无法根治.</p> <p>所以在一些大流量, 不要求高可靠的场景当中, 分层存储是一个很重要的成本优化手段. 但在一些存储成本不高, 对于性能, 可靠性要求却很高的场景中, 就不需要分层存储.</p> <p>总结来说, <strong>分层存储是一个可选项, 而不是必选项, 是一个用户可控开关的特性</strong>.</p> <h5 id="实现分层存储的技术思考"><a href="#实现分层存储的技术思考" class="header-anchor">#</a> 实现分层存储的技术思考</h5> <p>接下来看看技术上如何实现分层存储, 以及有哪些技术要点需要注意.</p> <p>先从开启分层存储后, <strong>数据的流动路径</strong>来理解一下分层存储在功能方面的表现.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1be63302d53b8b549674f2bc7563382b-20240421231949-dbqszp4.jpg" alt=""></p> <p>参考图示, 可以知道:</p> <ol><li>客户端的生产消费还是原先的流程, 从分区 Leader 所在的 Broker 进行生产消费.</li> <li>Broker 收到数据后, 还是将数据写入到<strong>本地存储</strong>. 当开启分层特性后, Broker 内部会有一个模块(可以理解为一批线程)根据设置的分层策略, <strong>将本地的分段文件数据上传到远端的分布式文件系统中</strong>.</li> <li><strong>消费时如果数据还留在本地, 则直接读取本地数据然后返回; 如果数据不在本地, 就从远程读取返回给客户端</strong>.</li></ol> <p>结合上面的流程, 从技术上分析, 实现分层存储主要需要关注 <strong>远程文件系统的选择, 生产性能优化, 消费性能优化, 隔离性和回滚</strong> 等四个方面. 接下来依次来分析一下, 先来看一下如何选择合适的分布式文件系统.</p> <h6 id="选择远程文件系统"><a href="#选择远程文件系统" class="header-anchor">#</a> 选择远程文件系统</h6> <p>先来看下图, 回顾一下前面讲过的消息队列底层消息数据的分段存储结构.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1cb88018d4yy166ecd477c766ce66a13-20240421231949-2389kpe.jpg" alt=""></p> <p>基于这个存储模型, 从业界落地的角度来看, <strong>目前最适合分层存储的分布式文件系统一般是各个云厂商提供的对象存储服务</strong>. 因为对象存储作为云上的基础组件, 稳定性和成本都具有较高的优势. 而如果希望自建服务, 一般会选择 HDFS.</p> <p>在分层存储架构中, 最核心的就是<strong>读写性能和优化</strong>, 这关系到消息队列的性能表现. 接下来就来看看分层存储在生产和消费时的性能优化方案.</p> <h6 id="生产性能优化"><a href="#生产性能优化" class="header-anchor">#</a> 生产性能优化</h6> <p>先来看一下生产性能的优化.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/cebb3a89d340030d6622f9cc435d348f-20240421231949-eck6cb2.jpg" alt=""></p> <p>如上图所示, 从生产的角度来看, 因为数据是写入到本地文件, 然后再通过异步线程上传到远端文件系统, 所以从性能的角度看, <strong>写入性能基本不受影响</strong>. 只有异步线程上传或下载文件时, 对资源的占用(比如对 CPU, 内存, 网卡, 硬盘等), 可能导致写入性能受到影响. 这部分的优化, 一会儿讲隔离性的时候再展开.</p> <p>而如果是实时写入远程存储的方案, 性能肯定会受到影响, 此时从技术上来看, 只能通过编码技巧来优化, 从而提高一定的性能. 这块在后面讲 RocketMQ 的实现时再展开.</p> <p>下面再来看一下消费性能的优化.</p> <h6 id="消费性能优化"><a href="#消费性能优化" class="header-anchor">#</a> 消费性能优化</h6> <p>消费流程的细节就比较多了, 核心点在于: <strong>当用户消费的数据在远程不在本地时, 如何高性能地消费数据</strong>. 从技术实现来看, 有以下两种方案:</p> <ol><li><strong>远程的分层文件先下载到本地, 消费请求只从本地硬盘读取数据</strong>.</li> <li><strong>当数据在本地就读取本地的数据, 当数据在远程时, 就流式的从远程存储系统读取数据</strong>.</li></ol> <p>这两种方案的主要区别在于: 远程数据的读取方式不同, 从而导致消费性能和开发复杂度的差异.</p> <p>先来看第一种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/454db96398682b55efb04a208e1a7f4a-20240421231949-yzzjaza.jpg" alt=""></p> <p>如图所示, 消费请求只从本地的硬盘读取数据, 同时有一个异步线程根据设置好的预读策略, 提前调度, 从远程下载接下来可能会消费的数据, 再写入到本地, 供消费请求读取. 这里的核心就是 <strong>预读算法</strong> 的设计.</p> <p>从技术上来看, 消息队列的预读算法比较好实现, 因为消息队列都是顺序消费的模型, 所以消费时自然就知道接下来消费哪些数据, 只要<strong>提前下载好下一份数据分段</strong>即可.</p> <p>但是预读算法无法做到完美, 还是会存在冷启动的情况. 比如初始化消费分组消费数据或在消费过程中重置消费位点时, 可能出现数据不在本地的情况, 此时就需要先把数据下载到本地, 然后才能消费, 此时消费就会有卡顿. 这个问题是无法避免的, 但是它只会出现在初始化和重置消费位点等场景, 并且也可以通过一定的技术手段来优化, 影响较小.</p> <p>该方案的优点是, <strong>可以通过预读, 批量读等手段提前将数据下载到本地, 从而保证原先的消费流程不变, 理论上如果全部命中热读, 性能可以和非分层架构保持一致</strong>. 缺点是下载数据写入到硬盘, 可能会占用硬盘空间, 影响 IOPS 性能, 并且会占用 Broker 节点的带宽, 此时可能会影响读写的性能. 因为理论上会有冷启动的情况, 所以此时消费性能就会低于非分层.</p> <p>再来看第二种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/def9a64122a405b1011f9c15f332a08d-20240421231949-29pfqpb.jpg" alt=""></p> <p>如图所示, 消费数据的时候先判断数据是否在本地, 在的话就读取本地数据; 不在的话, 则直接通过远程存储提供的 SDK 去流式地读取数据, 然后在内存中将流数据转成 FetchRecord, 返回给客户端.</p> <p>这种方案的好处是, 当数据在本地时, 性能理论上和非分层可以对齐. 读冷数据时无需将数据写入到本地硬盘, 因此不会对本地硬盘的写入 IO 和空间造成挤占. 缺点是远程存储性能较低, 直接远程读取数据的性能, 肯定会低于非分层的性能, 另外也会占用网卡带宽.</p> <p>理论上来说, 如果第二种方案中的性能问题能够通过技术手段解决, 那么就可以优先选择第二种方案. 但是从具体代码落地来看, 纯技术手段很难使性能和第一种方案对齐.</p> <p>所以, 在我看来, <strong>短期内第一种方案是比较常用的选择</strong>. 在第一种方案成熟后, 再探索第二种方案.</p> <p>接下来看看分层实现过程中的<strong>资源隔离性, 限流, 集群回滚</strong>等操作.</p> <h6 id="隔离性和回滚"><a href="#隔离性和回滚" class="header-anchor">#</a> 隔离性和回滚</h6> <p>隔离性是指如何避免上传和下载的操作过度挤占资源, 导致主流程的生产消费性能受到影响. 上面讲到, 上传和下载操作影响的主要是 CPU, 内存, 网卡和硬盘资源.</p> <p>那么从技术上来看, 在单个进程内是无法做到资源的强隔离的. 但是有几个思路可以了解一下.</p> <ol><li>从 CPU 的角度, 可以通过线程绑核操作, 在一定程度解决 CPU 隔离的问题. 即把上面提到的上传, 下载文件的线程绑定到某一批固定的 CPU 核心上, 从而让 CPU 的消耗控制在一定的范围内.</li> <li>对于内存的占用, 这点就很细节, 比如可以通过堆外内存, Direct IO 等手段, 精细化控制内存, 从而避免消耗过多内存.</li> <li>对于网卡的占用, 从应用程序上看, 没有办法控制程序对网卡的消耗, 但是可以通过控制同一时间上传或下载的文件数和速度, 来避免把网卡的带宽资源用光.</li> <li>对于硬盘 IO 的占用, 在空间层面的占用可以通过扩容存储空间来解决. 对于 IOPS 的占用, 从软件层面来看比较难解决, 但是可以在物理层面通过分盘来实现 IO 隔离, 比如正常的写入操作用 A 盘, 下载操作用 B 盘这样子, 只是分盘操作会增加系统运维的复杂度.</li></ol> <p>这里给一个我的结论, 如果要做到精细的资源隔离, 细节很多, 开发工作量也特别大, 周期会比较长. 并且从理论上讲, 很难做到完美的隔离.</p> <p>所以从具体落地的角度来看, 可以 <strong>通过对上传下载线程数的控制, 上传下载速度的限制, 以及优化预读缓存算法等手段来降低对资源的损耗</strong>. 在这几个操作的基础上, 配合上 CPU 绑核, 内存精细化管理, 就可以做到较好的资源保护.</p> <p>当启动了分层特性后, <strong>单一的消息队列集群就引入了一个远端存储. 此时当远程的存储系统服务抖动或服务不可用后, 就会影响消息队列的集群</strong>, 并且远端集群的异常可能会有很多种, 无法在消息队列集群本身 cover 住所有异常.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/4c39d31342535484dcd2734f13d06291-20240421231949-5r3y6bo.jpg" alt=""></p> <p>所以, 消息队列稳定性的兜底方案是 <strong>回滚</strong>. 即当远端存储服务出现无法解决的问题时, 可以<strong>将集群恢复到非分层的状态</strong>. 从技术上看, 集群抖动时不会影响生产数据的操作, 只是新的数据段不应该再上传到远程存储, 但是会影响老数据的消费, 即如果数据不在本地, 当远程服务异常, 这些数据就无法正常消费.</p> <p>所以回滚的核心分为以下两点:</p> <ol><li><strong>暂停上传</strong>. 即新增的数据段不再上传到远程存储, 都保留在本地, 保证生产和消费都是正常的.</li> <li><strong>消费老数据时提示错误, 只允许消费新数据</strong>. 理论上看, 回滚方案无法解决的就是老数据的消费, 这点是需要重点关注的.</li></ol> <h5 id="业界主流消息队列的架构分析"><a href="#业界主流消息队列的架构分析" class="header-anchor">#</a> 业界主流消息队列的架构分析</h5> <p>业界<strong>主流消息队列 Kafka, Pulsar, RocketMQ 都支持了分层存储</strong>. 因为 Kakfa 和 Pulsar 的实现思路基本一致, 而 RocketMQ 的实现思路不太一样, 所以接下来重点分析一下 Kakfa 和 RocketMQ 分层存储的实现.</p> <h6 id="rocektmq多级存储的实现分析"><a href="#rocektmq多级存储的实现分析" class="header-anchor">#</a> RocektMQ多级存储的实现分析</h6> <p>RocketMQ 把分层存储的特性叫做<strong>多级存储</strong>, 当前 RocketMQ 的多级存储还处于很早期的阶段. 不过已经有一个基础的技术设计了, 接下来就来简单分析一下.</p> <p>前面讲到分层存储的主要思路就是, 异步地将底层分区的数据段上传到远端, 然后消费时再从远端读取数据. 但是 RocketMQ 的实现方式不一样, 它是<strong>通过准实时的方式上传消息, 而不是等一个分段写满后再异步上传</strong>.</p> <p>看一下 RocketMQ 多级存储的架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/851022999cdba63eb39b8915fcf37f5e-20240421231949-7neoat5.jpg" alt=""></p> <p>参考图示, RocketMQ 多级存储的消息上传是由<strong>内核中的 Dispatch 机制触发</strong>的. 初始化多级存储时, 会将 TieredDispatcher 注册为 CommitLog 的 Dispacher. 这样当消息发送到 Broker, 就会调用 TieredDispatcher 进行消息分发. TieredDispatcher 将该消息的引用写入到内存 Buffer 以后立即返回成功. 然后在底层以 Queue 维度构建 CommitLog, ConsumeQueue, 再将文件上传到远端存储中. 这个数据分发上传的逻辑是准实时的, 即处理完部分数据后就会上传到远端存储.</p> <p>从数据读取的角度来看, TieredMessageStore 实现了 MessageStore 中的消息读取相关接口, 通过请求中的逻辑位点判断是否需要从多级存储中读取消息. 如果需要, 读取消息时会预读一部分消息供下次使用, 这些消息暂存在预读缓存中. 预读缓存的设计参考了 TCP 拥塞控制算法, 每次预读的消息量类似拥塞窗口采用加法增, 乘法减的机制控制.</p> <p>从底层的实现来看, RocketMQ 的多级存储还实现了<strong>故障恢复</strong>, 上传进度控制, 分层元数据管理, 广播消费等逻辑. 如果需要的了解更多细节, 可以参考官方的 RIP <a href="https://github.com/apache/rocketmq/wiki/RIP-57-Tiered-storage-for-RocketMQ" target="_blank" rel="noopener noreferrer">RocketMQ Tiered Storage<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. 接下来来看一下 Kafka 分层存储的实现.</p> <blockquote><p>为什么 RocketMQ 使用准实时的方式将数据上传到远端存储引擎呢?</p></blockquote> <p>官方解释如下:</p> <ol><li>均摊成本. RocketMQ 多级存储需要将全局 CommitLog 转换为 Topic 维度, 并重新构建消息索引, 一次性处理整个 CommitLog 文件会带来性能毛刺.</li> <li>对小规格实例更友好. 小规格实例往往配置较小的内存, 这意味着热数据会更快换出成为冷数据, 等待 CommitLog 写满再上传, 本身就有冷读风险. 采取准实时上传的方式既能规避消息上传时的冷读风险, 又能尽快使冷数据可以从多级存储读取.</li></ol> <p>在我看来, 主要原因是 RocketMQ Broker 底层所有 Topic 的消息数据都存储在同一个 CommitLog 文件中. 从业务的角度看, 不是每个 Topic 都需要开启分层, 因此分层特性一般是在 Topic 维度开启的.</p> <p>此时如果要把某个 Topic 的冷数据存储到远程, 就需要从单个 CommitLog 里面把某个 Topic 的数据提取出来, 重新构建成为独立的文件存储到远程. 在重构文件存储结构的过程中, 就会有上面提到的毛刺和冷读风险. 所以 RocketMQ 选择了准实时的方式上传数据到远端存储.</p> <h6 id="kakfa分层存储的实现分析"><a href="#kakfa分层存储的实现分析" class="header-anchor">#</a> Kakfa分层存储的实现分析</h6> <p>从技术实现上来看, Kafka 分层存储的核心思路就是, <strong>将底层分区维度的分段数据上传到远端存储, 在消费时再从远端读取数据返回给客户端</strong>.</p> <p>需要注意的是, 社区版本的 Kafka 的分层存储目前还在开发阶段, 还<strong>不能在业务中使用</strong>. 社区目前的进度是设计出了一个整体的架构, 并实现了一部分核心代码.</p> <p>看一下 Kafka 分层存储的架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e337b80efd58cb3b988b34510d7f43e7-20240421231949-trpufb1.png" alt=""></p> <p>如上图所示, RemoteLogManager(RLM)是一个新的内部组件, 不是一个公共 API 接口. 它的主要作用是:</p> <ol><li>接收处理 Leader 切换和 Topic / 分区的创建, 删除等操作, 然后将 Topic / 分区复制, 读取和删除操作交给 RemoteStorageManager 实现.</li> <li>通过 RemoteLogMetadataManager 维护相应的远程数据段的元数据.</li></ol> <p>RemoteLogMetadataManager 是一个接口, 用于提供具有强一致性语义的远程日志段的元数据的生命周期. 有一个使用内部主题的默认实现. 如果用户打算使用另一个系统来存储远程日志段的元数据, 则可以插入自己的实现, RemoteStorageManager 提供远程日志段和索引生命周期接口.</p> <p>从数据流来看, Kafka 分层存储的核心就是 <strong>上传文件段和从远程读取文件数据</strong>. 从功能上来看, Kafka 上传数据的实现跟我们前面讲到的思路是一样的. 因为读取数据的逻辑官方还没有明确实现, 从技术上看也是上面两种思路, 所以就不再赘述.</p> <p>从实现来看, Kafka 和 RocketMQ 最大的区别在于:</p> <ol><li><strong>RocketMQ 需要将开启分层存储的 Topic 的数据从 Broker 维度的 CommitLog 中分离出来, 重新构建 Topic 维度的 CommitLog, 然后将新的 CommitLog 上传到远程. 而 Kafka 是直接将分区数据段上传到远程</strong>.</li> <li><strong>RocketMQ 是准实时地将数据上传到远程. Kafka 是异步地将文件段上传到远程</strong>.</li> <li>RocketMQ 是实时读数据, 会通过预读算法缓存数据. Kafka 的消费方式官方没有明确实现, 技术上的思路就如上面所讲的两种.</li></ol> <h5 id="总结-37"><a href="#总结-37" class="header-anchor">#</a> 总结</h5> <p>说实话, 分层存储的技术细节特别多, 不是一节课就能讲完的, 这节课只挑了几个主要的技术点来分析讲解. 在不同的消息队列中, 分层存储的叫法不一样. 从技术上来看, <strong>都是基于冷热数据分离的思路, 将冷数据保存到远端存储引擎, 在需要读取数据的时候再从远程读取数据</strong>.</p> <p><strong>分层存储的核心作用就是降低成本, 反作用是性能必然会有所降低</strong>. 因此在一些对性能不敏感的场景, 分层存储能起到节省成本的作用. 而在性能敏感的场景, 不建议开启分层存储.</p> <p>从技术上来看, 分层存储的基础是选择合适的远程文件系统. 从实际落地以及稳定性的角度来看, 云厂商提供的对象存储服务是一个比较优的选择. 如果是自建集群, HDFS 集群是一个可选方案.</p> <p>从性能的角度来看, 生产和消费的性能优化是分层存储的核心. 生产主要关注的是实时写入远程还是异步上传文件到远程, 消费需要关注的是从远程读取数据的方式, 以及预读算法的设计. 集群资源的隔离性以及回滚方案设计, 能够极大地提高消息队列集群的稳定性.</p> <p>业界主流消息队列的分层思路, 主要有<strong>实时写入和异步上传</strong>两种方式. 两种方式的选择主要和消息队列集群的特性相关. 比如 RocketMQ 因为底层文件存储模型的原因, 需要重新构建 Topic 维度的分段文件, 就选择了准实时的方案. Kafka 因为已经是分区维度的分段存储, 则选择的是异步上传分段数据的方案.</p> <h4 id="_38-serverless-如何基于serverless架构实现流式数据处理"><a href="#_38-serverless-如何基于serverless架构实现流式数据处理" class="header-anchor">#</a> 38-Serverless:如何基于Serverless架构实现流式数据处理?</h4> <p>从这节课开始, 将用两节课的内容来梳理一下 <strong>Serverless, Event(事件), 消息队列三者之间的关系和应用价值</strong>. 这节课就聚焦<strong>如何基于 Serverless 架构实现流式处理</strong>, 下节课会详细分析如何基于消息队列和 Serverless 设计事件驱动架构.</p> <p>为什么要搞明白上述问题? 先从一张架构图讲起.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/7b49facf1a4e7f93ab1edc15656d9d26-20240421231949-0hwct2m.jpg" alt=""></p> <p>这是一张消息队列上下游生态的架构图, 分为<strong>数据源, 总线管道, 数据目标</strong>三部分. 可以看到消息队列在架构中处于缓存层, 起到的是削峰填谷的缓冲作用.</p> <p>从技术上看, 构建以<strong>消息队列为中心的数据流架构</strong>, 有很多现成的技术方案和开源框架. 比如分布式流计算框架 Spark/Flink, 开源体系内自带的 Kafka Stream, SeaTunnel/DataX 等数据集成产品, 或者 ELK 体系下的采集和数据处理的组件 Logstash, 都具有处理数据的能力.</p> <p>然而在上面的架构中, 存在一个问题: <strong>每种技术方案所适用的场景不一样, 业务一般需要同时使用多种方案, 而使用和运维多种方案的成本很高</strong>.</p> <p>为了解决使用和运维成本问题, 接下来学习一种非常实用的方案, 那就是<strong>基于 Serverless Funciton 实现流式的数据处理</strong>. 而为了让你对数据流场景有一个更深刻的理解, 先来看几个业务中常见且典型的数据流场景.</p> <h5 id="典型的数据流场景"><a href="#典型的数据流场景" class="header-anchor">#</a> 典型的数据流场景</h5> <p>从业务形态上看, 数据流场景主要可以分为<strong>计算, 集成, 清洗, 容灾</strong> 4 个方向.</p> <ol><li><strong>计算</strong>: 主要<strong>解决流式数据处理计算, 分析, 清洗, 聚合, 转储等需求</strong>. Spark/Flink 是计算方向中的主流解决方案, 其优点是功能和性能都很强大, 几乎可以满足所有流式计算的需求. 缺点是学习和运维成本较高, 在很大一部分简单的数据处理场景(如 ETL)下的投入产出比不高.</li> <li><strong>集成</strong>: 是指<strong>将数据从数据源同步到数据目标的过程</strong>. 链路构成通常为: 数据源, 数据集成套件, 数据目标. 其代表组件为 Flink CDC, Apache SeaTunnel, DataX 等等. 这些组件的优势是具备开箱即用的能力. 缺点是无法满足复杂的计算场景, 遇到一些复杂的计算场景, 需要引入 Spark/Flink. 另外, 一般集成组件底层引擎是 Spark 或 Flink, 在引擎上层做了应用封装, 所以在运维成本上也相对较高.</li> <li><strong>清洗</strong>: 严格来说清洗场景是计算或集成场景下的一个子集, 具备计算, 集成的套件都具备 ETL 能力. 这里的处理指简单的数据清洗, 即将数据简单清洗格式化(不需要计算聚合)后分发到下游. 主要代表组件是 Logstash, MQ Connector. 它们通过简单的语法完成数据的格式化, 清洗, 分发. 优点是使用简单, 运维简单. 缺点是功能场景相对局限, 单一.</li> <li><strong>容灾</strong>: 指<strong>消息队列集群之间的容灾, 即集群间的数据同步, 包括元数据, 业务数据</strong>. 主要解决方案是采用各个消息队列自带的容灾组件, 比如 Kafka/RocketMQ Connector, Pulsar IO, RabbitMQ Federation/Shovel 等等.</li></ol> <p>最后通过一个表格来总结一下这 4 个方向.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c347e83705cfbee5bb1831c7fe390292-20240421231949-vhj3aqd.jpg" alt=""></p> <p>接下来看一下基于 Serverless 架构是如何同时满足上面这四种场景的.</p> <h5 id="什么是serverless"><a href="#什么是serverless" class="header-anchor">#</a> 什么是Serverless</h5> <p>首先得搞明白什么是 Serverless.</p> <h6 id="serverless的定义"><a href="#serverless的定义" class="header-anchor">#</a> Serverless的定义</h6> <p>Serverless 从语义上来讲是 &quot;无服务器&quot;. 从技术架构和底层技术运行的角度看, 服务运行不可能没有服务器. 实际上, <strong>无服务器是从客户的角度来理解的, 指的是客户不需要关心服务器</strong>. 某种意义上看, 不关心相当于没有, 因此是 <strong>Serverless 平台来负责服务器资源管理及运行</strong>.</p> <p>举个例子来说明一下. 现在使用 Kubernetes 和容器, 研发或运维需要负责服务器的部署, 运行, 扩容, 故障处理, 但是如果使用 Serverless 的 Kubernetes 集群, 就不需要关心这些细节, 只要负责使用即可. 集群的安装, 部署, 运行, 调度, 扩缩容都会由平台帮忙实现.</p> <p>目前业界 Serverless 的理念已经融入到各个领域, 比如 Serverless 数据库, Serverless 消息队列等等. 目前 Serverless 主要的产品形态是 Serverless Funtion.</p> <p>这节课的核心思路就是 <strong>基于 Serverless Function 来实现简单, 轻量的数据流动</strong>. 所以接下来还得了解一下什么是 Serverless Function.</p> <h6 id="serverless-function"><a href="#serverless-function" class="header-anchor">#</a> Serverless Function</h6> <p>Serverless Function 是指 <strong>运行在 Serverless 平台中的函数段</strong>. 这里的函数和任何一个开发语言中函数的概念是同一个. 比如下面是一个 Python 函数, 同时也是一个可以运行在 Serverless 平台的函数段.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> logging
logger <span class="token operator">=</span> logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token punctuation">)</span>
logger<span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>logging<span class="token punctuation">.</span>INFO<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">main_handler</span><span class="token punctuation">(</span>event<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">:</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'got event{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;got event{}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">'Hello World!'</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>上面的函数段可以直接提交到 Serverless 平台上运行, 平台会执行整个函数代码流程, 并输出结果. 可以通过 Serverless Function 的生命周期来加深一下理解.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/198fbe710c2d55ace901d27b37c01c16-20240421231949-wnzv5ck.jpg" alt=""></p> <p>参考图示可以知道, 函数的生命周期主要包含 6 个阶段:</p> <ol><li><strong>编写代码段</strong>, 即写一个函数.</li> <li><strong>定义一个事件, 即定义在什么情况下触发这个函数</strong>, 比如定义用户上传了一个图片后就需要触发某个函数执行, 这就是一个事件.</li> <li><strong>触发事件, 上传图片成功后, 触发一个事件, 这个事件就会触发函数去运行</strong>.</li> <li><strong>部署函数, 即在函数运行之前, 首先要部署它</strong>. 部署函数本质上就是把这个函数放在一个容器里, 做成一个非常小的镜像, 然后把这个镜像写到 Kubernetes 里去运行.</li> <li><strong>输出结果</strong>, 运行之后, 它会返回一个结果.</li> <li><strong>销毁资源</strong>, 函数运行完成之后, 会将容器销毁.</li></ol> <p>从使用的角度看, Serverless Funciton 和 Spark 很像. 比如用 Spark 之前需要去学习 Spark 的语法, 编写代码逻辑, 然后打包, 最后将包发布到 Spark 集群去运行. 而 Serverless Funciton 是用熟悉的语言, 熟悉的语法去编写函数, 然后提交到 Serverless Function 平台去运行. 而从学习, 使用, 运维成本的角度看, Serverless Function 会低很多.</p> <p>这节课最重要的几个概念搞明白了, 接下来就来讲一下基于 Serverless Function 实现数据流转的处理流程, 及其底层运行原理.</p> <h5 id="如何基于serverless实现数据处理"><a href="#如何基于serverless实现数据处理" class="header-anchor">#</a> 如何基于Serverless实现数据处理</h5> <p>从基于 Serverless Function 的数据处理流程开始.</p> <h6 id="数据处理流程"><a href="#数据处理流程" class="header-anchor">#</a> 数据处理流程</h6> <p>先来看下面这张图:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e2f67001ef347010536b4d9f15b56967-20240421231949-f984ue0.jpg" alt=""></p> <p>这张图和最开始那张, 最大的区别在于: <strong>把中间这两个处理层替换为了 Serverless Function 平台, 用它来替代流入和流出过程中的多款开源组件</strong>.</p> <p>接下来用经典的数据清洗和转储场景来说明一下它的运行流程.</p> <p>在这个场景中, 可以写一个函数代码段来消费数据, 并做一些处理, 然后写入下游. 代码逻辑是对数据进行处理后, 返回一个新的数据. 代码示例如下:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/51811fdbb80c7ayyeyy64707af5bebe6-20240421231949-13b4xye.png" alt="">​</p> <p>这个代码段在业务量很小时, 只需写个 Cron 定时运行或者单进程运行即可. 当数据量大时再把它放到 Serverless Function 平台去运行. 唯一的区别在于, <strong>运行的地方平台不一样</strong>, 对研发来讲没有重复的开发成本.</p> <p>了解完数据处理流程, 接下来讲一下这个流程的底层架构和技术原理.</p> <h6 id="底层架构和技术原理"><a href="#底层架构和技术原理" class="header-anchor">#</a> 底层架构和技术原理</h6> <p>先来看一张架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ddff516f261d511bae479526da545a2b-20240421231949-ro62rij.jpg" alt=""></p> <p>在这张图中, 从左到右依次是 <strong>输入源, Serverless 调度运行平台, 数据目标</strong> 三部分. 这里面需要重点关注两个部分, 一个是数据源事件的触发方式, 另一个是 Serverless Function 平台的底层运行原理.</p> <p>数据源事件的触发方式, 是指当数据源有数据后, 如何触发下游的函数执行. 从技术上看, 主要有事件触发, 定时触发, 流式拉取 3 种形式.</p> <ul><li><strong>事件触发</strong> 是指数据源接收到某个数据后, 主动触发下游的函数段执行.</li> <li><strong>定时触发</strong> 是指设定时间后触发某个事件, 比如设置为 0 点定时触发平台去运行某个函数代码段.</li> <li><strong>流式拉取</strong> 是指实时不间断地流式拉取数据源的数据, 拉取到数据就触发函数逻辑进行处理.</li></ul> <p>从业界使用来看, 3 种形态都有其适用场景, 属于相互补充的关系.</p> <p><strong>Serverless 运行调度平台</strong> 是指运行函数的平台, 该平台底层的运行核心基本都是 Kubernetes 和容器. 运行的原理是: 先把函数代码段封装在镜像中; 启动时, 调度 Kubernetes 去运行带有代码段的镜像, 并启动 Pod(Pod 为 Kubernetes 中的最小调度对象); 镜像的核心逻辑都运行在这个调度平台里, 因此系统会自动运行函数, 扩容和缩容, 以及上传运行结果等.</p> <p>Serverless 平台的核心竞争力是 <strong>通过灵活的调度能力来提高资源的利用率, 从而降低成本</strong>. 技术上的核心是中间的这层运行调度平台. 调度平台能达到优化成本效果的理论依据是: <strong>下沉和规模效应</strong>. 因为业务都有波峰波谷效应, 多个业务使用同一个平台的话, 就可以通过资源调度, 达到资源复用的效果, 从而提高利用率, 节省成本.</p> <p>所以从实际落地来看, 虽然有一些开源的 Serverless 平台项目, 比如 Knative. 但是还是建议使用公有云的 Serverless 产品, 比如腾讯云, AWS 等等. 因为基于规模效应, 从成本结构来看, 会比自建更有优势.</p> <p>那是不是基于 Serverless 的方案就是完美的呢? 带着这个问题来看一下基于开源方案和基于 Serverless Function 方案的优劣势对比.</p> <h6 id="两种方案的优劣势对比"><a href="#两种方案的优劣势对比" class="header-anchor">#</a> 两种方案的优劣势对比</h6> <p>这里整理了一个表格.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0ca04ec7a9d2d6406d3bc5f17fd29a2a-20240421231949-axl1dne.jpg" alt=""></p> <p>从技术的角度上讲, 当前 Serverless 还处于快速发展阶段, 技术架构和稳定性等都处于快速完善期, 因此会不太稳定, 其本身的运维成本是比较高的. 所以, 它并不能完全替代其他的方案, 而是提供一种可能的选择, 在某些场景下它的表现更优, 比如图片处理, 小流量的流式数据处理, 事件型流处理等. 那么随着云原生架构的成熟, Serverless 方案也会越来越成熟.</p> <h5 id="业务案例和场景分析"><a href="#业务案例和场景分析" class="header-anchor">#</a> 业务案例和场景分析</h5> <p>接下通过日志清洗(ETL)和事件流处理两个场景, 来看一下这个方案实际落地场景及其效果.</p> <h6 id="日志清洗场景"><a href="#日志清洗场景" class="header-anchor">#</a> 日志清洗场景</h6> <p>场景描述: 合作方业务运行时, 每天都要产生大量的日志. 因为业务限制, 不能实时传到流式处理平台. 只能先打包成文件, 然后上传到文件系统, 然后再对日志进行提取, 转换, 并存储到下游, 以进行相关的分析工作.</p> <p>它有 3 个特点:</p> <ol><li>数据量特别大</li> <li>业务有明显的波峰/波谷曲线</li> <li>成本非常敏感</li></ol> <p>在老的架构中, 先后使用过 HDFS + Logstash + Spark 进行日志解压和处理. 日常准备了峰值机器, 在低峰时资源存在严重浪费. 不仅资源成本高, 运维成本也很高.</p> <p>为了解决这个问题, 引入了 Serverless Function 来处理数据. 方案架构图如下:</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3195d7354a7330e04db153f5e9dfb8f4-20240421231949-xamkspn.jpg" alt="">​</p> <p>首先合作方会把日志上传到业务的 HDFS. 这里要经过跨网络传输, 压缩等, 才能存储到统一的 HDFS. 接下来用户需要对 HDFS 的数据进行处理, 业务上有两条链路:</p> <ol><li>先用 Funtion 解压文件, 并进行数据清洗格式化, 再存为 HDFS 作为持久化存储, 最后再进行流式的处理.</li> <li><strong>业务要实时消费</strong>这些日志.</li></ol> <p>在架构中, 解压用的是事件模型, 直接触发函数去运行解压. 其他的处理函数是使用 Python 函数段实现的, 逻辑非常简单. 基于 Serverless Function, 在运行过程中, 因为不用关注下游的数据量, 平台会进行调度, 扩缩容, 平台能够根据流量的曲线调度机器, 节省接近 40% 的成本.</p> <p>下面再来看一个事件流处理的案例.</p> <h6 id="事件流处理"><a href="#事件流处理" class="header-anchor">#</a> 事件流处理</h6> <p>场景描述: 在我们的场景中, 系统中的视频数据, 评论数据, 帖子数据等会实时更新, <strong>中台审核系统需要非常实时地对这些数据进行相应处理</strong>, 例如图片审核, 文本审核, 商品打标, 统一类目, 死链监测, 视频解压分析, 图片转存等.</p> <p>这些业务数据的特点是, <strong>需要非常及时的自动化处理</strong>. 举个例子, 我有个网站, 用户发了一个帖子, 但里面有违规词语需要被禁, 如果没有采用事件模型, 那么在拉取审核的窗口时就会被直接暴露到外网, 产生不好的影响, 这就是事件触发的用途.</p> <p>来看一下基于 Serverless Function 的解决方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/025ba5f30876bcf9ee988c4aab48cb88-20240421231949-u12fygx.jpg" alt=""></p> <p>如上图所示, 消息首先接入 RabbitMQ, 通过事件触发的模型主动触发函数. 它是<strong>推模式(Push), 因此实时性很强</strong>.</p> <p>在之前的课程中讲过推模型的一个缺点, 那就是在业务高峰的时候, 如果下游的处理系统有瓶颈, 就会处理不过来, 导致数据反压, 影响服务端推的性能. 而这种场景正是 Serverless 平台能发挥优势的地方, <strong>容量近乎无限</strong>(依赖平台储备), 弹性扩缩容, 按量付费. 整体算下来, 更省成本, 也更及时.</p> <h5 id="总结-38"><a href="#总结-38" class="header-anchor">#</a> 总结</h5> <p>和当前的开源方案相比, Serverless 在架构理念和设计上是有极大的优势, 在未来也具有很大的想象空间和收益空间. 但是 Serverless 也有一些缺点, <strong>业务使用时需要根据当前的需求进行合理的选型</strong>.</p> <p>从技术上看, Serverless 也会涉及到一些<strong>冷启动问题</strong>. 比如当运行容器数缩减到了 0, 如果有事件触发, 如何才能快速地拉起函数运行呢? 虽然还有很多需要不断迭代和完善的地方, 但从整个架构来讲, 它已经能够带来一定的价值了.</p> <p>长期来看, 基于 Serverles 的流处理方案有几点可以改善.</p> <ol><li><strong>支持持久化的函数运行态</strong>. 函数当前阶段主要是以函数形态短时间运行的, 为了更好地支持稳定的流式处理场景, 需要函数支持持久化运行能力.</li> <li><strong>更多的事件源</strong>. 事件触发模型肯定会比现在的拉模型更及时, 更有效, 更多的事件源也意味着有更完整的生态, 更多的应用场景.</li> <li><strong>丰富的扩缩容因子</strong>. 目前从场景来看, 业务的扩缩容因子相对会很复杂, 比如 Kafka 主要是根据消息的堆积数量, 图片转换场景则是根据仓库中堆积的图片数量来判断是否需要更多的处理能力. 那就需要平台支持更多维度的指标, 比如 CPU, Kafka 堆积消息, 仓库图片数量等来作为扩缩容因子.</li> <li><strong>高阶算子的封装</strong>. 函数编写因为有算子能够使用, 所以不需要很复杂的学习成本, 开箱即用. 后面可以持续探索算子能力, 比如添加一些高阶的算子, 它会带来更多的便利.</li></ol> <h5 id="思考题-28"><a href="#思考题-28" class="header-anchor">#</a> 思考题</h5> <blockquote><p>在你当前的业务中, 还有哪些场景能够基于 Serverless 架构实现数据的流式处理?</p></blockquote> <p>分享一个我的, 数据库订阅场景, 举例说明.</p> <p>如下图所示, 我们的业务需要<strong>将 MongoDB, MySQL, 上游 MQ 等异构数据源同步到 ClickHouse 里面</strong>. 数据源的数据首先同步到消息队列(如 Kafka), 然后进行格式化和数据转换.</p> <p>这里的数据转换不是简单的数据格式化和清洗, 还需要和<strong>第三方系统交互, 渲染数据, 并且还需要多个库</strong>, 多个表之间的数据进行关联, 聚合成一个大列, 另外还有一些业务的特殊逻辑.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/bb9351839ea563f3d8c59d0ab28da8e6-20240421231949-2m1vbhl.jpg" alt=""></p> <p>解决思路依旧是通过 Serverless Function 来实现. 首先编写一段函数逻辑, 逻辑如下:</p> <ol><li>消费 Kafka 的数据.</li> <li>进行格式转换, 多系统交互, 多行合并, 数据裁剪等操作. 虽然看起来很复杂, 但是在函数式编程里面, 其实就是 100 多行代码的实现量.</li> <li>最后将处理完成的数据写入到下游的 ClickHouse.</li></ol> <p>通过这三步就简单地实现了一段函数逻辑, 进而实现了一个实时处理场景, 它和 Spark 的运行效果是一样的, 只是写一个函数的成本和写一个 Spark Jar 包的成本完全不是一个量级.</p> <h4 id="_39-serverless-如何基于mq和serverless设计事件驱动架构"><a href="#_39-serverless-如何基于mq和serverless设计事件驱动架构" class="header-anchor">#</a> 39-Serverless:如何基于MQ和Serverless设计事件驱动架构?</h4> <p>上节课讲了如何基于 Serverless 架构实现流式数据处理. 这节课来看一下<strong>如何基于消息队列和 Serverless 来设计实现事件驱动架构(EDA)</strong> .</p> <p>想必你对事件驱动架构这个词会有点陌生, 为了让你更好地理解它, 先来回顾两个知识点.</p> <ol><li>讲消费者的时候, 讲过消费数据时 Push 模型的实时性是最高的.</li> <li>讲到 Serverless Function 的数据源事件时, 事件源数据的触发方式有一种是事件触发.</li></ol> <p>从技术上来看, 这两个知识点都是<strong>事件驱动架构的一种实现</strong>. 接下来就详细了解一下什么是事件驱动架构, 它有什么用, 以及它的架构和底层运行原理.</p> <h5 id="什么是事件驱动架构"><a href="#什么是事件驱动架构" class="header-anchor">#</a> 什么是事件驱动架构</h5> <p>事件驱动架构, 英文是 Event Driven Architecture, 简称 EDA. 通过下面这张图来认识一下它.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3d3dd08aabb4349a661f86ac4b0c80df-20240421231949-51x7chq.jpg" alt=""></p> <p>如上图所示, 这是从事件驱动架构抽象出来的架构图, 图中包含了 <strong>事件源, 事件处理平台(事件总线), 事件目标</strong> 三个部分.</p> <ol><li><strong>事件源就是数据源, 一个事件可以理解为一个数据</strong>. 比如业务定义了一个事件, 然后投递到了事件处理中心, 本质上就是投递了一个数据.</li> <li><strong>事件处理平台</strong>(在公有云产品化后一般叫做事件总线)负责接收和持久化存储不同事件源的事件, 然后根据设置好的事件规则触发执行不同的业务逻辑.</li> <li><strong>事件目标包含事件目标和目标调用两部分</strong>. 事件目标一般是实体, 比如 HTTP/TCP Server, 某个存储引擎等等. 目标调用是一个动作, 比如 HTTP API 调用, 调用引擎客户端 SDK 写入数据等等.</li></ol> <p>所以说, <mark><strong>事件驱动架构是指主动拉取或被动接收上游不同事件源的数据, 然后根据配置好的事件规则, 触发执行不同的业务逻辑</strong></mark>.</p> <p>此时就有一个问题: 既然事件是数据, 那这个数据是什么格式的呢? 从本质上来看, 数据分为格式和内容两部分. 比如下面是一个 JSON 格式的事件数据, 该数据包含事件类型和事件值两个内容.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;EventType&quot;</span><span class="token operator">:</span> <span class="token string">&quot;UploadImage&quot;</span><span class="token punctuation">,</span> 
  <span class="token property">&quot;EventValue&quot;</span><span class="token operator">:</span><span class="token string">&quot;{}&quot;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>从技术上来看, <strong>格式和内容是由事件处理平台规定</strong>的. 此时就会出现不同事件处理平台设计的格式和内容都不一样, 从而会导致下面两个问题:</p> <ol><li>从用户的角度看, 不同事件平台事件定义不一样, 当用户需要切换平台时就需要修改代码以匹配新的事件平台. 因此就会造成用户和平台发生绑定, 无法低成本地切换到其他事件平台.</li> <li>从平台角度来看, 自定义规定格式和内容会增加重复开发和设计的成本, 长期来看也不利于行业的发展.</li></ol> <p>因此为了解决事件定义和描述的规范化, CNCF Serverless 工作组提出了 CloudEvents 的概念, 用来<strong>制定统一的事件标准, 比如请求方式, 内容格式, 内容组成等等</strong>. 接下来看看什么是 CloudEvents.</p> <h6 id="什么是cloudevents"><a href="#什么是cloudevents" class="header-anchor">#</a> 什么是CloudEvents</h6> <p>CloudEvents 是一个开源项目, 它的目的是 <strong>定义通用的, 标准化的事件格式</strong>. 用来简化事件驱动架构中的事件发布, 订阅和处理流程. 它<strong>规范定义了事件的结构和元数据, 使得不同的事件源, 中间件和消费者之间可以更容易地进行相互操作</strong>.</p> <p>它的主要目标是:</p> <ol><li>提供一种通用的事件格式, 以便在不同的云服务和应用程序之间传输事件.</li> <li>使事件驱动的系统更加可扩展, 可维护和可重用.</li> <li>降低事件生产者和消费者之间的耦合度, 简化事件处理流程.</li></ol> <p>如下图所示, CloudEvents 规范包括<strong>事件上下文, 事件数据, 传输协议</strong>三个部分.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fca17093f74881dcdc0ddd9ff18be5c5-20240421231949-wk2nspk.jpg" alt=""></p> <ol><li><strong>事件上下文</strong>: 包含事件的元数据, 如事件类型, 事件源, 事件 ID 等.</li> <li><strong>事件数据</strong>: 包含事件的有效负载, 即与事件相关的具体信息.</li> <li><strong>传输协议</strong>: 定义了如何在不同的系统和服务之间传输事件, 例如 HTTP, MQTT, AMQP 等.</li></ol> <p>从整体来看, 如果事件处理平台适配了 CloudEvents 标准, 用户就可以更容易地构建事件驱动的应用程序, 同时确保它们在不同的云平台和服务之间具有良好的互操作性. 如果需要了解更多技术的细节, 可以去看一下 <a href="https://cloudevents.io/" target="_blank" rel="noopener noreferrer">官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 和 <a href="https://github.com/cloudevents/spec/blob/main/cloudevents/languages/zh-CN/primer.md" target="_blank" rel="noopener noreferrer">官方 Github 项目<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>接下来通过几个事件驱动架构中的典型应用场景, 来认识一下它在业务中的价值, 也让你对事件驱动架构有一个更深的理解.</p> <h5 id="业务中的典型应用场景"><a href="#业务中的典型应用场景" class="header-anchor">#</a> 业务中的典型应用场景</h5> <p>这里主要讲自动化运维, 应用连接和集成, 商品订单中台三个比较典型的场景.</p> <h6 id="自动化运维"><a href="#自动化运维" class="header-anchor">#</a> 自动化运维</h6> <p><strong>事件总线</strong>的一个典型场景就是自动化运维.</p> <p>如下图所示, 在业务架构中, 系统异常时肯定会有一些指标异常. 正常处理逻辑是: <strong>收集基础指标并上报后, 根据一定的规则对源数据进行过滤或聚合, 然后触发告警推送后续的自动化处理流程</strong>.</p> <p>而为了达到这个效果, 就需要进行一些代码开发和系统对接的工作. 如果引入事件总线, 就可以省去这部分的工作量.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/df8e54da4f441f1fe53d3869f5589f4e-20240421231949-8kusj2m.jpg" alt=""></p> <p>如上图所示, 业务采集异常指标后, 可以通过<strong>事件处理平台开放的 API(比如 CloudEvent API )进行上报</strong>. 事件处理平台接收, 存储事件数据, 将这些数据聚合, 过滤, 处理, 然后根据预先设置的规则, 完成消息的推送与自动化处理.</p> <p>从使用者的角度上看, 满足这个需求只需要 &quot;根据事件平台定义的规范上报数据&quot; 和 &quot;配置数据的处理规则&quot; 两个工作, 开发实现的成本会降低很多.</p> <h6 id="应用连接和集成"><a href="#应用连接和集成" class="header-anchor">#</a> 应用连接和集成</h6> <p>接下来看看应用连接和集成的场景.</p> <p>工作中会使用邮件进行交流, 那么在邮件安全审核场景, 当收到某些特殊的邮件后, 就需要触发下游的安全审核, 深度木马分析等等动作.</p> <p>正常流程是: 开发一段代码对接安全审核系统, 收到邮件后进行初步的审核. 当发现可能有风险的邮件后, 就根据安全系统定义的 API 将邮件数据投递过去. 如果还需要对接其他业务系统, 也需要重复整个过程, 因此重复开发成本和维护成本就很高.</p> <p>为了解决这个问题, 可以引入事件处理平台.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/55bc853ba1bf0f2e7888cb871e59fc02-20240421231949-np375nk.jpg" alt=""></p> <p>如上图所示, 邮件系统对接事件中心, 将有风险的邮件数据上报到事件处理平台. 事件处理平台会根据事先设定的规则, 自动化调用对应系统的接口进行投递.</p> <p>从邮件业务开发的角度, 工作量只剩对接事件处理平台. 而且当需要接入其他业务时, 只需要在事件处理平台添加新的事件处理规则即可, 没有重复的开发工作量.</p> <h6 id="商品订单中台"><a href="#商品订单中台" class="header-anchor">#</a> 商品订单中台</h6> <p>最后来看一个比较复杂的商品订单中台场景.</p> <p>当前不少企业都会通过 ERP, CRM 等内部系统来实现企业数字化. 此时就会出现多项系统彼此闭环, 数据难以统一管理的问题. 为了解决它, 就需要拥有一套数据连接聚合系统, 把数据汇总起来. 如果全部自定义开发, 成本就很高, 此时就可以引入事件驱动架构.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/5c110ee9145131105a1fff74d66e02ba-20240421231949-6fpyfbz.jpg" alt=""></p> <p>如上图所示, <strong>事件处理平台提供了统一的事件投递规范</strong>. 业务方产生的不同类型事件(如用户下单, 商品入库, 订单更新等), 通过 CloudEvent API 以相同规范进行投递. <strong>由事件处理平台进行事件的过滤, 提取后, 根据配置的不同路由规则, 将对应事件投递给相应的处理目标, 完成事件的自动化处理</strong>.</p> <p>在这个场景下, 事件处理平台完成了类似业务中台的基础能力. 企业也可以基于事件处理平台提供的接口规范以及路由原则, 将事件处理平台作为底层架构, 完成更复杂的业务中台搭建, 从而简化开发成本.</p> <h5 id="如何构建事件处理平台"><a href="#如何构建事件处理平台" class="header-anchor">#</a> 如何构建事件处理平台</h5> <p>在了解了事件处理平台的典型应用场景之后, 来看一下如何构建事件处理平台.</p> <p>先来看一张整体的架构图. <strong>事件处理平台分为接入层, 缓存层, 运行层, 分发层四个部分</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e582a225a9yy4aa3edba2e71f2e57cd8-20240421231949-6qico74.jpg" alt=""></p> <h6 id="接入层"><a href="#接入层" class="header-anchor">#</a> 接入层</h6> <p>接入层顾名思义就是用来<strong>接收事件数据</strong>的. 从功能来看, 有<strong>被动接收和主动拉取</strong>两种形态.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6752e3e9aa2cbd9e11b1d743fb0166a7-20240421231949-q4l4qqz.jpg" alt=""></p> <p><strong>被动接收</strong> 是指开发部署维护支持 HTTP, CloudEvent 等协议的 Server, 并设计上报协议. 客户端会根据 Server 规定的协议组织数据并完成上报.</p> <p><strong>主动拉取</strong> 是指客户端没有上报的能力, 需要事件处理平台通过一定的方式去事件源拉取事件数据. 比如, 数据库类的事件源(MySQL Binlog, Mongo ChangeStream 等), 就需要事件处理平台去主动订阅.</p> <p>从技术上看, 被动接收一般通过维护接收数据的 Server 的集群来实现, 需要关注集群的容量和稳定性. 主动拉取一般通过一些开源的方案, 如 Kafka Connector, Flink CDC, Debezium 等来订阅数据源的数据. 或者走纯自研路线, 从数据源订阅数据, 自研路线的好处就是代码可控性高, 底层原理和开源方案差不多.</p> <h6 id="缓存层"><a href="#缓存层" class="header-anchor">#</a> 缓存层</h6> <p>从技术上看, 缓存层一般使用的是<strong>消息队列集群</strong>, 比如 Kafka, Pulsar, RocketMQ 等. 需要关注以下 3 个问题:</p> <ol><li><strong>消息队列集群的性能</strong>. 即集群的容量, 这个一般是业务根据数据源的数据量进行评估.</li> <li><strong>数据的可靠性</strong>. 即接收保存数据后, 需要保证数据不会丢失. 这个一般需要关注集群的副本数量和一致性协议的选择.</li> <li><strong>事件数据存储方式</strong>. 即事件源肯定是有归属的, 比如事件是归属某一个客户或某一个业务, 此时如果有多个事件源, 底层如何保存数据.</li></ol> <p>前两点很好理解, 关于第三点, 你可能有点模糊, 下面重点讲讲.</p> <p>如下图所示, 假设有 7 个事件源(以不同颜色区分). 此时如果所有的事件都存储在一个分区或 Topic 里面, 当某个事件源数据量太大导致消费堆积时, 同一个分区里面其他事件源的事件处理就会受到影响.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/cd946fe51f5f45840489aaff22a73862-20240421231949-4x9jiu3.jpg" alt=""></p> <p>此时就得考虑事件数据存储方式. <strong>所有的事件源存储在一起, 还是每个事件源都进行独立的分区或 Topic 存储</strong>. 使用哪种方案更合理呢? 它们各自存在什么问题? 又如何解决?</p> <p>如果所有的事件数据都存储在同一个 Topic 或者分区里面, 此时一旦某个事件源的数据很大导致消费堆积时, 必然会影响其他事件源数据的处理. 而这个问题是无法根治的, 所以合理的方案是, <strong>每个事件源的底层都是单层存储</strong>.</p> <p>那么使用独立的存储模型, 应该选择每个事件源一个 Topic, 还是每个事件源一个分区呢?</p> <p>从技术上来看, 建议<strong>选择每个事件源一个独立的 Topic 存储</strong>. 当数据量小时, 每个 Topic 只有一个分区. 当数据量大时, 可以扩容 Topic 的分区数.</p> <p>此时如果还出现消费堆积的话, 可以通过扩容分区, 调整消费者的消费模型来提高消费速度.</p> <p>从技术上来看, 需要拆分集群缓存数据. 比如可以根据固定的容量拆分, 根据 Topic 数, 分区数等, 或者根据大客户, 中长尾客户进行拆分.</p> <h6 id="运行层"><a href="#运行层" class="header-anchor">#</a> 运行层</h6> <p><mark><strong>运行层主要用来执行事件处理, 过滤, 分发的逻辑, 相当于事件总线的内核</strong></mark>. 它主要有三个功能.</p> <ol><li>提供接口给用户配置事件规则相关的信息, 提供增删改的接口, 并持久化存储这些数据.</li> <li>从缓存中拉取数据, 根据预先配置好的规则对数据进行处理, 过滤, 聚合.</li> <li>对处理完成的数据, 匹配对应的规则触发调用分发层的接口.</li></ol> <p>运行层需要关注它底层的运行时是什么? 如下图所示, 从技术上来看, 有<strong>内置固定规则运行时和 Serverless 运行时两种形态</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/900d69eac4d42d46945407548003f03f-20240421231949-54h4p8t.jpg" alt=""></p> <p><strong>内置固定规则运行时</strong>, 是指通过编码实现固定的业务处理, 分发逻辑. 然后用户通过一些配置项来配置事件处理规则或分发策略, 从而触发固定的逻辑处理.</p> <p>从技术实现来看, 这种运行时底层一般是基于自定义编码, Flink/Spark 等来构建的. 因为本质上运行时是一个计算层, 即拉取数据然后处理. 而大数据框架 Flink/Spark 擅长处理的就是这个场景. 这种方案的好处是用户开箱即用, 使用成本低. 缺点是平台开发成本较高, 不够灵活, 无法满足客户复杂的定制需求.</p> <p><strong>Serverless 运行时</strong>, 是指底层的部署形态是 Serverless Funciton. 即用户可以通过自定义编写, 修改函数来实现自定义的逻辑.</p> <p>比如事件数据处理时, 需要从某个第三方系统拉取一些数据进行汇总和计算, 这种就算是特殊的自定义逻辑. 这种场景就很适合使用 Serverless 运行时. 这种方案的好处就是非常灵活, 基本可以满足所有场景. 缺点是用户需要付出一定的编码成本.</p> <p>从业界落地来看, 事件处理平台都会同时支持这两种运行时, 以满足更多用户的需求. 最后来看看分发层.</p> <h6 id="分发层"><a href="#分发层" class="header-anchor">#</a> 分发层</h6> <p><strong>分发层的核心功能就是对接各种下游系统</strong>. 如下图所示, 即集成各种下游系统的 SDK, 比如 HTTP SDK, ES SDK, JDBC SDK 等, 然后供运行层调用. 每种下游系统, 在运行层只需要对接一次即可.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6bf05dc9b6edb4723112b06e37bd254a-20240421231949-1975ldv.jpg" alt=""></p> <p>从使用上看, <strong>运行层执行完计算, 处理, 过滤的逻辑后, 就会调用分发层触发具体的操作</strong>, 比如调用 HTTP API, 将数据写入到 DB 等等.</p> <h6 id="保证数据不丢失"><a href="#保证数据不丢失" class="header-anchor">#</a> 保证数据不丢失</h6> <p>除了架构层面四个部分的实现外, 事件处理平台还需要保证事件数据不会丢失.</p> <p>事件处理平台保证数据不丢失包含下面两层含义:</p> <ol><li>接入层接收成功的事件数据不能丢失.</li> <li>对事件数据的处理必须有结果.</li></ol> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/a0ed79686971aedbafb388a15410db49-20240421231949-vssvtlq.jpg" alt=""></p> <p>第一点比较好理解, 即接入层收到数据后, 需要写入缓存层成功后, 才能返回成功. 还得在缓存系统异常时, 保证数据不能丢失. 这块依赖的就是编码技巧, 以及缓存引擎的选择和使用方式.</p> <p>第二点需要重点关注, 即 <strong>一个事件必须有一个执行结果</strong>, 结果可以成功也可以失败. 成功, 可以是写入或者触发事件目标成功. 失败的话就需要保存相关的日志, 或投递到死信队列.</p> <p>注意, 这里不能出现用户上报事件, 但是这个事件却没有任何执行结果的情况. 即如果只接收到事件, 却没有执行, 那这个事件就相当于丢失了. 为了跟踪事件的处理过程, 就需要记录这个事件的运行轨迹. 此时就可以结合消息轨迹, 以及一些开源的可观测性方案(比如日志 + 监控 + Prometheus + Grafana)来观测事件的处理轨迹.</p> <p>最后来看看事件处理过程中, 事件数据的一致性问题.</p> <h6 id="数据一致性语义"><a href="#数据一致性语义" class="header-anchor">#</a> 数据一致性语义</h6> <p>先来看下图, 事件数据在事件处理平台可能是<strong>链式</strong>的处理, 此时一个事件就有可能被传递多次. 那如何保证事件不会被重复投递呢?</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/46e16ef2053b45f8b028c8ecf6fab40e-20240421231949-eqrjwcq.jpg" alt=""></p> <p>这个问题就是事件处理平台中数据一致性语义, 它分为<strong>最多投递一次, 最少投递一次, 精确投递一次</strong>三种情况.</p> <ol><li>最多一次指消息不会被重复发送, 最多被传输一次, 但也有可能一次也不传输.</li> <li>最少一次指消息不会被漏发送, 最少被传输一次, 但也有可能被重复传输.</li> <li>精确一次指不会漏传输也不会重复传输, 每个消息都只会被传输一次.</li></ol> <p>理想情况下, 在每个环节的传递, 处理过程中, 肯定是做到精确一次(Exactly Once)的语义是最好的. 但是前面讲过 Exactly Once 语义需要基于事务实现. 而事务的底层需要基于幂等, 协调者等机制, 性能会降低较多. 并且支持 Exactly Once 会让系统复杂度提升很多. 所以在实际实现中, 一般实现的是 <strong>最少一次</strong> 的语义, 即允许少量的重复, 让业务侧来处理重复的情况.</p> <p>当然, ExactlyOnce 语义也是总线的一个技术优化点, 如果能支持 ExactlyOnce 语义, 将是这款产品的核心竞争力.</p> <p>前面提到过, 事件处理平台在公有云产品化后一般叫做<mark><strong>事件总线</strong></mark>(EventBridge). 所以接下来就来设计实现一个事件总线.</p> <h5 id="设计实现事件总线架构"><a href="#设计实现事件总线架构" class="header-anchor">#</a> 设计实现事件总线架构</h5> <p>先来看一下整体的架构图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0aa9b13c2044a642ed6f1a99da8a6661-20240421231949-u7o73v1.jpg" alt="">​</p> <p>如上图所示, 整个架构分为<strong>数据源, 事件总线, 数据目标</strong>三个部分. 这里主要需要完成的是事件总线部分, 由接入层, 缓存层, 运行层, 分发层四部分组成.</p> <h6 id="核心流程拆解"><a href="#核心流程拆解" class="header-anchor">#</a> 核心流程拆解</h6> <p>在接入层分别提供了支持 HTTP 协议集群, 支持 TCP 协议的集群, 支持 Connector 集群三种形态.</p> <ul><li><strong>HTTP/TCP 协议的集群是用来满足被动接收的场景</strong>. 服务端既支持自定义的上报协议, 也支持标准的 CloudEvent 协议, 用来满足不同场景上报的需求.</li> <li><strong>Connector 集群用来满足主动拉取的场景</strong>. 从技术上看, Connector 集群有自研, 开源两种方案. 开源则包含比如各个 MQ Connector(如 Kakfa/RocketMQ Connector, Pulsar IO 等), Flink CDC 等多种方案.</li></ul> <p>缓存层选择了 Kafka 来作为中间层. 因为它具有高性能, 稳定性强等特性, 能够很好地扛住流量, 长期保存数据.</p> <p>因为选择了 Kafka 当缓存层, 所以接入层的 Connector 集群, 底层是基于 Kafka Connector 实现的. Connector 的作用是去主动订阅数据源的数据, 比如 MySQL Binlog, Mongo ChangeStream 等等. Kafka Connector 的技术细节会在下节课详细展开.</p> <p>在运行层提供了事件相关的元数据的管理, 如事件源/目标, 事件规则的增删改查等等. 同时提供了固定规则运行时和 Serverless 运行时, 来执行固定和灵活的数据处理, 过滤, 聚合等操作.</p> <p>这里选择了 Flink 来作为固定规则运行时的底层框架, 因为 Flink 的生态丰富, 有很多现成的能力可以复用. Serverless 运行时, 则是选择公有云上的 Serverless Function 产品, 比如腾讯云的云函数.</p> <p>在分发层它主要是一段代码库, 通过集成不同引擎的 SDK, 对接不同的下游引擎. 这块就比较简单, 不再赘述.</p> <p>讲完了架构图的核心处理流程, 从技术上来看, 还是有很多技术细节需要考虑, 来简单看一下.</p> <h6 id="技术细节"><a href="#技术细节" class="header-anchor">#</a> 技术细节</h6> <ol><li><strong>引入 Schema, 即事件数据在事件总线中传输, 也有上下游的概念</strong>. 需要保证事件数据在传递过程中, 是具备一定的规范格式的. 需要注意的是, 这里的 Schema 和消息队列的 Schema 概念有点不一样. 不过事件总线 Schema 的实现底层有一部分是可以基于消息队列 Schema 来实现的.</li> <li><strong>接入层/分发层如何快速集成更多的数据源和目标</strong>. 即在实际开发过程中, 需要对接各种各样的数据源. 此时就需要思考如何能够低成本地对接各种新的数据源. 从技术上看, 主要是插件化, 代码复用, 直接利用开源的插件等几个思路. 其中在开源的插件上二次开发是一个推荐的方案.</li> <li><strong>接入层集群的拆分, 扩缩容, 安全控制如何设计</strong>. 因为接入层集群是暴露在公网的, 流量也是最大的, 所以需要考虑是否给大客户部署独立的接入层集群, 如何快速地扩缩容(比如容器化), 如何给接口增加鉴权, 支持 TLS/SSL 协议, 防范 DoS 攻击等等.</li> <li><strong>缓存层的容量拆分问题</strong>. 从技术上来看, 缓存层主要是运维层面需要关注的, 主要需要关注集群的运行水位. 另外研发层面需要关注事件在缓存层的存储模型.</li> <li><strong>运行时固定规则的设计</strong>. 这块属于功能层面的设计, 即事件总线能支持怎样的事件处理规则, 比如数据清洗, 数据过滤, 数据聚合, 数据投递等等. 这块考验的是产品经理的设计, 技术上实现就还好.</li> <li>运行时如何集成 Serverless Function. 即如何考虑快速集成 Serverlss 运行时, 并做到 Serverless 运行时的可视化, 保证出问题时可以有告警, 能快速定位到问题等等.</li></ol> <h5 id="总结-39"><a href="#总结-39" class="header-anchor">#</a> 总结</h5> <p><strong>事件驱动架构(EDA)也称为事件总线, 它的作用是主动拉取或被动接收上游不同事件源的数据, 然后根据配置好的事件规则, 触发执行不同的业务逻辑</strong>.</p> <p>在事件驱动架构中传递的数据称为事件, 事件由格式和内容两部分组成. 为了规范数据的格式和内容, 业界推出了 CloudEvents 规范, 目的是定义通用的, 标准化的事件格式. CloudEvents 规范由事件上下文, 事件数据, 传输协议三部分组成.</p> <p>事件驱动架构在自动化运维, 数据集成, 业务数据中台等场景中有着广泛的应用.</p> <p>从技术上来看, 事件驱动架构由数据源, 事件处理平台, 数据目标三部分组成. 其中时间处理平台是架构的核心, 它由接入层, 缓存层, 运行层, 分发层四部分组成. 事件处理平台在处理事件的过程中, 需要注意保证数据不丢失, 并保证数据具有一定的一致性语义. 运行时来满足多种业务场景.</p> <p>流的事件驱动架构来看, 接入层一般会适配多种协议(比如基于 HTTP 或 TCP 的自定义协议或标准协议)来满足业务主动上报的场景, 同时也会提供主动订阅的组件(比如 Connector 集群, Flink CDC 集群等等)来订阅数据源的数据. 在缓存层, 一般选择能承载大流量的流场景的组件, 比如选择 Kafka, Pulsar 来作为业务管道. 运行层会同时支持固定规则的运行时和 Serverless 运行时. 分发层就比较简单, 定义接口, 调用下游的 SDK 写入数据即可.</p> <h4 id="_40-连接器-如何以mq为核心搭建数据集成架构"><a href="#_40-连接器-如何以mq为核心搭建数据集成架构" class="header-anchor">#</a> 40-连接器:如何以MQ为核心搭建数据集成架构?</h4> <p>这节来聊聊连接器. 在消息队列中, 连接器也称为 Connector, 它的作用是<strong>把不同数据源中的数据导入到消息队列, 或者把消息队列中的数据导出到下游的各种存储引擎</strong>. 连接器对于用户的价值是, 可以很方便地将数据导入, 导出消息队列.</p> <p>听起来, 它和前面两节课中讲的基于 Serverless 实现流式计算和事件驱动架构的作用很类似, 从功能上看, Flink 或 Spark 也能实现. 那为什么还有连接器这个概念呢? 它的价值是什么?</p> <h5 id="连接器是什么"><a href="#连接器是什么" class="header-anchor">#</a> 连接器是什么</h5> <p>从技术上来看, 连接器中的 &quot;连接&quot; 指的是数据的连接, 即把数据从某个地方搬到另外一个地方. 所以连接器就是指 <strong>将数据从源端搬到目标端的组件</strong>. 或者说只要具备数据连接功能的组件, 就可以称为连接器.</p> <p>同样的, 消息队列连接器的功能也是把数据从源端搬到目标端. 但和普通连接器不同的是, <strong>消息队列连接器的其中一端一定是消息队列</strong>.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/71a59faf3747f97d400c43cc5feb32c8-20240421231949-jdtzp5j.jpg" alt="">​</p> <p>如上图所示, <strong>业界主流消息队列 Kafka, RocketMQ, Pulsar 都支持连接器的概念, 组件名称分别是 Kafka Connector, RocketMQ Connector, Pulsar IO</strong>. 从功能上来看, 消息队列连接器分为 <strong>源连接器(Source)</strong>  和 <strong>目标连接器(Sink)</strong> , <mark><strong>作用分别是将数据源的数据导入到消息队列和把消息队列中的数据导出到下游的存储</strong></mark>.</p> <p>那这些连接器是如何运行的呢?</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/985b609eca7ff9db422f5ae740a28dyy-20240421231949-gdipyuv.jpg" alt=""></p> <p>如上图所示, 连接器是<strong>运行在多个物理节点(Worker)上的</strong>. 因为连接器需要并发运行多个任务且需要具备横向扩容的能力, 所以连接器运行的平台本质上是一个<strong>分布式任务调度平台</strong>. 这个平台跟 Flink, Spark, Mesos, Yarn 等集群的功能是类似的, 主要负责分布式任务的调度和运行.</p> <p>所以可以说, 消息队列连接器是由 <strong>分布式任务调度平台</strong> 和 <strong>源/目标连接器</strong> 两部分组成. 平台负责这些连接器的运行, 连接器负责对接各种数据源和数据目标.</p> <p>如果你了解过数据集成的话, 还会发现连接器的功能和数据集成很像. 所以接下来看看什么是数据集成, 以及数据集成和连接器的关系.</p> <h5 id="数据集成和连接器"><a href="#数据集成和连接器" class="header-anchor">#</a> 数据集成和连接器</h5> <p>从技术上看, 数据集成是一个概念, 不是具体的功能组件. 它是将数据从数据源搬到数据目标这个功能的描述, 数据从源到目标的过程就称为数据集成.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/262c10c6f709c2325d1325be35e4ca75-20240421231949-ig4058y.jpg" alt=""></p> <p>所以你会发现, 消息队列连接器是数据集成概念下的一种技术. 即消息队列的 Source 和 Sink 连接器都是一种数据集成. 数据集成是一个非常成熟的领域, 业界开源的数据集成就有 Flink CDC, DataX, SeaTunnel 等等.</p> <p>接下来通过一个典型的数据集成场景, 让你对数据集成和连接器有一个更深的认识.</p> <p>场景描述: 将 MySQL 中的数据实时同步到 Elasticsearch.</p> <p>实现这个功能, 有使用典型<strong>数据集成组件和消息队列连接器</strong>两种方案.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2c258e11b541748c3a4e67423d2145f0-20240421231949-lfgb1ld.jpg" alt="">​</p> <ol><li><strong>典型数据集成组件</strong>: 该方案使用开源组件, 如 Flink CDC, DataX, SeaTunnel 等组件, <strong>订阅 MySQL 的数据, 然后把订阅到的数据同步到下游</strong>.</li> <li><strong>消息队列连接器</strong>: 该方案需要先使用源连接器 SourceConnector 从 MySQL 订阅数据, 然后将数据写入到消息队列当中, 再使用 SinkConnector 将消息队列中的数据写入到下游存储引擎.</li></ol> <p>你会发现, 两者的最大差别是: <strong>消息队列连接器需要把数据先存储到消息队列中, 然后再从消息队列中消费数据写入到下游. 看起来是额外存储了一份数据, 有点浪费</strong>.</p> <p>但是可以思考这样一个场景, 如果<mark><strong>源数据需要被分发到下游多个目的地</strong></mark>呢?</p> <p>此时使用典型数据集成组件的话, 就要订阅多次源数据, 可能会对源端造成较大压力. 用消息队列连接器就很合适, 只订阅一次源数据, <strong>借助消息队列的缓存和分发能力, 就能实现多次分发</strong>.</p> <p>所以总结来看, <strong>第一种方案适合数据源和数据目标是一对一的场景, 第二种方案适合数据源和数据目标是一对多的场景</strong>.</p> <h5 id="消息队列连接器底层原理分析"><a href="#消息队列连接器底层原理分析" class="header-anchor">#</a> 消息队列连接器底层原理分析</h5> <p>讲完了数据集成和连接器的关系, 接下来讲一下消息队列连接器的架构和底层运行原理.</p> <p>先来看一张整体的架构图.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/0f2a655a99b8c0ea953ae710324abab5-20240421231949-ehcjc6e.jpg" alt="">​</p> <p>如上图所示, 消息队列连接连接器由 <strong>数据源, 源数据连接器, 分布式任务调度平台, 目标数据连接器, 数据目标</strong> 五部分组成.</p> <p>从技术上来看, 连接器的内核主要包括以下三部分内容:</p> <ol><li>分布式任务调度平台的开发和设计</li> <li>各种源, 目标连接器的开发</li> <li>简单的数据清洗能力</li></ol> <h6 id="分布式任务调度平台"><a href="#分布式任务调度平台" class="header-anchor">#</a> 分布式任务调度平台</h6> <p>分布式任务调度平台, 也称为连接器的 Runtime, 它的作用是用来运行各种 Connector 任务.</p> <p>从实现来看, Runtime 一般有 Connector 和 Task 两个概念. Connector 是一个逻辑概念, 用来表示一个订阅任务. Task 是任务运行的实体, 用来执行各个具体的订阅任务. 就是说 Runtime 里面会运行多个源/目标 Connector, 一个 Connector 会被拆分为多个 Task 运行, Task 是 Runtime 调度的最小单位.</p> <p>从功能角度, Runtime 一般需要具备以下四个功能:</p> <ol><li><strong>HTTP API</strong>, 提供增删改查 Connector 任务, 启动, 暂停, 扩容, 缩容等操作的 API 接口.</li> <li><strong>元数据存储</strong>, 用来保存集群 / Connector 基本信息, Connector/Task 运行信息(比如运行在哪些节点上, 当前运行状态等), 执行节点的基本信息等等.</li> <li><strong>调度模块</strong>, 用来完成 Connector 任务的拆分, 调度, 启停, 扩容等等.</li> <li><strong>任务执行节点</strong>, 用来执行各种 Connector 和 Task 任务.</li></ol> <p>接下来通过 Runtime 集群启动过程和 Connector 任务运行过程来认识一下这四个功能.</p> <p>先来看一下 Runtime 集群的启动过程.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/b850e2003f772e1c434d8e6eded24b57-20240421231949-dfzlnrd.jpg" alt=""></p> <p>如上图所示, 因为 Runtime 是集群部署, 集群由多个任务执行节点组成. 所以同样也需要有 <strong>节点发现, 元数据存储, 主节点, 节点探活</strong> 等流程. 这部分的原理前面讲过, 就不再赘述. 这里需要注意的是, 集群启动后需要启动内置的 HTTP Server, 比如支持 RESTful API, 来提供集群管控类操作.</p> <p>集群启动完成以后, 以<strong>订阅 MySQL 的 Binlog 数据到消息队列的场景举例</strong>, 来看看 Runtime 运行 Connector 的整体过程.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/306cc3108e012587b05aaf6483f72afc-20240421231949-o1xm6sm.jpg" alt=""></p> <ol><li>通过 HTTP RESTful 接口<strong>创建订阅 MySQL Binlog 到消息队列的 Source Connector</strong>.</li> <li>Runtime 收到请求后, 先保存 Connector 相关的元数据信息. 这个元数据包括 MySQL 的地址, 用户名, 密码以及消息队列的地址, Topic, Connector 最大任务数等信息. 元数据可以保存在消息队列的内置的 Topic, ZooKeeper, etcd 等引擎中.</li> <li><strong>保存完元数据后, 接下来 Runtime 会根据 Connector 配置的任务数, 在不同节点创建 Task</strong>. Task 从本质上看就是线程, Runtime 会控制多个 Task 分布在多个不同执行节点上.</li> <li><strong>每一个 Task 的核心逻辑是从 MySQL 订阅 Binlog, 然后经过本地处理后, 将订阅到的数据写入到消息队列中</strong>.</li> <li>在执行节点异常时, Runtime 会将异常节点上的 Task 调度到新节点运行.</li> <li>当增加或减少 Task 数量的时候, Runtime 就会通知对应的执行节点执行新增或删除对应的 Task.</li></ol> <p>那 Runtime 是如何通知执行节点执行对应的操作呢?  一般情况下, 每个执行节点会暴露 HTTP 或 TCP 接口来接收 Runtime 的指令, 然后执行对应的逻辑.</p> <p>那 Runtime 里是谁来下发指令或者调度任务的呢? 集群一般有主节点的概念, 集群中的管控操作一般是由主节点来完成的. 而在分布式任务调度平台里面, 道理也是类似的, 这里就不再重复.</p> <h6 id="源-目标连接器"><a href="#源-目标连接器" class="header-anchor">#</a> 源/目标连接器</h6> <p>讲完了分布式任务调度平台, 再来看看源和目标连接器是怎么实现的.</p> <p>连接器的功能是从数据源消费数据写入到数据目标. 所以从技术上拆解连接器, 它应该包含<strong>读取(Read), 本地处理(Local Transforms), 写入(Write)</strong> 三部分.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/fac3b22c311ba685c668c47acb87ed5a-20240421231949-6e684ov.jpg" alt=""></p> <ul><li><strong>读取</strong>, 负责从源端读取数据, 读取方式一般是<strong>主动读取</strong>. 主动读取需要源端支持远程读取. 比如订阅 MySQL Binlog, 可以理解为是通过 TCP 协议去 MySQL 拉取数据. 再比如订阅某个钉钉应用的消息, 就需要通过钉钉某个开放的 HTTP API 去读取数据.</li> <li><strong>本地处理</strong>, 指当数据拉取到本地后, 需要对数据进行格式转换, 类型转换等处理.</li> <li><strong>写入</strong>, 负责将处理完成的数据写入到下游的数据目标, 这块主要是使用下游引擎提供的 SDK 写入数据.</li></ul> <p>上面讲到 Connector 是一个逻辑概念, Task 才是执行的主体. 创建一个 Connector 就是创建一个订阅操作, Connector 的底层会拆分为多个 Task.</p> <p>来看下图, 这是典型的订阅 Kakfa 数据写入到 Elasticsearch 的 SinkConnector 场景. 此时可以设置 Connector 的任务数和分区数保持一致, 以达到最佳的性能.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/6e6a955838c70b749df21f024ce141d1-20240421231949-t5jwu35.jpg" alt=""></p> <p>从代码的角度, Connector 是如何实现的呢? 核心就是先定义 Interface 接口, 然后各个 Source, Sink 插件继承实现接口的具体逻辑, 从而实现具备不同功能的 Connector.</p> <p>如下所示, 简单定义了 Connector 和 Task 两个接口.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">class</span> <span class="token class-name">Connector</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">start</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">class</span> <span class="token class-name">Task</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">start</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">abstract</span> <span class="token keyword">void</span> <span class="token function">execute</span><span class="token punctuation">(</span><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SinkRecord</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">void</span> <span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>可以看到, 我们在 Conenctor 里面定义了 start 和 stop 接口, 分别用于实现 Connector 启动和停止时需要执行的代码逻辑. Task 同样提供了 start, execute, stop 接口, 分别用于实现 Task 启动, 业务逻辑处理, 停止三部分的代码逻辑.</p> <p>接下来来实现一个简单版本的 MySQLSource Connector, 伪代码如下:</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MySQLConnector</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">start</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 配置初始化</span>
        config<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 多个任务初始化</span>
        task<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        task<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MySQLTask</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">start</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 初始化 MySQL</span>
        mysql<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span>var1<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 连接 MySQL 实例</span>
        mysql<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">execute</span><span class="token punctuation">(</span><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SinkRecord</span><span class="token punctuation">&gt;</span></span> var1<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 从 MySQL 订阅数据</span>
        dada <span class="token operator">=</span> mysql<span class="token punctuation">.</span><span class="token function">query</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 对源数据进行格式转换, 处理</span>
        result <span class="token operator">=</span> <span class="token function">transforms</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 写入到目标 Topic</span>
        <span class="token function">writeTopic</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">void</span> <span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 停止 MySQL 连接</span>
        mysql<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><p>execute 方法是整个插件的核心, 业务逻辑都在这个方法里面实现.</p> <p>完成代码编写后, 再将代码打包, 提交到 Runtime 平台运行. <strong>Runtime 会先依次调用 Connector.start() 和 Task.start() 来启动任务, 然后不断地执行 Task.execute() 方法从源端订阅数据进行处理</strong>.</p> <p>从技术上看, Java 运行指定类是通过反射机制来实现的. 讲完了 Connector 编写和设计逻辑, 接下来来看看如何实现简单的数据清洗能力.</p> <h6 id="简单的数据清洗能力"><a href="#简单的数据清洗能力" class="header-anchor">#</a> 简单的数据清洗能力</h6> <p>先来看一下为什么要数据清洗能力(Transforms)呢? 通过一个例子来简单说明一下.</p> <p>来看下图, 图中上半部分是源数据, 下半部分是下游需要的数据.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/2ff11685b03a876e82b00109c9c77dfc-20240421231949-vgp8qzu.png" alt=""></p> <p>从图中可以看到, 源数据是一个 API 接口的返回值, 包含了 9 个字段. 而我们只需要 5 个字段, 而且部分字段的内容是从源数据的某个字段提取出来的. 按正常思路, 这部分逻辑在 Task.execute() 里面自定义实现即可.</p> <p>从实现的角度, 这样做是没有问题的, 但是数据清洗转换是一个很常见的需求, 如果所有插件都自定义实现数据清洗逻辑, 工作量就太大了. 那有没有办法<strong>降低插件开发的工作量</strong>呢?</p> <p>答案是可以的, <strong>可以把数据转换的逻辑放到 Runtime 里面去实现. 连接器中的 Transforms 模块就是做这个功能的</strong>. 下面给一个基础的数据处理功能清单, 来看看 Transforms 都能实现哪些功能.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/88734832ef6ca842c990c1e564f987f9-20240421231949-q6ckug0.jpg" alt=""></p> <p>可以看到, 表格中每一个操作都是很基础的数据格式转换操作. 在数据处理时, 将这些操作组合起来, 就能完成复杂的数据处理操作.</p> <p>下面通过一段伪代码, 来看一下底层是如何基于这些基础操作完成数据清洗的.</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">transform</span><span class="token punctuation">(</span><span class="token class-name">String</span> data<span class="token punctuation">)</span><span class="token punctuation">{</span>
    <span class="token class-name">String</span> data <span class="token operator">=</span> <span class="token function">add_field</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token class-name">String</span> data <span class="token operator">=</span> <span class="token function">replace</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token class-name">String</span> data <span class="token operator">=</span> <span class="token function">rename</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token class-name">String</span> data <span class="token operator">=</span> <span class="token function">uppercase</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token class-name">String</span> data <span class="token operator">=</span> <span class="token function">remove_field</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">return</span> data<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>上面代码表示, 每行数据都要经过添加字段, 替换字段, 重命名变量名, 首字母大写, 移除某个字段这五步逻辑. 这些处理逻辑是在创建 Conenctor 的时候配置好的, 根据定义的配置顺序执行即可.</p> <p>每个基础操作的代码实现, 本质上也是<strong>基于 Interface 和反射机制来实现</strong>的. 跟上面 Connector 和 Task 的逻辑原理是一样的.</p> <h5 id="apache-kafka-connector"><a href="#apache-kafka-connector" class="header-anchor">#</a> Apache Kafka Connector</h5> <p>讲完了连接器架构和底层原理, 接下来就来看看业界主流消息队列连接器的具体实现. RocketMQ, Kafka, Pulsar 都支持连接器的功能. 因为从实现原理来看, 三者基本是一致的, 所以下面就以 Kafka Connector 为例来拆解一下连接器具体的实现.</p> <p>Kafka Connector 是 Apache Kafka 官方支持的一个开源框架, 用于 <strong>将数据从外部系统导入到 Kafka 集群, 或者从 Kafka 集群导出到外部系统</strong>. 先来看一下 Kafka Connector 的系统架构.</p> <h6 id="系统架构"><a href="#系统架构" class="header-anchor">#</a> 系统架构</h6> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/dbf3e58e299e1efyy5e6b854610yy4a0-20240421231949-xkvyzwi.png" alt=""></p> <p>如上图所示, Kafka Connector 的架构主要由几个部分组成.</p> <ol><li>Cluster 表示 Connector 的集群, 也就是前面提到的 Runtime 集群.</li> <li>Connector 是负责管理整个订阅任务的逻辑概念, 它负责组织管理 Task 任务.</li> <li>Task 是执行实际数据传输工作的组件. 一个 Connector 可以有一个或多个 Task, 每个 Task 都是一个独立的数据处理单元, 可以并行运行.</li> <li>Worker 是运行 Connector 和 Task 的节点.</li> <li>Transform 是用于数据转换的组件.</li> <li>Config &amp; Status Storage 用来存储 Connector 和 Task 的配置信息以及运行状态, 这些信息通常存储在 Kafka 的内部主题中.</li></ol> <p>从实现来看, <strong>Kakfa Connector 的 Runtime 就是 Connector 集群, 集群的元数据是存储在 Kakfa 内置的 Topic 中的</strong>. 集群启动后, 它通过暴露 HTTP API 给用户管理 Connector 任务.</p> <p>从功能上来看, Kafka Connector 也分为了 Source Connector 和 Sink Connector.</p> <ol><li>Source Connector 的主要任务是从外部系统(如数据库, 消息队列或文件系统)中提取数据, 并将这些数据转换为 Kafka 可以理解的消息格式, 然后发布到 Kafka 主题中. 每个 Source Connector 可以有一个或多个 Source Task, 每个 Task 负责从数据源读取数据并将其发送到 Kafka. 这些 Task 可以并行运行, 以提高数据处理的吞吐量.</li> <li>Sink Connector 的主要任务是从 Kafka 主题中消费消息, 并将这些消息转换为目标系统可以理解的格式, 然后将数据写入目标系统. 与 Source Connector 类似, 每个 Sink Connector 也可以有一个或多个 Sink Task, 每个 Task 负责从 Kafka 读取数据并将其写入目标系统.</li></ol> <p>了解了 Kafka Connector 的系统架构, 接下来简单来看一下 Connector 暴露出来的 RESTful API.</p> <h6 id="restful-api"><a href="#restful-api" class="header-anchor">#</a> RESTful API</h6> <p>Kafka Connect 提供了一组 RESTful HTTP API, 包含了增删改查 Connector, 修改配置等等, 用来管理和监控 Kafka Connector 集群.</p> <p>下面通过创建 Connector 和获取 Connector 列表接口来简单讲解一下它们的使用.</p> <ul><li>创建 Connector, 你可以使用 POST 请求到 /connectors 端点创建一个新的 Connector. 请求体应包含 Connector 的配置, 请求格式如下:</li></ul> <div class="language-json line-numbers-mode"><pre class="language-json"><code>POST /connectors
<span class="token punctuation">{</span>
  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;my-connector&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;config&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      ...
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><ul><li>获取所有 Connectors, 可以使用 GET 请求到 /connectors 端点来获取所有已经创建的 Connectors 的列表, 请求格式如下:</li></ul> <div class="language-plain line-numbers-mode"><pre class="language-plain"><code>GET /connectors
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>因此如果想操作 Connector 集群, 直接调用集群暴露的 API 即可. 如果需要了解更多 API 使用方式, 可以去查看 Apache Kafka 的 <a href="https://kafka.apache.org/documentation/#connect_rest" target="_blank" rel="noopener noreferrer">官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>接下来看一下 Kafka Connector 的具体使用案例, 让你对 Kakfa Connector 有一个更深的理解.</p> <h6 id="示例-file-to-topic-source"><a href="#示例-file-to-topic-source" class="header-anchor">#</a> 示例:File to Topic Source</h6> <p>这是一个 Kafka SourceConnector 示例, 它的功能是<strong>订阅文件数据写入到 Topic</strong>.</p> <div class="language-yml line-numbers-mode"><pre class="language-yml"><code>name=local<span class="token punctuation">-</span>file<span class="token punctuation">-</span>source
connector.class=FileStreamSource
tasks.max=1
file=test.txt
topic=connect<span class="token punctuation">-</span>test
transforms=MakeMap<span class="token punctuation">,</span> InsertSource
transforms.MakeMap.type=
org.apache.kafka.connect.transforms.HoistField$Value
transforms.MakeMap.field=line
transforms.InsertSource.type=
org.apache.kafka.connect.transforms.InsertField$Value
transforms.InsertSource.static.field=data_source
transforms.InsertSource.static.value=test<span class="token punctuation">-</span>file<span class="token punctuation">-</span>source
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>这个 demo 的意思是: 将 test.txt 文件中的数据导入到名为 connect-test 的 Topic 中. 并在导入数据的过程中, 对数据进行清洗转换. 清洗转换的逻辑为: 把文本中每行的值加上 key: line, 然后每行数据添加一个固定值 <code>&quot;data_source&quot;:&quot;test-file-source&quot;</code>​, 最后将数据转换为 JSON 格式.</p> <div class="language-json line-numbers-mode"><pre class="language-json"><code>输入<span class="token operator">:</span> 
<span class="token string">&quot;foo&quot;</span>
<span class="token string">&quot;bar&quot;</span>
<span class="token string">&quot;hello world&quot;</span>
输出<span class="token operator">:</span> 
<span class="token punctuation">{</span><span class="token property">&quot;line&quot;</span><span class="token operator">:</span><span class="token string">&quot;foo&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;data_source&quot;</span><span class="token operator">:</span><span class="token string">&quot;test-file-source&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;line&quot;</span><span class="token operator">:</span><span class="token string">&quot;bar&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;data_source&quot;</span><span class="token operator">:</span><span class="token string">&quot;test-file-source&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;line&quot;</span><span class="token operator">:</span><span class="token string">&quot;hello world&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;data_source&quot;</span><span class="token operator">:</span><span class="token string">&quot;test-file-source&quot;</span><span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>从运行的角度看, 通过 RESTful API 调用 POST 的 /connectors 接口提交任务. 连接器 Runtime 会对应创建一个 Connector, 然后根据设置的 Task 数量, 将多个 Task 分配给不同的 Worker 节点. Worker 节点会以线程的形式去运行每个 Task, 从源端读取数据, 处理转换, 然后写入到下游.</p> <h5 id="总结-40"><a href="#总结-40" class="header-anchor">#</a> 总结</h5> <p><strong>连接器也称为 Connector, 它是将数据从源端搬到目标端的组件. 消息队列连接器和普通连接器的区别是, 消息队列的连接器的其中一端一定是消息队列</strong>.</p> <p>数据集成是一个概念, 不是一个具体的功能组件. 它描述的是将数据从数据源搬到数据目标的过程. 消息队列连接器只是数据集成概念下的一种具体实现方案.</p> <p>从是否缓存数据的角度看, 数据集成有典型数据集成组件和消息队列连接器两种方案. 它们最大的差别是, 消息队列连接器需要把数据先存储到消息队列中缓存, 然后根据需要再从消息队列中消费数据, 导入到下游. 而典型数据集成组件是将数据直接导入到下游组件的.</p> <p>从功能上来看, 典型的数据集成适合数据源和数据目标是一对一的场景, 消息队列连接器适合数据源和数据目标是一对多的场景.</p> <p>从技术上看, 消息队列连接器由 Runtime, Connector, Transforms 三部分组成. Runtime 本质上是一个分布式任务调度集群, 用来创建, 分配, 调度 Connector 和 Task 任务的运行, 停止, 更新等. Connector 一般会分为源连接器和目标连接器两种, 功能上分别表示将数据导入, 导出消息队列. Transforms 的作用是通过配置化的参数, 完成对数据的清洗和转换等操作.</p> <p>业界主流消息队列 Kafka, RocketMQ, Pulsar 都支持连接器的概念, 组件名称分别是 Kafka Connector, RocketMQ Connector, Pulsar IO. 从技术原理上看, 设计思路都是一致的, 核心都是一个分布式的任务调度平台, 并在平台上执行分布式的 Source 和 Sink 任务.</p> <h5 id="思考题-29"><a href="#思考题-29" class="header-anchor">#</a> 思考题</h5> <p>分布式任务调度平台的作用就是负责任务的运行, 调度, 启停. 从功能上来看, 像 Spark/Flink, Mesos 等分布式任务调度平台都具备这个能力, 为什么主流的消息队列还要自己独立开发 Runtime 呢?</p> <p>连接器实现的功能就是数据集成. 而数据集成的功能有很多方案都可以满足, 比如基于 Serverless Function 的流式数据处理方案和事件驱动架构都可以实现同样的功能. 在开源社区, 也有比如 Flink, Spark 这种流计算引擎可以实现. 另外也有专门的数据集成组件, 比如 DataX, SeaTunnel, Flink CDC 等. 所以说, 从数据集成的功能来看, 竞争是非常激烈的. 因此看起来, 消息队列没必要自己开发连接器.</p> <p>但是主流消息还是支持连接器, 我认为核心原因就是<strong>生态的闭环</strong>. 所以说不管是哪一款主流 MQ 的连接器, 比如 RocketMQ, Pulsar, Kafka, 它们主打的核心竞争力都是和当前的 MQ 绑定, 使用较为轻量. 就是说, 希望用户在使用当前消息队列的基础上, 能够轻量地完成数据接入和流出. 从这个角度来看, 消息队列连接器是有一定意义的.</p> <p>但我个人认为, 随着业界主流的流计算引擎和数据集成组件的开源和丰富, 这些组件会和消息队列连接器抢用户, 因为它们的功能存在相对严重的同质化. 本质上这些开源组件完成数据集成任务会比消息队列实现的连接器更加专业. <strong>所以消息队列连接器在客户侧的需求不会这么强烈, 这也是在技术领域, 你可能很少听到它们的原因之一</strong>.</p> <h4 id="_41-容灾-如何实现跨地域-跨可用区的容灾和同步"><a href="#_41-容灾-如何实现跨地域-跨可用区的容灾和同步" class="header-anchor">#</a> 41-容灾:如何实现跨地域,跨可用区的容灾和同步?</h4> <p>近几年, 多个知名互联网平台都出现过服务长时间不可用的情况, 原因有机房断电, 网络电缆中断等. 对于业务侧来说, 需要保证业务在任何情况都能正常运行, 即<strong>服务自身拥有容灾能力是基本要求</strong>.</p> <p>而消息队列作为基础组件, 容灾是它的基本能力. 所以这节课将会详细讲一下<strong>消息队列集群在发生异常时如何做好容灾, 以及异常时如何保证数据不丢失</strong>.</p> <h5 id="容灾能力的理论基础"><a href="#容灾能力的理论基础" class="header-anchor">#</a> 容灾能力的理论基础</h5> <p>先来看一些容灾相关的基础理论知识点.</p> <p><strong>当系统发生这些异常时, 服务能够自动切换并正常运行就是我们说的容灾</strong>. 下面盘点几个常见的故障场景.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/78685dac13835fe3999aa816yy68b4c3-20240421231949-4knrcsi.jpg" alt=""></p> <p>为了完成容灾, 从技术上来看, 容灾行为可以在集群内或者集群间完成. 所以容灾可以分为<strong>集群内容灾和集群间容灾</strong>两种类型. 接下来详细了解一下这两种类型.</p> <h6 id="集群内和集群间容灾"><a href="#集群内和集群间容灾" class="header-anchor">#</a> 集群内和集群间容灾</h6> <p>先来看下图, 这是一个同时具备跨可用区和跨地域容灾特性的集群架构.</p> <p>​<img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d07dabc51c22cb85fd6d3372bd720bd9-20240421231949-9zkzos4.jpg" alt="">​</p> <p>如上图所示, 有主备两套集群. 这两套集群分别部署在上海和广州, 且这两套集群都是<strong>跨可用区部署</strong>的. 所以当某个节点, 某个机架, 某个可用区发生故障时, 可以通过主从切换来恢复服务. 当某个地域故障时, 也可以通过主备切换来恢复服务.</p> <p>集群内容灾主要靠 <strong>主从切换</strong> 来达到容灾效果, 集群间容灾主要靠 <strong>主备集群</strong> 切换达到容灾效果. 从部署形态来看, 这两种容灾方式, 都可以是<strong>跨机架, 跨可用区, 跨地域部署</strong>的形式.</p> <p>而为了衡量容灾切换的质量, 会通过 RTO 和 RPO 两个指标来评估集群的容灾能力. 下面带了解下什么是 RTO 和 RPO.</p> <h6 id="rto和rpo"><a href="#rto和rpo" class="header-anchor">#</a> RTO和RPO</h6> <p><strong>RTO(Recovery Time Objective)指故障发生时业务系统所能容忍的服务停止时间</strong>. RTO 越低, 表示业务对服务的可用性要求越高.</p> <p><strong>RPO(Recovery Point Objective)指故障发生时可能有多少数据会丢失</strong>. RPO 越低, 表示业务对数据的可用性要求越高.</p> <p>正常来说, RTO 和 RPO 越低越好, 即服务故障时间越短越好, 丢失的数据越少越好. 理想情况或在一些金融场景下, 会要求 RTO 和 RPO 都做到 0.</p> <p>那么有了理论基础之后, 接下来详细看一下集群内容灾和集群间容灾的实现方案和原理分析.</p> <h5 id="集群内容灾方案的原理分析"><a href="#集群内容灾方案的原理分析" class="header-anchor">#</a> 集群内容灾方案的原理分析</h5> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/422301e2a0308f69ca0a85799d281711-20240421231949-55dj4tn.jpg" alt=""></p> <p>如上图所示, 这是一张集群内容灾的架构图, 可以看到 <strong>Broker 节点和副本都是分布在多个可用区的</strong>. 所以, 实现集群内容灾应该包含 3 个步骤:</p> <ol><li>将 Broker 部署到不同的可用区</li> <li>控制分区的副本分布在不同的可用区</li> <li>控制主从切换</li></ol> <p>将 Broker 部署在不同的可用区是运维的工作, 比较简单. 直接购买不同可用区的节点, 安装服务即可.</p> <p><strong>控制副本分布在多个可用区是容灾的核心</strong>. 前面讲了创建 Topic 的流程, 可以在这个创建流程中加上一步: <strong>感知 Broker 节点属于哪些可用区, 然后控制副本落在不同的可用区</strong>.</p> <p>一般情况下, 跨可用区集群的可用区数量没有限制, 可以是 2 个, 3个, 甚至 4 个. 此时建议集群中 Topic 的副本数是可用区数量的倍数, 比如双可用区, 则副本数建议是 2, 4, 6 这样子. 因为<strong>副本数是可用区的倍数的话, 可以尽量保证两个可用区之间的流量分布是均衡的</strong>.</p> <p>当副本分布在多个可用区之后, 则依赖内核自带的主从副本切换机制来完成容灾切换. 当 Broker 节点, 机架, 机房故障时, 就可以快速完成服务切换.</p> <p>接下来看看在集群内容灾场景中, RTO 和 RPO 的表现.</p> <h6 id="rto和rpo-2"><a href="#rto和rpo-2" class="header-anchor">#</a> RTO和RPO</h6> <p>集群内主从切换, 理论上是无法做到 RTO 为 0 的. 前面讲过, 主从切换需要经过 Broker 异常感知, Controller 控制 Leader 切换, 客户端感知 Leader 切换, 数据写入新 Leader 这几个步骤. 整套流程下来, 最少都是秒级的.</p> <p><strong>RPO 的值取决于一致性协议的设置</strong>. 一致性协议有强一致, 弱一致, 最终一致三种. 如果是强一致性协议, 则主从切换的 RPO 一定是 0, 不会丢数据. 如果不是强一致性协议, 就有可能丢数据, 此时 RPO 大于 0. 弱一致性的 RPO 的值大于最终一致, 因为弱一致丢数据的概率更大.</p> <p>从功能上来看, 集群内跨可用区容灾可以解决单节点故障, 机房故障, 可用区故障等问题, 但是解决不了整个地域故障的问题. 所以接下来再看看集群间(跨集群)容灾方案的实现.</p> <h5 id="跨集群容灾方案的原理分析"><a href="#跨集群容灾方案的原理分析" class="header-anchor">#</a> 跨集群容灾方案的原理分析</h5> <p>跨集群容灾, 顾名思义是指<strong>两套集群间的主备容灾</strong>. 相对集群内容灾, 这种方案除了解决地域级别的故障外, 还能解决集群内部比如元数据丢失, Topic 负载异常导致整个服务不可用的问题.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d4e409b07d917b88b53a69b02828030b-20240421231949-qxli3wy.jpg" alt=""></p> <p>如上图所示, 这是一张主备集群的架构图. 可以看到, 主备集群的核心是 <strong>主备集群之间消息数据和集群元数据的复制</strong>. 从技术上看, 主备集群之间数据的同步工具, 可以是前几节课讲到的连接器, 事件驱动架构, Serverless Function 等方案. 这些方案的技术思路是一致的, 只是底层运行的 Runtime 不一样.</p> <p>因为需要同时复制消息数据和元数据, 所以主备复制应该有两条链路, 分别是 <strong>实时同步消息数据</strong> 和 <strong>实时同步集群元数据</strong> 的链路. 从代码的角度, 可以理解为有两个 Connector, 一个是同步消息数据的 Connector, 一个是同步元数据的 Connector.</p> <p>那这两条链路数据的复制方式是怎样的呢? 接下来看一下<strong>主备集群之间数据的复制方式</strong>.</p> <h6 id="两种复制方式"><a href="#两种复制方式" class="header-anchor">#</a> 两种复制方式</h6> <p>目前主要有 <strong>独立运行复制组件, 主集群复制, 备集群复制</strong> 三种思路. 这三种方式的主要区别在于, 复制组件运行在哪里. 技术思路比较直观, 就不展开细讲了.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/3888cac8e6149c171d08fb2546009a3c-20240421231949-epn3vh9.jpg" alt=""></p> <p>比较推荐尝试 &quot;独立运行复制组件&quot; 的思路. 因为这个方案从开发, 稳定性, 运维, 升级的角度看, 都会比较独立且不会影响主备集群原本的功能.</p> <p>下面再来看看客户端是如何访问 Broker 集群的.</p> <h6 id="客户端连接集群"><a href="#客户端连接集群" class="header-anchor">#</a> 客户端连接集群</h6> <p>一般有 &quot;直连 Broker&quot; 和 &quot;通过网关或虚拟 IP 连接 Broker&quot; 两种方案.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d7344bfc9d4cb68cb2971ef296e938fe-20240421231949-v5m4kwg.jpg" alt=""></p> <p>如上图所示, <strong>直连 Broker 是指客户端直接配置 Broker 地址来访问集群. 通过网关或者虚拟 IP 连接则是在客户端和 Broker 之间加一个中间层, 请求先到中间层, 中间层再将请求转发到真实的 Broker</strong>.</p> <p>主备集群切换时, 这两种连接方式的切换策略是不一样的, 同时 RTO 和 RPO 的表现也会不一样, 来看一下细节.</p> <h6 id="主备切换"><a href="#主备切换" class="header-anchor">#</a> 主备切换</h6> <p>在切换时, 直连 Broker 的方案一般需要客户端修改配置在代码中的 Broker 地址, 然后重启集群. 但是这种方案的人工操作成本太高了, 而且 RTO 也会很高.</p> <p>为了解决这个问题, 在实际落地中就有 <strong>通过域名来访问集群</strong> 的方案. 即<strong>配置域名解析</strong>, 然后在代码中配置域名访问, 此时代码会根据域名解析到真实的 Broker 的 IP 完成访问. 基于 DNS 的方案, 切换时只需要修改 DNS 解析的 IP 和端口即可, 操作成本会降低很多.</p> <p>不过, DNS 方案虽然避免了修改配置, 但还是有两个风险需要关注.</p> <ol><li><strong>节点会缓存 DNS 信息</strong>, 默认情况下 DNS 的过期时间是 10 分钟, 因此可能会出现最长 10 分钟内客户端无法感知主备切换, 客户端还连接在老集群上, 从而导致服务异常的情况.</li> <li><strong>消息队列客户端和 Broker 之间是长连接</strong>, 即使本地 DNS 解析信息更新, 如果长连接没有断开, 客户端可能还是连接在老节点上, 此时服务也可能异常.</li></ol> <p>所以如果是基于 DNS 的方案, 切换的流程应该包含两步: <strong>首先是确认本地 DNS 信息已更新,</strong> <strong>然后通过重启服务保证客户端连接到新的节点</strong>.</p> <p>通过网关或虚拟 IP 连接 Broker 方案的主备切换方式是, <strong>修改网关或者虚拟 IP 后面映射的 Broker 地址</strong>, 从而实现客户端不需要修改配置和重启服务就能连接到新的 Broker. 这种方案是比较优雅的, 也是<strong>比较推荐</strong>的.</p> <p>这里需要注意的是, 从消费的视角来看, 主备切换时可能会出现有些数据在老集群还没有被消费, 此时这批数据短时间内不会被消费. 这种场景需要消费端能够支持双向集群消费或者回溯消费, 才能保证不漏消费数据.</p> <p>讲到这里应该就知道了, 这两种接入方式的主要区别就是<strong>容灾切换时的成本和影响不同</strong>. 从技术上来看, 第二种方案在容灾切换时的表现会更好.</p> <p>但是这两种切换方式都会遇到一个问题, 那就是当备集群提升为主集群后, 数据如何同步回主集群? 这就涉及到主备集群的双向同步问题了. 所以接下来再来看看<strong>主备集群之间是如何实现数据双向同步</strong>的.</p> <h6 id="双向同步"><a href="#双向同步" class="header-anchor">#</a> 双向同步</h6> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/5aec760e555a63883e23ac26f36e112c-20240421231949-xum5gmn.jpg" alt=""></p> <p>双向同步的数据包括元数据和消息数据.</p> <p>元数据双向同步的核心是 <strong>确认元数据信息以哪个集群为准</strong>. 因为如果短时间内发生多次主备切换, 就可能出现主备集群中某个 Topic 的配置不一样的情况.</p> <p>此时 Topic 配置应该以哪个集群为准呢? 是当前的主集群吗?</p> <p>其实不应该直接以当前的主集群为准. 因为当配置发生变更时, 当前的主集群可能就不是主集群了. 所以最合理的方案是: 以 Topic 配置变更时的主集群为主, 即当时哪个集群是主集群, 就以这个集群的配置为准. 但是在实际业务场景中, 频繁主备切换加上配置变更, 可能会出现无法精准识别配置变更时哪个是主集群的情况, 或者很难拿到当时的配置信息.</p> <p>所以更常用的方案是: 标记元数据信息的主集群, 元数据信息只在主集群上进行变更, 备集群永远是同步的角色. <strong>即不管主备如何切换, 复制方向都不变</strong>. 这种方案的好处是实现成本较低, 也没有明显的缺点.</p> <p>消息数据双向同步的核心是 <strong>解决消息回环的问题</strong>. 即启动双向同步后, 可能会出现消息在主从之间来回同步, 从而形成回环. 而解决回环的思路就是标记消息的来源集群.</p> <p>实现的思路就是通过在消息的 Header 中设置 source 字段来表示消息的来源集群, 从而解决消息回环问题.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/687608aba2b19a87e06dfc8f56999c60-20240421231949-6ylxlka.jpg" alt=""></p> <p>如上图所示, 客户端将数据直接写入集群时, 消息 Header 中 source 字段为空. 比如集群 C1 的数据 A1-A6, 集群 C2 的数据 A7-A8. 主备集群 C1 和 C2 开启了双向同步后, 同步数据时会执行以下四步判断:</p> <ol><li>判断消息 Header 是否有 source 信息, 否的话就将其同步到目标集群.</li> <li>如果是, 则判断 source 字段包含的集群是否和目标集群一样. 如果是, 则不进行投递; 如果否, 则正常进行同步.</li> <li>当消息写入目标集群时, 设置消息 Header 中 source 字段的值为源集群.</li> <li>当反方向同步时, 执行 1~3 步的判断, 就可以解决消息回环的问题.</li></ol> <p>最后来看一下在跨集群容灾的场景中, RTO 和 RPO 的表现.</p> <h6 id="rto和rpo-3"><a href="#rto和rpo-3" class="header-anchor">#</a> RTO和RPO</h6> <p>在跨集群容灾的场景中, <strong>RTO 一定是大于</strong> <strong>0</strong> <strong>的</strong>. 如果是使用直连 Broker 方案, 则通过修改配置, 重启客户端的形式来进行切换, 此时 RTO 能做到多少取决于客户端自动化运维的程度. 但是服务重启本身需要花费时间, 所以应该是分钟级的. 如果使用网关和虚拟 IP 的方案, 通过修改网关或者虚拟 IP 后面的 RS 的映射, 触发客户端重连, 理论上有可能做到秒级.</p> <p>因为主备集群之间数据是双向同步的, 及时数据没完成同步就发生切换, 数据还是会留在老集群不会丢失, 所以 <strong>主备切换场景中的 RPO 在大部分情况下可以做到</strong> <strong>0</strong>.</p> <p>从业界来看, Kafka 和 Pulsar 官方推出了自己的跨集群容灾方案, 技术思路基本一致. 所以接下来就挑 Kafka MirrorMaker 来分析一下它的实现.</p> <h5 id="apache-kafka-mirrormaker"><a href="#apache-kafka-mirrormaker" class="header-anchor">#</a> Apache Kafka MirrorMaker</h5> <p>Apache Kafka 官方提供的主备集群复制方案, 叫做 <strong>MirrorMaker</strong>, 它的功能是实现主备集群之间消息数据和元数据的复制.</p> <p>MirrorMaker 有 V1 和 V2 两个版本, 两个版本最大的区别是 V2 支持消费进度信息的同步, V1不支持. 所以接下来就以 MirrorMaker2 的实现为主展开讲解.</p> <p>先来看一下它的系统架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ceb30a9ba28d9e39bd5cf2ca6f10e0d8-20240421231949-b48eatv.jpg" alt=""></p> <p>如上图所示, MirrorMaker 是一个可以<strong>独立部署的应用程序</strong>, 它支持以集群模式运行. 它的底层是基于 Kafka Connector 来实现的, 简单理解就是, <strong>MirrorMaker 封装了多个 Connector. 比如同步消息数据和元数据的 Connector, 心跳检测的 Connector, Checkpoint 的 Connecor 等等</strong>.</p> <p>在数据复制方面, 它支持以下 3 种类型的数据复制:</p> <ol><li>从源集群消费数据, 再将消息数据生产到目标集群.</li> <li>同步源集群的 Topic, 分区, 配置等元数据到目标集群.</li> <li>同步消费分组的进度到目标集群.</li></ol> <p>同时 MirrorMaker 提供了故障转移和恢复功能. 即如果 Worker 出现故障, 其他 Worker 会自动承担其任务. 从技术上来看, 消息数据和元数据同步的底层原理, 跟前面讲的一样, 这里不再赘述. 下面主要看一下<strong>消费位点的同步</strong>, 这个比较重要.</p> <h6 id="消费位点同步"><a href="#消费位点同步" class="header-anchor">#</a> 消费位点同步</h6> <p>消费进度是由消费分组名称(订阅名称)+ Topic + 分区这个三元组标识的. 那是不是直接把这部分数据复制到备集群就好了呢?</p> <p>答案是否定的. 因为<strong>同步 Offset 时需要先识别和记录分区在主备集群中 Offset 的映射关系</strong>. 什么意思呢? 先来看下面这张图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/b3f90573314dd7b3aff592a1c33e7f4f-20240421231949-u9fu7pr.jpg" alt=""></p> <p>如上图所示, 在复制过程中, 消息数据是先从源集群消费再写入到目标集群的. 因为消息队列消息数据有过期机制, 可能就会 <strong>导致一条数据在源分区和目标分区中的偏移量不一样</strong>. 一般是<strong>源集群的 Offset 大于目标集群的 Offset</strong>.</p> <p>所以如果直接将源集群的消费位点信息同步到目标集群, 则会出现 Offset 错乱. 比如上图中源集群消息 A4 的 offset=4, 当某个消费分组消费到这条数据, ConsumeOffset 就为 4. 如果把 ConsumeOffset=4 复制到目标集群, 因为目标集群中 A4 的 Offset 为 14, 所以就对应不上了, 那么就会出现消费关系错乱.</p> <p>所以同步 ConsumeOffset 的时候, 如果消费到 A4, 则需要记录一下源集群 Offset=4 和目标集群 Offset=14 的<strong>映射关系</strong>, 以保证消费的是同一条消息.</p> <p>从实现的角度, MirrorMaker 在同步消费进度时, 会在一个内部 Topic 存储 Offset 的映射信息, 然后<strong>通过这个映射关系在备集群找到准确的消费位点</strong>.</p> <h5 id="总结-41"><a href="#总结-41" class="header-anchor">#</a> 总结</h5> <p>容灾是指当系统发生这些异常时, 服务能够自动切换, 并正常运行. 可以通过 RTO 和 RPO 来衡量容灾的质量. RTO 是指发生故障时业务系统所能容忍的最长停止服务时间, RPO 是指在故障期间能够容忍多少数据丢失. 业务追求的是 RTO 和 RPO 都为 0, 或者无限趋近于 0.</p> <p><strong>容灾分为集群内容灾和集群间容灾两种方案. 可用性最高的方案是同时具备集群内容灾和集群间容灾两种能力的集群</strong>.</p> <p>集群内容灾主要靠主从切换来达到容灾效果, 集群间容灾主要靠主备集群切换达到容灾效果. 主从切换是集群内自带的机制, 没有额外的开发量. 主备切换需要解决客户端切换, 数据双向同步, 消费位点同步等技术问题. 所以从实现角度看, 集群间容灾比集群内容灾的技术复杂度高很多.</p> <p>集群内容灾的 RTO 一般是大于 0. RPO 取决于一致性协议的设计, 强一致性协议时能做到 RPO 为 0, 弱一致性协议的 RPO 大于最终一致性协议. 跨集群容灾的 RTO 一般是大于0, RPO 一般可以做到 0.</p> <p><strong>业界主流消息队列都支持集群内容灾, 主从副本切换的方案</strong>. 在跨集群容灾方面, 理论上所有的消息队列都是依赖第三方组件实现的跨集群容灾, 只有 Kafka 和 Pulsar 官方推出了集群间复制的方案.</p> <h4 id="_42-消息中台-如何搭建企业内部统一的消息服务"><a href="#_42-消息中台-如何搭建企业内部统一的消息服务" class="header-anchor">#</a> 42-消息中台:如何搭建企业内部统一的消息服务?</h4> <p>同时使用多款消息队列, 从业务视角来看会增加学习和使用成本, 从公司视角看会增加运维和资源成本. 所以在一些有基础架构团队的企业, 都会有收拢消息队列服务的需求, 因此<strong>搭建消息中台</strong>总会被提起或者提上日程.</p> <p>那么这节课就来讲一下如何搭建企业内部中台型的消息服务, 会围绕主要的技术方案展开, 详细分析每个方案的实现思路以及优劣势.</p> <h5 id="统一的消息服务"><a href="#统一的消息服务" class="header-anchor">#</a> 统一的消息服务</h5> <p>首先来看一下什么是<strong>统一的消息服务</strong>.</p> <p>它是指<strong>收拢企业内部的消息组件, 集中交付, 运维, 管理等等</strong>. 业务侧不需要过多关心运维运营方面的细节, 专注使用就好.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/ba2d80c581224b89f0048e4ed297658b-20240421231949-zg0dw5x.jpg" alt=""></p> <h6 id="paas化和中台化"><a href="#paas化和中台化" class="header-anchor">#</a> PaaS化和中台化</h6> <p>从实际落地的角度来看, 统一消息服务一般有 PaaS 化和中台化两种方案.</p> <ol><li><strong>PaaS 化</strong>, 指由<strong>统一的团队提供各种开源的消息队列服务</strong>. 当业务需要某款消息队列时, 基础团队负责交付, 运维, 故障处理, 监控体系搭建等工作, 业务侧只需要负责使用即可.</li> <li><strong>中台化</strong>, 指通过<strong>提供统一的接入层负责消息的读写</strong>. 屏蔽底层细节, 以降低业务方使用成本和切换成本, 规范业务使用方式, 从而提升系统稳定性, 加快处理问题的速度.</li></ol> <p>但某种意义上说, PaaS 化只是降低了一部分业务团队使用消息队列过程中的搭建, 维护, 故障处理成本, 但是各个业务系统还是直接使用的各种开源消息队列, 所以还是会遇到各种问题, 比如功能, 稳定性, 容灾等等.</p> <p>中台化则会提供统一的接入层, 来支持各个业务的接入使用. 如下图所示, 统一接入层的存在对业务屏蔽了底层具体的存储引擎, 容灾情况, 使用率和运营调度等细节. 它的好处是业务只需要关注使用, 这样可以极大地降低使用成本, 并且可以通过提高资源利用率来降低资源成本, 通过多种容灾策略来提升系统稳定性.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/e044a02yy0f8af4b4bf0422dc60yy82e-20240421231949-avb4n0s.jpg" alt=""></p> <p>那这里就有一个问题, 应该选择哪种方案呢?</p> <h6 id="两种方案对比"><a href="#两种方案对比" class="header-anchor">#</a> 两种方案对比</h6> <p>从技术上看, 中台化相对 PaaS 化最大的区别是: <strong>通过提供统一接入层来屏蔽底层消息引擎的细节, 从而降低业务侧的理解和使用成本</strong>. 即业务不需要关注底层部署运行的是什么消息引擎, 是否做好了容灾, 如何完成主备/主从切换, 是否部署连接器同步数据等等.</p> <p>从技术上看, 中台化有两个明显的好处.</p> <ol><li>通过提供统一的接入层将基础能力下沉, 屏蔽底层细节, 可以降低业务侧使用消息队列的成本, 让业务侧更专注业务.</li> <li>底层的变更无需用户感知, 因此可以不断升级优化底层架构, 部署容灾策略, 甚至切换底层引擎, 从而提升消息队列服务的稳定性, 保证业务长期稳定地运行.</li></ol> <p>而中台化最大的缺点是<strong>开发成本极高</strong>, 需要投入大量的研发人力去建设平台. 它的价值只有在业务规模大, 子业务多, 业务对稳定性和可用性要求高的企业中才能更好地体现出来.</p> <p>如果一个企业只有少数消息队列需求, 且在使用, 运维, 升级方面的成本不高的情况下, 用 PaaS 化的方案就够了. 这也是为什么一般只有一些大企业才会建设自己的中台化消息服务.</p> <p>所以总结来看, 消息中台的必要性是根据企业的规模, 使用量, 对稳定性的需求来评估的. <strong>是一个可选项, 而不是一个必选项</strong>.</p> <p>清楚了什么是统一的消息服务, 接下来详细聊聊它的<strong>两种实现形态, PaaS 化和中台化的技术实现思路</strong>.</p> <h5 id="paas化的技术实现分析"><a href="#paas化的技术实现分析" class="header-anchor">#</a> PaaS化的技术实现分析</h5> <p>消息队列服务 PaaS 化是一种<strong>半托管</strong>的形态. 如下图所示, 基础服务团队负责搭建对应的 PaaS 平台, 提供各种基础的消息队列服务, 并提供对应的配套设施, 比如基础运维平台, 对接日志, 监控, 告警平台等等.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/13b1a0cd17cb534b7c75801493byyff8-20240421231949-leieffy.jpg" alt=""></p> <p>从具体落地来看, 工作量分为<strong>平台搭建和成本/稳定性</strong>两部分.</p> <p><strong>平台搭建</strong> 指搭建基础 PaaS 运维平台, 需要提供集群自动化部署, 升级, 扩缩容, 集群资源增删改查, 监控, 告警, 日志等能力. 集群部署的自动化主要依赖运维手段来完成, 比如公司的 CI/CD 系统, 运维常用的工具 Ansable 等. 监控, 告警, 日志一般集成公司内部的系统, 或者 ELK, Grafana + Prometheus 等. 这块的思路相对清晰, 执行也有比较多的方案可以参考.</p> <p><strong>成本/稳定性</strong> 指集群容灾部署, 提升资源利用率, 弹性扩缩容, 紧急故障恢复, 日常问题处理 SOP 等工作. 这一块挑战是比较大的, 只有深入了解对应的消息引擎的底层原理和源码, 才能做好这部分的事情. 因此如果需要运维多个消息队列, 成本就会上升很多.</p> <p>消息队列服务 PaaS 化, 主要的工作量就是上面说的那几点, 技术难度不高, 这里就不详细展开讲了. 接下来重点讲一讲中台化的技术实现思路.</p> <h5 id="中台化的技术实现分析"><a href="#中台化的技术实现分析" class="header-anchor">#</a> 中台化的技术实现分析</h5> <p>先来看一张消息中台的系统架构图.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/8ed0e48e843a872e0e98c2d9b6e8f50a-20240421231949-g3lyppy.jpg" alt=""></p> <p>如上图所示, 从技术上拆解消息中台, 应该包括<strong>底层存储引擎的选择, 接入层协议设计, 接入层开发, 自定义 SDK 开发, 配套基础设施开发</strong>五个部分.</p> <p>接下来就分析一下这五个部分的实现, 先来看一下存储引擎的选择.</p> <h6 id="存储引擎的选择"><a href="#存储引擎的选择" class="header-anchor">#</a> 存储引擎的选择</h6> <p>从单个企业的角度看, 不管对于大企业还是中长尾企业, 自研消息内核的成本都非常高, 周期也很长. 因此, 如果业务上没有开源组件满足不了的痛点, 基本不会走这条路. 所以<strong>底层存储引擎一般会选择业界主流的开源消息队列</strong>, 比如 Kafka, RocketMQ, Pulsar 等等.</p> <p>从落地的角度, 一般会选择一个当前阶段比较适合的引擎.</p> <p>RabbitMQ 是业务消息类的消息队列, 架构上有一些天然的缺陷, 比如一致性协议的设计导致其性能不高, 很难满足一些大流量和高并发的消息需求. 网络分区的存在导致在一些极端的场景下可能会出现消息服务中断的问题. 而 Pulsar 作为一个新兴的消息队列, 稳定性和功能完整度还不够承载现网的业务.</p> <p>所以综合考虑, <strong>一般会在 Kafka 和 RocketMQ 中做选择</strong>. 而选型主要考虑以下两个方面:</p> <ol><li>功能和流量方面的需求, 即根据公司的业务形态去评估这两方面诉求的侧重点. 这点跟消息队列选型的思路是一致的.</li> <li>比较主观, 就是公司人员对于这两款消息队列的熟悉程度和把握度.</li></ol> <p>但是选型并不是二选一. 因为接入层的存在, 底层是可以同时运行多种引擎来提供服务的, 所以在具体引擎的选择上, 可以根据业务需求随时切换, 不会涉及客户端的修改. 这也是消息中台的好处之一.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/1611de07348f69d9114604825762ce0f-20240421231949-vmx97ra.jpg" alt=""></p> <p>接下来来看看接入层的协议设计.</p> <h6 id="接入层协议设计"><a href="#接入层协议设计" class="header-anchor">#</a> 接入层协议设计</h6> <p>接入层协议设计, 跟前面讲到的协议设计思路是一致的. 所以接下来主要讨论接入层用什么协议?</p> <p>从落地角度看, 因为私有协议的可控性和灵活度高, 所以消息中台接入层的协议一般都是私有协议. 私有设计跟正常开源协议的设计思路不太一样, 主要考虑以下三点:</p> <ol><li>消息中台的协议是给企业内部使用的, 不需要太考虑协议的通用性和兼容性, 只要能满足业务的需求即可.</li> <li>根据二八原则, 企业内部业务大部分不需复杂的消息队列功能, 所以说开源协议中的很大一部分协议对于消息中台是没有意义的.</li> <li>因为是公司内部的服务, 业务侧是可以沟通和定义使用规范的, 所以可以通过和业务沟通, 降低协议设计的复杂度.</li></ol> <p>因此, <strong>如果是消息中台服务, 一般会建议自定义私有消息队列, 主要目标是简化协议的设计, 降低开发成本以及业务的使用理解成本</strong>.</p> <p>这里其实还有一点, 如果企业已经在使用开源的消息队列, 此时自定义了私有协议, 那这些存量服务该怎么处理呢?</p> <p>正常的思路就是, <strong>要将这些开源集群的服务迁移到消息中台里面, 然后通过统一的接入层提供服务</strong>. 但是这里有两个问题, 一个是底层集群的迁移方案会很复杂, 另外一点就是业务侧需要进行 SDK 切换的改造. 从工作量来看, 这两个问题的解决方案都很复杂, 特别是第二点, 业务侧的改造时间很难协调.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/c4db36cf62145cb4cba742eac2317b73-20240421231949-1gjle5a.jpg" alt=""></p> <p>所以, 就得考虑是否在接入层适配多种开源协议?</p> <p>其实从个人角度来看, 消息中台支持多协议的必要性不强, 最多支持一种企业内部用得最多的消息队列协议就可以.</p> <ul><li>从投入的角度看, 支持多协议的开发成本太高了, 会消耗大量的研发人力, 并且投入周期长.</li> <li>从稳定性的角度看, 多协议会导致业务侧直接使用开源的 SDK, 平台侧无法控制业务侧的使用方式, 从而无法统一收拢, 规避和降低风险.</li> <li>从长期维护的角度看, 多协议长期维护和配套设施建设的成本就很高.</li> <li>从业务的角度来看, 业务其实不一定需要这么多协议. 而且, 如果不限制业务的使用姿势和规范, 还可能会带来一些未知的稳定性问题, 所以我们往往还要限制使用多种协议, 这是很有必要的.</li></ul> <p>接下来再看一下接入层是如何开发的.</p> <h6 id="接入层开发"><a href="#接入层开发" class="header-anchor">#</a> 接入层开发</h6> <p>从技术上看, <strong>消息中台接入层的开发用的是代理(Proxy)的思路</strong>.</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/453ac4a68f278977fedc1f14f5bd14e5-20240421231949-bel1kgs.jpg" alt=""></p> <p>如上图所示, 接入层主要由 <strong>网关(如 Nginx), 元数据模块, 接入层集群</strong> 三部分组成. 网关用于流量接入, 拦截和分发; 元数据模块用来存储接入层相关的元数据信息; 接入层集群用于接收流量, 然后转发到存储层.</p> <p>从开发角度看, 主要开发工作量是在接入层集群. 接入层集群一般需要考虑<strong>集群构建, 协议解析, 元数据管理, 集群拆分, 连接管理</strong>五个部分.</p> <ul><li><strong>集群构建</strong>, 指设计实现接入层集群. 存算分离架构中的计算层一般是有状态的. 而消息中台接入层只需要负责数据的接收和转发, 没有太多计算逻辑, 所以接入层一般是<strong>无状态</strong>服务. 因此, 比如依赖 Nginx + Server 就可以构建一个无状态的集群了.</li> <li><strong>协议解析</strong>, 指在集群中适配解析指定协议, 比如支持 HTTP 协议或 TCP 协议. 从开发的角度看就比较直接, 在代码项目中支持两种协议即可, 不再赘述.</li> <li><strong>元数据管理</strong>, 指接入层相关的元数据存在哪里. 一般可以用 ZooKeeper 或者 MySQL 来存储. 有一点需要注意的是, 本地一般需要<strong>缓存</strong>元数据, 以避免接入层频繁访问元数据存储导致元数据存储的压力过大.</li> <li><strong>集群拆分</strong>, 指是否对接入层集群进行拆分. 即是所有接入层一套集群, 还是按照地域分集群, 或者给大客户独立搭建集群. 从落地的角度, 建议一开始一套集群就可以了, 但是需要预留拆分集群和独立集群的能力, 以便在后续拆分集群, 保证服务的可用性和横向扩容能力.</li> <li><strong>连接管理</strong>, 指接入层和存储层之间的连接管理. 因为接入层需要转发数据到存储层, 就需要使用存储层提供的 SDK 和存储层建立长连接. 此时就会存在连接冷启动和空闲连接问题.</li></ul> <p>从技术落地的角度, 接入层就是一个经典的无状态服务集群的搭建过程. 这节课只是宏观上讲了一下模块组成和注意点.</p> <p>接下来再来简单看一下自定义 SDK 和配套基础设施这两部分.</p> <h6 id="自定义sdk开发"><a href="#自定义sdk开发" class="header-anchor">#</a> 自定义SDK开发</h6> <p>如果使用的是自定义私有协议, 那么就需要提供对应的 SDK, 来降低业务侧的使用成本以及控制用户的使用姿势. 从编码的角度来看, 它的实现思路和开源 SDK 的设计思路是一致的.</p> <h6 id="配套基础设施"><a href="#配套基础设施" class="header-anchor">#</a> 配套基础设施</h6> <p>跟 PaaS 化方案的思路一样, 配套基础设施主要是解决的是资源增删改查, 配置变更, 监控, 告警, 日志查询等等功能, 属于日常的运营系统开发. 虽然这块的技术含量不高, 但是在实际业务中很重要, 需要谨慎对待.</p> <h5 id="总结-42"><a href="#总结-42" class="header-anchor">#</a> 总结</h5> <p>顾名思义, 统一的消息服务是收拢企业内部的消息组件, 然后提供统一交付, 运维, 故障处理等服务. 从实现上看, 有服务 PaaS 化和中台化两种方案.</p> <p>PaaS 化指由统一的团队提供各种开源的消息队列托管服务. 中台化指通过提供统一的接入层负责消息的读写. 两种方案的主要区别在于, 研发投入的工作量和业务感知的程度.</p> <p>中台化的研发投入很高, 它的优势只有在规模大, 对成本和稳定性有强诉求的场景才能更好地体现出来, 但它能屏蔽底层细节, 让业务专注于使用. PaaS 化的优点是开发成本低, 能满足大部分场景.</p> <p>从技术上看, PaaS 化的主要工作量是平台搭建和成本/稳定性两部分, 属于运营平台开发的范畴, 技术难度较低. 中台化则是由底层存储引擎的选择, 接入层协议设计, 接入层开发, 自定义 SDK 开发, 配套基础设施开发五个部分组成, 有一定复杂度.</p> <p>从实际落地来看, 大多数企业的业务形态都不太复杂且用量不大, 因此对消息队列的成本和稳定性的诉求没有那么高. 所以, 对于大部分企业来说, PaaS 化就可以满足大部分场景了.</p> <h3 id="结束语"><a href="#结束语" class="header-anchor">#</a> 结束语</h3> <h4 id="_43-未来-消息队列的技术架构会如何演进"><a href="#_43-未来-消息队列的技术架构会如何演进" class="header-anchor">#</a> 43-未来:消息队列的技术架构会如何演进?</h4> <p>到了本节就讲完了架构升级篇的内容, 同时本专栏中纯技术的讲解也已经结束了. 接下来开始经验总结篇的内容, 主要分享我个人在消息队列方面的一些思考, 包括<strong>未来发展, 商业化, 运维运营, 以及消息队列领域的研发人员如何提升技术能力和产品视野</strong>这五个方面. 每一讲的内容都将围绕一个问题展开, 内容相对精简.</p> <p>这节课就来梳理下消息队列的未来发展情况.</p> <p>在业界的一些技术分享中, 大家普遍会认为消息队列后面会往 <strong>云原生, 容器化, Serverless, Service Mesh</strong> 等等方向发展. 技术理念听起来很高大上, 也很符合当前技术的发展潮流. 但不知道你有没有深入思考过, 为什么是这几个方向, 而不是其他方向呢? 这几个方向的原始驱动力是什么?</p> <h5 id="价值导向的演化"><a href="#价值导向的演化" class="header-anchor">#</a> 价值导向的演化</h5> <p>在我看来, 任何一个商业化的产品中, 只有围绕  <strong>&quot;价值&quot;</strong>  出发, 才能理清楚问题的本质. 就是说做这个事情能带来什么价值, 给用户, 给平台带来什么价值. 所以想要知道消息队列未来会如何发展, 就需要先知道<strong>用户和平台</strong>要的是什么.</p> <p>从用户的角度看, 需求是很朴素的, 用户对消息队列的诉求可以总结为三个词: <strong>省钱, 能用, 好用</strong>. 无非就是花最少的钱, 用最好的服务. 而平台的要求就更简单了, 就一个词: <strong>赚钱</strong>. 就是从用户那里赚更多的钱. 听起来是冲突的, 有 GAP 点, 怎么解决呢?</p> <p>这就需要用技术来解决, 即<strong>用技术来实现一个既能让平台赚钱, 又能让用户省钱, 好用且能用的消息队列</strong>. 通过技术上的一些架构升级, 代码优化, 运维运营等手段, 来提高单位资源(CPU, 内存)可提供的服务能力, 从而在同等资源配置下, 能够提供更好, 更优质的服务, 达到双赢的效果.</p> <p>那从技术落地的角度, 围绕着这个目标, 未来应该往哪些方向发展呢?</p> <h5 id="五个发展方向"><a href="#五个发展方向" class="header-anchor">#</a> 五个发展方向</h5> <p>要达到这个目的, 结合前面所讲的技术点, 可以从<strong>融合型, 多协议, Serverless, 架构简单, 云原生</strong>五个方面来做拆解.</p> <h6 id="融合型"><a href="#融合型" class="header-anchor">#</a> 融合型</h6> <p>在前面讲到过, 消息队列从使用场景和功能的角度分为了消息和流两个方向, 分别有各自代表的消息队列. 对企业来说, 一般都需要同时使用消息和流两个方向的消息引擎. 此时遇到的问题是, 学习, 使用, 运维多款消息引擎的成本过高. 上节课讲到的消息中台, 它所提供的统一的消息服务, 就是为了解决这个问题.</p> <p>因此, 如果有一款消息引擎能够<strong>同时满足消息和流两个场景</strong>, 就能很好地解决这个问题. 这就是我认为的第一个发展方向, 融合型的消息队列. 那什么叫融合呢?</p> <p>&quot;融合&quot; 这个词参考的是数据库领域. 数据库领域因为场景丰富, 有各种方向的数据库产品, 比如 OLAP, OLTP 等等. 数据库领域为了创造能满足多种场景的数据库, 提出了融合数据库的概念. 意思就是这个数据库能同时满足多个场景, 而不仅仅局限于某个场景. 从具体的功能点来看, <strong>融合型的消息队列应该同时具备流方向的高性能, 高吞吐, 消息方向的丰富功能, 高可靠性, 低延时, 可追溯等等</strong>.</p> <h6 id="多协议"><a href="#多协议" class="header-anchor">#</a> 多协议</h6> <p><strong>多协议是指未来的消息队列可以适配现有的多种协议</strong>. 这个价值在于能够 <strong>满足存量用户的需求</strong>, 存量用户无需改造就可以直接使用.</p> <p>我们需要认识到, 引入一款新的协议, 不管是私有协议还是公有标准协议, 被用户接受并大规模使用都是非常难的. 因为这涉及到业务侧 SDK 的变更以及业务逻辑的改动, 这一点成本非常高, 改动也很困难.</p> <p>而从业界现状来看, 当前存量的这些消息队列基本能满足需求, 也都做得不错, 并不存在非换不可的理由. 因此, 多协议适配的关键就在于跳过市场培育, 减少教育用户的成本. 只要在性能, 稳定性, 成本方面做好, 就不会缺少用户.</p> <h6 id="serverless"><a href="#serverless" class="header-anchor">#</a> Serverless</h6> <p>Serverless 简单理解就是<strong>集群需要具备即时扩缩容的能力</strong>. 它核心解决的是 <strong>成本</strong> 问题.</p> <p>从用户的角度看, 自建消息队列或者购买云消息队列 PaaS 产品时, 困扰他们最大的问题就是容量评估和突发/闲置时的扩缩容. 大部分用户对资源容量的评估都非常不精准, 那么为了稳定性, 就会倾向于申请更多的资源, 从而造成很大的浪费, 导致成本居高不下.</p> <p>这样做的主要原因是消息队列是有状态的服务, 扩缩容时需要迁移数据, 而迁移时间不可控. 因此, 运维人员就会冗余更多的资源, 避免业务突发导致系统出现问题. 所以说, 如果消息队列底层架构具备随时扩缩容的能力, 就可以大大降低用户的运维成本和投入的资源成本.</p> <p>从平台的角度看, 提升产品竞争力的核心操作就是优化成本结构. 让同样的资源提供更强的服务, 那么在提供同样的服务时, 成本自然就会比自建或友商更低.</p> <p>而优化成本结构最主要的手段就是提高集群的利用率. 但是提高利用率后, 会遇到和用户一样的问题, 如何应对突发? 关键就是弹性扩缩容的能力.</p> <p>但从技术上看, <strong>当前很多消息队列的底层架构都无法做到真正的弹性. 所以, 如果消息队列的底层架构能够做到真正的弹性, 包括计算层和存储层的弹性, 也就是实现消息队列的 Serverless 化, 那么就可以给用户和平台带来极高的价值</strong>.</p> <h6 id="云原生"><a href="#云原生" class="header-anchor">#</a> 云原生</h6> <p>有的人对云原生的理解, 可能等同于 Kubernetes 和容器化, 这是不太准确的. 在我看来, 云原生的意思是, <strong>在系统架构设计时就考虑利用云的各种优势特性, 让系统更具竞争力</strong>. 竞争力可以是成本更低, 扩容更快, 稳定性更高等等.</p> <p>上面这句话不太好理解, 这里可以通过容器, 虚拟云盘, 对象存储三个云计算中的基础产品, 来说明一下什么叫做消息队列的云原生.</p> <p><strong>容器</strong> 指自建或云上 K8s 集群/容器服务. 现在很多主流消息队列都可以容器化部署, 但并不能说是能在容器中运行了. 关键是消息队列能利用到容器带来的好处. 那容器的好处是什么呢? 容器的好处就是轻量, 扩缩容快, 能够自动快速地创建出资源. 但前面讲过, 作为一个有状态的服务, 光是把服务启动起来是不行的, 还得把服务迁移过去, 才能承担流量. 所以消息队列容器化 <strong>除了能够部署在容器中以外, 还得从架构上考虑当拉起新的容器节点后, 新节点如何快速承载流量</strong>. 这就是我们说的快速扩缩容的能力.</p> <p><strong>虚拟云盘</strong> 指云上的硬盘, 它的特性是底层本身是多副本存储的. 所以相对物理硬盘, 它最大的特点是数据不会丢失, 但是单位成本更高. 所以基于数据不会丢失的特性, 在架构设计的时候, 就可以思考是否在消息队列层移除副本概念, 从而降低系统架构的复杂度以及成本.</p> <p><strong>对象存储</strong> 是云上的文件存储服务, 它最大的特性就是存储成本低. 就是说, 相对本地盘, 云盘存储, 成本会便宜很多. 所以为了优化成本结构, 提高竞争力, 就可以基于对象存储来设计存储层, 从而降低存储成本.</p> <p>所以说, 在设计架构的时候考虑云上的这些基础产品, 利用好它们的优势, 设计出有竞争力的架构, 这才是我理解的云原生架构.</p> <h6 id="架构简单"><a href="#架构简单" class="header-anchor">#</a> 架构简单</h6> <p>架构简单这个词经常被忽略, 个人认为是非常重要的. 当在内核中堆叠功能, 添加特性的时候, 系统架构就会膨胀. 比如前面讲到的存算分离, 分层存储, 多协议兼容, 集群容灾等等特性, 当增加这些特性时, 系统就会不自觉变得复杂. 所以要有意识地控制系统的复杂度, 从编码技巧, 架构设计的角度尽量让系统更加简化, 简洁.</p> <p>上面这句话有点空, 没有具体的落地措施, 可以进一步再说说. 这里我想表达的是, 设计架构时需要保证简洁的理念, 不要追求奇技淫巧, 追求复杂度和高大上, 前面其实讲过挺多了. 就比如讲集群构建时, 集群的元数据有 <strong>基于第三方组件来存储</strong> 和 <strong>集群内部自实现存储</strong> 两种方案, 从架构简洁的角度看, 就会建议使用第二种方案.</p> <p>这里总结几个简单架构的好处.</p> <ol><li>内核的开发工作量更少.</li> <li>集群更稳定, 问题更少. 因为架构更简洁, 出问题的概率就越低.</li> <li>部署时需要的资源更少, 成本更低.</li> <li>研发运维人员的学习成本更低.</li> <li>可以部署在更多的场景, 比如边缘计算, 小型机房等等.</li></ol> <p>所以总结来看, <strong>架构简单的最大好处就是可以降低成本</strong>.</p> <p>通过上述这五个发展方向, 你会发现, 它们都是围绕着 &quot;价值&quot; 这个词推导出来的. 未来的消息队列, 技术方向可能会有调整, 但是从核心来说, 是不会变的, 就是能产生什么价值.</p> <h5 id="融合型消息队列的设想"><a href="#融合型消息队列的设想" class="header-anchor">#</a> 融合型消息队列的设想</h5> <p>接下来, 我想带你简单设想一下未来的消息队列可能是什么样子的.</p> <p>基于价值和成本思维, 我希望有一个 <strong>融合型消息队列</strong>, 它能同时满足消息和流两个方向. 架构图如下:</p> <p><img src="https://nano-note.oss-cn-beijing.aliyuncs.com/images/d086623082de769a1510884ec4fd67d6-20240421231949-nf9cna3.jpg" alt=""></p> <p>这个架构由三台 Broker 组成, 没有依赖第三方组件. 从上到下分为接入层, 协议适配层, 计算层, 存储层四个部分. 希望满足的是:</p> <ol><li><strong>架构简单</strong>. 比如不依赖第三方组件来完成集群构建和元数据存储, 达到只有一台节点也可以启动服务. 此时这个消息队列就可以部署在小规格的节点, 边缘计算场景等.</li> <li><strong>多协议</strong>. 即在网络层适配多种存量协议, 比如 MQTT, AMQP 这种标准协议, 用来满足现有业务接入的需求. 使用者根据需要去启用相关协议来支持服务, 从而满足同时使用多款消息队列的业务团队, 达到一个企业只需要部署一款消息队列服务的效果.</li> <li><strong>计算层独立</strong>. 即在计算层实现各种消息队列的功能, 比如顺序消息, 延时消息, 事务消息等等. 跟协议层进行联动, 从而兼容现在各种主流消息队列, 达到功能复用, 满足各种消息队列的需求.</li> <li><strong>存储层插件化</strong>. 默认情况下是本地存储的模型, 如果需要可以配置开启存算分离或分层存储的特性架构, 用来满足不同场景对存储性能和成本的要求.</li></ol> <p>这是一个很宏大的设想, 从落地的角度看, 开发难度高, 成本高, 周期长. 但我觉得从终态来讲, 从用户的诉求出发来设想消息队列的未来是没问题的. 用户未来需要的是一个内核高度稳定, 支持多协议, 架构简单且有弹性, 学习&amp;部署&amp;运维成本低的消息队列.</p> <h4 id="结束语-尽最大的努力-做最好的自己"><a href="#结束语-尽最大的努力-做最好的自己" class="header-anchor">#</a> 结束语-尽最大的努力,做最好的自己</h4> <p>今天是这个专栏的最后一节课了. 我想和你聊聊我自己关于技术生涯的一些想法, 权当总结和共勉.</p> <p>内容可能会有点鸡汤, 道理可能你也都懂, 但同行的路上, 我觉得还是要给彼此一些鼓励和信心, 让我们都能在技术这条路上坚定地走下去.</p> <p>近几年, 关于程序员的职业生涯, 35岁是个门槛的说法, 可以说是研发人员焦虑的一大来源. 伴随着疫情, 大环境等一些因素的影响, 互联网裁员潮此起彼伏. 国内外顶尖的互联网公司都在收缩, 就业环境越来越恶劣.</p> <p>我第一份工作的 Leader 离职时, 说过这么一句话: &quot;<strong>我现在做的事情你们都能做, 那我的竞争力是什么?</strong> &quot; 那时候我刚毕业两年, 似懂非懂, 但后来这句话一直警醒着我.</p> <p>今年更是经常思考: <mark><strong>毕业多年, 我自己的核心竞争力是什么? 我和刚毕业的那些年轻同学相比, 我的优势是什么</strong></mark>?</p> <p>乐观来讲, 我觉得自己没有浪费什么时间. 从毕业到现在, 一直在学习各种技术, 看各种书, 也有一个明确的目标, 就是在行业内慢慢建立自己的影响力, 成为技术大牛. 从 Web, App 那套讲究高并发 To C 的技术栈, 到基础组件如容器, K8s, 搜索, 大数据等我都有涉猎, 到最后深入消息队列这个领域.</p> <p>悲观来讲, 我觉得现在的我和我们 Team 的成员比, 好像我做的他们也都能做, 我会的只要他们肯学他们也可以会, 甚至可以做得更好. 而且他们比我有更多的时间学习和深入思考, 对公司来讲单位时间成本也更低.</p> <p>工作多年后, 一个很残酷的事实是, <strong>慢慢认识到自己就是个普通人</strong>. 那作为普通人, 应该怎样延长自己的职业生涯呢?</p> <p>我的答案是: 要 &quot;卷&quot;, 要聪明地&quot;卷&quot;, 通过有意义, 有规划, 有目标地&quot;卷&quot;来达到目的.</p> <p>具体来讲, 我把&quot;卷&quot;拆解成四件事儿.</p> <ol><li>做一个长期坚持做事的人</li> <li>做一个靠谱的人</li> <li>做一个持续学习的人</li> <li>做一个乐观的人</li></ol> <blockquote><p>做一个长期坚持做事的人</p></blockquote> <p>我自己是比较相信, 在计算机工程方面, 拼的就是 &quot;体力活&quot;.</p> <p>只要肯花时间, 花精力, 长期坚持去学习, 去行动, 在技术能力发展方面一定会有一个好的结果, 至少可以带给我们一份稳定的工作和收入. 换句话说, <strong>长期坚持做事一定会保证你的下限</strong>.</p> <p>而如果要提高上限, 我认为还是体力活, 但得加一点小要求, 应该是聪明一点, 变通一点的体力活, 要加上 <strong>思考能力</strong>.</p> <p>思考自己还缺什么, 市场或者团队还缺什么, 哪个事情可以给你带来更高的收益. 然后及时调整学习和发展的方向, 调整做事的方式. 力求事半功倍, 切忌埋头苦干.</p> <blockquote><p>做一个靠谱的人</p></blockquote> <p>在成为技术大牛的路上, 会遇到很多分叉路口, 比如现在技术领域和方向这么多, 要学习哪些技术呢? 先走广度, 还是先走深度? 最近 AI 那么火, 要不要早点去学习?</p> <p>答案很多, 每个方向也都有成功的先例, 但可以从中找到一个共性. 如果周围人给你的标签是 &quot;<strong>靠谱</strong>&quot;, 那么你就已经在通往成功的路上了.</p> <p>靠谱说明大家信任你, 找你帮忙解决的问题你都能应对, 或者你可以协调解决, 尝试一起解决. 在这个过程中, 你会去理解同事或者客户需要什么, 下意识去完善自己的能力, 比如技术能力, 沟通能力, 团队影响力等等.</p> <blockquote><p>做一个持续学习的人</p></blockquote> <p>技术迭代这么快, 如果吃老本, 天天抱着 Java Spring 的一亩三分地, 做 CRUD 的事情, 肯定会失去竞争力.</p> <p>如果我们具备持续学习的能力, 就可以做到别人会的我也会. 而我们基于之前的经验, 掌握新技能的速度会更快. 即使更换赛道, 持续学习也可以帮助我们快速融入新环境, 在新的赛道也成为一个优秀的人.</p> <p>工作多年, 我发现身边那些技术大牛都是拥有持续学习能力的人. 他们学习的东西, 不一定是工程技术, 也不一定是最前沿的东西, 但一定是他们 <strong>需要</strong> 的.</p> <p>还有同事之间相比, 如果技术能力上有一些差距, 通过持续学习是可以赶上的.</p> <blockquote><p>做一个乐观的人</p></blockquote> <p>很多情况下, 可能付出了很多努力, 但结果依旧不尽人意. 这才是生活的常态.</p> <p>在广东, 香港这一块, 风水是一个需求很旺盛的行业. 之前不太理解, 写个代码看什么风水, 后来经历了一些事情, 才体会到寄希望于玄学是怎样的一种心态. 工作中, 除了坚持, 靠谱, 学习, 还需要一点运气. 有句话不是说嘛, 选择比努力更重要.</p> <p>但这只能算一个 buff 叠加, 我觉得还是要对自己的人生保持掌控感. 换句话说, <strong>人生不能摆烂, 听天命之前要尽人事</strong>.</p> <p>所以遇到什么事情, 我都是先努力了再说, 保持乐观的心态, 结果往往很好.</p> <p>我很理解, 大环境不好, 生活总有压力. 时代的一粒灰, 落在个人头上, 就是一座山. 困难面前, 要学会尽最大的努力, 做最好的自己.</p> <p>最后我还想分享一个我的减压方法给你, 那就是健身.</p> <p>健身对程序员来讲, 是一件 ROI 很高的事情. 它能让我们体态更佳, 身体更健康. 更重要的是, <strong>这是一件完全可控且坚持就能带来好结果的事情</strong>, 在面对很多不确定时还能带来强大的力量, 培养正面情绪. 科学上来说, 运动过程中分泌的多巴胺会冲淡很多负面情绪.</p> <p>我跑步时经常看 B 站的各种正能量短视频和番剧. 比如余华, 罗翔, 或者各种不知名的热血鸡汤短视频. 我觉得这是一个很好的充电方式, 看到大家都在努力, 也会激励到自己.</p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/xugaoyi/vuepress-theme-vdoing/edit/main/docs/30.系统/3000.系统/1100.中间件-消息队列/20-深入拆解消息队列(极客时间).md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <!----></div> <div class="page-nav-wapper"><!----> <!----></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="mailto:1174520425@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/nanodaemony" title="GitHub" target="_blank" class="iconfont icon-github"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2025
    <span>达尔文的猹 | MIT License</span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.3f3e0e10.js" defer></script><script src="/assets/js/2.e9fcb30c.js" defer></script><script src="/assets/js/3.1998f389.js" defer></script><script src="/assets/js/149.95017f0a.js" defer></script>
  </body>
</html>
